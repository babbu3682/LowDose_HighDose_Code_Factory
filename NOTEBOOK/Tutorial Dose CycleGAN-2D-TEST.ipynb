{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1.6.0 버전\n",
    "# !pip install torch==1.6.0\n",
    "# !pip install torchvision==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 13 02:40:48 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 41%   46C    P2   116W / 280W |   5982MiB / 24220MiB |     21%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 42%   48C    P0    58W / 280W |      0MiB / 24220MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 40%   48C    P0    58W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 35%   54C    P0    52W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/4.Dose_img2img/utils'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/MONAI'))\n",
    "from sunggu_utils import check_value, take_list, plot_confusion_matrix, list_sort_nicely, find_dir, plot_3D\n",
    "\n",
    "import piq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0+unknown\n",
      "Python version: 3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]\n",
      "OS version: Linux (4.4.0-206-generic)\n",
      "Numpy version: 1.19.5\n",
      "Pytorch version: 1.6.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 8.1.0\n",
      "Tensorboard version: 2.4.1\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.7.0\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.56.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import skimage\n",
    "import monai\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, GeneralizedDiceLoss, FocalLoss, TverskyLoss, NoiseRobustDiceLoss\n",
    "from monai.metrics import compute_meandice, DiceMetric, ConfusionMatrixMetric \n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet, highresnet\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadNiftid,\n",
    "    LoadNumpyd,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Lambdad,\n",
    "    ToTensord,\n",
    "    RandScaleIntensityd,\n",
    "    RandGaussianNoised,\n",
    "    RandFlipd,\n",
    "    RandZoomd,\n",
    "    RandGaussianNoised,\n",
    "    RandGaussianSmoothd,\n",
    "    RandShiftIntensityd,\n",
    "    SpatialPadd,\n",
    "    RandAffined,\n",
    "    CastToTyped,\n",
    "    DeleteItemsd,\n",
    "    FgBgToIndicesd,\n",
    "    Rand3DElasticd,\n",
    "    RandZoomd,\n",
    "    Rand2DElasticd,\n",
    "    RandWeightedCropd,\n",
    "    AsDiscrete,\n",
    "    SpatialPadd,\n",
    "    adaptor,\n",
    ")\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 시드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "set_determinism(seed=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_low_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/2D_dataset/Test/*/*Low Dose Neck*/*.npy\"))\n",
    "test_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/2D_dataset/Test/*/*Neck Other*/*.npy\"))\n",
    "\n",
    "dcm_test_low_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Cleansing_dcm_dataset/Test/*/*Low Dose Neck*/*/*.dcm\"))\n",
    "dcm_test_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Cleansing_dcm_dataset/Test/*/*Neck Other*/*/*.dcm\"))\n",
    "\n",
    "test_files = [{\"low\": low_name, \"high\": high_name, \"dcm_low\" : dcm_low, \"dcm_high\" : dcm_high} for low_name, high_name, dcm_low, dcm_high in zip(test_low_images,\n",
    "                                                                                  test_high_images, \n",
    "                                                                                  dcm_test_low_images, \n",
    "                                                                                  dcm_test_high_images)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CT에 맞는 Augmentation\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadNumpyd(keys=[\"low\", \"high\"]),\n",
    "        AddChanneld(keys=[\"low\", \"high\"]),   \n",
    "        ToTensord(keys=[\"low\", \"high\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1ecde3f77fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# check_loader = DataLoader(check_ds, batch_size=1, shuffle=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# check_data = next(iter(check_loader))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheck_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_files' is not defined"
     ]
    }
   ],
   "source": [
    "check_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "# check_loader = DataLoader(check_ds, batch_size=1, shuffle=False)\n",
    "# check_data = next(iter(check_loader))\n",
    "\n",
    "check_data = check_ds[300]\n",
    "\n",
    "print(check_data['low_meta_dict']['filename_or_obj'])\n",
    "print(check_data['high_meta_dict']['filename_or_obj'])\n",
    "\n",
    "low = (check_data[\"low\"][0])\n",
    "high = (check_data[\"high\"][0])\n",
    "print(f\"image shape: {low.shape}\")\n",
    "\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"low\")\n",
    "plt.imshow(low, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"high\")\n",
    "plt.imshow(high, cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())\n",
    "\n",
    "# Cachedataset 이거 뭔가 문제가 있음...\n",
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=16, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lambda_rule(epoch):\n",
    "#     lr_l = 1.0 - max(0, epoch + 1 - 100) / float(100 + 1)\n",
    "#     return lr_l\n",
    "\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, threshold=0.01, patience=5)\n",
    "# scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Cyclegan_sunggu.model import *\n",
    "from Cyclegan_sunggu.util import *\n",
    "import itertools\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "## 모델\n",
    "netG_low_2_high = CycleGAN_Generator(in_channels=1, out_channels=1, feature=64, norm='inorm', nblk=9)\n",
    "netG_high_2_low = CycleGAN_Generator(in_channels=1, out_channels=1, feature=64, norm='inorm', nblk=9)\n",
    "\n",
    "netD_low  = CycleGAN_Discriminator(in_channels=1, out_channels=1, feature=64, norm='inorm')\n",
    "netD_high = CycleGAN_Discriminator(in_channels=1, out_channels=1, feature=64, norm='inorm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 이어서 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 불러오기\n",
    "checkpoint_dir = '/workspace/sunggu/4.Dose_img2img/model/Cycle_Gan_2D/epoch_215_model.pth'\n",
    "checkpoint = torch.load(checkpoint_dir)\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "netG_low_2_high.load_state_dict(checkpoint['netG_low_2_high_state_dict'])\n",
    "netG_high_2_low.load_state_dict(checkpoint['netG_high_2_low_state_dict'])\n",
    "\n",
    "netD_low.load_state_dict(checkpoint['netD_low_state_dict'])\n",
    "netD_high.load_state_dict(checkpoint['netD_high_state_dict'])\n",
    "\n",
    "# print(checkpoint['optimizer_G_state_dict'])\n",
    "# print(checkpoint['optimizer_D_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_low_2_high.to('cuda')\n",
    "netG_high_2_low.to('cuda')\n",
    "netD_low.to('cuda')\n",
    "netD_high.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 필요한 Weight만 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Before\n",
    "# model_dict = model.state_dict()\n",
    "# print(\"이전 weight = \", model_dict['encoder._conv_stem.weight'][0])\n",
    "\n",
    "# load_dir = '/workspace/sunggu/1.Hemorrhage/monai_experiment/model/Efficient3d_conv2d_Aux/'\n",
    "# pretrained_dict =  torch.load(os.path.join(load_dir, \"epoch_0_best_metric_model.pth\")) \n",
    "\n",
    "# # 1. filter out unnecessary keys\n",
    "# pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# # 2. overwrite entries in the existing state dict\n",
    "# model_dict.update(pretrained_dict) \n",
    "# # 3. load the new state dict\n",
    "# model.load_state_dict(model_dict)\n",
    "\n",
    "# # After\n",
    "# print(\"이후 weight = \", model_dict['encoder._conv_stem.weight'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그밖에 부수적인 functions 설정하기\n",
    "fn_tonumpy = lambda x: x.cpu().detach().numpy().transpose(0, 2, 3, 1)\n",
    "fn_denorm = lambda x: (x * STD) + MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_preprocessing(x):\n",
    "    x = (4096.0)*x - 1024.0\n",
    "    return x\n",
    "\n",
    "def return_preprocessing_for_dcm(x):\n",
    "    x = (4096.0)*x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "\n",
    "def save_dicom(original_dcm_path, np_img, save_path):\n",
    "    dcm = dcmread(original_dcm_path)\n",
    "#     dcm.is_little_endian = True\n",
    "#     dcm.is_implicit_VR = False\n",
    "#     dcm.PixelData = np_img.astype('uint16').squeeze().tostring()\n",
    "    dcm.PixelData = np_img.astype('int16').squeeze().tobytes()\n",
    "    \n",
    "    dcm.save_as(save_path)\n",
    "    print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch= 37\n",
    "test_low2high_save_folder = '/workspace/sunggu/4.Dose_img2img/Predictions/dcm/test_cyclegan_2d_epoch_'+str(epoch) + '/low2high/'\n",
    "test_high2low_save_folder = '/workspace/sunggu/4.Dose_img2img/Predictions/dcm/test_cyclegan_2d_epoch_'+str(epoch) + '/high2low/'\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Model 선언\n",
    "    netG_low_2_high.eval()\n",
    "    netG_high_2_low.eval()\n",
    "    netD_low.eval()\n",
    "    netD_high.eval()\n",
    "\n",
    "    test_iterator = tqdm(test_loader, desc='Test', file=sys.stdout)    \n",
    "    for batch_data in test_iterator:\n",
    "\n",
    "        os.makedirs(test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[7], mode=0o777, exist_ok=True)\n",
    "        os.makedirs(test_high2low_save_folder+batch_data['dcm_high'][0].split('/')[7], mode=0o777, exist_ok=True)\n",
    "        \n",
    "        # forward pass\n",
    "        input_low = batch_data['low'].to(device)\n",
    "        input_high = batch_data['high'].to(device)\n",
    "        \n",
    "        # Forward Generator\n",
    "        output_high = netG_low_2_high(input_low)\n",
    "        output_low = netG_high_2_low(input_high)\n",
    "\n",
    "        # 저장하기\n",
    "#         print(input_low.min(), input_low.max())\n",
    "        input_low = fn_tonumpy(return_preprocessing_for_dcm(input_low))\n",
    "        print(input_low.shape)\n",
    "        input_low[:, 128:128+256, 128:128+256, :] = 0\n",
    "        input_high = fn_tonumpy(return_preprocessing_for_dcm(input_high))\n",
    "        output_high = fn_tonumpy(return_preprocessing_for_dcm(output_high))\n",
    "        output_low = fn_tonumpy(return_preprocessing_for_dcm(output_low))\n",
    "        \n",
    "        save_dicom(batch_data['dcm_low'][0], input_low, test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[7]+'/gt_low_' +batch_data['dcm_low'][0].split('/')[-1])\n",
    "        save_dicom(batch_data['dcm_low'][0], output_high, test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[7]+'/pred_high_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "        save_dicom(batch_data['dcm_high'][0], input_high, test_high2low_save_folder+batch_data['dcm_high'][0].split('/')[7]+'/gt_high_' +batch_data['dcm_high'][0].split('/')[-1])\n",
    "        save_dicom(batch_data['dcm_high'][0], output_low, test_high2low_save_folder+batch_data['dcm_high'][0].split('/')[7]+'/pred_low_' +batch_data['dcm_high'][0].split('/')[-1])\n",
    "        \n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(output_low.squeeze())\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(output_high.squeeze())\n",
    "        plt.show()\n",
    "#         break\n",
    "#         # 0과 1로 안전빵\n",
    "#         input_low = np.clip(input_low, a_min=0, a_max=1)\n",
    "#         input_high = np.clip(input_high, a_min=0, a_max=1)\n",
    "        \n",
    "#         output_high = np.clip(output_high, a_min=0, a_max=1)        \n",
    "#         output_low = np.clip(output_low, a_min=0, a_max=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223.026px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
