{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CUDA 11.1\n",
    "# !pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE -> MAE Loss 꿀팁!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 10 09:07:45 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:18:00.0 Off |                  Off |\r\n",
      "| 45%   72C    P2   223W / 300W |  48324MiB / 48685MiB |     62%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:3B:00.0 Off |                  Off |\r\n",
      "| 54%   79C    P2   255W / 300W |  45254MiB / 48685MiB |     25%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000    Off  | 00000000:86:00.0 Off |                  Off |\r\n",
      "| 51%   76C    P2   273W / 300W |  48324MiB / 48685MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000    Off  | 00000000:AF:00.0 Off |                  Off |\r\n",
      "| 30%   29C    P8    19W / 300W |      1MiB / 48685MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/sunggu/4.Dose_img2img/scripts study\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/sunggu/4.Dose_img2img/scripts study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 갯수 =  64\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "***********************************************\n",
      "Dataset Name:  Sinogram_DCM\n",
      "---------- Model ----------\n",
      "Resume From:  \n",
      "Output To:  /workspace/sunggu/4.Dose_img2img/model/[Ours]MLPMixer_L1\n",
      "Save   To:  /workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/\n",
      "---------- Optimizer ----------\n",
      "Learning Rate:  0.0001\n",
      "Batchsize:  40\n",
      "Loading dataset ....\n",
      "Train [Total]  number =  6899\n",
      "Valid [Total]  number =  14\n",
      "Creating criterion: Change L2 L1 Loss\n",
      "Creating model: MLPMixer\n",
      "Load feature extractor...!\n",
      "Number of Learnable Params: 69703168\n",
      "MLPMixer(\n",
      "  (denoiser): Revised_UNet(\n",
      "    (enc1_1): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (enc1_2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (pool1): DownsampleBlock(\n",
      "      (downsample): Sequential(\n",
      "        (0): PixelUnshuffle(downscale_factor=2)\n",
      "        (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (enc2_1): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (enc2_2): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (pool2): DownsampleBlock(\n",
      "      (downsample): Sequential(\n",
      "        (0): PixelUnshuffle(downscale_factor=2)\n",
      "        (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (enc3_1): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (enc3_2): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (pool3): DownsampleBlock(\n",
      "      (downsample): Sequential(\n",
      "        (0): PixelUnshuffle(downscale_factor=2)\n",
      "        (1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (enc4_1): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (enc4_2): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (pool4): DownsampleBlock(\n",
      "      (downsample): Sequential(\n",
      "        (0): PixelUnshuffle(downscale_factor=2)\n",
      "        (1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (enc5_1): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (dec5_1): Sequential(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (unpool4): UpsampleBlock(\n",
      "      (upsample): Sequential(\n",
      "        (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): PixelShuffle(upscale_factor=2)\n",
      "        (2): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (dec4_2): Sequential(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (dec4_1): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (unpool3): UpsampleBlock(\n",
      "      (upsample): Sequential(\n",
      "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): PixelShuffle(upscale_factor=2)\n",
      "        (2): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (dec3_2): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (dec3_1): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (unpool2): UpsampleBlock(\n",
      "      (upsample): Sequential(\n",
      "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): PixelShuffle(upscale_factor=2)\n",
      "        (2): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (dec2_2): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (dec2_1): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (unpool1): UpsampleBlock(\n",
      "      (upsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): PixelShuffle(upscale_factor=2)\n",
      "        (2): PReLU(num_parameters=1)\n",
      "      )\n",
      "    )\n",
      "    (dec1_2): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (dec1_1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (fc): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (patch_embed): Sequential(\n",
      "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=16, p2=16)\n",
      "    (1): Linear(in_features=256, out_features=768, bias=True)\n",
      "  )\n",
      "  (mixer_blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (8): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (2): Rearrange('b (h w) (p1 p2 c) -> b c (h p1) (w p2)', h=32, p1=16, p2=16)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 1000 epochs\n",
      "Train: [epoch:0]  [  0/172]  eta: 0:07:53  lr: 0.000000  loss: 0.1923 (0.1923)  time: 2.7531  data: 1.4835  max mem: 39483\n",
      "Train: [epoch:0]  [ 10/172]  eta: 0:03:20  lr: 0.000000  loss: 0.1931 (0.1930)  time: 1.2387  data: 0.1350  max mem: 40324\n",
      "Train: [epoch:0]  [ 20/172]  eta: 0:02:56  lr: 0.000000  loss: 0.1925 (0.1926)  time: 1.0828  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [ 30/172]  eta: 0:02:41  lr: 0.000000  loss: 0.1920 (0.1923)  time: 1.0770  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [ 40/172]  eta: 0:02:28  lr: 0.000000  loss: 0.1910 (0.1919)  time: 1.0785  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [ 50/172]  eta: 0:02:15  lr: 0.000000  loss: 0.1907 (0.1917)  time: 1.0824  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [ 60/172]  eta: 0:02:04  lr: 0.000000  loss: 0.1904 (0.1914)  time: 1.0828  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [ 70/172]  eta: 0:01:52  lr: 0.000000  loss: 0.1901 (0.1912)  time: 1.0819  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [ 80/172]  eta: 0:01:41  lr: 0.000000  loss: 0.1894 (0.1909)  time: 1.0827  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [ 90/172]  eta: 0:01:30  lr: 0.000000  loss: 0.1886 (0.1907)  time: 1.0842  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [100/172]  eta: 0:01:19  lr: 0.000000  loss: 0.1886 (0.1904)  time: 1.0852  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [110/172]  eta: 0:01:08  lr: 0.000000  loss: 0.1880 (0.1902)  time: 1.0885  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [120/172]  eta: 0:00:57  lr: 0.000000  loss: 0.1875 (0.1899)  time: 1.0918  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [130/172]  eta: 0:00:46  lr: 0.000000  loss: 0.1874 (0.1897)  time: 1.0921  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [140/172]  eta: 0:00:35  lr: 0.000000  loss: 0.1870 (0.1895)  time: 1.0918  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [150/172]  eta: 0:00:24  lr: 0.000000  loss: 0.1863 (0.1893)  time: 1.0914  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [160/172]  eta: 0:00:13  lr: 0.000000  loss: 0.1858 (0.1891)  time: 1.0908  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [170/172]  eta: 0:00:02  lr: 0.000000  loss: 0.1854 (0.1888)  time: 1.0915  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0]  [171/172]  eta: 0:00:01  lr: 0.000000  loss: 0.1854 (0.1888)  time: 1.0919  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:0] Total time: 0:03:08 (1.0970 s / it)\n",
      "Averaged stats: lr: 0.000000  loss: 0.1854 (0.1888)\n",
      "Valid: [epoch:0]  [ 0/14]  eta: 0:00:07  loss: 0.1824 (0.1824)  time: 0.5138  data: 0.4866  max mem: 40324\n",
      "Valid: [epoch:0]  [13/14]  eta: 0:00:00  loss: 0.1839 (0.1847)  time: 0.0587  data: 0.0353  max mem: 40324\n",
      "Valid: [epoch:0] Total time: 0:00:00 (0.0689 s / it)\n",
      "Averaged stats: loss: 0.1839 (0.1847)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_0_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.185%\n",
      "Min loss: 0.185\n",
      "Best Epoch: 0.000\n",
      "/home/sunggu/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Train: [epoch:1]  [  0/172]  eta: 0:07:20  lr: 0.000000  loss: 0.1856 (0.1856)  time: 2.5610  data: 1.4427  max mem: 40324\n",
      "Train: [epoch:1]  [ 10/172]  eta: 0:03:16  lr: 0.000000  loss: 0.1846 (0.1847)  time: 1.2138  data: 0.1313  max mem: 40324\n",
      "Train: [epoch:1]  [ 20/172]  eta: 0:02:54  lr: 0.000000  loss: 0.1841 (0.1843)  time: 1.0796  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [ 30/172]  eta: 0:02:40  lr: 0.000000  loss: 0.1838 (0.1840)  time: 1.0831  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [ 40/172]  eta: 0:02:27  lr: 0.000000  loss: 0.1830 (0.1837)  time: 1.0875  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [ 50/172]  eta: 0:02:15  lr: 0.000000  loss: 0.1830 (0.1836)  time: 1.0902  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [ 60/172]  eta: 0:02:04  lr: 0.000000  loss: 0.1828 (0.1834)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [ 70/172]  eta: 0:01:52  lr: 0.000000  loss: 0.1821 (0.1832)  time: 1.0912  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [ 80/172]  eta: 0:01:41  lr: 0.000000  loss: 0.1814 (0.1829)  time: 1.0881  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [ 90/172]  eta: 0:01:30  lr: 0.000000  loss: 0.1805 (0.1827)  time: 1.0884  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [100/172]  eta: 0:01:19  lr: 0.000000  loss: 0.1804 (0.1824)  time: 1.0902  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [110/172]  eta: 0:01:08  lr: 0.000000  loss: 0.1801 (0.1822)  time: 1.0918  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [120/172]  eta: 0:00:57  lr: 0.000000  loss: 0.1799 (0.1820)  time: 1.0935  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [130/172]  eta: 0:00:46  lr: 0.000000  loss: 0.1795 (0.1818)  time: 1.0942  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [140/172]  eta: 0:00:35  lr: 0.000000  loss: 0.1786 (0.1815)  time: 1.0942  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [150/172]  eta: 0:00:24  lr: 0.000000  loss: 0.1785 (0.1813)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [160/172]  eta: 0:00:13  lr: 0.000000  loss: 0.1782 (0.1811)  time: 1.0913  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [170/172]  eta: 0:00:02  lr: 0.000000  loss: 0.1777 (0.1809)  time: 1.0925  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1]  [171/172]  eta: 0:00:01  lr: 0.000000  loss: 0.1773 (0.1809)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:1] Total time: 0:03:09 (1.0994 s / it)\n",
      "Averaged stats: lr: 0.000000  loss: 0.1773 (0.1809)\n",
      "Valid: [epoch:1]  [ 0/14]  eta: 0:00:06  loss: 0.1758 (0.1758)  time: 0.4622  data: 0.4359  max mem: 40324\n",
      "Valid: [epoch:1]  [13/14]  eta: 0:00:00  loss: 0.1761 (0.1770)  time: 0.0551  data: 0.0317  max mem: 40324\n",
      "Valid: [epoch:1] Total time: 0:00:00 (0.0661 s / it)\n",
      "Averaged stats: loss: 0.1761 (0.1770)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_1_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.177%\n",
      "Min loss: 0.177\n",
      "Best Epoch: 1.000\n",
      "Train: [epoch:2]  [  0/172]  eta: 0:07:00  lr: 0.000010  loss: 0.1779 (0.1779)  time: 2.4450  data: 1.3521  max mem: 40324\n",
      "Train: [epoch:2]  [ 10/172]  eta: 0:03:16  lr: 0.000010  loss: 0.0585 (0.0770)  time: 1.2147  data: 0.1230  max mem: 40324\n",
      "Train: [epoch:2]  [ 20/172]  eta: 0:02:55  lr: 0.000010  loss: 0.0324 (0.0539)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [ 30/172]  eta: 0:02:41  lr: 0.000010  loss: 0.0263 (0.0440)  time: 1.0935  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [ 40/172]  eta: 0:02:28  lr: 0.000010  loss: 0.0193 (0.0375)  time: 1.0956  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [ 50/172]  eta: 0:02:16  lr: 0.000010  loss: 0.0155 (0.0329)  time: 1.0963  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [ 60/172]  eta: 0:02:05  lr: 0.000010  loss: 0.0122 (0.0292)  time: 1.0949  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [ 70/172]  eta: 0:01:53  lr: 0.000010  loss: 0.0095 (0.0264)  time: 1.0930  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [ 80/172]  eta: 0:01:42  lr: 0.000010  loss: 0.0078 (0.0239)  time: 1.0902  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [ 90/172]  eta: 0:01:30  lr: 0.000010  loss: 0.0065 (0.0220)  time: 1.0901  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [100/172]  eta: 0:01:19  lr: 0.000010  loss: 0.0057 (0.0203)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [110/172]  eta: 0:01:08  lr: 0.000010  loss: 0.0047 (0.0189)  time: 1.0943  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [120/172]  eta: 0:00:57  lr: 0.000010  loss: 0.0044 (0.0177)  time: 1.0955  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [130/172]  eta: 0:00:46  lr: 0.000010  loss: 0.0040 (0.0167)  time: 1.0962  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [140/172]  eta: 0:00:35  lr: 0.000010  loss: 0.0037 (0.0157)  time: 1.0953  data: 0.0001  max mem: 40324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [150/172]  eta: 0:00:24  lr: 0.000010  loss: 0.0033 (0.0149)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [160/172]  eta: 0:00:13  lr: 0.000010  loss: 0.0031 (0.0141)  time: 1.0923  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [170/172]  eta: 0:00:02  lr: 0.000010  loss: 0.0027 (0.0135)  time: 1.0932  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.0026 (0.0134)  time: 1.0935  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:2] Total time: 0:03:09 (1.1027 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.0026 (0.0134)\n",
      "Valid: [epoch:2]  [ 0/14]  eta: 0:00:06  loss: 0.0027 (0.0027)  time: 0.4736  data: 0.4472  max mem: 40324\n",
      "Valid: [epoch:2]  [13/14]  eta: 0:00:00  loss: 0.0021 (0.0023)  time: 0.0563  data: 0.0328  max mem: 40324\n",
      "Valid: [epoch:2] Total time: 0:00:00 (0.0678 s / it)\n",
      "Averaged stats: loss: 0.0021 (0.0023)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_2_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 2.000\n",
      "Train: [epoch:3]  [  0/172]  eta: 0:07:26  lr: 0.000020  loss: 0.0026 (0.0026)  time: 2.5967  data: 1.4909  max mem: 40324\n",
      "Train: [epoch:3]  [ 10/172]  eta: 0:03:17  lr: 0.000020  loss: 0.0025 (0.0025)  time: 1.2169  data: 0.1357  max mem: 40324\n",
      "Train: [epoch:3]  [ 20/172]  eta: 0:02:55  lr: 0.000020  loss: 0.0023 (0.0023)  time: 1.0802  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [ 30/172]  eta: 0:02:40  lr: 0.000020  loss: 0.0020 (0.0021)  time: 1.0850  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [ 40/172]  eta: 0:02:27  lr: 0.000020  loss: 0.0015 (0.0020)  time: 1.0881  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [ 50/172]  eta: 0:02:16  lr: 0.000020  loss: 0.0013 (0.0018)  time: 1.0884  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [ 60/172]  eta: 0:02:04  lr: 0.000020  loss: 0.0012 (0.0017)  time: 1.0900  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [ 70/172]  eta: 0:01:53  lr: 0.000020  loss: 0.0010 (0.0016)  time: 1.0904  data: 0.0002  max mem: 40324\n",
      "Train: [epoch:3]  [ 80/172]  eta: 0:01:41  lr: 0.000020  loss: 0.0009 (0.0015)  time: 1.0892  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [ 90/172]  eta: 0:01:30  lr: 0.000020  loss: 0.0008 (0.0014)  time: 1.0890  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [100/172]  eta: 0:01:19  lr: 0.000020  loss: 0.0008 (0.0014)  time: 1.0909  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [110/172]  eta: 0:01:08  lr: 0.000020  loss: 0.0008 (0.0013)  time: 1.0926  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [120/172]  eta: 0:00:57  lr: 0.000020  loss: 0.0008 (0.0013)  time: 1.0930  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [130/172]  eta: 0:00:46  lr: 0.000020  loss: 0.0007 (0.0012)  time: 1.0933  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [140/172]  eta: 0:00:35  lr: 0.000020  loss: 0.0007 (0.0012)  time: 1.0934  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [150/172]  eta: 0:00:24  lr: 0.000020  loss: 0.0007 (0.0012)  time: 1.0925  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [160/172]  eta: 0:00:13  lr: 0.000020  loss: 0.0007 (0.0011)  time: 1.0906  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [170/172]  eta: 0:00:02  lr: 0.000020  loss: 0.0006 (0.0011)  time: 1.0912  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.0006 (0.0011)  time: 1.0915  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:3] Total time: 0:03:09 (1.0992 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.0006 (0.0011)\n",
      "Valid: [epoch:3]  [ 0/14]  eta: 0:00:05  loss: 0.0005 (0.0005)  time: 0.4180  data: 0.3885  max mem: 40324\n",
      "Valid: [epoch:3]  [13/14]  eta: 0:00:00  loss: 0.0006 (0.0006)  time: 0.0560  data: 0.0322  max mem: 40324\n",
      "Valid: [epoch:3] Total time: 0:00:00 (0.0661 s / it)\n",
      "Averaged stats: loss: 0.0006 (0.0006)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_3_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.001%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 3.000\n",
      "Train: [epoch:4]  [  0/172]  eta: 0:07:16  lr: 0.000030  loss: 0.0007 (0.0007)  time: 2.5400  data: 1.4519  max mem: 40324\n",
      "Train: [epoch:4]  [ 10/172]  eta: 0:03:17  lr: 0.000030  loss: 0.0007 (0.0006)  time: 1.2219  data: 0.1321  max mem: 40324\n",
      "Train: [epoch:4]  [ 20/172]  eta: 0:02:56  lr: 0.000030  loss: 0.0006 (0.0006)  time: 1.0897  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [ 30/172]  eta: 0:02:41  lr: 0.000030  loss: 0.0006 (0.0006)  time: 1.0917  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [ 40/172]  eta: 0:02:28  lr: 0.000030  loss: 0.0005 (0.0006)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [ 50/172]  eta: 0:02:16  lr: 0.000030  loss: 0.0005 (0.0006)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [ 60/172]  eta: 0:02:05  lr: 0.000030  loss: 0.0005 (0.0006)  time: 1.0944  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [ 70/172]  eta: 0:01:53  lr: 0.000030  loss: 0.0005 (0.0005)  time: 1.0926  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [ 80/172]  eta: 0:01:42  lr: 0.000030  loss: 0.0005 (0.0005)  time: 1.0900  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [ 90/172]  eta: 0:01:30  lr: 0.000030  loss: 0.0005 (0.0005)  time: 1.0898  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [100/172]  eta: 0:01:19  lr: 0.000030  loss: 0.0004 (0.0005)  time: 1.0913  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [110/172]  eta: 0:01:08  lr: 0.000030  loss: 0.0004 (0.0005)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [120/172]  eta: 0:00:57  lr: 0.000030  loss: 0.0003 (0.0005)  time: 1.0940  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [130/172]  eta: 0:00:46  lr: 0.000030  loss: 0.0003 (0.0005)  time: 1.0950  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [140/172]  eta: 0:00:35  lr: 0.000030  loss: 0.0003 (0.0005)  time: 1.0954  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [150/172]  eta: 0:00:24  lr: 0.000030  loss: 0.0003 (0.0005)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [160/172]  eta: 0:00:13  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.0912  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [170/172]  eta: 0:00:02  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.0926  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:4] Total time: 0:03:09 (1.1018 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.0003 (0.0004)\n",
      "Valid: [epoch:4]  [ 0/14]  eta: 0:00:05  loss: 0.0003 (0.0003)  time: 0.4029  data: 0.3728  max mem: 40324\n",
      "Valid: [epoch:4]  [13/14]  eta: 0:00:00  loss: 0.0002 (0.0003)  time: 0.0507  data: 0.0271  max mem: 40324\n",
      "Valid: [epoch:4] Total time: 0:00:00 (0.0594 s / it)\n",
      "Averaged stats: loss: 0.0002 (0.0003)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_4_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 4.000\n",
      "Train: [epoch:5]  [  0/172]  eta: 0:07:19  lr: 0.000040  loss: 0.0002 (0.0002)  time: 2.5545  data: 1.4407  max mem: 40324\n",
      "Train: [epoch:5]  [ 10/172]  eta: 0:03:16  lr: 0.000040  loss: 0.0003 (0.0003)  time: 1.2128  data: 0.1311  max mem: 40324\n",
      "Train: [epoch:5]  [ 20/172]  eta: 0:02:54  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0796  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [ 30/172]  eta: 0:02:40  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0867  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [ 40/172]  eta: 0:02:27  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0899  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [ 50/172]  eta: 0:02:15  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0876  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [ 60/172]  eta: 0:02:04  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0904  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [ 70/172]  eta: 0:01:52  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0911  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [ 80/172]  eta: 0:01:41  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0885  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [ 90/172]  eta: 0:01:30  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0885  data: 0.0001  max mem: 40324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [100/172]  eta: 0:01:19  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0896  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [110/172]  eta: 0:01:08  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0918  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [120/172]  eta: 0:00:57  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [130/172]  eta: 0:00:46  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [140/172]  eta: 0:00:35  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0943  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [150/172]  eta: 0:00:24  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0945  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [160/172]  eta: 0:00:13  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0919  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [170/172]  eta: 0:00:02  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0915  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.0920  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:5] Total time: 0:03:09 (1.0994 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.0002 (0.0002)\n",
      "Valid: [epoch:5]  [ 0/14]  eta: 0:00:06  loss: 0.0002 (0.0002)  time: 0.4639  data: 0.4295  max mem: 40324\n",
      "Valid: [epoch:5]  [13/14]  eta: 0:00:00  loss: 0.0002 (0.0002)  time: 0.0555  data: 0.0315  max mem: 40324\n",
      "Valid: [epoch:5] Total time: 0:00:00 (0.0666 s / it)\n",
      "Averaged stats: loss: 0.0002 (0.0002)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_5_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 5.000\n",
      "Train: [epoch:6]  [  0/172]  eta: 0:06:45  lr: 0.000050  loss: 0.0002 (0.0002)  time: 2.3582  data: 1.2695  max mem: 40324\n",
      "Train: [epoch:6]  [ 10/172]  eta: 0:03:15  lr: 0.000050  loss: 0.0002 (0.0002)  time: 1.2055  data: 0.1155  max mem: 40324\n",
      "Train: [epoch:6]  [ 20/172]  eta: 0:02:54  lr: 0.000050  loss: 0.0002 (0.0002)  time: 1.0900  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [ 30/172]  eta: 0:02:40  lr: 0.000050  loss: 0.0002 (0.0002)  time: 1.0923  data: 0.0002  max mem: 40324\n",
      "Train: [epoch:6]  [ 40/172]  eta: 0:02:28  lr: 0.000050  loss: 0.0001 (0.0002)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [ 50/172]  eta: 0:02:16  lr: 0.000050  loss: 0.0001 (0.0002)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [ 60/172]  eta: 0:02:04  lr: 0.000050  loss: 0.0001 (0.0002)  time: 1.0947  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [ 70/172]  eta: 0:01:53  lr: 0.000050  loss: 0.0001 (0.0002)  time: 1.0933  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [ 80/172]  eta: 0:01:41  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0895  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [ 90/172]  eta: 0:01:30  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0902  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [100/172]  eta: 0:01:19  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0917  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [110/172]  eta: 0:01:08  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0929  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [120/172]  eta: 0:00:57  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0947  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [130/172]  eta: 0:00:46  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0945  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [140/172]  eta: 0:00:35  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0943  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [150/172]  eta: 0:00:24  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [160/172]  eta: 0:00:13  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0913  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [170/172]  eta: 0:00:02  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0923  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.0926  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:6] Total time: 0:03:09 (1.1010 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.0001 (0.0001)\n",
      "Valid: [epoch:6]  [ 0/14]  eta: 0:00:06  loss: 0.0001 (0.0001)  time: 0.4813  data: 0.4515  max mem: 40324\n",
      "Valid: [epoch:6]  [13/14]  eta: 0:00:00  loss: 0.0001 (0.0001)  time: 0.0560  data: 0.0323  max mem: 40324\n",
      "Valid: [epoch:6] Total time: 0:00:00 (0.0676 s / it)\n",
      "Averaged stats: loss: 0.0001 (0.0001)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_6_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 6.000\n",
      "Train: [epoch:7]  [  0/172]  eta: 0:07:21  lr: 0.000060  loss: 0.0001 (0.0001)  time: 2.5690  data: 1.4777  max mem: 40324\n",
      "Train: [epoch:7]  [ 10/172]  eta: 0:03:16  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.2139  data: 0.1344  max mem: 40324\n",
      "Train: [epoch:7]  [ 20/172]  eta: 0:02:54  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0802  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [ 30/172]  eta: 0:02:40  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0842  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [ 40/172]  eta: 0:02:27  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0870  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [ 50/172]  eta: 0:02:15  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0890  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [ 60/172]  eta: 0:02:04  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0909  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [ 70/172]  eta: 0:01:52  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0897  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [ 80/172]  eta: 0:01:41  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0891  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [ 90/172]  eta: 0:01:30  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0910  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [100/172]  eta: 0:01:19  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0912  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [110/172]  eta: 0:01:08  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0932  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [120/172]  eta: 0:00:57  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0940  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [130/172]  eta: 0:00:46  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0926  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [140/172]  eta: 0:00:35  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [150/172]  eta: 0:00:24  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [160/172]  eta: 0:00:13  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0931  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [170/172]  eta: 0:00:02  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0930  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.0933  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:7] Total time: 0:03:09 (1.0998 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.0001 (0.0001)\n",
      "Valid: [epoch:7]  [ 0/14]  eta: 0:00:07  loss: 0.0001 (0.0001)  time: 0.5063  data: 0.4766  max mem: 40324\n",
      "Valid: [epoch:7]  [13/14]  eta: 0:00:00  loss: 0.0001 (0.0001)  time: 0.0578  data: 0.0341  max mem: 40324\n",
      "Valid: [epoch:7] Total time: 0:00:00 (0.0674 s / it)\n",
      "Averaged stats: loss: 0.0001 (0.0001)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_7_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 7.000\n",
      "Train: [epoch:8]  [  0/172]  eta: 0:06:58  lr: 0.000070  loss: 0.0001 (0.0001)  time: 2.4346  data: 1.3479  max mem: 40324\n",
      "Train: [epoch:8]  [ 10/172]  eta: 0:03:16  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.2123  data: 0.1226  max mem: 40324\n",
      "Train: [epoch:8]  [ 20/172]  eta: 0:02:55  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0904  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [ 30/172]  eta: 0:02:41  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0917  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [ 40/172]  eta: 0:02:28  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0928  data: 0.0001  max mem: 40324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [ 50/172]  eta: 0:02:16  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0929  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [ 60/172]  eta: 0:02:04  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [ 70/172]  eta: 0:01:53  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [ 80/172]  eta: 0:01:41  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0892  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [ 90/172]  eta: 0:01:30  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0890  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [100/172]  eta: 0:01:19  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0904  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [110/172]  eta: 0:01:08  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0934  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [120/172]  eta: 0:00:57  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0971  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [130/172]  eta: 0:00:46  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0957  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [140/172]  eta: 0:00:35  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0953  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [150/172]  eta: 0:00:24  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0957  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [160/172]  eta: 0:00:13  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [170/172]  eta: 0:00:02  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0918  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.0921  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:8] Total time: 0:03:09 (1.1015 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.0001 (0.0001)\n",
      "Valid: [epoch:8]  [ 0/14]  eta: 0:00:06  loss: 0.0001 (0.0001)  time: 0.4901  data: 0.4636  max mem: 40324\n",
      "Valid: [epoch:8]  [13/14]  eta: 0:00:00  loss: 0.0001 (0.0001)  time: 0.0571  data: 0.0338  max mem: 40324\n",
      "Valid: [epoch:8] Total time: 0:00:00 (0.0672 s / it)\n",
      "Averaged stats: loss: 0.0001 (0.0001)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_8_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:9]  [  0/172]  eta: 0:07:04  lr: 0.000080  loss: 0.0001 (0.0001)  time: 2.4671  data: 1.3715  max mem: 40324\n",
      "Train: [epoch:9]  [ 10/172]  eta: 0:03:15  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.2068  data: 0.1248  max mem: 40324\n",
      "Train: [epoch:9]  [ 20/172]  eta: 0:02:54  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0823  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [ 30/172]  eta: 0:02:40  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0855  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [ 40/172]  eta: 0:02:27  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0882  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [ 50/172]  eta: 0:02:15  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0899  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [ 60/172]  eta: 0:02:04  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0910  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [ 70/172]  eta: 0:01:52  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0905  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [ 80/172]  eta: 0:01:41  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0887  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [ 90/172]  eta: 0:01:30  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0888  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [100/172]  eta: 0:01:19  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0897  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [110/172]  eta: 0:01:08  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0925  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [120/172]  eta: 0:00:57  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0946  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [130/172]  eta: 0:00:46  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [140/172]  eta: 0:00:35  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [150/172]  eta: 0:00:24  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0931  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [160/172]  eta: 0:00:13  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.0919  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [170/172]  eta: 0:00:02  lr: 0.000080  loss: 0.0000 (0.0001)  time: 1.0927  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.0000 (0.0001)  time: 1.0931  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:9] Total time: 0:03:09 (1.0994 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.0000 (0.0001)\n",
      "Valid: [epoch:9]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4905  data: 0.4586  max mem: 40324\n",
      "Valid: [epoch:9]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0569  data: 0.0328  max mem: 40324\n",
      "Valid: [epoch:9] Total time: 0:00:00 (0.0681 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_9_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 9.000\n",
      "Train: [epoch:10]  [  0/172]  eta: 0:06:44  lr: 0.000090  loss: 0.0001 (0.0001)  time: 2.3511  data: 1.2627  max mem: 40324\n",
      "Train: [epoch:10]  [ 10/172]  eta: 0:03:15  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.2054  data: 0.1149  max mem: 40324\n",
      "Train: [epoch:10]  [ 20/172]  eta: 0:02:54  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0904  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [ 30/172]  eta: 0:02:40  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0923  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [ 40/172]  eta: 0:02:28  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0948  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [ 50/172]  eta: 0:02:16  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0943  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [ 60/172]  eta: 0:02:04  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [ 70/172]  eta: 0:01:53  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0927  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [ 80/172]  eta: 0:01:41  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0914  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [ 90/172]  eta: 0:01:30  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0915  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [100/172]  eta: 0:01:19  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0923  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [110/172]  eta: 0:01:08  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [120/172]  eta: 0:00:57  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0947  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [130/172]  eta: 0:00:46  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0947  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [140/172]  eta: 0:00:35  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0945  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [150/172]  eta: 0:00:24  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [160/172]  eta: 0:00:13  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [170/172]  eta: 0:00:02  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0923  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.0927  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:10] Total time: 0:03:09 (1.1015 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:10]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4784  data: 0.4509  max mem: 40324\n",
      "Valid: [epoch:10]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0560  data: 0.0323  max mem: 40324\n",
      "Valid: [epoch:10] Total time: 0:00:00 (0.0666 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_10_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [  0/172]  eta: 0:07:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.6474  data: 1.5371  max mem: 40324\n",
      "Train: [epoch:11]  [ 10/172]  eta: 0:03:17  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2221  data: 0.1398  max mem: 40324\n",
      "Train: [epoch:11]  [ 20/172]  eta: 0:02:55  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0799  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [ 30/172]  eta: 0:02:40  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0832  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0869  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0893  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [ 60/172]  eta: 0:02:04  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0910  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0897  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [ 80/172]  eta: 0:01:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0873  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0879  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0897  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0913  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0930  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0931  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0944  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0914  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0926  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0929  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:11] Total time: 0:03:09 (1.0997 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:11]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4545  data: 0.4225  max mem: 40324\n",
      "Valid: [epoch:11]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0547  data: 0.0308  max mem: 40324\n",
      "Valid: [epoch:11] Total time: 0:00:00 (0.0659 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_11_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 11.000\n",
      "Train: [epoch:12]  [  0/172]  eta: 0:07:23  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.5758  data: 1.4880  max mem: 40324\n",
      "Train: [epoch:12]  [ 10/172]  eta: 0:03:18  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2256  data: 0.1354  max mem: 40324\n",
      "Train: [epoch:12]  [ 20/172]  eta: 0:02:56  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0901  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [ 30/172]  eta: 0:02:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0930  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0950  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [ 60/172]  eta: 0:02:05  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [ 80/172]  eta: 0:01:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0895  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0896  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0946  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0959  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0955  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0948  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0939  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0910  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0925  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:12] Total time: 0:03:09 (1.1026 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:12]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4524  data: 0.4246  max mem: 40324\n",
      "Valid: [epoch:12]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0559  data: 0.0324  max mem: 40324\n",
      "Valid: [epoch:12] Total time: 0:00:00 (0.0668 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_12_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 12.000\n",
      "Train: [epoch:13]  [  0/172]  eta: 0:07:33  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.6367  data: 1.5425  max mem: 40324\n",
      "Train: [epoch:13]  [ 10/172]  eta: 0:03:17  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2209  data: 0.1403  max mem: 40324\n",
      "Train: [epoch:13]  [ 20/172]  eta: 0:02:55  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0810  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [ 30/172]  eta: 0:02:40  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0848  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0890  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0920  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [ 60/172]  eta: 0:02:04  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0920  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0903  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [ 80/172]  eta: 0:01:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0881  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0885  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0903  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0942  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0934  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0939  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0929  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:13]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0940  data: 0.0001  max mem: 40324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13] Total time: 0:03:09 (1.1004 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:13]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4800  data: 0.4559  max mem: 40324\n",
      "Valid: [epoch:13]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0580  data: 0.0348  max mem: 40324\n",
      "Valid: [epoch:13] Total time: 0:00:00 (0.0695 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_13_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 13.000\n",
      "Train: [epoch:14]  [  0/172]  eta: 0:07:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.6216  data: 1.5121  max mem: 40324\n",
      "Train: [epoch:14]  [ 10/172]  eta: 0:03:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2312  data: 0.1376  max mem: 40324\n",
      "Train: [epoch:14]  [ 20/172]  eta: 0:02:56  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0910  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [ 30/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0920  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [ 40/172]  eta: 0:02:29  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0947  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [ 50/172]  eta: 0:02:17  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0950  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [ 60/172]  eta: 0:02:05  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [ 80/172]  eta: 0:01:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0914  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0906  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0924  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0943  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0953  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0940  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0943  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0926  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0932  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0935  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:14] Total time: 0:03:09 (1.1034 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:14]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4791  data: 0.4470  max mem: 40324\n",
      "Valid: [epoch:14]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0605  data: 0.0364  max mem: 40324\n",
      "Valid: [epoch:14] Total time: 0:00:01 (0.0718 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_14_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 14.000\n",
      "Train: [epoch:15]  [  0/172]  eta: 0:07:39  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.6733  data: 1.5774  max mem: 40324\n",
      "Train: [epoch:15]  [ 10/172]  eta: 0:03:18  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2240  data: 0.1435  max mem: 40324\n",
      "Train: [epoch:15]  [ 20/172]  eta: 0:02:55  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0807  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [ 30/172]  eta: 0:02:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0846  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0878  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0903  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [ 60/172]  eta: 0:02:04  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0912  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0898  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [ 80/172]  eta: 0:01:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0882  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0884  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0897  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0921  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0934  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0930  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0920  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0905  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0917  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0921  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:15] Total time: 0:03:09 (1.1001 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:15]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4612  data: 0.4254  max mem: 40324\n",
      "Valid: [epoch:15]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0547  data: 0.0305  max mem: 40324\n",
      "Valid: [epoch:15] Total time: 0:00:00 (0.0649 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_15_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 15.000\n",
      "Train: [epoch:16]  [  0/172]  eta: 0:07:20  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.5624  data: 1.4733  max mem: 40324\n",
      "Train: [epoch:16]  [ 10/172]  eta: 0:03:18  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2258  data: 0.1340  max mem: 40324\n",
      "Train: [epoch:16]  [ 20/172]  eta: 0:02:56  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0908  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [ 30/172]  eta: 0:02:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0924  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [ 60/172]  eta: 0:02:05  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0943  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [ 80/172]  eta: 0:01:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0896  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0903  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0951  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0964  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0954  data: 0.0001  max mem: 40324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0956  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0935  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0915  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0925  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:16] Total time: 0:03:09 (1.1027 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:16]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4831  data: 0.4574  max mem: 40324\n",
      "Valid: [epoch:16]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0569  data: 0.0336  max mem: 40324\n",
      "Valid: [epoch:16] Total time: 0:00:00 (0.0686 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_16_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:17]  [  0/172]  eta: 0:07:56  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.7721  data: 1.6804  max mem: 40324\n",
      "Train: [epoch:17]  [ 10/172]  eta: 0:03:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2329  data: 0.1529  max mem: 40324\n",
      "Train: [epoch:17]  [ 20/172]  eta: 0:02:56  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0799  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [ 30/172]  eta: 0:02:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0840  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0881  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0893  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [ 60/172]  eta: 0:02:04  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0903  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0898  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [ 80/172]  eta: 0:01:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0879  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0884  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0899  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0915  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0929  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0931  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0923  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0924  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0924  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:17] Total time: 0:03:09 (1.1005 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:17]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4887  data: 0.4555  max mem: 40324\n",
      "Valid: [epoch:17]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0568  data: 0.0329  max mem: 40324\n",
      "Valid: [epoch:17] Total time: 0:00:00 (0.0678 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_17_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:18]  [  0/172]  eta: 0:07:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.6896  data: 1.6044  max mem: 40324\n",
      "Train: [epoch:18]  [ 10/172]  eta: 0:03:20  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2355  data: 0.1460  max mem: 40324\n",
      "Train: [epoch:18]  [ 20/172]  eta: 0:02:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0897  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [ 30/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0915  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [ 40/172]  eta: 0:02:29  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [ 50/172]  eta: 0:02:17  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0944  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [ 60/172]  eta: 0:02:05  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0944  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0924  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [ 80/172]  eta: 0:01:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0904  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0901  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0905  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0932  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0959  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0949  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0948  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0947  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0916  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0929  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0932  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:18] Total time: 0:03:09 (1.1030 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:18]  [ 0/14]  eta: 0:00:05  loss: 0.0000 (0.0000)  time: 0.4059  data: 0.3782  max mem: 40324\n",
      "Valid: [epoch:18]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0508  data: 0.0274  max mem: 40324\n",
      "Valid: [epoch:18] Total time: 0:00:00 (0.0599 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_18_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:19]  [  0/172]  eta: 0:06:50  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.3895  data: 1.2764  max mem: 40324\n",
      "Train: [epoch:19]  [ 10/172]  eta: 0:03:14  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.1996  data: 0.1161  max mem: 40324\n",
      "Train: [epoch:19]  [ 20/172]  eta: 0:02:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0814  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [ 30/172]  eta: 0:02:39  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0845  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [ 40/172]  eta: 0:02:27  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0889  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [ 50/172]  eta: 0:02:15  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0903  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [ 60/172]  eta: 0:02:04  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0902  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [ 70/172]  eta: 0:01:52  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0895  data: 0.0002  max mem: 40324\n",
      "Train: [epoch:19]  [ 80/172]  eta: 0:01:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0876  data: 0.0001  max mem: 40324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:19]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0878  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0889  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0908  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0940  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0908  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0919  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:19] Total time: 0:03:08 (1.0982 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:19]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4801  data: 0.4478  max mem: 40324\n",
      "Valid: [epoch:19]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0558  data: 0.0321  max mem: 40324\n",
      "Valid: [epoch:19] Total time: 0:00:00 (0.0675 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_19_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:20]  [  0/172]  eta: 0:07:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.5531  data: 1.4540  max mem: 40324\n",
      "Train: [epoch:20]  [ 10/172]  eta: 0:03:18  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2226  data: 0.1323  max mem: 40324\n",
      "Train: [epoch:20]  [ 20/172]  eta: 0:02:56  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0906  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [ 30/172]  eta: 0:02:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0919  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [ 60/172]  eta: 0:02:05  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0927  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0912  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [ 80/172]  eta: 0:01:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0886  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0888  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0911  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0932  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0939  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0934  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0940  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0919  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0930  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0934  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:20] Total time: 0:03:09 (1.1019 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:20]  [ 0/14]  eta: 0:00:07  loss: 0.0000 (0.0000)  time: 0.5056  data: 0.4779  max mem: 40324\n",
      "Valid: [epoch:20]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0602  data: 0.0364  max mem: 40324\n",
      "Valid: [epoch:20] Total time: 0:00:00 (0.0701 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_20_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:21]  [  0/172]  eta: 0:07:37  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.6608  data: 1.5466  max mem: 40324\n",
      "Train: [epoch:21]  [ 10/172]  eta: 0:03:18  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2239  data: 0.1407  max mem: 40324\n",
      "Train: [epoch:21]  [ 20/172]  eta: 0:02:55  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0807  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [ 30/172]  eta: 0:02:40  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0837  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0888  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0905  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [ 60/172]  eta: 0:02:04  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0900  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0894  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [ 80/172]  eta: 0:01:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0872  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0874  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0911  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0948  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0944  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0949  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0958  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0916  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0912  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0915  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:21] Total time: 0:03:09 (1.1005 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:21]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4738  data: 0.4394  max mem: 40324\n",
      "Valid: [epoch:21]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0563  data: 0.0322  max mem: 40324\n",
      "Valid: [epoch:21] Total time: 0:00:00 (0.0679 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_21_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:22]  [  0/172]  eta: 0:07:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.5391  data: 1.4529  max mem: 40324\n",
      "Train: [epoch:22]  [ 10/172]  eta: 0:03:17  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2218  data: 0.1322  max mem: 40324\n",
      "Train: [epoch:22]  [ 20/172]  eta: 0:02:56  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0901  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [ 30/172]  eta: 0:02:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0923  data: 0.0001  max mem: 40324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:22]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0935  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [ 60/172]  eta: 0:02:05  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0934  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0914  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [ 80/172]  eta: 0:01:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0890  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0890  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0919  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0940  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0957  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0953  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0922  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0933  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:22] Total time: 0:03:09 (1.1023 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:22]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4623  data: 0.4372  max mem: 40324\n",
      "Valid: [epoch:22]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0552  data: 0.0320  max mem: 40324\n",
      "Valid: [epoch:22] Total time: 0:00:00 (0.0651 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_22_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:23]  [  0/172]  eta: 0:07:37  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.6618  data: 1.5646  max mem: 40324\n",
      "Train: [epoch:23]  [ 10/172]  eta: 0:03:18  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2245  data: 0.1424  max mem: 40324\n",
      "Train: [epoch:23]  [ 20/172]  eta: 0:02:55  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0804  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [ 30/172]  eta: 0:02:40  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0828  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0868  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0888  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [ 60/172]  eta: 0:02:04  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0898  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0892  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [ 80/172]  eta: 0:01:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0872  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0875  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0891  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0920  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0937  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0943  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0933  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0923  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0934  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:23] Total time: 0:03:09 (1.0999 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:23]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4744  data: 0.4470  max mem: 40324\n",
      "Valid: [epoch:23]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0582  data: 0.0347  max mem: 40324\n",
      "Valid: [epoch:23] Total time: 0:00:00 (0.0699 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_23_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:24]  [  0/172]  eta: 0:08:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.8406  data: 1.7554  max mem: 40324\n",
      "Train: [epoch:24]  [ 10/172]  eta: 0:03:22  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2488  data: 0.1597  max mem: 40324\n",
      "Train: [epoch:24]  [ 20/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0891  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [ 30/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0911  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [ 40/172]  eta: 0:02:29  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0942  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [ 50/172]  eta: 0:02:17  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0946  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [ 60/172]  eta: 0:02:05  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0944  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0929  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [ 80/172]  eta: 0:01:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0897  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [ 90/172]  eta: 0:01:31  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0898  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0924  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0948  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0951  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0945  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0945  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0932  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0917  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0931  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:24] Total time: 0:03:09 (1.1038 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:24]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4793  data: 0.4460  max mem: 40324\n",
      "Valid: [epoch:24]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0578  data: 0.0332  max mem: 40324\n",
      "Valid: [epoch:24] Total time: 0:00:01 (0.0734 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_24_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:25]  [  0/172]  eta: 0:07:37  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.6578  data: 1.5447  max mem: 40324\n",
      "Train: [epoch:25]  [ 10/172]  eta: 0:03:18  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2242  data: 0.1406  max mem: 40324\n",
      "Train: [epoch:25]  [ 20/172]  eta: 0:02:55  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0821  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [ 30/172]  eta: 0:02:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0847  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [ 40/172]  eta: 0:02:28  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0871  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0887  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [ 60/172]  eta: 0:02:04  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0896  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0889  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [ 80/172]  eta: 0:01:41  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0872  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0891  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0905  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0909  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0927  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0931  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0929  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0912  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0921  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0925  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:25] Total time: 0:03:09 (1.0998 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:25]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4831  data: 0.4581  max mem: 40324\n",
      "Valid: [epoch:25]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0567  data: 0.0334  max mem: 40324\n",
      "Valid: [epoch:25] Total time: 0:00:00 (0.0676 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_25_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:26]  [  0/172]  eta: 0:07:31  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.6226  data: 1.5374  max mem: 40324\n",
      "Train: [epoch:26]  [ 10/172]  eta: 0:03:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2294  data: 0.1399  max mem: 40324\n",
      "Train: [epoch:26]  [ 20/172]  eta: 0:02:56  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0908  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [ 30/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0923  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [ 40/172]  eta: 0:02:29  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0935  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [ 50/172]  eta: 0:02:16  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0938  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [ 60/172]  eta: 0:02:05  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0939  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [ 70/172]  eta: 0:01:53  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0926  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [ 80/172]  eta: 0:01:42  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0910  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [ 90/172]  eta: 0:01:30  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0914  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [100/172]  eta: 0:01:19  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0926  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [110/172]  eta: 0:01:08  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0936  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [120/172]  eta: 0:00:57  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0941  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [130/172]  eta: 0:00:46  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0944  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [140/172]  eta: 0:00:35  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0952  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [150/172]  eta: 0:00:24  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0944  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [160/172]  eta: 0:00:13  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0920  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [170/172]  eta: 0:00:02  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0928  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0931  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:26] Total time: 0:03:09 (1.1029 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0000 (0.0000)\n",
      "Valid: [epoch:26]  [ 0/14]  eta: 0:00:06  loss: 0.0000 (0.0000)  time: 0.4605  data: 0.4291  max mem: 40324\n",
      "Valid: [epoch:26]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0558  data: 0.0320  max mem: 40324\n",
      "Valid: [epoch:26] Total time: 0:00:00 (0.0662 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/epoch_26_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 16.000\n",
      "Train: [epoch:27]  [  0/172]  eta: 0:07:23  lr: 0.000100  loss: 0.0000 (0.0000)  time: 2.5767  data: 1.4681  max mem: 40324\n",
      "Train: [epoch:27]  [ 10/172]  eta: 0:03:17  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.2176  data: 0.1336  max mem: 40324\n",
      "Train: [epoch:27]  [ 20/172]  eta: 0:02:55  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0807  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:27]  [ 30/172]  eta: 0:02:40  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0825  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:27]  [ 40/172]  eta: 0:02:27  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0876  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:27]  [ 50/172]  eta: 0:02:15  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0895  data: 0.0001  max mem: 40324\n",
      "Train: [epoch:27]  [ 60/172]  eta: 0:02:04  lr: 0.000100  loss: 0.0000 (0.0000)  time: 1.0895  data: 0.0001  max mem: 40324\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--batch-size 40 \\\n",
    "--epochs 1000 \\\n",
    "--lr_scheduler \"lambda\" \\\n",
    "--lr 1e-4 \\\n",
    "--data-set 'Sinogram_DCM' \\\n",
    "--model-name 'MLPMixer' \\\n",
    "--criterion 'Change L2 L1 Loss' \\\n",
    "--output_dir '/workspace/sunggu/4.Dose_img2img/model/[Ours]MLPMixer_L1' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_L1/low2high/' \\\n",
    "--validate-every 2 \\\n",
    "--num_workers 4 \\\n",
    "--criterion_mode 'not balance' \\\n",
    "--multiple_GT \"False\" \\\n",
    "--patch_training \"False\" \\\n",
    "--multi-gpu-mode 'Single' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "import functools\n",
    "import pydicom\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='ignore') \n",
    "\n",
    "\n",
    "def list_sort_nicely(l):   \n",
    "    def tryint(s):        \n",
    "        try:            \n",
    "            return int(s)        \n",
    "        except:            \n",
    "            return s\n",
    "        \n",
    "    def alphanum_key(s):\n",
    "        return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "    l.sort(key=alphanum_key)    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_20_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/20/*/*/*.dcm')) + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/20/*/*/*.dcm'))\n",
    "n_100_imgs  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/X/*/*/*.dcm'))  + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/X/*/*/*.dcm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_hu(path):\n",
    "    # pydicom version...!\n",
    "    # referred from https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial\n",
    "    # ref: pydicom.pixel_data_handlers.util.apply_modality_lut\n",
    "    # '''\n",
    "    # Awesome pydicom lut fuction...!\n",
    "    # ds  = pydicom.dcmread(fname)\n",
    "    # arr = ds.pixel_array\n",
    "    # hu  = apply_modality_lut(arr, ds)\n",
    "    # '''\n",
    "    dcm_image = pydicom.read_file(path)\n",
    "    image = dcm_image.pixel_array\n",
    "    image = image.astype(np.int16)\n",
    "    image[image == -2000] = 0\n",
    "\n",
    "    intercept = dcm_image.RescaleIntercept\n",
    "    slope     = dcm_image.RescaleSlope\n",
    "\n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "\n",
    "    image += np.int16(intercept)\n",
    "    # print(image.shape) # (512, 512)\n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "def dicom_normalize(image, MIN_HU=-1024.0, MAX_HU=3071.0):   # I already check the max value is 3071.0\n",
    "   image = (image - MIN_HU) / (MAX_HU - MIN_HU)   # Range  0.0 ~ 1.0\n",
    "#    image = (image - 0.5) / 0.5                  # Range -1.0 ~ 1.0   @ We do not use -1~1 range becuase there is no Tanh act.\n",
    "   return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from monai.transforms import *\n",
    "from monai.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_20_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/20/*/*/*.dcm')) + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/20/*/*/*.dcm'))\n",
    "n_100_imgs  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/X/*/*/*.dcm'))  + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/X/*/*/*.dcm'))\n",
    "\n",
    "files = [{\"n_20\": n_20, \"n_100\": n_100} for n_20, n_100 in zip(n_20_imgs, n_100_imgs)]            \n",
    "print(\"Train [Total]  number = \", len(n_20_imgs))\n",
    "\n",
    "# CT에 맞는 Augmentation\n",
    "\n",
    "transforms = Compose(\n",
    "    [\n",
    "        Lambdad(keys=[\"n_20\", \"n_100\"], func=get_pixels_hu),\n",
    "        Lambdad(keys=[\"n_20\", \"n_100\"], func=dicom_normalize),\n",
    "        AddChanneld(keys=[\"n_20\", \"n_100\"]),                 \n",
    "\n",
    "        # Crop  \n",
    "        # RandWeightedCropd(keys=[\"image\"], w_key=[\"image\"], spatial_size=(512,512,1), num_samples=1),\n",
    "        # RandSpatialCropd(keys=[\"image\"], roi_size=(512, 512), random_size=False, random_center=True),\n",
    "        # RandSpatialCropd(keys=[\"image\"], roi_size=(512,512,3), random_size=False, random_center=True),\n",
    "#         RandSpatialCropSamplesd(keys=[\"n_20\", \"n_100\"], roi_size=(64, 64), num_samples=8, random_center=True, random_size=False, meta_keys=None, allow_missing_keys=False), \n",
    "            # patch training, next(iter(loader)) output : list로 sample 만큼,,, 그 List 안에 (B, C, H, W)\n",
    "\n",
    "        # (45 degree rotation, vertical & horizontal flip & scaling)\n",
    "#         RandFlipd(keys=[\"n_20\", \"n_100\"], prob=0.1, spatial_axis=[0, 1], allow_missing_keys=False),\n",
    "#         RandRotated(keys=[\"n_20\", \"n_100\"], prob=0.1, range_x=np.pi/4, range_y=np.pi/4, range_z=0.0, keep_size=True, align_corners=False, allow_missing_keys=False),\n",
    "#         RandZoomd(keys=[\"n_20\", \"n_100\"], prob=0.1, min_zoom=0.5, max_zoom=2.0, align_corners=None, keep_size=True, allow_missing_keys=False),\n",
    "        ToTensord(keys=[\"n_20\", \"n_100\"]),\n",
    "    ]\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Dataset(data=files, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_denormalize(image, MIN_HU=-1024.0, MAX_HU=3071.0):\n",
    "    # image = (image - 0.5) / 0.5           # Range -1.0 ~ 1.0   @ We do not use -1~1 range becuase there is no Tanh act.\n",
    "    image = (MAX_HU - MIN_HU)*image + MIN_HU\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(dicom_denormalize(t[470]['n_20'].squeeze()), 'gray', vmin=0, vmax=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dicom_denormalize(t[470]['n_100'].squeeze()), 'gray', vmin=0, vmax=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(t[470]['n_100'], t[470]['n_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCoshLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n",
    "#         return torch.mean(torch.log(torch.cosh(torch.pow(ey_t, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LogCoshLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a(t[470]['n_100'], t[470]['n_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.1081e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a(t[470]['n_100'], t[470]['n_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a(t[470]['n_100'], t[470]['n_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000*4.1081e-06 - 1000*2.1081e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_log(path):\n",
    "    log_list = []\n",
    "    lines = open(path, 'r').read().splitlines() \n",
    "    for i in range(len(lines)):\n",
    "        exec('log_list.append('+lines[i] + ')')\n",
    "    return  log_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = read_log(path = '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/log.txt')\n",
    "\n",
    "train_lr   = [ log_list[i]['train_lr'] for i in range(len(log_list)) ]\n",
    "train_loss = [ log_list[i]['train_loss'] for i in range(len(log_list)) ]\n",
    "valid_loss = [ log_list[i]['valid_loss'] for i in range(len(log_list)) ]\n",
    "epoch      = [ log_list[i]['epoch'] for i in range(len(log_list)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(train_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(valid_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(np.argsort(valid_loss)[:10]) & set(np.argsort(train_loss)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py \\\n",
    "--training-mode 'sinogram' \\\n",
    "--data-set 'TEST_Sinogram_DCM' \\\n",
    "--model-name 'ED_CNN' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Test/png/[Privious]ED_CNN/epoch_999/' \\\n",
    "--num_workers 4 \\\n",
    "--pin-mem \\\n",
    "--range-minus1-plus1 'False' \\\n",
    "--teacher_forcing \"False\" \\\n",
    "--resume '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/epoch_999_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 978 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Original === \n",
    "PSNR avg: 54.4628 \n",
    "SSIM avg: 0.9956 \n",
    "RMSE avg: 7.9607\n",
    "\n",
    "\n",
    "Predictions === \n",
    "PSNR avg: 57.6190 \n",
    "SSIM avg: 0.9980 \n",
    "RMSE avg: 5.5423\n",
    "***********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
