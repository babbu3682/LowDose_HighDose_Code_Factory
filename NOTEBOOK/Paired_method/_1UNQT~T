{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CUDA 11.1\n",
    "# !pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE -> MAE Loss 꿀팁!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 13 03:08:45 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 41%   35C    P8    13W / 280W |   8902MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 41%   36C    P8     3W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 40%   49C    P0    58W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 30%   55C    P0    39W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2, 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/sunggu/4.Dose_img2img/scripts study\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/sunggu/4.Dose_img2img/scripts study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0+cu111\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 갯수 =  32\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WCMT_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "***********************************************\n",
      "***********************************************\n",
      "Dataset Name:  Sinogram_DCM\n",
      "---------- Model ----------\n",
      "Resume From:  \n",
      "Output To:  /workspace/sunggu/4.Dose_img2img/model/[Ours]WCMT_2D\n",
      "Save   To:  /workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/\n",
      "---------- Optimizer ----------\n",
      "Learning Rate:  0.0002\n",
      "Weight Decay:  0.05\n",
      "Batchsize:  6\n",
      "Loading dataset ....\n",
      "Train [Total]  number =  6899\n",
      "Valid [Total]  number =  14\n",
      "inintializing...!\n",
      "Creating model: WCMT_2D\n",
      "Number of Learnable Params: 134450481\n",
      "Start training for 1000 epochs\n",
      "Train: [epoch:0]  [   0/1149]  eta: 2:09:11  lr: 0.000001  loss: 0.2446 (0.2446)  time: 6.7467  data: 1.4331  max mem: 34118\n",
      "Train: [epoch:0]  [  10/1149]  eta: 0:29:49  lr: 0.000001  loss: 0.2310 (0.2274)  time: 1.5709  data: 0.1304  max mem: 35661\n",
      "Train: [epoch:0]  [  20/1149]  eta: 0:24:55  lr: 0.000001  loss: 0.2071 (0.2134)  time: 1.0533  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [  30/1149]  eta: 0:22:59  lr: 0.000001  loss: 0.2094 (0.2168)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [  40/1149]  eta: 0:21:55  lr: 0.000001  loss: 0.2135 (0.2157)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [  50/1149]  eta: 0:21:11  lr: 0.000001  loss: 0.2176 (0.2173)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [  60/1149]  eta: 0:20:41  lr: 0.000001  loss: 0.2218 (0.2171)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [  70/1149]  eta: 0:20:17  lr: 0.000001  loss: 0.2218 (0.2169)  time: 1.0554  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [  80/1149]  eta: 0:19:54  lr: 0.000001  loss: 0.2130 (0.2164)  time: 1.0491  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [  90/1149]  eta: 0:19:35  lr: 0.000001  loss: 0.2342 (0.2193)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 100/1149]  eta: 0:19:18  lr: 0.000001  loss: 0.2353 (0.2198)  time: 1.0514  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 110/1149]  eta: 0:19:01  lr: 0.000001  loss: 0.2226 (0.2199)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 120/1149]  eta: 0:18:47  lr: 0.000001  loss: 0.2146 (0.2194)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 130/1149]  eta: 0:18:32  lr: 0.000001  loss: 0.2199 (0.2192)  time: 1.0552  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 140/1149]  eta: 0:18:19  lr: 0.000001  loss: 0.2238 (0.2185)  time: 1.0560  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 150/1149]  eta: 0:18:06  lr: 0.000001  loss: 0.2081 (0.2172)  time: 1.0562  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 160/1149]  eta: 0:17:52  lr: 0.000001  loss: 0.2084 (0.2168)  time: 1.0494  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 170/1149]  eta: 0:17:40  lr: 0.000001  loss: 0.2137 (0.2170)  time: 1.0491  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 180/1149]  eta: 0:17:27  lr: 0.000001  loss: 0.2219 (0.2170)  time: 1.0493  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 190/1149]  eta: 0:17:14  lr: 0.000001  loss: 0.2062 (0.2162)  time: 1.0426  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:0]  [ 200/1149]  eta: 0:17:02  lr: 0.000001  loss: 0.2028 (0.2161)  time: 1.0428  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:0]  [ 210/1149]  eta: 0:16:49  lr: 0.000001  loss: 0.2154 (0.2160)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 220/1149]  eta: 0:16:37  lr: 0.000001  loss: 0.2254 (0.2165)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 230/1149]  eta: 0:16:25  lr: 0.000001  loss: 0.2090 (0.2156)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 240/1149]  eta: 0:16:13  lr: 0.000001  loss: 0.1947 (0.2149)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 250/1149]  eta: 0:16:01  lr: 0.000001  loss: 0.1999 (0.2144)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 260/1149]  eta: 0:15:50  lr: 0.000001  loss: 0.1962 (0.2140)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 270/1149]  eta: 0:15:38  lr: 0.000001  loss: 0.1835 (0.2130)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 280/1149]  eta: 0:15:27  lr: 0.000001  loss: 0.1830 (0.2120)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 290/1149]  eta: 0:15:15  lr: 0.000001  loss: 0.1830 (0.2114)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 300/1149]  eta: 0:15:04  lr: 0.000001  loss: 0.2066 (0.2116)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 310/1149]  eta: 0:14:53  lr: 0.000001  loss: 0.2149 (0.2117)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 320/1149]  eta: 0:14:42  lr: 0.000001  loss: 0.2174 (0.2118)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 330/1149]  eta: 0:14:30  lr: 0.000001  loss: 0.2073 (0.2112)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 340/1149]  eta: 0:14:20  lr: 0.000001  loss: 0.1853 (0.2107)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 350/1149]  eta: 0:14:08  lr: 0.000001  loss: 0.1840 (0.2101)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 360/1149]  eta: 0:13:57  lr: 0.000001  loss: 0.1920 (0.2097)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 370/1149]  eta: 0:13:47  lr: 0.000001  loss: 0.1896 (0.2091)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 380/1149]  eta: 0:13:35  lr: 0.000001  loss: 0.1949 (0.2090)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 390/1149]  eta: 0:13:25  lr: 0.000001  loss: 0.1930 (0.2085)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 400/1149]  eta: 0:13:14  lr: 0.000001  loss: 0.1901 (0.2082)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 410/1149]  eta: 0:13:03  lr: 0.000001  loss: 0.1948 (0.2082)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 420/1149]  eta: 0:12:52  lr: 0.000001  loss: 0.2112 (0.2080)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 430/1149]  eta: 0:12:41  lr: 0.000001  loss: 0.1967 (0.2075)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 440/1149]  eta: 0:12:30  lr: 0.000001  loss: 0.2095 (0.2077)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 450/1149]  eta: 0:12:19  lr: 0.000001  loss: 0.2100 (0.2071)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 460/1149]  eta: 0:12:09  lr: 0.000001  loss: 0.1848 (0.2069)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 470/1149]  eta: 0:11:58  lr: 0.000001  loss: 0.1839 (0.2063)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 480/1149]  eta: 0:11:47  lr: 0.000001  loss: 0.1861 (0.2062)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 490/1149]  eta: 0:11:36  lr: 0.000001  loss: 0.1865 (0.2055)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 500/1149]  eta: 0:11:26  lr: 0.000001  loss: 0.1691 (0.2048)  time: 1.0512  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 510/1149]  eta: 0:11:15  lr: 0.000001  loss: 0.1687 (0.2044)  time: 1.0524  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:0]  [ 520/1149]  eta: 0:11:04  lr: 0.000001  loss: 0.1725 (0.2039)  time: 1.0432  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:0]  [ 530/1149]  eta: 0:10:54  lr: 0.000001  loss: 0.1776 (0.2033)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 540/1149]  eta: 0:10:43  lr: 0.000001  loss: 0.1776 (0.2029)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 550/1149]  eta: 0:10:32  lr: 0.000001  loss: 0.1754 (0.2025)  time: 1.0479  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 560/1149]  eta: 0:10:22  lr: 0.000001  loss: 0.1898 (0.2024)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 570/1149]  eta: 0:10:11  lr: 0.000001  loss: 0.1952 (0.2022)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 580/1149]  eta: 0:10:00  lr: 0.000001  loss: 0.1952 (0.2022)  time: 1.0441  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [ 590/1149]  eta: 0:09:50  lr: 0.000001  loss: 0.1791 (0.2017)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 600/1149]  eta: 0:09:39  lr: 0.000001  loss: 0.1772 (0.2014)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 610/1149]  eta: 0:09:28  lr: 0.000001  loss: 0.1781 (0.2011)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 620/1149]  eta: 0:09:18  lr: 0.000001  loss: 0.1781 (0.2009)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 630/1149]  eta: 0:09:07  lr: 0.000001  loss: 0.1837 (0.2008)  time: 1.0466  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 640/1149]  eta: 0:08:56  lr: 0.000001  loss: 0.1837 (0.2004)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 650/1149]  eta: 0:08:46  lr: 0.000001  loss: 0.2030 (0.2008)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 660/1149]  eta: 0:08:35  lr: 0.000001  loss: 0.2183 (0.2009)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 670/1149]  eta: 0:08:24  lr: 0.000001  loss: 0.1965 (0.2009)  time: 1.0380  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 680/1149]  eta: 0:08:14  lr: 0.000001  loss: 0.1742 (0.2006)  time: 1.0352  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 690/1149]  eta: 0:08:03  lr: 0.000001  loss: 0.1762 (0.2003)  time: 1.0386  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 700/1149]  eta: 0:07:52  lr: 0.000001  loss: 0.1747 (0.1999)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 710/1149]  eta: 0:07:42  lr: 0.000001  loss: 0.1737 (0.1997)  time: 1.0481  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 720/1149]  eta: 0:07:31  lr: 0.000001  loss: 0.1737 (0.1993)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 730/1149]  eta: 0:07:21  lr: 0.000001  loss: 0.1799 (0.1992)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 740/1149]  eta: 0:07:10  lr: 0.000001  loss: 0.1733 (0.1989)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 750/1149]  eta: 0:06:59  lr: 0.000001  loss: 0.1811 (0.1987)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 760/1149]  eta: 0:06:49  lr: 0.000001  loss: 0.1979 (0.1987)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 770/1149]  eta: 0:06:38  lr: 0.000001  loss: 0.2039 (0.1987)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 780/1149]  eta: 0:06:28  lr: 0.000001  loss: 0.2026 (0.1987)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 790/1149]  eta: 0:06:17  lr: 0.000001  loss: 0.1932 (0.1987)  time: 1.0534  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 800/1149]  eta: 0:06:07  lr: 0.000001  loss: 0.1806 (0.1985)  time: 1.0547  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 810/1149]  eta: 0:05:56  lr: 0.000001  loss: 0.1764 (0.1983)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 820/1149]  eta: 0:05:46  lr: 0.000001  loss: 0.1697 (0.1979)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 830/1149]  eta: 0:05:35  lr: 0.000001  loss: 0.1715 (0.1980)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 840/1149]  eta: 0:05:25  lr: 0.000001  loss: 0.1998 (0.1979)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 850/1149]  eta: 0:05:14  lr: 0.000001  loss: 0.1965 (0.1978)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 860/1149]  eta: 0:05:03  lr: 0.000001  loss: 0.1863 (0.1976)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 870/1149]  eta: 0:04:53  lr: 0.000001  loss: 0.1850 (0.1974)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 880/1149]  eta: 0:04:42  lr: 0.000001  loss: 0.1794 (0.1971)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 890/1149]  eta: 0:04:32  lr: 0.000001  loss: 0.1745 (0.1969)  time: 1.0511  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 900/1149]  eta: 0:04:21  lr: 0.000001  loss: 0.1748 (0.1968)  time: 1.0660  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 910/1149]  eta: 0:04:11  lr: 0.000001  loss: 0.1784 (0.1965)  time: 1.0593  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 920/1149]  eta: 0:04:00  lr: 0.000001  loss: 0.1955 (0.1965)  time: 1.0466  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 930/1149]  eta: 0:03:50  lr: 0.000001  loss: 0.1761 (0.1963)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 940/1149]  eta: 0:03:39  lr: 0.000001  loss: 0.1761 (0.1962)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 950/1149]  eta: 0:03:29  lr: 0.000001  loss: 0.1821 (0.1959)  time: 1.0510  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 960/1149]  eta: 0:03:18  lr: 0.000001  loss: 0.1784 (0.1957)  time: 1.0509  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 970/1149]  eta: 0:03:08  lr: 0.000001  loss: 0.1733 (0.1956)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 980/1149]  eta: 0:02:57  lr: 0.000001  loss: 0.1637 (0.1953)  time: 1.0537  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [ 990/1149]  eta: 0:02:47  lr: 0.000001  loss: 0.1722 (0.1952)  time: 1.0499  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1000/1149]  eta: 0:02:36  lr: 0.000001  loss: 0.1803 (0.1951)  time: 1.0484  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1010/1149]  eta: 0:02:26  lr: 0.000001  loss: 0.1691 (0.1948)  time: 1.0480  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1020/1149]  eta: 0:02:15  lr: 0.000001  loss: 0.1763 (0.1949)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1030/1149]  eta: 0:02:05  lr: 0.000001  loss: 0.1998 (0.1948)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1040/1149]  eta: 0:01:54  lr: 0.000001  loss: 0.1738 (0.1946)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1050/1149]  eta: 0:01:44  lr: 0.000001  loss: 0.1738 (0.1943)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1060/1149]  eta: 0:01:33  lr: 0.000001  loss: 0.1797 (0.1942)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1070/1149]  eta: 0:01:23  lr: 0.000001  loss: 0.1802 (0.1940)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1080/1149]  eta: 0:01:12  lr: 0.000001  loss: 0.1805 (0.1940)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1090/1149]  eta: 0:01:02  lr: 0.000001  loss: 0.1840 (0.1938)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1100/1149]  eta: 0:00:51  lr: 0.000001  loss: 0.1828 (0.1938)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1110/1149]  eta: 0:00:40  lr: 0.000001  loss: 0.1871 (0.1938)  time: 1.0529  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1120/1149]  eta: 0:00:30  lr: 0.000001  loss: 0.1871 (0.1938)  time: 1.0512  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1130/1149]  eta: 0:00:19  lr: 0.000001  loss: 0.1816 (0.1936)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1140/1149]  eta: 0:00:09  lr: 0.000001  loss: 0.1743 (0.1936)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0]  [1148/1149]  eta: 0:00:01  lr: 0.000001  loss: 0.1869 (0.1935)  time: 1.0589  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:0] Total time: 0:20:07 (1.0512 s / it)\n",
      "Averaged stats: lr: 0.000001  loss: 0.1869 (0.1935)\n",
      "Valid: [epoch:0]  [ 0/14]  eta: 0:00:52  loss: 0.1370 (0.1370)  time: 3.7398  data: 0.5310  max mem: 35661\n",
      "Valid: [epoch:0]  [13/14]  eta: 0:00:03  loss: 0.1289 (0.1308)  time: 3.1135  data: 0.0381  max mem: 35661\n",
      "Valid: [epoch:0] Total time: 0:00:43 (3.1299 s / it)\n",
      "Averaged stats: loss: 0.1289 (0.1308)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_0_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.131%\n",
      "Min loss: 0.131\n",
      "Best Epoch: 0.000\n",
      "/home/sunggu/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [   0/1149]  eta: 0:39:53  lr: 0.000001  loss: 0.1763 (0.1763)  time: 2.0828  data: 0.9664  max mem: 35661\n",
      "Train: [epoch:1]  [  10/1149]  eta: 0:21:49  lr: 0.000001  loss: 0.1708 (0.1694)  time: 1.1499  data: 0.0880  max mem: 35661\n",
      "Train: [epoch:1]  [  20/1149]  eta: 0:20:40  lr: 0.000001  loss: 0.1665 (0.1750)  time: 1.0497  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [  30/1149]  eta: 0:20:10  lr: 0.000001  loss: 0.1706 (0.1761)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [  40/1149]  eta: 0:19:49  lr: 0.000001  loss: 0.1680 (0.1731)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [  50/1149]  eta: 0:19:33  lr: 0.000001  loss: 0.1711 (0.1732)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [  60/1149]  eta: 0:19:18  lr: 0.000001  loss: 0.1714 (0.1724)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [  70/1149]  eta: 0:19:05  lr: 0.000001  loss: 0.1714 (0.1729)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [  80/1149]  eta: 0:18:52  lr: 0.000001  loss: 0.1639 (0.1714)  time: 1.0473  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [  90/1149]  eta: 0:18:40  lr: 0.000001  loss: 0.1582 (0.1734)  time: 1.0482  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 100/1149]  eta: 0:18:29  lr: 0.000001  loss: 0.1791 (0.1736)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 110/1149]  eta: 0:18:17  lr: 0.000001  loss: 0.1772 (0.1733)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 120/1149]  eta: 0:18:05  lr: 0.000001  loss: 0.1696 (0.1729)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 130/1149]  eta: 0:17:53  lr: 0.000001  loss: 0.1696 (0.1729)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 140/1149]  eta: 0:17:42  lr: 0.000001  loss: 0.1714 (0.1736)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 150/1149]  eta: 0:17:29  lr: 0.000001  loss: 0.1705 (0.1736)  time: 1.0350  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 160/1149]  eta: 0:17:18  lr: 0.000001  loss: 0.1751 (0.1738)  time: 1.0286  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 170/1149]  eta: 0:17:06  lr: 0.000001  loss: 0.1817 (0.1745)  time: 1.0288  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 180/1149]  eta: 0:16:55  lr: 0.000001  loss: 0.1910 (0.1753)  time: 1.0347  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 190/1149]  eta: 0:16:43  lr: 0.000001  loss: 0.1830 (0.1753)  time: 1.0334  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 200/1149]  eta: 0:16:33  lr: 0.000001  loss: 0.1783 (0.1752)  time: 1.0323  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 210/1149]  eta: 0:16:22  lr: 0.000001  loss: 0.1758 (0.1750)  time: 1.0369  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 220/1149]  eta: 0:16:11  lr: 0.000001  loss: 0.1812 (0.1756)  time: 1.0382  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 230/1149]  eta: 0:16:00  lr: 0.000001  loss: 0.1869 (0.1756)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 240/1149]  eta: 0:15:50  lr: 0.000001  loss: 0.1772 (0.1762)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 250/1149]  eta: 0:15:38  lr: 0.000001  loss: 0.1772 (0.1762)  time: 1.0356  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 260/1149]  eta: 0:15:27  lr: 0.000001  loss: 0.1695 (0.1757)  time: 1.0252  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 270/1149]  eta: 0:15:17  lr: 0.000001  loss: 0.1671 (0.1759)  time: 1.0284  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 280/1149]  eta: 0:15:06  lr: 0.000001  loss: 0.1826 (0.1762)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 290/1149]  eta: 0:14:56  lr: 0.000001  loss: 0.1706 (0.1759)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 300/1149]  eta: 0:14:45  lr: 0.000001  loss: 0.1708 (0.1764)  time: 1.0342  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 310/1149]  eta: 0:14:34  lr: 0.000001  loss: 0.1913 (0.1770)  time: 1.0366  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 320/1149]  eta: 0:14:24  lr: 0.000001  loss: 0.1845 (0.1771)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 330/1149]  eta: 0:14:14  lr: 0.000001  loss: 0.1845 (0.1775)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 340/1149]  eta: 0:14:03  lr: 0.000001  loss: 0.1847 (0.1778)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 350/1149]  eta: 0:13:53  lr: 0.000001  loss: 0.1881 (0.1780)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 360/1149]  eta: 0:13:42  lr: 0.000001  loss: 0.1655 (0.1774)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 370/1149]  eta: 0:13:32  lr: 0.000001  loss: 0.1602 (0.1771)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 380/1149]  eta: 0:13:22  lr: 0.000001  loss: 0.1654 (0.1769)  time: 1.0481  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 390/1149]  eta: 0:13:11  lr: 0.000001  loss: 0.1690 (0.1766)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 400/1149]  eta: 0:13:01  lr: 0.000001  loss: 0.1547 (0.1761)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 410/1149]  eta: 0:12:50  lr: 0.000001  loss: 0.1547 (0.1761)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 420/1149]  eta: 0:12:40  lr: 0.000001  loss: 0.1804 (0.1764)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 430/1149]  eta: 0:12:29  lr: 0.000001  loss: 0.1708 (0.1760)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 440/1149]  eta: 0:12:19  lr: 0.000001  loss: 0.1731 (0.1763)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 450/1149]  eta: 0:12:09  lr: 0.000001  loss: 0.1873 (0.1767)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 460/1149]  eta: 0:11:58  lr: 0.000001  loss: 0.2001 (0.1772)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 470/1149]  eta: 0:11:48  lr: 0.000001  loss: 0.1669 (0.1767)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 480/1149]  eta: 0:11:37  lr: 0.000001  loss: 0.1665 (0.1768)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 490/1149]  eta: 0:11:27  lr: 0.000001  loss: 0.1683 (0.1766)  time: 1.0485  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 500/1149]  eta: 0:11:17  lr: 0.000001  loss: 0.1651 (0.1764)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 510/1149]  eta: 0:11:06  lr: 0.000001  loss: 0.1782 (0.1765)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 520/1149]  eta: 0:10:56  lr: 0.000001  loss: 0.1732 (0.1763)  time: 1.0499  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 530/1149]  eta: 0:10:45  lr: 0.000001  loss: 0.1636 (0.1760)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 540/1149]  eta: 0:10:35  lr: 0.000001  loss: 0.1640 (0.1761)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 550/1149]  eta: 0:10:24  lr: 0.000001  loss: 0.1833 (0.1762)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 560/1149]  eta: 0:10:14  lr: 0.000001  loss: 0.1838 (0.1764)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 570/1149]  eta: 0:10:03  lr: 0.000001  loss: 0.1838 (0.1766)  time: 1.0314  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 580/1149]  eta: 0:09:53  lr: 0.000001  loss: 0.1953 (0.1768)  time: 1.0361  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 590/1149]  eta: 0:09:43  lr: 0.000001  loss: 0.1671 (0.1764)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 600/1149]  eta: 0:09:32  lr: 0.000001  loss: 0.1511 (0.1761)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 610/1149]  eta: 0:09:22  lr: 0.000001  loss: 0.1628 (0.1762)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 620/1149]  eta: 0:09:11  lr: 0.000001  loss: 0.1741 (0.1760)  time: 1.0497  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 630/1149]  eta: 0:09:01  lr: 0.000001  loss: 0.1595 (0.1759)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 640/1149]  eta: 0:08:50  lr: 0.000001  loss: 0.1618 (0.1759)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 650/1149]  eta: 0:08:40  lr: 0.000001  loss: 0.1690 (0.1759)  time: 1.0431  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [ 660/1149]  eta: 0:08:30  lr: 0.000001  loss: 0.1879 (0.1762)  time: 1.0366  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 670/1149]  eta: 0:08:19  lr: 0.000001  loss: 0.1839 (0.1761)  time: 1.0368  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 680/1149]  eta: 0:08:09  lr: 0.000001  loss: 0.1650 (0.1761)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 690/1149]  eta: 0:07:58  lr: 0.000001  loss: 0.1771 (0.1761)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 700/1149]  eta: 0:07:48  lr: 0.000001  loss: 0.1664 (0.1758)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 710/1149]  eta: 0:07:37  lr: 0.000001  loss: 0.1575 (0.1755)  time: 1.0366  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 720/1149]  eta: 0:07:27  lr: 0.000001  loss: 0.1577 (0.1755)  time: 1.0351  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 730/1149]  eta: 0:07:16  lr: 0.000001  loss: 0.1710 (0.1755)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 740/1149]  eta: 0:07:06  lr: 0.000001  loss: 0.1691 (0.1753)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 750/1149]  eta: 0:06:56  lr: 0.000001  loss: 0.1546 (0.1751)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 760/1149]  eta: 0:06:45  lr: 0.000001  loss: 0.1669 (0.1752)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 770/1149]  eta: 0:06:35  lr: 0.000001  loss: 0.1878 (0.1755)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 780/1149]  eta: 0:06:24  lr: 0.000001  loss: 0.1884 (0.1755)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 790/1149]  eta: 0:06:14  lr: 0.000001  loss: 0.1825 (0.1756)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 800/1149]  eta: 0:06:03  lr: 0.000001  loss: 0.1814 (0.1756)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 810/1149]  eta: 0:05:53  lr: 0.000001  loss: 0.1743 (0.1756)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 820/1149]  eta: 0:05:43  lr: 0.000001  loss: 0.1643 (0.1754)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 830/1149]  eta: 0:05:32  lr: 0.000001  loss: 0.1664 (0.1754)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 840/1149]  eta: 0:05:22  lr: 0.000001  loss: 0.1779 (0.1754)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 850/1149]  eta: 0:05:11  lr: 0.000001  loss: 0.1779 (0.1756)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 860/1149]  eta: 0:05:01  lr: 0.000001  loss: 0.1895 (0.1757)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 870/1149]  eta: 0:04:50  lr: 0.000001  loss: 0.1743 (0.1756)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 880/1149]  eta: 0:04:40  lr: 0.000001  loss: 0.1643 (0.1755)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 890/1149]  eta: 0:04:30  lr: 0.000001  loss: 0.1643 (0.1755)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 900/1149]  eta: 0:04:19  lr: 0.000001  loss: 0.1571 (0.1752)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 910/1149]  eta: 0:04:09  lr: 0.000001  loss: 0.1548 (0.1749)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 920/1149]  eta: 0:03:58  lr: 0.000001  loss: 0.1723 (0.1751)  time: 1.0367  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 930/1149]  eta: 0:03:48  lr: 0.000001  loss: 0.1751 (0.1751)  time: 1.0386  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 940/1149]  eta: 0:03:37  lr: 0.000001  loss: 0.1803 (0.1752)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 950/1149]  eta: 0:03:27  lr: 0.000001  loss: 0.1780 (0.1751)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 960/1149]  eta: 0:03:17  lr: 0.000001  loss: 0.1685 (0.1750)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 970/1149]  eta: 0:03:06  lr: 0.000001  loss: 0.1709 (0.1751)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 980/1149]  eta: 0:02:56  lr: 0.000001  loss: 0.1568 (0.1748)  time: 1.0379  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [ 990/1149]  eta: 0:02:45  lr: 0.000001  loss: 0.1419 (0.1746)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1000/1149]  eta: 0:02:35  lr: 0.000001  loss: 0.1526 (0.1745)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1010/1149]  eta: 0:02:24  lr: 0.000001  loss: 0.1669 (0.1744)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1020/1149]  eta: 0:02:14  lr: 0.000001  loss: 0.1669 (0.1744)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1030/1149]  eta: 0:02:04  lr: 0.000001  loss: 0.1694 (0.1743)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1040/1149]  eta: 0:01:53  lr: 0.000001  loss: 0.1715 (0.1744)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1050/1149]  eta: 0:01:43  lr: 0.000001  loss: 0.1715 (0.1743)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1060/1149]  eta: 0:01:32  lr: 0.000001  loss: 0.1657 (0.1743)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1070/1149]  eta: 0:01:22  lr: 0.000001  loss: 0.1648 (0.1742)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1080/1149]  eta: 0:01:11  lr: 0.000001  loss: 0.1688 (0.1743)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1090/1149]  eta: 0:01:01  lr: 0.000001  loss: 0.1728 (0.1744)  time: 1.0372  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1100/1149]  eta: 0:00:51  lr: 0.000001  loss: 0.1740 (0.1744)  time: 1.0355  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1110/1149]  eta: 0:00:40  lr: 0.000001  loss: 0.1861 (0.1745)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1120/1149]  eta: 0:00:30  lr: 0.000001  loss: 0.1784 (0.1746)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1130/1149]  eta: 0:00:19  lr: 0.000001  loss: 0.1738 (0.1744)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1140/1149]  eta: 0:00:09  lr: 0.000001  loss: 0.1738 (0.1746)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1]  [1148/1149]  eta: 0:00:01  lr: 0.000001  loss: 0.1749 (0.1746)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:1] Total time: 0:19:58 (1.0427 s / it)\n",
      "Averaged stats: lr: 0.000001  loss: 0.1749 (0.1746)\n",
      "Valid: [epoch:1]  [ 0/14]  eta: 0:00:50  loss: 0.1290 (0.1290)  time: 3.6013  data: 0.7510  max mem: 35661\n",
      "Valid: [epoch:1]  [13/14]  eta: 0:00:02  loss: 0.1227 (0.1241)  time: 2.8621  data: 0.0537  max mem: 35661\n",
      "Valid: [epoch:1] Total time: 0:00:40 (2.8785 s / it)\n",
      "Averaged stats: loss: 0.1227 (0.1241)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_1_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.124%\n",
      "Min loss: 0.124\n",
      "Best Epoch: 1.000\n",
      "Train: [epoch:2]  [   0/1149]  eta: 0:56:07  lr: 0.000020  loss: 0.1595 (0.1595)  time: 2.9308  data: 1.7909  max mem: 35661\n",
      "Train: [epoch:2]  [  10/1149]  eta: 0:22:55  lr: 0.000020  loss: 0.1595 (0.1701)  time: 1.2079  data: 0.1629  max mem: 35661\n",
      "Train: [epoch:2]  [  20/1149]  eta: 0:21:11  lr: 0.000020  loss: 0.1576 (0.1676)  time: 1.0362  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [  30/1149]  eta: 0:20:23  lr: 0.000020  loss: 0.1617 (0.1699)  time: 1.0306  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [  40/1149]  eta: 0:19:54  lr: 0.000020  loss: 0.1617 (0.1687)  time: 1.0249  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [  50/1149]  eta: 0:19:35  lr: 0.000020  loss: 0.1524 (0.1665)  time: 1.0331  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [  60/1149]  eta: 0:19:20  lr: 0.000020  loss: 0.1549 (0.1638)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [  70/1149]  eta: 0:19:06  lr: 0.000020  loss: 0.1648 (0.1658)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [  80/1149]  eta: 0:18:54  lr: 0.000020  loss: 0.1660 (0.1643)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [  90/1149]  eta: 0:18:42  lr: 0.000020  loss: 0.1801 (0.1673)  time: 1.0486  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 100/1149]  eta: 0:18:29  lr: 0.000020  loss: 0.1782 (0.1668)  time: 1.0426  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [ 110/1149]  eta: 0:18:16  lr: 0.000020  loss: 0.1494 (0.1657)  time: 1.0350  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 120/1149]  eta: 0:18:03  lr: 0.000020  loss: 0.1568 (0.1664)  time: 1.0316  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 130/1149]  eta: 0:17:53  lr: 0.000020  loss: 0.1717 (0.1662)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 140/1149]  eta: 0:17:43  lr: 0.000020  loss: 0.1669 (0.1666)  time: 1.0567  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 150/1149]  eta: 0:17:32  lr: 0.000020  loss: 0.1669 (0.1664)  time: 1.0562  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 160/1149]  eta: 0:17:21  lr: 0.000020  loss: 0.1693 (0.1663)  time: 1.0528  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 170/1149]  eta: 0:17:10  lr: 0.000020  loss: 0.1519 (0.1659)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 180/1149]  eta: 0:16:59  lr: 0.000020  loss: 0.1621 (0.1661)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 190/1149]  eta: 0:16:48  lr: 0.000020  loss: 0.1696 (0.1656)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 200/1149]  eta: 0:16:37  lr: 0.000020  loss: 0.1525 (0.1652)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 210/1149]  eta: 0:16:26  lr: 0.000020  loss: 0.1553 (0.1652)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 220/1149]  eta: 0:16:16  lr: 0.000020  loss: 0.1780 (0.1658)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 230/1149]  eta: 0:16:05  lr: 0.000020  loss: 0.1780 (0.1662)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 240/1149]  eta: 0:15:54  lr: 0.000020  loss: 0.1733 (0.1667)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 250/1149]  eta: 0:15:44  lr: 0.000020  loss: 0.1728 (0.1663)  time: 1.0497  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 260/1149]  eta: 0:15:33  lr: 0.000020  loss: 0.1516 (0.1658)  time: 1.0502  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 270/1149]  eta: 0:15:23  lr: 0.000020  loss: 0.1464 (0.1650)  time: 1.0535  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 280/1149]  eta: 0:15:12  lr: 0.000020  loss: 0.1540 (0.1653)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 290/1149]  eta: 0:15:02  lr: 0.000020  loss: 0.1759 (0.1652)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 300/1149]  eta: 0:14:51  lr: 0.000020  loss: 0.1704 (0.1656)  time: 1.0531  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 310/1149]  eta: 0:14:41  lr: 0.000020  loss: 0.1640 (0.1657)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 320/1149]  eta: 0:14:30  lr: 0.000020  loss: 0.1621 (0.1656)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 330/1149]  eta: 0:14:20  lr: 0.000020  loss: 0.1583 (0.1653)  time: 1.0489  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 340/1149]  eta: 0:14:09  lr: 0.000020  loss: 0.1528 (0.1650)  time: 1.0486  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 350/1149]  eta: 0:13:58  lr: 0.000020  loss: 0.1509 (0.1648)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 360/1149]  eta: 0:13:48  lr: 0.000020  loss: 0.1698 (0.1649)  time: 1.0485  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 370/1149]  eta: 0:13:37  lr: 0.000020  loss: 0.1698 (0.1648)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 380/1149]  eta: 0:13:26  lr: 0.000020  loss: 0.1638 (0.1649)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 390/1149]  eta: 0:13:15  lr: 0.000020  loss: 0.1505 (0.1645)  time: 1.0270  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 400/1149]  eta: 0:13:05  lr: 0.000020  loss: 0.1436 (0.1641)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 410/1149]  eta: 0:12:55  lr: 0.000020  loss: 0.1561 (0.1640)  time: 1.0536  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 420/1149]  eta: 0:12:44  lr: 0.000020  loss: 0.1604 (0.1637)  time: 1.0491  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 430/1149]  eta: 0:12:34  lr: 0.000020  loss: 0.1508 (0.1636)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 440/1149]  eta: 0:12:23  lr: 0.000020  loss: 0.1591 (0.1637)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 450/1149]  eta: 0:12:12  lr: 0.000020  loss: 0.1714 (0.1638)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 460/1149]  eta: 0:12:02  lr: 0.000020  loss: 0.1802 (0.1641)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 470/1149]  eta: 0:11:51  lr: 0.000020  loss: 0.1663 (0.1640)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 480/1149]  eta: 0:11:41  lr: 0.000020  loss: 0.1595 (0.1642)  time: 1.0360  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 490/1149]  eta: 0:11:30  lr: 0.000020  loss: 0.1621 (0.1641)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 500/1149]  eta: 0:11:20  lr: 0.000020  loss: 0.1419 (0.1638)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 510/1149]  eta: 0:11:09  lr: 0.000020  loss: 0.1399 (0.1634)  time: 1.0485  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 520/1149]  eta: 0:10:59  lr: 0.000020  loss: 0.1521 (0.1633)  time: 1.0483  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 530/1149]  eta: 0:10:48  lr: 0.000020  loss: 0.1485 (0.1629)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 540/1149]  eta: 0:10:38  lr: 0.000020  loss: 0.1463 (0.1627)  time: 1.0477  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 550/1149]  eta: 0:10:27  lr: 0.000020  loss: 0.1469 (0.1626)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 560/1149]  eta: 0:10:17  lr: 0.000020  loss: 0.1589 (0.1628)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 570/1149]  eta: 0:10:06  lr: 0.000020  loss: 0.1591 (0.1626)  time: 1.0321  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 580/1149]  eta: 0:09:55  lr: 0.000020  loss: 0.1416 (0.1625)  time: 1.0278  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 590/1149]  eta: 0:09:45  lr: 0.000020  loss: 0.1397 (0.1621)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 600/1149]  eta: 0:09:34  lr: 0.000020  loss: 0.1339 (0.1615)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 610/1149]  eta: 0:09:24  lr: 0.000020  loss: 0.1293 (0.1612)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 620/1149]  eta: 0:09:13  lr: 0.000020  loss: 0.1543 (0.1613)  time: 1.0498  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 630/1149]  eta: 0:09:03  lr: 0.000020  loss: 0.1586 (0.1611)  time: 1.0494  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 640/1149]  eta: 0:08:52  lr: 0.000020  loss: 0.1492 (0.1609)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 650/1149]  eta: 0:08:42  lr: 0.000020  loss: 0.1588 (0.1613)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 660/1149]  eta: 0:08:31  lr: 0.000020  loss: 0.1828 (0.1614)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 670/1149]  eta: 0:08:21  lr: 0.000020  loss: 0.1684 (0.1613)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 680/1149]  eta: 0:08:10  lr: 0.000020  loss: 0.1464 (0.1611)  time: 1.0478  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 690/1149]  eta: 0:08:00  lr: 0.000020  loss: 0.1434 (0.1608)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 700/1149]  eta: 0:07:50  lr: 0.000020  loss: 0.1349 (0.1604)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 710/1149]  eta: 0:07:39  lr: 0.000020  loss: 0.1265 (0.1600)  time: 1.0481  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 720/1149]  eta: 0:07:28  lr: 0.000020  loss: 0.1416 (0.1599)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 730/1149]  eta: 0:07:18  lr: 0.000020  loss: 0.1478 (0.1597)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 740/1149]  eta: 0:07:08  lr: 0.000020  loss: 0.1465 (0.1594)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 750/1149]  eta: 0:06:57  lr: 0.000020  loss: 0.1433 (0.1592)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 760/1149]  eta: 0:06:47  lr: 0.000020  loss: 0.1532 (0.1592)  time: 1.0447  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [ 770/1149]  eta: 0:06:36  lr: 0.000020  loss: 0.1570 (0.1592)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 780/1149]  eta: 0:06:26  lr: 0.000020  loss: 0.1560 (0.1591)  time: 1.0499  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 790/1149]  eta: 0:06:15  lr: 0.000020  loss: 0.1571 (0.1591)  time: 1.0505  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 800/1149]  eta: 0:06:05  lr: 0.000020  loss: 0.1494 (0.1590)  time: 1.0517  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 810/1149]  eta: 0:05:54  lr: 0.000020  loss: 0.1360 (0.1586)  time: 1.0502  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 820/1149]  eta: 0:05:44  lr: 0.000020  loss: 0.1336 (0.1584)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 830/1149]  eta: 0:05:33  lr: 0.000020  loss: 0.1551 (0.1584)  time: 1.0466  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 840/1149]  eta: 0:05:23  lr: 0.000020  loss: 0.1536 (0.1582)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 850/1149]  eta: 0:05:12  lr: 0.000020  loss: 0.1493 (0.1582)  time: 1.0480  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 860/1149]  eta: 0:05:02  lr: 0.000020  loss: 0.1569 (0.1580)  time: 1.0506  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 870/1149]  eta: 0:04:52  lr: 0.000020  loss: 0.1569 (0.1580)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 880/1149]  eta: 0:04:41  lr: 0.000020  loss: 0.1465 (0.1579)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 890/1149]  eta: 0:04:31  lr: 0.000020  loss: 0.1388 (0.1577)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 900/1149]  eta: 0:04:20  lr: 0.000020  loss: 0.1365 (0.1575)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 910/1149]  eta: 0:04:10  lr: 0.000020  loss: 0.1364 (0.1572)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 920/1149]  eta: 0:03:59  lr: 0.000020  loss: 0.1405 (0.1573)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 930/1149]  eta: 0:03:49  lr: 0.000020  loss: 0.1608 (0.1574)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 940/1149]  eta: 0:03:38  lr: 0.000020  loss: 0.1529 (0.1573)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 950/1149]  eta: 0:03:28  lr: 0.000020  loss: 0.1529 (0.1572)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 960/1149]  eta: 0:03:17  lr: 0.000020  loss: 0.1521 (0.1571)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 970/1149]  eta: 0:03:07  lr: 0.000020  loss: 0.1516 (0.1571)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 980/1149]  eta: 0:02:56  lr: 0.000020  loss: 0.1421 (0.1568)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [ 990/1149]  eta: 0:02:46  lr: 0.000020  loss: 0.1312 (0.1566)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1000/1149]  eta: 0:02:35  lr: 0.000020  loss: 0.1354 (0.1563)  time: 1.0488  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1010/1149]  eta: 0:02:25  lr: 0.000020  loss: 0.1195 (0.1560)  time: 1.0521  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1020/1149]  eta: 0:02:14  lr: 0.000020  loss: 0.1208 (0.1559)  time: 1.0521  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1030/1149]  eta: 0:02:04  lr: 0.000020  loss: 0.1361 (0.1556)  time: 1.0515  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1040/1149]  eta: 0:01:54  lr: 0.000020  loss: 0.1387 (0.1556)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1050/1149]  eta: 0:01:43  lr: 0.000020  loss: 0.1396 (0.1554)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1060/1149]  eta: 0:01:33  lr: 0.000020  loss: 0.1351 (0.1553)  time: 1.2406  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:2]  [1070/1149]  eta: 0:01:22  lr: 0.000020  loss: 0.1424 (0.1551)  time: 1.2485  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1080/1149]  eta: 0:01:12  lr: 0.000020  loss: 0.1268 (0.1548)  time: 1.2300  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1090/1149]  eta: 0:01:02  lr: 0.000020  loss: 0.1394 (0.1548)  time: 1.2248  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1100/1149]  eta: 0:00:51  lr: 0.000020  loss: 0.1546 (0.1548)  time: 1.0649  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1110/1149]  eta: 0:00:41  lr: 0.000020  loss: 0.1333 (0.1546)  time: 1.0617  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1120/1149]  eta: 0:00:30  lr: 0.000020  loss: 0.1266 (0.1544)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1130/1149]  eta: 0:00:20  lr: 0.000020  loss: 0.1239 (0.1541)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1140/1149]  eta: 0:00:09  lr: 0.000020  loss: 0.1252 (0.1540)  time: 1.0370  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2]  [1148/1149]  eta: 0:00:01  lr: 0.000020  loss: 0.1411 (0.1540)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:2] Total time: 0:20:10 (1.0534 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.1411 (0.1540)\n",
      "Valid: [epoch:2]  [ 0/14]  eta: 0:00:49  loss: 0.0732 (0.0732)  time: 3.5544  data: 0.6291  max mem: 35661\n",
      "Valid: [epoch:2]  [13/14]  eta: 0:00:02  loss: 0.0902 (0.0930)  time: 2.8671  data: 0.0451  max mem: 35661\n",
      "Valid: [epoch:2] Total time: 0:00:40 (2.8851 s / it)\n",
      "Averaged stats: loss: 0.0902 (0.0930)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_2_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.093%\n",
      "Min loss: 0.093\n",
      "Best Epoch: 2.000\n",
      "Train: [epoch:3]  [   0/1149]  eta: 0:47:10  lr: 0.000040  loss: 0.1559 (0.1559)  time: 2.4638  data: 1.3482  max mem: 35661\n",
      "Train: [epoch:3]  [  10/1149]  eta: 0:21:53  lr: 0.000040  loss: 0.1353 (0.1376)  time: 1.1531  data: 0.1227  max mem: 35661\n",
      "Train: [epoch:3]  [  20/1149]  eta: 0:20:42  lr: 0.000040  loss: 0.1318 (0.1339)  time: 1.0324  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [  30/1149]  eta: 0:20:15  lr: 0.000040  loss: 0.1231 (0.1322)  time: 1.0491  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [  40/1149]  eta: 0:19:53  lr: 0.000040  loss: 0.1231 (0.1307)  time: 1.0508  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [  50/1149]  eta: 0:19:35  lr: 0.000040  loss: 0.1240 (0.1308)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [  60/1149]  eta: 0:19:18  lr: 0.000040  loss: 0.1189 (0.1292)  time: 1.0369  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [  70/1149]  eta: 0:19:04  lr: 0.000040  loss: 0.1200 (0.1289)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [  80/1149]  eta: 0:18:53  lr: 0.000040  loss: 0.1190 (0.1273)  time: 1.0510  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [  90/1149]  eta: 0:18:40  lr: 0.000040  loss: 0.1185 (0.1272)  time: 1.0493  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 100/1149]  eta: 0:18:28  lr: 0.000040  loss: 0.1251 (0.1265)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 110/1149]  eta: 0:18:17  lr: 0.000040  loss: 0.1238 (0.1260)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 120/1149]  eta: 0:18:05  lr: 0.000040  loss: 0.1083 (0.1247)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 130/1149]  eta: 0:17:54  lr: 0.000040  loss: 0.1083 (0.1243)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 140/1149]  eta: 0:17:42  lr: 0.000040  loss: 0.1117 (0.1234)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 150/1149]  eta: 0:17:31  lr: 0.000040  loss: 0.1066 (0.1222)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 160/1149]  eta: 0:17:20  lr: 0.000040  loss: 0.1052 (0.1213)  time: 1.0486  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 170/1149]  eta: 0:17:09  lr: 0.000040  loss: 0.1081 (0.1211)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 180/1149]  eta: 0:16:58  lr: 0.000040  loss: 0.1150 (0.1207)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 190/1149]  eta: 0:16:48  lr: 0.000040  loss: 0.1021 (0.1196)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 200/1149]  eta: 0:16:36  lr: 0.000040  loss: 0.0972 (0.1184)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 210/1149]  eta: 0:16:25  lr: 0.000040  loss: 0.0912 (0.1177)  time: 1.0391  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [ 220/1149]  eta: 0:16:14  lr: 0.000040  loss: 0.0989 (0.1171)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 230/1149]  eta: 0:16:04  lr: 0.000040  loss: 0.1052 (0.1168)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 240/1149]  eta: 0:15:52  lr: 0.000040  loss: 0.1047 (0.1163)  time: 1.0344  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 250/1149]  eta: 0:15:41  lr: 0.000040  loss: 0.1020 (0.1155)  time: 1.0315  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 260/1149]  eta: 0:15:30  lr: 0.000040  loss: 0.0891 (0.1146)  time: 1.0314  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 270/1149]  eta: 0:15:19  lr: 0.000040  loss: 0.0904 (0.1140)  time: 1.0229  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 280/1149]  eta: 0:15:08  lr: 0.000040  loss: 0.0945 (0.1134)  time: 1.0218  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 290/1149]  eta: 0:14:57  lr: 0.000040  loss: 0.0862 (0.1126)  time: 1.0346  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 300/1149]  eta: 0:14:46  lr: 0.000040  loss: 0.0876 (0.1121)  time: 1.0360  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 310/1149]  eta: 0:14:35  lr: 0.000040  loss: 0.1028 (0.1121)  time: 1.0279  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 320/1149]  eta: 0:14:25  lr: 0.000040  loss: 0.1022 (0.1116)  time: 1.0311  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 330/1149]  eta: 0:14:14  lr: 0.000040  loss: 0.0896 (0.1108)  time: 1.0293  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 340/1149]  eta: 0:14:03  lr: 0.000040  loss: 0.0779 (0.1098)  time: 1.0256  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 350/1149]  eta: 0:13:52  lr: 0.000040  loss: 0.0790 (0.1096)  time: 1.0285  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 360/1149]  eta: 0:13:42  lr: 0.000040  loss: 0.0848 (0.1089)  time: 1.0353  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 370/1149]  eta: 0:13:31  lr: 0.000040  loss: 0.0839 (0.1082)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 380/1149]  eta: 0:13:21  lr: 0.000040  loss: 0.0901 (0.1079)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 390/1149]  eta: 0:13:11  lr: 0.000040  loss: 0.0894 (0.1072)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 400/1149]  eta: 0:13:00  lr: 0.000040  loss: 0.0800 (0.1065)  time: 1.0507  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 410/1149]  eta: 0:12:50  lr: 0.000040  loss: 0.0784 (0.1058)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 420/1149]  eta: 0:12:39  lr: 0.000040  loss: 0.0784 (0.1053)  time: 1.0348  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 430/1149]  eta: 0:12:29  lr: 0.000040  loss: 0.0804 (0.1047)  time: 1.0339  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 440/1149]  eta: 0:12:19  lr: 0.000040  loss: 0.0792 (0.1042)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 450/1149]  eta: 0:12:08  lr: 0.000040  loss: 0.0788 (0.1036)  time: 1.0478  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 460/1149]  eta: 0:11:58  lr: 0.000040  loss: 0.0788 (0.1032)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 470/1149]  eta: 0:11:48  lr: 0.000040  loss: 0.0787 (0.1026)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 480/1149]  eta: 0:11:37  lr: 0.000040  loss: 0.0703 (0.1020)  time: 1.0507  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 490/1149]  eta: 0:11:27  lr: 0.000040  loss: 0.0722 (0.1014)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 500/1149]  eta: 0:11:16  lr: 0.000040  loss: 0.0698 (0.1007)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 510/1149]  eta: 0:11:06  lr: 0.000040  loss: 0.0650 (0.1000)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 520/1149]  eta: 0:10:56  lr: 0.000040  loss: 0.0656 (0.0993)  time: 1.0519  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 530/1149]  eta: 0:10:45  lr: 0.000040  loss: 0.0630 (0.0985)  time: 1.0561  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 540/1149]  eta: 0:10:35  lr: 0.000040  loss: 0.0565 (0.0979)  time: 1.0508  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 550/1149]  eta: 0:10:25  lr: 0.000040  loss: 0.0633 (0.0974)  time: 1.0510  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 560/1149]  eta: 0:10:14  lr: 0.000040  loss: 0.0716 (0.0971)  time: 1.0543  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 570/1149]  eta: 0:10:04  lr: 0.000040  loss: 0.0652 (0.0965)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 580/1149]  eta: 0:09:53  lr: 0.000040  loss: 0.0628 (0.0960)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 590/1149]  eta: 0:09:43  lr: 0.000040  loss: 0.0604 (0.0953)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 600/1149]  eta: 0:09:32  lr: 0.000040  loss: 0.0568 (0.0947)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 610/1149]  eta: 0:09:22  lr: 0.000040  loss: 0.0584 (0.0941)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 620/1149]  eta: 0:09:12  lr: 0.000040  loss: 0.0574 (0.0935)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 630/1149]  eta: 0:09:01  lr: 0.000040  loss: 0.0568 (0.0930)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 640/1149]  eta: 0:08:51  lr: 0.000040  loss: 0.0584 (0.0924)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 650/1149]  eta: 0:08:40  lr: 0.000040  loss: 0.0608 (0.0920)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 660/1149]  eta: 0:08:30  lr: 0.000040  loss: 0.0666 (0.0916)  time: 1.0304  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 670/1149]  eta: 0:08:19  lr: 0.000040  loss: 0.0666 (0.0912)  time: 1.0349  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 680/1149]  eta: 0:08:09  lr: 0.000040  loss: 0.0556 (0.0907)  time: 1.0382  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 690/1149]  eta: 0:07:58  lr: 0.000040  loss: 0.0510 (0.0901)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 700/1149]  eta: 0:07:48  lr: 0.000040  loss: 0.0521 (0.0897)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 710/1149]  eta: 0:07:37  lr: 0.000040  loss: 0.0541 (0.0892)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 720/1149]  eta: 0:07:27  lr: 0.000040  loss: 0.0536 (0.0887)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 730/1149]  eta: 0:07:17  lr: 0.000040  loss: 0.0549 (0.0883)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 740/1149]  eta: 0:07:06  lr: 0.000040  loss: 0.0578 (0.0878)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 750/1149]  eta: 0:06:56  lr: 0.000040  loss: 0.0509 (0.0873)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 760/1149]  eta: 0:06:45  lr: 0.000040  loss: 0.0524 (0.0869)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 770/1149]  eta: 0:06:35  lr: 0.000040  loss: 0.0564 (0.0866)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 780/1149]  eta: 0:06:24  lr: 0.000040  loss: 0.0564 (0.0861)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 790/1149]  eta: 0:06:14  lr: 0.000040  loss: 0.0536 (0.0858)  time: 1.0347  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 800/1149]  eta: 0:06:03  lr: 0.000040  loss: 0.0560 (0.0854)  time: 1.0311  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 810/1149]  eta: 0:05:53  lr: 0.000040  loss: 0.0520 (0.0850)  time: 1.0319  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 820/1149]  eta: 0:05:43  lr: 0.000040  loss: 0.0475 (0.0845)  time: 1.0351  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 830/1149]  eta: 0:05:32  lr: 0.000040  loss: 0.0475 (0.0842)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 840/1149]  eta: 0:05:22  lr: 0.000040  loss: 0.0479 (0.0837)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 850/1149]  eta: 0:05:11  lr: 0.000040  loss: 0.0474 (0.0833)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 860/1149]  eta: 0:05:01  lr: 0.000040  loss: 0.0530 (0.0830)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 870/1149]  eta: 0:04:50  lr: 0.000040  loss: 0.0530 (0.0826)  time: 1.0463  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [ 880/1149]  eta: 0:04:40  lr: 0.000040  loss: 0.0496 (0.0822)  time: 1.0536  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 890/1149]  eta: 0:04:30  lr: 0.000040  loss: 0.0496 (0.0819)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 900/1149]  eta: 0:04:19  lr: 0.000040  loss: 0.0512 (0.0816)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 910/1149]  eta: 0:04:09  lr: 0.000040  loss: 0.0490 (0.0812)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 920/1149]  eta: 0:03:58  lr: 0.000040  loss: 0.0485 (0.0809)  time: 1.0311  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 930/1149]  eta: 0:03:48  lr: 0.000040  loss: 0.0490 (0.0805)  time: 1.0188  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 940/1149]  eta: 0:03:37  lr: 0.000040  loss: 0.0474 (0.0802)  time: 1.0224  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 950/1149]  eta: 0:03:27  lr: 0.000040  loss: 0.0467 (0.0798)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 960/1149]  eta: 0:03:17  lr: 0.000040  loss: 0.0422 (0.0794)  time: 1.0542  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 970/1149]  eta: 0:03:06  lr: 0.000040  loss: 0.0429 (0.0791)  time: 1.0503  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 980/1149]  eta: 0:02:56  lr: 0.000040  loss: 0.0428 (0.0787)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [ 990/1149]  eta: 0:02:45  lr: 0.000040  loss: 0.0383 (0.0783)  time: 1.0494  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1000/1149]  eta: 0:02:35  lr: 0.000040  loss: 0.0416 (0.0779)  time: 1.0516  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1010/1149]  eta: 0:02:24  lr: 0.000040  loss: 0.0416 (0.0776)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1020/1149]  eta: 0:02:14  lr: 0.000040  loss: 0.0442 (0.0773)  time: 1.0376  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1030/1149]  eta: 0:02:04  lr: 0.000040  loss: 0.0447 (0.0769)  time: 1.0282  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1040/1149]  eta: 0:01:53  lr: 0.000040  loss: 0.0402 (0.0765)  time: 1.0266  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1050/1149]  eta: 0:01:43  lr: 0.000040  loss: 0.0373 (0.0762)  time: 1.0278  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1060/1149]  eta: 0:01:32  lr: 0.000040  loss: 0.0380 (0.0758)  time: 1.0314  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1070/1149]  eta: 0:01:22  lr: 0.000040  loss: 0.0380 (0.0755)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1080/1149]  eta: 0:01:11  lr: 0.000040  loss: 0.0371 (0.0751)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1090/1149]  eta: 0:01:01  lr: 0.000040  loss: 0.0374 (0.0748)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1100/1149]  eta: 0:00:51  lr: 0.000040  loss: 0.0372 (0.0745)  time: 1.0352  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1110/1149]  eta: 0:00:40  lr: 0.000040  loss: 0.0365 (0.0741)  time: 1.0261  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1120/1149]  eta: 0:00:30  lr: 0.000040  loss: 0.0334 (0.0738)  time: 1.0291  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1130/1149]  eta: 0:00:19  lr: 0.000040  loss: 0.0329 (0.0734)  time: 1.0347  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1140/1149]  eta: 0:00:09  lr: 0.000040  loss: 0.0356 (0.0731)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3]  [1148/1149]  eta: 0:00:01  lr: 0.000040  loss: 0.0348 (0.0729)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:3] Total time: 0:19:57 (1.0420 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.0348 (0.0729)\n",
      "Valid: [epoch:3]  [ 0/14]  eta: 0:00:54  loss: 0.0227 (0.0227)  time: 3.8807  data: 0.7432  max mem: 35661\n",
      "Valid: [epoch:3]  [13/14]  eta: 0:00:03  loss: 0.0227 (0.0247)  time: 3.2177  data: 0.0532  max mem: 35661\n",
      "Valid: [epoch:3] Total time: 0:00:45 (3.2361 s / it)\n",
      "Averaged stats: loss: 0.0227 (0.0247)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_3_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.025%\n",
      "Min loss: 0.025\n",
      "Best Epoch: 3.000\n",
      "Train: [epoch:4]  [   0/1149]  eta: 0:53:29  lr: 0.000060  loss: 0.0322 (0.0322)  time: 2.7935  data: 1.7081  max mem: 35661\n",
      "Train: [epoch:4]  [  10/1149]  eta: 0:22:58  lr: 0.000060  loss: 0.0322 (0.0351)  time: 1.2102  data: 0.1554  max mem: 35661\n",
      "Train: [epoch:4]  [  20/1149]  eta: 0:21:16  lr: 0.000060  loss: 0.0299 (0.0338)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [  30/1149]  eta: 0:20:36  lr: 0.000060  loss: 0.0315 (0.0342)  time: 1.0473  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [  40/1149]  eta: 0:20:12  lr: 0.000060  loss: 0.0338 (0.0337)  time: 1.0540  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [  50/1149]  eta: 0:19:51  lr: 0.000060  loss: 0.0337 (0.0335)  time: 1.0518  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [  60/1149]  eta: 0:19:34  lr: 0.000060  loss: 0.0324 (0.0332)  time: 1.0487  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [  70/1149]  eta: 0:19:19  lr: 0.000060  loss: 0.0324 (0.0333)  time: 1.0502  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [  80/1149]  eta: 0:19:04  lr: 0.000060  loss: 0.0309 (0.0331)  time: 1.0482  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [  90/1149]  eta: 0:18:51  lr: 0.000060  loss: 0.0309 (0.0334)  time: 1.0465  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 100/1149]  eta: 0:18:37  lr: 0.000060  loss: 0.0335 (0.0334)  time: 1.0432  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:4]  [ 110/1149]  eta: 0:18:25  lr: 0.000060  loss: 0.0324 (0.0331)  time: 1.0440  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:4]  [ 120/1149]  eta: 0:18:14  lr: 0.000060  loss: 0.0294 (0.0327)  time: 1.0528  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 130/1149]  eta: 0:18:02  lr: 0.000060  loss: 0.0288 (0.0325)  time: 1.0504  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 140/1149]  eta: 0:17:50  lr: 0.000060  loss: 0.0313 (0.0325)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 150/1149]  eta: 0:17:39  lr: 0.000060  loss: 0.0308 (0.0323)  time: 1.0495  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 160/1149]  eta: 0:17:27  lr: 0.000060  loss: 0.0302 (0.0323)  time: 1.0487  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:4]  [ 170/1149]  eta: 0:17:17  lr: 0.000060  loss: 0.0305 (0.0322)  time: 1.0537  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:4]  [ 180/1149]  eta: 0:17:05  lr: 0.000060  loss: 0.0303 (0.0322)  time: 1.0522  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 190/1149]  eta: 0:16:54  lr: 0.000060  loss: 0.0299 (0.0320)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 200/1149]  eta: 0:16:44  lr: 0.000060  loss: 0.0267 (0.0319)  time: 1.0516  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 210/1149]  eta: 0:16:32  lr: 0.000060  loss: 0.0268 (0.0317)  time: 1.0513  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 220/1149]  eta: 0:16:21  lr: 0.000060  loss: 0.0293 (0.0317)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 230/1149]  eta: 0:16:10  lr: 0.000060  loss: 0.0293 (0.0315)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 240/1149]  eta: 0:15:59  lr: 0.000060  loss: 0.0280 (0.0313)  time: 1.0478  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 250/1149]  eta: 0:15:49  lr: 0.000060  loss: 0.0241 (0.0311)  time: 1.0491  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 260/1149]  eta: 0:15:38  lr: 0.000060  loss: 0.0224 (0.0307)  time: 1.0479  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 270/1149]  eta: 0:15:27  lr: 0.000060  loss: 0.0216 (0.0304)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 280/1149]  eta: 0:15:16  lr: 0.000060  loss: 0.0223 (0.0302)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 290/1149]  eta: 0:15:05  lr: 0.000060  loss: 0.0236 (0.0300)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 300/1149]  eta: 0:14:54  lr: 0.000060  loss: 0.0233 (0.0298)  time: 1.0347  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 310/1149]  eta: 0:14:44  lr: 0.000060  loss: 0.0241 (0.0297)  time: 1.0507  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 320/1149]  eta: 0:14:33  lr: 0.000060  loss: 0.0257 (0.0295)  time: 1.0515  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [ 330/1149]  eta: 0:14:22  lr: 0.000060  loss: 0.0230 (0.0293)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 340/1149]  eta: 0:14:11  lr: 0.000060  loss: 0.0210 (0.0291)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 350/1149]  eta: 0:14:01  lr: 0.000060  loss: 0.0222 (0.0289)  time: 1.0486  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 360/1149]  eta: 0:13:50  lr: 0.000060  loss: 0.0223 (0.0287)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 370/1149]  eta: 0:13:39  lr: 0.000060  loss: 0.0196 (0.0284)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 380/1149]  eta: 0:13:29  lr: 0.000060  loss: 0.0206 (0.0283)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 390/1149]  eta: 0:13:18  lr: 0.000060  loss: 0.0210 (0.0281)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 400/1149]  eta: 0:13:07  lr: 0.000060  loss: 0.0199 (0.0279)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 410/1149]  eta: 0:12:57  lr: 0.000060  loss: 0.0213 (0.0278)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 420/1149]  eta: 0:12:46  lr: 0.000060  loss: 0.0223 (0.0276)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 430/1149]  eta: 0:12:36  lr: 0.000060  loss: 0.0200 (0.0274)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 440/1149]  eta: 0:12:25  lr: 0.000060  loss: 0.0214 (0.0273)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 450/1149]  eta: 0:12:14  lr: 0.000060  loss: 0.0225 (0.0272)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 460/1149]  eta: 0:12:04  lr: 0.000060  loss: 0.0218 (0.0271)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 470/1149]  eta: 0:11:53  lr: 0.000060  loss: 0.0211 (0.0269)  time: 1.0480  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 480/1149]  eta: 0:11:43  lr: 0.000060  loss: 0.0187 (0.0268)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 490/1149]  eta: 0:11:32  lr: 0.000060  loss: 0.0196 (0.0266)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 500/1149]  eta: 0:11:21  lr: 0.000060  loss: 0.0201 (0.0265)  time: 1.0484  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 510/1149]  eta: 0:11:11  lr: 0.000060  loss: 0.0195 (0.0263)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 520/1149]  eta: 0:11:00  lr: 0.000060  loss: 0.0175 (0.0262)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 530/1149]  eta: 0:10:50  lr: 0.000060  loss: 0.0183 (0.0261)  time: 1.0382  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 540/1149]  eta: 0:10:39  lr: 0.000060  loss: 0.0194 (0.0260)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 550/1149]  eta: 0:10:28  lr: 0.000060  loss: 0.0208 (0.0259)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 560/1149]  eta: 0:10:18  lr: 0.000060  loss: 0.0208 (0.0258)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 570/1149]  eta: 0:10:07  lr: 0.000060  loss: 0.0214 (0.0257)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 580/1149]  eta: 0:09:57  lr: 0.000060  loss: 0.0193 (0.0256)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 590/1149]  eta: 0:09:46  lr: 0.000060  loss: 0.0194 (0.0255)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 600/1149]  eta: 0:09:36  lr: 0.000060  loss: 0.0170 (0.0254)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 610/1149]  eta: 0:09:25  lr: 0.000060  loss: 0.0177 (0.0253)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 620/1149]  eta: 0:09:15  lr: 0.000060  loss: 0.0196 (0.0252)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 630/1149]  eta: 0:09:04  lr: 0.000060  loss: 0.0194 (0.0251)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 640/1149]  eta: 0:08:53  lr: 0.000060  loss: 0.0173 (0.0250)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 650/1149]  eta: 0:08:43  lr: 0.000060  loss: 0.0222 (0.0250)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 660/1149]  eta: 0:08:32  lr: 0.000060  loss: 0.0251 (0.0250)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 670/1149]  eta: 0:08:22  lr: 0.000060  loss: 0.0213 (0.0249)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 680/1149]  eta: 0:08:11  lr: 0.000060  loss: 0.0201 (0.0249)  time: 1.0473  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 690/1149]  eta: 0:08:01  lr: 0.000060  loss: 0.0187 (0.0248)  time: 1.0477  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 700/1149]  eta: 0:07:50  lr: 0.000060  loss: 0.0192 (0.0247)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 710/1149]  eta: 0:07:40  lr: 0.000060  loss: 0.0195 (0.0246)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 720/1149]  eta: 0:07:29  lr: 0.000060  loss: 0.0205 (0.0246)  time: 1.0373  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 730/1149]  eta: 0:07:19  lr: 0.000060  loss: 0.0207 (0.0246)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 740/1149]  eta: 0:07:08  lr: 0.000060  loss: 0.0201 (0.0245)  time: 1.0482  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 750/1149]  eta: 0:06:58  lr: 0.000060  loss: 0.0200 (0.0244)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 760/1149]  eta: 0:06:47  lr: 0.000060  loss: 0.0193 (0.0244)  time: 1.0308  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 770/1149]  eta: 0:06:37  lr: 0.000060  loss: 0.0181 (0.0243)  time: 1.0339  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 780/1149]  eta: 0:06:26  lr: 0.000060  loss: 0.0176 (0.0242)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 790/1149]  eta: 0:06:16  lr: 0.000060  loss: 0.0189 (0.0242)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 800/1149]  eta: 0:06:05  lr: 0.000060  loss: 0.0190 (0.0241)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 810/1149]  eta: 0:05:55  lr: 0.000060  loss: 0.0189 (0.0240)  time: 1.0386  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 820/1149]  eta: 0:05:44  lr: 0.000060  loss: 0.0175 (0.0240)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 830/1149]  eta: 0:05:34  lr: 0.000060  loss: 0.0192 (0.0239)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 840/1149]  eta: 0:05:23  lr: 0.000060  loss: 0.0192 (0.0238)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 850/1149]  eta: 0:05:13  lr: 0.000060  loss: 0.0186 (0.0238)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 860/1149]  eta: 0:05:02  lr: 0.000060  loss: 0.0211 (0.0238)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 870/1149]  eta: 0:04:52  lr: 0.000060  loss: 0.0192 (0.0237)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 880/1149]  eta: 0:04:41  lr: 0.000060  loss: 0.0165 (0.0236)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 890/1149]  eta: 0:04:31  lr: 0.000060  loss: 0.0175 (0.0236)  time: 1.0473  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 900/1149]  eta: 0:04:20  lr: 0.000060  loss: 0.0192 (0.0235)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 910/1149]  eta: 0:04:10  lr: 0.000060  loss: 0.0186 (0.0235)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 920/1149]  eta: 0:03:59  lr: 0.000060  loss: 0.0186 (0.0234)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 930/1149]  eta: 0:03:49  lr: 0.000060  loss: 0.0185 (0.0234)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 940/1149]  eta: 0:03:38  lr: 0.000060  loss: 0.0176 (0.0233)  time: 1.0369  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 950/1149]  eta: 0:03:28  lr: 0.000060  loss: 0.0174 (0.0233)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 960/1149]  eta: 0:03:17  lr: 0.000060  loss: 0.0163 (0.0232)  time: 1.0482  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 970/1149]  eta: 0:03:07  lr: 0.000060  loss: 0.0163 (0.0232)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [ 980/1149]  eta: 0:02:56  lr: 0.000060  loss: 0.0183 (0.0231)  time: 1.0506  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [ 990/1149]  eta: 0:02:46  lr: 0.000060  loss: 0.0166 (0.0230)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1000/1149]  eta: 0:02:35  lr: 0.000060  loss: 0.0178 (0.0230)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1010/1149]  eta: 0:02:25  lr: 0.000060  loss: 0.0178 (0.0229)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1020/1149]  eta: 0:02:15  lr: 0.000060  loss: 0.0188 (0.0229)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1030/1149]  eta: 0:02:04  lr: 0.000060  loss: 0.0191 (0.0229)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1040/1149]  eta: 0:01:54  lr: 0.000060  loss: 0.0163 (0.0228)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1050/1149]  eta: 0:01:43  lr: 0.000060  loss: 0.0170 (0.0228)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1060/1149]  eta: 0:01:33  lr: 0.000060  loss: 0.0170 (0.0228)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1070/1149]  eta: 0:01:22  lr: 0.000060  loss: 0.0170 (0.0227)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1080/1149]  eta: 0:01:12  lr: 0.000060  loss: 0.0173 (0.0227)  time: 1.0507  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1090/1149]  eta: 0:01:01  lr: 0.000060  loss: 0.0169 (0.0226)  time: 1.0507  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1100/1149]  eta: 0:00:51  lr: 0.000060  loss: 0.0185 (0.0226)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1110/1149]  eta: 0:00:40  lr: 0.000060  loss: 0.0191 (0.0226)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1120/1149]  eta: 0:00:30  lr: 0.000060  loss: 0.0186 (0.0225)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1130/1149]  eta: 0:00:19  lr: 0.000060  loss: 0.0175 (0.0225)  time: 1.0499  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1140/1149]  eta: 0:00:09  lr: 0.000060  loss: 0.0169 (0.0224)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4]  [1148/1149]  eta: 0:00:01  lr: 0.000060  loss: 0.0170 (0.0224)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:4] Total time: 0:20:02 (1.0470 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.0170 (0.0224)\n",
      "Valid: [epoch:4]  [ 0/14]  eta: 0:00:54  loss: 0.0161 (0.0161)  time: 3.8669  data: 0.7355  max mem: 35661\n",
      "Valid: [epoch:4]  [13/14]  eta: 0:00:03  loss: 0.0124 (0.0132)  time: 3.2172  data: 0.0526  max mem: 35661\n",
      "Valid: [epoch:4] Total time: 0:00:45 (3.2341 s / it)\n",
      "Averaged stats: loss: 0.0124 (0.0132)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_4_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.013%\n",
      "Min loss: 0.013\n",
      "Best Epoch: 4.000\n",
      "Train: [epoch:5]  [   0/1149]  eta: 0:42:16  lr: 0.000080  loss: 0.0155 (0.0155)  time: 2.2073  data: 1.1071  max mem: 35661\n",
      "Train: [epoch:5]  [  10/1149]  eta: 0:21:59  lr: 0.000080  loss: 0.0166 (0.0176)  time: 1.1588  data: 0.1008  max mem: 35661\n",
      "Train: [epoch:5]  [  20/1149]  eta: 0:20:52  lr: 0.000080  loss: 0.0177 (0.0176)  time: 1.0546  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [  30/1149]  eta: 0:20:17  lr: 0.000080  loss: 0.0177 (0.0179)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [  40/1149]  eta: 0:19:55  lr: 0.000080  loss: 0.0151 (0.0171)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [  50/1149]  eta: 0:19:37  lr: 0.000080  loss: 0.0147 (0.0170)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [  60/1149]  eta: 0:19:21  lr: 0.000080  loss: 0.0147 (0.0167)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [  70/1149]  eta: 0:19:08  lr: 0.000080  loss: 0.0147 (0.0166)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [  80/1149]  eta: 0:18:54  lr: 0.000080  loss: 0.0147 (0.0167)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [  90/1149]  eta: 0:18:42  lr: 0.000080  loss: 0.0172 (0.0169)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 100/1149]  eta: 0:18:30  lr: 0.000080  loss: 0.0181 (0.0170)  time: 1.0510  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 110/1149]  eta: 0:18:19  lr: 0.000080  loss: 0.0166 (0.0169)  time: 1.0507  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 120/1149]  eta: 0:18:08  lr: 0.000080  loss: 0.0150 (0.0169)  time: 1.0501  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 130/1149]  eta: 0:17:56  lr: 0.000080  loss: 0.0165 (0.0169)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 140/1149]  eta: 0:17:44  lr: 0.000080  loss: 0.0165 (0.0169)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 150/1149]  eta: 0:17:33  lr: 0.000080  loss: 0.0164 (0.0168)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 160/1149]  eta: 0:17:22  lr: 0.000080  loss: 0.0148 (0.0168)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 170/1149]  eta: 0:17:11  lr: 0.000080  loss: 0.0175 (0.0171)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 180/1149]  eta: 0:17:00  lr: 0.000080  loss: 0.0182 (0.0171)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 190/1149]  eta: 0:16:49  lr: 0.000080  loss: 0.0156 (0.0170)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 200/1149]  eta: 0:16:38  lr: 0.000080  loss: 0.0142 (0.0169)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 210/1149]  eta: 0:16:27  lr: 0.000080  loss: 0.0149 (0.0169)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 220/1149]  eta: 0:16:16  lr: 0.000080  loss: 0.0170 (0.0169)  time: 1.0504  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 230/1149]  eta: 0:16:06  lr: 0.000080  loss: 0.0170 (0.0169)  time: 1.0484  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 240/1149]  eta: 0:15:55  lr: 0.000080  loss: 0.0162 (0.0169)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 250/1149]  eta: 0:15:45  lr: 0.000080  loss: 0.0154 (0.0168)  time: 1.0497  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 260/1149]  eta: 0:15:34  lr: 0.000080  loss: 0.0154 (0.0168)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 270/1149]  eta: 0:15:23  lr: 0.000080  loss: 0.0154 (0.0168)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 280/1149]  eta: 0:15:12  lr: 0.000080  loss: 0.0148 (0.0167)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 290/1149]  eta: 0:15:02  lr: 0.000080  loss: 0.0148 (0.0167)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 300/1149]  eta: 0:14:51  lr: 0.000080  loss: 0.0166 (0.0167)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 310/1149]  eta: 0:14:40  lr: 0.000080  loss: 0.0172 (0.0168)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 320/1149]  eta: 0:14:30  lr: 0.000080  loss: 0.0161 (0.0167)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 330/1149]  eta: 0:14:19  lr: 0.000080  loss: 0.0147 (0.0167)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 340/1149]  eta: 0:14:08  lr: 0.000080  loss: 0.0148 (0.0166)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 350/1149]  eta: 0:13:58  lr: 0.000080  loss: 0.0148 (0.0166)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 360/1149]  eta: 0:13:47  lr: 0.000080  loss: 0.0134 (0.0165)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 370/1149]  eta: 0:13:37  lr: 0.000080  loss: 0.0143 (0.0165)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 380/1149]  eta: 0:13:26  lr: 0.000080  loss: 0.0170 (0.0165)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 390/1149]  eta: 0:13:16  lr: 0.000080  loss: 0.0160 (0.0165)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 400/1149]  eta: 0:13:05  lr: 0.000080  loss: 0.0153 (0.0164)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 410/1149]  eta: 0:12:55  lr: 0.000080  loss: 0.0151 (0.0164)  time: 1.0500  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 420/1149]  eta: 0:12:44  lr: 0.000080  loss: 0.0151 (0.0164)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 430/1149]  eta: 0:12:34  lr: 0.000080  loss: 0.0153 (0.0164)  time: 1.0415  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [ 440/1149]  eta: 0:12:23  lr: 0.000080  loss: 0.0145 (0.0163)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 450/1149]  eta: 0:12:12  lr: 0.000080  loss: 0.0131 (0.0163)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 460/1149]  eta: 0:12:02  lr: 0.000080  loss: 0.0155 (0.0163)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 470/1149]  eta: 0:11:51  lr: 0.000080  loss: 0.0156 (0.0163)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 480/1149]  eta: 0:11:41  lr: 0.000080  loss: 0.0141 (0.0162)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 490/1149]  eta: 0:11:30  lr: 0.000080  loss: 0.0135 (0.0162)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 500/1149]  eta: 0:11:20  lr: 0.000080  loss: 0.0135 (0.0161)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 510/1149]  eta: 0:11:09  lr: 0.000080  loss: 0.0134 (0.0161)  time: 1.0361  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 520/1149]  eta: 0:10:58  lr: 0.000080  loss: 0.0131 (0.0161)  time: 1.0351  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 530/1149]  eta: 0:10:48  lr: 0.000080  loss: 0.0131 (0.0160)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 540/1149]  eta: 0:10:37  lr: 0.000080  loss: 0.0132 (0.0160)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 550/1149]  eta: 0:10:27  lr: 0.000080  loss: 0.0135 (0.0159)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 560/1149]  eta: 0:10:16  lr: 0.000080  loss: 0.0137 (0.0159)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 570/1149]  eta: 0:10:06  lr: 0.000080  loss: 0.0150 (0.0159)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 580/1149]  eta: 0:09:55  lr: 0.000080  loss: 0.0136 (0.0159)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 590/1149]  eta: 0:09:45  lr: 0.000080  loss: 0.0129 (0.0158)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 600/1149]  eta: 0:09:34  lr: 0.000080  loss: 0.0123 (0.0158)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 610/1149]  eta: 0:09:24  lr: 0.000080  loss: 0.0129 (0.0157)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 620/1149]  eta: 0:09:13  lr: 0.000080  loss: 0.0134 (0.0157)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 630/1149]  eta: 0:09:03  lr: 0.000080  loss: 0.0144 (0.0157)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 640/1149]  eta: 0:08:52  lr: 0.000080  loss: 0.0137 (0.0157)  time: 1.0334  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 650/1149]  eta: 0:08:42  lr: 0.000080  loss: 0.0154 (0.0157)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 660/1149]  eta: 0:08:31  lr: 0.000080  loss: 0.0159 (0.0157)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 670/1149]  eta: 0:08:21  lr: 0.000080  loss: 0.0143 (0.0157)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 680/1149]  eta: 0:08:10  lr: 0.000080  loss: 0.0126 (0.0156)  time: 1.0465  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 690/1149]  eta: 0:08:00  lr: 0.000080  loss: 0.0120 (0.0156)  time: 1.0491  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 700/1149]  eta: 0:07:49  lr: 0.000080  loss: 0.0130 (0.0156)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 710/1149]  eta: 0:07:39  lr: 0.000080  loss: 0.0133 (0.0155)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 720/1149]  eta: 0:07:28  lr: 0.000080  loss: 0.0128 (0.0155)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 730/1149]  eta: 0:07:18  lr: 0.000080  loss: 0.0136 (0.0155)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 740/1149]  eta: 0:07:08  lr: 0.000080  loss: 0.0141 (0.0155)  time: 1.0503  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 750/1149]  eta: 0:06:57  lr: 0.000080  loss: 0.0126 (0.0154)  time: 1.0496  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 760/1149]  eta: 0:06:47  lr: 0.000080  loss: 0.0118 (0.0154)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 770/1149]  eta: 0:06:36  lr: 0.000080  loss: 0.0135 (0.0154)  time: 1.0310  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 780/1149]  eta: 0:06:26  lr: 0.000080  loss: 0.0132 (0.0153)  time: 1.0343  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 790/1149]  eta: 0:06:15  lr: 0.000080  loss: 0.0133 (0.0153)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 800/1149]  eta: 0:06:05  lr: 0.000080  loss: 0.0125 (0.0153)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 810/1149]  eta: 0:05:54  lr: 0.000080  loss: 0.0118 (0.0153)  time: 1.0465  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 820/1149]  eta: 0:05:44  lr: 0.000080  loss: 0.0139 (0.0153)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 830/1149]  eta: 0:05:33  lr: 0.000080  loss: 0.0146 (0.0152)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 840/1149]  eta: 0:05:23  lr: 0.000080  loss: 0.0115 (0.0152)  time: 1.0499  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 850/1149]  eta: 0:05:12  lr: 0.000080  loss: 0.0115 (0.0152)  time: 1.0528  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 860/1149]  eta: 0:05:02  lr: 0.000080  loss: 0.0126 (0.0151)  time: 1.0503  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 870/1149]  eta: 0:04:51  lr: 0.000080  loss: 0.0114 (0.0151)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 880/1149]  eta: 0:04:41  lr: 0.000080  loss: 0.0105 (0.0150)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 890/1149]  eta: 0:04:31  lr: 0.000080  loss: 0.0115 (0.0150)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 900/1149]  eta: 0:04:20  lr: 0.000080  loss: 0.0116 (0.0150)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 910/1149]  eta: 0:04:10  lr: 0.000080  loss: 0.0106 (0.0149)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 920/1149]  eta: 0:03:59  lr: 0.000080  loss: 0.0130 (0.0149)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 930/1149]  eta: 0:03:49  lr: 0.000080  loss: 0.0130 (0.0149)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 940/1149]  eta: 0:03:38  lr: 0.000080  loss: 0.0121 (0.0149)  time: 1.0480  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 950/1149]  eta: 0:03:28  lr: 0.000080  loss: 0.0110 (0.0148)  time: 1.0473  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 960/1149]  eta: 0:03:17  lr: 0.000080  loss: 0.0109 (0.0148)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 970/1149]  eta: 0:03:07  lr: 0.000080  loss: 0.0109 (0.0148)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 980/1149]  eta: 0:02:56  lr: 0.000080  loss: 0.0109 (0.0148)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [ 990/1149]  eta: 0:02:46  lr: 0.000080  loss: 0.0119 (0.0147)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1000/1149]  eta: 0:02:35  lr: 0.000080  loss: 0.0122 (0.0147)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1010/1149]  eta: 0:02:25  lr: 0.000080  loss: 0.0118 (0.0147)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1020/1149]  eta: 0:02:14  lr: 0.000080  loss: 0.0118 (0.0147)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1030/1149]  eta: 0:02:04  lr: 0.000080  loss: 0.0121 (0.0146)  time: 1.0480  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1040/1149]  eta: 0:01:54  lr: 0.000080  loss: 0.0111 (0.0146)  time: 1.0477  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1050/1149]  eta: 0:01:43  lr: 0.000080  loss: 0.0110 (0.0146)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1060/1149]  eta: 0:01:33  lr: 0.000080  loss: 0.0116 (0.0146)  time: 1.0465  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1070/1149]  eta: 0:01:22  lr: 0.000080  loss: 0.0116 (0.0145)  time: 1.0371  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1080/1149]  eta: 0:01:12  lr: 0.000080  loss: 0.0121 (0.0145)  time: 1.0373  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1090/1149]  eta: 0:01:01  lr: 0.000080  loss: 0.0123 (0.0145)  time: 1.0485  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [1100/1149]  eta: 0:00:51  lr: 0.000080  loss: 0.0114 (0.0145)  time: 1.0487  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1110/1149]  eta: 0:00:40  lr: 0.000080  loss: 0.0115 (0.0145)  time: 1.0500  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1120/1149]  eta: 0:00:30  lr: 0.000080  loss: 0.0122 (0.0145)  time: 1.0502  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1130/1149]  eta: 0:00:19  lr: 0.000080  loss: 0.0119 (0.0144)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1140/1149]  eta: 0:00:09  lr: 0.000080  loss: 0.0116 (0.0144)  time: 1.0488  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5]  [1148/1149]  eta: 0:00:01  lr: 0.000080  loss: 0.0114 (0.0144)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:5] Total time: 0:20:02 (1.0465 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.0114 (0.0144)\n",
      "Valid: [epoch:5]  [ 0/14]  eta: 0:00:56  loss: 0.0061 (0.0061)  time: 4.0069  data: 0.7960  max mem: 35661\n",
      "Valid: [epoch:5]  [13/14]  eta: 0:00:03  loss: 0.0085 (0.0092)  time: 3.2824  data: 0.0570  max mem: 35661\n",
      "Valid: [epoch:5] Total time: 0:00:46 (3.2985 s / it)\n",
      "Averaged stats: loss: 0.0085 (0.0092)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_5_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.009%\n",
      "Min loss: 0.009\n",
      "Best Epoch: 5.000\n",
      "Train: [epoch:6]  [   0/1149]  eta: 0:42:28  lr: 0.000100  loss: 0.0138 (0.0138)  time: 2.2179  data: 1.1256  max mem: 35661\n",
      "Train: [epoch:6]  [  10/1149]  eta: 0:22:03  lr: 0.000100  loss: 0.0102 (0.0109)  time: 1.1623  data: 0.1025  max mem: 35661\n",
      "Train: [epoch:6]  [  20/1149]  eta: 0:20:47  lr: 0.000100  loss: 0.0102 (0.0114)  time: 1.0489  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [  30/1149]  eta: 0:20:16  lr: 0.000100  loss: 0.0103 (0.0112)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [  40/1149]  eta: 0:19:54  lr: 0.000100  loss: 0.0107 (0.0113)  time: 1.0483  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [  50/1149]  eta: 0:19:36  lr: 0.000100  loss: 0.0119 (0.0116)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [  60/1149]  eta: 0:19:21  lr: 0.000100  loss: 0.0110 (0.0115)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [  70/1149]  eta: 0:19:07  lr: 0.000100  loss: 0.0110 (0.0114)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [  80/1149]  eta: 0:18:55  lr: 0.000100  loss: 0.0111 (0.0114)  time: 1.0507  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [  90/1149]  eta: 0:18:42  lr: 0.000100  loss: 0.0115 (0.0118)  time: 1.0478  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 100/1149]  eta: 0:18:30  lr: 0.000100  loss: 0.0124 (0.0118)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 110/1149]  eta: 0:18:19  lr: 0.000100  loss: 0.0120 (0.0119)  time: 1.0478  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 120/1149]  eta: 0:18:07  lr: 0.000100  loss: 0.0114 (0.0119)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 130/1149]  eta: 0:17:56  lr: 0.000100  loss: 0.0108 (0.0119)  time: 1.0483  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 140/1149]  eta: 0:17:45  lr: 0.000100  loss: 0.0117 (0.0119)  time: 1.0511  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 150/1149]  eta: 0:17:33  lr: 0.000100  loss: 0.0114 (0.0118)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 160/1149]  eta: 0:17:22  lr: 0.000100  loss: 0.0112 (0.0118)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 170/1149]  eta: 0:17:11  lr: 0.000100  loss: 0.0121 (0.0119)  time: 1.0481  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 180/1149]  eta: 0:17:00  lr: 0.000100  loss: 0.0118 (0.0119)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 190/1149]  eta: 0:16:49  lr: 0.000100  loss: 0.0110 (0.0118)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 200/1149]  eta: 0:16:39  lr: 0.000100  loss: 0.0097 (0.0117)  time: 1.0487  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 210/1149]  eta: 0:16:28  lr: 0.000100  loss: 0.0111 (0.0118)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 220/1149]  eta: 0:16:17  lr: 0.000100  loss: 0.0119 (0.0118)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 230/1149]  eta: 0:16:06  lr: 0.000100  loss: 0.0122 (0.0118)  time: 1.0502  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 240/1149]  eta: 0:15:56  lr: 0.000100  loss: 0.0122 (0.0118)  time: 1.0485  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 250/1149]  eta: 0:15:45  lr: 0.000100  loss: 0.0120 (0.0119)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 260/1149]  eta: 0:15:34  lr: 0.000100  loss: 0.0110 (0.0118)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 270/1149]  eta: 0:15:23  lr: 0.000100  loss: 0.0108 (0.0118)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 280/1149]  eta: 0:15:12  lr: 0.000100  loss: 0.0109 (0.0118)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 290/1149]  eta: 0:15:02  lr: 0.000100  loss: 0.0104 (0.0118)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 300/1149]  eta: 0:14:52  lr: 0.000100  loss: 0.0104 (0.0118)  time: 1.0519  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 310/1149]  eta: 0:14:41  lr: 0.000100  loss: 0.0113 (0.0118)  time: 1.0514  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 320/1149]  eta: 0:14:30  lr: 0.000100  loss: 0.0119 (0.0118)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 330/1149]  eta: 0:14:20  lr: 0.000100  loss: 0.0103 (0.0117)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 340/1149]  eta: 0:14:09  lr: 0.000100  loss: 0.0102 (0.0117)  time: 1.0466  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 350/1149]  eta: 0:13:58  lr: 0.000100  loss: 0.0111 (0.0117)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 360/1149]  eta: 0:13:48  lr: 0.000100  loss: 0.0122 (0.0117)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 370/1149]  eta: 0:13:37  lr: 0.000100  loss: 0.0106 (0.0116)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 380/1149]  eta: 0:13:26  lr: 0.000100  loss: 0.0107 (0.0117)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 390/1149]  eta: 0:13:16  lr: 0.000100  loss: 0.0125 (0.0117)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 400/1149]  eta: 0:13:05  lr: 0.000100  loss: 0.0122 (0.0117)  time: 1.0484  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 410/1149]  eta: 0:12:55  lr: 0.000100  loss: 0.0102 (0.0117)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 420/1149]  eta: 0:12:44  lr: 0.000100  loss: 0.0100 (0.0117)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 430/1149]  eta: 0:12:34  lr: 0.000100  loss: 0.0094 (0.0116)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 440/1149]  eta: 0:12:23  lr: 0.000100  loss: 0.0095 (0.0116)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 450/1149]  eta: 0:12:12  lr: 0.000100  loss: 0.0095 (0.0116)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 460/1149]  eta: 0:12:02  lr: 0.000100  loss: 0.0104 (0.0116)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 470/1149]  eta: 0:11:51  lr: 0.000100  loss: 0.0116 (0.0116)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 480/1149]  eta: 0:11:41  lr: 0.000100  loss: 0.0116 (0.0116)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 490/1149]  eta: 0:11:30  lr: 0.000100  loss: 0.0105 (0.0116)  time: 1.0494  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 500/1149]  eta: 0:11:20  lr: 0.000100  loss: 0.0102 (0.0115)  time: 1.0517  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 510/1149]  eta: 0:11:09  lr: 0.000100  loss: 0.0101 (0.0115)  time: 1.0478  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 520/1149]  eta: 0:10:59  lr: 0.000100  loss: 0.0104 (0.0115)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 530/1149]  eta: 0:10:48  lr: 0.000100  loss: 0.0103 (0.0115)  time: 1.0482  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:6]  [ 540/1149]  eta: 0:10:38  lr: 0.000100  loss: 0.0081 (0.0114)  time: 1.0443  data: 0.0003  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [ 550/1149]  eta: 0:10:27  lr: 0.000100  loss: 0.0074 (0.0113)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 560/1149]  eta: 0:10:17  lr: 0.000100  loss: 0.0073 (0.0113)  time: 1.0511  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 570/1149]  eta: 0:10:06  lr: 0.000100  loss: 0.0076 (0.0112)  time: 1.0499  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 580/1149]  eta: 0:09:56  lr: 0.000100  loss: 0.0076 (0.0111)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 590/1149]  eta: 0:09:45  lr: 0.000100  loss: 0.0058 (0.0110)  time: 1.0361  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 600/1149]  eta: 0:09:35  lr: 0.000100  loss: 0.0045 (0.0109)  time: 1.0358  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 610/1149]  eta: 0:09:24  lr: 0.000100  loss: 0.0046 (0.0108)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 620/1149]  eta: 0:09:14  lr: 0.000100  loss: 0.0043 (0.0107)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 630/1149]  eta: 0:09:03  lr: 0.000100  loss: 0.0046 (0.0106)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 640/1149]  eta: 0:08:53  lr: 0.000100  loss: 0.0055 (0.0106)  time: 1.0484  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 650/1149]  eta: 0:08:42  lr: 0.000100  loss: 0.0056 (0.0105)  time: 1.0482  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 660/1149]  eta: 0:08:32  lr: 0.000100  loss: 0.0046 (0.0104)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 670/1149]  eta: 0:08:21  lr: 0.000100  loss: 0.0058 (0.0104)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 680/1149]  eta: 0:08:11  lr: 0.000100  loss: 0.0051 (0.0103)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 690/1149]  eta: 0:08:00  lr: 0.000100  loss: 0.0040 (0.0102)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 700/1149]  eta: 0:07:50  lr: 0.000100  loss: 0.0035 (0.0101)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 710/1149]  eta: 0:07:39  lr: 0.000100  loss: 0.0035 (0.0100)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 720/1149]  eta: 0:07:29  lr: 0.000100  loss: 0.0029 (0.0099)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 730/1149]  eta: 0:07:18  lr: 0.000100  loss: 0.0028 (0.0098)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 740/1149]  eta: 0:07:08  lr: 0.000100  loss: 0.0048 (0.0098)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 750/1149]  eta: 0:06:57  lr: 0.000100  loss: 0.0050 (0.0097)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 760/1149]  eta: 0:06:47  lr: 0.000100  loss: 0.0076 (0.0097)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 770/1149]  eta: 0:06:36  lr: 0.000100  loss: 0.0060 (0.0096)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 780/1149]  eta: 0:06:26  lr: 0.000100  loss: 0.0046 (0.0096)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 790/1149]  eta: 0:06:15  lr: 0.000100  loss: 0.0046 (0.0095)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 800/1149]  eta: 0:06:05  lr: 0.000100  loss: 0.0042 (0.0094)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 810/1149]  eta: 0:05:54  lr: 0.000100  loss: 0.0045 (0.0094)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 820/1149]  eta: 0:05:44  lr: 0.000100  loss: 0.0039 (0.0093)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 830/1149]  eta: 0:05:33  lr: 0.000100  loss: 0.0034 (0.0093)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 840/1149]  eta: 0:05:23  lr: 0.000100  loss: 0.0030 (0.0092)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 850/1149]  eta: 0:05:13  lr: 0.000100  loss: 0.0027 (0.0091)  time: 1.0495  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 860/1149]  eta: 0:05:02  lr: 0.000100  loss: 0.0032 (0.0090)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 870/1149]  eta: 0:04:52  lr: 0.000100  loss: 0.0036 (0.0090)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 880/1149]  eta: 0:04:41  lr: 0.000100  loss: 0.0033 (0.0089)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 890/1149]  eta: 0:04:31  lr: 0.000100  loss: 0.0034 (0.0089)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 900/1149]  eta: 0:04:20  lr: 0.000100  loss: 0.0038 (0.0088)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 910/1149]  eta: 0:04:10  lr: 0.000100  loss: 0.0036 (0.0088)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 920/1149]  eta: 0:03:59  lr: 0.000100  loss: 0.0036 (0.0087)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 930/1149]  eta: 0:03:49  lr: 0.000100  loss: 0.0031 (0.0086)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 940/1149]  eta: 0:03:38  lr: 0.000100  loss: 0.0027 (0.0086)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 950/1149]  eta: 0:03:28  lr: 0.000100  loss: 0.0029 (0.0085)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 960/1149]  eta: 0:03:17  lr: 0.000100  loss: 0.0026 (0.0085)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 970/1149]  eta: 0:03:07  lr: 0.000100  loss: 0.0025 (0.0084)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 980/1149]  eta: 0:02:56  lr: 0.000100  loss: 0.0023 (0.0084)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [ 990/1149]  eta: 0:02:46  lr: 0.000100  loss: 0.0020 (0.0083)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1000/1149]  eta: 0:02:35  lr: 0.000100  loss: 0.0025 (0.0082)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1010/1149]  eta: 0:02:25  lr: 0.000100  loss: 0.0025 (0.0082)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1020/1149]  eta: 0:02:14  lr: 0.000100  loss: 0.0022 (0.0081)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1030/1149]  eta: 0:02:04  lr: 0.000100  loss: 0.0028 (0.0081)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1040/1149]  eta: 0:01:54  lr: 0.000100  loss: 0.0033 (0.0080)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1050/1149]  eta: 0:01:43  lr: 0.000100  loss: 0.0032 (0.0080)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1060/1149]  eta: 0:01:33  lr: 0.000100  loss: 0.0031 (0.0080)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1070/1149]  eta: 0:01:22  lr: 0.000100  loss: 0.0030 (0.0079)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1080/1149]  eta: 0:01:12  lr: 0.000100  loss: 0.0031 (0.0079)  time: 1.0513  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1090/1149]  eta: 0:01:01  lr: 0.000100  loss: 0.0032 (0.0078)  time: 1.0493  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1100/1149]  eta: 0:00:51  lr: 0.000100  loss: 0.0031 (0.0078)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1110/1149]  eta: 0:00:40  lr: 0.000100  loss: 0.0034 (0.0078)  time: 1.0381  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1120/1149]  eta: 0:00:30  lr: 0.000100  loss: 0.0053 (0.0078)  time: 1.0351  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1130/1149]  eta: 0:00:19  lr: 0.000100  loss: 0.0043 (0.0077)  time: 1.0358  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1140/1149]  eta: 0:00:09  lr: 0.000100  loss: 0.0033 (0.0077)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6]  [1148/1149]  eta: 0:00:01  lr: 0.000100  loss: 0.0030 (0.0076)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:6] Total time: 0:20:02 (1.0463 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0030 (0.0076)\n",
      "Valid: [epoch:6]  [ 0/14]  eta: 0:00:53  loss: 0.0035 (0.0035)  time: 3.8500  data: 0.5723  max mem: 35661\n",
      "Valid: [epoch:6]  [13/14]  eta: 0:00:03  loss: 0.0030 (0.0034)  time: 3.2135  data: 0.0410  max mem: 35661\n",
      "Valid: [epoch:6] Total time: 0:00:45 (3.2270 s / it)\n",
      "Averaged stats: loss: 0.0030 (0.0034)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_6_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.003%\n",
      "Min loss: 0.003\n",
      "Best Epoch: 6.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [   0/1149]  eta: 0:56:05  lr: 0.000120  loss: 0.0041 (0.0041)  time: 2.9287  data: 1.8476  max mem: 35661\n",
      "Train: [epoch:7]  [  10/1149]  eta: 0:23:07  lr: 0.000120  loss: 0.0027 (0.0028)  time: 1.2179  data: 0.1681  max mem: 35661\n",
      "Train: [epoch:7]  [  20/1149]  eta: 0:21:21  lr: 0.000120  loss: 0.0027 (0.0030)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [  30/1149]  eta: 0:20:38  lr: 0.000120  loss: 0.0025 (0.0028)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [  40/1149]  eta: 0:20:08  lr: 0.000120  loss: 0.0025 (0.0028)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [  50/1149]  eta: 0:19:46  lr: 0.000120  loss: 0.0021 (0.0027)  time: 1.0380  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [  60/1149]  eta: 0:19:27  lr: 0.000120  loss: 0.0022 (0.0027)  time: 1.0367  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [  70/1149]  eta: 0:19:13  lr: 0.000120  loss: 0.0024 (0.0027)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [  80/1149]  eta: 0:19:00  lr: 0.000120  loss: 0.0026 (0.0029)  time: 1.0516  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [  90/1149]  eta: 0:18:47  lr: 0.000120  loss: 0.0032 (0.0031)  time: 1.0497  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 100/1149]  eta: 0:18:34  lr: 0.000120  loss: 0.0041 (0.0032)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 110/1149]  eta: 0:18:23  lr: 0.000120  loss: 0.0041 (0.0033)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 120/1149]  eta: 0:18:11  lr: 0.000120  loss: 0.0035 (0.0033)  time: 1.0514  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 130/1149]  eta: 0:17:59  lr: 0.000120  loss: 0.0035 (0.0033)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 140/1149]  eta: 0:17:48  lr: 0.000120  loss: 0.0035 (0.0034)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 150/1149]  eta: 0:17:36  lr: 0.000120  loss: 0.0026 (0.0033)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 160/1149]  eta: 0:17:25  lr: 0.000120  loss: 0.0024 (0.0033)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 170/1149]  eta: 0:17:14  lr: 0.000120  loss: 0.0032 (0.0033)  time: 1.0486  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 180/1149]  eta: 0:17:03  lr: 0.000120  loss: 0.0032 (0.0033)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 190/1149]  eta: 0:16:52  lr: 0.000120  loss: 0.0021 (0.0033)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 200/1149]  eta: 0:16:41  lr: 0.000120  loss: 0.0021 (0.0032)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 210/1149]  eta: 0:16:30  lr: 0.000120  loss: 0.0019 (0.0032)  time: 1.0521  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 220/1149]  eta: 0:16:19  lr: 0.000120  loss: 0.0020 (0.0032)  time: 1.0511  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 230/1149]  eta: 0:16:08  lr: 0.000120  loss: 0.0024 (0.0031)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 240/1149]  eta: 0:15:57  lr: 0.000120  loss: 0.0025 (0.0031)  time: 1.0450  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:7]  [ 250/1149]  eta: 0:15:46  lr: 0.000120  loss: 0.0020 (0.0031)  time: 1.0364  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:7]  [ 260/1149]  eta: 0:15:35  lr: 0.000120  loss: 0.0020 (0.0031)  time: 1.0353  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 270/1149]  eta: 0:15:25  lr: 0.000120  loss: 0.0021 (0.0030)  time: 1.0509  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:7]  [ 280/1149]  eta: 0:15:14  lr: 0.000120  loss: 0.0019 (0.0030)  time: 1.0546  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 290/1149]  eta: 0:15:04  lr: 0.000120  loss: 0.0023 (0.0030)  time: 1.0514  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 300/1149]  eta: 0:14:53  lr: 0.000120  loss: 0.0020 (0.0030)  time: 1.0473  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 310/1149]  eta: 0:14:42  lr: 0.000120  loss: 0.0022 (0.0030)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 320/1149]  eta: 0:14:32  lr: 0.000120  loss: 0.0028 (0.0030)  time: 1.0485  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 330/1149]  eta: 0:14:21  lr: 0.000120  loss: 0.0031 (0.0030)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 340/1149]  eta: 0:14:10  lr: 0.000120  loss: 0.0027 (0.0030)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 350/1149]  eta: 0:14:00  lr: 0.000120  loss: 0.0030 (0.0030)  time: 1.0479  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 360/1149]  eta: 0:13:49  lr: 0.000120  loss: 0.0035 (0.0030)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 370/1149]  eta: 0:13:39  lr: 0.000120  loss: 0.0035 (0.0030)  time: 1.0545  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:7]  [ 380/1149]  eta: 0:13:28  lr: 0.000120  loss: 0.0029 (0.0030)  time: 1.0518  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:7]  [ 390/1149]  eta: 0:13:18  lr: 0.000120  loss: 0.0018 (0.0030)  time: 1.0499  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 400/1149]  eta: 0:13:07  lr: 0.000120  loss: 0.0018 (0.0030)  time: 1.0536  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 410/1149]  eta: 0:12:56  lr: 0.000120  loss: 0.0022 (0.0030)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 420/1149]  eta: 0:12:46  lr: 0.000120  loss: 0.0018 (0.0029)  time: 1.0481  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 430/1149]  eta: 0:12:35  lr: 0.000120  loss: 0.0018 (0.0029)  time: 1.0515  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 440/1149]  eta: 0:12:25  lr: 0.000120  loss: 0.0020 (0.0029)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 450/1149]  eta: 0:12:14  lr: 0.000120  loss: 0.0019 (0.0029)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 460/1149]  eta: 0:12:03  lr: 0.000120  loss: 0.0022 (0.0029)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 470/1149]  eta: 0:11:53  lr: 0.000120  loss: 0.0022 (0.0029)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 480/1149]  eta: 0:11:42  lr: 0.000120  loss: 0.0018 (0.0029)  time: 1.0494  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 490/1149]  eta: 0:11:32  lr: 0.000120  loss: 0.0016 (0.0028)  time: 1.0477  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 500/1149]  eta: 0:11:21  lr: 0.000120  loss: 0.0019 (0.0028)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 510/1149]  eta: 0:11:11  lr: 0.000120  loss: 0.0019 (0.0028)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 520/1149]  eta: 0:11:00  lr: 0.000120  loss: 0.0016 (0.0028)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 530/1149]  eta: 0:10:49  lr: 0.000120  loss: 0.0016 (0.0028)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 540/1149]  eta: 0:10:39  lr: 0.000120  loss: 0.0018 (0.0028)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 550/1149]  eta: 0:10:28  lr: 0.000120  loss: 0.0019 (0.0028)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 560/1149]  eta: 0:10:18  lr: 0.000120  loss: 0.0018 (0.0027)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 570/1149]  eta: 0:10:07  lr: 0.000120  loss: 0.0018 (0.0027)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 580/1149]  eta: 0:09:57  lr: 0.000120  loss: 0.0021 (0.0027)  time: 1.0486  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 590/1149]  eta: 0:09:46  lr: 0.000120  loss: 0.0018 (0.0027)  time: 1.0518  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 600/1149]  eta: 0:09:36  lr: 0.000120  loss: 0.0014 (0.0027)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 610/1149]  eta: 0:09:25  lr: 0.000120  loss: 0.0015 (0.0027)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 620/1149]  eta: 0:09:15  lr: 0.000120  loss: 0.0015 (0.0027)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 630/1149]  eta: 0:09:04  lr: 0.000120  loss: 0.0015 (0.0026)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 640/1149]  eta: 0:08:53  lr: 0.000120  loss: 0.0014 (0.0026)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 650/1149]  eta: 0:08:43  lr: 0.000120  loss: 0.0016 (0.0026)  time: 1.0429  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [ 660/1149]  eta: 0:08:32  lr: 0.000120  loss: 0.0020 (0.0026)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 670/1149]  eta: 0:08:22  lr: 0.000120  loss: 0.0020 (0.0026)  time: 1.0499  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 680/1149]  eta: 0:08:11  lr: 0.000120  loss: 0.0018 (0.0026)  time: 1.0529  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 690/1149]  eta: 0:08:01  lr: 0.000120  loss: 0.0015 (0.0026)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 700/1149]  eta: 0:07:50  lr: 0.000120  loss: 0.0014 (0.0026)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 710/1149]  eta: 0:07:40  lr: 0.000120  loss: 0.0015 (0.0026)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 720/1149]  eta: 0:07:29  lr: 0.000120  loss: 0.0015 (0.0026)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 730/1149]  eta: 0:07:19  lr: 0.000120  loss: 0.0013 (0.0025)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 740/1149]  eta: 0:07:08  lr: 0.000120  loss: 0.0013 (0.0025)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 750/1149]  eta: 0:06:58  lr: 0.000120  loss: 0.0014 (0.0025)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 760/1149]  eta: 0:06:47  lr: 0.000120  loss: 0.0014 (0.0025)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 770/1149]  eta: 0:06:37  lr: 0.000120  loss: 0.0014 (0.0025)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 780/1149]  eta: 0:06:26  lr: 0.000120  loss: 0.0015 (0.0025)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 790/1149]  eta: 0:06:16  lr: 0.000120  loss: 0.0014 (0.0025)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 800/1149]  eta: 0:06:05  lr: 0.000120  loss: 0.0017 (0.0025)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 810/1149]  eta: 0:05:55  lr: 0.000120  loss: 0.0018 (0.0025)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 820/1149]  eta: 0:05:44  lr: 0.000120  loss: 0.0014 (0.0024)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 830/1149]  eta: 0:05:34  lr: 0.000120  loss: 0.0016 (0.0024)  time: 1.0465  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 840/1149]  eta: 0:05:23  lr: 0.000120  loss: 0.0018 (0.0024)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 850/1149]  eta: 0:05:13  lr: 0.000120  loss: 0.0020 (0.0024)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 860/1149]  eta: 0:05:02  lr: 0.000120  loss: 0.0028 (0.0025)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 870/1149]  eta: 0:04:52  lr: 0.000120  loss: 0.0031 (0.0025)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 880/1149]  eta: 0:04:41  lr: 0.000120  loss: 0.0020 (0.0025)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 890/1149]  eta: 0:04:31  lr: 0.000120  loss: 0.0017 (0.0025)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 900/1149]  eta: 0:04:20  lr: 0.000120  loss: 0.0013 (0.0024)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 910/1149]  eta: 0:04:10  lr: 0.000120  loss: 0.0014 (0.0024)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 920/1149]  eta: 0:03:59  lr: 0.000120  loss: 0.0016 (0.0024)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 930/1149]  eta: 0:03:49  lr: 0.000120  loss: 0.0015 (0.0024)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 940/1149]  eta: 0:03:38  lr: 0.000120  loss: 0.0014 (0.0024)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 950/1149]  eta: 0:03:28  lr: 0.000120  loss: 0.0012 (0.0024)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 960/1149]  eta: 0:03:18  lr: 0.000120  loss: 0.0011 (0.0024)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 970/1149]  eta: 0:03:07  lr: 0.000120  loss: 0.0012 (0.0024)  time: 1.0485  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 980/1149]  eta: 0:02:57  lr: 0.000120  loss: 0.0011 (0.0024)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [ 990/1149]  eta: 0:02:46  lr: 0.000120  loss: 0.0009 (0.0024)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1000/1149]  eta: 0:02:36  lr: 0.000120  loss: 0.0011 (0.0024)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1010/1149]  eta: 0:02:25  lr: 0.000120  loss: 0.0012 (0.0023)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1020/1149]  eta: 0:02:15  lr: 0.000120  loss: 0.0011 (0.0023)  time: 1.0508  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1030/1149]  eta: 0:02:04  lr: 0.000120  loss: 0.0012 (0.0023)  time: 1.0584  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1040/1149]  eta: 0:01:54  lr: 0.000120  loss: 0.0012 (0.0023)  time: 1.0582  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1050/1149]  eta: 0:01:43  lr: 0.000120  loss: 0.0011 (0.0023)  time: 1.0496  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1060/1149]  eta: 0:01:33  lr: 0.000120  loss: 0.0011 (0.0023)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1070/1149]  eta: 0:01:22  lr: 0.000120  loss: 0.0011 (0.0023)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1080/1149]  eta: 0:01:12  lr: 0.000120  loss: 0.0011 (0.0023)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1090/1149]  eta: 0:01:01  lr: 0.000120  loss: 0.0012 (0.0023)  time: 1.0483  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1100/1149]  eta: 0:00:51  lr: 0.000120  loss: 0.0014 (0.0023)  time: 1.0488  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1110/1149]  eta: 0:00:40  lr: 0.000120  loss: 0.0014 (0.0023)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1120/1149]  eta: 0:00:30  lr: 0.000120  loss: 0.0012 (0.0023)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1130/1149]  eta: 0:00:19  lr: 0.000120  loss: 0.0011 (0.0023)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1140/1149]  eta: 0:00:09  lr: 0.000120  loss: 0.0012 (0.0023)  time: 1.0523  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7]  [1148/1149]  eta: 0:00:01  lr: 0.000120  loss: 0.0012 (0.0022)  time: 1.0533  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:7] Total time: 0:20:04 (1.0479 s / it)\n",
      "Averaged stats: lr: 0.000120  loss: 0.0012 (0.0022)\n",
      "Valid: [epoch:7]  [ 0/14]  eta: 0:00:57  loss: 0.0007 (0.0007)  time: 4.1246  data: 0.8733  max mem: 35661\n",
      "Valid: [epoch:7]  [13/14]  eta: 0:00:03  loss: 0.0008 (0.0010)  time: 3.2130  data: 0.0625  max mem: 35661\n",
      "Valid: [epoch:7] Total time: 0:00:45 (3.2287 s / it)\n",
      "Averaged stats: loss: 0.0008 (0.0010)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_7_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.001%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 7.000\n",
      "Train: [epoch:8]  [   0/1149]  eta: 0:50:47  lr: 0.000140  loss: 0.0010 (0.0010)  time: 2.6524  data: 1.5569  max mem: 35661\n",
      "Train: [epoch:8]  [  10/1149]  eta: 0:22:33  lr: 0.000140  loss: 0.0012 (0.0014)  time: 1.1886  data: 0.1417  max mem: 35661\n",
      "Train: [epoch:8]  [  20/1149]  eta: 0:21:05  lr: 0.000140  loss: 0.0012 (0.0013)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [  30/1149]  eta: 0:20:23  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [  40/1149]  eta: 0:20:01  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [  50/1149]  eta: 0:19:39  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [  60/1149]  eta: 0:19:24  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [  70/1149]  eta: 0:19:10  lr: 0.000140  loss: 0.0011 (0.0012)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [  80/1149]  eta: 0:18:57  lr: 0.000140  loss: 0.0010 (0.0012)  time: 1.0481  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [  90/1149]  eta: 0:18:45  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0497  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 100/1149]  eta: 0:18:33  lr: 0.000140  loss: 0.0014 (0.0014)  time: 1.0509  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [ 110/1149]  eta: 0:18:20  lr: 0.000140  loss: 0.0014 (0.0014)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 120/1149]  eta: 0:18:08  lr: 0.000140  loss: 0.0014 (0.0014)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 130/1149]  eta: 0:17:56  lr: 0.000140  loss: 0.0013 (0.0014)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 140/1149]  eta: 0:17:44  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 150/1149]  eta: 0:17:33  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 160/1149]  eta: 0:17:22  lr: 0.000140  loss: 0.0013 (0.0014)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 170/1149]  eta: 0:17:11  lr: 0.000140  loss: 0.0013 (0.0015)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 180/1149]  eta: 0:17:00  lr: 0.000140  loss: 0.0012 (0.0015)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 190/1149]  eta: 0:16:49  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 200/1149]  eta: 0:16:38  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 210/1149]  eta: 0:16:27  lr: 0.000140  loss: 0.0010 (0.0014)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 220/1149]  eta: 0:16:16  lr: 0.000140  loss: 0.0010 (0.0014)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 230/1149]  eta: 0:16:05  lr: 0.000140  loss: 0.0012 (0.0014)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 240/1149]  eta: 0:15:55  lr: 0.000140  loss: 0.0012 (0.0014)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 250/1149]  eta: 0:15:44  lr: 0.000140  loss: 0.0010 (0.0014)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 260/1149]  eta: 0:15:33  lr: 0.000140  loss: 0.0008 (0.0014)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 270/1149]  eta: 0:15:22  lr: 0.000140  loss: 0.0010 (0.0014)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 280/1149]  eta: 0:15:11  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 290/1149]  eta: 0:15:01  lr: 0.000140  loss: 0.0009 (0.0014)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 300/1149]  eta: 0:14:50  lr: 0.000140  loss: 0.0010 (0.0014)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 310/1149]  eta: 0:14:40  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 320/1149]  eta: 0:14:29  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 330/1149]  eta: 0:14:19  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 340/1149]  eta: 0:14:08  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 350/1149]  eta: 0:13:57  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 360/1149]  eta: 0:13:47  lr: 0.000140  loss: 0.0009 (0.0014)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 370/1149]  eta: 0:13:36  lr: 0.000140  loss: 0.0009 (0.0014)  time: 1.0482  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 380/1149]  eta: 0:13:26  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0516  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 390/1149]  eta: 0:13:15  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 400/1149]  eta: 0:13:05  lr: 0.000140  loss: 0.0010 (0.0014)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 410/1149]  eta: 0:12:54  lr: 0.000140  loss: 0.0009 (0.0014)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 420/1149]  eta: 0:12:44  lr: 0.000140  loss: 0.0009 (0.0014)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 430/1149]  eta: 0:12:33  lr: 0.000140  loss: 0.0010 (0.0014)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 440/1149]  eta: 0:12:22  lr: 0.000140  loss: 0.0010 (0.0014)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 450/1149]  eta: 0:12:12  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 460/1149]  eta: 0:12:01  lr: 0.000140  loss: 0.0012 (0.0014)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 470/1149]  eta: 0:11:51  lr: 0.000140  loss: 0.0011 (0.0014)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 480/1149]  eta: 0:11:40  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 490/1149]  eta: 0:11:30  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 500/1149]  eta: 0:11:19  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 510/1149]  eta: 0:11:09  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 520/1149]  eta: 0:10:58  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 530/1149]  eta: 0:10:48  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 540/1149]  eta: 0:10:37  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 550/1149]  eta: 0:10:27  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 560/1149]  eta: 0:10:16  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0366  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 570/1149]  eta: 0:10:06  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 580/1149]  eta: 0:09:55  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 590/1149]  eta: 0:09:45  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 600/1149]  eta: 0:09:34  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 610/1149]  eta: 0:09:24  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 620/1149]  eta: 0:09:13  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 630/1149]  eta: 0:09:03  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 640/1149]  eta: 0:08:52  lr: 0.000140  loss: 0.0008 (0.0013)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 650/1149]  eta: 0:08:42  lr: 0.000140  loss: 0.0008 (0.0013)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 660/1149]  eta: 0:08:31  lr: 0.000140  loss: 0.0013 (0.0013)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 670/1149]  eta: 0:08:21  lr: 0.000140  loss: 0.0015 (0.0013)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 680/1149]  eta: 0:08:10  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0489  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 690/1149]  eta: 0:08:00  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0465  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 700/1149]  eta: 0:07:49  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 710/1149]  eta: 0:07:39  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 720/1149]  eta: 0:07:28  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 730/1149]  eta: 0:07:18  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 740/1149]  eta: 0:07:07  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 750/1149]  eta: 0:06:57  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 760/1149]  eta: 0:06:46  lr: 0.000140  loss: 0.0014 (0.0013)  time: 1.0441  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [ 770/1149]  eta: 0:06:36  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 780/1149]  eta: 0:06:25  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 790/1149]  eta: 0:06:15  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 800/1149]  eta: 0:06:05  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 810/1149]  eta: 0:05:54  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 820/1149]  eta: 0:05:44  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 830/1149]  eta: 0:05:33  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 840/1149]  eta: 0:05:23  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 850/1149]  eta: 0:05:12  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0494  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 860/1149]  eta: 0:05:02  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0482  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 870/1149]  eta: 0:04:51  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 880/1149]  eta: 0:04:41  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 890/1149]  eta: 0:04:30  lr: 0.000140  loss: 0.0012 (0.0013)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 900/1149]  eta: 0:04:20  lr: 0.000140  loss: 0.0012 (0.0013)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 910/1149]  eta: 0:04:09  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 920/1149]  eta: 0:03:59  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 930/1149]  eta: 0:03:48  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0365  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 940/1149]  eta: 0:03:38  lr: 0.000140  loss: 0.0012 (0.0013)  time: 1.0364  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 950/1149]  eta: 0:03:28  lr: 0.000140  loss: 0.0013 (0.0013)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 960/1149]  eta: 0:03:17  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 970/1149]  eta: 0:03:07  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 980/1149]  eta: 0:02:56  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0484  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [ 990/1149]  eta: 0:02:46  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0465  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1000/1149]  eta: 0:02:35  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1010/1149]  eta: 0:02:25  lr: 0.000140  loss: 0.0008 (0.0013)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1020/1149]  eta: 0:02:14  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0487  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1030/1149]  eta: 0:02:04  lr: 0.000140  loss: 0.0013 (0.0013)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1040/1149]  eta: 0:01:53  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1050/1149]  eta: 0:01:43  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1060/1149]  eta: 0:01:33  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1070/1149]  eta: 0:01:22  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1080/1149]  eta: 0:01:12  lr: 0.000140  loss: 0.0013 (0.0013)  time: 1.0547  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1090/1149]  eta: 0:01:01  lr: 0.000140  loss: 0.0013 (0.0013)  time: 1.0559  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1100/1149]  eta: 0:00:51  lr: 0.000140  loss: 0.0010 (0.0013)  time: 1.0465  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1110/1149]  eta: 0:00:40  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0498  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1120/1149]  eta: 0:00:30  lr: 0.000140  loss: 0.0011 (0.0013)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1130/1149]  eta: 0:00:19  lr: 0.000140  loss: 0.0009 (0.0013)  time: 1.0376  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1140/1149]  eta: 0:00:09  lr: 0.000140  loss: 0.0008 (0.0013)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8]  [1148/1149]  eta: 0:00:01  lr: 0.000140  loss: 0.0008 (0.0013)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:8] Total time: 0:20:01 (1.0459 s / it)\n",
      "Averaged stats: lr: 0.000140  loss: 0.0008 (0.0013)\n",
      "Valid: [epoch:8]  [ 0/14]  eta: 0:00:53  loss: 0.0006 (0.0006)  time: 3.7968  data: 0.6805  max mem: 35661\n",
      "Valid: [epoch:8]  [13/14]  eta: 0:00:03  loss: 0.0007 (0.0009)  time: 3.1908  data: 0.0487  max mem: 35661\n",
      "Valid: [epoch:8] Total time: 0:00:44 (3.2086 s / it)\n",
      "Averaged stats: loss: 0.0007 (0.0009)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_8_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.001%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:9]  [   0/1149]  eta: 0:48:57  lr: 0.000160  loss: 0.0010 (0.0010)  time: 2.5563  data: 1.4585  max mem: 35661\n",
      "Train: [epoch:9]  [  10/1149]  eta: 0:22:17  lr: 0.000160  loss: 0.0008 (0.0008)  time: 1.1745  data: 0.1327  max mem: 35661\n",
      "Train: [epoch:9]  [  20/1149]  eta: 0:20:53  lr: 0.000160  loss: 0.0009 (0.0011)  time: 1.0382  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [  30/1149]  eta: 0:20:19  lr: 0.000160  loss: 0.0010 (0.0011)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [  40/1149]  eta: 0:19:56  lr: 0.000160  loss: 0.0008 (0.0011)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [  50/1149]  eta: 0:19:38  lr: 0.000160  loss: 0.0008 (0.0011)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [  60/1149]  eta: 0:19:22  lr: 0.000160  loss: 0.0008 (0.0011)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [  70/1149]  eta: 0:19:07  lr: 0.000160  loss: 0.0008 (0.0010)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [  80/1149]  eta: 0:18:54  lr: 0.000160  loss: 0.0009 (0.0011)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [  90/1149]  eta: 0:18:42  lr: 0.000160  loss: 0.0013 (0.0012)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 100/1149]  eta: 0:18:30  lr: 0.000160  loss: 0.0013 (0.0012)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 110/1149]  eta: 0:18:18  lr: 0.000160  loss: 0.0012 (0.0012)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 120/1149]  eta: 0:18:06  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 130/1149]  eta: 0:17:54  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 140/1149]  eta: 0:17:43  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 150/1149]  eta: 0:17:32  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0466  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 160/1149]  eta: 0:17:21  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 170/1149]  eta: 0:17:10  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 180/1149]  eta: 0:16:58  lr: 0.000160  loss: 0.0013 (0.0012)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 190/1149]  eta: 0:16:47  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0367  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 200/1149]  eta: 0:16:36  lr: 0.000160  loss: 0.0008 (0.0012)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 210/1149]  eta: 0:16:26  lr: 0.000160  loss: 0.0008 (0.0012)  time: 1.0454  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [ 220/1149]  eta: 0:16:15  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 230/1149]  eta: 0:16:04  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 240/1149]  eta: 0:15:53  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 250/1149]  eta: 0:15:43  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 260/1149]  eta: 0:15:32  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 270/1149]  eta: 0:15:21  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0362  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 280/1149]  eta: 0:15:11  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 290/1149]  eta: 0:15:00  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0506  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 300/1149]  eta: 0:14:49  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 310/1149]  eta: 0:14:39  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 320/1149]  eta: 0:14:28  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 330/1149]  eta: 0:14:18  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 340/1149]  eta: 0:14:07  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 350/1149]  eta: 0:13:56  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 360/1149]  eta: 0:13:46  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 370/1149]  eta: 0:13:35  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 380/1149]  eta: 0:13:25  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 390/1149]  eta: 0:13:14  lr: 0.000160  loss: 0.0011 (0.0013)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 400/1149]  eta: 0:13:04  lr: 0.000160  loss: 0.0011 (0.0013)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 410/1149]  eta: 0:12:53  lr: 0.000160  loss: 0.0011 (0.0013)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 420/1149]  eta: 0:12:43  lr: 0.000160  loss: 0.0011 (0.0013)  time: 1.0478  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 430/1149]  eta: 0:12:32  lr: 0.000160  loss: 0.0009 (0.0013)  time: 1.0477  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 440/1149]  eta: 0:12:22  lr: 0.000160  loss: 0.0009 (0.0013)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 450/1149]  eta: 0:12:11  lr: 0.000160  loss: 0.0010 (0.0013)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 460/1149]  eta: 0:12:01  lr: 0.000160  loss: 0.0011 (0.0013)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 470/1149]  eta: 0:11:50  lr: 0.000160  loss: 0.0010 (0.0013)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 480/1149]  eta: 0:11:39  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0380  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 490/1149]  eta: 0:11:29  lr: 0.000160  loss: 0.0011 (0.0013)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 500/1149]  eta: 0:11:18  lr: 0.000160  loss: 0.0009 (0.0013)  time: 1.0349  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 510/1149]  eta: 0:11:08  lr: 0.000160  loss: 0.0010 (0.0013)  time: 1.0343  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 520/1149]  eta: 0:10:57  lr: 0.000160  loss: 0.0011 (0.0013)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 530/1149]  eta: 0:10:47  lr: 0.000160  loss: 0.0008 (0.0012)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 540/1149]  eta: 0:10:36  lr: 0.000160  loss: 0.0008 (0.0012)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 550/1149]  eta: 0:10:26  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 560/1149]  eta: 0:10:15  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 570/1149]  eta: 0:10:05  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 580/1149]  eta: 0:09:54  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 590/1149]  eta: 0:09:44  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 600/1149]  eta: 0:09:33  lr: 0.000160  loss: 0.0006 (0.0012)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 610/1149]  eta: 0:09:23  lr: 0.000160  loss: 0.0007 (0.0012)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 620/1149]  eta: 0:09:12  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 630/1149]  eta: 0:09:02  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 640/1149]  eta: 0:08:51  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 650/1149]  eta: 0:08:41  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 660/1149]  eta: 0:08:30  lr: 0.000160  loss: 0.0013 (0.0012)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 670/1149]  eta: 0:08:20  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 680/1149]  eta: 0:08:09  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0369  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 690/1149]  eta: 0:07:59  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 700/1149]  eta: 0:07:49  lr: 0.000160  loss: 0.0008 (0.0012)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 710/1149]  eta: 0:07:38  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 720/1149]  eta: 0:07:28  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 730/1149]  eta: 0:07:17  lr: 0.000160  loss: 0.0013 (0.0012)  time: 1.0376  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 740/1149]  eta: 0:07:07  lr: 0.000160  loss: 0.0015 (0.0012)  time: 1.0363  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 750/1149]  eta: 0:06:56  lr: 0.000160  loss: 0.0012 (0.0012)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 760/1149]  eta: 0:06:46  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 770/1149]  eta: 0:06:35  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 780/1149]  eta: 0:06:25  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0372  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 790/1149]  eta: 0:06:14  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 800/1149]  eta: 0:06:04  lr: 0.000160  loss: 0.0008 (0.0012)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 810/1149]  eta: 0:05:53  lr: 0.000160  loss: 0.0008 (0.0012)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 820/1149]  eta: 0:05:43  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 830/1149]  eta: 0:05:33  lr: 0.000160  loss: 0.0009 (0.0012)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 840/1149]  eta: 0:05:22  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 850/1149]  eta: 0:05:12  lr: 0.000160  loss: 0.0010 (0.0012)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 860/1149]  eta: 0:05:01  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 870/1149]  eta: 0:04:51  lr: 0.000160  loss: 0.0011 (0.0012)  time: 1.0431  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [ 880/1149]  eta: 0:04:40  lr: 0.000160  loss: 0.0017 (0.0013)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 890/1149]  eta: 0:04:30  lr: 0.000160  loss: 0.0019 (0.0013)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 900/1149]  eta: 0:04:19  lr: 0.000160  loss: 0.0018 (0.0013)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 910/1149]  eta: 0:04:09  lr: 0.000160  loss: 0.0016 (0.0013)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 920/1149]  eta: 0:03:59  lr: 0.000160  loss: 0.0016 (0.0013)  time: 1.0342  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 930/1149]  eta: 0:03:48  lr: 0.000160  loss: 0.0017 (0.0013)  time: 1.0288  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 940/1149]  eta: 0:03:38  lr: 0.000160  loss: 0.0017 (0.0013)  time: 1.0355  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 950/1149]  eta: 0:03:27  lr: 0.000160  loss: 0.0016 (0.0013)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 960/1149]  eta: 0:03:17  lr: 0.000160  loss: 0.0017 (0.0013)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 970/1149]  eta: 0:03:06  lr: 0.000160  loss: 0.0018 (0.0013)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 980/1149]  eta: 0:02:56  lr: 0.000160  loss: 0.0017 (0.0013)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [ 990/1149]  eta: 0:02:45  lr: 0.000160  loss: 0.0015 (0.0013)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1000/1149]  eta: 0:02:35  lr: 0.000160  loss: 0.0016 (0.0013)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1010/1149]  eta: 0:02:25  lr: 0.000160  loss: 0.0017 (0.0013)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1020/1149]  eta: 0:02:14  lr: 0.000160  loss: 0.0018 (0.0013)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1030/1149]  eta: 0:02:04  lr: 0.000160  loss: 0.0021 (0.0014)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1040/1149]  eta: 0:01:53  lr: 0.000160  loss: 0.0016 (0.0014)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1050/1149]  eta: 0:01:43  lr: 0.000160  loss: 0.0015 (0.0014)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1060/1149]  eta: 0:01:32  lr: 0.000160  loss: 0.0018 (0.0014)  time: 1.0335  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1070/1149]  eta: 0:01:22  lr: 0.000160  loss: 0.0018 (0.0014)  time: 1.0339  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1080/1149]  eta: 0:01:11  lr: 0.000160  loss: 0.0017 (0.0014)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1090/1149]  eta: 0:01:01  lr: 0.000160  loss: 0.0017 (0.0014)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1100/1149]  eta: 0:00:51  lr: 0.000160  loss: 0.0020 (0.0014)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1110/1149]  eta: 0:00:40  lr: 0.000160  loss: 0.0019 (0.0014)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1120/1149]  eta: 0:00:30  lr: 0.000160  loss: 0.0017 (0.0014)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1130/1149]  eta: 0:00:19  lr: 0.000160  loss: 0.0016 (0.0014)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1140/1149]  eta: 0:00:09  lr: 0.000160  loss: 0.0019 (0.0014)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9]  [1148/1149]  eta: 0:00:01  lr: 0.000160  loss: 0.0020 (0.0014)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:9] Total time: 0:19:58 (1.0433 s / it)\n",
      "Averaged stats: lr: 0.000160  loss: 0.0020 (0.0014)\n",
      "Valid: [epoch:9]  [ 0/14]  eta: 0:00:55  loss: 0.0022 (0.0022)  time: 3.9516  data: 0.7520  max mem: 35661\n",
      "Valid: [epoch:9]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.2152  data: 0.0538  max mem: 35661\n",
      "Valid: [epoch:9] Total time: 0:00:45 (3.2315 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_9_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:10]  [   0/1149]  eta: 0:45:53  lr: 0.000180  loss: 0.0019 (0.0019)  time: 2.3965  data: 1.3006  max mem: 35661\n",
      "Train: [epoch:10]  [  10/1149]  eta: 0:22:10  lr: 0.000180  loss: 0.0019 (0.0019)  time: 1.1683  data: 0.1184  max mem: 35661\n",
      "Train: [epoch:10]  [  20/1149]  eta: 0:20:47  lr: 0.000180  loss: 0.0016 (0.0018)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [  30/1149]  eta: 0:20:12  lr: 0.000180  loss: 0.0014 (0.0017)  time: 1.0370  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [  40/1149]  eta: 0:19:52  lr: 0.000180  loss: 0.0015 (0.0018)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [  50/1149]  eta: 0:19:34  lr: 0.000180  loss: 0.0015 (0.0018)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [  60/1149]  eta: 0:19:19  lr: 0.000180  loss: 0.0014 (0.0018)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [  70/1149]  eta: 0:19:05  lr: 0.000180  loss: 0.0015 (0.0018)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [  80/1149]  eta: 0:18:52  lr: 0.000180  loss: 0.0018 (0.0018)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [  90/1149]  eta: 0:18:40  lr: 0.000180  loss: 0.0018 (0.0018)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 100/1149]  eta: 0:18:27  lr: 0.000180  loss: 0.0016 (0.0018)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 110/1149]  eta: 0:18:14  lr: 0.000180  loss: 0.0016 (0.0019)  time: 1.0336  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 120/1149]  eta: 0:18:03  lr: 0.000180  loss: 0.0016 (0.0019)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 130/1149]  eta: 0:17:51  lr: 0.000180  loss: 0.0014 (0.0019)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 140/1149]  eta: 0:17:40  lr: 0.000180  loss: 0.0012 (0.0018)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 150/1149]  eta: 0:17:29  lr: 0.000180  loss: 0.0012 (0.0018)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 160/1149]  eta: 0:17:18  lr: 0.000180  loss: 0.0015 (0.0018)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 170/1149]  eta: 0:17:07  lr: 0.000180  loss: 0.0019 (0.0019)  time: 1.0382  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 180/1149]  eta: 0:16:56  lr: 0.000180  loss: 0.0019 (0.0019)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 190/1149]  eta: 0:16:45  lr: 0.000180  loss: 0.0015 (0.0019)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 200/1149]  eta: 0:16:34  lr: 0.000180  loss: 0.0016 (0.0019)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 210/1149]  eta: 0:16:23  lr: 0.000180  loss: 0.0018 (0.0019)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 220/1149]  eta: 0:16:13  lr: 0.000180  loss: 0.0019 (0.0019)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 230/1149]  eta: 0:16:02  lr: 0.000180  loss: 0.0017 (0.0019)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 240/1149]  eta: 0:15:51  lr: 0.000180  loss: 0.0017 (0.0019)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 250/1149]  eta: 0:15:41  lr: 0.000180  loss: 0.0020 (0.0019)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 260/1149]  eta: 0:15:30  lr: 0.000180  loss: 0.0017 (0.0019)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 270/1149]  eta: 0:15:19  lr: 0.000180  loss: 0.0017 (0.0019)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 280/1149]  eta: 0:15:09  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 290/1149]  eta: 0:14:58  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 300/1149]  eta: 0:14:48  lr: 0.000180  loss: 0.0017 (0.0019)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 310/1149]  eta: 0:14:37  lr: 0.000180  loss: 0.0021 (0.0020)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 320/1149]  eta: 0:14:27  lr: 0.000180  loss: 0.0022 (0.0020)  time: 1.0426  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [ 330/1149]  eta: 0:14:16  lr: 0.000180  loss: 0.0020 (0.0020)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 340/1149]  eta: 0:14:05  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 350/1149]  eta: 0:13:54  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0328  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 360/1149]  eta: 0:13:44  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0360  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 370/1149]  eta: 0:13:34  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 380/1149]  eta: 0:13:23  lr: 0.000180  loss: 0.0020 (0.0021)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 390/1149]  eta: 0:13:13  lr: 0.000180  loss: 0.0020 (0.0021)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 400/1149]  eta: 0:13:02  lr: 0.000180  loss: 0.0016 (0.0021)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 410/1149]  eta: 0:12:52  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 420/1149]  eta: 0:12:41  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 430/1149]  eta: 0:12:31  lr: 0.000180  loss: 0.0017 (0.0021)  time: 1.0372  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 440/1149]  eta: 0:12:20  lr: 0.000180  loss: 0.0014 (0.0020)  time: 1.0279  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 450/1149]  eta: 0:12:09  lr: 0.000180  loss: 0.0014 (0.0020)  time: 1.0283  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 460/1149]  eta: 0:11:59  lr: 0.000180  loss: 0.0020 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 470/1149]  eta: 0:11:48  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 480/1149]  eta: 0:11:38  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 490/1149]  eta: 0:11:27  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0354  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 500/1149]  eta: 0:11:17  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 510/1149]  eta: 0:11:06  lr: 0.000180  loss: 0.0021 (0.0021)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 520/1149]  eta: 0:10:56  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 530/1149]  eta: 0:10:45  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 540/1149]  eta: 0:10:35  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 550/1149]  eta: 0:10:25  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 560/1149]  eta: 0:10:14  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 570/1149]  eta: 0:10:04  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 580/1149]  eta: 0:09:53  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 590/1149]  eta: 0:09:43  lr: 0.000180  loss: 0.0013 (0.0020)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 600/1149]  eta: 0:09:32  lr: 0.000180  loss: 0.0013 (0.0020)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 610/1149]  eta: 0:09:22  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 620/1149]  eta: 0:09:11  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0367  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 630/1149]  eta: 0:09:01  lr: 0.000180  loss: 0.0016 (0.0020)  time: 1.0347  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 640/1149]  eta: 0:08:50  lr: 0.000180  loss: 0.0016 (0.0020)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 650/1149]  eta: 0:08:40  lr: 0.000180  loss: 0.0016 (0.0020)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 660/1149]  eta: 0:08:29  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 670/1149]  eta: 0:08:19  lr: 0.000180  loss: 0.0021 (0.0020)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 680/1149]  eta: 0:08:09  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 690/1149]  eta: 0:07:58  lr: 0.000180  loss: 0.0016 (0.0020)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 700/1149]  eta: 0:07:48  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 710/1149]  eta: 0:07:37  lr: 0.000180  loss: 0.0016 (0.0020)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 720/1149]  eta: 0:07:27  lr: 0.000180  loss: 0.0016 (0.0020)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 730/1149]  eta: 0:07:16  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 740/1149]  eta: 0:07:06  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 750/1149]  eta: 0:06:55  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 760/1149]  eta: 0:06:45  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0376  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 770/1149]  eta: 0:06:35  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0367  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 780/1149]  eta: 0:06:24  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 790/1149]  eta: 0:06:14  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 800/1149]  eta: 0:06:03  lr: 0.000180  loss: 0.0019 (0.0020)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 810/1149]  eta: 0:05:53  lr: 0.000180  loss: 0.0020 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 820/1149]  eta: 0:05:42  lr: 0.000180  loss: 0.0017 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 830/1149]  eta: 0:05:32  lr: 0.000180  loss: 0.0016 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 840/1149]  eta: 0:05:22  lr: 0.000180  loss: 0.0016 (0.0021)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 850/1149]  eta: 0:05:11  lr: 0.000180  loss: 0.0014 (0.0021)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 860/1149]  eta: 0:05:01  lr: 0.000180  loss: 0.0014 (0.0021)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 870/1149]  eta: 0:04:50  lr: 0.000180  loss: 0.0015 (0.0020)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 880/1149]  eta: 0:04:40  lr: 0.000180  loss: 0.0015 (0.0020)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 890/1149]  eta: 0:04:29  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 900/1149]  eta: 0:04:19  lr: 0.000180  loss: 0.0017 (0.0020)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 910/1149]  eta: 0:04:09  lr: 0.000180  loss: 0.0016 (0.0020)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 920/1149]  eta: 0:03:58  lr: 0.000180  loss: 0.0016 (0.0020)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 930/1149]  eta: 0:03:48  lr: 0.000180  loss: 0.0022 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 940/1149]  eta: 0:03:37  lr: 0.000180  loss: 0.0018 (0.0020)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 950/1149]  eta: 0:03:27  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 960/1149]  eta: 0:03:16  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 970/1149]  eta: 0:03:06  lr: 0.000180  loss: 0.0016 (0.0021)  time: 1.0382  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [ 980/1149]  eta: 0:02:56  lr: 0.000180  loss: 0.0015 (0.0021)  time: 1.0393  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [ 990/1149]  eta: 0:02:45  lr: 0.000180  loss: 0.0016 (0.0021)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1000/1149]  eta: 0:02:35  lr: 0.000180  loss: 0.0020 (0.0021)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1010/1149]  eta: 0:02:24  lr: 0.000180  loss: 0.0017 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1020/1149]  eta: 0:02:14  lr: 0.000180  loss: 0.0017 (0.0021)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1030/1149]  eta: 0:02:04  lr: 0.000180  loss: 0.0020 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1040/1149]  eta: 0:01:53  lr: 0.000180  loss: 0.0019 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1050/1149]  eta: 0:01:43  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1060/1149]  eta: 0:01:32  lr: 0.000180  loss: 0.0017 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1070/1149]  eta: 0:01:22  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1080/1149]  eta: 0:01:11  lr: 0.000180  loss: 0.0017 (0.0021)  time: 1.0381  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1090/1149]  eta: 0:01:01  lr: 0.000180  loss: 0.0017 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1100/1149]  eta: 0:00:51  lr: 0.000180  loss: 0.0017 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1110/1149]  eta: 0:00:40  lr: 0.000180  loss: 0.0021 (0.0021)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1120/1149]  eta: 0:00:30  lr: 0.000180  loss: 0.0021 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1130/1149]  eta: 0:00:19  lr: 0.000180  loss: 0.0017 (0.0021)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1140/1149]  eta: 0:00:09  lr: 0.000180  loss: 0.0016 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10]  [1148/1149]  eta: 0:00:01  lr: 0.000180  loss: 0.0019 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:10] Total time: 0:19:57 (1.0423 s / it)\n",
      "Averaged stats: lr: 0.000180  loss: 0.0019 (0.0021)\n",
      "Valid: [epoch:10]  [ 0/14]  eta: 0:00:55  loss: 0.0014 (0.0014)  time: 3.9418  data: 0.7070  max mem: 35661\n",
      "Valid: [epoch:10]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.1427  data: 0.0506  max mem: 35661\n",
      "Valid: [epoch:10] Total time: 0:00:44 (3.1597 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_10_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:11]  [   0/1149]  eta: 0:52:18  lr: 0.000200  loss: 0.0022 (0.0022)  time: 2.7313  data: 1.6553  max mem: 35661\n",
      "Train: [epoch:11]  [  10/1149]  eta: 0:22:44  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.1979  data: 0.1506  max mem: 35661\n",
      "Train: [epoch:11]  [  20/1149]  eta: 0:21:04  lr: 0.000200  loss: 0.0016 (0.0018)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [  30/1149]  eta: 0:20:21  lr: 0.000200  loss: 0.0015 (0.0018)  time: 1.0330  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [  40/1149]  eta: 0:19:56  lr: 0.000200  loss: 0.0014 (0.0018)  time: 1.0362  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [  50/1149]  eta: 0:19:36  lr: 0.000200  loss: 0.0014 (0.0017)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [  60/1149]  eta: 0:19:20  lr: 0.000200  loss: 0.0016 (0.0018)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [  70/1149]  eta: 0:19:06  lr: 0.000200  loss: 0.0017 (0.0018)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [  80/1149]  eta: 0:18:53  lr: 0.000200  loss: 0.0019 (0.0019)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [  90/1149]  eta: 0:18:40  lr: 0.000200  loss: 0.0020 (0.0019)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 100/1149]  eta: 0:18:27  lr: 0.000200  loss: 0.0021 (0.0020)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 110/1149]  eta: 0:18:15  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 120/1149]  eta: 0:18:04  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 130/1149]  eta: 0:17:52  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 140/1149]  eta: 0:17:40  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.0335  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 150/1149]  eta: 0:17:29  lr: 0.000200  loss: 0.0013 (0.0019)  time: 1.0319  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 160/1149]  eta: 0:17:17  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 170/1149]  eta: 0:17:06  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0379  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 180/1149]  eta: 0:16:55  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 190/1149]  eta: 0:16:44  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0377  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 200/1149]  eta: 0:16:32  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0260  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 210/1149]  eta: 0:16:22  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0298  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 220/1149]  eta: 0:16:10  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0356  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 230/1149]  eta: 0:16:00  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0355  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 240/1149]  eta: 0:15:49  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 250/1149]  eta: 0:15:39  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 260/1149]  eta: 0:15:28  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 270/1149]  eta: 0:15:18  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 280/1149]  eta: 0:15:07  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 290/1149]  eta: 0:14:57  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 300/1149]  eta: 0:14:46  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0381  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 310/1149]  eta: 0:14:35  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0326  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 320/1149]  eta: 0:14:25  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0342  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 330/1149]  eta: 0:14:14  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 340/1149]  eta: 0:14:03  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 350/1149]  eta: 0:13:53  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0359  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 360/1149]  eta: 0:13:42  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0358  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 370/1149]  eta: 0:13:32  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 380/1149]  eta: 0:13:22  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 390/1149]  eta: 0:13:11  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 400/1149]  eta: 0:13:01  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 410/1149]  eta: 0:12:50  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 420/1149]  eta: 0:12:40  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 430/1149]  eta: 0:12:29  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0314  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [ 440/1149]  eta: 0:12:18  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0328  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 450/1149]  eta: 0:12:08  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0381  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 460/1149]  eta: 0:11:58  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 470/1149]  eta: 0:11:47  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 480/1149]  eta: 0:11:37  lr: 0.000200  loss: 0.0013 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 490/1149]  eta: 0:11:26  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0361  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 500/1149]  eta: 0:11:16  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 510/1149]  eta: 0:11:05  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 520/1149]  eta: 0:10:55  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 530/1149]  eta: 0:10:44  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 540/1149]  eta: 0:10:34  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0363  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 550/1149]  eta: 0:10:23  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0362  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 560/1149]  eta: 0:10:13  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 570/1149]  eta: 0:10:03  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 580/1149]  eta: 0:09:52  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 590/1149]  eta: 0:09:42  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 600/1149]  eta: 0:09:31  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 610/1149]  eta: 0:09:21  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 620/1149]  eta: 0:09:10  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0369  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 630/1149]  eta: 0:09:00  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0373  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 640/1149]  eta: 0:08:50  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 650/1149]  eta: 0:08:39  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 660/1149]  eta: 0:08:29  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 670/1149]  eta: 0:08:18  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 680/1149]  eta: 0:08:08  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 690/1149]  eta: 0:07:57  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 700/1149]  eta: 0:07:47  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 710/1149]  eta: 0:07:37  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0360  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 720/1149]  eta: 0:07:26  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0294  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 730/1149]  eta: 0:07:16  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0356  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 740/1149]  eta: 0:07:05  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 750/1149]  eta: 0:06:55  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 760/1149]  eta: 0:06:44  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 770/1149]  eta: 0:06:34  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 780/1149]  eta: 0:06:24  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 790/1149]  eta: 0:06:13  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0376  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 800/1149]  eta: 0:06:03  lr: 0.000200  loss: 0.0024 (0.0021)  time: 1.0369  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 810/1149]  eta: 0:05:52  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 820/1149]  eta: 0:05:42  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 830/1149]  eta: 0:05:31  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0238  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 840/1149]  eta: 0:05:21  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0253  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 850/1149]  eta: 0:05:11  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0361  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 860/1149]  eta: 0:05:00  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 870/1149]  eta: 0:04:50  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 880/1149]  eta: 0:04:39  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0370  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 890/1149]  eta: 0:04:29  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 900/1149]  eta: 0:04:19  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 910/1149]  eta: 0:04:08  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 920/1149]  eta: 0:03:58  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 930/1149]  eta: 0:03:47  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 940/1149]  eta: 0:03:37  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 950/1149]  eta: 0:03:27  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0387  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 960/1149]  eta: 0:03:16  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 970/1149]  eta: 0:03:06  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 980/1149]  eta: 0:02:55  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [ 990/1149]  eta: 0:02:45  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1000/1149]  eta: 0:02:35  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1010/1149]  eta: 0:02:24  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1020/1149]  eta: 0:02:14  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1030/1149]  eta: 0:02:03  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1040/1149]  eta: 0:01:53  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0382  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1050/1149]  eta: 0:01:43  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1060/1149]  eta: 0:01:32  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1070/1149]  eta: 0:01:22  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1080/1149]  eta: 0:01:11  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0376  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1090/1149]  eta: 0:01:01  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [1100/1149]  eta: 0:00:50  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1110/1149]  eta: 0:00:40  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1120/1149]  eta: 0:00:30  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1130/1149]  eta: 0:00:19  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1140/1149]  eta: 0:00:09  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:11] Total time: 0:19:55 (1.0408 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0021)\n",
      "Valid: [epoch:11]  [ 0/14]  eta: 0:00:54  loss: 0.0022 (0.0022)  time: 3.8636  data: 0.6534  max mem: 35661\n",
      "Valid: [epoch:11]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.1170  data: 0.0468  max mem: 35661\n",
      "Valid: [epoch:11] Total time: 0:00:43 (3.1341 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_11_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:12]  [   0/1149]  eta: 0:44:54  lr: 0.000200  loss: 0.0022 (0.0022)  time: 2.3453  data: 1.1456  max mem: 35661\n",
      "Train: [epoch:12]  [  10/1149]  eta: 0:21:57  lr: 0.000200  loss: 0.0024 (0.0026)  time: 1.1564  data: 0.1043  max mem: 35661\n",
      "Train: [epoch:12]  [  20/1149]  eta: 0:20:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0303  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [  30/1149]  eta: 0:20:04  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0324  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [  40/1149]  eta: 0:19:43  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [  50/1149]  eta: 0:19:26  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0387  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [  60/1149]  eta: 0:19:11  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [  70/1149]  eta: 0:18:58  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [  80/1149]  eta: 0:18:46  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [  90/1149]  eta: 0:18:34  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 100/1149]  eta: 0:18:22  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0380  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 110/1149]  eta: 0:18:10  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 120/1149]  eta: 0:17:59  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 130/1149]  eta: 0:17:48  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 140/1149]  eta: 0:17:37  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 150/1149]  eta: 0:17:26  lr: 0.000200  loss: 0.0014 (0.0020)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 160/1149]  eta: 0:17:15  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 170/1149]  eta: 0:17:05  lr: 0.000200  loss: 0.0024 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 180/1149]  eta: 0:16:54  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 190/1149]  eta: 0:16:43  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 200/1149]  eta: 0:16:32  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 210/1149]  eta: 0:16:21  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 220/1149]  eta: 0:16:11  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 230/1149]  eta: 0:16:00  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0357  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 240/1149]  eta: 0:15:49  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0357  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 250/1149]  eta: 0:15:38  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 260/1149]  eta: 0:15:28  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 270/1149]  eta: 0:15:17  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 280/1149]  eta: 0:15:07  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0376  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 290/1149]  eta: 0:14:56  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0327  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 300/1149]  eta: 0:14:45  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0279  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 310/1149]  eta: 0:14:35  lr: 0.000200  loss: 0.0021 (0.0020)  time: 1.0360  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 320/1149]  eta: 0:14:24  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 330/1149]  eta: 0:14:14  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0438  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:12]  [ 340/1149]  eta: 0:14:03  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0379  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:12]  [ 350/1149]  eta: 0:13:53  lr: 0.000200  loss: 0.0023 (0.0020)  time: 1.0348  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 360/1149]  eta: 0:13:42  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0352  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 370/1149]  eta: 0:13:32  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 380/1149]  eta: 0:13:21  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 390/1149]  eta: 0:13:11  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0380  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 400/1149]  eta: 0:13:00  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0372  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 410/1149]  eta: 0:12:50  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 420/1149]  eta: 0:12:39  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 430/1149]  eta: 0:12:29  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 440/1149]  eta: 0:12:18  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 450/1149]  eta: 0:12:08  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0353  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 460/1149]  eta: 0:11:57  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0313  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 470/1149]  eta: 0:11:47  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0337  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 480/1149]  eta: 0:11:36  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 490/1149]  eta: 0:11:26  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 500/1149]  eta: 0:11:15  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 510/1149]  eta: 0:11:05  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 520/1149]  eta: 0:10:55  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 530/1149]  eta: 0:10:44  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 540/1149]  eta: 0:10:34  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [ 550/1149]  eta: 0:10:23  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 560/1149]  eta: 0:10:13  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 570/1149]  eta: 0:10:03  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0387  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 580/1149]  eta: 0:09:52  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 590/1149]  eta: 0:09:42  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 600/1149]  eta: 0:09:31  lr: 0.000200  loss: 0.0013 (0.0020)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 610/1149]  eta: 0:09:21  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0364  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 620/1149]  eta: 0:09:10  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 630/1149]  eta: 0:09:00  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 640/1149]  eta: 0:08:49  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0346  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 650/1149]  eta: 0:08:39  lr: 0.000200  loss: 0.0014 (0.0020)  time: 1.0373  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 660/1149]  eta: 0:08:29  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 670/1149]  eta: 0:08:18  lr: 0.000200  loss: 0.0022 (0.0020)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 680/1149]  eta: 0:08:08  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 690/1149]  eta: 0:07:57  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 700/1149]  eta: 0:07:47  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 710/1149]  eta: 0:07:37  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 720/1149]  eta: 0:07:26  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 730/1149]  eta: 0:07:16  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 740/1149]  eta: 0:07:05  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 750/1149]  eta: 0:06:55  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 760/1149]  eta: 0:06:44  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 770/1149]  eta: 0:06:34  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0316  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 780/1149]  eta: 0:06:24  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0286  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 790/1149]  eta: 0:06:13  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0368  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 800/1149]  eta: 0:06:03  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 810/1149]  eta: 0:05:52  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0386  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 820/1149]  eta: 0:05:42  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0366  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 830/1149]  eta: 0:05:31  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0265  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 840/1149]  eta: 0:05:21  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0276  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 850/1149]  eta: 0:05:11  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 860/1149]  eta: 0:05:00  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 870/1149]  eta: 0:04:50  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 880/1149]  eta: 0:04:39  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 890/1149]  eta: 0:04:29  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 900/1149]  eta: 0:04:19  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 910/1149]  eta: 0:04:08  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 920/1149]  eta: 0:03:58  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0477  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:12]  [ 930/1149]  eta: 0:03:47  lr: 0.000200  loss: 0.0025 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 940/1149]  eta: 0:03:37  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 950/1149]  eta: 0:03:27  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 960/1149]  eta: 0:03:16  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 970/1149]  eta: 0:03:06  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 980/1149]  eta: 0:02:55  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [ 990/1149]  eta: 0:02:45  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1000/1149]  eta: 0:02:35  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1010/1149]  eta: 0:02:24  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1020/1149]  eta: 0:02:14  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1030/1149]  eta: 0:02:03  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1040/1149]  eta: 0:01:53  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1050/1149]  eta: 0:01:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1060/1149]  eta: 0:01:32  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1070/1149]  eta: 0:01:22  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1080/1149]  eta: 0:01:11  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1090/1149]  eta: 0:01:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1100/1149]  eta: 0:00:50  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1110/1149]  eta: 0:00:40  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1120/1149]  eta: 0:00:30  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1130/1149]  eta: 0:00:19  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1140/1149]  eta: 0:00:09  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:12] Total time: 0:19:56 (1.0411 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0021)\n",
      "Valid: [epoch:12]  [ 0/14]  eta: 0:00:57  loss: 0.0007 (0.0007)  time: 4.1136  data: 0.7059  max mem: 35661\n",
      "Valid: [epoch:12]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.2044  data: 0.0505  max mem: 35661\n",
      "Valid: [epoch:12] Total time: 0:00:45 (3.2191 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_12_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:13]  [   0/1149]  eta: 0:52:40  lr: 0.000200  loss: 0.0017 (0.0017)  time: 2.7506  data: 1.4946  max mem: 35661\n",
      "Train: [epoch:13]  [  10/1149]  eta: 0:22:32  lr: 0.000200  loss: 0.0016 (0.0019)  time: 1.1874  data: 0.1360  max mem: 35661\n",
      "Train: [epoch:13]  [  20/1149]  eta: 0:21:03  lr: 0.000200  loss: 0.0015 (0.0018)  time: 1.0379  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:13]  [  30/1149]  eta: 0:20:22  lr: 0.000200  loss: 0.0018 (0.0019)  time: 1.0407  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:13]  [  40/1149]  eta: 0:19:56  lr: 0.000200  loss: 0.0021 (0.0020)  time: 1.0365  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [  50/1149]  eta: 0:19:38  lr: 0.000200  loss: 0.0025 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [  60/1149]  eta: 0:19:22  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0444  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:13]  [  70/1149]  eta: 0:19:08  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [  80/1149]  eta: 0:18:55  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [  90/1149]  eta: 0:18:42  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 100/1149]  eta: 0:18:31  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 110/1149]  eta: 0:18:18  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 120/1149]  eta: 0:18:06  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 130/1149]  eta: 0:17:54  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 140/1149]  eta: 0:17:43  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 150/1149]  eta: 0:17:32  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 160/1149]  eta: 0:17:21  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 170/1149]  eta: 0:17:10  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 180/1149]  eta: 0:16:58  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0360  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 190/1149]  eta: 0:16:48  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 200/1149]  eta: 0:16:37  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 210/1149]  eta: 0:16:26  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 220/1149]  eta: 0:16:15  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 230/1149]  eta: 0:16:04  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 240/1149]  eta: 0:15:53  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 250/1149]  eta: 0:15:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 260/1149]  eta: 0:15:32  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 270/1149]  eta: 0:15:21  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 280/1149]  eta: 0:15:10  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 290/1149]  eta: 0:14:59  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0369  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 300/1149]  eta: 0:14:49  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0334  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 310/1149]  eta: 0:14:38  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0365  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 320/1149]  eta: 0:14:27  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 330/1149]  eta: 0:14:17  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 340/1149]  eta: 0:14:06  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0420  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:13]  [ 350/1149]  eta: 0:13:56  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0422  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:13]  [ 360/1149]  eta: 0:13:45  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 370/1149]  eta: 0:13:34  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0386  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 380/1149]  eta: 0:13:24  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 390/1149]  eta: 0:13:13  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 400/1149]  eta: 0:13:03  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 410/1149]  eta: 0:12:52  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 420/1149]  eta: 0:12:42  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0360  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 430/1149]  eta: 0:12:31  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0379  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 440/1149]  eta: 0:12:21  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 450/1149]  eta: 0:12:10  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 460/1149]  eta: 0:12:00  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 470/1149]  eta: 0:11:49  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 480/1149]  eta: 0:11:39  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0371  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 490/1149]  eta: 0:11:28  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 500/1149]  eta: 0:11:18  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 510/1149]  eta: 0:11:07  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 520/1149]  eta: 0:10:57  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 530/1149]  eta: 0:10:46  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 540/1149]  eta: 0:10:35  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0357  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 550/1149]  eta: 0:10:25  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0349  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 560/1149]  eta: 0:10:15  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 570/1149]  eta: 0:10:04  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 580/1149]  eta: 0:09:54  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 590/1149]  eta: 0:09:43  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 600/1149]  eta: 0:09:33  lr: 0.000200  loss: 0.0013 (0.0021)  time: 1.0358  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 610/1149]  eta: 0:09:22  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0266  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 620/1149]  eta: 0:09:11  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0290  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 630/1149]  eta: 0:09:01  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0345  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 640/1149]  eta: 0:08:50  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [ 650/1149]  eta: 0:08:40  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 660/1149]  eta: 0:08:30  lr: 0.000200  loss: 0.0024 (0.0021)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 670/1149]  eta: 0:08:19  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 680/1149]  eta: 0:08:09  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 690/1149]  eta: 0:07:58  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 700/1149]  eta: 0:07:48  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 710/1149]  eta: 0:07:37  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 720/1149]  eta: 0:07:27  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 730/1149]  eta: 0:07:17  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 740/1149]  eta: 0:07:06  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 750/1149]  eta: 0:06:56  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0403  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:13]  [ 760/1149]  eta: 0:06:45  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0382  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:13]  [ 770/1149]  eta: 0:06:35  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 780/1149]  eta: 0:06:24  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 790/1149]  eta: 0:06:14  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 800/1149]  eta: 0:06:03  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 810/1149]  eta: 0:05:53  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 820/1149]  eta: 0:05:43  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 830/1149]  eta: 0:05:32  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 840/1149]  eta: 0:05:22  lr: 0.000200  loss: 0.0013 (0.0021)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 850/1149]  eta: 0:05:11  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 860/1149]  eta: 0:05:01  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 870/1149]  eta: 0:04:50  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0381  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 880/1149]  eta: 0:04:40  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 890/1149]  eta: 0:04:30  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 900/1149]  eta: 0:04:19  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 910/1149]  eta: 0:04:09  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0361  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 920/1149]  eta: 0:03:58  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0367  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 930/1149]  eta: 0:03:48  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 940/1149]  eta: 0:03:37  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 950/1149]  eta: 0:03:27  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 960/1149]  eta: 0:03:17  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0386  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 970/1149]  eta: 0:03:06  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0286  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 980/1149]  eta: 0:02:56  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0287  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [ 990/1149]  eta: 0:02:45  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1000/1149]  eta: 0:02:35  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1010/1149]  eta: 0:02:24  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1020/1149]  eta: 0:02:14  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1030/1149]  eta: 0:02:04  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1040/1149]  eta: 0:01:53  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1050/1149]  eta: 0:01:43  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0481  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1060/1149]  eta: 0:01:32  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1070/1149]  eta: 0:01:22  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1080/1149]  eta: 0:01:11  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0387  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1090/1149]  eta: 0:01:01  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1100/1149]  eta: 0:00:51  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1110/1149]  eta: 0:00:40  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0370  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1120/1149]  eta: 0:00:30  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0380  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1130/1149]  eta: 0:00:19  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1140/1149]  eta: 0:00:09  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:13] Total time: 0:19:57 (1.0425 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0021)\n",
      "Valid: [epoch:13]  [ 0/14]  eta: 0:00:54  loss: 0.0023 (0.0023)  time: 3.9065  data: 0.7198  max mem: 35661\n",
      "Valid: [epoch:13]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.1889  data: 0.0515  max mem: 35661\n",
      "Valid: [epoch:13] Total time: 0:00:44 (3.2041 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_13_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:14]  [   0/1149]  eta: 0:48:57  lr: 0.000200  loss: 0.0035 (0.0035)  time: 2.5562  data: 1.3012  max mem: 35661\n",
      "Train: [epoch:14]  [  10/1149]  eta: 0:22:24  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.1800  data: 0.1184  max mem: 35661\n",
      "Train: [epoch:14]  [  20/1149]  eta: 0:20:55  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [  30/1149]  eta: 0:20:21  lr: 0.000200  loss: 0.0016 (0.0019)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [  40/1149]  eta: 0:19:59  lr: 0.000200  loss: 0.0016 (0.0018)  time: 1.0488  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [  50/1149]  eta: 0:19:39  lr: 0.000200  loss: 0.0016 (0.0019)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [  60/1149]  eta: 0:19:22  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [  70/1149]  eta: 0:19:07  lr: 0.000200  loss: 0.0024 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [  80/1149]  eta: 0:18:54  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [  90/1149]  eta: 0:18:41  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0431  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [ 100/1149]  eta: 0:18:29  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 110/1149]  eta: 0:18:16  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0372  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 120/1149]  eta: 0:18:04  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0377  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 130/1149]  eta: 0:17:52  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0377  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 140/1149]  eta: 0:17:40  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0346  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 150/1149]  eta: 0:17:29  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0371  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 160/1149]  eta: 0:17:18  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 170/1149]  eta: 0:17:07  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 180/1149]  eta: 0:16:56  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0360  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 190/1149]  eta: 0:16:44  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0318  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 200/1149]  eta: 0:16:33  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0326  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 210/1149]  eta: 0:16:22  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0299  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 220/1149]  eta: 0:16:11  lr: 0.000200  loss: 0.0016 (0.0022)  time: 1.0379  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 230/1149]  eta: 0:16:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 240/1149]  eta: 0:15:50  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0346  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 250/1149]  eta: 0:15:39  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 260/1149]  eta: 0:15:29  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 270/1149]  eta: 0:15:18  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 280/1149]  eta: 0:15:08  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 290/1149]  eta: 0:14:57  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 300/1149]  eta: 0:14:46  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 310/1149]  eta: 0:14:36  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 320/1149]  eta: 0:14:25  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 330/1149]  eta: 0:14:15  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 340/1149]  eta: 0:14:05  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 350/1149]  eta: 0:13:54  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0348  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 360/1149]  eta: 0:13:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 370/1149]  eta: 0:13:33  lr: 0.000200  loss: 0.0025 (0.0021)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 380/1149]  eta: 0:13:22  lr: 0.000200  loss: 0.0026 (0.0022)  time: 1.0341  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 390/1149]  eta: 0:13:12  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0320  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 400/1149]  eta: 0:13:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 410/1149]  eta: 0:12:51  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 420/1149]  eta: 0:12:40  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 430/1149]  eta: 0:12:30  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 440/1149]  eta: 0:12:19  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 450/1149]  eta: 0:12:09  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 460/1149]  eta: 0:11:58  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 470/1149]  eta: 0:11:48  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 480/1149]  eta: 0:11:37  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0326  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 490/1149]  eta: 0:11:27  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0329  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 500/1149]  eta: 0:11:16  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0367  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 510/1149]  eta: 0:11:06  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0350  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 520/1149]  eta: 0:10:55  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0344  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 530/1149]  eta: 0:10:45  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0370  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 540/1149]  eta: 0:10:34  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 550/1149]  eta: 0:10:24  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 560/1149]  eta: 0:10:13  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 570/1149]  eta: 0:10:03  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 580/1149]  eta: 0:09:53  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 590/1149]  eta: 0:09:42  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 600/1149]  eta: 0:09:32  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 610/1149]  eta: 0:09:21  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 620/1149]  eta: 0:09:11  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 630/1149]  eta: 0:09:00  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0305  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 640/1149]  eta: 0:08:50  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0317  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 650/1149]  eta: 0:08:39  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 660/1149]  eta: 0:08:29  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 670/1149]  eta: 0:08:19  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 680/1149]  eta: 0:08:08  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 690/1149]  eta: 0:07:58  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 700/1149]  eta: 0:07:47  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0480  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 710/1149]  eta: 0:07:37  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 720/1149]  eta: 0:07:27  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 730/1149]  eta: 0:07:16  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 740/1149]  eta: 0:07:06  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 750/1149]  eta: 0:06:55  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0389  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [ 760/1149]  eta: 0:06:45  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 770/1149]  eta: 0:06:34  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 780/1149]  eta: 0:06:24  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 790/1149]  eta: 0:06:14  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 800/1149]  eta: 0:06:03  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 810/1149]  eta: 0:05:53  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 820/1149]  eta: 0:05:42  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 830/1149]  eta: 0:05:32  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 840/1149]  eta: 0:05:21  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 850/1149]  eta: 0:05:11  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 860/1149]  eta: 0:05:01  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0355  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 870/1149]  eta: 0:04:50  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 880/1149]  eta: 0:04:40  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 890/1149]  eta: 0:04:29  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 900/1149]  eta: 0:04:19  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0496  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 910/1149]  eta: 0:04:09  lr: 0.000200  loss: 0.0013 (0.0021)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 920/1149]  eta: 0:03:58  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 930/1149]  eta: 0:03:48  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 940/1149]  eta: 0:03:37  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 950/1149]  eta: 0:03:27  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 960/1149]  eta: 0:03:16  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 970/1149]  eta: 0:03:06  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 980/1149]  eta: 0:02:56  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [ 990/1149]  eta: 0:02:45  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0457  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:14]  [1000/1149]  eta: 0:02:35  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0456  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:14]  [1010/1149]  eta: 0:02:24  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1020/1149]  eta: 0:02:14  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1030/1149]  eta: 0:02:04  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0368  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1040/1149]  eta: 0:01:53  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1050/1149]  eta: 0:01:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1060/1149]  eta: 0:01:32  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1070/1149]  eta: 0:01:22  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0387  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1080/1149]  eta: 0:01:11  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1090/1149]  eta: 0:01:01  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0484  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1100/1149]  eta: 0:00:51  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1110/1149]  eta: 0:00:40  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0362  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1120/1149]  eta: 0:00:30  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1130/1149]  eta: 0:00:19  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:14]  [1140/1149]  eta: 0:00:09  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0425  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:14]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0419  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:14] Total time: 0:19:57 (1.0425 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0021)\n",
      "Valid: [epoch:14]  [ 0/14]  eta: 0:00:54  loss: 0.0024 (0.0024)  time: 3.9180  data: 0.6867  max mem: 35661\n",
      "Valid: [epoch:14]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.2028  data: 0.0492  max mem: 35661\n",
      "Valid: [epoch:14] Total time: 0:00:45 (3.2189 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_14_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:15]  [   0/1149]  eta: 0:40:18  lr: 0.000200  loss: 0.0046 (0.0046)  time: 2.1052  data: 0.9972  max mem: 35661\n",
      "Train: [epoch:15]  [  10/1149]  eta: 0:21:25  lr: 0.000200  loss: 0.0029 (0.0029)  time: 1.1288  data: 0.0908  max mem: 35661\n",
      "Train: [epoch:15]  [  20/1149]  eta: 0:20:30  lr: 0.000200  loss: 0.0015 (0.0023)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [  30/1149]  eta: 0:20:03  lr: 0.000200  loss: 0.0015 (0.0022)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [  40/1149]  eta: 0:19:42  lr: 0.000200  loss: 0.0015 (0.0022)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [  50/1149]  eta: 0:19:25  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [  60/1149]  eta: 0:19:10  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [  70/1149]  eta: 0:18:59  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [  80/1149]  eta: 0:18:44  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0367  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [  90/1149]  eta: 0:18:32  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0314  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 100/1149]  eta: 0:18:21  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 110/1149]  eta: 0:18:10  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 120/1149]  eta: 0:18:00  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0500  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 130/1149]  eta: 0:17:49  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0528  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 140/1149]  eta: 0:17:38  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 150/1149]  eta: 0:17:26  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0365  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 160/1149]  eta: 0:17:16  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0380  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 170/1149]  eta: 0:17:05  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 180/1149]  eta: 0:16:54  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 190/1149]  eta: 0:16:43  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 200/1149]  eta: 0:16:33  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0441  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [ 210/1149]  eta: 0:16:22  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 220/1149]  eta: 0:16:11  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 230/1149]  eta: 0:16:01  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0372  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 240/1149]  eta: 0:15:50  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0379  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 250/1149]  eta: 0:15:39  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 260/1149]  eta: 0:15:29  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 270/1149]  eta: 0:15:18  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 280/1149]  eta: 0:15:08  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 290/1149]  eta: 0:14:57  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 300/1149]  eta: 0:14:47  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 310/1149]  eta: 0:14:36  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 320/1149]  eta: 0:14:26  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 330/1149]  eta: 0:14:15  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 340/1149]  eta: 0:14:05  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 350/1149]  eta: 0:13:54  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 360/1149]  eta: 0:13:44  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 370/1149]  eta: 0:13:33  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 380/1149]  eta: 0:13:23  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 390/1149]  eta: 0:13:12  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 400/1149]  eta: 0:13:02  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 410/1149]  eta: 0:12:51  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 420/1149]  eta: 0:12:41  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0369  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 430/1149]  eta: 0:12:30  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 440/1149]  eta: 0:12:20  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0495  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 450/1149]  eta: 0:12:09  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 460/1149]  eta: 0:11:59  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0433  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:15]  [ 470/1149]  eta: 0:11:49  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 480/1149]  eta: 0:11:38  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0371  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 490/1149]  eta: 0:11:27  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 500/1149]  eta: 0:11:17  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 510/1149]  eta: 0:11:07  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 520/1149]  eta: 0:10:56  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0377  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 530/1149]  eta: 0:10:46  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0344  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 540/1149]  eta: 0:10:35  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 550/1149]  eta: 0:10:25  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0480  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 560/1149]  eta: 0:10:14  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 570/1149]  eta: 0:10:04  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 580/1149]  eta: 0:09:53  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 590/1149]  eta: 0:09:43  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0466  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 600/1149]  eta: 0:09:32  lr: 0.000200  loss: 0.0013 (0.0021)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 610/1149]  eta: 0:09:22  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 620/1149]  eta: 0:09:12  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 630/1149]  eta: 0:09:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0349  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 640/1149]  eta: 0:08:51  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 650/1149]  eta: 0:08:40  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 660/1149]  eta: 0:08:30  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 670/1149]  eta: 0:08:19  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 680/1149]  eta: 0:08:09  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0324  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 690/1149]  eta: 0:07:58  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0338  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 700/1149]  eta: 0:07:48  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 710/1149]  eta: 0:07:37  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 720/1149]  eta: 0:07:27  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 730/1149]  eta: 0:07:17  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 740/1149]  eta: 0:07:06  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0427  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:15]  [ 750/1149]  eta: 0:06:56  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0412  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:15]  [ 760/1149]  eta: 0:06:45  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 770/1149]  eta: 0:06:35  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 780/1149]  eta: 0:06:24  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 790/1149]  eta: 0:06:14  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 800/1149]  eta: 0:06:03  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 810/1149]  eta: 0:05:53  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 820/1149]  eta: 0:05:43  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 830/1149]  eta: 0:05:32  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 840/1149]  eta: 0:05:22  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 850/1149]  eta: 0:05:11  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 860/1149]  eta: 0:05:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0398  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [ 870/1149]  eta: 0:04:50  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 880/1149]  eta: 0:04:40  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 890/1149]  eta: 0:04:30  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 900/1149]  eta: 0:04:19  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 910/1149]  eta: 0:04:09  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 920/1149]  eta: 0:03:58  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 930/1149]  eta: 0:03:48  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 940/1149]  eta: 0:03:37  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 950/1149]  eta: 0:03:27  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 960/1149]  eta: 0:03:17  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 970/1149]  eta: 0:03:06  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 980/1149]  eta: 0:02:56  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [ 990/1149]  eta: 0:02:45  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1000/1149]  eta: 0:02:35  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1010/1149]  eta: 0:02:24  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0359  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1020/1149]  eta: 0:02:14  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1030/1149]  eta: 0:02:04  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0519  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1040/1149]  eta: 0:01:53  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0485  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:15]  [1050/1149]  eta: 0:01:43  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1060/1149]  eta: 0:01:32  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1070/1149]  eta: 0:01:22  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1080/1149]  eta: 0:01:11  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1090/1149]  eta: 0:01:01  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0533  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1100/1149]  eta: 0:00:51  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1110/1149]  eta: 0:00:40  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1120/1149]  eta: 0:00:30  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0367  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1130/1149]  eta: 0:00:19  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0396  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:15]  [1140/1149]  eta: 0:00:09  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:15] Total time: 0:19:58 (1.0432 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0021)\n",
      "Valid: [epoch:15]  [ 0/14]  eta: 0:00:54  loss: 0.0007 (0.0007)  time: 3.8777  data: 0.6866  max mem: 35661\n",
      "Valid: [epoch:15]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.3263  data: 0.0492  max mem: 35661\n",
      "Valid: [epoch:15] Total time: 0:00:46 (3.3425 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_15_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:16]  [   0/1149]  eta: 0:45:24  lr: 0.000200  loss: 0.0023 (0.0023)  time: 2.3716  data: 1.2610  max mem: 35661\n",
      "Train: [epoch:16]  [  10/1149]  eta: 0:22:00  lr: 0.000200  loss: 0.0017 (0.0018)  time: 1.1597  data: 0.1148  max mem: 35661\n",
      "Train: [epoch:16]  [  20/1149]  eta: 0:20:48  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [  30/1149]  eta: 0:20:14  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [  40/1149]  eta: 0:19:51  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [  50/1149]  eta: 0:19:32  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [  60/1149]  eta: 0:19:16  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0352  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [  70/1149]  eta: 0:19:02  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [  80/1149]  eta: 0:18:49  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [  90/1149]  eta: 0:18:37  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 100/1149]  eta: 0:18:25  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 110/1149]  eta: 0:18:11  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0321  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 120/1149]  eta: 0:18:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0323  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 130/1149]  eta: 0:17:48  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0361  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 140/1149]  eta: 0:17:38  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 150/1149]  eta: 0:17:27  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0513  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 160/1149]  eta: 0:17:17  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 170/1149]  eta: 0:17:05  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 180/1149]  eta: 0:16:55  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0376  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 190/1149]  eta: 0:16:44  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 200/1149]  eta: 0:16:33  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 210/1149]  eta: 0:16:22  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 220/1149]  eta: 0:16:12  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 230/1149]  eta: 0:16:01  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 240/1149]  eta: 0:15:51  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 250/1149]  eta: 0:15:40  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 260/1149]  eta: 0:15:29  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 270/1149]  eta: 0:15:18  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0356  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 280/1149]  eta: 0:15:08  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 290/1149]  eta: 0:14:57  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 300/1149]  eta: 0:14:47  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 310/1149]  eta: 0:14:36  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [ 320/1149]  eta: 0:14:26  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 330/1149]  eta: 0:14:15  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 340/1149]  eta: 0:14:05  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 350/1149]  eta: 0:13:54  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 360/1149]  eta: 0:13:44  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 370/1149]  eta: 0:13:33  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 380/1149]  eta: 0:13:23  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 390/1149]  eta: 0:13:13  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0495  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:16]  [ 400/1149]  eta: 0:13:02  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0427  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:16]  [ 410/1149]  eta: 0:12:51  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0373  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 420/1149]  eta: 0:12:41  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 430/1149]  eta: 0:12:30  lr: 0.000200  loss: 0.0013 (0.0021)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 440/1149]  eta: 0:12:20  lr: 0.000200  loss: 0.0012 (0.0020)  time: 1.0429  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:16]  [ 450/1149]  eta: 0:12:10  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0439  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 460/1149]  eta: 0:11:59  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0349  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 470/1149]  eta: 0:11:48  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0318  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 480/1149]  eta: 0:11:38  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0377  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 490/1149]  eta: 0:11:27  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 500/1149]  eta: 0:11:17  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0455  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:16]  [ 510/1149]  eta: 0:11:06  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0418  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 520/1149]  eta: 0:10:56  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 530/1149]  eta: 0:10:46  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 540/1149]  eta: 0:10:35  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0467  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:16]  [ 550/1149]  eta: 0:10:25  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 560/1149]  eta: 0:10:14  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 570/1149]  eta: 0:10:04  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 580/1149]  eta: 0:09:53  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 590/1149]  eta: 0:09:43  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 600/1149]  eta: 0:09:33  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 610/1149]  eta: 0:09:22  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 620/1149]  eta: 0:09:12  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 630/1149]  eta: 0:09:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 640/1149]  eta: 0:08:51  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0459  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 650/1149]  eta: 0:08:40  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 660/1149]  eta: 0:08:30  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 670/1149]  eta: 0:08:19  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 680/1149]  eta: 0:08:09  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 690/1149]  eta: 0:07:59  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 700/1149]  eta: 0:07:48  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 710/1149]  eta: 0:07:38  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0495  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:16]  [ 720/1149]  eta: 0:07:27  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 730/1149]  eta: 0:07:17  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 740/1149]  eta: 0:07:06  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 750/1149]  eta: 0:06:56  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 760/1149]  eta: 0:06:46  lr: 0.000200  loss: 0.0013 (0.0021)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 770/1149]  eta: 0:06:35  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 780/1149]  eta: 0:06:25  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 790/1149]  eta: 0:06:14  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0507  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 800/1149]  eta: 0:06:04  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 810/1149]  eta: 0:05:53  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 820/1149]  eta: 0:05:43  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 830/1149]  eta: 0:05:33  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 840/1149]  eta: 0:05:22  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 850/1149]  eta: 0:05:12  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 860/1149]  eta: 0:05:01  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 870/1149]  eta: 0:04:51  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 880/1149]  eta: 0:04:40  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 890/1149]  eta: 0:04:30  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0396  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:16]  [ 900/1149]  eta: 0:04:19  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 910/1149]  eta: 0:04:09  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 920/1149]  eta: 0:03:58  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 930/1149]  eta: 0:03:48  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 940/1149]  eta: 0:03:38  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 950/1149]  eta: 0:03:27  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 960/1149]  eta: 0:03:17  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0334  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 970/1149]  eta: 0:03:06  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0362  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [ 980/1149]  eta: 0:02:56  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [ 990/1149]  eta: 0:02:45  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1000/1149]  eta: 0:02:35  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1010/1149]  eta: 0:02:25  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1020/1149]  eta: 0:02:14  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0380  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1030/1149]  eta: 0:02:04  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1040/1149]  eta: 0:01:53  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1050/1149]  eta: 0:01:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1060/1149]  eta: 0:01:32  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1070/1149]  eta: 0:01:22  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1080/1149]  eta: 0:01:11  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0365  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:16]  [1090/1149]  eta: 0:01:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1100/1149]  eta: 0:00:51  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1110/1149]  eta: 0:00:40  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0388  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1120/1149]  eta: 0:00:30  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1130/1149]  eta: 0:00:19  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1140/1149]  eta: 0:00:09  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0477  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0498  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:16] Total time: 0:19:58 (1.0435 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0016 (0.0021)\n",
      "Valid: [epoch:16]  [ 0/14]  eta: 0:01:01  loss: 0.0007 (0.0007)  time: 4.4240  data: 0.6816  max mem: 35661\n",
      "Valid: [epoch:16]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.3841  data: 0.0488  max mem: 35661\n",
      "Valid: [epoch:16] Total time: 0:00:47 (3.4022 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_16_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:17]  [   0/1149]  eta: 0:42:24  lr: 0.000200  loss: 0.0015 (0.0015)  time: 2.2142  data: 1.0986  max mem: 35661\n",
      "Train: [epoch:17]  [  10/1149]  eta: 0:21:46  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.1470  data: 0.1000  max mem: 35661\n",
      "Train: [epoch:17]  [  20/1149]  eta: 0:20:37  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [  30/1149]  eta: 0:20:05  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0387  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [  40/1149]  eta: 0:19:47  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [  50/1149]  eta: 0:19:32  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0501  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [  60/1149]  eta: 0:19:15  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [  70/1149]  eta: 0:19:01  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0351  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [  80/1149]  eta: 0:18:49  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [  90/1149]  eta: 0:18:38  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0512  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 100/1149]  eta: 0:18:26  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 110/1149]  eta: 0:18:14  lr: 0.000200  loss: 0.0016 (0.0022)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 120/1149]  eta: 0:18:04  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0473  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 130/1149]  eta: 0:17:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0471  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 140/1149]  eta: 0:17:42  lr: 0.000200  loss: 0.0016 (0.0022)  time: 1.0477  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 150/1149]  eta: 0:17:30  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0465  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 160/1149]  eta: 0:17:19  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0427  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 170/1149]  eta: 0:17:08  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 180/1149]  eta: 0:16:57  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 190/1149]  eta: 0:16:47  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0490  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 200/1149]  eta: 0:16:36  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0532  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 210/1149]  eta: 0:16:26  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 220/1149]  eta: 0:16:15  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 230/1149]  eta: 0:16:04  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 240/1149]  eta: 0:15:53  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 250/1149]  eta: 0:15:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0531  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 260/1149]  eta: 0:15:32  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 270/1149]  eta: 0:15:21  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0387  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 280/1149]  eta: 0:15:11  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 290/1149]  eta: 0:15:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 300/1149]  eta: 0:14:49  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 310/1149]  eta: 0:14:39  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 320/1149]  eta: 0:14:28  lr: 0.000200  loss: 0.0026 (0.0023)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 330/1149]  eta: 0:14:18  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 340/1149]  eta: 0:14:07  lr: 0.000200  loss: 0.0017 (0.0023)  time: 1.0495  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 350/1149]  eta: 0:13:57  lr: 0.000200  loss: 0.0017 (0.0023)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 360/1149]  eta: 0:13:46  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0481  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 370/1149]  eta: 0:13:36  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0501  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 380/1149]  eta: 0:13:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 390/1149]  eta: 0:13:15  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 400/1149]  eta: 0:13:04  lr: 0.000200  loss: 0.0015 (0.0022)  time: 1.0470  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 410/1149]  eta: 0:12:54  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 420/1149]  eta: 0:12:43  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0428  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [ 430/1149]  eta: 0:12:32  lr: 0.000200  loss: 0.0015 (0.0022)  time: 1.0391  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 440/1149]  eta: 0:12:22  lr: 0.000200  loss: 0.0015 (0.0022)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 450/1149]  eta: 0:12:11  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 460/1149]  eta: 0:12:01  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 470/1149]  eta: 0:11:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 480/1149]  eta: 0:11:40  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 490/1149]  eta: 0:11:30  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 500/1149]  eta: 0:11:19  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 510/1149]  eta: 0:11:08  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 520/1149]  eta: 0:10:58  lr: 0.000200  loss: 0.0014 (0.0022)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 530/1149]  eta: 0:10:47  lr: 0.000200  loss: 0.0015 (0.0022)  time: 1.0368  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 540/1149]  eta: 0:10:37  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0361  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 550/1149]  eta: 0:10:26  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 560/1149]  eta: 0:10:16  lr: 0.000200  loss: 0.0016 (0.0022)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 570/1149]  eta: 0:10:05  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 580/1149]  eta: 0:09:55  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0382  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 590/1149]  eta: 0:09:44  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 600/1149]  eta: 0:09:34  lr: 0.000200  loss: 0.0016 (0.0022)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 610/1149]  eta: 0:09:23  lr: 0.000200  loss: 0.0014 (0.0022)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 620/1149]  eta: 0:09:13  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 630/1149]  eta: 0:09:02  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 640/1149]  eta: 0:08:52  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 650/1149]  eta: 0:08:41  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0511  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 660/1149]  eta: 0:08:31  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 670/1149]  eta: 0:08:20  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 680/1149]  eta: 0:08:10  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 690/1149]  eta: 0:07:59  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 700/1149]  eta: 0:07:49  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 710/1149]  eta: 0:07:39  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 720/1149]  eta: 0:07:28  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 730/1149]  eta: 0:07:18  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 740/1149]  eta: 0:07:07  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 750/1149]  eta: 0:06:57  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0516  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 760/1149]  eta: 0:06:46  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0515  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 770/1149]  eta: 0:06:36  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 780/1149]  eta: 0:06:25  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 790/1149]  eta: 0:06:15  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0362  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 800/1149]  eta: 0:06:04  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0430  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 810/1149]  eta: 0:05:54  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0500  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 820/1149]  eta: 0:05:43  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0403  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 830/1149]  eta: 0:05:33  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0339  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 840/1149]  eta: 0:05:22  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 850/1149]  eta: 0:05:12  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0502  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 860/1149]  eta: 0:05:02  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0442  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 870/1149]  eta: 0:04:51  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0389  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:17]  [ 880/1149]  eta: 0:04:41  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0440  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 890/1149]  eta: 0:04:30  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 900/1149]  eta: 0:04:20  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0379  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 910/1149]  eta: 0:04:09  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 920/1149]  eta: 0:03:59  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 930/1149]  eta: 0:03:48  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 940/1149]  eta: 0:03:38  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0369  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 950/1149]  eta: 0:03:27  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0383  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 960/1149]  eta: 0:03:17  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 970/1149]  eta: 0:03:06  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 980/1149]  eta: 0:02:56  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [ 990/1149]  eta: 0:02:46  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1000/1149]  eta: 0:02:35  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0444  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1010/1149]  eta: 0:02:25  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1020/1149]  eta: 0:02:14  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0373  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1030/1149]  eta: 0:02:04  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1040/1149]  eta: 0:01:53  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1050/1149]  eta: 0:01:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1060/1149]  eta: 0:01:32  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1070/1149]  eta: 0:01:22  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1080/1149]  eta: 0:01:12  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0373  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [1090/1149]  eta: 0:01:01  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0381  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1100/1149]  eta: 0:00:51  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0484  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1110/1149]  eta: 0:00:40  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1120/1149]  eta: 0:00:30  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1130/1149]  eta: 0:00:19  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1140/1149]  eta: 0:00:09  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0378  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0381  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:17] Total time: 0:20:00 (1.0444 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0016 (0.0021)\n",
      "Valid: [epoch:17]  [ 0/14]  eta: 0:00:53  loss: 0.0024 (0.0024)  time: 3.8421  data: 0.7408  max mem: 35661\n",
      "Valid: [epoch:17]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.1489  data: 0.0530  max mem: 35661\n",
      "Valid: [epoch:17] Total time: 0:00:44 (3.1647 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_17_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:18]  [   0/1149]  eta: 0:57:19  lr: 0.000200  loss: 0.0030 (0.0030)  time: 2.9933  data: 1.9023  max mem: 35661\n",
      "Train: [epoch:18]  [  10/1149]  eta: 0:23:01  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.2128  data: 0.1731  max mem: 35661\n",
      "Train: [epoch:18]  [  20/1149]  eta: 0:21:15  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0370  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [  30/1149]  eta: 0:20:31  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0385  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [  40/1149]  eta: 0:20:05  lr: 0.000200  loss: 0.0014 (0.0019)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [  50/1149]  eta: 0:19:45  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0448  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [  60/1149]  eta: 0:19:27  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0429  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [  70/1149]  eta: 0:19:12  lr: 0.000200  loss: 0.0014 (0.0019)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [  80/1149]  eta: 0:18:59  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [  90/1149]  eta: 0:18:46  lr: 0.000200  loss: 0.0021 (0.0020)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 100/1149]  eta: 0:18:33  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 110/1149]  eta: 0:18:20  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 120/1149]  eta: 0:18:08  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0384  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 130/1149]  eta: 0:17:57  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 140/1149]  eta: 0:17:46  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0501  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 150/1149]  eta: 0:17:34  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0477  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 160/1149]  eta: 0:17:22  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0356  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 170/1149]  eta: 0:17:11  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0338  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 180/1149]  eta: 0:16:59  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 190/1149]  eta: 0:16:48  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 200/1149]  eta: 0:16:37  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 210/1149]  eta: 0:16:27  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 220/1149]  eta: 0:16:16  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 230/1149]  eta: 0:16:05  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 240/1149]  eta: 0:15:54  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 250/1149]  eta: 0:15:43  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 260/1149]  eta: 0:15:33  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0432  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 270/1149]  eta: 0:15:22  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 280/1149]  eta: 0:15:11  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0420  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 290/1149]  eta: 0:15:00  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 300/1149]  eta: 0:14:50  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 310/1149]  eta: 0:14:39  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 320/1149]  eta: 0:14:29  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 330/1149]  eta: 0:14:18  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 340/1149]  eta: 0:14:07  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 350/1149]  eta: 0:13:57  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0455  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 360/1149]  eta: 0:13:46  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 370/1149]  eta: 0:13:35  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 380/1149]  eta: 0:13:25  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0376  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 390/1149]  eta: 0:13:14  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 400/1149]  eta: 0:13:04  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0433  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 410/1149]  eta: 0:12:53  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 420/1149]  eta: 0:12:42  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 430/1149]  eta: 0:12:32  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0358  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 440/1149]  eta: 0:12:21  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 450/1149]  eta: 0:12:11  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0493  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 460/1149]  eta: 0:12:00  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0491  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 470/1149]  eta: 0:11:50  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 480/1149]  eta: 0:11:39  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 490/1149]  eta: 0:11:29  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 500/1149]  eta: 0:11:19  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0497  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 510/1149]  eta: 0:11:08  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 520/1149]  eta: 0:10:57  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0365  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 530/1149]  eta: 0:10:47  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [ 540/1149]  eta: 0:10:37  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0494  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 550/1149]  eta: 0:10:26  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 560/1149]  eta: 0:10:16  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 570/1149]  eta: 0:10:05  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 580/1149]  eta: 0:09:55  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0496  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 590/1149]  eta: 0:09:44  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 600/1149]  eta: 0:09:34  lr: 0.000200  loss: 0.0013 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 610/1149]  eta: 0:09:23  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 620/1149]  eta: 0:09:13  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 630/1149]  eta: 0:09:02  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0477  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 640/1149]  eta: 0:08:52  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 650/1149]  eta: 0:08:41  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 660/1149]  eta: 0:08:31  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0405  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 670/1149]  eta: 0:08:21  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0487  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 680/1149]  eta: 0:08:10  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0509  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 690/1149]  eta: 0:08:00  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 700/1149]  eta: 0:07:49  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0442  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 710/1149]  eta: 0:07:39  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 720/1149]  eta: 0:07:28  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0500  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 730/1149]  eta: 0:07:18  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0548  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 740/1149]  eta: 0:07:07  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0473  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 750/1149]  eta: 0:06:57  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 760/1149]  eta: 0:06:46  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 770/1149]  eta: 0:06:36  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0365  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 780/1149]  eta: 0:06:25  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0390  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 790/1149]  eta: 0:06:15  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0437  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:18]  [ 800/1149]  eta: 0:06:04  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 810/1149]  eta: 0:05:54  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 820/1149]  eta: 0:05:44  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 830/1149]  eta: 0:05:33  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0480  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 840/1149]  eta: 0:05:23  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 850/1149]  eta: 0:05:12  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0336  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 860/1149]  eta: 0:05:02  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0362  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 870/1149]  eta: 0:04:51  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 880/1149]  eta: 0:04:41  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 890/1149]  eta: 0:04:30  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0487  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 900/1149]  eta: 0:04:20  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 910/1149]  eta: 0:04:09  lr: 0.000200  loss: 0.0013 (0.0020)  time: 1.0471  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 920/1149]  eta: 0:03:59  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 930/1149]  eta: 0:03:48  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 940/1149]  eta: 0:03:38  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0415  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 950/1149]  eta: 0:03:27  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0389  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 960/1149]  eta: 0:03:17  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0430  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 970/1149]  eta: 0:03:07  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 980/1149]  eta: 0:02:56  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [ 990/1149]  eta: 0:02:46  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1000/1149]  eta: 0:02:35  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0352  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1010/1149]  eta: 0:02:25  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1020/1149]  eta: 0:02:14  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0476  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1030/1149]  eta: 0:02:04  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1040/1149]  eta: 0:01:53  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0352  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1050/1149]  eta: 0:01:43  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1060/1149]  eta: 0:01:32  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0460  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1070/1149]  eta: 0:01:22  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0429  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:18]  [1080/1149]  eta: 0:01:12  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0454  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:18]  [1090/1149]  eta: 0:01:01  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0395  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1100/1149]  eta: 0:00:51  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1110/1149]  eta: 0:00:40  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1120/1149]  eta: 0:00:30  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1130/1149]  eta: 0:00:19  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1140/1149]  eta: 0:00:09  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:18] Total time: 0:20:00 (1.0450 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0016 (0.0021)\n",
      "Valid: [epoch:18]  [ 0/14]  eta: 0:00:57  loss: 0.0022 (0.0022)  time: 4.1236  data: 0.6661  max mem: 35661\n",
      "Valid: [epoch:18]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.2931  data: 0.0477  max mem: 35661\n",
      "Valid: [epoch:18] Total time: 0:00:46 (3.3090 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_18_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:19]  [   0/1149]  eta: 1:01:23  lr: 0.000200  loss: 0.0020 (0.0020)  time: 3.2057  data: 2.1119  max mem: 35661\n",
      "Train: [epoch:19]  [  10/1149]  eta: 0:23:43  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.2496  data: 0.1921  max mem: 35661\n",
      "Train: [epoch:19]  [  20/1149]  eta: 0:21:48  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0564  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [  30/1149]  eta: 0:20:54  lr: 0.000200  loss: 0.0014 (0.0019)  time: 1.0500  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [  40/1149]  eta: 0:20:23  lr: 0.000200  loss: 0.0014 (0.0018)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [  50/1149]  eta: 0:20:02  lr: 0.000200  loss: 0.0016 (0.0018)  time: 1.0522  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [  60/1149]  eta: 0:19:42  lr: 0.000200  loss: 0.0018 (0.0018)  time: 1.0509  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [  70/1149]  eta: 0:19:24  lr: 0.000200  loss: 0.0017 (0.0018)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [  80/1149]  eta: 0:19:09  lr: 0.000200  loss: 0.0019 (0.0018)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [  90/1149]  eta: 0:18:56  lr: 0.000200  loss: 0.0019 (0.0018)  time: 1.0494  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 100/1149]  eta: 0:18:43  lr: 0.000200  loss: 0.0018 (0.0019)  time: 1.0533  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 110/1149]  eta: 0:18:30  lr: 0.000200  loss: 0.0018 (0.0019)  time: 1.0512  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 120/1149]  eta: 0:18:17  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 130/1149]  eta: 0:18:06  lr: 0.000200  loss: 0.0016 (0.0019)  time: 1.0489  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 140/1149]  eta: 0:17:55  lr: 0.000200  loss: 0.0016 (0.0019)  time: 1.0619  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 150/1149]  eta: 0:17:43  lr: 0.000200  loss: 0.0019 (0.0019)  time: 1.0536  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 160/1149]  eta: 0:17:31  lr: 0.000200  loss: 0.0018 (0.0019)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 170/1149]  eta: 0:17:19  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0408  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 180/1149]  eta: 0:17:07  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0413  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 190/1149]  eta: 0:16:56  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0480  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 200/1149]  eta: 0:16:45  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0447  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 210/1149]  eta: 0:16:34  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 220/1149]  eta: 0:16:22  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 230/1149]  eta: 0:16:11  lr: 0.000200  loss: 0.0023 (0.0020)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 240/1149]  eta: 0:16:00  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 250/1149]  eta: 0:15:49  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0524  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 260/1149]  eta: 0:15:38  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 270/1149]  eta: 0:15:27  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0422  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:19]  [ 280/1149]  eta: 0:15:17  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0450  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:19]  [ 290/1149]  eta: 0:15:06  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0505  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 300/1149]  eta: 0:14:55  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0497  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 310/1149]  eta: 0:14:44  lr: 0.000200  loss: 0.0021 (0.0020)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 320/1149]  eta: 0:14:33  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0426  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 330/1149]  eta: 0:14:23  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 340/1149]  eta: 0:14:12  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0462  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 350/1149]  eta: 0:14:01  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0519  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 360/1149]  eta: 0:13:51  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0524  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 370/1149]  eta: 0:13:40  lr: 0.000200  loss: 0.0014 (0.0020)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 380/1149]  eta: 0:13:30  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0489  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 390/1149]  eta: 0:13:19  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 400/1149]  eta: 0:13:08  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 410/1149]  eta: 0:12:57  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0498  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 420/1149]  eta: 0:12:47  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 430/1149]  eta: 0:12:36  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0480  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 440/1149]  eta: 0:12:26  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0503  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 450/1149]  eta: 0:12:15  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0460  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 460/1149]  eta: 0:12:04  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0475  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 470/1149]  eta: 0:11:54  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0486  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 480/1149]  eta: 0:11:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0504  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 490/1149]  eta: 0:11:33  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0495  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 500/1149]  eta: 0:11:22  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0442  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 510/1149]  eta: 0:11:11  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0412  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 520/1149]  eta: 0:11:01  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0483  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 530/1149]  eta: 0:10:50  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0540  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 540/1149]  eta: 0:10:40  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0514  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 550/1149]  eta: 0:10:29  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0474  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 560/1149]  eta: 0:10:19  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 570/1149]  eta: 0:10:08  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0490  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 580/1149]  eta: 0:09:58  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0540  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 590/1149]  eta: 0:09:47  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 600/1149]  eta: 0:09:37  lr: 0.000200  loss: 0.0014 (0.0020)  time: 1.0464  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 610/1149]  eta: 0:09:26  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 620/1149]  eta: 0:09:15  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 630/1149]  eta: 0:09:05  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0406  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 640/1149]  eta: 0:08:54  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0434  data: 0.0002  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:19]  [ 650/1149]  eta: 0:08:44  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 660/1149]  eta: 0:08:33  lr: 0.000200  loss: 0.0022 (0.0020)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 670/1149]  eta: 0:08:23  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0489  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 680/1149]  eta: 0:08:12  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0462  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 690/1149]  eta: 0:08:02  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0375  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 700/1149]  eta: 0:07:51  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0402  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 710/1149]  eta: 0:07:40  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0438  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 720/1149]  eta: 0:07:30  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0474  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 730/1149]  eta: 0:07:19  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0518  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 740/1149]  eta: 0:07:09  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 750/1149]  eta: 0:06:58  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 760/1149]  eta: 0:06:48  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0382  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 770/1149]  eta: 0:06:37  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0457  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 780/1149]  eta: 0:06:27  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0493  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 790/1149]  eta: 0:06:16  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 800/1149]  eta: 0:06:06  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 810/1149]  eta: 0:05:55  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0379  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 820/1149]  eta: 0:05:45  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0352  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 830/1149]  eta: 0:05:34  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0422  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 840/1149]  eta: 0:05:24  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 850/1149]  eta: 0:05:13  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0417  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 860/1149]  eta: 0:05:03  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 870/1149]  eta: 0:04:52  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0475  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 880/1149]  eta: 0:04:42  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0432  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 890/1149]  eta: 0:04:31  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0420  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 900/1149]  eta: 0:04:21  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 910/1149]  eta: 0:04:10  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0445  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 920/1149]  eta: 0:04:00  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 930/1149]  eta: 0:03:49  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0424  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 940/1149]  eta: 0:03:39  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0469  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 950/1149]  eta: 0:03:28  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 960/1149]  eta: 0:03:18  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 970/1149]  eta: 0:03:07  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0485  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [ 980/1149]  eta: 0:02:57  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0484  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [ 990/1149]  eta: 0:02:46  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0452  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [1000/1149]  eta: 0:02:36  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0468  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [1010/1149]  eta: 0:02:25  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0452  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [1020/1149]  eta: 0:02:15  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0483  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [1030/1149]  eta: 0:02:04  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0438  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [1040/1149]  eta: 0:01:54  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0415  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [1050/1149]  eta: 0:01:43  lr: 0.000200  loss: 0.0024 (0.0021)  time: 1.0443  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [1060/1149]  eta: 0:01:33  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0419  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [1070/1149]  eta: 0:01:22  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0502  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [1080/1149]  eta: 0:01:12  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0472  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:19]  [1090/1149]  eta: 0:01:01  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0371  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [1100/1149]  eta: 0:00:51  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [1110/1149]  eta: 0:00:40  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [1120/1149]  eta: 0:00:30  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0450  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19]  [1130/1149]  eta: 0:00:19  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0473  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:19]  [1140/1149]  eta: 0:00:09  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0436  data: 0.0003  max mem: 35661\n",
      "Train: [epoch:19]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0428  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:19] Total time: 0:20:04 (1.0481 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0017 (0.0021)\n",
      "Valid: [epoch:19]  [ 0/14]  eta: 0:01:01  loss: 0.0022 (0.0022)  time: 4.3908  data: 0.7660  max mem: 35661\n",
      "Valid: [epoch:19]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.4258  data: 0.0549  max mem: 35661\n",
      "Valid: [epoch:19] Total time: 0:00:48 (3.4413 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_19_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:20]  [   0/1149]  eta: 0:54:01  lr: 0.000200  loss: 0.0019 (0.0019)  time: 2.8211  data: 1.7108  max mem: 35661\n",
      "Train: [epoch:20]  [  10/1149]  eta: 0:22:50  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.2034  data: 0.1557  max mem: 35661\n",
      "Train: [epoch:20]  [  20/1149]  eta: 0:21:12  lr: 0.000200  loss: 0.0015 (0.0018)  time: 1.0426  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [  30/1149]  eta: 0:20:31  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [  40/1149]  eta: 0:20:05  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [  50/1149]  eta: 0:19:48  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.0517  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [  60/1149]  eta: 0:19:32  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0543  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [  70/1149]  eta: 0:19:15  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0442  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [  80/1149]  eta: 0:19:02  lr: 0.000200  loss: 0.0015 (0.0020)  time: 1.0451  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [  90/1149]  eta: 0:18:47  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0437  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [ 100/1149]  eta: 0:18:35  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 110/1149]  eta: 0:18:24  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0550  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 120/1149]  eta: 0:18:12  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0515  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 130/1149]  eta: 0:18:00  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0410  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 140/1149]  eta: 0:17:48  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0422  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 150/1149]  eta: 0:17:35  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0374  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 160/1149]  eta: 0:17:25  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0466  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 170/1149]  eta: 0:17:14  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0509  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 180/1149]  eta: 0:17:02  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0387  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 190/1149]  eta: 0:16:50  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0352  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 200/1149]  eta: 0:16:39  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 210/1149]  eta: 0:16:29  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0461  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 220/1149]  eta: 0:16:17  lr: 0.000200  loss: 0.0024 (0.0021)  time: 1.0418  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 230/1149]  eta: 0:16:06  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 240/1149]  eta: 0:15:56  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0431  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 250/1149]  eta: 0:15:45  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0460  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 260/1149]  eta: 0:15:34  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0454  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 270/1149]  eta: 0:15:23  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0453  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 280/1149]  eta: 0:15:13  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 290/1149]  eta: 0:15:02  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0475  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 300/1149]  eta: 0:14:52  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0492  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 310/1149]  eta: 0:14:41  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 320/1149]  eta: 0:14:30  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0402  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 330/1149]  eta: 0:14:19  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0355  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 340/1149]  eta: 0:14:09  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0417  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 350/1149]  eta: 0:13:58  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0518  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 360/1149]  eta: 0:13:48  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0467  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 370/1149]  eta: 0:13:37  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0386  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 380/1149]  eta: 0:13:26  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0423  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 390/1149]  eta: 0:13:16  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0425  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 400/1149]  eta: 0:13:05  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0462  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 410/1149]  eta: 0:12:55  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0498  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 420/1149]  eta: 0:12:44  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0427  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 430/1149]  eta: 0:12:33  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0347  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 440/1149]  eta: 0:12:22  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0248  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 450/1149]  eta: 0:12:12  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0342  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 460/1149]  eta: 0:12:01  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0503  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 470/1149]  eta: 0:11:51  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0463  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 480/1149]  eta: 0:11:40  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0410  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 490/1149]  eta: 0:11:30  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0437  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 500/1149]  eta: 0:11:19  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0553  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 510/1149]  eta: 0:11:09  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0550  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 520/1149]  eta: 0:10:59  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0474  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 530/1149]  eta: 0:10:48  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0508  data: 0.0002  max mem: 35661\n",
      "Train: [epoch:20]  [ 540/1149]  eta: 0:10:38  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0537  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 550/1149]  eta: 0:10:27  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0533  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 560/1149]  eta: 0:10:17  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0490  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 570/1149]  eta: 0:10:06  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 580/1149]  eta: 0:09:56  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 590/1149]  eta: 0:09:45  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0467  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 600/1149]  eta: 0:09:35  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0484  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 610/1149]  eta: 0:09:24  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0456  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 620/1149]  eta: 0:09:14  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0449  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 630/1149]  eta: 0:09:03  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.0397  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 640/1149]  eta: 0:08:53  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0478  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 650/1149]  eta: 0:08:42  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0498  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 660/1149]  eta: 0:08:32  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0401  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 670/1149]  eta: 0:08:21  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0394  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 680/1149]  eta: 0:08:11  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0446  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 690/1149]  eta: 0:08:00  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0483  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 700/1149]  eta: 0:07:50  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0434  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 710/1149]  eta: 0:07:39  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0298  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 720/1149]  eta: 0:07:28  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0197  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 730/1149]  eta: 0:07:18  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0269  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 740/1149]  eta: 0:07:07  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 750/1149]  eta: 0:06:57  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0519  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [ 760/1149]  eta: 0:06:47  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0592  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 770/1149]  eta: 0:06:39  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.3139  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 780/1149]  eta: 0:06:31  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.5754  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 790/1149]  eta: 0:06:20  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.3137  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 800/1149]  eta: 0:06:09  lr: 0.000200  loss: 0.0014 (0.0021)  time: 1.0481  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 810/1149]  eta: 0:05:59  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0417  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 820/1149]  eta: 0:05:48  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0392  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 830/1149]  eta: 0:05:37  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0458  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 840/1149]  eta: 0:05:27  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0436  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 850/1149]  eta: 0:05:16  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0393  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 860/1149]  eta: 0:05:05  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 870/1149]  eta: 0:04:55  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 880/1149]  eta: 0:04:44  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0414  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 890/1149]  eta: 0:04:33  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0396  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 900/1149]  eta: 0:04:23  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0416  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 910/1149]  eta: 0:04:12  lr: 0.000200  loss: 0.0013 (0.0021)  time: 1.0472  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 920/1149]  eta: 0:04:02  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.1832  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 930/1149]  eta: 0:03:54  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.6304  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 940/1149]  eta: 0:03:45  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.9645  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 950/1149]  eta: 0:03:35  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.6276  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 960/1149]  eta: 0:03:26  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.6587  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 970/1149]  eta: 0:03:16  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.9827  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 980/1149]  eta: 0:03:06  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.6202  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [ 990/1149]  eta: 0:02:55  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.1846  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1000/1149]  eta: 0:02:44  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0441  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1010/1149]  eta: 0:02:32  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0375  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1020/1149]  eta: 0:02:23  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.5195  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1030/1149]  eta: 0:02:12  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.7285  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1040/1149]  eta: 0:02:01  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.2461  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1050/1149]  eta: 0:01:50  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.1786  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1060/1149]  eta: 0:01:39  lr: 0.000200  loss: 0.0015 (0.0021)  time: 1.5726  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1070/1149]  eta: 0:01:28  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.4341  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1080/1149]  eta: 0:01:17  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1090/1149]  eta: 0:01:05  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0398  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1100/1149]  eta: 0:00:54  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1110/1149]  eta: 0:00:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0350  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1120/1149]  eta: 0:00:32  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.3095  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1130/1149]  eta: 0:00:21  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.7531  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1140/1149]  eta: 0:00:10  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.8597  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20]  [1148/1149]  eta: 0:00:01  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.9271  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:20] Total time: 0:21:51 (1.1410 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0017 (0.0021)\n",
      "Valid: [epoch:20]  [ 0/14]  eta: 0:00:53  loss: 0.0022 (0.0022)  time: 3.8569  data: 0.7111  max mem: 35661\n",
      "Valid: [epoch:20]  [13/14]  eta: 0:00:03  loss: 0.0014 (0.0016)  time: 3.2184  data: 0.0509  max mem: 35661\n",
      "Valid: [epoch:20] Total time: 0:00:45 (3.2350 s / it)\n",
      "Averaged stats: loss: 0.0014 (0.0016)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/epoch_20_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.001\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:21]  [   0/1149]  eta: 1:02:19  lr: 0.000200  loss: 0.0019 (0.0019)  time: 3.2549  data: 1.1350  max mem: 35661\n",
      "Train: [epoch:21]  [  10/1149]  eta: 0:36:22  lr: 0.000200  loss: 0.0018 (0.0019)  time: 1.9158  data: 0.1033  max mem: 35661\n",
      "Train: [epoch:21]  [  20/1149]  eta: 0:35:14  lr: 0.000200  loss: 0.0017 (0.0017)  time: 1.8039  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [  30/1149]  eta: 0:35:57  lr: 0.000200  loss: 0.0018 (0.0019)  time: 1.9353  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [  40/1149]  eta: 0:34:52  lr: 0.000200  loss: 0.0018 (0.0018)  time: 1.9016  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [  50/1149]  eta: 0:34:18  lr: 0.000200  loss: 0.0015 (0.0019)  time: 1.7877  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [  60/1149]  eta: 0:33:49  lr: 0.000200  loss: 0.0015 (0.0018)  time: 1.8146  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [  70/1149]  eta: 0:33:58  lr: 0.000200  loss: 0.0016 (0.0019)  time: 1.9285  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [  80/1149]  eta: 0:33:29  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.9299  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [  90/1149]  eta: 0:33:02  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.8107  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 100/1149]  eta: 0:32:37  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.8120  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 110/1149]  eta: 0:32:25  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.8761  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 120/1149]  eta: 0:32:11  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.9332  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 130/1149]  eta: 0:31:46  lr: 0.000200  loss: 0.0016 (0.0019)  time: 1.8596  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 140/1149]  eta: 0:31:23  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.8039  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 150/1149]  eta: 0:31:02  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.8262  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 160/1149]  eta: 0:30:52  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.9194  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 170/1149]  eta: 0:30:30  lr: 0.000200  loss: 0.0021 (0.0020)  time: 1.9128  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 180/1149]  eta: 0:30:07  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.8005  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 190/1149]  eta: 0:29:43  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.7738  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 200/1149]  eta: 0:28:46  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.4031  data: 0.0001  max mem: 35661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:21]  [ 210/1149]  eta: 0:27:53  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0400  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 220/1149]  eta: 0:27:03  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.0302  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 230/1149]  eta: 0:26:17  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0239  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 240/1149]  eta: 0:25:34  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0324  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 250/1149]  eta: 0:24:54  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0407  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 260/1149]  eta: 0:24:17  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0435  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 270/1149]  eta: 0:23:41  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 280/1149]  eta: 0:23:07  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.0411  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 290/1149]  eta: 0:22:34  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0324  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 300/1149]  eta: 0:22:03  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0285  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 310/1149]  eta: 0:21:33  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0399  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 320/1149]  eta: 0:21:05  lr: 0.000200  loss: 0.0027 (0.0021)  time: 1.0412  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 330/1149]  eta: 0:20:38  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0421  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 340/1149]  eta: 0:20:11  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0409  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 350/1149]  eta: 0:19:46  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0404  data: 0.0001  max mem: 35661\n",
      "Train: [epoch:21]  [ 360/1149]  eta: 0:19:22  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0426  data: 0.0001  max mem: 35661\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--batch-size 6 \\\n",
    "--epochs 1000 \\\n",
    "--min-lr 5e-6 \\\n",
    "--lr 2e-4 \\\n",
    "--data-set 'Sinogram_DCM' \\\n",
    "--model-name 'WCMT_2D' \\\n",
    "--criterion 'Window Compound Loss' \\\n",
    "--output_dir '/workspace/sunggu/4.Dose_img2img/model/[Ours]WCMT_2D' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]WCMT_2D/low2high/' \\\n",
    "--validate-every 1 \\\n",
    "--num_workers 4 \\\n",
    "--criterion_mode 'not balance' \\\n",
    "--multiple_GT \"False\" \\\n",
    "--patch_training \"True\" \\\n",
    "--multi-gpu-mode 'DataParallel' \n",
    "# --multi-gpu-mode 'DataParallel' \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비율 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "***********************************************\n",
      "***********************************************\n",
      "Dataset Name:  Sinogram_DCM\n",
      "---------- Model ----------\n",
      "Resume From:  \n",
      "Output To:  /workspace/sunggu/4.Dose_img2img/model/[Ours]MAP_WCMT\n",
      "Save   To:  /workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/\n",
      "---------- Optimizer ----------\n",
      "Learning Rate:  0.0002\n",
      "Weight Decay:  0.05\n",
      "Batchsize:  16\n",
      "Loading dataset ....\n",
      "Train [Total]  number =  6899\n",
      "Valid [Total]  number =  14\n",
      "inintializing...!\n",
      "Creating model: MAP_WCMT\n",
      "Number of Learnable Params: 134450481\n",
      "Start training for 1000 epochs\n",
      "Train: [epoch:0]  [  0/431]  eta: 2:06:07  lr: 0.000001  loss: 0.0057 (0.0057)  time: 17.5591  data: 2.8362  max mem: 39366\n",
      "Train: [epoch:0]  [ 10/431]  eta: 0:30:01  lr: 0.000001  loss: 0.0089 (0.0095)  time: 4.2799  data: 0.2580  max mem: 39468\n",
      "Train: [epoch:0]  [ 20/431]  eta: 0:25:01  lr: 0.000001  loss: 0.0086 (0.0092)  time: 2.9577  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:0]  [ 30/431]  eta: 0:22:54  lr: 0.000001  loss: 0.0081 (0.0088)  time: 2.9582  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:0]  [ 40/431]  eta: 0:21:34  lr: 0.000001  loss: 0.0090 (0.0092)  time: 2.9528  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [ 50/431]  eta: 0:20:35  lr: 0.000001  loss: 0.0097 (0.0095)  time: 2.9537  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [ 60/431]  eta: 0:19:45  lr: 0.000001  loss: 0.0092 (0.0097)  time: 2.9540  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [ 70/431]  eta: 0:19:00  lr: 0.000001  loss: 0.0088 (0.0099)  time: 2.9518  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [ 80/431]  eta: 0:18:20  lr: 0.000001  loss: 0.0098 (0.0101)  time: 2.9545  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [ 90/431]  eta: 0:17:42  lr: 0.000001  loss: 0.0109 (0.0102)  time: 2.9550  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [100/431]  eta: 0:17:05  lr: 0.000001  loss: 0.0085 (0.0101)  time: 2.9503  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [110/431]  eta: 0:16:30  lr: 0.000001  loss: 0.0089 (0.0102)  time: 2.9605  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [120/431]  eta: 0:15:56  lr: 0.000001  loss: 0.0096 (0.0101)  time: 2.9623  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [130/431]  eta: 0:15:23  lr: 0.000001  loss: 0.0087 (0.0101)  time: 2.9545  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [140/431]  eta: 0:14:51  lr: 0.000001  loss: 0.0094 (0.0102)  time: 2.9870  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [150/431]  eta: 0:14:19  lr: 0.000001  loss: 0.0094 (0.0101)  time: 2.9955  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [160/431]  eta: 0:13:47  lr: 0.000001  loss: 0.0076 (0.0100)  time: 2.9773  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [170/431]  eta: 0:13:15  lr: 0.000001  loss: 0.0078 (0.0100)  time: 2.9702  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [180/431]  eta: 0:12:43  lr: 0.000001  loss: 0.0097 (0.0100)  time: 2.9573  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [190/431]  eta: 0:12:12  lr: 0.000001  loss: 0.0098 (0.0100)  time: 2.9535  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [200/431]  eta: 0:11:40  lr: 0.000001  loss: 0.0082 (0.0100)  time: 2.9559  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [210/431]  eta: 0:11:09  lr: 0.000001  loss: 0.0098 (0.0100)  time: 2.9615  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [220/431]  eta: 0:10:38  lr: 0.000001  loss: 0.0106 (0.0101)  time: 2.9626  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [230/431]  eta: 0:10:07  lr: 0.000001  loss: 0.0093 (0.0100)  time: 2.9598  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [240/431]  eta: 0:09:37  lr: 0.000001  loss: 0.0094 (0.0101)  time: 2.9602  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [250/431]  eta: 0:09:06  lr: 0.000001  loss: 0.0099 (0.0101)  time: 2.9611  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [260/431]  eta: 0:08:35  lr: 0.000001  loss: 0.0097 (0.0101)  time: 2.9591  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [270/431]  eta: 0:08:05  lr: 0.000001  loss: 0.0097 (0.0101)  time: 2.9584  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [280/431]  eta: 0:07:34  lr: 0.000001  loss: 0.0094 (0.0101)  time: 2.9564  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [290/431]  eta: 0:07:04  lr: 0.000001  loss: 0.0099 (0.0101)  time: 2.9544  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [300/431]  eta: 0:06:34  lr: 0.000001  loss: 0.0099 (0.0101)  time: 2.9546  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [310/431]  eta: 0:06:03  lr: 0.000001  loss: 0.0093 (0.0101)  time: 2.9555  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [320/431]  eta: 0:05:33  lr: 0.000001  loss: 0.0096 (0.0101)  time: 2.9581  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [330/431]  eta: 0:05:03  lr: 0.000001  loss: 0.0092 (0.0101)  time: 2.9590  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [340/431]  eta: 0:04:33  lr: 0.000001  loss: 0.0095 (0.0102)  time: 2.9557  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [350/431]  eta: 0:04:03  lr: 0.000001  loss: 0.0088 (0.0101)  time: 2.9543  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [360/431]  eta: 0:03:33  lr: 0.000001  loss: 0.0088 (0.0102)  time: 2.9568  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [370/431]  eta: 0:03:02  lr: 0.000001  loss: 0.0101 (0.0102)  time: 2.9602  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [380/431]  eta: 0:02:32  lr: 0.000001  loss: 0.0091 (0.0101)  time: 2.9569  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [390/431]  eta: 0:02:02  lr: 0.000001  loss: 0.0088 (0.0101)  time: 2.9551  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [400/431]  eta: 0:01:32  lr: 0.000001  loss: 0.0091 (0.0101)  time: 2.9580  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [410/431]  eta: 0:01:02  lr: 0.000001  loss: 0.0102 (0.0101)  time: 2.9582  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [420/431]  eta: 0:00:32  lr: 0.000001  loss: 0.0107 (0.0102)  time: 2.9608  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0]  [430/431]  eta: 0:00:02  lr: 0.000001  loss: 0.0109 (0.0102)  time: 2.9561  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:0] Total time: 0:21:30 (2.9935 s / it)\n",
      "Averaged stats: lr: 0.000001  loss: 0.0109 (0.0102)\n",
      "Valid: [epoch:0]  [ 0/14]  eta: 0:03:22  loss: 0.0024 (0.0024)  time: 14.4480  data: 0.5812  max mem: 39468\n",
      "Valid: [epoch:0]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.7882  data: 0.0416  max mem: 39468\n",
      "Valid: [epoch:0] Total time: 0:03:13 (13.8042 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_0_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "/home/sunggu/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Train: [epoch:1]  [  0/431]  eta: 0:37:22  lr: 0.000001  loss: 0.0119 (0.0119)  time: 5.2027  data: 2.1936  max mem: 39468\n",
      "Train: [epoch:1]  [ 10/431]  eta: 0:22:12  lr: 0.000001  loss: 0.0094 (0.0094)  time: 3.1651  data: 0.1995  max mem: 39468\n",
      "Train: [epoch:1]  [ 20/431]  eta: 0:21:00  lr: 0.000001  loss: 0.0091 (0.0090)  time: 2.9592  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:1]  [ 30/431]  eta: 0:20:15  lr: 0.000001  loss: 0.0075 (0.0089)  time: 2.9568  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:1]  [ 40/431]  eta: 0:19:38  lr: 0.000001  loss: 0.0075 (0.0091)  time: 2.9575  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [ 50/431]  eta: 0:19:04  lr: 0.000001  loss: 0.0081 (0.0094)  time: 2.9649  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [ 60/431]  eta: 0:18:31  lr: 0.000001  loss: 0.0107 (0.0097)  time: 2.9633  data: 0.0001  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [ 70/431]  eta: 0:18:00  lr: 0.000001  loss: 0.0109 (0.0100)  time: 2.9609  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [ 80/431]  eta: 0:17:28  lr: 0.000001  loss: 0.0093 (0.0100)  time: 2.9595  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [ 90/431]  eta: 0:16:57  lr: 0.000001  loss: 0.0089 (0.0101)  time: 2.9529  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [100/431]  eta: 0:16:26  lr: 0.000001  loss: 0.0088 (0.0101)  time: 2.9520  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:1]  [110/431]  eta: 0:15:55  lr: 0.000001  loss: 0.0086 (0.0101)  time: 2.9521  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:1]  [120/431]  eta: 0:15:26  lr: 0.000001  loss: 0.0098 (0.0100)  time: 2.9664  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:1]  [130/431]  eta: 0:14:57  lr: 0.000001  loss: 0.0097 (0.0100)  time: 2.9926  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [140/431]  eta: 0:14:26  lr: 0.000001  loss: 0.0096 (0.0100)  time: 2.9855  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [150/431]  eta: 0:13:57  lr: 0.000001  loss: 0.0096 (0.0100)  time: 2.9805  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [160/431]  eta: 0:13:27  lr: 0.000001  loss: 0.0085 (0.0100)  time: 2.9879  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [170/431]  eta: 0:12:58  lr: 0.000001  loss: 0.0085 (0.0099)  time: 2.9876  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [180/431]  eta: 0:12:28  lr: 0.000001  loss: 0.0085 (0.0098)  time: 2.9840  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [190/431]  eta: 0:11:58  lr: 0.000001  loss: 0.0092 (0.0099)  time: 2.9736  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [200/431]  eta: 0:11:28  lr: 0.000001  loss: 0.0100 (0.0100)  time: 2.9637  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [210/431]  eta: 0:10:58  lr: 0.000001  loss: 0.0107 (0.0100)  time: 2.9676  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [220/431]  eta: 0:10:28  lr: 0.000001  loss: 0.0100 (0.0101)  time: 2.9781  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [230/431]  eta: 0:09:58  lr: 0.000001  loss: 0.0093 (0.0101)  time: 2.9782  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [240/431]  eta: 0:09:28  lr: 0.000001  loss: 0.0087 (0.0101)  time: 2.9756  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [250/431]  eta: 0:08:59  lr: 0.000001  loss: 0.0093 (0.0101)  time: 2.9717  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [260/431]  eta: 0:08:29  lr: 0.000001  loss: 0.0091 (0.0101)  time: 2.9816  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [270/431]  eta: 0:07:59  lr: 0.000001  loss: 0.0091 (0.0101)  time: 2.9775  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [280/431]  eta: 0:07:29  lr: 0.000001  loss: 0.0089 (0.0100)  time: 2.9645  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [290/431]  eta: 0:06:59  lr: 0.000001  loss: 0.0090 (0.0102)  time: 2.9789  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [300/431]  eta: 0:06:30  lr: 0.000001  loss: 0.0104 (0.0102)  time: 2.9885  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [310/431]  eta: 0:06:00  lr: 0.000001  loss: 0.0105 (0.0102)  time: 2.9780  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [320/431]  eta: 0:05:30  lr: 0.000001  loss: 0.0107 (0.0103)  time: 2.9664  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [330/431]  eta: 0:05:00  lr: 0.000001  loss: 0.0099 (0.0103)  time: 2.9840  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [340/431]  eta: 0:04:31  lr: 0.000001  loss: 0.0086 (0.0102)  time: 3.0027  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [350/431]  eta: 0:04:01  lr: 0.000001  loss: 0.0085 (0.0102)  time: 2.9998  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [360/431]  eta: 0:03:31  lr: 0.000001  loss: 0.0091 (0.0103)  time: 2.9963  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [370/431]  eta: 0:03:01  lr: 0.000001  loss: 0.0089 (0.0102)  time: 2.9922  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [380/431]  eta: 0:02:32  lr: 0.000001  loss: 0.0089 (0.0102)  time: 2.9893  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [390/431]  eta: 0:02:02  lr: 0.000001  loss: 0.0085 (0.0102)  time: 2.9689  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:1]  [400/431]  eta: 0:01:32  lr: 0.000001  loss: 0.0085 (0.0102)  time: 2.9517  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:1]  [410/431]  eta: 0:01:02  lr: 0.000001  loss: 0.0113 (0.0102)  time: 2.9546  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:1]  [420/431]  eta: 0:00:32  lr: 0.000001  loss: 0.0109 (0.0102)  time: 2.9704  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1]  [430/431]  eta: 0:00:02  lr: 0.000001  loss: 0.0095 (0.0103)  time: 2.9655  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:1] Total time: 0:21:23 (2.9788 s / it)\n",
      "Averaged stats: lr: 0.000001  loss: 0.0095 (0.0103)\n",
      "Valid: [epoch:1]  [ 0/14]  eta: 0:03:26  loss: 0.0024 (0.0024)  time: 14.7431  data: 0.5833  max mem: 39468\n",
      "Valid: [epoch:1]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.1870  data: 0.0418  max mem: 39468\n",
      "Valid: [epoch:1] Total time: 0:03:18 (14.2091 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_1_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:2]  [  0/431]  eta: 0:40:05  lr: 0.000020  loss: 0.0066 (0.0066)  time: 5.5812  data: 2.5257  max mem: 39468\n",
      "Train: [epoch:2]  [ 10/431]  eta: 0:22:25  lr: 0.000020  loss: 0.0132 (0.0124)  time: 3.1971  data: 0.2297  max mem: 39468\n",
      "Train: [epoch:2]  [ 20/431]  eta: 0:21:05  lr: 0.000020  loss: 0.0099 (0.0109)  time: 2.9547  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [ 30/431]  eta: 0:20:19  lr: 0.000020  loss: 0.0081 (0.0099)  time: 2.9544  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [ 40/431]  eta: 0:19:40  lr: 0.000020  loss: 0.0083 (0.0097)  time: 2.9564  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [ 50/431]  eta: 0:19:05  lr: 0.000020  loss: 0.0094 (0.0098)  time: 2.9564  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [ 60/431]  eta: 0:18:33  lr: 0.000020  loss: 0.0098 (0.0102)  time: 2.9610  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [ 70/431]  eta: 0:18:01  lr: 0.000020  loss: 0.0105 (0.0102)  time: 2.9644  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [ 80/431]  eta: 0:17:30  lr: 0.000020  loss: 0.0093 (0.0102)  time: 2.9684  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [ 90/431]  eta: 0:16:59  lr: 0.000020  loss: 0.0098 (0.0103)  time: 2.9702  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [100/431]  eta: 0:16:28  lr: 0.000020  loss: 0.0094 (0.0102)  time: 2.9639  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [110/431]  eta: 0:15:57  lr: 0.000020  loss: 0.0092 (0.0103)  time: 2.9582  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [120/431]  eta: 0:15:28  lr: 0.000020  loss: 0.0091 (0.0102)  time: 2.9717  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [130/431]  eta: 0:14:57  lr: 0.000020  loss: 0.0082 (0.0100)  time: 2.9695  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [140/431]  eta: 0:14:27  lr: 0.000020  loss: 0.0087 (0.0102)  time: 2.9530  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [150/431]  eta: 0:13:56  lr: 0.000020  loss: 0.0116 (0.0102)  time: 2.9555  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [160/431]  eta: 0:13:26  lr: 0.000020  loss: 0.0076 (0.0100)  time: 2.9585  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [170/431]  eta: 0:12:56  lr: 0.000020  loss: 0.0080 (0.0100)  time: 2.9571  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [180/431]  eta: 0:12:26  lr: 0.000020  loss: 0.0087 (0.0101)  time: 2.9576  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [190/431]  eta: 0:11:56  lr: 0.000020  loss: 0.0085 (0.0100)  time: 2.9572  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [200/431]  eta: 0:11:26  lr: 0.000020  loss: 0.0082 (0.0099)  time: 2.9567  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [210/431]  eta: 0:10:56  lr: 0.000020  loss: 0.0099 (0.0100)  time: 2.9567  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [220/431]  eta: 0:10:26  lr: 0.000020  loss: 0.0083 (0.0099)  time: 2.9543  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [230/431]  eta: 0:09:57  lr: 0.000020  loss: 0.0080 (0.0099)  time: 2.9575  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [240/431]  eta: 0:09:27  lr: 0.000020  loss: 0.0092 (0.0099)  time: 2.9573  data: 0.0001  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [250/431]  eta: 0:08:57  lr: 0.000020  loss: 0.0106 (0.0100)  time: 2.9552  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [260/431]  eta: 0:08:27  lr: 0.000020  loss: 0.0091 (0.0100)  time: 2.9552  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [270/431]  eta: 0:07:57  lr: 0.000020  loss: 0.0088 (0.0100)  time: 2.9550  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [280/431]  eta: 0:07:28  lr: 0.000020  loss: 0.0089 (0.0100)  time: 2.9539  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [290/431]  eta: 0:06:58  lr: 0.000020  loss: 0.0095 (0.0100)  time: 2.9536  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [300/431]  eta: 0:06:28  lr: 0.000020  loss: 0.0093 (0.0100)  time: 2.9557  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [310/431]  eta: 0:05:58  lr: 0.000020  loss: 0.0082 (0.0100)  time: 2.9563  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [320/431]  eta: 0:05:29  lr: 0.000020  loss: 0.0104 (0.0100)  time: 2.9571  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [330/431]  eta: 0:04:59  lr: 0.000020  loss: 0.0105 (0.0101)  time: 2.9560  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [340/431]  eta: 0:04:29  lr: 0.000020  loss: 0.0099 (0.0101)  time: 2.9550  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [350/431]  eta: 0:04:00  lr: 0.000020  loss: 0.0099 (0.0101)  time: 2.9548  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [360/431]  eta: 0:03:30  lr: 0.000020  loss: 0.0105 (0.0102)  time: 2.9542  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [370/431]  eta: 0:03:00  lr: 0.000020  loss: 0.0099 (0.0102)  time: 2.9555  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [380/431]  eta: 0:02:31  lr: 0.000020  loss: 0.0088 (0.0101)  time: 2.9551  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [390/431]  eta: 0:02:01  lr: 0.000020  loss: 0.0091 (0.0101)  time: 2.9548  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [400/431]  eta: 0:01:31  lr: 0.000020  loss: 0.0096 (0.0102)  time: 2.9552  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [410/431]  eta: 0:01:02  lr: 0.000020  loss: 0.0096 (0.0102)  time: 2.9569  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [420/431]  eta: 0:00:32  lr: 0.000020  loss: 0.0106 (0.0102)  time: 2.9683  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2]  [430/431]  eta: 0:00:02  lr: 0.000020  loss: 0.0115 (0.0102)  time: 2.9634  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:2] Total time: 0:21:17 (2.9648 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.0115 (0.0102)\n",
      "Valid: [epoch:2]  [ 0/14]  eta: 0:03:23  loss: 0.0007 (0.0007)  time: 14.5366  data: 0.5601  max mem: 39468\n",
      "Valid: [epoch:2]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.8232  data: 0.0401  max mem: 39468\n",
      "Valid: [epoch:2] Total time: 0:03:13 (13.8463 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_2_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:3]  [  0/431]  eta: 0:44:19  lr: 0.000040  loss: 0.0056 (0.0056)  time: 6.1715  data: 3.1492  max mem: 39468\n",
      "Train: [epoch:3]  [ 10/431]  eta: 0:22:45  lr: 0.000040  loss: 0.0092 (0.0090)  time: 3.2438  data: 0.2864  max mem: 39468\n",
      "Train: [epoch:3]  [ 20/431]  eta: 0:21:16  lr: 0.000040  loss: 0.0095 (0.0106)  time: 2.9535  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [ 30/431]  eta: 0:20:29  lr: 0.000040  loss: 0.0094 (0.0101)  time: 2.9691  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [ 40/431]  eta: 0:19:51  lr: 0.000040  loss: 0.0083 (0.0104)  time: 2.9831  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [ 50/431]  eta: 0:19:15  lr: 0.000040  loss: 0.0111 (0.0105)  time: 2.9790  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [ 60/431]  eta: 0:18:41  lr: 0.000040  loss: 0.0094 (0.0103)  time: 2.9736  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [ 70/431]  eta: 0:18:09  lr: 0.000040  loss: 0.0094 (0.0104)  time: 2.9821  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [ 80/431]  eta: 0:17:36  lr: 0.000040  loss: 0.0086 (0.0101)  time: 2.9738  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [ 90/431]  eta: 0:17:05  lr: 0.000040  loss: 0.0088 (0.0102)  time: 2.9638  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [100/431]  eta: 0:16:33  lr: 0.000040  loss: 0.0093 (0.0101)  time: 2.9640  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [110/431]  eta: 0:16:02  lr: 0.000040  loss: 0.0093 (0.0101)  time: 2.9575  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [120/431]  eta: 0:15:31  lr: 0.000040  loss: 0.0103 (0.0103)  time: 2.9581  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [130/431]  eta: 0:15:00  lr: 0.000040  loss: 0.0107 (0.0102)  time: 2.9593  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [140/431]  eta: 0:14:29  lr: 0.000040  loss: 0.0087 (0.0102)  time: 2.9601  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [150/431]  eta: 0:13:59  lr: 0.000040  loss: 0.0086 (0.0101)  time: 2.9597  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [160/431]  eta: 0:13:29  lr: 0.000040  loss: 0.0097 (0.0103)  time: 2.9568  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [170/431]  eta: 0:12:58  lr: 0.000040  loss: 0.0104 (0.0102)  time: 2.9536  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [180/431]  eta: 0:12:28  lr: 0.000040  loss: 0.0085 (0.0102)  time: 2.9568  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [190/431]  eta: 0:11:58  lr: 0.000040  loss: 0.0079 (0.0102)  time: 2.9602  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [200/431]  eta: 0:11:28  lr: 0.000040  loss: 0.0083 (0.0101)  time: 2.9595  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [210/431]  eta: 0:10:58  lr: 0.000040  loss: 0.0090 (0.0102)  time: 2.9581  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [220/431]  eta: 0:10:28  lr: 0.000040  loss: 0.0115 (0.0103)  time: 2.9562  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [230/431]  eta: 0:09:58  lr: 0.000040  loss: 0.0100 (0.0103)  time: 2.9583  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [240/431]  eta: 0:09:28  lr: 0.000040  loss: 0.0091 (0.0102)  time: 2.9608  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [250/431]  eta: 0:08:58  lr: 0.000040  loss: 0.0098 (0.0102)  time: 2.9600  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [260/431]  eta: 0:08:28  lr: 0.000040  loss: 0.0098 (0.0102)  time: 2.9583  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [270/431]  eta: 0:07:58  lr: 0.000040  loss: 0.0097 (0.0102)  time: 2.9550  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [280/431]  eta: 0:07:29  lr: 0.000040  loss: 0.0099 (0.0102)  time: 2.9561  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [290/431]  eta: 0:06:59  lr: 0.000040  loss: 0.0091 (0.0103)  time: 2.9563  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [300/431]  eta: 0:06:29  lr: 0.000040  loss: 0.0091 (0.0103)  time: 2.9555  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [310/431]  eta: 0:05:59  lr: 0.000040  loss: 0.0092 (0.0103)  time: 2.9554  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [320/431]  eta: 0:05:29  lr: 0.000040  loss: 0.0090 (0.0102)  time: 2.9531  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [330/431]  eta: 0:05:00  lr: 0.000040  loss: 0.0097 (0.0103)  time: 2.9522  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [340/431]  eta: 0:04:30  lr: 0.000040  loss: 0.0103 (0.0103)  time: 2.9560  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [350/431]  eta: 0:04:00  lr: 0.000040  loss: 0.0090 (0.0102)  time: 2.9587  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [360/431]  eta: 0:03:30  lr: 0.000040  loss: 0.0097 (0.0102)  time: 2.9569  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [370/431]  eta: 0:03:01  lr: 0.000040  loss: 0.0097 (0.0103)  time: 2.9604  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [380/431]  eta: 0:02:31  lr: 0.000040  loss: 0.0092 (0.0102)  time: 2.9631  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [390/431]  eta: 0:02:01  lr: 0.000040  loss: 0.0088 (0.0102)  time: 2.9605  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [400/431]  eta: 0:01:32  lr: 0.000040  loss: 0.0091 (0.0102)  time: 2.9584  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [410/431]  eta: 0:01:02  lr: 0.000040  loss: 0.0093 (0.0102)  time: 2.9583  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3]  [420/431]  eta: 0:00:32  lr: 0.000040  loss: 0.0091 (0.0102)  time: 2.9564  data: 0.0001  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [430/431]  eta: 0:00:02  lr: 0.000040  loss: 0.0093 (0.0102)  time: 2.9505  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:3] Total time: 0:21:19 (2.9682 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.0093 (0.0102)\n",
      "Valid: [epoch:3]  [ 0/14]  eta: 0:03:21  loss: 0.0015 (0.0015)  time: 14.3724  data: 0.5471  max mem: 39468\n",
      "Valid: [epoch:3]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.7453  data: 0.0392  max mem: 39468\n",
      "Valid: [epoch:3] Total time: 0:03:12 (13.7635 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_3_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:4]  [  0/431]  eta: 0:37:33  lr: 0.000060  loss: 0.0083 (0.0083)  time: 5.2275  data: 2.1952  max mem: 39468\n",
      "Train: [epoch:4]  [ 10/431]  eta: 0:22:12  lr: 0.000060  loss: 0.0083 (0.0089)  time: 3.1662  data: 0.1997  max mem: 39468\n",
      "Train: [epoch:4]  [ 20/431]  eta: 0:21:00  lr: 0.000060  loss: 0.0081 (0.0095)  time: 2.9590  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [ 30/431]  eta: 0:20:14  lr: 0.000060  loss: 0.0093 (0.0099)  time: 2.9540  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [ 40/431]  eta: 0:19:38  lr: 0.000060  loss: 0.0093 (0.0100)  time: 2.9589  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [ 50/431]  eta: 0:19:04  lr: 0.000060  loss: 0.0091 (0.0099)  time: 2.9635  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [ 60/431]  eta: 0:18:30  lr: 0.000060  loss: 0.0090 (0.0097)  time: 2.9536  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [ 70/431]  eta: 0:17:58  lr: 0.000060  loss: 0.0097 (0.0099)  time: 2.9498  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [ 80/431]  eta: 0:17:27  lr: 0.000060  loss: 0.0097 (0.0099)  time: 2.9526  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [ 90/431]  eta: 0:16:56  lr: 0.000060  loss: 0.0085 (0.0100)  time: 2.9521  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [100/431]  eta: 0:16:25  lr: 0.000060  loss: 0.0098 (0.0100)  time: 2.9506  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [110/431]  eta: 0:16:03  lr: 0.000060  loss: 0.0099 (0.0101)  time: 3.1044  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [120/431]  eta: 0:15:44  lr: 0.000060  loss: 0.0099 (0.0101)  time: 3.3374  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [130/431]  eta: 0:15:23  lr: 0.000060  loss: 0.0097 (0.0101)  time: 3.4414  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [140/431]  eta: 0:15:01  lr: 0.000060  loss: 0.0092 (0.0100)  time: 3.4760  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [150/431]  eta: 0:14:37  lr: 0.000060  loss: 0.0093 (0.0101)  time: 3.4754  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [160/431]  eta: 0:14:10  lr: 0.000060  loss: 0.0086 (0.0100)  time: 3.4041  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [170/431]  eta: 0:13:44  lr: 0.000060  loss: 0.0079 (0.0100)  time: 3.4174  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [180/431]  eta: 0:13:18  lr: 0.000060  loss: 0.0079 (0.0099)  time: 3.5261  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [190/431]  eta: 0:12:50  lr: 0.000060  loss: 0.0079 (0.0098)  time: 3.5232  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [200/431]  eta: 0:12:22  lr: 0.000060  loss: 0.0088 (0.0098)  time: 3.5035  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [210/431]  eta: 0:11:52  lr: 0.000060  loss: 0.0092 (0.0098)  time: 3.5008  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [220/431]  eta: 0:11:22  lr: 0.000060  loss: 0.0091 (0.0099)  time: 3.4683  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [230/431]  eta: 0:10:50  lr: 0.000060  loss: 0.0088 (0.0098)  time: 3.3729  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [240/431]  eta: 0:10:20  lr: 0.000060  loss: 0.0083 (0.0098)  time: 3.3709  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [250/431]  eta: 0:09:47  lr: 0.000060  loss: 0.0096 (0.0099)  time: 3.3666  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [260/431]  eta: 0:09:17  lr: 0.000060  loss: 0.0096 (0.0099)  time: 3.4041  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [270/431]  eta: 0:08:46  lr: 0.000060  loss: 0.0096 (0.0099)  time: 3.5846  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [280/431]  eta: 0:08:16  lr: 0.000060  loss: 0.0102 (0.0099)  time: 3.6646  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [290/431]  eta: 0:07:44  lr: 0.000060  loss: 0.0091 (0.0100)  time: 3.5596  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [300/431]  eta: 0:07:12  lr: 0.000060  loss: 0.0096 (0.0100)  time: 3.4786  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [310/431]  eta: 0:06:40  lr: 0.000060  loss: 0.0087 (0.0100)  time: 3.5114  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [320/431]  eta: 0:06:07  lr: 0.000060  loss: 0.0098 (0.0100)  time: 3.4372  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [330/431]  eta: 0:05:34  lr: 0.000060  loss: 0.0091 (0.0100)  time: 3.4227  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [340/431]  eta: 0:05:02  lr: 0.000060  loss: 0.0089 (0.0100)  time: 3.4856  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:4]  [350/431]  eta: 0:04:29  lr: 0.000060  loss: 0.0090 (0.0100)  time: 3.5318  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [360/431]  eta: 0:03:56  lr: 0.000060  loss: 0.0091 (0.0101)  time: 3.5618  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [370/431]  eta: 0:03:23  lr: 0.000060  loss: 0.0106 (0.0101)  time: 3.5158  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [380/431]  eta: 0:02:50  lr: 0.000060  loss: 0.0106 (0.0101)  time: 3.3767  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [390/431]  eta: 0:02:16  lr: 0.000060  loss: 0.0107 (0.0102)  time: 3.3434  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [400/431]  eta: 0:01:43  lr: 0.000060  loss: 0.0095 (0.0101)  time: 3.4233  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [410/431]  eta: 0:01:10  lr: 0.000060  loss: 0.0095 (0.0102)  time: 3.4771  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [420/431]  eta: 0:00:36  lr: 0.000060  loss: 0.0108 (0.0102)  time: 3.4588  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4]  [430/431]  eta: 0:00:03  lr: 0.000060  loss: 0.0095 (0.0102)  time: 3.3540  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:4] Total time: 0:24:01 (3.3447 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.0095 (0.0102)\n",
      "Valid: [epoch:4]  [ 0/14]  eta: 0:03:29  loss: 0.0025 (0.0025)  time: 14.9983  data: 0.5672  max mem: 39468\n",
      "Valid: [epoch:4]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.6698  data: 0.0406  max mem: 39468\n",
      "Valid: [epoch:4] Total time: 0:03:25 (14.6844 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_4_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:5]  [  0/431]  eta: 0:38:50  lr: 0.000080  loss: 0.0146 (0.0146)  time: 5.4083  data: 2.3031  max mem: 39468\n",
      "Train: [epoch:5]  [ 10/431]  eta: 0:24:49  lr: 0.000080  loss: 0.0099 (0.0108)  time: 3.5390  data: 0.2096  max mem: 39468\n",
      "Train: [epoch:5]  [ 20/431]  eta: 0:23:55  lr: 0.000080  loss: 0.0094 (0.0107)  time: 3.3982  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [ 30/431]  eta: 0:23:15  lr: 0.000080  loss: 0.0085 (0.0098)  time: 3.4490  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [ 40/431]  eta: 0:22:30  lr: 0.000080  loss: 0.0085 (0.0100)  time: 3.4140  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [ 50/431]  eta: 0:21:59  lr: 0.000080  loss: 0.0098 (0.0102)  time: 3.4363  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [ 60/431]  eta: 0:21:22  lr: 0.000080  loss: 0.0113 (0.0104)  time: 3.4569  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [ 70/431]  eta: 0:20:43  lr: 0.000080  loss: 0.0100 (0.0104)  time: 3.3949  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [ 80/431]  eta: 0:20:04  lr: 0.000080  loss: 0.0094 (0.0103)  time: 3.3584  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [ 90/431]  eta: 0:19:31  lr: 0.000080  loss: 0.0100 (0.0105)  time: 3.4044  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:5]  [100/431]  eta: 0:18:59  lr: 0.000080  loss: 0.0097 (0.0104)  time: 3.4864  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [110/431]  eta: 0:18:26  lr: 0.000080  loss: 0.0097 (0.0106)  time: 3.4924  data: 0.0002  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [120/431]  eta: 0:17:52  lr: 0.000080  loss: 0.0096 (0.0104)  time: 3.4698  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [130/431]  eta: 0:17:19  lr: 0.000080  loss: 0.0096 (0.0105)  time: 3.4909  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [140/431]  eta: 0:16:53  lr: 0.000080  loss: 0.0096 (0.0105)  time: 3.6983  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [150/431]  eta: 0:16:20  lr: 0.000080  loss: 0.0093 (0.0105)  time: 3.7334  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [160/431]  eta: 0:15:46  lr: 0.000080  loss: 0.0098 (0.0105)  time: 3.5762  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [170/431]  eta: 0:15:11  lr: 0.000080  loss: 0.0098 (0.0104)  time: 3.5052  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [180/431]  eta: 0:14:35  lr: 0.000080  loss: 0.0087 (0.0104)  time: 3.4497  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [190/431]  eta: 0:14:01  lr: 0.000080  loss: 0.0098 (0.0103)  time: 3.4863  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [200/431]  eta: 0:13:25  lr: 0.000080  loss: 0.0084 (0.0103)  time: 3.4799  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [210/431]  eta: 0:12:50  lr: 0.000080  loss: 0.0081 (0.0102)  time: 3.4244  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [220/431]  eta: 0:12:14  lr: 0.000080  loss: 0.0101 (0.0103)  time: 3.4291  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [230/431]  eta: 0:11:40  lr: 0.000080  loss: 0.0093 (0.0102)  time: 3.4796  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:5]  [240/431]  eta: 0:11:05  lr: 0.000080  loss: 0.0093 (0.0103)  time: 3.4811  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:5]  [250/431]  eta: 0:10:31  lr: 0.000080  loss: 0.0107 (0.0104)  time: 3.5736  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [260/431]  eta: 0:09:59  lr: 0.000080  loss: 0.0090 (0.0104)  time: 3.8150  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [270/431]  eta: 0:09:27  lr: 0.000080  loss: 0.0086 (0.0103)  time: 3.9111  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [280/431]  eta: 0:08:53  lr: 0.000080  loss: 0.0083 (0.0103)  time: 3.8618  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [290/431]  eta: 0:08:20  lr: 0.000080  loss: 0.0093 (0.0103)  time: 3.8738  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [300/431]  eta: 0:07:45  lr: 0.000080  loss: 0.0078 (0.0103)  time: 3.7809  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [310/431]  eta: 0:07:12  lr: 0.000080  loss: 0.0095 (0.0103)  time: 3.9306  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [320/431]  eta: 0:06:36  lr: 0.000080  loss: 0.0097 (0.0103)  time: 3.9717  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [330/431]  eta: 0:06:01  lr: 0.000080  loss: 0.0084 (0.0103)  time: 3.7768  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [340/431]  eta: 0:05:27  lr: 0.000080  loss: 0.0077 (0.0102)  time: 3.8715  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [350/431]  eta: 0:04:51  lr: 0.000080  loss: 0.0097 (0.0102)  time: 3.8540  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [360/431]  eta: 0:04:15  lr: 0.000080  loss: 0.0099 (0.0103)  time: 3.7787  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [370/431]  eta: 0:03:40  lr: 0.000080  loss: 0.0110 (0.0103)  time: 3.8794  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [380/431]  eta: 0:03:04  lr: 0.000080  loss: 0.0096 (0.0103)  time: 3.9080  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [390/431]  eta: 0:02:28  lr: 0.000080  loss: 0.0083 (0.0102)  time: 3.9000  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [400/431]  eta: 0:01:52  lr: 0.000080  loss: 0.0081 (0.0102)  time: 3.8437  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [410/431]  eta: 0:01:16  lr: 0.000080  loss: 0.0098 (0.0103)  time: 3.7993  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [420/431]  eta: 0:00:40  lr: 0.000080  loss: 0.0101 (0.0102)  time: 3.9016  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5]  [430/431]  eta: 0:00:03  lr: 0.000080  loss: 0.0101 (0.0103)  time: 3.8457  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:5] Total time: 0:26:12 (3.6474 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.0101 (0.0103)\n",
      "Valid: [epoch:5]  [ 0/14]  eta: 0:03:35  loss: 0.0007 (0.0007)  time: 15.4217  data: 0.5750  max mem: 39468\n",
      "Valid: [epoch:5]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.3097  data: 0.0412  max mem: 39468\n",
      "Valid: [epoch:5] Total time: 0:03:34 (15.3306 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_5_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:6]  [  0/431]  eta: 0:52:11  lr: 0.000100  loss: 0.0062 (0.0062)  time: 7.2654  data: 2.6503  max mem: 39468\n",
      "Train: [epoch:6]  [ 10/431]  eta: 0:28:17  lr: 0.000100  loss: 0.0107 (0.0105)  time: 4.0328  data: 0.2411  max mem: 39468\n",
      "Train: [epoch:6]  [ 20/431]  eta: 0:26:28  lr: 0.000100  loss: 0.0095 (0.0100)  time: 3.6950  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [ 30/431]  eta: 0:25:49  lr: 0.000100  loss: 0.0079 (0.0093)  time: 3.7722  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [ 40/431]  eta: 0:24:57  lr: 0.000100  loss: 0.0085 (0.0095)  time: 3.7914  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [ 50/431]  eta: 0:24:04  lr: 0.000100  loss: 0.0098 (0.0096)  time: 3.6807  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [ 60/431]  eta: 0:23:51  lr: 0.000100  loss: 0.0091 (0.0098)  time: 3.9205  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [ 70/431]  eta: 0:23:10  lr: 0.000100  loss: 0.0085 (0.0098)  time: 3.9995  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [ 80/431]  eta: 0:22:31  lr: 0.000100  loss: 0.0091 (0.0098)  time: 3.8261  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [ 90/431]  eta: 0:21:56  lr: 0.000100  loss: 0.0096 (0.0098)  time: 3.8918  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [100/431]  eta: 0:21:14  lr: 0.000100  loss: 0.0092 (0.0099)  time: 3.8455  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [110/431]  eta: 0:20:34  lr: 0.000100  loss: 0.0092 (0.0099)  time: 3.7750  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [120/431]  eta: 0:19:59  lr: 0.000100  loss: 0.0093 (0.0099)  time: 3.8971  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [130/431]  eta: 0:19:26  lr: 0.000100  loss: 0.0095 (0.0099)  time: 4.0362  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [140/431]  eta: 0:18:45  lr: 0.000100  loss: 0.0098 (0.0100)  time: 3.9233  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [150/431]  eta: 0:18:10  lr: 0.000100  loss: 0.0121 (0.0101)  time: 3.9376  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [160/431]  eta: 0:17:33  lr: 0.000100  loss: 0.0091 (0.0101)  time: 4.0383  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [170/431]  eta: 0:16:55  lr: 0.000100  loss: 0.0082 (0.0100)  time: 3.9548  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [180/431]  eta: 0:16:19  lr: 0.000100  loss: 0.0090 (0.0099)  time: 4.0084  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [190/431]  eta: 0:15:39  lr: 0.000100  loss: 0.0094 (0.0100)  time: 3.9474  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [200/431]  eta: 0:14:59  lr: 0.000100  loss: 0.0094 (0.0100)  time: 3.8094  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [210/431]  eta: 0:14:21  lr: 0.000100  loss: 0.0091 (0.0100)  time: 3.9304  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [220/431]  eta: 0:13:41  lr: 0.000100  loss: 0.0092 (0.0100)  time: 3.9238  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [230/431]  eta: 0:13:04  lr: 0.000100  loss: 0.0085 (0.0100)  time: 3.9385  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [240/431]  eta: 0:12:25  lr: 0.000100  loss: 0.0084 (0.0100)  time: 3.9876  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [250/431]  eta: 0:11:45  lr: 0.000100  loss: 0.0094 (0.0100)  time: 3.8476  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [260/431]  eta: 0:11:04  lr: 0.000100  loss: 0.0086 (0.0100)  time: 3.7199  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [270/431]  eta: 0:10:26  lr: 0.000100  loss: 0.0086 (0.0101)  time: 3.7825  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [280/431]  eta: 0:09:47  lr: 0.000100  loss: 0.0101 (0.0101)  time: 3.9132  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [290/431]  eta: 0:09:08  lr: 0.000100  loss: 0.0102 (0.0102)  time: 3.8676  data: 0.0002  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [300/431]  eta: 0:08:29  lr: 0.000100  loss: 0.0092 (0.0101)  time: 3.8822  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [310/431]  eta: 0:07:49  lr: 0.000100  loss: 0.0092 (0.0102)  time: 3.7644  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [320/431]  eta: 0:07:10  lr: 0.000100  loss: 0.0101 (0.0102)  time: 3.6896  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [330/431]  eta: 0:06:31  lr: 0.000100  loss: 0.0095 (0.0102)  time: 3.8713  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [340/431]  eta: 0:05:53  lr: 0.000100  loss: 0.0103 (0.0102)  time: 4.0482  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [350/431]  eta: 0:05:14  lr: 0.000100  loss: 0.0095 (0.0102)  time: 4.0089  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [360/431]  eta: 0:04:36  lr: 0.000100  loss: 0.0092 (0.0102)  time: 3.9975  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [370/431]  eta: 0:03:57  lr: 0.000100  loss: 0.0100 (0.0102)  time: 3.9314  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [380/431]  eta: 0:03:18  lr: 0.000100  loss: 0.0105 (0.0103)  time: 3.7826  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [390/431]  eta: 0:02:39  lr: 0.000100  loss: 0.0097 (0.0103)  time: 3.8814  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [400/431]  eta: 0:02:00  lr: 0.000100  loss: 0.0089 (0.0103)  time: 3.7609  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [410/431]  eta: 0:01:21  lr: 0.000100  loss: 0.0083 (0.0103)  time: 3.7693  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [420/431]  eta: 0:00:42  lr: 0.000100  loss: 0.0084 (0.0103)  time: 3.8362  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6]  [430/431]  eta: 0:00:03  lr: 0.000100  loss: 0.0087 (0.0103)  time: 3.7556  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:6] Total time: 0:27:51 (3.8782 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0087 (0.0103)\n",
      "Valid: [epoch:6]  [ 0/14]  eta: 0:03:36  loss: 0.0019 (0.0019)  time: 15.4373  data: 0.5938  max mem: 39468\n",
      "Valid: [epoch:6]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.0390  data: 0.0425  max mem: 39468\n",
      "Valid: [epoch:6] Total time: 0:03:30 (15.0574 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_6_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:7]  [  0/431]  eta: 0:57:59  lr: 0.000120  loss: 0.0123 (0.0123)  time: 8.0727  data: 4.0397  max mem: 39468\n",
      "Train: [epoch:7]  [ 10/431]  eta: 0:28:33  lr: 0.000120  loss: 0.0094 (0.0107)  time: 4.0696  data: 0.3675  max mem: 39468\n",
      "Train: [epoch:7]  [ 20/431]  eta: 0:26:33  lr: 0.000120  loss: 0.0095 (0.0107)  time: 3.6669  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [ 30/431]  eta: 0:25:33  lr: 0.000120  loss: 0.0097 (0.0102)  time: 3.6881  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [ 40/431]  eta: 0:24:24  lr: 0.000120  loss: 0.0093 (0.0103)  time: 3.6102  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [ 50/431]  eta: 0:23:47  lr: 0.000120  loss: 0.0089 (0.0103)  time: 3.6257  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [ 60/431]  eta: 0:23:43  lr: 0.000120  loss: 0.0095 (0.0102)  time: 4.0196  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [ 70/431]  eta: 0:22:52  lr: 0.000120  loss: 0.0114 (0.0105)  time: 3.9485  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [ 80/431]  eta: 0:22:12  lr: 0.000120  loss: 0.0100 (0.0104)  time: 3.6755  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [ 90/431]  eta: 0:21:20  lr: 0.000120  loss: 0.0093 (0.0105)  time: 3.5803  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [100/431]  eta: 0:20:42  lr: 0.000120  loss: 0.0099 (0.0104)  time: 3.5865  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [110/431]  eta: 0:20:05  lr: 0.000120  loss: 0.0091 (0.0104)  time: 3.7696  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [120/431]  eta: 0:19:27  lr: 0.000120  loss: 0.0091 (0.0103)  time: 3.7470  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [130/431]  eta: 0:18:58  lr: 0.000120  loss: 0.0088 (0.0103)  time: 3.9297  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [140/431]  eta: 0:18:22  lr: 0.000120  loss: 0.0089 (0.0103)  time: 4.0105  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:7]  [150/431]  eta: 0:17:50  lr: 0.000120  loss: 0.0087 (0.0101)  time: 3.9794  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:7]  [160/431]  eta: 0:17:10  lr: 0.000120  loss: 0.0081 (0.0100)  time: 3.8968  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:7]  [170/431]  eta: 0:16:30  lr: 0.000120  loss: 0.0089 (0.0101)  time: 3.6943  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [180/431]  eta: 0:15:56  lr: 0.000120  loss: 0.0094 (0.0101)  time: 3.8534  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [190/431]  eta: 0:15:23  lr: 0.000120  loss: 0.0103 (0.0101)  time: 4.1311  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [200/431]  eta: 0:14:45  lr: 0.000120  loss: 0.0103 (0.0101)  time: 4.0742  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [210/431]  eta: 0:14:08  lr: 0.000120  loss: 0.0096 (0.0101)  time: 3.9052  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [220/431]  eta: 0:13:30  lr: 0.000120  loss: 0.0099 (0.0101)  time: 3.8767  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [230/431]  eta: 0:12:50  lr: 0.000120  loss: 0.0086 (0.0101)  time: 3.7922  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [240/431]  eta: 0:12:12  lr: 0.000120  loss: 0.0081 (0.0100)  time: 3.7958  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [250/431]  eta: 0:11:36  lr: 0.000120  loss: 0.0089 (0.0101)  time: 4.0358  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [260/431]  eta: 0:10:59  lr: 0.000120  loss: 0.0096 (0.0100)  time: 4.0755  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [270/431]  eta: 0:10:21  lr: 0.000120  loss: 0.0102 (0.0101)  time: 4.0041  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [280/431]  eta: 0:09:43  lr: 0.000120  loss: 0.0102 (0.0101)  time: 3.9719  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [290/431]  eta: 0:09:03  lr: 0.000120  loss: 0.0087 (0.0101)  time: 3.7514  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [300/431]  eta: 0:08:25  lr: 0.000120  loss: 0.0087 (0.0101)  time: 3.8116  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [310/431]  eta: 0:07:47  lr: 0.000120  loss: 0.0087 (0.0101)  time: 3.9482  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [320/431]  eta: 0:07:09  lr: 0.000120  loss: 0.0087 (0.0101)  time: 4.0773  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [330/431]  eta: 0:06:30  lr: 0.000120  loss: 0.0097 (0.0101)  time: 3.9713  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [340/431]  eta: 0:05:52  lr: 0.000120  loss: 0.0115 (0.0102)  time: 3.8112  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [350/431]  eta: 0:05:13  lr: 0.000120  loss: 0.0108 (0.0102)  time: 3.8780  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [360/431]  eta: 0:04:35  lr: 0.000120  loss: 0.0098 (0.0102)  time: 4.0247  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [370/431]  eta: 0:03:56  lr: 0.000120  loss: 0.0089 (0.0102)  time: 4.0381  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [380/431]  eta: 0:03:17  lr: 0.000120  loss: 0.0100 (0.0102)  time: 3.9500  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [390/431]  eta: 0:02:39  lr: 0.000120  loss: 0.0108 (0.0102)  time: 3.9423  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [400/431]  eta: 0:02:00  lr: 0.000120  loss: 0.0092 (0.0102)  time: 3.7818  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [410/431]  eta: 0:01:21  lr: 0.000120  loss: 0.0097 (0.0102)  time: 3.7729  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [420/431]  eta: 0:00:42  lr: 0.000120  loss: 0.0097 (0.0102)  time: 3.7455  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7]  [430/431]  eta: 0:00:03  lr: 0.000120  loss: 0.0088 (0.0102)  time: 3.8702  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:7] Total time: 0:27:50 (3.8752 s / it)\n",
      "Averaged stats: lr: 0.000120  loss: 0.0088 (0.0102)\n",
      "Valid: [epoch:7]  [ 0/14]  eta: 0:03:35  loss: 0.0012 (0.0012)  time: 15.3782  data: 0.5558  max mem: 39468\n",
      "Valid: [epoch:7]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.8183  data: 0.0398  max mem: 39468\n",
      "Valid: [epoch:7] Total time: 0:03:27 (14.8362 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_7_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:8]  [  0/431]  eta: 0:40:50  lr: 0.000140  loss: 0.0056 (0.0056)  time: 5.6860  data: 2.3874  max mem: 39468\n",
      "Train: [epoch:8]  [ 10/431]  eta: 0:28:31  lr: 0.000140  loss: 0.0097 (0.0100)  time: 4.0659  data: 0.2172  max mem: 39468\n",
      "Train: [epoch:8]  [ 20/431]  eta: 0:26:37  lr: 0.000140  loss: 0.0111 (0.0105)  time: 3.7978  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [ 30/431]  eta: 0:26:06  lr: 0.000140  loss: 0.0084 (0.0096)  time: 3.8206  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [ 40/431]  eta: 0:25:55  lr: 0.000140  loss: 0.0084 (0.0100)  time: 4.0757  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [ 50/431]  eta: 0:25:11  lr: 0.000140  loss: 0.0100 (0.0103)  time: 4.0611  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [ 60/431]  eta: 0:24:38  lr: 0.000140  loss: 0.0104 (0.0103)  time: 3.9951  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [ 70/431]  eta: 0:24:03  lr: 0.000140  loss: 0.0102 (0.0103)  time: 4.0747  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [ 80/431]  eta: 0:23:11  lr: 0.000140  loss: 0.0091 (0.0102)  time: 3.9063  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [ 90/431]  eta: 0:22:23  lr: 0.000140  loss: 0.0091 (0.0103)  time: 3.7392  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [100/431]  eta: 0:21:32  lr: 0.000140  loss: 0.0099 (0.0102)  time: 3.6602  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [110/431]  eta: 0:20:52  lr: 0.000140  loss: 0.0098 (0.0102)  time: 3.7173  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [120/431]  eta: 0:20:11  lr: 0.000140  loss: 0.0103 (0.0103)  time: 3.8503  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [130/431]  eta: 0:19:25  lr: 0.000140  loss: 0.0103 (0.0103)  time: 3.7212  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [140/431]  eta: 0:18:52  lr: 0.000140  loss: 0.0091 (0.0103)  time: 3.8776  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [150/431]  eta: 0:18:13  lr: 0.000140  loss: 0.0090 (0.0102)  time: 4.0033  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [160/431]  eta: 0:17:45  lr: 0.000140  loss: 0.0075 (0.0101)  time: 4.2097  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [170/431]  eta: 0:17:16  lr: 0.000140  loss: 0.0077 (0.0100)  time: 4.5868  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [180/431]  eta: 0:16:46  lr: 0.000140  loss: 0.0081 (0.0100)  time: 4.6480  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [190/431]  eta: 0:16:11  lr: 0.000140  loss: 0.0083 (0.0100)  time: 4.5275  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [200/431]  eta: 0:15:41  lr: 0.000140  loss: 0.0094 (0.0099)  time: 4.6600  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [210/431]  eta: 0:15:05  lr: 0.000140  loss: 0.0083 (0.0099)  time: 4.7299  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [220/431]  eta: 0:14:31  lr: 0.000140  loss: 0.0091 (0.0100)  time: 4.6988  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [230/431]  eta: 0:13:53  lr: 0.000140  loss: 0.0092 (0.0100)  time: 4.6715  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [240/431]  eta: 0:13:18  lr: 0.000140  loss: 0.0082 (0.0099)  time: 4.7080  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [250/431]  eta: 0:12:37  lr: 0.000140  loss: 0.0106 (0.0101)  time: 4.6184  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [260/431]  eta: 0:12:02  lr: 0.000140  loss: 0.0111 (0.0101)  time: 4.7289  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [270/431]  eta: 0:11:20  lr: 0.000140  loss: 0.0095 (0.0101)  time: 4.7532  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [280/431]  eta: 0:10:42  lr: 0.000140  loss: 0.0088 (0.0101)  time: 4.6897  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [290/431]  eta: 0:10:00  lr: 0.000140  loss: 0.0093 (0.0101)  time: 4.7179  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [300/431]  eta: 0:09:19  lr: 0.000140  loss: 0.0093 (0.0101)  time: 4.5151  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [310/431]  eta: 0:08:38  lr: 0.000140  loss: 0.0090 (0.0101)  time: 4.6173  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [320/431]  eta: 0:07:56  lr: 0.000140  loss: 0.0090 (0.0101)  time: 4.5792  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [330/431]  eta: 0:07:15  lr: 0.000140  loss: 0.0092 (0.0101)  time: 4.6915  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [340/431]  eta: 0:06:32  lr: 0.000140  loss: 0.0102 (0.0102)  time: 4.5763  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [350/431]  eta: 0:05:50  lr: 0.000140  loss: 0.0108 (0.0102)  time: 4.6452  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [360/431]  eta: 0:05:07  lr: 0.000140  loss: 0.0101 (0.0102)  time: 4.6121  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [370/431]  eta: 0:04:25  lr: 0.000140  loss: 0.0101 (0.0102)  time: 4.7077  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [380/431]  eta: 0:03:41  lr: 0.000140  loss: 0.0096 (0.0102)  time: 4.6698  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [390/431]  eta: 0:02:58  lr: 0.000140  loss: 0.0096 (0.0103)  time: 4.6791  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [400/431]  eta: 0:02:15  lr: 0.000140  loss: 0.0088 (0.0102)  time: 4.6610  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [410/431]  eta: 0:01:31  lr: 0.000140  loss: 0.0098 (0.0103)  time: 4.6912  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [420/431]  eta: 0:00:48  lr: 0.000140  loss: 0.0113 (0.0103)  time: 4.6094  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8]  [430/431]  eta: 0:00:04  lr: 0.000140  loss: 0.0094 (0.0103)  time: 4.6088  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:8] Total time: 0:31:32 (4.3915 s / it)\n",
      "Averaged stats: lr: 0.000140  loss: 0.0094 (0.0103)\n",
      "Valid: [epoch:8]  [ 0/14]  eta: 0:03:49  loss: 0.0013 (0.0013)  time: 16.3617  data: 0.6080  max mem: 39468\n",
      "Valid: [epoch:8]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.2476  data: 0.0435  max mem: 39468\n",
      "Valid: [epoch:8] Total time: 0:03:33 (15.2614 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_8_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:9]  [  0/431]  eta: 0:59:41  lr: 0.000160  loss: 0.0062 (0.0062)  time: 8.3097  data: 2.9593  max mem: 39468\n",
      "Train: [epoch:9]  [ 10/431]  eta: 0:31:03  lr: 0.000160  loss: 0.0103 (0.0107)  time: 4.4271  data: 0.2692  max mem: 39468\n",
      "Train: [epoch:9]  [ 20/431]  eta: 0:32:18  lr: 0.000160  loss: 0.0084 (0.0092)  time: 4.5363  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [ 30/431]  eta: 0:30:09  lr: 0.000160  loss: 0.0075 (0.0086)  time: 4.5605  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [ 40/431]  eta: 0:30:06  lr: 0.000160  loss: 0.0081 (0.0088)  time: 4.5178  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [ 50/431]  eta: 0:29:04  lr: 0.000160  loss: 0.0090 (0.0088)  time: 4.6799  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [ 60/431]  eta: 0:28:38  lr: 0.000160  loss: 0.0103 (0.0091)  time: 4.6542  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [ 70/431]  eta: 0:27:34  lr: 0.000160  loss: 0.0105 (0.0092)  time: 4.5929  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [ 80/431]  eta: 0:27:18  lr: 0.000160  loss: 0.0102 (0.0094)  time: 4.7796  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [ 90/431]  eta: 0:26:13  lr: 0.000160  loss: 0.0098 (0.0094)  time: 4.7295  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [100/431]  eta: 0:25:40  lr: 0.000160  loss: 0.0093 (0.0095)  time: 4.5947  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [110/431]  eta: 0:24:36  lr: 0.000160  loss: 0.0102 (0.0097)  time: 4.5373  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [120/431]  eta: 0:24:08  lr: 0.000160  loss: 0.0102 (0.0098)  time: 4.6750  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [130/431]  eta: 0:23:08  lr: 0.000160  loss: 0.0097 (0.0098)  time: 4.6831  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [140/431]  eta: 0:22:29  lr: 0.000160  loss: 0.0117 (0.0100)  time: 4.5144  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [150/431]  eta: 0:21:34  lr: 0.000160  loss: 0.0108 (0.0100)  time: 4.5555  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [160/431]  eta: 0:20:52  lr: 0.000160  loss: 0.0088 (0.0100)  time: 4.5283  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [170/431]  eta: 0:19:55  lr: 0.000160  loss: 0.0093 (0.0099)  time: 4.3971  data: 0.0002  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [180/431]  eta: 0:19:14  lr: 0.000160  loss: 0.0085 (0.0099)  time: 4.3967  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [190/431]  eta: 0:18:20  lr: 0.000160  loss: 0.0091 (0.0100)  time: 4.4195  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [200/431]  eta: 0:17:42  lr: 0.000160  loss: 0.0096 (0.0100)  time: 4.6118  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [210/431]  eta: 0:16:53  lr: 0.000160  loss: 0.0092 (0.0100)  time: 4.7982  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [220/431]  eta: 0:16:12  lr: 0.000160  loss: 0.0087 (0.0100)  time: 4.6954  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [230/431]  eta: 0:15:21  lr: 0.000160  loss: 0.0083 (0.0099)  time: 4.5846  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [240/431]  eta: 0:14:38  lr: 0.000160  loss: 0.0084 (0.0100)  time: 4.4857  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [250/431]  eta: 0:13:51  lr: 0.000160  loss: 0.0098 (0.0100)  time: 4.7062  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [260/431]  eta: 0:13:07  lr: 0.000160  loss: 0.0099 (0.0100)  time: 4.6829  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [270/431]  eta: 0:12:19  lr: 0.000160  loss: 0.0085 (0.0101)  time: 4.5936  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [280/431]  eta: 0:11:33  lr: 0.000160  loss: 0.0098 (0.0101)  time: 4.4838  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [290/431]  eta: 0:10:45  lr: 0.000160  loss: 0.0098 (0.0101)  time: 4.3421  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [300/431]  eta: 0:10:00  lr: 0.000160  loss: 0.0083 (0.0100)  time: 4.4467  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [310/431]  eta: 0:09:13  lr: 0.000160  loss: 0.0083 (0.0101)  time: 4.5798  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [320/431]  eta: 0:08:28  lr: 0.000160  loss: 0.0105 (0.0101)  time: 4.5521  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [330/431]  eta: 0:07:42  lr: 0.000160  loss: 0.0113 (0.0101)  time: 4.5111  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [340/431]  eta: 0:06:56  lr: 0.000160  loss: 0.0107 (0.0102)  time: 4.4992  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [350/431]  eta: 0:06:11  lr: 0.000160  loss: 0.0085 (0.0101)  time: 4.7619  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [360/431]  eta: 0:05:25  lr: 0.000160  loss: 0.0085 (0.0101)  time: 4.6146  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [370/431]  eta: 0:04:39  lr: 0.000160  loss: 0.0090 (0.0101)  time: 4.4476  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [380/431]  eta: 0:03:53  lr: 0.000160  loss: 0.0085 (0.0101)  time: 4.4719  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [390/431]  eta: 0:03:07  lr: 0.000160  loss: 0.0077 (0.0101)  time: 4.5827  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [400/431]  eta: 0:02:22  lr: 0.000160  loss: 0.0077 (0.0101)  time: 4.7485  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [410/431]  eta: 0:01:36  lr: 0.000160  loss: 0.0097 (0.0101)  time: 4.7978  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [420/431]  eta: 0:00:50  lr: 0.000160  loss: 0.0107 (0.0101)  time: 4.5669  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9]  [430/431]  eta: 0:00:04  lr: 0.000160  loss: 0.0107 (0.0102)  time: 4.6507  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:9] Total time: 0:32:59 (4.5922 s / it)\n",
      "Averaged stats: lr: 0.000160  loss: 0.0107 (0.0102)\n",
      "Valid: [epoch:9]  [ 0/14]  eta: 0:03:40  loss: 0.0024 (0.0024)  time: 15.7582  data: 0.5650  max mem: 39468\n",
      "Valid: [epoch:9]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.3940  data: 0.0405  max mem: 39468\n",
      "Valid: [epoch:9] Total time: 0:03:35 (15.4097 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_9_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:10]  [  0/431]  eta: 0:54:37  lr: 0.000180  loss: 0.0076 (0.0076)  time: 7.6053  data: 2.3296  max mem: 39468\n",
      "Train: [epoch:10]  [ 10/431]  eta: 0:32:39  lr: 0.000180  loss: 0.0081 (0.0088)  time: 4.6554  data: 0.2120  max mem: 39468\n",
      "Train: [epoch:10]  [ 20/431]  eta: 0:31:24  lr: 0.000180  loss: 0.0083 (0.0096)  time: 4.4332  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [ 30/431]  eta: 0:30:02  lr: 0.000180  loss: 0.0084 (0.0092)  time: 4.4069  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [ 40/431]  eta: 0:29:56  lr: 0.000180  loss: 0.0084 (0.0093)  time: 4.6048  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [ 50/431]  eta: 0:28:43  lr: 0.000180  loss: 0.0086 (0.0094)  time: 4.5674  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [ 60/431]  eta: 0:28:25  lr: 0.000180  loss: 0.0092 (0.0093)  time: 4.5993  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [ 70/431]  eta: 0:28:57  lr: 0.000180  loss: 0.0092 (0.0094)  time: 5.5467  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [ 80/431]  eta: 0:28:25  lr: 0.000180  loss: 0.0092 (0.0095)  time: 5.6574  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [ 90/431]  eta: 0:27:16  lr: 0.000180  loss: 0.0095 (0.0096)  time: 4.7550  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [100/431]  eta: 0:26:27  lr: 0.000180  loss: 0.0091 (0.0096)  time: 4.5488  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [110/431]  eta: 0:25:43  lr: 0.000180  loss: 0.0091 (0.0097)  time: 4.8548  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [120/431]  eta: 0:24:39  lr: 0.000180  loss: 0.0099 (0.0098)  time: 4.5578  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [130/431]  eta: 0:23:45  lr: 0.000180  loss: 0.0109 (0.0099)  time: 4.3188  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [140/431]  eta: 0:23:24  lr: 0.000180  loss: 0.0112 (0.0100)  time: 5.2363  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [150/431]  eta: 0:22:54  lr: 0.000180  loss: 0.0106 (0.0100)  time: 5.9175  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [160/431]  eta: 0:21:59  lr: 0.000180  loss: 0.0085 (0.0099)  time: 5.1716  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [170/431]  eta: 0:21:09  lr: 0.000180  loss: 0.0082 (0.0098)  time: 4.6481  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [180/431]  eta: 0:20:20  lr: 0.000180  loss: 0.0084 (0.0098)  time: 4.8277  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [190/431]  eta: 0:19:29  lr: 0.000180  loss: 0.0097 (0.0098)  time: 4.7662  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [200/431]  eta: 0:18:56  lr: 0.000180  loss: 0.0090 (0.0098)  time: 5.4378  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [210/431]  eta: 0:18:19  lr: 0.000180  loss: 0.0090 (0.0098)  time: 6.1626  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [220/431]  eta: 0:17:41  lr: 0.000180  loss: 0.0084 (0.0098)  time: 6.1519  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [230/431]  eta: 0:17:01  lr: 0.000180  loss: 0.0086 (0.0098)  time: 6.1872  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [240/431]  eta: 0:16:19  lr: 0.000180  loss: 0.0087 (0.0098)  time: 6.1774  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [250/431]  eta: 0:15:35  lr: 0.000180  loss: 0.0089 (0.0098)  time: 6.1898  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [260/431]  eta: 0:14:48  lr: 0.000180  loss: 0.0096 (0.0099)  time: 6.0387  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [270/431]  eta: 0:14:02  lr: 0.000180  loss: 0.0097 (0.0099)  time: 6.0255  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [280/431]  eta: 0:13:15  lr: 0.000180  loss: 0.0097 (0.0099)  time: 6.1563  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [290/431]  eta: 0:12:27  lr: 0.000180  loss: 0.0100 (0.0099)  time: 6.1817  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [300/431]  eta: 0:11:38  lr: 0.000180  loss: 0.0095 (0.0099)  time: 6.2124  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [310/431]  eta: 0:10:47  lr: 0.000180  loss: 0.0095 (0.0100)  time: 6.1773  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [320/431]  eta: 0:09:57  lr: 0.000180  loss: 0.0099 (0.0100)  time: 6.2033  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [330/431]  eta: 0:09:06  lr: 0.000180  loss: 0.0079 (0.0100)  time: 6.2467  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [340/431]  eta: 0:08:14  lr: 0.000180  loss: 0.0083 (0.0100)  time: 6.2164  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [350/431]  eta: 0:07:21  lr: 0.000180  loss: 0.0099 (0.0100)  time: 6.2023  data: 0.0002  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [360/431]  eta: 0:06:27  lr: 0.000180  loss: 0.0111 (0.0101)  time: 5.8986  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [370/431]  eta: 0:05:34  lr: 0.000180  loss: 0.0112 (0.0101)  time: 5.8940  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [380/431]  eta: 0:04:40  lr: 0.000180  loss: 0.0092 (0.0101)  time: 6.2026  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [390/431]  eta: 0:03:46  lr: 0.000180  loss: 0.0095 (0.0102)  time: 6.2027  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [400/431]  eta: 0:02:51  lr: 0.000180  loss: 0.0095 (0.0102)  time: 6.1843  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [410/431]  eta: 0:01:56  lr: 0.000180  loss: 0.0090 (0.0101)  time: 6.1691  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [420/431]  eta: 0:01:01  lr: 0.000180  loss: 0.0095 (0.0102)  time: 6.1830  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10]  [430/431]  eta: 0:00:05  lr: 0.000180  loss: 0.0105 (0.0102)  time: 6.1773  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:10] Total time: 0:40:03 (5.5765 s / it)\n",
      "Averaged stats: lr: 0.000180  loss: 0.0105 (0.0102)\n",
      "Valid: [epoch:10]  [ 0/14]  eta: 0:06:58  loss: 0.0015 (0.0015)  time: 29.8922  data: 0.6179  max mem: 39468\n",
      "Valid: [epoch:10]  [13/14]  eta: 0:00:28  loss: 0.0015 (0.0018)  time: 28.6258  data: 0.0443  max mem: 39468\n",
      "Valid: [epoch:10] Total time: 0:06:40 (28.6423 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_10_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:11]  [  0/431]  eta: 1:07:51  lr: 0.000200  loss: 0.0066 (0.0066)  time: 9.4459  data: 3.4030  max mem: 39468\n",
      "Train: [epoch:11]  [ 10/431]  eta: 0:45:27  lr: 0.000200  loss: 0.0089 (0.0092)  time: 6.4791  data: 0.3095  max mem: 39468\n",
      "Train: [epoch:11]  [ 20/431]  eta: 0:42:50  lr: 0.000200  loss: 0.0086 (0.0091)  time: 6.0951  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [ 30/431]  eta: 0:41:37  lr: 0.000200  loss: 0.0085 (0.0093)  time: 6.0895  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [ 40/431]  eta: 0:40:29  lr: 0.000200  loss: 0.0100 (0.0096)  time: 6.1695  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [ 50/431]  eta: 0:39:23  lr: 0.000200  loss: 0.0100 (0.0095)  time: 6.1651  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [ 60/431]  eta: 0:38:17  lr: 0.000200  loss: 0.0100 (0.0100)  time: 6.1529  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [ 70/431]  eta: 0:37:14  lr: 0.000200  loss: 0.0119 (0.0101)  time: 6.1538  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [ 80/431]  eta: 0:36:13  lr: 0.000200  loss: 0.0100 (0.0102)  time: 6.1870  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [ 90/431]  eta: 0:35:10  lr: 0.000200  loss: 0.0098 (0.0102)  time: 6.1875  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [100/431]  eta: 0:34:08  lr: 0.000200  loss: 0.0093 (0.0101)  time: 6.1811  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [110/431]  eta: 0:33:08  lr: 0.000200  loss: 0.0092 (0.0101)  time: 6.2148  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [120/431]  eta: 0:31:47  lr: 0.000200  loss: 0.0101 (0.0101)  time: 5.8545  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [130/431]  eta: 0:30:48  lr: 0.000200  loss: 0.0097 (0.0101)  time: 5.8596  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [140/431]  eta: 0:29:48  lr: 0.000200  loss: 0.0102 (0.0102)  time: 6.2125  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [150/431]  eta: 0:28:48  lr: 0.000200  loss: 0.0093 (0.0101)  time: 6.2092  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [160/431]  eta: 0:27:47  lr: 0.000200  loss: 0.0079 (0.0100)  time: 6.2132  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [170/431]  eta: 0:26:47  lr: 0.000200  loss: 0.0088 (0.0100)  time: 6.2043  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [180/431]  eta: 0:25:45  lr: 0.000200  loss: 0.0071 (0.0099)  time: 6.2014  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [190/431]  eta: 0:24:44  lr: 0.000200  loss: 0.0088 (0.0099)  time: 6.1696  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [200/431]  eta: 0:23:43  lr: 0.000200  loss: 0.0088 (0.0099)  time: 6.1956  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [210/431]  eta: 0:22:42  lr: 0.000200  loss: 0.0080 (0.0099)  time: 6.2038  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [220/431]  eta: 0:21:21  lr: 0.000200  loss: 0.0103 (0.0099)  time: 5.1577  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [230/431]  eta: 0:20:14  lr: 0.000200  loss: 0.0110 (0.0100)  time: 4.7499  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [240/431]  eta: 0:19:03  lr: 0.000200  loss: 0.0096 (0.0099)  time: 5.0243  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [250/431]  eta: 0:17:55  lr: 0.000200  loss: 0.0097 (0.0099)  time: 4.7787  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [260/431]  eta: 0:16:43  lr: 0.000200  loss: 0.0094 (0.0099)  time: 4.4308  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [270/431]  eta: 0:15:40  lr: 0.000200  loss: 0.0088 (0.0099)  time: 4.5940  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [280/431]  eta: 0:14:34  lr: 0.000200  loss: 0.0110 (0.0099)  time: 4.7956  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [290/431]  eta: 0:13:31  lr: 0.000200  loss: 0.0113 (0.0100)  time: 4.5487  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [300/431]  eta: 0:12:29  lr: 0.000200  loss: 0.0101 (0.0100)  time: 4.7611  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [310/431]  eta: 0:11:26  lr: 0.000200  loss: 0.0098 (0.0101)  time: 4.5557  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [320/431]  eta: 0:10:23  lr: 0.000200  loss: 0.0099 (0.0101)  time: 3.9956  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [330/431]  eta: 0:09:21  lr: 0.000200  loss: 0.0102 (0.0102)  time: 3.7586  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [340/431]  eta: 0:08:21  lr: 0.000200  loss: 0.0105 (0.0102)  time: 3.7777  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [350/431]  eta: 0:07:21  lr: 0.000200  loss: 0.0097 (0.0102)  time: 3.6981  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [360/431]  eta: 0:06:23  lr: 0.000200  loss: 0.0085 (0.0103)  time: 3.6805  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [370/431]  eta: 0:05:27  lr: 0.000200  loss: 0.0094 (0.0102)  time: 3.7687  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [380/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0088 (0.0102)  time: 3.7862  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [390/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0088 (0.0102)  time: 3.7809  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [400/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0096 (0.0102)  time: 3.8336  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [410/431]  eta: 0:01:49  lr: 0.000200  loss: 0.0098 (0.0102)  time: 3.9409  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [420/431]  eta: 0:00:56  lr: 0.000200  loss: 0.0093 (0.0102)  time: 3.8913  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11]  [430/431]  eta: 0:00:05  lr: 0.000200  loss: 0.0106 (0.0103)  time: 3.7688  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:11] Total time: 0:36:59 (5.1499 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0106 (0.0103)\n",
      "Valid: [epoch:11]  [ 0/14]  eta: 0:03:40  loss: 0.0024 (0.0024)  time: 15.7706  data: 0.6527  max mem: 39468\n",
      "Valid: [epoch:11]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.1327  data: 0.0467  max mem: 39468\n",
      "Valid: [epoch:11] Total time: 0:03:32 (15.1454 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_11_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:12]  [  0/431]  eta: 1:00:14  lr: 0.000200  loss: 0.0091 (0.0091)  time: 8.3871  data: 2.9209  max mem: 39468\n",
      "Train: [epoch:12]  [ 10/431]  eta: 0:33:26  lr: 0.000200  loss: 0.0091 (0.0108)  time: 4.7650  data: 0.2658  max mem: 39468\n",
      "Train: [epoch:12]  [ 20/431]  eta: 0:31:26  lr: 0.000200  loss: 0.0088 (0.0102)  time: 4.4011  data: 0.0003  max mem: 39468\n",
      "Train: [epoch:12]  [ 30/431]  eta: 0:30:37  lr: 0.000200  loss: 0.0084 (0.0096)  time: 4.4815  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [ 40/431]  eta: 0:29:42  lr: 0.000200  loss: 0.0084 (0.0100)  time: 4.5256  data: 0.0002  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [ 50/431]  eta: 0:28:45  lr: 0.000200  loss: 0.0100 (0.0099)  time: 4.4433  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [ 60/431]  eta: 0:27:55  lr: 0.000200  loss: 0.0099 (0.0099)  time: 4.4277  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [ 70/431]  eta: 0:27:05  lr: 0.000200  loss: 0.0096 (0.0099)  time: 4.4441  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [ 80/431]  eta: 0:26:19  lr: 0.000200  loss: 0.0081 (0.0097)  time: 4.4455  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [ 90/431]  eta: 0:25:29  lr: 0.000200  loss: 0.0081 (0.0096)  time: 4.4149  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [100/431]  eta: 0:24:43  lr: 0.000200  loss: 0.0086 (0.0096)  time: 4.4167  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [110/431]  eta: 0:24:00  lr: 0.000200  loss: 0.0088 (0.0096)  time: 4.4929  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [120/431]  eta: 0:23:11  lr: 0.000200  loss: 0.0088 (0.0096)  time: 4.4265  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [130/431]  eta: 0:22:26  lr: 0.000200  loss: 0.0083 (0.0097)  time: 4.3931  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [140/431]  eta: 0:21:39  lr: 0.000200  loss: 0.0091 (0.0097)  time: 4.4182  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [150/431]  eta: 0:20:52  lr: 0.000200  loss: 0.0097 (0.0097)  time: 4.3651  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [160/431]  eta: 0:20:10  lr: 0.000200  loss: 0.0096 (0.0097)  time: 4.4800  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [170/431]  eta: 0:19:27  lr: 0.000200  loss: 0.0096 (0.0097)  time: 4.5965  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [180/431]  eta: 0:18:40  lr: 0.000200  loss: 0.0101 (0.0098)  time: 4.4550  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [190/431]  eta: 0:17:54  lr: 0.000200  loss: 0.0101 (0.0098)  time: 4.3098  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [200/431]  eta: 0:17:11  lr: 0.000200  loss: 0.0101 (0.0099)  time: 4.4490  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [210/431]  eta: 0:16:26  lr: 0.000200  loss: 0.0090 (0.0098)  time: 4.5146  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [220/431]  eta: 0:15:42  lr: 0.000200  loss: 0.0088 (0.0098)  time: 4.5018  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [230/431]  eta: 0:14:56  lr: 0.000200  loss: 0.0088 (0.0098)  time: 4.4675  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [240/431]  eta: 0:14:12  lr: 0.000200  loss: 0.0085 (0.0098)  time: 4.3999  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [250/431]  eta: 0:13:28  lr: 0.000200  loss: 0.0112 (0.0099)  time: 4.5387  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [260/431]  eta: 0:12:45  lr: 0.000200  loss: 0.0116 (0.0099)  time: 4.6419  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [270/431]  eta: 0:12:01  lr: 0.000200  loss: 0.0119 (0.0101)  time: 4.6398  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [280/431]  eta: 0:11:16  lr: 0.000200  loss: 0.0091 (0.0100)  time: 4.5369  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [290/431]  eta: 0:10:31  lr: 0.000200  loss: 0.0101 (0.0101)  time: 4.3938  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [300/431]  eta: 0:09:46  lr: 0.000200  loss: 0.0109 (0.0101)  time: 4.4290  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [310/431]  eta: 0:09:02  lr: 0.000200  loss: 0.0115 (0.0102)  time: 4.5653  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [320/431]  eta: 0:08:17  lr: 0.000200  loss: 0.0130 (0.0103)  time: 4.5567  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [330/431]  eta: 0:07:31  lr: 0.000200  loss: 0.0097 (0.0102)  time: 4.3597  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [340/431]  eta: 0:06:47  lr: 0.000200  loss: 0.0095 (0.0103)  time: 4.4168  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [350/431]  eta: 0:06:02  lr: 0.000200  loss: 0.0105 (0.0103)  time: 4.5767  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [360/431]  eta: 0:05:18  lr: 0.000200  loss: 0.0110 (0.0103)  time: 4.5713  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [370/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0090 (0.0103)  time: 4.5228  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [380/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0086 (0.0103)  time: 4.4163  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [390/431]  eta: 0:03:03  lr: 0.000200  loss: 0.0093 (0.0103)  time: 4.4230  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [400/431]  eta: 0:02:18  lr: 0.000200  loss: 0.0093 (0.0103)  time: 4.4808  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [410/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0094 (0.0103)  time: 4.4712  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [420/431]  eta: 0:00:49  lr: 0.000200  loss: 0.0091 (0.0103)  time: 4.4735  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12]  [430/431]  eta: 0:00:04  lr: 0.000200  loss: 0.0092 (0.0103)  time: 4.4928  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:12] Total time: 0:32:10 (4.4800 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0092 (0.0103)\n",
      "Valid: [epoch:12]  [ 0/14]  eta: 0:03:44  loss: 0.0007 (0.0007)  time: 16.0423  data: 0.6167  max mem: 39468\n",
      "Valid: [epoch:12]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.7145  data: 0.0442  max mem: 39468\n",
      "Valid: [epoch:12] Total time: 0:03:40 (15.7313 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_12_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:13]  [  0/431]  eta: 1:06:02  lr: 0.000200  loss: 0.0090 (0.0090)  time: 9.1928  data: 3.9471  max mem: 39468\n",
      "Train: [epoch:13]  [ 10/431]  eta: 0:34:02  lr: 0.000200  loss: 0.0088 (0.0095)  time: 4.8514  data: 0.3590  max mem: 39468\n",
      "Train: [epoch:13]  [ 20/431]  eta: 0:32:21  lr: 0.000200  loss: 0.0085 (0.0101)  time: 4.5011  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [ 30/431]  eta: 0:30:59  lr: 0.000200  loss: 0.0085 (0.0099)  time: 4.5174  data: 0.0003  max mem: 39468\n",
      "Train: [epoch:13]  [ 40/431]  eta: 0:29:55  lr: 0.000200  loss: 0.0086 (0.0100)  time: 4.4514  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [ 50/431]  eta: 0:29:10  lr: 0.000200  loss: 0.0089 (0.0101)  time: 4.5316  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [ 60/431]  eta: 0:28:27  lr: 0.000200  loss: 0.0092 (0.0102)  time: 4.6281  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [ 70/431]  eta: 0:27:40  lr: 0.000200  loss: 0.0087 (0.0100)  time: 4.6164  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [ 80/431]  eta: 0:26:45  lr: 0.000200  loss: 0.0085 (0.0101)  time: 4.4840  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [ 90/431]  eta: 0:25:51  lr: 0.000200  loss: 0.0095 (0.0102)  time: 4.3625  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [100/431]  eta: 0:25:06  lr: 0.000200  loss: 0.0106 (0.0102)  time: 4.4590  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [110/431]  eta: 0:24:19  lr: 0.000200  loss: 0.0099 (0.0103)  time: 4.5362  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [120/431]  eta: 0:23:30  lr: 0.000200  loss: 0.0096 (0.0102)  time: 4.4481  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [130/431]  eta: 0:22:46  lr: 0.000200  loss: 0.0093 (0.0102)  time: 4.4979  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [140/431]  eta: 0:22:00  lr: 0.000200  loss: 0.0091 (0.0102)  time: 4.5520  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [150/431]  eta: 0:21:14  lr: 0.000200  loss: 0.0090 (0.0102)  time: 4.5222  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [160/431]  eta: 0:20:30  lr: 0.000200  loss: 0.0080 (0.0100)  time: 4.5540  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [170/431]  eta: 0:19:44  lr: 0.000200  loss: 0.0073 (0.0100)  time: 4.5501  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [180/431]  eta: 0:18:59  lr: 0.000200  loss: 0.0095 (0.0101)  time: 4.5504  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [190/431]  eta: 0:18:12  lr: 0.000200  loss: 0.0095 (0.0101)  time: 4.4917  data: 0.0001  max mem: 39468\n",
      "Train: [epoch:13]  [200/431]  eta: 0:17:26  lr: 0.000200  loss: 0.0087 (0.0101)  time: 4.4382  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [210/431]  eta: 0:16:38  lr: 0.000200  loss: 0.0083 (0.0101)  time: 4.3665  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [220/431]  eta: 0:15:52  lr: 0.000200  loss: 0.0094 (0.0100)  time: 4.3620  data: 0.0002  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [230/431]  eta: 0:15:07  lr: 0.000200  loss: 0.0098 (0.0101)  time: 4.4853  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [240/431]  eta: 0:14:21  lr: 0.000200  loss: 0.0098 (0.0101)  time: 4.4506  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [250/431]  eta: 0:13:36  lr: 0.000200  loss: 0.0102 (0.0101)  time: 4.4931  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [260/431]  eta: 0:12:52  lr: 0.000200  loss: 0.0092 (0.0101)  time: 4.6107  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [270/431]  eta: 0:12:07  lr: 0.000200  loss: 0.0090 (0.0101)  time: 4.6164  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [280/431]  eta: 0:11:23  lr: 0.000200  loss: 0.0117 (0.0102)  time: 4.6307  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [290/431]  eta: 0:10:38  lr: 0.000200  loss: 0.0110 (0.0102)  time: 4.6298  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [300/431]  eta: 0:09:53  lr: 0.000200  loss: 0.0103 (0.0102)  time: 4.6017  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [310/431]  eta: 0:09:07  lr: 0.000200  loss: 0.0092 (0.0102)  time: 4.5037  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [320/431]  eta: 0:08:22  lr: 0.000200  loss: 0.0088 (0.0102)  time: 4.4778  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [330/431]  eta: 0:07:37  lr: 0.000200  loss: 0.0095 (0.0102)  time: 4.5357  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [340/431]  eta: 0:06:52  lr: 0.000200  loss: 0.0115 (0.0103)  time: 4.5784  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [350/431]  eta: 0:06:07  lr: 0.000200  loss: 0.0091 (0.0102)  time: 4.6132  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [360/431]  eta: 0:05:21  lr: 0.000200  loss: 0.0090 (0.0102)  time: 4.5715  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [370/431]  eta: 0:04:36  lr: 0.000200  loss: 0.0094 (0.0102)  time: 4.4690  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [380/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0085 (0.0102)  time: 4.4770  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [390/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0099 (0.0102)  time: 4.5495  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [400/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0109 (0.0102)  time: 4.6181  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [410/431]  eta: 0:01:35  lr: 0.000200  loss: 0.0109 (0.0103)  time: 4.6052  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [420/431]  eta: 0:00:49  lr: 0.000200  loss: 0.0107 (0.0103)  time: 4.5239  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13]  [430/431]  eta: 0:00:04  lr: 0.000200  loss: 0.0104 (0.0103)  time: 4.5179  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:13] Total time: 0:32:33 (4.5334 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0104 (0.0103)\n",
      "Valid: [epoch:13]  [ 0/14]  eta: 0:04:01  loss: 0.0025 (0.0025)  time: 17.2665  data: 0.5958  max mem: 39468\n",
      "Valid: [epoch:13]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.8125  data: 0.0427  max mem: 39468\n",
      "Valid: [epoch:13] Total time: 0:03:41 (15.8318 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_13_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:14]  [  0/431]  eta: 1:07:07  lr: 0.000200  loss: 0.0100 (0.0100)  time: 9.3440  data: 4.4297  max mem: 39468\n",
      "Train: [epoch:14]  [ 10/431]  eta: 0:33:33  lr: 0.000200  loss: 0.0098 (0.0097)  time: 4.7828  data: 0.4029  max mem: 39468\n",
      "Train: [epoch:14]  [ 20/431]  eta: 0:31:28  lr: 0.000200  loss: 0.0097 (0.0100)  time: 4.3571  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [ 30/431]  eta: 0:30:30  lr: 0.000200  loss: 0.0110 (0.0108)  time: 4.4452  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [ 40/431]  eta: 0:29:33  lr: 0.000200  loss: 0.0122 (0.0111)  time: 4.4760  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [ 50/431]  eta: 0:28:31  lr: 0.000200  loss: 0.0111 (0.0108)  time: 4.3811  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [ 60/431]  eta: 0:27:28  lr: 0.000200  loss: 0.0085 (0.0105)  time: 4.2530  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [ 70/431]  eta: 0:26:41  lr: 0.000200  loss: 0.0085 (0.0104)  time: 4.2933  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [ 80/431]  eta: 0:25:48  lr: 0.000200  loss: 0.0084 (0.0103)  time: 4.3117  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [ 90/431]  eta: 0:24:56  lr: 0.000200  loss: 0.0080 (0.0103)  time: 4.2122  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [100/431]  eta: 0:24:03  lr: 0.000200  loss: 0.0083 (0.0102)  time: 4.1630  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [110/431]  eta: 0:23:20  lr: 0.000200  loss: 0.0091 (0.0101)  time: 4.2573  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [120/431]  eta: 0:22:36  lr: 0.000200  loss: 0.0097 (0.0101)  time: 4.3673  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [130/431]  eta: 0:21:55  lr: 0.000200  loss: 0.0091 (0.0101)  time: 4.4027  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [140/431]  eta: 0:21:12  lr: 0.000200  loss: 0.0096 (0.0103)  time: 4.4444  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [150/431]  eta: 0:20:28  lr: 0.000200  loss: 0.0097 (0.0102)  time: 4.3755  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [160/431]  eta: 0:19:41  lr: 0.000200  loss: 0.0083 (0.0101)  time: 4.2561  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [170/431]  eta: 0:18:58  lr: 0.000200  loss: 0.0096 (0.0101)  time: 4.2892  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [180/431]  eta: 0:18:15  lr: 0.000200  loss: 0.0097 (0.0102)  time: 4.4119  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [190/431]  eta: 0:17:31  lr: 0.000200  loss: 0.0104 (0.0103)  time: 4.3726  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [200/431]  eta: 0:16:47  lr: 0.000200  loss: 0.0095 (0.0102)  time: 4.3151  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [210/431]  eta: 0:16:04  lr: 0.000200  loss: 0.0089 (0.0102)  time: 4.3666  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [220/431]  eta: 0:15:19  lr: 0.000200  loss: 0.0088 (0.0101)  time: 4.3321  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [230/431]  eta: 0:14:34  lr: 0.000200  loss: 0.0086 (0.0101)  time: 4.2086  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [240/431]  eta: 0:13:51  lr: 0.000200  loss: 0.0081 (0.0100)  time: 4.3170  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [250/431]  eta: 0:13:08  lr: 0.000200  loss: 0.0100 (0.0101)  time: 4.4123  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [260/431]  eta: 0:12:24  lr: 0.000200  loss: 0.0102 (0.0101)  time: 4.3681  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [270/431]  eta: 0:11:41  lr: 0.000200  loss: 0.0092 (0.0101)  time: 4.3788  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [280/431]  eta: 0:10:57  lr: 0.000200  loss: 0.0089 (0.0101)  time: 4.3614  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [290/431]  eta: 0:10:14  lr: 0.000200  loss: 0.0107 (0.0102)  time: 4.3813  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [300/431]  eta: 0:09:30  lr: 0.000200  loss: 0.0101 (0.0102)  time: 4.3185  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [310/431]  eta: 0:08:46  lr: 0.000200  loss: 0.0084 (0.0102)  time: 4.2879  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [320/431]  eta: 0:08:03  lr: 0.000200  loss: 0.0082 (0.0101)  time: 4.3968  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [330/431]  eta: 0:07:19  lr: 0.000200  loss: 0.0084 (0.0101)  time: 4.3886  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [340/431]  eta: 0:06:36  lr: 0.000200  loss: 0.0093 (0.0101)  time: 4.3903  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [350/431]  eta: 0:05:53  lr: 0.000200  loss: 0.0084 (0.0101)  time: 4.4350  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [360/431]  eta: 0:05:09  lr: 0.000200  loss: 0.0095 (0.0101)  time: 4.3791  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [370/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0097 (0.0101)  time: 4.2173  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [380/431]  eta: 0:03:41  lr: 0.000200  loss: 0.0092 (0.0101)  time: 4.2347  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [390/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0099 (0.0101)  time: 4.3860  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [400/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0104 (0.0101)  time: 4.4044  data: 0.0002  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [410/431]  eta: 0:01:31  lr: 0.000200  loss: 0.0101 (0.0102)  time: 4.3965  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [420/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0109 (0.0102)  time: 4.4549  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14]  [430/431]  eta: 0:00:04  lr: 0.000200  loss: 0.0098 (0.0102)  time: 4.5097  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:14] Total time: 0:31:20 (4.3640 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0098 (0.0102)\n",
      "Valid: [epoch:14]  [ 0/14]  eta: 0:03:42  loss: 0.0026 (0.0026)  time: 15.8966  data: 0.5998  max mem: 39468\n",
      "Valid: [epoch:14]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.4826  data: 0.0429  max mem: 39468\n",
      "Valid: [epoch:14] Total time: 0:03:37 (15.5036 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_14_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:15]  [  0/431]  eta: 1:02:44  lr: 0.000200  loss: 0.0168 (0.0168)  time: 8.7350  data: 3.4673  max mem: 39468\n",
      "Train: [epoch:15]  [ 10/431]  eta: 0:33:12  lr: 0.000200  loss: 0.0107 (0.0121)  time: 4.7320  data: 0.3154  max mem: 39468\n",
      "Train: [epoch:15]  [ 20/431]  eta: 0:30:32  lr: 0.000200  loss: 0.0095 (0.0109)  time: 4.2459  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [ 30/431]  eta: 0:29:32  lr: 0.000200  loss: 0.0078 (0.0102)  time: 4.2494  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [ 40/431]  eta: 0:28:40  lr: 0.000200  loss: 0.0080 (0.0101)  time: 4.3353  data: 0.0003  max mem: 39468\n",
      "Train: [epoch:15]  [ 50/431]  eta: 0:27:23  lr: 0.000200  loss: 0.0099 (0.0103)  time: 4.1511  data: 0.0003  max mem: 39468\n",
      "Train: [epoch:15]  [ 60/431]  eta: 0:26:46  lr: 0.000200  loss: 0.0099 (0.0102)  time: 4.1916  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [ 70/431]  eta: 0:26:09  lr: 0.000200  loss: 0.0096 (0.0102)  time: 4.4319  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [ 80/431]  eta: 0:25:29  lr: 0.000200  loss: 0.0096 (0.0103)  time: 4.4387  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [ 90/431]  eta: 0:24:50  lr: 0.000200  loss: 0.0101 (0.0105)  time: 4.4561  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [100/431]  eta: 0:24:09  lr: 0.000200  loss: 0.0096 (0.0105)  time: 4.4713  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [110/431]  eta: 0:23:22  lr: 0.000200  loss: 0.0092 (0.0105)  time: 4.3627  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [120/431]  eta: 0:22:33  lr: 0.000200  loss: 0.0092 (0.0105)  time: 4.2186  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [130/431]  eta: 0:21:50  lr: 0.000200  loss: 0.0090 (0.0104)  time: 4.2638  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [140/431]  eta: 0:21:05  lr: 0.000200  loss: 0.0095 (0.0104)  time: 4.3215  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [150/431]  eta: 0:20:25  lr: 0.000200  loss: 0.0095 (0.0104)  time: 4.3995  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [160/431]  eta: 0:19:41  lr: 0.000200  loss: 0.0091 (0.0104)  time: 4.4418  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [170/431]  eta: 0:18:56  lr: 0.000200  loss: 0.0091 (0.0103)  time: 4.3176  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [180/431]  eta: 0:18:09  lr: 0.000200  loss: 0.0093 (0.0103)  time: 4.1712  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [190/431]  eta: 0:17:26  lr: 0.000200  loss: 0.0095 (0.0102)  time: 4.2245  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [200/431]  eta: 0:16:41  lr: 0.000200  loss: 0.0093 (0.0102)  time: 4.3057  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [210/431]  eta: 0:15:59  lr: 0.000200  loss: 0.0094 (0.0102)  time: 4.3372  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [220/431]  eta: 0:15:16  lr: 0.000200  loss: 0.0099 (0.0102)  time: 4.4370  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [230/431]  eta: 0:14:33  lr: 0.000200  loss: 0.0091 (0.0103)  time: 4.4241  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [240/431]  eta: 0:13:50  lr: 0.000200  loss: 0.0086 (0.0102)  time: 4.3882  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [250/431]  eta: 0:13:06  lr: 0.000200  loss: 0.0091 (0.0103)  time: 4.3448  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [260/431]  eta: 0:12:23  lr: 0.000200  loss: 0.0092 (0.0103)  time: 4.3342  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [270/431]  eta: 0:11:40  lr: 0.000200  loss: 0.0091 (0.0103)  time: 4.3987  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [280/431]  eta: 0:10:58  lr: 0.000200  loss: 0.0125 (0.0104)  time: 4.5327  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [290/431]  eta: 0:10:15  lr: 0.000200  loss: 0.0112 (0.0104)  time: 4.5745  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [300/431]  eta: 0:09:32  lr: 0.000200  loss: 0.0097 (0.0104)  time: 4.4619  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [310/431]  eta: 0:08:48  lr: 0.000200  loss: 0.0094 (0.0104)  time: 4.4216  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [320/431]  eta: 0:08:05  lr: 0.000200  loss: 0.0091 (0.0104)  time: 4.3964  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [330/431]  eta: 0:07:21  lr: 0.000200  loss: 0.0085 (0.0104)  time: 4.3160  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [340/431]  eta: 0:06:37  lr: 0.000200  loss: 0.0089 (0.0104)  time: 4.4090  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [350/431]  eta: 0:05:54  lr: 0.000200  loss: 0.0091 (0.0104)  time: 4.4462  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [360/431]  eta: 0:05:10  lr: 0.000200  loss: 0.0090 (0.0104)  time: 4.4339  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [370/431]  eta: 0:04:27  lr: 0.000200  loss: 0.0089 (0.0104)  time: 4.4727  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [380/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0090 (0.0104)  time: 4.3303  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [390/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0090 (0.0104)  time: 4.3585  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [400/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0086 (0.0103)  time: 4.4687  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [410/431]  eta: 0:01:31  lr: 0.000200  loss: 0.0088 (0.0103)  time: 4.4631  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [420/431]  eta: 0:00:48  lr: 0.000200  loss: 0.0088 (0.0103)  time: 4.4834  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15]  [430/431]  eta: 0:00:04  lr: 0.000200  loss: 0.0094 (0.0103)  time: 4.4622  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:15] Total time: 0:31:29 (4.3849 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0094 (0.0103)\n",
      "Valid: [epoch:15]  [ 0/14]  eta: 0:03:53  loss: 0.0007 (0.0007)  time: 16.6562  data: 0.6248  max mem: 39468\n",
      "Valid: [epoch:15]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.7150  data: 0.0447  max mem: 39468\n",
      "Valid: [epoch:15] Total time: 0:03:40 (15.7320 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_15_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:16]  [  0/431]  eta: 1:01:18  lr: 0.000200  loss: 0.0118 (0.0118)  time: 8.5358  data: 4.3513  max mem: 39468\n",
      "Train: [epoch:16]  [ 10/431]  eta: 0:34:06  lr: 0.000200  loss: 0.0108 (0.0110)  time: 4.8602  data: 0.3957  max mem: 39468\n",
      "Train: [epoch:16]  [ 20/431]  eta: 0:31:43  lr: 0.000200  loss: 0.0094 (0.0102)  time: 4.4364  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [ 30/431]  eta: 0:30:10  lr: 0.000200  loss: 0.0086 (0.0097)  time: 4.3255  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [ 40/431]  eta: 0:29:18  lr: 0.000200  loss: 0.0080 (0.0100)  time: 4.3584  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [ 50/431]  eta: 0:28:33  lr: 0.000200  loss: 0.0106 (0.0102)  time: 4.4664  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [ 60/431]  eta: 0:27:27  lr: 0.000200  loss: 0.0087 (0.0100)  time: 4.3253  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [ 70/431]  eta: 0:26:44  lr: 0.000200  loss: 0.0091 (0.0101)  time: 4.3166  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [ 80/431]  eta: 0:25:56  lr: 0.000200  loss: 0.0087 (0.0100)  time: 4.4173  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [ 90/431]  eta: 0:25:13  lr: 0.000200  loss: 0.0091 (0.0102)  time: 4.4132  data: 0.0002  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [100/431]  eta: 0:24:32  lr: 0.000200  loss: 0.0101 (0.0100)  time: 4.4978  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [110/431]  eta: 0:23:49  lr: 0.000200  loss: 0.0082 (0.0101)  time: 4.5250  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [120/431]  eta: 0:23:04  lr: 0.000200  loss: 0.0098 (0.0101)  time: 4.4794  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [130/431]  eta: 0:22:12  lr: 0.000200  loss: 0.0094 (0.0101)  time: 4.2692  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [140/431]  eta: 0:21:28  lr: 0.000200  loss: 0.0095 (0.0102)  time: 4.2778  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [150/431]  eta: 0:20:44  lr: 0.000200  loss: 0.0099 (0.0103)  time: 4.4577  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [160/431]  eta: 0:20:03  lr: 0.000200  loss: 0.0072 (0.0100)  time: 4.5299  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [170/431]  eta: 0:19:20  lr: 0.000200  loss: 0.0067 (0.0100)  time: 4.5658  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [180/431]  eta: 0:18:34  lr: 0.000200  loss: 0.0091 (0.0100)  time: 4.4266  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [190/431]  eta: 0:17:48  lr: 0.000200  loss: 0.0103 (0.0101)  time: 4.3176  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [200/431]  eta: 0:17:03  lr: 0.000200  loss: 0.0099 (0.0101)  time: 4.3483  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [210/431]  eta: 0:16:19  lr: 0.000200  loss: 0.0086 (0.0100)  time: 4.4217  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [220/431]  eta: 0:15:34  lr: 0.000200  loss: 0.0087 (0.0100)  time: 4.4250  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [230/431]  eta: 0:14:49  lr: 0.000200  loss: 0.0096 (0.0100)  time: 4.3806  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [240/431]  eta: 0:14:03  lr: 0.000200  loss: 0.0095 (0.0101)  time: 4.2867  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [250/431]  eta: 0:13:20  lr: 0.000200  loss: 0.0111 (0.0101)  time: 4.3530  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [260/431]  eta: 0:12:37  lr: 0.000200  loss: 0.0111 (0.0101)  time: 4.5492  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [270/431]  eta: 0:11:53  lr: 0.000200  loss: 0.0106 (0.0101)  time: 4.5893  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [280/431]  eta: 0:11:09  lr: 0.000200  loss: 0.0110 (0.0102)  time: 4.5421  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [290/431]  eta: 0:10:25  lr: 0.000200  loss: 0.0110 (0.0102)  time: 4.4651  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [300/431]  eta: 0:09:40  lr: 0.000200  loss: 0.0085 (0.0102)  time: 4.3698  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [310/431]  eta: 0:08:55  lr: 0.000200  loss: 0.0099 (0.0102)  time: 4.3155  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [320/431]  eta: 0:08:11  lr: 0.000200  loss: 0.0111 (0.0103)  time: 4.4226  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [330/431]  eta: 0:07:27  lr: 0.000200  loss: 0.0102 (0.0102)  time: 4.4823  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [340/431]  eta: 0:06:43  lr: 0.000200  loss: 0.0097 (0.0102)  time: 4.5085  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [350/431]  eta: 0:05:59  lr: 0.000200  loss: 0.0088 (0.0102)  time: 4.5648  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [360/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0090 (0.0102)  time: 4.5005  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [370/431]  eta: 0:04:30  lr: 0.000200  loss: 0.0104 (0.0102)  time: 4.3850  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [380/431]  eta: 0:03:46  lr: 0.000200  loss: 0.0093 (0.0102)  time: 4.3337  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [390/431]  eta: 0:03:01  lr: 0.000200  loss: 0.0086 (0.0102)  time: 4.4217  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [400/431]  eta: 0:02:17  lr: 0.000200  loss: 0.0097 (0.0102)  time: 4.4965  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [410/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0097 (0.0102)  time: 4.4976  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [420/431]  eta: 0:00:48  lr: 0.000200  loss: 0.0100 (0.0102)  time: 4.5247  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16]  [430/431]  eta: 0:00:04  lr: 0.000200  loss: 0.0097 (0.0103)  time: 4.3956  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:16] Total time: 0:31:52 (4.4370 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0097 (0.0103)\n",
      "Valid: [epoch:16]  [ 0/14]  eta: 0:03:53  loss: 0.0007 (0.0007)  time: 16.6898  data: 0.5912  max mem: 39468\n",
      "Valid: [epoch:16]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.7645  data: 0.0423  max mem: 39468\n",
      "Valid: [epoch:16] Total time: 0:03:40 (15.7823 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_16_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:17]  [  0/431]  eta: 1:06:27  lr: 0.000200  loss: 0.0100 (0.0100)  time: 9.2515  data: 4.0081  max mem: 39468\n",
      "Train: [epoch:17]  [ 10/431]  eta: 0:34:03  lr: 0.000200  loss: 0.0104 (0.0108)  time: 4.8548  data: 0.3645  max mem: 39468\n",
      "Train: [epoch:17]  [ 20/431]  eta: 0:31:27  lr: 0.000200  loss: 0.0101 (0.0108)  time: 4.3583  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [ 30/431]  eta: 0:30:27  lr: 0.000200  loss: 0.0090 (0.0101)  time: 4.3920  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [ 40/431]  eta: 0:29:29  lr: 0.000200  loss: 0.0090 (0.0102)  time: 4.4555  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [ 50/431]  eta: 0:28:42  lr: 0.000200  loss: 0.0094 (0.0103)  time: 4.4649  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [ 60/431]  eta: 0:27:40  lr: 0.000200  loss: 0.0090 (0.0101)  time: 4.3777  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [ 70/431]  eta: 0:26:45  lr: 0.000200  loss: 0.0096 (0.0102)  time: 4.2579  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [ 80/431]  eta: 0:25:59  lr: 0.000200  loss: 0.0093 (0.0102)  time: 4.3394  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [ 90/431]  eta: 0:25:17  lr: 0.000200  loss: 0.0125 (0.0107)  time: 4.4618  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [100/431]  eta: 0:24:33  lr: 0.000200  loss: 0.0112 (0.0106)  time: 4.4847  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [110/431]  eta: 0:23:41  lr: 0.000200  loss: 0.0102 (0.0107)  time: 4.3295  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [120/431]  eta: 0:22:57  lr: 0.000200  loss: 0.0096 (0.0108)  time: 4.3231  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [130/431]  eta: 0:22:13  lr: 0.000200  loss: 0.0095 (0.0108)  time: 4.4476  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [140/431]  eta: 0:21:30  lr: 0.000200  loss: 0.0094 (0.0108)  time: 4.4689  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [150/431]  eta: 0:20:49  lr: 0.000200  loss: 0.0094 (0.0107)  time: 4.5353  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [160/431]  eta: 0:20:04  lr: 0.000200  loss: 0.0083 (0.0106)  time: 4.5204  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [170/431]  eta: 0:19:16  lr: 0.000200  loss: 0.0084 (0.0105)  time: 4.3105  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [180/431]  eta: 0:18:30  lr: 0.000200  loss: 0.0086 (0.0106)  time: 4.2320  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [190/431]  eta: 0:17:46  lr: 0.000200  loss: 0.0093 (0.0105)  time: 4.3984  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [200/431]  eta: 0:17:02  lr: 0.000200  loss: 0.0093 (0.0105)  time: 4.4567  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [210/431]  eta: 0:16:17  lr: 0.000200  loss: 0.0085 (0.0104)  time: 4.3843  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [220/431]  eta: 0:15:32  lr: 0.000200  loss: 0.0091 (0.0105)  time: 4.3790  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [230/431]  eta: 0:14:47  lr: 0.000200  loss: 0.0093 (0.0104)  time: 4.3539  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [240/431]  eta: 0:14:04  lr: 0.000200  loss: 0.0084 (0.0103)  time: 4.4111  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [250/431]  eta: 0:13:20  lr: 0.000200  loss: 0.0091 (0.0104)  time: 4.5279  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [260/431]  eta: 0:12:36  lr: 0.000200  loss: 0.0088 (0.0103)  time: 4.4984  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [270/431]  eta: 0:11:53  lr: 0.000200  loss: 0.0090 (0.0104)  time: 4.4848  data: 0.0002  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [280/431]  eta: 0:11:08  lr: 0.000200  loss: 0.0091 (0.0103)  time: 4.4596  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [290/431]  eta: 0:10:23  lr: 0.000200  loss: 0.0084 (0.0103)  time: 4.3451  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [300/431]  eta: 0:09:39  lr: 0.000200  loss: 0.0090 (0.0103)  time: 4.3648  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [310/431]  eta: 0:08:55  lr: 0.000200  loss: 0.0091 (0.0103)  time: 4.4357  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [320/431]  eta: 0:08:11  lr: 0.000200  loss: 0.0091 (0.0103)  time: 4.4492  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [330/431]  eta: 0:07:27  lr: 0.000200  loss: 0.0085 (0.0103)  time: 4.5422  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [340/431]  eta: 0:06:43  lr: 0.000200  loss: 0.0103 (0.0103)  time: 4.5429  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [350/431]  eta: 0:05:59  lr: 0.000200  loss: 0.0101 (0.0103)  time: 4.4962  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [360/431]  eta: 0:05:14  lr: 0.000200  loss: 0.0098 (0.0103)  time: 4.4184  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [370/431]  eta: 0:04:30  lr: 0.000200  loss: 0.0099 (0.0103)  time: 4.3673  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [380/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0093 (0.0104)  time: 4.3927  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [390/431]  eta: 0:03:01  lr: 0.000200  loss: 0.0086 (0.0103)  time: 4.3637  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [400/431]  eta: 0:02:17  lr: 0.000200  loss: 0.0087 (0.0103)  time: 4.3456  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [410/431]  eta: 0:01:32  lr: 0.000200  loss: 0.0113 (0.0103)  time: 4.3865  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [420/431]  eta: 0:00:48  lr: 0.000200  loss: 0.0096 (0.0103)  time: 4.3756  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17]  [430/431]  eta: 0:00:04  lr: 0.000200  loss: 0.0094 (0.0103)  time: 4.3499  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:17] Total time: 0:31:46 (4.4232 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0094 (0.0103)\n",
      "Valid: [epoch:17]  [ 0/14]  eta: 0:03:41  loss: 0.0025 (0.0025)  time: 15.8390  data: 0.5621  max mem: 39468\n",
      "Valid: [epoch:17]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.2164  data: 0.0403  max mem: 39468\n",
      "Valid: [epoch:17] Total time: 0:03:33 (15.2320 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_17_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:18]  [  0/431]  eta: 0:56:59  lr: 0.000200  loss: 0.0098 (0.0098)  time: 7.9345  data: 4.3615  max mem: 39468\n",
      "Train: [epoch:18]  [ 10/431]  eta: 0:34:08  lr: 0.000200  loss: 0.0098 (0.0095)  time: 4.8663  data: 0.3966  max mem: 39468\n",
      "Train: [epoch:18]  [ 20/431]  eta: 0:32:04  lr: 0.000200  loss: 0.0098 (0.0101)  time: 4.5187  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [ 30/431]  eta: 0:30:39  lr: 0.000200  loss: 0.0081 (0.0095)  time: 4.4353  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [ 40/431]  eta: 0:29:41  lr: 0.000200  loss: 0.0086 (0.0100)  time: 4.4250  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [ 50/431]  eta: 0:28:49  lr: 0.000200  loss: 0.0103 (0.0102)  time: 4.4605  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [ 60/431]  eta: 0:27:53  lr: 0.000200  loss: 0.0103 (0.0102)  time: 4.4135  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [ 70/431]  eta: 0:26:55  lr: 0.000200  loss: 0.0089 (0.0100)  time: 4.3162  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [ 80/431]  eta: 0:26:03  lr: 0.000200  loss: 0.0089 (0.0100)  time: 4.2902  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [ 90/431]  eta: 0:25:23  lr: 0.000200  loss: 0.0090 (0.0100)  time: 4.4350  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [100/431]  eta: 0:24:33  lr: 0.000200  loss: 0.0093 (0.0100)  time: 4.4405  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [110/431]  eta: 0:23:49  lr: 0.000200  loss: 0.0101 (0.0101)  time: 4.3950  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [120/431]  eta: 0:23:07  lr: 0.000200  loss: 0.0095 (0.0102)  time: 4.5144  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [130/431]  eta: 0:22:23  lr: 0.000200  loss: 0.0092 (0.0103)  time: 4.5178  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [140/431]  eta: 0:21:34  lr: 0.000200  loss: 0.0096 (0.0103)  time: 4.3505  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [150/431]  eta: 0:20:45  lr: 0.000200  loss: 0.0091 (0.0102)  time: 4.2308  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [160/431]  eta: 0:20:00  lr: 0.000200  loss: 0.0090 (0.0101)  time: 4.3043  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [170/431]  eta: 0:19:16  lr: 0.000200  loss: 0.0096 (0.0101)  time: 4.4339  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [180/431]  eta: 0:18:31  lr: 0.000200  loss: 0.0093 (0.0100)  time: 4.4350  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [190/431]  eta: 0:17:48  lr: 0.000200  loss: 0.0093 (0.0101)  time: 4.4427  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [200/431]  eta: 0:17:03  lr: 0.000200  loss: 0.0104 (0.0101)  time: 4.4412  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [210/431]  eta: 0:16:18  lr: 0.000200  loss: 0.0086 (0.0100)  time: 4.3483  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [220/431]  eta: 0:15:31  lr: 0.000200  loss: 0.0089 (0.0100)  time: 4.2572  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [230/431]  eta: 0:14:47  lr: 0.000200  loss: 0.0096 (0.0100)  time: 4.3016  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [240/431]  eta: 0:14:02  lr: 0.000200  loss: 0.0093 (0.0100)  time: 4.3403  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [250/431]  eta: 0:13:18  lr: 0.000200  loss: 0.0095 (0.0100)  time: 4.3833  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [260/431]  eta: 0:12:34  lr: 0.000200  loss: 0.0092 (0.0100)  time: 4.4307  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [270/431]  eta: 0:11:50  lr: 0.000200  loss: 0.0092 (0.0100)  time: 4.3951  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [280/431]  eta: 0:11:06  lr: 0.000200  loss: 0.0092 (0.0100)  time: 4.4545  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [290/431]  eta: 0:10:22  lr: 0.000200  loss: 0.0092 (0.0100)  time: 4.4774  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [300/431]  eta: 0:09:37  lr: 0.000200  loss: 0.0087 (0.0100)  time: 4.3412  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [310/431]  eta: 0:08:53  lr: 0.000200  loss: 0.0098 (0.0100)  time: 4.3507  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [320/431]  eta: 0:08:09  lr: 0.000200  loss: 0.0087 (0.0100)  time: 4.4046  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [330/431]  eta: 0:07:25  lr: 0.000200  loss: 0.0083 (0.0099)  time: 4.3653  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [340/431]  eta: 0:06:41  lr: 0.000200  loss: 0.0084 (0.0100)  time: 4.3897  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [350/431]  eta: 0:05:56  lr: 0.000200  loss: 0.0086 (0.0099)  time: 4.3543  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [360/431]  eta: 0:05:12  lr: 0.000200  loss: 0.0091 (0.0100)  time: 4.3833  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [370/431]  eta: 0:04:28  lr: 0.000200  loss: 0.0115 (0.0100)  time: 4.3925  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [380/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0117 (0.0101)  time: 4.2992  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [390/431]  eta: 0:03:00  lr: 0.000200  loss: 0.0112 (0.0101)  time: 4.3119  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [400/431]  eta: 0:02:16  lr: 0.000200  loss: 0.0128 (0.0102)  time: 4.2873  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [410/431]  eta: 0:01:32  lr: 0.000200  loss: 0.0128 (0.0102)  time: 4.2697  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [420/431]  eta: 0:00:48  lr: 0.000200  loss: 0.0105 (0.0102)  time: 4.3258  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18]  [430/431]  eta: 0:00:04  lr: 0.000200  loss: 0.0097 (0.0102)  time: 4.3994  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:18] Total time: 0:31:34 (4.3948 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0097 (0.0102)\n",
      "Valid: [epoch:18]  [ 0/14]  eta: 0:03:44  loss: 0.0024 (0.0024)  time: 16.0589  data: 0.5923  max mem: 39468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:18]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.4243  data: 0.0424  max mem: 39468\n",
      "Valid: [epoch:18] Total time: 0:03:36 (15.4400 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/epoch_18_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:19]  [  0/431]  eta: 1:02:36  lr: 0.000200  loss: 0.0077 (0.0077)  time: 8.7150  data: 3.4594  max mem: 39468\n",
      "Train: [epoch:19]  [ 10/431]  eta: 0:33:10  lr: 0.000200  loss: 0.0084 (0.0093)  time: 4.7289  data: 0.3146  max mem: 39468\n",
      "Train: [epoch:19]  [ 20/431]  eta: 0:31:24  lr: 0.000200  loss: 0.0081 (0.0089)  time: 4.3791  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:19]  [ 30/431]  eta: 0:30:08  lr: 0.000200  loss: 0.0081 (0.0087)  time: 4.3911  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:19]  [ 40/431]  eta: 0:29:01  lr: 0.000200  loss: 0.0088 (0.0090)  time: 4.3135  data: 0.0002  max mem: 39468\n",
      "Train: [epoch:19]  [ 50/431]  eta: 0:28:12  lr: 0.000200  loss: 0.0094 (0.0091)  time: 4.3357  data: 0.0002  max mem: 39468\n",
      "^C\n",
      "Exception in thread Thread-32795:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sunggu/.local/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/sunggu/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 358, in <module>\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--batch-size 16 \\\n",
    "--epochs 1000 \\\n",
    "--min-lr 5e-6 \\\n",
    "--lr 2e-4 \\\n",
    "--data-set 'Sinogram_DCM' \\\n",
    "--model-name 'MAP_WCMT' \\\n",
    "--criterion 'Window Compound Loss' \\\n",
    "--output_dir '/workspace/sunggu/4.Dose_img2img/model/[Ours]MAP_WCMT' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT/low2high/' \\\n",
    "--validate-every 1 \\\n",
    "--num_workers 4 \\\n",
    "--criterion_mode 'not balance' \\\n",
    "--multiple_GT \"True\" \\\n",
    "--patch_training \"True\" \\\n",
    "--multi-gpu-mode 'DataParallel' \n",
    "# --multi-gpu-mode 'DataParallel' \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "***********************************************\n",
      "***********************************************\n",
      "Dataset Name:  Sinogram_DCM\n",
      "---------- Model ----------\n",
      "Resume From:  \n",
      "Output To:  /workspace/sunggu/4.Dose_img2img/model/[Ours]MAP_WCMT_test\n",
      "Save   To:  /workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/\n",
      "---------- Optimizer ----------\n",
      "Learning Rate:  0.0002\n",
      "Weight Decay:  0.05\n",
      "Batchsize:  16\n",
      "Loading dataset ....\n",
      "Train [Total]  number =  6899\n",
      "Valid [Total]  number =  14\n",
      "inintializing...!\n",
      "Creating model: MAP_WCMT\n",
      "Number of Learnable Params: 134450481\n",
      "Start training for 1000 epochs\n",
      "Train: [epoch:0]  [  0/431]  eta: 1:43:45  lr: 0.000001  loss: 0.0012 (0.0012)  time: 14.4435  data: 1.6745  max mem: 39360\n",
      "Train: [epoch:0]  [ 10/431]  eta: 0:15:30  lr: 0.000001  loss: 0.0018 (0.0021)  time: 2.2097  data: 0.1523  max mem: 39452\n",
      "Train: [epoch:0]  [ 20/431]  eta: 0:11:41  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.0694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [ 30/431]  eta: 0:09:54  lr: 0.000001  loss: 0.0019 (0.0021)  time: 1.0845  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [ 40/431]  eta: 0:09:10  lr: 0.000001  loss: 0.0019 (0.0021)  time: 1.0951  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [ 50/431]  eta: 0:08:25  lr: 0.000001  loss: 0.0023 (0.0022)  time: 1.0834  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [ 60/431]  eta: 0:08:04  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.0954  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [ 70/431]  eta: 0:07:32  lr: 0.000001  loss: 0.0018 (0.0021)  time: 1.0697  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [ 80/431]  eta: 0:07:20  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0962  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [ 90/431]  eta: 0:07:06  lr: 0.000001  loss: 0.0022 (0.0022)  time: 1.2410  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [100/431]  eta: 0:06:54  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.2388  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [110/431]  eta: 0:06:41  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.2477  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [120/431]  eta: 0:06:28  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.2395  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [130/431]  eta: 0:06:15  lr: 0.000001  loss: 0.0018 (0.0022)  time: 1.2374  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [140/431]  eta: 0:06:02  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.2209  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [150/431]  eta: 0:05:47  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.1658  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [160/431]  eta: 0:05:35  lr: 0.000001  loss: 0.0018 (0.0022)  time: 1.1891  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [170/431]  eta: 0:05:19  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.1256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [180/431]  eta: 0:05:05  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.0400  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [190/431]  eta: 0:04:51  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.0879  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [200/431]  eta: 0:04:38  lr: 0.000001  loss: 0.0018 (0.0022)  time: 1.1196  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [210/431]  eta: 0:04:24  lr: 0.000001  loss: 0.0023 (0.0022)  time: 1.0762  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [220/431]  eta: 0:04:12  lr: 0.000001  loss: 0.0024 (0.0022)  time: 1.0918  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [230/431]  eta: 0:03:59  lr: 0.000001  loss: 0.0022 (0.0022)  time: 1.1114  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [240/431]  eta: 0:03:47  lr: 0.000001  loss: 0.0023 (0.0022)  time: 1.1304  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [250/431]  eta: 0:03:35  lr: 0.000001  loss: 0.0023 (0.0022)  time: 1.2091  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [260/431]  eta: 0:03:23  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.1945  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [270/431]  eta: 0:03:11  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.1415  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [280/431]  eta: 0:02:59  lr: 0.000001  loss: 0.0022 (0.0022)  time: 1.1263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [290/431]  eta: 0:02:47  lr: 0.000001  loss: 0.0025 (0.0022)  time: 1.1745  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [300/431]  eta: 0:02:35  lr: 0.000001  loss: 0.0022 (0.0022)  time: 1.1843  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [310/431]  eta: 0:02:23  lr: 0.000001  loss: 0.0018 (0.0022)  time: 1.2067  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [320/431]  eta: 0:02:12  lr: 0.000001  loss: 0.0018 (0.0022)  time: 1.2411  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [330/431]  eta: 0:02:00  lr: 0.000001  loss: 0.0022 (0.0022)  time: 1.2489  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [340/431]  eta: 0:01:48  lr: 0.000001  loss: 0.0025 (0.0022)  time: 1.2519  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [350/431]  eta: 0:01:36  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.2184  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [360/431]  eta: 0:01:24  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.1998  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [370/431]  eta: 0:01:12  lr: 0.000001  loss: 0.0023 (0.0022)  time: 1.2283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0]  [380/431]  eta: 0:01:00  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.1978  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [390/431]  eta: 0:00:48  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.1796  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [400/431]  eta: 0:00:37  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.2120  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [410/431]  eta: 0:00:25  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.2383  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [420/431]  eta: 0:00:13  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.2141  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:0]  [430/431]  eta: 0:00:01  lr: 0.000001  loss: 0.0022 (0.0022)  time: 1.2195  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:0] Total time: 0:08:36 (1.1982 s / it)\n",
      "Averaged stats: lr: 0.000001  loss: 0.0022 (0.0022)\n",
      "Valid: [epoch:0]  [ 0/14]  eta: 0:03:50  loss: 0.0024 (0.0024)  time: 16.4550  data: 0.6127  max mem: 39452\n",
      "Valid: [epoch:0]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.4956  data: 0.0439  max mem: 39452\n",
      "Valid: [epoch:0] Total time: 0:03:37 (15.5117 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_0_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "/home/sunggu/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Train: [epoch:1]  [  0/431]  eta: 0:15:42  lr: 0.000001  loss: 0.0031 (0.0031)  time: 2.1874  data: 1.3825  max mem: 39452\n",
      "Train: [epoch:1]  [ 10/431]  eta: 0:07:11  lr: 0.000001  loss: 0.0020 (0.0020)  time: 1.0248  data: 0.1423  max mem: 39452\n",
      "Train: [epoch:1]  [ 20/431]  eta: 0:07:24  lr: 0.000001  loss: 0.0019 (0.0021)  time: 1.0250  data: 0.0092  max mem: 39452\n",
      "Train: [epoch:1]  [ 30/431]  eta: 0:06:49  lr: 0.000001  loss: 0.0020 (0.0021)  time: 1.0202  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [ 40/431]  eta: 0:06:58  lr: 0.000001  loss: 0.0020 (0.0021)  time: 1.0596  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [ 50/431]  eta: 0:06:39  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0930  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:1]  [ 60/431]  eta: 0:06:35  lr: 0.000001  loss: 0.0023 (0.0022)  time: 1.0574  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [ 70/431]  eta: 0:06:17  lr: 0.000001  loss: 0.0021 (0.0023)  time: 1.0369  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [ 80/431]  eta: 0:06:05  lr: 0.000001  loss: 0.0020 (0.0022)  time: 0.9621  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [ 90/431]  eta: 0:05:53  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0061  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [100/431]  eta: 0:05:45  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0633  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [110/431]  eta: 0:05:33  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0383  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [120/431]  eta: 0:05:24  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0432  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [130/431]  eta: 0:05:13  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.0549  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [140/431]  eta: 0:05:02  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.0019  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [150/431]  eta: 0:04:51  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0230  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [160/431]  eta: 0:04:42  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.0672  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [170/431]  eta: 0:04:31  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.0556  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [180/431]  eta: 0:04:20  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.0115  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [190/431]  eta: 0:04:10  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0498  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [200/431]  eta: 0:03:58  lr: 0.000001  loss: 0.0021 (0.0022)  time: 0.9542  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [210/431]  eta: 0:03:49  lr: 0.000001  loss: 0.0022 (0.0022)  time: 1.0050  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [220/431]  eta: 0:03:37  lr: 0.000001  loss: 0.0022 (0.0022)  time: 1.0449  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [230/431]  eta: 0:03:28  lr: 0.000001  loss: 0.0023 (0.0023)  time: 1.0408  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [240/431]  eta: 0:03:16  lr: 0.000001  loss: 0.0022 (0.0023)  time: 1.0275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [250/431]  eta: 0:03:07  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.0289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [260/431]  eta: 0:02:56  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.0182  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [270/431]  eta: 0:02:46  lr: 0.000001  loss: 0.0020 (0.0022)  time: 0.9969  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [280/431]  eta: 0:02:35  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0317  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [290/431]  eta: 0:02:25  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.0480  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [300/431]  eta: 0:02:15  lr: 0.000001  loss: 0.0022 (0.0022)  time: 1.0449  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [310/431]  eta: 0:02:04  lr: 0.000001  loss: 0.0021 (0.0022)  time: 0.9755  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [320/431]  eta: 0:01:54  lr: 0.000001  loss: 0.0022 (0.0023)  time: 1.0557  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [330/431]  eta: 0:01:44  lr: 0.000001  loss: 0.0022 (0.0023)  time: 1.0911  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [340/431]  eta: 0:01:34  lr: 0.000001  loss: 0.0018 (0.0022)  time: 1.0632  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [350/431]  eta: 0:01:23  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [360/431]  eta: 0:01:13  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.0500  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [370/431]  eta: 0:01:03  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.0833  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [380/431]  eta: 0:00:52  lr: 0.000001  loss: 0.0021 (0.0022)  time: 1.0712  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [390/431]  eta: 0:00:42  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.1176  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [400/431]  eta: 0:00:32  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.0600  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [410/431]  eta: 0:00:21  lr: 0.000001  loss: 0.0023 (0.0022)  time: 0.9971  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [420/431]  eta: 0:00:11  lr: 0.000001  loss: 0.0020 (0.0022)  time: 1.1018  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1]  [430/431]  eta: 0:00:01  lr: 0.000001  loss: 0.0019 (0.0022)  time: 1.0919  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:1] Total time: 0:07:29 (1.0422 s / it)\n",
      "Averaged stats: lr: 0.000001  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:1]  [ 0/14]  eta: 0:03:41  loss: 0.0024 (0.0024)  time: 15.8508  data: 0.5493  max mem: 39452\n",
      "Valid: [epoch:1]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.4962  data: 0.0393  max mem: 39452\n",
      "Valid: [epoch:1] Total time: 0:03:37 (15.5115 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_1_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:2]  [  0/431]  eta: 0:18:20  lr: 0.000020  loss: 0.0015 (0.0015)  time: 2.5537  data: 1.4720  max mem: 39452\n",
      "Train: [epoch:2]  [ 10/431]  eta: 0:07:55  lr: 0.000020  loss: 0.0030 (0.0028)  time: 1.1304  data: 0.1340  max mem: 39452\n",
      "Train: [epoch:2]  [ 20/431]  eta: 0:07:35  lr: 0.000020  loss: 0.0024 (0.0025)  time: 1.0370  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [ 30/431]  eta: 0:07:06  lr: 0.000020  loss: 0.0020 (0.0024)  time: 1.0281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [ 40/431]  eta: 0:07:06  lr: 0.000020  loss: 0.0019 (0.0023)  time: 1.0730  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [ 50/431]  eta: 0:06:47  lr: 0.000020  loss: 0.0021 (0.0023)  time: 1.0770  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [ 60/431]  eta: 0:06:40  lr: 0.000020  loss: 0.0021 (0.0023)  time: 1.0562  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [ 70/431]  eta: 0:06:21  lr: 0.000020  loss: 0.0020 (0.0023)  time: 1.0243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [ 80/431]  eta: 0:06:18  lr: 0.000020  loss: 0.0018 (0.0022)  time: 1.0707  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [ 90/431]  eta: 0:06:02  lr: 0.000020  loss: 0.0020 (0.0022)  time: 1.0899  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [100/431]  eta: 0:05:55  lr: 0.000020  loss: 0.0020 (0.0022)  time: 1.0620  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:2]  [110/431]  eta: 0:05:39  lr: 0.000020  loss: 0.0021 (0.0022)  time: 1.0211  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:2]  [120/431]  eta: 0:05:31  lr: 0.000020  loss: 0.0022 (0.0022)  time: 1.0262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [130/431]  eta: 0:05:16  lr: 0.000020  loss: 0.0017 (0.0022)  time: 1.0300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [140/431]  eta: 0:05:09  lr: 0.000020  loss: 0.0017 (0.0022)  time: 1.0521  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [150/431]  eta: 0:04:56  lr: 0.000020  loss: 0.0025 (0.0022)  time: 1.0764  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [160/431]  eta: 0:04:48  lr: 0.000020  loss: 0.0018 (0.0022)  time: 1.0692  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [170/431]  eta: 0:04:35  lr: 0.000020  loss: 0.0019 (0.0022)  time: 1.0577  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [180/431]  eta: 0:04:25  lr: 0.000020  loss: 0.0020 (0.0022)  time: 1.0158  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [190/431]  eta: 0:04:13  lr: 0.000020  loss: 0.0021 (0.0022)  time: 1.0127  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [200/431]  eta: 0:04:03  lr: 0.000020  loss: 0.0018 (0.0022)  time: 1.0244  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:2]  [210/431]  eta: 0:03:51  lr: 0.000020  loss: 0.0021 (0.0022)  time: 1.0264  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [220/431]  eta: 0:03:42  lr: 0.000020  loss: 0.0021 (0.0022)  time: 1.0577  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [230/431]  eta: 0:03:30  lr: 0.000020  loss: 0.0020 (0.0022)  time: 1.0318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [240/431]  eta: 0:03:20  lr: 0.000020  loss: 0.0021 (0.0022)  time: 0.9632  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [250/431]  eta: 0:03:10  lr: 0.000020  loss: 0.0022 (0.0022)  time: 1.0961  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [260/431]  eta: 0:02:59  lr: 0.000020  loss: 0.0021 (0.0022)  time: 1.0468  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [270/431]  eta: 0:02:48  lr: 0.000020  loss: 0.0022 (0.0022)  time: 1.0287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [280/431]  eta: 0:02:37  lr: 0.000020  loss: 0.0020 (0.0022)  time: 1.0186  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:2]  [290/431]  eta: 0:02:28  lr: 0.000020  loss: 0.0021 (0.0022)  time: 1.0697  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:2]  [300/431]  eta: 0:02:17  lr: 0.000020  loss: 0.0021 (0.0022)  time: 1.0488  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [310/431]  eta: 0:02:07  lr: 0.000020  loss: 0.0017 (0.0022)  time: 1.0556  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [320/431]  eta: 0:01:55  lr: 0.000020  loss: 0.0020 (0.0022)  time: 1.0198  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [330/431]  eta: 0:01:45  lr: 0.000020  loss: 0.0025 (0.0022)  time: 0.9765  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [340/431]  eta: 0:01:34  lr: 0.000020  loss: 0.0020 (0.0022)  time: 1.0118  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [350/431]  eta: 0:01:24  lr: 0.000020  loss: 0.0022 (0.0022)  time: 1.0356  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [360/431]  eta: 0:01:13  lr: 0.000020  loss: 0.0024 (0.0022)  time: 1.0247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [370/431]  eta: 0:01:03  lr: 0.000020  loss: 0.0021 (0.0022)  time: 1.0083  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [380/431]  eta: 0:00:53  lr: 0.000020  loss: 0.0019 (0.0022)  time: 1.0753  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [390/431]  eta: 0:00:42  lr: 0.000020  loss: 0.0018 (0.0022)  time: 1.1082  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:2]  [400/431]  eta: 0:00:32  lr: 0.000020  loss: 0.0022 (0.0022)  time: 1.0775  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [410/431]  eta: 0:00:22  lr: 0.000020  loss: 0.0020 (0.0022)  time: 1.0543  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [420/431]  eta: 0:00:11  lr: 0.000020  loss: 0.0019 (0.0022)  time: 1.0661  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2]  [430/431]  eta: 0:00:01  lr: 0.000020  loss: 0.0021 (0.0022)  time: 1.0812  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:2] Total time: 0:07:32 (1.0498 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:2]  [ 0/14]  eta: 0:03:41  loss: 0.0007 (0.0007)  time: 15.8025  data: 0.5739  max mem: 39452\n",
      "Valid: [epoch:2]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.2817  data: 0.0411  max mem: 39452\n",
      "Valid: [epoch:2] Total time: 0:03:34 (15.2945 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_2_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:3]  [  0/431]  eta: 0:21:34  lr: 0.000040  loss: 0.0013 (0.0013)  time: 3.0039  data: 1.7225  max mem: 39452\n",
      "Train: [epoch:3]  [ 10/431]  eta: 0:07:09  lr: 0.000040  loss: 0.0017 (0.0019)  time: 1.0200  data: 0.1567  max mem: 39452\n",
      "Train: [epoch:3]  [ 20/431]  eta: 0:07:38  lr: 0.000040  loss: 0.0021 (0.0023)  time: 1.0221  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [ 30/431]  eta: 0:06:54  lr: 0.000040  loss: 0.0024 (0.0023)  time: 1.0427  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:3]  [ 40/431]  eta: 0:07:01  lr: 0.000040  loss: 0.0020 (0.0024)  time: 1.0350  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [ 50/431]  eta: 0:06:37  lr: 0.000040  loss: 0.0021 (0.0023)  time: 1.0534  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [ 60/431]  eta: 0:06:33  lr: 0.000040  loss: 0.0020 (0.0023)  time: 1.0290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [ 70/431]  eta: 0:06:14  lr: 0.000040  loss: 0.0019 (0.0023)  time: 1.0303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [ 80/431]  eta: 0:06:10  lr: 0.000040  loss: 0.0019 (0.0022)  time: 1.0431  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [ 90/431]  eta: 0:05:54  lr: 0.000040  loss: 0.0019 (0.0022)  time: 1.0391  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [100/431]  eta: 0:05:50  lr: 0.000040  loss: 0.0019 (0.0022)  time: 1.0610  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [110/431]  eta: 0:05:36  lr: 0.000040  loss: 0.0019 (0.0022)  time: 1.0930  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [120/431]  eta: 0:05:26  lr: 0.000040  loss: 0.0024 (0.0022)  time: 1.0191  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [130/431]  eta: 0:05:15  lr: 0.000040  loss: 0.0024 (0.0022)  time: 1.0567  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:3]  [140/431]  eta: 0:05:06  lr: 0.000040  loss: 0.0018 (0.0022)  time: 1.0742  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [150/431]  eta: 0:04:54  lr: 0.000040  loss: 0.0020 (0.0022)  time: 1.0406  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [160/431]  eta: 0:04:44  lr: 0.000040  loss: 0.0024 (0.0022)  time: 1.0279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [170/431]  eta: 0:04:34  lr: 0.000040  loss: 0.0026 (0.0023)  time: 1.0762  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [180/431]  eta: 0:04:25  lr: 0.000040  loss: 0.0019 (0.0023)  time: 1.1068  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [190/431]  eta: 0:04:13  lr: 0.000040  loss: 0.0019 (0.0022)  time: 1.0632  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [200/431]  eta: 0:04:03  lr: 0.000040  loss: 0.0020 (0.0022)  time: 1.0121  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [210/431]  eta: 0:03:52  lr: 0.000040  loss: 0.0021 (0.0022)  time: 1.0458  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [220/431]  eta: 0:03:42  lr: 0.000040  loss: 0.0024 (0.0023)  time: 1.0704  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [230/431]  eta: 0:03:31  lr: 0.000040  loss: 0.0023 (0.0023)  time: 1.0542  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [240/431]  eta: 0:03:21  lr: 0.000040  loss: 0.0022 (0.0023)  time: 1.0879  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [250/431]  eta: 0:03:09  lr: 0.000040  loss: 0.0022 (0.0023)  time: 1.0127  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [260/431]  eta: 0:02:59  lr: 0.000040  loss: 0.0022 (0.0023)  time: 0.9600  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [270/431]  eta: 0:02:49  lr: 0.000040  loss: 0.0022 (0.0023)  time: 1.0690  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [280/431]  eta: 0:02:38  lr: 0.000040  loss: 0.0022 (0.0023)  time: 1.0760  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [290/431]  eta: 0:02:28  lr: 0.000040  loss: 0.0020 (0.0023)  time: 1.0798  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [300/431]  eta: 0:02:18  lr: 0.000040  loss: 0.0021 (0.0023)  time: 1.1149  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [310/431]  eta: 0:02:07  lr: 0.000040  loss: 0.0019 (0.0023)  time: 1.0252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [320/431]  eta: 0:01:56  lr: 0.000040  loss: 0.0018 (0.0023)  time: 1.0085  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [330/431]  eta: 0:01:45  lr: 0.000040  loss: 0.0021 (0.0023)  time: 1.0118  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [340/431]  eta: 0:01:35  lr: 0.000040  loss: 0.0022 (0.0023)  time: 1.0462  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [350/431]  eta: 0:01:25  lr: 0.000040  loss: 0.0019 (0.0023)  time: 1.0794  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [360/431]  eta: 0:01:14  lr: 0.000040  loss: 0.0020 (0.0023)  time: 1.0427  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [370/431]  eta: 0:01:03  lr: 0.000040  loss: 0.0020 (0.0023)  time: 1.0180  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [380/431]  eta: 0:00:53  lr: 0.000040  loss: 0.0019 (0.0023)  time: 1.0108  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [390/431]  eta: 0:00:43  lr: 0.000040  loss: 0.0018 (0.0023)  time: 1.0548  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [400/431]  eta: 0:00:32  lr: 0.000040  loss: 0.0019 (0.0023)  time: 1.0879  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [410/431]  eta: 0:00:22  lr: 0.000040  loss: 0.0019 (0.0023)  time: 1.0679  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3]  [420/431]  eta: 0:00:11  lr: 0.000040  loss: 0.0019 (0.0022)  time: 1.0602  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [430/431]  eta: 0:00:01  lr: 0.000040  loss: 0.0020 (0.0022)  time: 1.0219  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:3] Total time: 0:07:32 (1.0491 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:3]  [ 0/14]  eta: 0:03:36  loss: 0.0015 (0.0015)  time: 15.4655  data: 0.5661  max mem: 39452\n",
      "Valid: [epoch:3]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.8876  data: 0.0405  max mem: 39452\n",
      "Valid: [epoch:3] Total time: 0:03:28 (14.9036 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_3_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:4]  [  0/431]  eta: 0:23:03  lr: 0.000060  loss: 0.0021 (0.0021)  time: 3.2098  data: 1.9588  max mem: 39452\n",
      "Train: [epoch:4]  [ 10/431]  eta: 0:07:30  lr: 0.000060  loss: 0.0017 (0.0018)  time: 1.0710  data: 0.1781  max mem: 39452\n",
      "Train: [epoch:4]  [ 20/431]  eta: 0:07:25  lr: 0.000060  loss: 0.0019 (0.0020)  time: 0.9766  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [ 30/431]  eta: 0:06:38  lr: 0.000060  loss: 0.0022 (0.0022)  time: 0.9528  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [ 40/431]  eta: 0:06:32  lr: 0.000060  loss: 0.0022 (0.0023)  time: 0.9214  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [ 50/431]  eta: 0:06:12  lr: 0.000060  loss: 0.0019 (0.0022)  time: 0.9519  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [ 60/431]  eta: 0:06:01  lr: 0.000060  loss: 0.0017 (0.0021)  time: 0.9114  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [ 70/431]  eta: 0:05:50  lr: 0.000060  loss: 0.0019 (0.0021)  time: 0.9537  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [ 80/431]  eta: 0:05:38  lr: 0.000060  loss: 0.0020 (0.0021)  time: 0.9352  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [ 90/431]  eta: 0:05:30  lr: 0.000060  loss: 0.0018 (0.0021)  time: 0.9608  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [100/431]  eta: 0:05:21  lr: 0.000060  loss: 0.0018 (0.0021)  time: 0.9986  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [110/431]  eta: 0:05:11  lr: 0.000060  loss: 0.0020 (0.0022)  time: 0.9796  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [120/431]  eta: 0:04:59  lr: 0.000060  loss: 0.0021 (0.0022)  time: 0.9170  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [130/431]  eta: 0:04:51  lr: 0.000060  loss: 0.0019 (0.0022)  time: 0.9594  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [140/431]  eta: 0:04:39  lr: 0.000060  loss: 0.0019 (0.0021)  time: 0.9415  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [150/431]  eta: 0:04:32  lr: 0.000060  loss: 0.0019 (0.0022)  time: 0.9672  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [160/431]  eta: 0:04:19  lr: 0.000060  loss: 0.0019 (0.0022)  time: 0.9533  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [170/431]  eta: 0:04:13  lr: 0.000060  loss: 0.0019 (0.0022)  time: 0.9770  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [180/431]  eta: 0:04:00  lr: 0.000060  loss: 0.0020 (0.0022)  time: 0.9525  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [190/431]  eta: 0:03:51  lr: 0.000060  loss: 0.0018 (0.0022)  time: 0.8957  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [200/431]  eta: 0:03:41  lr: 0.000060  loss: 0.0019 (0.0022)  time: 0.9577  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [210/431]  eta: 0:03:32  lr: 0.000060  loss: 0.0020 (0.0022)  time: 0.9793  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [220/431]  eta: 0:03:22  lr: 0.000060  loss: 0.0021 (0.0022)  time: 0.9949  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [230/431]  eta: 0:03:14  lr: 0.000060  loss: 0.0021 (0.0022)  time: 1.0249  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [240/431]  eta: 0:03:03  lr: 0.000060  loss: 0.0020 (0.0022)  time: 0.9743  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [250/431]  eta: 0:02:54  lr: 0.000060  loss: 0.0020 (0.0022)  time: 0.9300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [260/431]  eta: 0:02:44  lr: 0.000060  loss: 0.0020 (0.0022)  time: 0.9610  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [270/431]  eta: 0:02:35  lr: 0.000060  loss: 0.0023 (0.0022)  time: 0.9645  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [280/431]  eta: 0:02:25  lr: 0.000060  loss: 0.0022 (0.0022)  time: 0.9706  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [290/431]  eta: 0:02:16  lr: 0.000060  loss: 0.0021 (0.0022)  time: 0.9978  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [300/431]  eta: 0:02:06  lr: 0.000060  loss: 0.0021 (0.0022)  time: 0.9732  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [310/431]  eta: 0:01:57  lr: 0.000060  loss: 0.0020 (0.0022)  time: 0.9676  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [320/431]  eta: 0:01:47  lr: 0.000060  loss: 0.0021 (0.0022)  time: 0.9787  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [330/431]  eta: 0:01:37  lr: 0.000060  loss: 0.0021 (0.0022)  time: 0.9637  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [340/431]  eta: 0:01:27  lr: 0.000060  loss: 0.0021 (0.0022)  time: 0.9921  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [350/431]  eta: 0:01:18  lr: 0.000060  loss: 0.0021 (0.0022)  time: 1.0265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [360/431]  eta: 0:01:08  lr: 0.000060  loss: 0.0020 (0.0022)  time: 0.9930  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [370/431]  eta: 0:00:59  lr: 0.000060  loss: 0.0024 (0.0022)  time: 0.9988  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [380/431]  eta: 0:00:49  lr: 0.000060  loss: 0.0023 (0.0022)  time: 0.9558  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [390/431]  eta: 0:00:39  lr: 0.000060  loss: 0.0022 (0.0022)  time: 0.9160  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [400/431]  eta: 0:00:30  lr: 0.000060  loss: 0.0020 (0.0022)  time: 0.9906  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [410/431]  eta: 0:00:20  lr: 0.000060  loss: 0.0021 (0.0022)  time: 1.0079  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [420/431]  eta: 0:00:10  lr: 0.000060  loss: 0.0022 (0.0022)  time: 0.9718  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4]  [430/431]  eta: 0:00:00  lr: 0.000060  loss: 0.0018 (0.0022)  time: 0.9334  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:4] Total time: 0:06:58 (0.9703 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:4]  [ 0/14]  eta: 0:03:39  loss: 0.0025 (0.0025)  time: 15.7107  data: 0.5610  max mem: 39452\n",
      "Valid: [epoch:4]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.7293  data: 0.0402  max mem: 39452\n",
      "Valid: [epoch:4] Total time: 0:03:26 (14.7445 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_4_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:5]  [  0/431]  eta: 0:17:30  lr: 0.000080  loss: 0.0025 (0.0025)  time: 2.4365  data: 1.4517  max mem: 39452\n",
      "Train: [epoch:5]  [ 10/431]  eta: 0:08:52  lr: 0.000080  loss: 0.0023 (0.0023)  time: 1.2649  data: 0.1321  max mem: 39452\n",
      "Train: [epoch:5]  [ 20/431]  eta: 0:07:01  lr: 0.000080  loss: 0.0023 (0.0024)  time: 0.9539  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [ 30/431]  eta: 0:07:08  lr: 0.000080  loss: 0.0021 (0.0023)  time: 0.9623  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [ 40/431]  eta: 0:06:29  lr: 0.000080  loss: 0.0021 (0.0023)  time: 0.9641  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [ 50/431]  eta: 0:06:28  lr: 0.000080  loss: 0.0022 (0.0024)  time: 0.9392  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [ 60/431]  eta: 0:06:05  lr: 0.000080  loss: 0.0025 (0.0024)  time: 0.9614  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [ 70/431]  eta: 0:06:04  lr: 0.000080  loss: 0.0020 (0.0023)  time: 0.9832  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [ 80/431]  eta: 0:05:48  lr: 0.000080  loss: 0.0020 (0.0023)  time: 1.0150  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [ 90/431]  eta: 0:05:41  lr: 0.000080  loss: 0.0021 (0.0023)  time: 0.9789  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [100/431]  eta: 0:05:23  lr: 0.000080  loss: 0.0021 (0.0023)  time: 0.9247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [110/431]  eta: 0:05:18  lr: 0.000080  loss: 0.0023 (0.0023)  time: 0.9555  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [120/431]  eta: 0:05:03  lr: 0.000080  loss: 0.0019 (0.0023)  time: 0.9703  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [130/431]  eta: 0:04:58  lr: 0.000080  loss: 0.0018 (0.0023)  time: 0.9768  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [140/431]  eta: 0:04:43  lr: 0.000080  loss: 0.0022 (0.0023)  time: 0.9629  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [150/431]  eta: 0:04:37  lr: 0.000080  loss: 0.0022 (0.0023)  time: 0.9578  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [160/431]  eta: 0:04:24  lr: 0.000080  loss: 0.0024 (0.0023)  time: 0.9779  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [170/431]  eta: 0:04:17  lr: 0.000080  loss: 0.0024 (0.0023)  time: 0.9773  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [180/431]  eta: 0:04:04  lr: 0.000080  loss: 0.0019 (0.0023)  time: 0.9694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [190/431]  eta: 0:03:57  lr: 0.000080  loss: 0.0019 (0.0023)  time: 0.9754  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [200/431]  eta: 0:03:45  lr: 0.000080  loss: 0.0020 (0.0023)  time: 1.0085  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [210/431]  eta: 0:03:37  lr: 0.000080  loss: 0.0018 (0.0022)  time: 0.9893  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [220/431]  eta: 0:03:27  lr: 0.000080  loss: 0.0020 (0.0023)  time: 1.0124  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [230/431]  eta: 0:03:18  lr: 0.000080  loss: 0.0024 (0.0023)  time: 0.9925  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [240/431]  eta: 0:03:06  lr: 0.000080  loss: 0.0024 (0.0023)  time: 0.9358  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [250/431]  eta: 0:02:58  lr: 0.000080  loss: 0.0025 (0.0023)  time: 0.9682  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [260/431]  eta: 0:02:47  lr: 0.000080  loss: 0.0021 (0.0023)  time: 0.9888  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [270/431]  eta: 0:02:38  lr: 0.000080  loss: 0.0021 (0.0023)  time: 0.9656  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [280/431]  eta: 0:02:27  lr: 0.000080  loss: 0.0020 (0.0023)  time: 0.9618  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [290/431]  eta: 0:02:18  lr: 0.000080  loss: 0.0020 (0.0023)  time: 0.9864  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [300/431]  eta: 0:02:07  lr: 0.000080  loss: 0.0019 (0.0023)  time: 0.9679  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [310/431]  eta: 0:01:58  lr: 0.000080  loss: 0.0022 (0.0023)  time: 0.9668  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [320/431]  eta: 0:01:48  lr: 0.000080  loss: 0.0022 (0.0023)  time: 0.9693  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [330/431]  eta: 0:01:39  lr: 0.000080  loss: 0.0018 (0.0023)  time: 0.9707  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [340/431]  eta: 0:01:28  lr: 0.000080  loss: 0.0017 (0.0022)  time: 0.9400  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [350/431]  eta: 0:01:18  lr: 0.000080  loss: 0.0020 (0.0022)  time: 0.8622  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [360/431]  eta: 0:01:09  lr: 0.000080  loss: 0.0021 (0.0023)  time: 0.9622  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [370/431]  eta: 0:00:59  lr: 0.000080  loss: 0.0022 (0.0023)  time: 0.8757  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [380/431]  eta: 0:00:49  lr: 0.000080  loss: 0.0022 (0.0023)  time: 0.9845  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [390/431]  eta: 0:00:39  lr: 0.000080  loss: 0.0017 (0.0022)  time: 0.9817  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [400/431]  eta: 0:00:30  lr: 0.000080  loss: 0.0018 (0.0022)  time: 0.9850  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [410/431]  eta: 0:00:20  lr: 0.000080  loss: 0.0022 (0.0022)  time: 0.9415  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [420/431]  eta: 0:00:10  lr: 0.000080  loss: 0.0019 (0.0022)  time: 0.9146  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5]  [430/431]  eta: 0:00:00  lr: 0.000080  loss: 0.0021 (0.0022)  time: 0.9835  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:5] Total time: 0:06:57 (0.9697 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:5]  [ 0/14]  eta: 0:03:37  loss: 0.0007 (0.0007)  time: 15.5034  data: 0.5575  max mem: 39452\n",
      "Valid: [epoch:5]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.6470  data: 0.0399  max mem: 39452\n",
      "Valid: [epoch:5] Total time: 0:03:25 (14.6645 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_5_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:6]  [  0/431]  eta: 0:25:15  lr: 0.000100  loss: 0.0017 (0.0017)  time: 3.5153  data: 2.2611  max mem: 39452\n",
      "Train: [epoch:6]  [ 10/431]  eta: 0:08:25  lr: 0.000100  loss: 0.0020 (0.0023)  time: 1.1998  data: 0.2056  max mem: 39452\n",
      "Train: [epoch:6]  [ 20/431]  eta: 0:07:44  lr: 0.000100  loss: 0.0020 (0.0023)  time: 1.0110  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [ 30/431]  eta: 0:07:07  lr: 0.000100  loss: 0.0020 (0.0022)  time: 0.9923  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [ 40/431]  eta: 0:06:56  lr: 0.000100  loss: 0.0019 (0.0022)  time: 0.9955  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [ 50/431]  eta: 0:06:35  lr: 0.000100  loss: 0.0021 (0.0022)  time: 0.9974  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [ 60/431]  eta: 0:06:32  lr: 0.000100  loss: 0.0019 (0.0021)  time: 1.0418  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [ 70/431]  eta: 0:06:10  lr: 0.000100  loss: 0.0018 (0.0021)  time: 0.9938  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [ 80/431]  eta: 0:06:04  lr: 0.000100  loss: 0.0017 (0.0021)  time: 0.9804  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [ 90/431]  eta: 0:05:45  lr: 0.000100  loss: 0.0018 (0.0021)  time: 0.9652  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [100/431]  eta: 0:05:37  lr: 0.000100  loss: 0.0018 (0.0021)  time: 0.9450  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [110/431]  eta: 0:05:21  lr: 0.000100  loss: 0.0018 (0.0021)  time: 0.9580  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [120/431]  eta: 0:05:14  lr: 0.000100  loss: 0.0019 (0.0021)  time: 0.9684  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [130/431]  eta: 0:05:01  lr: 0.000100  loss: 0.0019 (0.0021)  time: 0.9893  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [140/431]  eta: 0:04:54  lr: 0.000100  loss: 0.0021 (0.0021)  time: 1.0093  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [150/431]  eta: 0:04:40  lr: 0.000100  loss: 0.0024 (0.0021)  time: 0.9766  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [160/431]  eta: 0:04:32  lr: 0.000100  loss: 0.0020 (0.0021)  time: 0.9682  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [170/431]  eta: 0:04:19  lr: 0.000100  loss: 0.0020 (0.0021)  time: 0.9530  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [180/431]  eta: 0:04:09  lr: 0.000100  loss: 0.0021 (0.0021)  time: 0.9083  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [190/431]  eta: 0:03:58  lr: 0.000100  loss: 0.0022 (0.0022)  time: 0.9723  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [200/431]  eta: 0:03:48  lr: 0.000100  loss: 0.0022 (0.0022)  time: 0.9512  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [210/431]  eta: 0:03:38  lr: 0.000100  loss: 0.0019 (0.0022)  time: 0.9801  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [220/431]  eta: 0:03:30  lr: 0.000100  loss: 0.0019 (0.0022)  time: 1.0442  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [230/431]  eta: 0:03:19  lr: 0.000100  loss: 0.0020 (0.0022)  time: 1.0000  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [240/431]  eta: 0:03:09  lr: 0.000100  loss: 0.0022 (0.0022)  time: 0.9466  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [250/431]  eta: 0:02:58  lr: 0.000100  loss: 0.0020 (0.0022)  time: 0.9676  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [260/431]  eta: 0:02:49  lr: 0.000100  loss: 0.0019 (0.0022)  time: 1.0018  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [270/431]  eta: 0:02:39  lr: 0.000100  loss: 0.0021 (0.0022)  time: 0.9829  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [280/431]  eta: 0:02:30  lr: 0.000100  loss: 0.0024 (0.0022)  time: 1.0148  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [290/431]  eta: 0:02:19  lr: 0.000100  loss: 0.0022 (0.0022)  time: 0.9982  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [300/431]  eta: 0:02:09  lr: 0.000100  loss: 0.0019 (0.0022)  time: 0.9329  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [310/431]  eta: 0:01:59  lr: 0.000100  loss: 0.0020 (0.0022)  time: 0.9705  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [320/431]  eta: 0:01:49  lr: 0.000100  loss: 0.0020 (0.0022)  time: 0.9156  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [330/431]  eta: 0:01:39  lr: 0.000100  loss: 0.0021 (0.0022)  time: 0.9749  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [340/431]  eta: 0:01:29  lr: 0.000100  loss: 0.0021 (0.0022)  time: 0.9314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [350/431]  eta: 0:01:19  lr: 0.000100  loss: 0.0019 (0.0022)  time: 0.9859  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [360/431]  eta: 0:01:09  lr: 0.000100  loss: 0.0021 (0.0022)  time: 0.9958  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [370/431]  eta: 0:01:00  lr: 0.000100  loss: 0.0024 (0.0022)  time: 0.9790  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [380/431]  eta: 0:00:49  lr: 0.000100  loss: 0.0024 (0.0022)  time: 0.9306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [390/431]  eta: 0:00:40  lr: 0.000100  loss: 0.0021 (0.0022)  time: 0.8953  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [400/431]  eta: 0:00:30  lr: 0.000100  loss: 0.0020 (0.0022)  time: 1.0005  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [410/431]  eta: 0:00:20  lr: 0.000100  loss: 0.0018 (0.0022)  time: 1.0539  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [420/431]  eta: 0:00:10  lr: 0.000100  loss: 0.0017 (0.0022)  time: 1.0115  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6]  [430/431]  eta: 0:00:00  lr: 0.000100  loss: 0.0019 (0.0022)  time: 1.0096  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:6] Total time: 0:07:05 (0.9868 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:6]  [ 0/14]  eta: 0:03:33  loss: 0.0019 (0.0019)  time: 15.2267  data: 0.5384  max mem: 39452\n",
      "Valid: [epoch:6]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.9503  data: 0.0386  max mem: 39452\n",
      "Valid: [epoch:6] Total time: 0:03:29 (14.9676 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_6_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:7]  [  0/431]  eta: 0:22:37  lr: 0.000120  loss: 0.0034 (0.0034)  time: 3.1504  data: 1.9053  max mem: 39452\n",
      "Train: [epoch:7]  [ 10/431]  eta: 0:08:37  lr: 0.000120  loss: 0.0021 (0.0024)  time: 1.2298  data: 0.1733  max mem: 39452\n",
      "Train: [epoch:7]  [ 20/431]  eta: 0:07:17  lr: 0.000120  loss: 0.0023 (0.0025)  time: 0.9606  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [ 30/431]  eta: 0:07:06  lr: 0.000120  loss: 0.0023 (0.0024)  time: 0.9722  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [ 40/431]  eta: 0:06:43  lr: 0.000120  loss: 0.0021 (0.0024)  time: 0.9976  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [ 50/431]  eta: 0:06:31  lr: 0.000120  loss: 0.0020 (0.0024)  time: 0.9744  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [ 60/431]  eta: 0:06:20  lr: 0.000120  loss: 0.0020 (0.0023)  time: 1.0147  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [ 70/431]  eta: 0:06:12  lr: 0.000120  loss: 0.0020 (0.0023)  time: 1.0399  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [ 80/431]  eta: 0:06:05  lr: 0.000120  loss: 0.0019 (0.0023)  time: 1.0919  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [ 90/431]  eta: 0:05:50  lr: 0.000120  loss: 0.0018 (0.0023)  time: 1.0149  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [100/431]  eta: 0:05:37  lr: 0.000120  loss: 0.0020 (0.0023)  time: 0.9205  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [110/431]  eta: 0:05:29  lr: 0.000120  loss: 0.0021 (0.0023)  time: 1.0208  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [120/431]  eta: 0:05:18  lr: 0.000120  loss: 0.0020 (0.0023)  time: 1.0573  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [130/431]  eta: 0:05:10  lr: 0.000120  loss: 0.0020 (0.0022)  time: 1.0497  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [140/431]  eta: 0:04:59  lr: 0.000120  loss: 0.0020 (0.0022)  time: 1.0457  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [150/431]  eta: 0:04:48  lr: 0.000120  loss: 0.0019 (0.0022)  time: 0.9968  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [160/431]  eta: 0:04:35  lr: 0.000120  loss: 0.0019 (0.0022)  time: 0.9486  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [170/431]  eta: 0:04:27  lr: 0.000120  loss: 0.0021 (0.0022)  time: 1.0329  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [180/431]  eta: 0:04:15  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.0277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [190/431]  eta: 0:04:07  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.0332  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [200/431]  eta: 0:03:55  lr: 0.000120  loss: 0.0020 (0.0022)  time: 1.0278  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [210/431]  eta: 0:03:47  lr: 0.000120  loss: 0.0020 (0.0022)  time: 1.0349  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [220/431]  eta: 0:03:37  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.1264  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [230/431]  eta: 0:03:28  lr: 0.000120  loss: 0.0021 (0.0022)  time: 1.1246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [240/431]  eta: 0:03:17  lr: 0.000120  loss: 0.0020 (0.0022)  time: 1.0736  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [250/431]  eta: 0:03:08  lr: 0.000120  loss: 0.0019 (0.0022)  time: 1.0732  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [260/431]  eta: 0:02:56  lr: 0.000120  loss: 0.0021 (0.0022)  time: 1.0482  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [270/431]  eta: 0:02:47  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.0704  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [280/431]  eta: 0:02:36  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.0672  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [290/431]  eta: 0:02:26  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.0319  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [300/431]  eta: 0:02:16  lr: 0.000120  loss: 0.0021 (0.0022)  time: 1.0965  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [310/431]  eta: 0:02:06  lr: 0.000120  loss: 0.0019 (0.0022)  time: 1.0592  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [320/431]  eta: 0:01:55  lr: 0.000120  loss: 0.0018 (0.0022)  time: 1.0794  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [330/431]  eta: 0:01:45  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.1364  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [340/431]  eta: 0:01:35  lr: 0.000120  loss: 0.0024 (0.0022)  time: 1.1271  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [350/431]  eta: 0:01:25  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.1022  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [360/431]  eta: 0:01:14  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.0779  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [370/431]  eta: 0:01:04  lr: 0.000120  loss: 0.0020 (0.0022)  time: 1.0466  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [380/431]  eta: 0:00:53  lr: 0.000120  loss: 0.0023 (0.0022)  time: 1.0721  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [390/431]  eta: 0:00:43  lr: 0.000120  loss: 0.0022 (0.0022)  time: 1.0819  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [400/431]  eta: 0:00:32  lr: 0.000120  loss: 0.0020 (0.0022)  time: 1.0953  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [410/431]  eta: 0:00:22  lr: 0.000120  loss: 0.0021 (0.0022)  time: 1.1086  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:7]  [420/431]  eta: 0:00:11  lr: 0.000120  loss: 0.0021 (0.0022)  time: 1.0949  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7]  [430/431]  eta: 0:00:01  lr: 0.000120  loss: 0.0018 (0.0022)  time: 1.1189  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:7] Total time: 0:07:36 (1.0585 s / it)\n",
      "Averaged stats: lr: 0.000120  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:7]  [ 0/14]  eta: 0:03:54  loss: 0.0012 (0.0012)  time: 16.7418  data: 0.5451  max mem: 39452\n",
      "Valid: [epoch:7]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0714  data: 0.0391  max mem: 39452\n",
      "Valid: [epoch:7] Total time: 0:03:45 (16.0943 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_7_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:8]  [  0/431]  eta: 0:22:04  lr: 0.000140  loss: 0.0015 (0.0015)  time: 3.0729  data: 1.9013  max mem: 39452\n",
      "Train: [epoch:8]  [ 10/431]  eta: 0:07:59  lr: 0.000140  loss: 0.0019 (0.0021)  time: 1.1383  data: 0.1730  max mem: 39452\n",
      "Train: [epoch:8]  [ 20/431]  eta: 0:08:03  lr: 0.000140  loss: 0.0020 (0.0023)  time: 1.0824  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [ 30/431]  eta: 0:07:14  lr: 0.000140  loss: 0.0019 (0.0022)  time: 1.0522  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [ 40/431]  eta: 0:07:17  lr: 0.000140  loss: 0.0018 (0.0022)  time: 1.0589  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [ 50/431]  eta: 0:06:48  lr: 0.000140  loss: 0.0024 (0.0023)  time: 1.0537  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [ 60/431]  eta: 0:06:41  lr: 0.000140  loss: 0.0023 (0.0023)  time: 1.0052  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [ 70/431]  eta: 0:06:24  lr: 0.000140  loss: 0.0020 (0.0023)  time: 1.0498  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [ 80/431]  eta: 0:06:18  lr: 0.000140  loss: 0.0018 (0.0022)  time: 1.0693  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [ 90/431]  eta: 0:06:05  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.0899  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [100/431]  eta: 0:05:58  lr: 0.000140  loss: 0.0021 (0.0022)  time: 1.1075  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [110/431]  eta: 0:05:43  lr: 0.000140  loss: 0.0021 (0.0022)  time: 1.0707  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [120/431]  eta: 0:05:34  lr: 0.000140  loss: 0.0022 (0.0022)  time: 1.0341  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [130/431]  eta: 0:05:24  lr: 0.000140  loss: 0.0023 (0.0022)  time: 1.1195  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [140/431]  eta: 0:05:16  lr: 0.000140  loss: 0.0019 (0.0022)  time: 1.1563  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [150/431]  eta: 0:05:02  lr: 0.000140  loss: 0.0019 (0.0022)  time: 1.0562  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [160/431]  eta: 0:04:53  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.0605  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [170/431]  eta: 0:04:40  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.0836  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [180/431]  eta: 0:04:32  lr: 0.000140  loss: 0.0018 (0.0022)  time: 1.0839  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [190/431]  eta: 0:04:20  lr: 0.000140  loss: 0.0018 (0.0022)  time: 1.1122  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [200/431]  eta: 0:04:11  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.1210  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [210/431]  eta: 0:03:58  lr: 0.000140  loss: 0.0018 (0.0022)  time: 1.0530  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [220/431]  eta: 0:03:48  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.0325  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [230/431]  eta: 0:03:37  lr: 0.000140  loss: 0.0021 (0.0022)  time: 1.1434  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [240/431]  eta: 0:03:27  lr: 0.000140  loss: 0.0019 (0.0022)  time: 1.1469  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [250/431]  eta: 0:03:15  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.0679  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [260/431]  eta: 0:03:05  lr: 0.000140  loss: 0.0023 (0.0022)  time: 1.0545  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [270/431]  eta: 0:02:54  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.0943  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [280/431]  eta: 0:02:44  lr: 0.000140  loss: 0.0019 (0.0022)  time: 1.1032  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [290/431]  eta: 0:02:32  lr: 0.000140  loss: 0.0021 (0.0022)  time: 1.0414  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [300/431]  eta: 0:02:21  lr: 0.000140  loss: 0.0021 (0.0022)  time: 1.0170  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [310/431]  eta: 0:02:11  lr: 0.000140  loss: 0.0021 (0.0022)  time: 1.1358  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [320/431]  eta: 0:02:00  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.1213  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [330/431]  eta: 0:01:49  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.0626  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [340/431]  eta: 0:01:38  lr: 0.000140  loss: 0.0021 (0.0022)  time: 1.0878  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [350/431]  eta: 0:01:27  lr: 0.000140  loss: 0.0021 (0.0022)  time: 1.1013  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [360/431]  eta: 0:01:16  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.0751  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:8]  [370/431]  eta: 0:01:06  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.1309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [380/431]  eta: 0:00:55  lr: 0.000140  loss: 0.0021 (0.0022)  time: 1.1042  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [390/431]  eta: 0:00:44  lr: 0.000140  loss: 0.0020 (0.0022)  time: 1.0256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [400/431]  eta: 0:00:33  lr: 0.000140  loss: 0.0020 (0.0022)  time: 0.9964  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [410/431]  eta: 0:00:22  lr: 0.000140  loss: 0.0022 (0.0022)  time: 1.0275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [420/431]  eta: 0:00:11  lr: 0.000140  loss: 0.0022 (0.0022)  time: 1.1199  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8]  [430/431]  eta: 0:00:01  lr: 0.000140  loss: 0.0019 (0.0022)  time: 1.1244  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:8] Total time: 0:07:46 (1.0828 s / it)\n",
      "Averaged stats: lr: 0.000140  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:8]  [ 0/14]  eta: 0:03:54  loss: 0.0013 (0.0013)  time: 16.7163  data: 0.7688  max mem: 39452\n",
      "Valid: [epoch:8]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0490  data: 0.0550  max mem: 39452\n",
      "Valid: [epoch:8] Total time: 0:03:44 (16.0632 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_8_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:9]  [  0/431]  eta: 0:22:33  lr: 0.000160  loss: 0.0014 (0.0014)  time: 3.1397  data: 1.9478  max mem: 39452\n",
      "Train: [epoch:9]  [ 10/431]  eta: 0:09:26  lr: 0.000160  loss: 0.0024 (0.0022)  time: 1.3455  data: 0.1772  max mem: 39452\n",
      "Train: [epoch:9]  [ 20/431]  eta: 0:08:17  lr: 0.000160  loss: 0.0021 (0.0021)  time: 1.1141  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [ 30/431]  eta: 0:08:03  lr: 0.000160  loss: 0.0019 (0.0021)  time: 1.1293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [ 40/431]  eta: 0:07:26  lr: 0.000160  loss: 0.0019 (0.0021)  time: 1.0717  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [ 50/431]  eta: 0:07:20  lr: 0.000160  loss: 0.0019 (0.0021)  time: 1.0777  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [ 60/431]  eta: 0:06:56  lr: 0.000160  loss: 0.0019 (0.0021)  time: 1.0841  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [ 70/431]  eta: 0:06:48  lr: 0.000160  loss: 0.0020 (0.0020)  time: 1.0720  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [ 80/431]  eta: 0:06:33  lr: 0.000160  loss: 0.0020 (0.0021)  time: 1.1147  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [ 90/431]  eta: 0:06:24  lr: 0.000160  loss: 0.0018 (0.0021)  time: 1.1157  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [100/431]  eta: 0:06:07  lr: 0.000160  loss: 0.0018 (0.0021)  time: 1.0694  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [110/431]  eta: 0:06:00  lr: 0.000160  loss: 0.0022 (0.0021)  time: 1.0925  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [120/431]  eta: 0:05:41  lr: 0.000160  loss: 0.0019 (0.0021)  time: 1.0317  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [130/431]  eta: 0:05:32  lr: 0.000160  loss: 0.0018 (0.0021)  time: 1.0002  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [140/431]  eta: 0:05:17  lr: 0.000160  loss: 0.0022 (0.0021)  time: 1.0606  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [150/431]  eta: 0:05:06  lr: 0.000160  loss: 0.0023 (0.0022)  time: 1.0186  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [160/431]  eta: 0:04:55  lr: 0.000160  loss: 0.0019 (0.0022)  time: 1.0618  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [170/431]  eta: 0:04:44  lr: 0.000160  loss: 0.0020 (0.0022)  time: 1.0756  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [180/431]  eta: 0:04:32  lr: 0.000160  loss: 0.0020 (0.0022)  time: 1.0566  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [190/431]  eta: 0:04:21  lr: 0.000160  loss: 0.0021 (0.0022)  time: 1.0243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [200/431]  eta: 0:04:10  lr: 0.000160  loss: 0.0024 (0.0022)  time: 1.0694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [210/431]  eta: 0:03:58  lr: 0.000160  loss: 0.0019 (0.0022)  time: 1.0446  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [220/431]  eta: 0:03:48  lr: 0.000160  loss: 0.0018 (0.0022)  time: 1.0572  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [230/431]  eta: 0:03:37  lr: 0.000160  loss: 0.0018 (0.0022)  time: 1.0919  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [240/431]  eta: 0:03:27  lr: 0.000160  loss: 0.0021 (0.0022)  time: 1.1183  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [250/431]  eta: 0:03:16  lr: 0.000160  loss: 0.0023 (0.0022)  time: 1.1202  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [260/431]  eta: 0:03:05  lr: 0.000160  loss: 0.0023 (0.0022)  time: 1.1140  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [270/431]  eta: 0:02:54  lr: 0.000160  loss: 0.0023 (0.0022)  time: 1.1180  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [280/431]  eta: 0:02:44  lr: 0.000160  loss: 0.0023 (0.0022)  time: 1.0950  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [290/431]  eta: 0:02:32  lr: 0.000160  loss: 0.0021 (0.0022)  time: 1.0609  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [300/431]  eta: 0:02:22  lr: 0.000160  loss: 0.0019 (0.0022)  time: 1.1011  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [310/431]  eta: 0:02:11  lr: 0.000160  loss: 0.0019 (0.0022)  time: 1.1501  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [320/431]  eta: 0:02:00  lr: 0.000160  loss: 0.0021 (0.0022)  time: 1.0651  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [330/431]  eta: 0:01:49  lr: 0.000160  loss: 0.0024 (0.0022)  time: 1.0422  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [340/431]  eta: 0:01:38  lr: 0.000160  loss: 0.0022 (0.0022)  time: 1.0597  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [350/431]  eta: 0:01:27  lr: 0.000160  loss: 0.0020 (0.0022)  time: 1.0697  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [360/431]  eta: 0:01:16  lr: 0.000160  loss: 0.0020 (0.0022)  time: 1.0487  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [370/431]  eta: 0:01:06  lr: 0.000160  loss: 0.0020 (0.0022)  time: 1.0642  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9]  [380/431]  eta: 0:00:55  lr: 0.000160  loss: 0.0020 (0.0022)  time: 1.0961  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [390/431]  eta: 0:00:44  lr: 0.000160  loss: 0.0019 (0.0022)  time: 1.0838  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [400/431]  eta: 0:00:33  lr: 0.000160  loss: 0.0020 (0.0022)  time: 1.0945  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [410/431]  eta: 0:00:22  lr: 0.000160  loss: 0.0021 (0.0022)  time: 1.0933  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [420/431]  eta: 0:00:11  lr: 0.000160  loss: 0.0021 (0.0022)  time: 1.0917  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:9]  [430/431]  eta: 0:00:01  lr: 0.000160  loss: 0.0023 (0.0022)  time: 1.0687  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:9] Total time: 0:07:47 (1.0843 s / it)\n",
      "Averaged stats: lr: 0.000160  loss: 0.0023 (0.0022)\n",
      "Valid: [epoch:9]  [ 0/14]  eta: 0:03:52  loss: 0.0024 (0.0024)  time: 16.6132  data: 0.5971  max mem: 39452\n",
      "Valid: [epoch:9]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.2188  data: 0.0428  max mem: 39452\n",
      "Valid: [epoch:9] Total time: 0:03:47 (16.2359 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_9_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:10]  [  0/431]  eta: 0:17:08  lr: 0.000180  loss: 0.0017 (0.0017)  time: 2.3869  data: 1.4638  max mem: 39452\n",
      "Train: [epoch:10]  [ 10/431]  eta: 0:07:32  lr: 0.000180  loss: 0.0021 (0.0020)  time: 1.0742  data: 0.1332  max mem: 39452\n",
      "Train: [epoch:10]  [ 20/431]  eta: 0:07:49  lr: 0.000180  loss: 0.0021 (0.0022)  time: 1.0810  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [ 30/431]  eta: 0:07:21  lr: 0.000180  loss: 0.0020 (0.0022)  time: 1.1176  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [ 40/431]  eta: 0:07:17  lr: 0.000180  loss: 0.0020 (0.0022)  time: 1.0955  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [ 50/431]  eta: 0:07:04  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.1319  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [ 60/431]  eta: 0:06:55  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.1195  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [ 70/431]  eta: 0:06:40  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.1000  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [ 80/431]  eta: 0:06:29  lr: 0.000180  loss: 0.0018 (0.0021)  time: 1.0832  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [ 90/431]  eta: 0:06:17  lr: 0.000180  loss: 0.0019 (0.0021)  time: 1.0928  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [100/431]  eta: 0:06:06  lr: 0.000180  loss: 0.0019 (0.0021)  time: 1.0862  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [110/431]  eta: 0:05:56  lr: 0.000180  loss: 0.0022 (0.0021)  time: 1.1243  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [120/431]  eta: 0:05:46  lr: 0.000180  loss: 0.0025 (0.0021)  time: 1.1547  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [130/431]  eta: 0:05:35  lr: 0.000180  loss: 0.0022 (0.0022)  time: 1.1381  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [140/431]  eta: 0:05:23  lr: 0.000180  loss: 0.0022 (0.0022)  time: 1.0939  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [150/431]  eta: 0:05:11  lr: 0.000180  loss: 0.0023 (0.0022)  time: 1.0823  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [160/431]  eta: 0:04:59  lr: 0.000180  loss: 0.0018 (0.0022)  time: 1.0718  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [170/431]  eta: 0:04:50  lr: 0.000180  loss: 0.0017 (0.0022)  time: 1.1289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [180/431]  eta: 0:04:38  lr: 0.000180  loss: 0.0017 (0.0022)  time: 1.1404  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [190/431]  eta: 0:04:28  lr: 0.000180  loss: 0.0022 (0.0022)  time: 1.1354  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [200/431]  eta: 0:04:16  lr: 0.000180  loss: 0.0020 (0.0022)  time: 1.1147  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [210/431]  eta: 0:04:04  lr: 0.000180  loss: 0.0018 (0.0022)  time: 1.0381  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [220/431]  eta: 0:03:54  lr: 0.000180  loss: 0.0018 (0.0022)  time: 1.0957  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [230/431]  eta: 0:03:43  lr: 0.000180  loss: 0.0020 (0.0022)  time: 1.1537  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [240/431]  eta: 0:03:32  lr: 0.000180  loss: 0.0020 (0.0022)  time: 1.1530  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [250/431]  eta: 0:03:21  lr: 0.000180  loss: 0.0018 (0.0022)  time: 1.1106  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [260/431]  eta: 0:03:10  lr: 0.000180  loss: 0.0019 (0.0022)  time: 1.0941  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [270/431]  eta: 0:02:58  lr: 0.000180  loss: 0.0021 (0.0022)  time: 1.0887  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [280/431]  eta: 0:02:47  lr: 0.000180  loss: 0.0020 (0.0022)  time: 1.1129  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [290/431]  eta: 0:02:36  lr: 0.000180  loss: 0.0023 (0.0022)  time: 1.1393  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [300/431]  eta: 0:02:25  lr: 0.000180  loss: 0.0021 (0.0022)  time: 1.1032  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [310/431]  eta: 0:02:13  lr: 0.000180  loss: 0.0022 (0.0022)  time: 1.0146  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [320/431]  eta: 0:02:02  lr: 0.000180  loss: 0.0023 (0.0022)  time: 1.0286  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [330/431]  eta: 0:01:51  lr: 0.000180  loss: 0.0021 (0.0022)  time: 1.0491  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [340/431]  eta: 0:01:40  lr: 0.000180  loss: 0.0020 (0.0022)  time: 1.0933  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [350/431]  eta: 0:01:29  lr: 0.000180  loss: 0.0020 (0.0022)  time: 1.0533  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [360/431]  eta: 0:01:18  lr: 0.000180  loss: 0.0021 (0.0022)  time: 1.0628  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [370/431]  eta: 0:01:06  lr: 0.000180  loss: 0.0022 (0.0022)  time: 1.0559  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [380/431]  eta: 0:00:56  lr: 0.000180  loss: 0.0020 (0.0022)  time: 1.0255  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [390/431]  eta: 0:00:44  lr: 0.000180  loss: 0.0019 (0.0022)  time: 1.0883  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [400/431]  eta: 0:00:34  lr: 0.000180  loss: 0.0023 (0.0022)  time: 1.1267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [410/431]  eta: 0:00:22  lr: 0.000180  loss: 0.0019 (0.0022)  time: 1.0714  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10]  [420/431]  eta: 0:00:12  lr: 0.000180  loss: 0.0018 (0.0022)  time: 1.0357  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:10]  [430/431]  eta: 0:00:01  lr: 0.000180  loss: 0.0021 (0.0022)  time: 1.0985  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:10] Total time: 0:07:52 (1.0960 s / it)\n",
      "Averaged stats: lr: 0.000180  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:10]  [ 0/14]  eta: 0:03:58  loss: 0.0015 (0.0015)  time: 17.0208  data: 0.5784  max mem: 39452\n",
      "Valid: [epoch:10]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.3093  data: 0.0414  max mem: 39452\n",
      "Valid: [epoch:10] Total time: 0:03:48 (16.3223 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_10_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:11]  [  0/431]  eta: 0:22:55  lr: 0.000200  loss: 0.0016 (0.0016)  time: 3.1922  data: 1.9731  max mem: 39452\n",
      "Train: [epoch:11]  [ 10/431]  eta: 0:08:50  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.2591  data: 0.1795  max mem: 39452\n",
      "Train: [epoch:11]  [ 20/431]  eta: 0:08:17  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.1111  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [ 30/431]  eta: 0:07:40  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0885  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [ 40/431]  eta: 0:07:29  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0841  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [ 50/431]  eta: 0:07:03  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0532  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [ 60/431]  eta: 0:06:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0371  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [ 70/431]  eta: 0:06:41  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1143  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [ 80/431]  eta: 0:06:31  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1307  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [ 90/431]  eta: 0:06:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0603  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [100/431]  eta: 0:06:04  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0456  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [110/431]  eta: 0:05:54  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1207  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [120/431]  eta: 0:05:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1288  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [130/431]  eta: 0:05:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0763  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [140/431]  eta: 0:05:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1221  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [150/431]  eta: 0:05:09  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1171  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [160/431]  eta: 0:04:58  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0467  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [170/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1329  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [180/431]  eta: 0:04:38  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.1768  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [190/431]  eta: 0:04:26  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.1242  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [200/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.1487  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [210/431]  eta: 0:04:04  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.1090  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [220/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0557  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [230/431]  eta: 0:03:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0914  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [240/431]  eta: 0:03:30  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0626  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [250/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0938  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [260/431]  eta: 0:03:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0897  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [270/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [280/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0478  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [290/431]  eta: 0:02:34  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0729  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [300/431]  eta: 0:02:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0729  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [310/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0675  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [320/431]  eta: 0:02:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0583  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [330/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0362  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [340/431]  eta: 0:01:39  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0047  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [350/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0681  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [360/431]  eta: 0:01:17  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0993  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [370/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0781  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [380/431]  eta: 0:00:55  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0966  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [390/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0702  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:11]  [400/431]  eta: 0:00:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0528  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [410/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1101  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0498  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0812  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:11] Total time: 0:07:50 (1.0905 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0022 (0.0022)\n",
      "Valid: [epoch:11]  [ 0/14]  eta: 0:03:52  loss: 0.0024 (0.0024)  time: 16.6129  data: 0.5407  max mem: 39452\n",
      "Valid: [epoch:11]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0257  data: 0.0387  max mem: 39452\n",
      "Valid: [epoch:11] Total time: 0:03:44 (16.0479 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_11_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:12]  [  0/431]  eta: 0:19:25  lr: 0.000200  loss: 0.0027 (0.0027)  time: 2.7034  data: 1.4246  max mem: 39452\n",
      "Train: [epoch:12]  [ 10/431]  eta: 0:09:20  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.3318  data: 0.1297  max mem: 39452\n",
      "Train: [epoch:12]  [ 20/431]  eta: 0:07:55  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0806  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [ 30/431]  eta: 0:07:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0962  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [ 40/431]  eta: 0:07:17  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0789  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [ 50/431]  eta: 0:07:08  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0371  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [ 60/431]  eta: 0:06:46  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0500  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [ 70/431]  eta: 0:06:40  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0745  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [ 80/431]  eta: 0:06:23  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0757  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [ 90/431]  eta: 0:06:13  lr: 0.000200  loss: 0.0016 (0.0021)  time: 1.0392  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [100/431]  eta: 0:06:00  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0859  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [110/431]  eta: 0:05:49  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0647  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [120/431]  eta: 0:05:38  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0718  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [130/431]  eta: 0:05:27  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0790  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [140/431]  eta: 0:05:14  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0391  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [150/431]  eta: 0:05:04  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0470  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [160/431]  eta: 0:04:52  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0636  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [170/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0772  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [180/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0024 (0.0021)  time: 1.1099  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [190/431]  eta: 0:04:21  lr: 0.000200  loss: 0.0024 (0.0021)  time: 1.1013  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [200/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0024 (0.0021)  time: 1.0827  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [210/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0905  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [220/431]  eta: 0:03:46  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0122  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [230/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [240/431]  eta: 0:03:25  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0537  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [250/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [260/431]  eta: 0:03:04  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.1181  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [270/431]  eta: 0:02:54  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.1504  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [280/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [290/431]  eta: 0:02:33  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1602  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [300/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.1140  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [310/431]  eta: 0:02:11  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.1063  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [320/431]  eta: 0:02:00  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.1373  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [330/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [340/431]  eta: 0:01:38  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0725  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [350/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0730  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [360/431]  eta: 0:01:17  lr: 0.000200  loss: 0.0026 (0.0022)  time: 1.1097  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [370/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0688  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [380/431]  eta: 0:00:55  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0695  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [390/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1046  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [400/431]  eta: 0:00:33  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1032  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:12]  [410/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0988  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.1295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0741  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:12] Total time: 0:07:49 (1.0894 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:12]  [ 0/14]  eta: 0:03:52  loss: 0.0007 (0.0007)  time: 16.6286  data: 0.5587  max mem: 39452\n",
      "Valid: [epoch:12]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.1953  data: 0.0400  max mem: 39452\n",
      "Valid: [epoch:12] Total time: 0:03:46 (16.2083 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_12_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:13]  [  0/431]  eta: 0:20:55  lr: 0.000200  loss: 0.0022 (0.0022)  time: 2.9121  data: 1.7284  max mem: 39452\n",
      "Train: [epoch:13]  [ 10/431]  eta: 0:09:25  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.3423  data: 0.1572  max mem: 39452\n",
      "Train: [epoch:13]  [ 20/431]  eta: 0:08:21  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.1347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [ 30/431]  eta: 0:07:49  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0758  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [ 40/431]  eta: 0:07:28  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0709  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [ 50/431]  eta: 0:07:13  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0903  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [ 60/431]  eta: 0:06:54  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0560  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [ 70/431]  eta: 0:06:46  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0917  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [ 80/431]  eta: 0:06:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0904  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [ 90/431]  eta: 0:06:19  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0658  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [100/431]  eta: 0:06:07  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1037  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [110/431]  eta: 0:05:56  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1019  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [120/431]  eta: 0:05:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0841  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [130/431]  eta: 0:05:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0836  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [140/431]  eta: 0:05:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0950  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [150/431]  eta: 0:05:11  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1091  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [160/431]  eta: 0:04:59  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1074  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [170/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0968  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [180/431]  eta: 0:04:37  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.1031  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [190/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0693  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [200/431]  eta: 0:04:14  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0965  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [210/431]  eta: 0:04:03  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.1103  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [220/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1037  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [230/431]  eta: 0:03:41  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1025  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [240/431]  eta: 0:03:30  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.0595  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [250/431]  eta: 0:03:19  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.0979  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [260/431]  eta: 0:03:08  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1539  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [270/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1114  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [280/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.1205  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [290/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.1135  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [300/431]  eta: 0:02:24  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0644  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [310/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0729  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [320/431]  eta: 0:02:02  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1328  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [330/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0872  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [340/431]  eta: 0:01:40  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0169  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [350/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0624  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [360/431]  eta: 0:01:18  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1336  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [370/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1254  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [380/431]  eta: 0:00:56  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0794  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [390/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0471  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [400/431]  eta: 0:00:34  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0616  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [410/431]  eta: 0:00:23  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0541  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:13]  [420/431]  eta: 0:00:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0835  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1163  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:13] Total time: 0:07:52 (1.0968 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:13]  [ 0/14]  eta: 0:03:50  loss: 0.0025 (0.0025)  time: 16.4883  data: 0.5911  max mem: 39452\n",
      "Valid: [epoch:13]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.9522  data: 0.0423  max mem: 39452\n",
      "Valid: [epoch:13] Total time: 0:03:43 (15.9695 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_13_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:14]  [  0/431]  eta: 0:20:30  lr: 0.000200  loss: 0.0027 (0.0027)  time: 2.8559  data: 1.5767  max mem: 39452\n",
      "Train: [epoch:14]  [ 10/431]  eta: 0:08:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.2215  data: 0.1434  max mem: 39452\n",
      "Train: [epoch:14]  [ 20/431]  eta: 0:08:05  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0978  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [ 30/431]  eta: 0:07:36  lr: 0.000200  loss: 0.0025 (0.0025)  time: 1.0935  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [ 40/431]  eta: 0:07:23  lr: 0.000200  loss: 0.0028 (0.0026)  time: 1.0848  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [ 50/431]  eta: 0:07:09  lr: 0.000200  loss: 0.0024 (0.0025)  time: 1.1089  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [ 60/431]  eta: 0:07:00  lr: 0.000200  loss: 0.0019 (0.0024)  time: 1.1309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [ 70/431]  eta: 0:06:46  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.1277  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [ 80/431]  eta: 0:06:39  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.1583  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [ 90/431]  eta: 0:06:20  lr: 0.000200  loss: 0.0018 (0.0023)  time: 1.0756  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [100/431]  eta: 0:06:11  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0492  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [110/431]  eta: 0:05:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1410  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [120/431]  eta: 0:05:47  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1027  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [130/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0643  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [140/431]  eta: 0:05:25  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.1092  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [150/431]  eta: 0:05:12  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1117  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [160/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1045  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [170/431]  eta: 0:04:50  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.1290  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [180/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0024 (0.0023)  time: 1.1151  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [190/431]  eta: 0:04:26  lr: 0.000200  loss: 0.0024 (0.0023)  time: 1.0321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [200/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0354  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [210/431]  eta: 0:04:04  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0996  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [220/431]  eta: 0:03:54  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.1403  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [230/431]  eta: 0:03:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0666  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [240/431]  eta: 0:03:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0413  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [250/431]  eta: 0:03:19  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1134  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [260/431]  eta: 0:03:09  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1168  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [270/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1025  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [280/431]  eta: 0:02:47  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1252  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [290/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.1220  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [300/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.1112  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [310/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0758  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [320/431]  eta: 0:02:02  lr: 0.000200  loss: 0.0016 (0.0022)  time: 1.0609  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [330/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1012  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [340/431]  eta: 0:01:40  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1130  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [350/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1187  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [360/431]  eta: 0:01:18  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0938  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [370/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0943  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [380/431]  eta: 0:00:56  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1165  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:14]  [390/431]  eta: 0:00:45  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0713  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [400/431]  eta: 0:00:34  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0906  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [410/431]  eta: 0:00:23  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.1765  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [420/431]  eta: 0:00:12  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.1628  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1525  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:14] Total time: 0:07:57 (1.1074 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:14]  [ 0/14]  eta: 0:03:50  loss: 0.0026 (0.0026)  time: 16.4527  data: 0.5804  max mem: 39452\n",
      "Valid: [epoch:14]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0729  data: 0.0416  max mem: 39452\n",
      "Valid: [epoch:14] Total time: 0:03:45 (16.0920 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_14_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:15]  [  0/431]  eta: 0:21:46  lr: 0.000200  loss: 0.0031 (0.0031)  time: 3.0312  data: 1.8058  max mem: 39452\n",
      "Train: [epoch:15]  [ 10/431]  eta: 0:09:33  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.3630  data: 0.1643  max mem: 39452\n",
      "Train: [epoch:15]  [ 20/431]  eta: 0:08:07  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0938  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [ 30/431]  eta: 0:07:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0756  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [ 40/431]  eta: 0:07:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0733  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [ 50/431]  eta: 0:07:14  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0809  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [ 60/431]  eta: 0:06:52  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0741  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [ 70/431]  eta: 0:06:46  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0949  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [ 80/431]  eta: 0:06:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1047  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [ 90/431]  eta: 0:06:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1054  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [100/431]  eta: 0:06:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0901  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [110/431]  eta: 0:05:56  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0640  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [120/431]  eta: 0:05:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1098  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [130/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.1102  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [140/431]  eta: 0:05:19  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0476  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [150/431]  eta: 0:05:09  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0455  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [160/431]  eta: 0:04:55  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0443  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [170/431]  eta: 0:04:44  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9956  data: 0.0003  max mem: 39452\n",
      "Train: [epoch:15]  [180/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0851  data: 0.0003  max mem: 39452\n",
      "Train: [epoch:15]  [190/431]  eta: 0:04:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0833  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [200/431]  eta: 0:04:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0414  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [210/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0831  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [220/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0503  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [230/431]  eta: 0:03:38  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0717  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [240/431]  eta: 0:03:26  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0885  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [250/431]  eta: 0:03:15  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9672  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [260/431]  eta: 0:03:04  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [270/431]  eta: 0:02:53  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0403  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [280/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0026 (0.0022)  time: 1.0233  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [290/431]  eta: 0:02:31  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0455  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [300/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0639  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [310/431]  eta: 0:02:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0960  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [320/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0823  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [330/431]  eta: 0:01:48  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0933  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [340/431]  eta: 0:01:37  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1053  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [350/431]  eta: 0:01:27  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0828  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [360/431]  eta: 0:01:16  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0761  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [370/431]  eta: 0:01:05  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1198  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [380/431]  eta: 0:00:55  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1214  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [390/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0849  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [400/431]  eta: 0:00:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0845  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:15]  [410/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0971  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0581  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9752  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:15] Total time: 0:07:43 (1.0755 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:15]  [ 0/14]  eta: 0:04:01  loss: 0.0007 (0.0007)  time: 17.2848  data: 0.5998  max mem: 39452\n",
      "Valid: [epoch:15]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.5231  data: 0.0430  max mem: 39452\n",
      "Valid: [epoch:15] Total time: 0:03:51 (16.5385 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_15_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:16]  [  0/431]  eta: 0:26:30  lr: 0.000200  loss: 0.0031 (0.0031)  time: 3.6896  data: 2.3274  max mem: 39452\n",
      "Train: [epoch:16]  [ 10/431]  eta: 0:09:15  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.3191  data: 0.2117  max mem: 39452\n",
      "Train: [epoch:16]  [ 20/431]  eta: 0:08:11  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0700  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [ 30/431]  eta: 0:07:31  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0204  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [ 40/431]  eta: 0:07:01  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9547  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [ 50/431]  eta: 0:06:53  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0213  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [ 60/431]  eta: 0:06:38  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0683  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [ 70/431]  eta: 0:06:28  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0495  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [ 80/431]  eta: 0:06:09  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9827  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [ 90/431]  eta: 0:05:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9778  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [100/431]  eta: 0:05:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9621  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [110/431]  eta: 0:05:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0079  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [120/431]  eta: 0:05:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [130/431]  eta: 0:05:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0141  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [140/431]  eta: 0:05:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0376  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [150/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0115  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [160/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0226  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [170/431]  eta: 0:04:29  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9875  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [180/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9713  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [190/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [200/431]  eta: 0:03:57  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0349  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [210/431]  eta: 0:03:47  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0112  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [220/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0420  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [230/431]  eta: 0:03:26  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0330  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [240/431]  eta: 0:03:17  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0773  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [250/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0560  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [260/431]  eta: 0:02:56  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0340  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [270/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [280/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0272  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [290/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9952  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [300/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0105  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [310/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0350  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [320/431]  eta: 0:01:54  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0574  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [330/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0570  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0389  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [350/431]  eta: 0:01:23  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0424  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [360/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0409  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0172  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:16]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9875  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9957  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0350  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0335  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0496  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0789  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:16] Total time: 0:07:24 (1.0323 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:16]  [ 0/14]  eta: 0:03:50  loss: 0.0007 (0.0007)  time: 16.4808  data: 0.8347  max mem: 39452\n",
      "Valid: [epoch:16]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.6518  data: 0.0598  max mem: 39452\n",
      "Valid: [epoch:16] Total time: 0:03:39 (15.6714 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_16_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:17]  [  0/431]  eta: 0:20:25  lr: 0.000200  loss: 0.0029 (0.0029)  time: 2.8442  data: 1.6264  max mem: 39452\n",
      "Train: [epoch:17]  [ 10/431]  eta: 0:08:24  lr: 0.000200  loss: 0.0024 (0.0025)  time: 1.1987  data: 0.1480  max mem: 39452\n",
      "Train: [epoch:17]  [ 20/431]  eta: 0:07:38  lr: 0.000200  loss: 0.0024 (0.0025)  time: 1.0300  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [ 30/431]  eta: 0:07:22  lr: 0.000200  loss: 0.0022 (0.0024)  time: 1.0506  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [ 40/431]  eta: 0:07:03  lr: 0.000200  loss: 0.0021 (0.0024)  time: 1.0496  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [ 50/431]  eta: 0:06:45  lr: 0.000200  loss: 0.0021 (0.0024)  time: 1.0068  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [ 60/431]  eta: 0:06:38  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0562  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [ 70/431]  eta: 0:06:19  lr: 0.000200  loss: 0.0018 (0.0023)  time: 1.0110  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [ 80/431]  eta: 0:06:14  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0410  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [ 90/431]  eta: 0:05:56  lr: 0.000200  loss: 0.0023 (0.0024)  time: 1.0320  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [100/431]  eta: 0:05:48  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9908  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [110/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0021 (0.0024)  time: 1.0241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [120/431]  eta: 0:05:26  lr: 0.000200  loss: 0.0021 (0.0024)  time: 1.0331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [130/431]  eta: 0:05:13  lr: 0.000200  loss: 0.0021 (0.0024)  time: 1.0359  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [140/431]  eta: 0:05:04  lr: 0.000200  loss: 0.0020 (0.0024)  time: 1.0277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [150/431]  eta: 0:04:52  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0355  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [160/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9785  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [170/431]  eta: 0:04:30  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0003  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [180/431]  eta: 0:04:20  lr: 0.000200  loss: 0.0018 (0.0023)  time: 1.0398  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [190/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0122  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [200/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0195  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [210/431]  eta: 0:03:47  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0032  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [220/431]  eta: 0:03:38  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0194  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [230/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0383  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [240/431]  eta: 0:03:17  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0039  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [250/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0172  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [260/431]  eta: 0:02:56  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0380  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [270/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0516  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [280/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0033  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [290/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0018 (0.0023)  time: 1.0089  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [300/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0343  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [310/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0526  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [320/431]  eta: 0:01:54  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0651  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [330/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0018 (0.0023)  time: 1.0455  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [350/431]  eta: 0:01:23  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0199  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [360/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9773  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0077  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0473  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0317  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9934  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0158  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:17]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0353  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:17] Total time: 0:07:24 (1.0306 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:17]  [ 0/14]  eta: 0:03:45  loss: 0.0025 (0.0025)  time: 16.0715  data: 0.7577  max mem: 39452\n",
      "Valid: [epoch:17]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.6576  data: 0.0543  max mem: 39452\n",
      "Valid: [epoch:17] Total time: 0:03:39 (15.6731 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_17_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:18]  [  0/431]  eta: 0:17:53  lr: 0.000200  loss: 0.0024 (0.0024)  time: 2.4917  data: 1.3691  max mem: 39452\n",
      "Train: [epoch:18]  [ 10/431]  eta: 0:08:25  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.2015  data: 0.1246  max mem: 39452\n",
      "Train: [epoch:18]  [ 20/431]  eta: 0:07:26  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0149  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:18]  [ 30/431]  eta: 0:07:18  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0344  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [ 40/431]  eta: 0:06:48  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0038  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [ 50/431]  eta: 0:06:46  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0231  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [ 60/431]  eta: 0:06:25  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0224  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [ 70/431]  eta: 0:06:15  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9769  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [ 80/431]  eta: 0:06:04  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0400  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:18]  [ 90/431]  eta: 0:05:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9978  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [100/431]  eta: 0:05:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0206  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [110/431]  eta: 0:05:32  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0606  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [120/431]  eta: 0:05:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0589  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [130/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1030  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:18]  [140/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1078  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:18]  [150/431]  eta: 0:04:55  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0786  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [160/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9903  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [170/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9838  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [180/431]  eta: 0:04:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0027  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [190/431]  eta: 0:04:11  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0484  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:18]  [200/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0181  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [210/431]  eta: 0:03:49  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9901  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [220/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0120  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [230/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9964  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [240/431]  eta: 0:03:16  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0066  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [250/431]  eta: 0:03:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0326  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [260/431]  eta: 0:02:56  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0573  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [270/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0573  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [280/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0528  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [290/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0093  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [300/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0382  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [310/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0922  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [320/431]  eta: 0:01:55  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0863  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [330/431]  eta: 0:01:45  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0888  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [340/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0036  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [350/431]  eta: 0:01:24  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0095  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [360/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0190  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [370/431]  eta: 0:01:03  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0028  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0043  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0117  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [400/431]  eta: 0:00:32  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.0721  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.0943  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0251  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9736  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:18] Total time: 0:07:26 (1.0367 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0021 (0.0022)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:18]  [ 0/14]  eta: 0:03:49  loss: 0.0024 (0.0024)  time: 16.3810  data: 0.7280  max mem: 39452\n",
      "Valid: [epoch:18]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.5739  data: 0.0521  max mem: 39452\n",
      "Valid: [epoch:18] Total time: 0:03:38 (15.5893 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_18_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:19]  [  0/431]  eta: 0:22:21  lr: 0.000200  loss: 0.0017 (0.0017)  time: 3.1130  data: 2.3006  max mem: 39452\n",
      "Train: [epoch:19]  [ 10/431]  eta: 0:07:20  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0470  data: 0.2093  max mem: 39452\n",
      "Train: [epoch:19]  [ 20/431]  eta: 0:07:36  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0094  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [ 30/431]  eta: 0:07:04  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0656  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [ 40/431]  eta: 0:07:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0449  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [ 50/431]  eta: 0:06:39  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [ 60/431]  eta: 0:06:33  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0217  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:19]  [ 70/431]  eta: 0:06:17  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0404  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:19]  [ 80/431]  eta: 0:06:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0388  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:19]  [ 90/431]  eta: 0:05:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0205  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [100/431]  eta: 0:05:46  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0167  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [110/431]  eta: 0:05:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0789  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [120/431]  eta: 0:05:26  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0659  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:19]  [130/431]  eta: 0:05:16  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0648  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [140/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0092  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [150/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0137  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [160/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0657  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:19]  [170/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0900  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:19]  [180/431]  eta: 0:04:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [190/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0452  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [200/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0114  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [210/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0139  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [220/431]  eta: 0:03:39  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0141  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:19]  [230/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0200  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:19]  [240/431]  eta: 0:03:18  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0139  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [250/431]  eta: 0:03:08  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [260/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0142  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [270/431]  eta: 0:02:47  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9956  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [280/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0715  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [290/431]  eta: 0:02:26  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0718  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [300/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0088  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [310/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0054  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [320/431]  eta: 0:01:55  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0511  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [330/431]  eta: 0:01:45  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0654  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [340/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0141  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [350/431]  eta: 0:01:24  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9982  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [360/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9904  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [370/431]  eta: 0:01:03  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9859  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9811  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9605  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0605  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0092  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9969  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9730  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:19] Total time: 0:07:23 (1.0288 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:19]  [ 0/14]  eta: 0:03:49  loss: 0.0024 (0.0024)  time: 16.3980  data: 0.7308  max mem: 39452\n",
      "Valid: [epoch:19]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.6709  data: 0.0523  max mem: 39452\n",
      "Valid: [epoch:19] Total time: 0:03:39 (15.6900 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_19_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:20]  [  0/431]  eta: 0:15:32  lr: 0.000200  loss: 0.0015 (0.0015)  time: 2.1644  data: 1.3855  max mem: 39452\n",
      "Train: [epoch:20]  [ 10/431]  eta: 0:07:55  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.1285  data: 0.1261  max mem: 39452\n",
      "Train: [epoch:20]  [ 20/431]  eta: 0:07:11  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9953  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [ 30/431]  eta: 0:07:04  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0208  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [ 40/431]  eta: 0:06:48  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0376  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [ 50/431]  eta: 0:06:41  lr: 0.000200  loss: 0.0022 (0.0024)  time: 1.0490  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [ 60/431]  eta: 0:06:27  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0455  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [ 70/431]  eta: 0:06:20  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0479  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [ 80/431]  eta: 0:06:03  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0050  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [ 90/431]  eta: 0:05:54  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9877  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [100/431]  eta: 0:05:43  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0492  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [110/431]  eta: 0:05:35  lr: 0.000200  loss: 0.0018 (0.0023)  time: 1.0779  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [120/431]  eta: 0:05:24  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0709  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [130/431]  eta: 0:05:14  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0302  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [140/431]  eta: 0:05:01  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9967  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [150/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0025 (0.0023)  time: 1.0498  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [160/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0024 (0.0023)  time: 1.0409  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [170/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0357  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [180/431]  eta: 0:04:19  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0188  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [190/431]  eta: 0:04:11  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0294  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [200/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0159  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [210/431]  eta: 0:03:49  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0038  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [220/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0023  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [230/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0026 (0.0023)  time: 1.0142  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [240/431]  eta: 0:03:16  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.0217  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [250/431]  eta: 0:03:07  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0087  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [260/431]  eta: 0:02:55  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0097  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [270/431]  eta: 0:02:45  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9811  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [280/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0413  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [290/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0419  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [300/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0570  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:20]  [310/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0964  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [320/431]  eta: 0:01:54  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [330/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0122  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [350/431]  eta: 0:01:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0383  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [360/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0193  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [370/431]  eta: 0:01:03  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0572  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0611  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9867  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0014  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0560  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0534  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:20] Total time: 0:07:26 (1.0350 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:20]  [ 0/14]  eta: 0:03:51  loss: 0.0024 (0.0024)  time: 16.5589  data: 0.7680  max mem: 39452\n",
      "Valid: [epoch:20]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.7837  data: 0.0550  max mem: 39452\n",
      "Valid: [epoch:20] Total time: 0:03:41 (15.8044 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_20_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:21]  [  0/431]  eta: 0:21:46  lr: 0.000200  loss: 0.0022 (0.0022)  time: 3.0322  data: 1.9922  max mem: 39452\n",
      "Train: [epoch:21]  [ 10/431]  eta: 0:09:27  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.3480  data: 0.1812  max mem: 39452\n",
      "Train: [epoch:21]  [ 20/431]  eta: 0:07:42  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [ 30/431]  eta: 0:07:30  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0010  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [ 40/431]  eta: 0:07:04  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0452  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [ 50/431]  eta: 0:06:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9663  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [ 60/431]  eta: 0:06:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0113  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [ 70/431]  eta: 0:06:18  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0165  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [ 80/431]  eta: 0:06:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0365  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [ 90/431]  eta: 0:05:56  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0372  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [100/431]  eta: 0:05:47  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0255  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [110/431]  eta: 0:05:33  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0034  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [120/431]  eta: 0:05:26  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0493  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [130/431]  eta: 0:05:12  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [140/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0504  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [150/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0829  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [160/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0195  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [170/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0177  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [180/431]  eta: 0:04:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [190/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9947  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [200/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0061  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [210/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0106  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [220/431]  eta: 0:03:39  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0336  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [230/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0371  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [240/431]  eta: 0:03:17  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0054  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [250/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9875  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [260/431]  eta: 0:02:56  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0160  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [270/431]  eta: 0:02:45  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0125  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [280/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0141  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [290/431]  eta: 0:02:24  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0235  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [300/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0261  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [310/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0143  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:21]  [320/431]  eta: 0:01:54  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0097  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [330/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0218  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0165  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [350/431]  eta: 0:01:23  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0630  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:21]  [360/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0028 (0.0022)  time: 1.0691  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0026 (0.0022)  time: 1.0577  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9867  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0163  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0599  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0593  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0174  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:21] Total time: 0:07:23 (1.0299 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0023 (0.0022)\n",
      "Valid: [epoch:21]  [ 0/14]  eta: 0:03:53  loss: 0.0025 (0.0025)  time: 16.7006  data: 0.7252  max mem: 39452\n",
      "Valid: [epoch:21]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.7140  data: 0.0519  max mem: 39452\n",
      "Valid: [epoch:21] Total time: 0:03:40 (15.7304 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_21_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:22]  [  0/431]  eta: 0:25:23  lr: 0.000200  loss: 0.0024 (0.0024)  time: 3.5354  data: 2.2003  max mem: 39452\n",
      "Train: [epoch:22]  [ 10/431]  eta: 0:07:52  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.1217  data: 0.2002  max mem: 39452\n",
      "Train: [epoch:22]  [ 20/431]  eta: 0:07:43  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0086  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [ 30/431]  eta: 0:07:06  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0328  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:22]  [ 40/431]  eta: 0:06:53  lr: 0.000200  loss: 0.0020 (0.0020)  time: 0.9811  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:22]  [ 50/431]  eta: 0:06:36  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0067  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [ 60/431]  eta: 0:06:28  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0276  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [ 70/431]  eta: 0:06:16  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0503  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [ 80/431]  eta: 0:06:11  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0928  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [ 90/431]  eta: 0:05:56  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0565  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [100/431]  eta: 0:05:49  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0456  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [110/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [120/431]  eta: 0:05:26  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0094  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:22]  [130/431]  eta: 0:05:13  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0271  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [140/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0643  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [150/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0674  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [160/431]  eta: 0:04:44  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0579  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [170/431]  eta: 0:04:30  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.9812  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [180/431]  eta: 0:04:21  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9549  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [190/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0044  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [200/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0157  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [210/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0608  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [220/431]  eta: 0:03:40  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0987  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:22]  [230/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0750  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [240/431]  eta: 0:03:18  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0163  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [250/431]  eta: 0:03:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0542  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [260/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0677  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [270/431]  eta: 0:02:47  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0436  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [280/431]  eta: 0:02:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0685  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [290/431]  eta: 0:02:26  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0177  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [300/431]  eta: 0:02:16  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0374  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [310/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [320/431]  eta: 0:01:55  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0022  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [330/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9876  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [340/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9954  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [350/431]  eta: 0:01:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0364  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [360/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0514  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [370/431]  eta: 0:01:03  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0224  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9986  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0394  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [400/431]  eta: 0:00:32  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0191  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0034  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:22]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0400  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:22]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0637  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:22] Total time: 0:07:26 (1.0354 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0023 (0.0022)\n",
      "Valid: [epoch:22]  [ 0/14]  eta: 0:03:46  loss: 0.0015 (0.0015)  time: 16.1775  data: 0.6056  max mem: 39452\n",
      "Valid: [epoch:22]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.6446  data: 0.0434  max mem: 39452\n",
      "Valid: [epoch:22] Total time: 0:03:39 (15.6622 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_22_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:23]  [  0/431]  eta: 0:18:48  lr: 0.000200  loss: 0.0028 (0.0028)  time: 2.6190  data: 1.6426  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:23]  [ 10/431]  eta: 0:07:07  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0153  data: 0.1495  max mem: 39452\n",
      "Train: [epoch:23]  [ 20/431]  eta: 0:07:30  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0187  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [ 30/431]  eta: 0:06:46  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0120  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [ 40/431]  eta: 0:06:47  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.9877  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [ 50/431]  eta: 0:06:21  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.9843  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [ 60/431]  eta: 0:06:20  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.9884  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [ 70/431]  eta: 0:06:06  lr: 0.000200  loss: 0.0018 (0.0023)  time: 1.0460  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [ 80/431]  eta: 0:06:02  lr: 0.000200  loss: 0.0018 (0.0023)  time: 1.0583  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [ 90/431]  eta: 0:05:48  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0484  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [100/431]  eta: 0:05:40  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0063  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [110/431]  eta: 0:05:29  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0416  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [120/431]  eta: 0:05:21  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0658  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [130/431]  eta: 0:05:09  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0525  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [140/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0852  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [150/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0022  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [160/431]  eta: 0:04:40  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9790  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [170/431]  eta: 0:04:28  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0416  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [180/431]  eta: 0:04:19  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0400  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [190/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0412  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [200/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0512  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [210/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0842  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [220/431]  eta: 0:03:39  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0721  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [230/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0027  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [240/431]  eta: 0:03:18  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [250/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0171  data: 0.0003  max mem: 39452\n",
      "Train: [epoch:23]  [260/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0145  data: 0.0003  max mem: 39452\n",
      "Train: [epoch:23]  [270/431]  eta: 0:02:45  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0094  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [280/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9611  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [290/431]  eta: 0:02:24  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0189  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [300/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9841  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [310/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0573  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [320/431]  eta: 0:01:54  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0884  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [330/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0620  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [340/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1081  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [350/431]  eta: 0:01:23  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0682  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [360/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0502  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [370/431]  eta: 0:01:03  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0331  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0361  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0478  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [400/431]  eta: 0:00:32  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0647  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0488  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0395  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:23]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0166  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:23] Total time: 0:07:26 (1.0352 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:23]  [ 0/14]  eta: 0:03:48  loss: 0.0024 (0.0024)  time: 16.3257  data: 0.7543  max mem: 39452\n",
      "Valid: [epoch:23]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.6643  data: 0.0540  max mem: 39452\n",
      "Valid: [epoch:23] Total time: 0:03:39 (15.6825 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_23_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:24]  [  0/431]  eta: 0:23:00  lr: 0.000200  loss: 0.0025 (0.0025)  time: 3.2041  data: 1.9856  max mem: 39452\n",
      "Train: [epoch:24]  [ 10/431]  eta: 0:09:00  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.2829  data: 0.1806  max mem: 39452\n",
      "Train: [epoch:24]  [ 20/431]  eta: 0:07:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0221  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [ 30/431]  eta: 0:07:28  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [ 40/431]  eta: 0:07:02  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0337  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [ 50/431]  eta: 0:06:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [ 60/431]  eta: 0:06:31  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0008  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [ 70/431]  eta: 0:06:23  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0135  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [ 80/431]  eta: 0:06:09  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0497  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [ 90/431]  eta: 0:06:01  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0445  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:24]  [100/431]  eta: 0:05:46  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0146  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:24]  [110/431]  eta: 0:05:37  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0172  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [120/431]  eta: 0:05:23  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0213  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [130/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [140/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0141  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [150/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [160/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9791  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [170/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9894  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [180/431]  eta: 0:04:18  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0191  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:24]  [190/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0070  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [200/431]  eta: 0:03:57  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0173  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [210/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0130  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [220/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [230/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0484  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [240/431]  eta: 0:03:16  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0225  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:24]  [250/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0026 (0.0022)  time: 1.0065  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [260/431]  eta: 0:02:55  lr: 0.000200  loss: 0.0028 (0.0022)  time: 0.9788  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [270/431]  eta: 0:02:45  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.9808  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [280/431]  eta: 0:02:34  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0267  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:24]  [290/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0383  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:24]  [300/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0996  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:24]  [310/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0637  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [320/431]  eta: 0:01:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0128  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [330/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0422  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0472  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:24]  [350/431]  eta: 0:01:23  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [360/431]  eta: 0:01:12  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9710  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0018  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0527  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0197  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0367  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0391  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0174  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:24] Total time: 0:07:24 (1.0310 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:24]  [ 0/14]  eta: 0:03:50  loss: 0.0024 (0.0024)  time: 16.4720  data: 0.7991  max mem: 39452\n",
      "Valid: [epoch:24]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.6470  data: 0.0572  max mem: 39452\n",
      "Valid: [epoch:24] Total time: 0:03:39 (15.6638 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_24_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:25]  [  0/431]  eta: 0:19:50  lr: 0.000200  loss: 0.0025 (0.0025)  time: 2.7620  data: 1.6097  max mem: 39452\n",
      "Train: [epoch:25]  [ 10/431]  eta: 0:09:01  lr: 0.000200  loss: 0.0025 (0.0023)  time: 1.2860  data: 0.1465  max mem: 39452\n",
      "Train: [epoch:25]  [ 20/431]  eta: 0:07:40  lr: 0.000200  loss: 0.0023 (0.0024)  time: 1.0385  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:25]  [ 30/431]  eta: 0:07:37  lr: 0.000200  loss: 0.0022 (0.0024)  time: 1.0600  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:25]  [ 40/431]  eta: 0:07:13  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0938  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:25]  [ 50/431]  eta: 0:07:02  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0618  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [ 60/431]  eta: 0:06:45  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0605  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:25]  [ 70/431]  eta: 0:06:37  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0756  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [ 80/431]  eta: 0:06:16  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0170  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [ 90/431]  eta: 0:06:07  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.9996  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:25]  [100/431]  eta: 0:05:49  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9873  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:25]  [110/431]  eta: 0:05:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9959  data: 0.0004  max mem: 39452\n",
      "Train: [epoch:25]  [120/431]  eta: 0:05:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0543  data: 0.0004  max mem: 39452\n",
      "Train: [epoch:25]  [130/431]  eta: 0:05:20  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0705  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:25]  [140/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [150/431]  eta: 0:04:57  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0117  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [160/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9876  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [170/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.9828  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [180/431]  eta: 0:04:19  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9611  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [190/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9222  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [200/431]  eta: 0:03:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [210/431]  eta: 0:03:46  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [220/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9762  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [230/431]  eta: 0:03:25  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9734  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [240/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9626  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [250/431]  eta: 0:03:03  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9504  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [260/431]  eta: 0:02:53  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.9838  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [270/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9780  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [280/431]  eta: 0:02:32  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9754  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [290/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9099  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [300/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9669  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [310/431]  eta: 0:02:01  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0047  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [320/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.9924  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [330/431]  eta: 0:01:41  lr: 0.000200  loss: 0.0017 (0.0023)  time: 1.0404  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [340/431]  eta: 0:01:31  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0002  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [350/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9220  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [360/431]  eta: 0:01:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9552  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:25]  [370/431]  eta: 0:01:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9543  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [380/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9738  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [390/431]  eta: 0:00:40  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9712  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9892  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [410/431]  eta: 0:00:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9853  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9498  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9680  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:25] Total time: 0:07:09 (0.9972 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:25]  [ 0/14]  eta: 0:03:37  loss: 0.0026 (0.0026)  time: 15.5241  data: 0.7287  max mem: 39452\n",
      "Valid: [epoch:25]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.8074  data: 0.0522  max mem: 39452\n",
      "Valid: [epoch:25] Total time: 0:03:27 (14.8242 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_25_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:26]  [  0/431]  eta: 0:18:49  lr: 0.000200  loss: 0.0019 (0.0019)  time: 2.6196  data: 1.3744  max mem: 39452\n",
      "Train: [epoch:26]  [ 10/431]  eta: 0:07:17  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0380  data: 0.1250  max mem: 39452\n",
      "Train: [epoch:26]  [ 20/431]  eta: 0:06:51  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9208  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [ 30/431]  eta: 0:06:39  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9737  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [ 40/431]  eta: 0:06:29  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9924  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [ 50/431]  eta: 0:06:14  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9612  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [ 60/431]  eta: 0:06:05  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9630  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [ 70/431]  eta: 0:05:54  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9759  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [ 80/431]  eta: 0:05:41  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.9292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [ 90/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9785  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [100/431]  eta: 0:05:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9842  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [110/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9976  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [120/431]  eta: 0:05:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9417  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [130/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9574  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [140/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9640  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [150/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9636  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [160/431]  eta: 0:04:21  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9525  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [170/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9354  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [180/431]  eta: 0:04:03  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9915  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [190/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9560  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [200/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.9719  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [210/431]  eta: 0:03:34  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9722  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [220/431]  eta: 0:03:24  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9689  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [230/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9053  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [240/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9769  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [250/431]  eta: 0:02:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9564  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [260/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9835  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [270/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9698  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [280/431]  eta: 0:02:26  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9777  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [290/431]  eta: 0:02:16  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9851  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [300/431]  eta: 0:02:07  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9522  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [310/431]  eta: 0:01:57  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9848  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [320/431]  eta: 0:01:48  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0186  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [330/431]  eta: 0:01:38  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0238  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [340/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0099  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [350/431]  eta: 0:01:18  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9587  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [360/431]  eta: 0:01:09  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9485  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [370/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [380/431]  eta: 0:00:49  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9498  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [390/431]  eta: 0:00:39  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9897  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [400/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [410/431]  eta: 0:00:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0079  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0115  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9632  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:26] Total time: 0:06:59 (0.9731 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:26]  [ 0/14]  eta: 0:03:37  loss: 0.0013 (0.0013)  time: 15.5005  data: 0.6495  max mem: 39452\n",
      "Valid: [epoch:26]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.7550  data: 0.0465  max mem: 39452\n",
      "Valid: [epoch:26] Total time: 0:03:26 (14.7753 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_26_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:27]  [  0/431]  eta: 0:17:11  lr: 0.000200  loss: 0.0037 (0.0037)  time: 2.3922  data: 1.5781  max mem: 39452\n",
      "Train: [epoch:27]  [ 10/431]  eta: 0:08:50  lr: 0.000200  loss: 0.0019 (0.0024)  time: 1.2601  data: 0.1436  max mem: 39452\n",
      "Train: [epoch:27]  [ 20/431]  eta: 0:07:04  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.9638  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [ 30/431]  eta: 0:06:53  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9043  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [ 40/431]  eta: 0:06:31  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9695  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [ 50/431]  eta: 0:06:29  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0078  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:27]  [ 60/431]  eta: 0:06:11  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9987  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [ 70/431]  eta: 0:06:05  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9853  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [ 80/431]  eta: 0:05:47  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9547  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [ 90/431]  eta: 0:05:37  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9192  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [100/431]  eta: 0:05:26  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9789  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [110/431]  eta: 0:05:18  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9973  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [120/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9749  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [130/431]  eta: 0:04:57  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9727  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [140/431]  eta: 0:04:45  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9536  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [150/431]  eta: 0:04:36  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9532  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [160/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.9591  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [170/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8688  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [180/431]  eta: 0:04:05  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9612  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [190/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9345  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [200/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9592  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [210/431]  eta: 0:03:33  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9641  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [220/431]  eta: 0:03:25  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9720  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [230/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9501  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [240/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.9614  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [250/431]  eta: 0:02:54  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9642  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [260/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9669  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [270/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9844  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [280/431]  eta: 0:02:26  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9794  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [290/431]  eta: 0:02:16  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9764  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [300/431]  eta: 0:02:07  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9498  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [310/431]  eta: 0:01:57  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9726  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [320/431]  eta: 0:01:48  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9988  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [330/431]  eta: 0:01:37  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9374  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [340/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9127  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [350/431]  eta: 0:01:18  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9781  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [360/431]  eta: 0:01:08  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9921  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [370/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9790  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [380/431]  eta: 0:00:49  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [390/431]  eta: 0:00:39  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9723  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [400/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9976  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [410/431]  eta: 0:00:20  lr: 0.000200  loss: 0.0026 (0.0023)  time: 0.9790  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9928  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9826  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:27] Total time: 0:06:57 (0.9695 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:27]  [ 0/14]  eta: 0:03:34  loss: 0.0015 (0.0015)  time: 15.3256  data: 0.7430  max mem: 39452\n",
      "Valid: [epoch:27]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.6682  data: 0.0532  max mem: 39452\n",
      "Valid: [epoch:27] Total time: 0:03:25 (14.6867 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_27_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:28]  [  0/431]  eta: 0:17:33  lr: 0.000200  loss: 0.0017 (0.0017)  time: 2.4445  data: 1.6628  max mem: 39452\n",
      "Train: [epoch:28]  [ 10/431]  eta: 0:08:31  lr: 0.000200  loss: 0.0020 (0.0020)  time: 1.2138  data: 0.1513  max mem: 39452\n",
      "Train: [epoch:28]  [ 20/431]  eta: 0:07:14  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9873  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [ 30/431]  eta: 0:06:48  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9108  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [ 40/431]  eta: 0:06:38  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9778  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [ 50/431]  eta: 0:06:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9830  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [ 60/431]  eta: 0:06:11  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9699  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [ 70/431]  eta: 0:05:58  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9619  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [ 80/431]  eta: 0:05:50  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9826  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [ 90/431]  eta: 0:05:35  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9469  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [100/431]  eta: 0:05:27  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.9574  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [110/431]  eta: 0:05:13  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.9556  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [120/431]  eta: 0:05:07  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9823  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [130/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9935  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [140/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0061  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [150/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9549  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [160/431]  eta: 0:04:27  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9645  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [170/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9804  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [180/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9572  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [190/431]  eta: 0:03:55  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9599  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [200/431]  eta: 0:03:46  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9679  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [210/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9644  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [220/431]  eta: 0:03:26  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9396  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [230/431]  eta: 0:03:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9821  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:28]  [240/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8978  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [250/431]  eta: 0:02:56  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9582  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [260/431]  eta: 0:02:45  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [270/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9728  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [280/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [290/431]  eta: 0:02:17  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9539  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [300/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9531  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [310/431]  eta: 0:01:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9671  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [320/431]  eta: 0:01:47  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9793  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [330/431]  eta: 0:01:37  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9326  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [340/431]  eta: 0:01:27  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9735  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [350/431]  eta: 0:01:18  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9883  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [360/431]  eta: 0:01:08  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9777  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [370/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9862  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [380/431]  eta: 0:00:49  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9853  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [390/431]  eta: 0:00:39  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9361  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [400/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9715  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [410/431]  eta: 0:00:20  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0107  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9781  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9658  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:28] Total time: 0:06:58 (0.9721 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0017 (0.0022)\n",
      "Valid: [epoch:28]  [ 0/14]  eta: 0:03:42  loss: 0.0019 (0.0019)  time: 15.9230  data: 0.7143  max mem: 39452\n",
      "Valid: [epoch:28]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.7594  data: 0.0511  max mem: 39452\n",
      "Valid: [epoch:28] Total time: 0:03:26 (14.7768 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_28_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:29]  [  0/431]  eta: 0:17:10  lr: 0.000200  loss: 0.0021 (0.0021)  time: 2.3902  data: 1.5414  max mem: 39452\n",
      "Train: [epoch:29]  [ 10/431]  eta: 0:07:51  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.1194  data: 0.1403  max mem: 39452\n",
      "Train: [epoch:29]  [ 20/431]  eta: 0:07:10  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9801  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [ 30/431]  eta: 0:06:45  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9499  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [ 40/431]  eta: 0:06:36  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9784  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [ 50/431]  eta: 0:06:22  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9944  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [ 60/431]  eta: 0:06:12  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.9880  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [ 70/431]  eta: 0:05:58  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [ 80/431]  eta: 0:05:53  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0073  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [ 90/431]  eta: 0:05:39  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0064  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [100/431]  eta: 0:05:32  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9969  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [110/431]  eta: 0:05:17  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9454  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [120/431]  eta: 0:05:11  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9879  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [130/431]  eta: 0:04:58  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0142  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [140/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9928  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [150/431]  eta: 0:04:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9632  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [160/431]  eta: 0:04:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9649  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [170/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9864  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [180/431]  eta: 0:04:10  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0025  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [190/431]  eta: 0:03:57  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9688  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [200/431]  eta: 0:03:49  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9833  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [210/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9643  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [220/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9431  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [230/431]  eta: 0:03:17  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9912  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [240/431]  eta: 0:03:08  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9643  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [250/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9778  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [260/431]  eta: 0:02:47  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8794  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [270/431]  eta: 0:02:38  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9887  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [280/431]  eta: 0:02:27  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9808  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [290/431]  eta: 0:02:18  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9637  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [300/431]  eta: 0:02:07  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8943  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [310/431]  eta: 0:01:56  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [320/431]  eta: 0:01:46  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [330/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [340/431]  eta: 0:01:26  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [350/431]  eta: 0:01:16  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [360/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [370/431]  eta: 0:00:56  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [380/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7340  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [390/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [400/431]  eta: 0:00:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7321  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:29]  [420/431]  eta: 0:00:09  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:29] Total time: 0:06:28 (0.9012 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0023 (0.0022)\n",
      "Valid: [epoch:29]  [ 0/14]  eta: 0:03:26  loss: 0.0014 (0.0014)  time: 14.7484  data: 0.7601  max mem: 39452\n",
      "Valid: [epoch:29]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9720  data: 0.0544  max mem: 39452\n",
      "Valid: [epoch:29] Total time: 0:03:15 (13.9904 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_29_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:30]  [  0/431]  eta: 0:17:43  lr: 0.000200  loss: 0.0017 (0.0017)  time: 2.4665  data: 1.6490  max mem: 39452\n",
      "Train: [epoch:30]  [ 10/431]  eta: 0:06:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8899  data: 0.1500  max mem: 39452\n",
      "Train: [epoch:30]  [ 20/431]  eta: 0:05:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [ 30/431]  eta: 0:05:16  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7332  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [ 40/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0026 (0.0024)  time: 0.7344  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [ 50/431]  eta: 0:04:52  lr: 0.000200  loss: 0.0026 (0.0024)  time: 0.7370  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [ 60/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7359  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [ 70/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7325  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [ 90/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7329  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7322  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [120/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7371  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [130/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7399  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [140/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7389  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [150/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7407  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [160/431]  eta: 0:03:22  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7405  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [170/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7400  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [180/431]  eta: 0:03:07  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7435  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [190/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7450  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [200/431]  eta: 0:02:52  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7382  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [210/431]  eta: 0:02:44  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [220/431]  eta: 0:02:37  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7362  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [230/431]  eta: 0:02:29  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7361  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7328  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [250/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0026 (0.0023)  time: 0.7324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [270/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [280/431]  eta: 0:01:52  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7368  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [290/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7370  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [300/431]  eta: 0:01:37  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7345  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7332  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [320/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7336  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7361  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [340/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7357  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7334  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7336  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [370/431]  eta: 0:00:45  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7355  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7351  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7345  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:30]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7339  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:30]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7244  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:30] Total time: 0:05:18 (0.7397 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:30]  [ 0/14]  eta: 0:03:24  loss: 0.0025 (0.0025)  time: 14.6119  data: 0.5948  max mem: 39452\n",
      "Valid: [epoch:30]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9718  data: 0.0426  max mem: 39452\n",
      "Valid: [epoch:30] Total time: 0:03:15 (13.9904 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_30_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:31]  [  0/431]  eta: 0:20:04  lr: 0.000200  loss: 0.0019 (0.0019)  time: 2.7957  data: 1.9734  max mem: 39452\n",
      "Train: [epoch:31]  [ 10/431]  eta: 0:06:26  lr: 0.000200  loss: 0.0019 (0.0019)  time: 0.9181  data: 0.1795  max mem: 39452\n",
      "Train: [epoch:31]  [ 20/431]  eta: 0:05:41  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [ 30/431]  eta: 0:05:20  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7338  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [ 40/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7335  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [ 50/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7326  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [ 60/431]  eta: 0:04:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [ 70/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7317  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [ 90/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [100/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7335  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:31]  [110/431]  eta: 0:04:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7348  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [120/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7365  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [130/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7353  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [140/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [150/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [170/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7339  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [190/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [200/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [210/431]  eta: 0:02:44  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [220/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [290/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7251  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [340/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7320  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:31] Total time: 0:05:17 (0.7356 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:31]  [ 0/14]  eta: 0:03:27  loss: 0.0010 (0.0010)  time: 14.8153  data: 0.7627  max mem: 39452\n",
      "Valid: [epoch:31]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9909  data: 0.0546  max mem: 39452\n",
      "Valid: [epoch:31] Total time: 0:03:16 (14.0090 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_31_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:32]  [  0/431]  eta: 0:15:45  lr: 0.000200  loss: 0.0042 (0.0042)  time: 2.1948  data: 1.3955  max mem: 39452\n",
      "Train: [epoch:32]  [ 10/431]  eta: 0:06:03  lr: 0.000200  loss: 0.0017 (0.0020)  time: 0.8637  data: 0.1273  max mem: 39452\n",
      "Train: [epoch:32]  [ 20/431]  eta: 0:05:28  lr: 0.000200  loss: 0.0017 (0.0023)  time: 0.7286  data: 0.0003  max mem: 39452\n",
      "Train: [epoch:32]  [ 30/431]  eta: 0:05:11  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [ 40/431]  eta: 0:04:59  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7343  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [ 50/431]  eta: 0:04:49  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.7323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [ 60/431]  eta: 0:04:40  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [ 70/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [ 80/431]  eta: 0:04:22  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [ 90/431]  eta: 0:04:14  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [100/431]  eta: 0:04:06  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [110/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [120/431]  eta: 0:03:50  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0016 (0.0023)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [140/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [150/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [160/431]  eta: 0:03:19  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [170/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7245  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [180/431]  eta: 0:03:04  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [190/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [200/431]  eta: 0:02:49  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [210/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [230/431]  eta: 0:02:27  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [250/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [280/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7301  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:32]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7316  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [310/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0029 (0.0023)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0016 (0.0022)  time: 0.7350  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7351  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:32] Total time: 0:05:16 (0.7333 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0023)\n",
      "Valid: [epoch:32]  [ 0/14]  eta: 0:03:28  loss: 0.0014 (0.0014)  time: 14.8599  data: 0.7375  max mem: 39452\n",
      "Valid: [epoch:32]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.0417  data: 0.0528  max mem: 39452\n",
      "Valid: [epoch:32] Total time: 0:03:16 (14.0591 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_32_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:33]  [  0/431]  eta: 0:17:43  lr: 0.000200  loss: 0.0024 (0.0024)  time: 2.4668  data: 1.6733  max mem: 39452\n",
      "Train: [epoch:33]  [ 10/431]  eta: 0:06:19  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9026  data: 0.1522  max mem: 39452\n",
      "Train: [epoch:33]  [ 20/431]  eta: 0:05:37  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7400  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [ 30/431]  eta: 0:05:18  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7343  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [ 40/431]  eta: 0:05:04  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7341  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [ 50/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7338  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [ 60/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7341  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [ 70/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [ 90/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [120/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [130/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [140/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7337  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7345  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7337  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [200/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7332  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7348  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [220/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7371  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7424  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7422  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7416  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7422  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7409  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7401  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7417  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7412  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:33] Total time: 0:05:17 (0.7378 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:33]  [ 0/14]  eta: 0:03:26  loss: 0.0024 (0.0024)  time: 14.7412  data: 0.7539  max mem: 39452\n",
      "Valid: [epoch:33]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9593  data: 0.0539  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:33] Total time: 0:03:15 (13.9772 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_33_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:34]  [  0/431]  eta: 0:19:35  lr: 0.000200  loss: 0.0017 (0.0017)  time: 2.7266  data: 1.8852  max mem: 39452\n",
      "Train: [epoch:34]  [ 10/431]  eta: 0:06:25  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9169  data: 0.1715  max mem: 39452\n",
      "Train: [epoch:34]  [ 20/431]  eta: 0:05:41  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7351  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [ 30/431]  eta: 0:05:20  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7361  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [ 40/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0020 (0.0024)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [ 50/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7328  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [ 60/431]  eta: 0:04:44  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7326  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [ 70/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7264  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [ 90/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [120/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [130/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [140/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7264  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7325  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7264  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7230  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:34] Total time: 0:05:16 (0.7343 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:34]  [ 0/14]  eta: 0:03:28  loss: 0.0024 (0.0024)  time: 14.8769  data: 0.7742  max mem: 39452\n",
      "Valid: [epoch:34]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9598  data: 0.0554  max mem: 39452\n",
      "Valid: [epoch:34] Total time: 0:03:15 (13.9789 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_34_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:35]  [  0/431]  eta: 0:21:38  lr: 0.000200  loss: 0.0017 (0.0017)  time: 3.0117  data: 2.1372  max mem: 39452\n",
      "Train: [epoch:35]  [ 10/431]  eta: 0:06:34  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9374  data: 0.1944  max mem: 39452\n",
      "Train: [epoch:35]  [ 20/431]  eta: 0:05:44  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7307  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [ 30/431]  eta: 0:05:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [ 40/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7234  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [ 50/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [ 60/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [ 70/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [ 90/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [120/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [130/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7332  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [140/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7348  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:35]  [150/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7337  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7329  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [170/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [200/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [220/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7342  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7316  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7316  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [270/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7327  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7330  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [290/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7328  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7307  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [340/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7339  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7330  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:35] Total time: 0:05:17 (0.7364 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:35]  [ 0/14]  eta: 0:03:26  loss: 0.0013 (0.0013)  time: 14.7316  data: 0.7692  max mem: 39452\n",
      "Valid: [epoch:35]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9667  data: 0.0550  max mem: 39452\n",
      "Valid: [epoch:35] Total time: 0:03:15 (13.9861 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_35_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:36]  [  0/431]  eta: 0:19:42  lr: 0.000200  loss: 0.0016 (0.0016)  time: 2.7438  data: 1.9322  max mem: 39452\n",
      "Train: [epoch:36]  [ 10/431]  eta: 0:06:23  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9101  data: 0.1757  max mem: 39452\n",
      "Train: [epoch:36]  [ 20/431]  eta: 0:05:38  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [ 30/431]  eta: 0:05:17  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [ 40/431]  eta: 0:05:04  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7310  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [ 50/431]  eta: 0:04:52  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [ 60/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.7292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [ 70/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0024 (0.0024)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [ 80/431]  eta: 0:04:24  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [ 90/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0026 (0.0024)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0020 (0.0024)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [130/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [140/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0017 (0.0023)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7310  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7317  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:36]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7271  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.7343  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7337  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:36] Total time: 0:05:16 (0.7354 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:36]  [ 0/14]  eta: 0:03:27  loss: 0.0025 (0.0025)  time: 14.7900  data: 0.7498  max mem: 39452\n",
      "Valid: [epoch:36]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9967  data: 0.0537  max mem: 39452\n",
      "Valid: [epoch:36] Total time: 0:03:16 (14.0140 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_36_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:37]  [  0/431]  eta: 0:22:52  lr: 0.000200  loss: 0.0025 (0.0025)  time: 3.1836  data: 2.3976  max mem: 39452\n",
      "Train: [epoch:37]  [ 10/431]  eta: 0:06:41  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9548  data: 0.2181  max mem: 39452\n",
      "Train: [epoch:37]  [ 20/431]  eta: 0:05:48  lr: 0.000200  loss: 0.0017 (0.0021)  time: 0.7320  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [ 30/431]  eta: 0:05:25  lr: 0.000200  loss: 0.0017 (0.0021)  time: 0.7331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [ 40/431]  eta: 0:05:09  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.7337  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [ 50/431]  eta: 0:04:57  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7328  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [ 60/431]  eta: 0:04:46  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [ 70/431]  eta: 0:04:36  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [ 80/431]  eta: 0:04:27  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7343  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [ 90/431]  eta: 0:04:19  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7339  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [100/431]  eta: 0:04:10  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [110/431]  eta: 0:04:02  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [120/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [130/431]  eta: 0:03:46  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [140/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [150/431]  eta: 0:03:30  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7251  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [160/431]  eta: 0:03:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [170/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [190/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [200/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7339  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [210/431]  eta: 0:02:44  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [220/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0016 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [270/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [290/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [340/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:37] Total time: 0:05:17 (0.7359 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:37]  [ 0/14]  eta: 0:03:24  loss: 0.0025 (0.0025)  time: 14.6065  data: 0.7156  max mem: 39452\n",
      "Valid: [epoch:37]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9457  data: 0.0512  max mem: 39452\n",
      "Valid: [epoch:37] Total time: 0:03:15 (13.9648 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_37_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:38]  [  0/431]  eta: 0:16:03  lr: 0.000200  loss: 0.0022 (0.0022)  time: 2.2361  data: 1.4605  max mem: 39452\n",
      "Train: [epoch:38]  [ 10/431]  eta: 0:06:05  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.8687  data: 0.1329  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:38]  [ 20/431]  eta: 0:05:31  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7345  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:38]  [ 30/431]  eta: 0:05:12  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [ 40/431]  eta: 0:05:00  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [ 50/431]  eta: 0:04:49  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [ 60/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [ 70/431]  eta: 0:04:30  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7249  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [ 80/431]  eta: 0:04:22  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [ 90/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7251  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [100/431]  eta: 0:04:05  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [110/431]  eta: 0:03:57  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7261  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [120/431]  eta: 0:03:50  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [130/431]  eta: 0:03:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [140/431]  eta: 0:03:34  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7251  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [150/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [160/431]  eta: 0:03:19  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [170/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [180/431]  eta: 0:03:04  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7235  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [190/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7234  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [200/431]  eta: 0:02:49  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7233  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [210/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [220/431]  eta: 0:02:34  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [230/431]  eta: 0:02:27  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [250/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0017 (0.0023)  time: 0.7330  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [280/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7364  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7351  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7329  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [310/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7376  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7385  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7341  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7322  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7341  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7337  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7293  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:38]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:38] Total time: 0:05:16 (0.7335 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:38]  [ 0/14]  eta: 0:03:27  loss: 0.0024 (0.0024)  time: 14.8319  data: 0.7489  max mem: 39452\n",
      "Valid: [epoch:38]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.0261  data: 0.0536  max mem: 39452\n",
      "Valid: [epoch:38] Total time: 0:03:16 (14.0461 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_38_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:39]  [  0/431]  eta: 0:17:16  lr: 0.000200  loss: 0.0018 (0.0018)  time: 2.4040  data: 1.6357  max mem: 39452\n",
      "Train: [epoch:39]  [ 10/431]  eta: 0:06:16  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8947  data: 0.1595  max mem: 39452\n",
      "Train: [epoch:39]  [ 20/431]  eta: 0:05:35  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7361  data: 0.0060  max mem: 39452\n",
      "Train: [epoch:39]  [ 30/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [ 40/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7310  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [ 50/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [ 60/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [ 70/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [ 80/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [ 90/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [100/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [110/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7341  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [140/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7334  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7321  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:39]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7325  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7338  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [220/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7378  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7381  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7373  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7425  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7414  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [270/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7413  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7411  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [290/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7392  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7392  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7397  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [320/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7388  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7344  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [340/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7343  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7394  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7412  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [370/431]  eta: 0:00:45  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7409  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7405  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7408  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7397  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:39]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7413  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:39]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7440  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:39]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7351  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:39] Total time: 0:05:18 (0.7399 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:39]  [ 0/14]  eta: 0:03:24  loss: 0.0014 (0.0014)  time: 14.6268  data: 0.5543  max mem: 39452\n",
      "Valid: [epoch:39]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.1495  data: 0.0397  max mem: 39452\n",
      "Valid: [epoch:39] Total time: 0:03:18 (14.1696 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_39_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:40]  [  0/431]  eta: 0:20:02  lr: 0.000200  loss: 0.0018 (0.0018)  time: 2.7893  data: 1.9805  max mem: 39452\n",
      "Train: [epoch:40]  [ 10/431]  eta: 0:06:28  lr: 0.000200  loss: 0.0017 (0.0018)  time: 0.9226  data: 0.1801  max mem: 39452\n",
      "Train: [epoch:40]  [ 20/431]  eta: 0:05:40  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [ 30/431]  eta: 0:05:19  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [ 40/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7367  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [ 50/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.7352  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [ 60/431]  eta: 0:04:44  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.7344  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [ 70/431]  eta: 0:04:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [ 80/431]  eta: 0:04:26  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [ 90/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7328  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [100/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [110/431]  eta: 0:04:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [120/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7307  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:40]  [130/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [140/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [150/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [170/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [200/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [220/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7334  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [290/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [340/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7311  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:40]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7277  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:40]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:40] Total time: 0:05:17 (0.7355 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0023 (0.0023)\n",
      "Valid: [epoch:40]  [ 0/14]  eta: 0:03:26  loss: 0.0025 (0.0025)  time: 14.7305  data: 0.5584  max mem: 39452\n",
      "Valid: [epoch:40]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.1157  data: 0.0400  max mem: 39452\n",
      "Valid: [epoch:40] Total time: 0:03:17 (14.1349 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_40_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:41]  [  0/431]  eta: 0:16:47  lr: 0.000200  loss: 0.0019 (0.0019)  time: 2.3365  data: 1.5724  max mem: 39452\n",
      "Train: [epoch:41]  [ 10/431]  eta: 0:06:08  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.8765  data: 0.1430  max mem: 39452\n",
      "Train: [epoch:41]  [ 20/431]  eta: 0:05:30  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [ 30/431]  eta: 0:05:12  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [ 40/431]  eta: 0:05:00  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [ 50/431]  eta: 0:04:49  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7310  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [ 60/431]  eta: 0:04:40  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [ 70/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.7261  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [ 80/431]  eta: 0:04:22  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [ 90/431]  eta: 0:04:14  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [100/431]  eta: 0:04:06  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [110/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7334  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [140/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7330  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7345  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:41]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7336  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7342  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7344  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7334  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7342  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7341  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7328  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7232  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7339  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7321  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:41]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7327  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:41]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7332  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:41]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7320  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:41]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7264  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7240  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:41] Total time: 0:05:16 (0.7345 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:41]  [ 0/14]  eta: 0:03:25  loss: 0.0008 (0.0008)  time: 14.6677  data: 0.7727  max mem: 39452\n",
      "Valid: [epoch:41]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.1829  data: 0.0553  max mem: 39452\n",
      "Valid: [epoch:41] Total time: 0:03:18 (14.2027 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_41_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:42]  [  0/431]  eta: 0:17:54  lr: 0.000200  loss: 0.0015 (0.0015)  time: 2.4939  data: 1.7127  max mem: 39452\n",
      "Train: [epoch:42]  [ 10/431]  eta: 0:06:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8887  data: 0.1558  max mem: 39452\n",
      "Train: [epoch:42]  [ 20/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [ 30/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [ 40/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [ 50/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [ 60/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:42]  [ 70/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [ 80/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [ 90/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [100/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [110/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [140/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [170/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [190/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [210/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7317  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7276  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [280/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [310/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7317  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7251  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7276  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7304  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:42]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:42] Total time: 0:05:15 (0.7331 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:42]  [ 0/14]  eta: 0:03:24  loss: 0.0025 (0.0025)  time: 14.6279  data: 0.5585  max mem: 39452\n",
      "Valid: [epoch:42]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.0199  data: 0.0400  max mem: 39452\n",
      "Valid: [epoch:42] Total time: 0:03:16 (14.0368 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_42_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:43]  [  0/431]  eta: 0:21:15  lr: 0.000200  loss: 0.0015 (0.0015)  time: 2.9595  data: 2.1564  max mem: 39452\n",
      "Train: [epoch:43]  [ 10/431]  eta: 0:06:31  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9301  data: 0.1961  max mem: 39452\n",
      "Train: [epoch:43]  [ 20/431]  eta: 0:05:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [ 30/431]  eta: 0:05:20  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [ 40/431]  eta: 0:05:04  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7228  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [ 50/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7245  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [ 60/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7255  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [ 70/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [ 80/431]  eta: 0:04:24  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [ 90/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [100/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [110/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.7254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7240  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7239  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [140/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [150/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7249  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [170/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [190/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [210/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [230/431]  eta: 0:02:27  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7231  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7239  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:43]  [250/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7238  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [280/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [300/431]  eta: 0:01:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [310/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7228  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [330/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [360/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7237  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7240  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [390/431]  eta: 0:00:29  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7231  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7239  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:43] Total time: 0:05:15 (0.7309 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0024 (0.0022)\n",
      "Valid: [epoch:43]  [ 0/14]  eta: 0:03:27  loss: 0.0024 (0.0024)  time: 14.8532  data: 0.7599  max mem: 39452\n",
      "Valid: [epoch:43]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.0763  data: 0.0544  max mem: 39452\n",
      "Valid: [epoch:43] Total time: 0:03:17 (14.0959 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_43_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:44]  [  0/431]  eta: 0:17:47  lr: 0.000200  loss: 0.0016 (0.0016)  time: 2.4763  data: 1.6490  max mem: 39452\n",
      "Train: [epoch:44]  [ 10/431]  eta: 0:06:12  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8859  data: 0.1500  max mem: 39452\n",
      "Train: [epoch:44]  [ 20/431]  eta: 0:05:33  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [ 30/431]  eta: 0:05:14  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [ 40/431]  eta: 0:05:01  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [ 50/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [ 60/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [ 70/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [ 80/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [ 90/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [100/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [110/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7240  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [140/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7230  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [150/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [170/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7249  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [190/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7238  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [210/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7261  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [230/431]  eta: 0:02:27  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [250/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7276  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [280/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7240  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7239  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [300/431]  eta: 0:01:35  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [310/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7221  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [330/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7225  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7231  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7234  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [360/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7233  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [390/431]  eta: 0:00:29  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:44]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:44] Total time: 0:05:15 (0.7310 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0023 (0.0022)\n",
      "Valid: [epoch:44]  [ 0/14]  eta: 0:03:28  loss: 0.0019 (0.0019)  time: 14.8637  data: 0.5681  max mem: 39452\n",
      "Valid: [epoch:44]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.0921  data: 0.0407  max mem: 39452\n",
      "Valid: [epoch:44] Total time: 0:03:17 (14.1124 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_44_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:45]  [  0/431]  eta: 0:20:23  lr: 0.000200  loss: 0.0042 (0.0042)  time: 2.8377  data: 1.8839  max mem: 39452\n",
      "Train: [epoch:45]  [ 10/431]  eta: 0:06:24  lr: 0.000200  loss: 0.0026 (0.0025)  time: 0.9135  data: 0.1713  max mem: 39452\n",
      "Train: [epoch:45]  [ 20/431]  eta: 0:05:38  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7233  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [ 30/431]  eta: 0:05:18  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [ 40/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [ 50/431]  eta: 0:04:52  lr: 0.000200  loss: 0.0023 (0.0024)  time: 0.7241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [ 60/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7255  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [ 70/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [ 80/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7234  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [ 90/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [100/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [110/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [140/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7264  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7330  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7341  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7354  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7360  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7362  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7326  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7326  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:45] Total time: 0:05:17 (0.7355 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:45]  [ 0/14]  eta: 0:03:30  loss: 0.0025 (0.0025)  time: 15.0008  data: 0.5842  max mem: 39452\n",
      "Valid: [epoch:45]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.0928  data: 0.0419  max mem: 39452\n",
      "Valid: [epoch:45] Total time: 0:03:17 (14.1106 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_45_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:46]  [  0/431]  eta: 0:18:53  lr: 0.000200  loss: 0.0019 (0.0019)  time: 2.6311  data: 1.8488  max mem: 39452\n",
      "Train: [epoch:46]  [ 10/431]  eta: 0:06:21  lr: 0.000200  loss: 0.0019 (0.0020)  time: 0.9059  data: 0.1682  max mem: 39452\n",
      "Train: [epoch:46]  [ 20/431]  eta: 0:05:39  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7366  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [ 30/431]  eta: 0:05:19  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7366  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [ 40/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [ 50/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [ 60/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.7326  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [ 70/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7343  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7344  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [ 90/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7316  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7321  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:46]  [120/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7322  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [130/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.7324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [140/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [150/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7328  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7338  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7317  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7326  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7316  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7332  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7342  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7343  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7353  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7342  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:46] Total time: 0:05:17 (0.7360 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:46]  [ 0/14]  eta: 0:03:27  loss: 0.0024 (0.0024)  time: 14.8419  data: 0.7736  max mem: 39452\n",
      "Valid: [epoch:46]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9273  data: 0.0554  max mem: 39452\n",
      "Valid: [epoch:46] Total time: 0:03:15 (13.9460 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_46_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:47]  [  0/431]  eta: 0:19:21  lr: 0.000200  loss: 0.0023 (0.0023)  time: 2.6937  data: 1.7906  max mem: 39452\n",
      "Train: [epoch:47]  [ 10/431]  eta: 0:06:24  lr: 0.000200  loss: 0.0023 (0.0025)  time: 0.9133  data: 0.1629  max mem: 39452\n",
      "Train: [epoch:47]  [ 20/431]  eta: 0:05:39  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.7331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [ 30/431]  eta: 0:05:18  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [ 40/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [ 50/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [ 60/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7310  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [ 70/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [ 90/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7340  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7338  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [120/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [130/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7341  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [140/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7336  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [150/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [200/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [220/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.7291  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:47]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:47] Total time: 0:05:16 (0.7345 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:47]  [ 0/14]  eta: 0:03:26  loss: 0.0024 (0.0024)  time: 14.7456  data: 0.7326  max mem: 39452\n",
      "Valid: [epoch:47]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9590  data: 0.0524  max mem: 39452\n",
      "Valid: [epoch:47] Total time: 0:03:15 (13.9746 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_47_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:48]  [  0/431]  eta: 0:21:17  lr: 0.000200  loss: 0.0020 (0.0020)  time: 2.9633  data: 2.1427  max mem: 39452\n",
      "Train: [epoch:48]  [ 10/431]  eta: 0:06:33  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9336  data: 0.1949  max mem: 39452\n",
      "Train: [epoch:48]  [ 20/431]  eta: 0:05:43  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [ 30/431]  eta: 0:05:20  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7271  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [ 40/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [ 50/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [ 60/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [ 70/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [ 90/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7329  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [120/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [130/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [140/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [200/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7240  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:48] Total time: 0:05:16 (0.7345 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:48]  [ 0/14]  eta: 0:03:27  loss: 0.0015 (0.0015)  time: 14.8017  data: 0.7454  max mem: 39452\n",
      "Valid: [epoch:48]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9306  data: 0.0534  max mem: 39452\n",
      "Valid: [epoch:48] Total time: 0:03:15 (13.9493 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_48_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:49]  [  0/431]  eta: 0:18:49  lr: 0.000200  loss: 0.0019 (0.0019)  time: 2.6216  data: 1.8107  max mem: 39452\n",
      "Train: [epoch:49]  [ 10/431]  eta: 0:06:21  lr: 0.000200  loss: 0.0019 (0.0020)  time: 0.9060  data: 0.1647  max mem: 39452\n",
      "Train: [epoch:49]  [ 20/431]  eta: 0:05:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [ 30/431]  eta: 0:05:17  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [ 40/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [ 50/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [ 60/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [ 70/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [ 80/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [ 90/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [100/431]  eta: 0:04:06  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [110/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [140/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7236  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [150/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7245  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [170/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [190/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [210/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7271  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [230/431]  eta: 0:02:27  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [250/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [280/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7271  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [310/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7245  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:49] Total time: 0:05:15 (0.7321 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:49]  [ 0/14]  eta: 0:03:28  loss: 0.0025 (0.0025)  time: 14.8924  data: 0.7668  max mem: 39452\n",
      "Valid: [epoch:49]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.0409  data: 0.0549  max mem: 39452\n",
      "Valid: [epoch:49] Total time: 0:03:16 (14.0576 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_49_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:50]  [  0/431]  eta: 0:20:38  lr: 0.000200  loss: 0.0020 (0.0020)  time: 2.8726  data: 2.0581  max mem: 39452\n",
      "Train: [epoch:50]  [ 10/431]  eta: 0:06:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9232  data: 0.1872  max mem: 39452\n",
      "Train: [epoch:50]  [ 20/431]  eta: 0:05:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [ 30/431]  eta: 0:05:19  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [ 40/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [ 50/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [ 60/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7264  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [ 70/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0016 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [ 80/431]  eta: 0:04:24  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [ 90/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [100/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [110/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [130/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [140/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7282  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:50]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7239  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7261  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [310/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7267  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7245  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7229  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:50] Total time: 0:05:16 (0.7332 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:50]  [ 0/14]  eta: 0:03:26  loss: 0.0026 (0.0026)  time: 14.7266  data: 0.7653  max mem: 39452\n",
      "Valid: [epoch:50]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9302  data: 0.0548  max mem: 39452\n",
      "Valid: [epoch:50] Total time: 0:03:15 (13.9486 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_50_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:51]  [  0/431]  eta: 0:20:53  lr: 0.000200  loss: 0.0014 (0.0014)  time: 2.9091  data: 2.0980  max mem: 39452\n",
      "Train: [epoch:51]  [ 10/431]  eta: 0:06:29  lr: 0.000200  loss: 0.0019 (0.0020)  time: 0.9258  data: 0.1908  max mem: 39452\n",
      "Train: [epoch:51]  [ 20/431]  eta: 0:05:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [ 30/431]  eta: 0:05:20  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [ 40/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [ 50/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0020 (0.0024)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [ 60/431]  eta: 0:04:44  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [ 70/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [ 90/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [120/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [130/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7307  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [140/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [150/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [200/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7317  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7307  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [220/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7316  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7335  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7245  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [340/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7307  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:51]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:51] Total time: 0:05:16 (0.7355 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0022 (0.0022)\n",
      "Valid: [epoch:51]  [ 0/14]  eta: 0:03:25  loss: 0.0008 (0.0008)  time: 14.6522  data: 0.5851  max mem: 39452\n",
      "Valid: [epoch:51]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9419  data: 0.0419  max mem: 39452\n",
      "Valid: [epoch:51] Total time: 0:03:15 (13.9602 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_51_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:52]  [  0/431]  eta: 0:17:53  lr: 0.000200  loss: 0.0011 (0.0011)  time: 2.4901  data: 1.6834  max mem: 39452\n",
      "Train: [epoch:52]  [ 10/431]  eta: 0:06:15  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.8923  data: 0.1531  max mem: 39452\n",
      "Train: [epoch:52]  [ 20/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [ 30/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [ 40/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [ 50/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [ 60/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [ 70/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [ 80/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [ 90/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [100/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [110/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [140/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7281  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7316  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7306  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7327  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7334  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7356  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7335  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7287  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:52] Total time: 0:05:16 (0.7349 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0024 (0.0022)\n",
      "Valid: [epoch:52]  [ 0/14]  eta: 0:03:27  loss: 0.0010 (0.0010)  time: 14.8190  data: 0.7411  max mem: 39452\n",
      "Valid: [epoch:52]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9913  data: 0.0530  max mem: 39452\n",
      "Valid: [epoch:52] Total time: 0:03:16 (14.0094 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_52_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:53]  [  0/431]  eta: 0:23:10  lr: 0.000200  loss: 0.0036 (0.0036)  time: 3.2263  data: 2.4302  max mem: 39452\n",
      "Train: [epoch:53]  [ 10/431]  eta: 0:06:39  lr: 0.000200  loss: 0.0023 (0.0026)  time: 0.9488  data: 0.2210  max mem: 39452\n",
      "Train: [epoch:53]  [ 20/431]  eta: 0:05:46  lr: 0.000200  loss: 0.0022 (0.0025)  time: 0.7230  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [ 30/431]  eta: 0:05:22  lr: 0.000200  loss: 0.0024 (0.0026)  time: 0.7248  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:53]  [ 40/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0024 (0.0025)  time: 0.7243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [ 50/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0024 (0.0025)  time: 0.7238  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [ 60/431]  eta: 0:04:44  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [ 70/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0019 (0.0024)  time: 0.7319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [ 80/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.7321  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [ 90/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [110/431]  eta: 0:04:00  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [120/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7355  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [130/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.7378  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [140/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7310  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [150/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [170/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [180/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7345  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [190/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7337  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [200/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [210/431]  eta: 0:02:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [220/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7330  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [230/431]  eta: 0:02:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7327  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [240/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [250/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7334  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [270/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.7331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [290/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [320/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [340/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7269  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7327  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7345  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7345  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7291  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:53] Total time: 0:05:17 (0.7373 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:53]  [ 0/14]  eta: 0:03:25  loss: 0.0008 (0.0008)  time: 14.6842  data: 0.7438  max mem: 39452\n",
      "Valid: [epoch:53]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9991  data: 0.0532  max mem: 39452\n",
      "Valid: [epoch:53] Total time: 0:03:16 (14.0163 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_53_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:54]  [  0/431]  eta: 0:18:43  lr: 0.000200  loss: 0.0018 (0.0018)  time: 2.6074  data: 1.7854  max mem: 39452\n",
      "Train: [epoch:54]  [ 10/431]  eta: 0:06:19  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.9010  data: 0.1624  max mem: 39452\n",
      "Train: [epoch:54]  [ 20/431]  eta: 0:05:36  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [ 30/431]  eta: 0:05:17  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7333  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [ 40/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [ 50/431]  eta: 0:04:52  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [ 60/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [ 70/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [ 80/431]  eta: 0:04:24  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7317  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [ 90/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7322  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [100/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [110/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [120/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7294  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [130/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7284  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [140/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [160/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [170/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7336  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [190/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7285  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [210/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:54]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [230/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7320  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7327  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [250/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [260/431]  eta: 0:02:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [280/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [310/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7316  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [330/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7238  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7232  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [360/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [390/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7268  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:54] Total time: 0:05:16 (0.7343 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:54]  [ 0/14]  eta: 0:03:28  loss: 0.0015 (0.0015)  time: 14.9165  data: 0.7401  max mem: 39452\n",
      "Valid: [epoch:54]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9525  data: 0.0530  max mem: 39452\n",
      "Valid: [epoch:54] Total time: 0:03:15 (13.9702 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_54_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:55]  [  0/431]  eta: 0:20:15  lr: 0.000200  loss: 0.0018 (0.0018)  time: 2.8191  data: 1.9956  max mem: 39452\n",
      "Train: [epoch:55]  [ 10/431]  eta: 0:06:25  lr: 0.000200  loss: 0.0019 (0.0020)  time: 0.9159  data: 0.1815  max mem: 39452\n",
      "Train: [epoch:55]  [ 20/431]  eta: 0:05:38  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7249  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [ 30/431]  eta: 0:05:17  lr: 0.000200  loss: 0.0024 (0.0024)  time: 0.7236  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [ 40/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.7241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [ 50/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [ 60/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [ 70/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [ 80/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [ 90/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [100/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.7260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [110/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7235  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [120/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [130/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [140/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0017 (0.0021)  time: 0.7257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [150/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.7296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [160/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [170/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [180/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [190/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [200/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [210/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [220/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7283  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [230/431]  eta: 0:02:27  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [240/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [250/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7239  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [270/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7266  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [280/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7231  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [300/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7245  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [310/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [330/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7263  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [360/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7249  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [390/431]  eta: 0:00:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7238  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:55]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7244  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:55] Total time: 0:05:15 (0.7312 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:55]  [ 0/14]  eta: 0:03:23  loss: 0.0025 (0.0025)  time: 14.5669  data: 0.6064  max mem: 39452\n",
      "Valid: [epoch:55]  [13/14]  eta: 0:00:13  loss: 0.0015 (0.0018)  time: 13.9054  data: 0.0434  max mem: 39452\n",
      "Valid: [epoch:55] Total time: 0:03:14 (13.9239 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_55_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:56]  [  0/431]  eta: 0:19:40  lr: 0.000200  loss: 0.0015 (0.0015)  time: 2.7384  data: 1.9433  max mem: 39452\n",
      "Train: [epoch:56]  [ 10/431]  eta: 0:06:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9078  data: 0.1768  max mem: 39452\n",
      "Train: [epoch:56]  [ 20/431]  eta: 0:05:37  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [ 30/431]  eta: 0:05:16  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [ 40/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [ 50/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [ 60/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [ 70/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7226  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [ 80/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7228  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [ 90/431]  eta: 0:04:14  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7237  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [100/431]  eta: 0:04:06  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [110/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [120/431]  eta: 0:03:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [130/431]  eta: 0:03:42  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [140/431]  eta: 0:03:34  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7213  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [150/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7234  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [160/431]  eta: 0:03:19  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.7242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [170/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [180/431]  eta: 0:03:04  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.7256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [190/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [200/431]  eta: 0:02:49  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7252  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [210/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [220/431]  eta: 0:02:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [230/431]  eta: 0:02:27  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [240/431]  eta: 0:02:19  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7238  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [250/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [260/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [270/431]  eta: 0:01:57  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [280/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7235  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [290/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7248  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [300/431]  eta: 0:01:35  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7239  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [310/431]  eta: 0:01:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [320/431]  eta: 0:01:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7241  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [330/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7231  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [340/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7235  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [350/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [360/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7265  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [370/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7251  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [380/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7227  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [390/431]  eta: 0:00:29  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7237  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [400/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7243  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [410/431]  eta: 0:00:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7249  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [420/431]  eta: 0:00:08  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.7247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.7232  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:56] Total time: 0:05:14 (0.7297 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0026 (0.0022)\n",
      "Valid: [epoch:56]  [ 0/14]  eta: 0:03:27  loss: 0.0026 (0.0026)  time: 14.7941  data: 0.7711  max mem: 39452\n",
      "Valid: [epoch:56]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.4873  data: 0.0552  max mem: 39452\n",
      "Valid: [epoch:56] Total time: 0:03:23 (14.5044 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_56_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:57]  [  0/431]  eta: 0:18:57  lr: 0.000200  loss: 0.0027 (0.0027)  time: 2.6394  data: 1.6850  max mem: 39452\n",
      "Train: [epoch:57]  [ 10/431]  eta: 0:07:00  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.9994  data: 0.1533  max mem: 39452\n",
      "Train: [epoch:57]  [ 20/431]  eta: 0:06:42  lr: 0.000200  loss: 0.0020 (0.0024)  time: 0.8970  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:57]  [ 30/431]  eta: 0:06:09  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8795  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:57]  [ 40/431]  eta: 0:05:49  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.8036  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:57]  [ 50/431]  eta: 0:05:38  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8370  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:57]  [ 60/431]  eta: 0:05:23  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8304  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:57]  [ 70/431]  eta: 0:05:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7955  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [ 80/431]  eta: 0:05:00  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8096  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:57]  [ 90/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7905  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [100/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7928  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:57]  [110/431]  eta: 0:04:28  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7929  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [120/431]  eta: 0:04:20  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8050  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [130/431]  eta: 0:04:12  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8508  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [140/431]  eta: 0:04:03  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8385  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [150/431]  eta: 0:03:55  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8329  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [160/431]  eta: 0:03:46  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8315  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [170/431]  eta: 0:03:38  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8150  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [180/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8149  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [190/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8391  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [200/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8599  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [210/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8571  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [220/431]  eta: 0:02:56  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8418  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [230/431]  eta: 0:02:48  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8649  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [240/431]  eta: 0:02:40  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8680  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [250/431]  eta: 0:02:31  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8050  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [260/431]  eta: 0:02:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7750  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [270/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7986  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [280/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.7770  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [290/431]  eta: 0:01:57  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.7944  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [300/431]  eta: 0:01:48  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8386  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [310/431]  eta: 0:01:40  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8235  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [320/431]  eta: 0:01:32  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8670  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [330/431]  eta: 0:01:24  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8546  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [340/431]  eta: 0:01:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8383  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [350/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8709  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [360/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8442  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [370/431]  eta: 0:00:50  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [380/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8353  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [390/431]  eta: 0:00:34  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.8768  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:57]  [400/431]  eta: 0:00:25  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [410/431]  eta: 0:00:17  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8235  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [420/431]  eta: 0:00:09  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8986  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8605  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:57] Total time: 0:06:01 (0.8381 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:57]  [ 0/14]  eta: 0:03:45  loss: 0.0014 (0.0014)  time: 16.0977  data: 0.6191  max mem: 39452\n",
      "Valid: [epoch:57]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.5445  data: 0.0444  max mem: 39452\n",
      "Valid: [epoch:57] Total time: 0:03:37 (15.5600 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_57_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:58]  [  0/431]  eta: 0:17:49  lr: 0.000200  loss: 0.0021 (0.0021)  time: 2.4819  data: 1.2186  max mem: 39452\n",
      "Train: [epoch:58]  [ 10/431]  eta: 0:06:19  lr: 0.000200  loss: 0.0023 (0.0025)  time: 0.9017  data: 0.1109  max mem: 39452\n",
      "Train: [epoch:58]  [ 20/431]  eta: 0:06:19  lr: 0.000200  loss: 0.0023 (0.0025)  time: 0.8442  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [ 30/431]  eta: 0:06:00  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.8971  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [ 40/431]  eta: 0:05:51  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.8741  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [ 50/431]  eta: 0:05:43  lr: 0.000200  loss: 0.0023 (0.0024)  time: 0.9077  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [ 60/431]  eta: 0:05:26  lr: 0.000200  loss: 0.0020 (0.0024)  time: 0.8415  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [ 70/431]  eta: 0:05:14  lr: 0.000200  loss: 0.0019 (0.0024)  time: 0.7896  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:58]  [ 80/431]  eta: 0:05:01  lr: 0.000200  loss: 0.0023 (0.0024)  time: 0.7946  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:58]  [ 90/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0023 (0.0024)  time: 0.7996  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [100/431]  eta: 0:04:45  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8717  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [110/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8233  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [120/431]  eta: 0:04:27  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.8580  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [130/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8675  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [140/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [150/431]  eta: 0:04:03  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9555  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [160/431]  eta: 0:03:55  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9685  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:58]  [170/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8667  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:58]  [180/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8414  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [190/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [200/431]  eta: 0:03:19  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8335  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [210/431]  eta: 0:03:11  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8950  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [220/431]  eta: 0:03:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8481  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [230/431]  eta: 0:02:54  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8802  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [240/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9761  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:58]  [250/431]  eta: 0:02:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9461  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [260/431]  eta: 0:02:30  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9532  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:58]  [270/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9668  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:58]  [280/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9249  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [290/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [300/431]  eta: 0:01:55  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9091  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [310/431]  eta: 0:01:47  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9109  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [320/431]  eta: 0:01:38  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8930  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [330/431]  eta: 0:01:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8764  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [340/431]  eta: 0:01:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9121  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [350/431]  eta: 0:01:11  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8473  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [360/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [370/431]  eta: 0:00:53  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [380/431]  eta: 0:00:44  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.7905  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:58]  [390/431]  eta: 0:00:36  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8845  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:58]  [400/431]  eta: 0:00:27  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9045  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [410/431]  eta: 0:00:18  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8332  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58]  [420/431]  eta: 0:00:09  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8982  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:58]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8715  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:58] Total time: 0:06:18 (0.8779 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:58]  [ 0/14]  eta: 0:03:51  loss: 0.0024 (0.0024)  time: 16.5173  data: 0.8013  max mem: 39452\n",
      "Valid: [epoch:58]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.6613  data: 0.0574  max mem: 39452\n",
      "Valid: [epoch:58] Total time: 0:03:39 (15.6791 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_58_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:59]  [  0/431]  eta: 0:22:04  lr: 0.000200  loss: 0.0015 (0.0015)  time: 3.0731  data: 2.2092  max mem: 39452\n",
      "Train: [epoch:59]  [ 10/431]  eta: 0:07:34  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.0806  data: 0.2010  max mem: 39452\n",
      "Train: [epoch:59]  [ 20/431]  eta: 0:06:52  lr: 0.000200  loss: 0.0018 (0.0020)  time: 0.8997  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [ 30/431]  eta: 0:06:20  lr: 0.000200  loss: 0.0018 (0.0020)  time: 0.8749  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [ 40/431]  eta: 0:06:06  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.8680  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [ 50/431]  eta: 0:05:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8742  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [ 60/431]  eta: 0:05:36  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.8428  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [ 70/431]  eta: 0:05:33  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9329  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [ 80/431]  eta: 0:05:18  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9153  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [ 90/431]  eta: 0:05:10  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.8729  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [100/431]  eta: 0:05:01  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9255  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [110/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.9250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [120/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9073  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [130/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8375  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [140/431]  eta: 0:04:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8559  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [150/431]  eta: 0:04:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8803  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:59]  [160/431]  eta: 0:04:05  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9125  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:59]  [170/431]  eta: 0:03:56  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9435  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [180/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9491  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [190/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8864  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:59]  [200/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8903  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [210/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9483  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:59]  [220/431]  eta: 0:03:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8727  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:59]  [230/431]  eta: 0:03:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8839  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [240/431]  eta: 0:02:53  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9468  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [250/431]  eta: 0:02:45  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9886  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [260/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.9718  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [270/431]  eta: 0:02:26  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.9017  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [280/431]  eta: 0:02:17  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8962  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [290/431]  eta: 0:02:07  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8575  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [300/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [310/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9478  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [320/431]  eta: 0:01:40  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9125  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [330/431]  eta: 0:01:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8982  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [340/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9342  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [350/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8910  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [360/431]  eta: 0:01:04  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [370/431]  eta: 0:00:55  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9082  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [380/431]  eta: 0:00:46  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9181  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [390/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9513  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [400/431]  eta: 0:00:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9084  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8888  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9185  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:59] Total time: 0:06:32 (0.9108 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:59]  [ 0/14]  eta: 0:03:47  loss: 0.0014 (0.0014)  time: 16.2754  data: 0.7898  max mem: 39452\n",
      "Valid: [epoch:59]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.4608  data: 0.0565  max mem: 39452\n",
      "Valid: [epoch:59] Total time: 0:03:36 (15.4798 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_59_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:60]  [  0/431]  eta: 0:17:08  lr: 0.000200  loss: 0.0025 (0.0025)  time: 2.3852  data: 1.4764  max mem: 39452\n",
      "Train: [epoch:60]  [ 10/431]  eta: 0:07:27  lr: 0.000200  loss: 0.0017 (0.0019)  time: 1.0641  data: 0.1343  max mem: 39452\n",
      "Train: [epoch:60]  [ 20/431]  eta: 0:06:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8875  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:60]  [ 30/431]  eta: 0:06:11  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8499  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:60]  [ 40/431]  eta: 0:06:06  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9130  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [ 50/431]  eta: 0:06:03  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9966  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [ 60/431]  eta: 0:05:50  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9646  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [ 70/431]  eta: 0:05:44  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9595  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [ 80/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9794  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [ 90/431]  eta: 0:05:27  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9804  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [100/431]  eta: 0:05:20  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0184  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [110/431]  eta: 0:05:08  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9705  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [120/431]  eta: 0:04:58  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [130/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [140/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9705  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [150/431]  eta: 0:04:30  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9932  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [160/431]  eta: 0:04:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9438  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [170/431]  eta: 0:04:10  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9293  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [180/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8829  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [190/431]  eta: 0:03:49  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8930  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [200/431]  eta: 0:03:38  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8840  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [210/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8053  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [220/431]  eta: 0:03:17  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.8568  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [230/431]  eta: 0:03:07  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.8966  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [240/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [250/431]  eta: 0:02:48  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9234  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [260/431]  eta: 0:02:39  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8743  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [270/431]  eta: 0:02:29  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8953  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:60]  [280/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9004  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:60]  [290/431]  eta: 0:02:11  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9310  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [300/431]  eta: 0:02:01  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9449  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [310/431]  eta: 0:01:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8936  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [320/431]  eta: 0:01:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8841  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:60]  [330/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8790  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [340/431]  eta: 0:01:24  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9527  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [350/431]  eta: 0:01:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9990  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [360/431]  eta: 0:01:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8951  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [370/431]  eta: 0:00:56  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8857  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [380/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8998  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [390/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8275  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [400/431]  eta: 0:00:28  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8280  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8945  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:60]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9628  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9616  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:60] Total time: 0:06:37 (0.9231 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:60]  [ 0/14]  eta: 0:03:47  loss: 0.0026 (0.0026)  time: 16.2460  data: 0.7806  max mem: 39452\n",
      "Valid: [epoch:60]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.3387  data: 0.0559  max mem: 39452\n",
      "Valid: [epoch:60] Total time: 0:03:34 (15.3563 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_60_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:61]  [  0/431]  eta: 0:16:31  lr: 0.000200  loss: 0.0022 (0.0022)  time: 2.2995  data: 1.5284  max mem: 39452\n",
      "Train: [epoch:61]  [ 10/431]  eta: 0:07:24  lr: 0.000200  loss: 0.0026 (0.0026)  time: 1.0557  data: 0.1391  max mem: 39452\n",
      "Train: [epoch:61]  [ 20/431]  eta: 0:07:01  lr: 0.000200  loss: 0.0026 (0.0025)  time: 0.9607  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [ 30/431]  eta: 0:06:39  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9638  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [ 40/431]  eta: 0:06:22  lr: 0.000200  loss: 0.0017 (0.0023)  time: 0.9324  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [ 50/431]  eta: 0:06:07  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9168  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [ 60/431]  eta: 0:05:55  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9140  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [ 70/431]  eta: 0:05:39  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8770  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [ 80/431]  eta: 0:05:32  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9124  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [ 90/431]  eta: 0:05:20  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9343  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [100/431]  eta: 0:05:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8989  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [110/431]  eta: 0:05:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9394  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [120/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9768  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [130/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9221  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:61]  [140/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8611  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [150/431]  eta: 0:04:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8872  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [160/431]  eta: 0:04:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8999  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [170/431]  eta: 0:04:02  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9377  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [180/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9644  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [190/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9697  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [200/431]  eta: 0:03:36  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9660  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [210/431]  eta: 0:03:26  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9394  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [220/431]  eta: 0:03:17  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9655  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [230/431]  eta: 0:03:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9277  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [240/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9104  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [250/431]  eta: 0:02:49  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [260/431]  eta: 0:02:39  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9097  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [270/431]  eta: 0:02:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0028  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [280/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9743  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [290/431]  eta: 0:02:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8187  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [300/431]  eta: 0:02:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8506  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [310/431]  eta: 0:01:52  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9654  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [320/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9904  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [330/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9437  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [340/431]  eta: 0:01:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9419  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [350/431]  eta: 0:01:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9842  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [360/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9901  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [370/431]  eta: 0:00:57  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9440  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [380/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9036  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [390/431]  eta: 0:00:38  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [400/431]  eta: 0:00:28  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9002  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8429  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8391  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8805  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:61] Total time: 0:06:41 (0.9307 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:61]  [ 0/14]  eta: 0:03:47  loss: 0.0026 (0.0026)  time: 16.2203  data: 0.8156  max mem: 39452\n",
      "Valid: [epoch:61]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.2633  data: 0.0584  max mem: 39452\n",
      "Valid: [epoch:61] Total time: 0:03:33 (15.2801 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_61_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:62]  [  0/431]  eta: 0:24:50  lr: 0.000200  loss: 0.0022 (0.0022)  time: 3.4573  data: 2.2340  max mem: 39452\n",
      "Train: [epoch:62]  [ 10/431]  eta: 0:08:09  lr: 0.000200  loss: 0.0028 (0.0026)  time: 1.1634  data: 0.2032  max mem: 39452\n",
      "Train: [epoch:62]  [ 20/431]  eta: 0:07:13  lr: 0.000200  loss: 0.0025 (0.0025)  time: 0.9339  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [ 30/431]  eta: 0:06:29  lr: 0.000200  loss: 0.0020 (0.0025)  time: 0.8669  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [ 40/431]  eta: 0:06:14  lr: 0.000200  loss: 0.0020 (0.0024)  time: 0.8560  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [ 50/431]  eta: 0:06:05  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9385  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [ 60/431]  eta: 0:05:55  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.9593  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [ 70/431]  eta: 0:05:47  lr: 0.000200  loss: 0.0016 (0.0022)  time: 0.9707  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [ 80/431]  eta: 0:05:35  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9447  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [ 90/431]  eta: 0:05:26  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9470  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [100/431]  eta: 0:05:16  lr: 0.000200  loss: 0.0016 (0.0021)  time: 0.9663  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [110/431]  eta: 0:05:04  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.8990  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [120/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.8422  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [130/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.8585  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [140/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9239  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [150/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9579  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [160/431]  eta: 0:04:12  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.9093  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [170/431]  eta: 0:04:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8485  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [180/431]  eta: 0:03:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9366  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [190/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9787  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [200/431]  eta: 0:03:33  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8439  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [210/431]  eta: 0:03:25  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8916  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [220/431]  eta: 0:03:15  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [230/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8799  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [240/431]  eta: 0:02:56  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9519  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [250/431]  eta: 0:02:47  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9466  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [260/431]  eta: 0:02:38  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9407  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [270/431]  eta: 0:02:29  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9522  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [280/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9456  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [290/431]  eta: 0:02:10  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.9101  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [300/431]  eta: 0:02:01  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9046  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [310/431]  eta: 0:01:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9604  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:62]  [320/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9417  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [330/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8914  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [340/431]  eta: 0:01:24  lr: 0.000200  loss: 0.0016 (0.0022)  time: 0.9326  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [350/431]  eta: 0:01:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9472  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [360/431]  eta: 0:01:05  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9011  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [370/431]  eta: 0:00:56  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9560  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [380/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9713  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [390/431]  eta: 0:00:38  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9678  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [400/431]  eta: 0:00:28  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9467  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0082  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9482  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:62] Total time: 0:06:42 (0.9336 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:62]  [ 0/14]  eta: 0:03:51  loss: 0.0008 (0.0008)  time: 16.5415  data: 0.7472  max mem: 39452\n",
      "Valid: [epoch:62]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.6494  data: 0.0535  max mem: 39452\n",
      "Valid: [epoch:62] Total time: 0:03:39 (15.6678 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_62_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:63]  [  0/431]  eta: 0:19:45  lr: 0.000200  loss: 0.0016 (0.0016)  time: 2.7501  data: 1.9636  max mem: 39452\n",
      "Train: [epoch:63]  [ 10/431]  eta: 0:07:49  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1143  data: 0.1786  max mem: 39452\n",
      "Train: [epoch:63]  [ 20/431]  eta: 0:06:49  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9075  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [ 30/431]  eta: 0:06:27  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.8845  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [ 40/431]  eta: 0:06:17  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9326  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:63]  [ 50/431]  eta: 0:06:03  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9364  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:63]  [ 60/431]  eta: 0:05:54  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9351  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [ 70/431]  eta: 0:05:47  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9871  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [ 80/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9511  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [ 90/431]  eta: 0:05:25  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [100/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9525  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [110/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8984  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [120/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8485  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [130/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8796  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [140/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9745  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [150/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9626  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [160/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8943  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [170/431]  eta: 0:04:04  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9146  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [180/431]  eta: 0:03:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [190/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9335  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:63]  [200/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9110  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [210/431]  eta: 0:03:26  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9349  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [220/431]  eta: 0:03:18  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [230/431]  eta: 0:03:09  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0061  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [240/431]  eta: 0:03:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9811  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [250/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9556  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [260/431]  eta: 0:02:40  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8601  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [270/431]  eta: 0:02:30  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8365  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [280/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8488  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [290/431]  eta: 0:02:10  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8381  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [300/431]  eta: 0:02:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8939  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [310/431]  eta: 0:01:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9154  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [320/431]  eta: 0:01:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8597  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [330/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8834  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [340/431]  eta: 0:01:24  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9153  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [350/431]  eta: 0:01:14  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9346  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [360/431]  eta: 0:01:05  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9414  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [370/431]  eta: 0:00:56  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9364  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [380/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9320  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [390/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9304  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [400/431]  eta: 0:00:28  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9115  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9159  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.8974  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9175  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:63] Total time: 0:06:39 (0.9260 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0022 (0.0022)\n",
      "Valid: [epoch:63]  [ 0/14]  eta: 0:03:46  loss: 0.0026 (0.0026)  time: 16.2053  data: 0.7814  max mem: 39452\n",
      "Valid: [epoch:63]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.4133  data: 0.0559  max mem: 39452\n",
      "Valid: [epoch:63] Total time: 0:03:36 (15.4293 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_63_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:64]  [  0/431]  eta: 0:17:00  lr: 0.000200  loss: 0.0031 (0.0031)  time: 2.3682  data: 1.5709  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:64]  [ 10/431]  eta: 0:07:13  lr: 0.000200  loss: 0.0019 (0.0024)  time: 1.0305  data: 0.1430  max mem: 39452\n",
      "Train: [epoch:64]  [ 20/431]  eta: 0:06:32  lr: 0.000200  loss: 0.0021 (0.0025)  time: 0.8831  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [ 30/431]  eta: 0:06:16  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.8870  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [ 40/431]  eta: 0:06:03  lr: 0.000200  loss: 0.0019 (0.0024)  time: 0.9048  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [ 50/431]  eta: 0:05:49  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8876  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [ 60/431]  eta: 0:05:43  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.9189  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [ 70/431]  eta: 0:05:32  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [ 80/431]  eta: 0:05:25  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9259  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [ 90/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9382  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [100/431]  eta: 0:05:08  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9613  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [110/431]  eta: 0:04:58  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9503  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [120/431]  eta: 0:04:46  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8682  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [130/431]  eta: 0:04:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8921  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [140/431]  eta: 0:04:26  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8651  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [150/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8646  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [160/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9557  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [170/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [180/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9325  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [190/431]  eta: 0:03:41  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9322  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [200/431]  eta: 0:03:31  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8510  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [210/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8419  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [220/431]  eta: 0:03:11  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8684  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [230/431]  eta: 0:03:02  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8734  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [240/431]  eta: 0:02:53  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9142  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [250/431]  eta: 0:02:45  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9758  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [260/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9350  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [270/431]  eta: 0:02:26  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8785  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [280/431]  eta: 0:02:17  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9049  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [290/431]  eta: 0:02:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9113  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [300/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8980  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [310/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9028  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [320/431]  eta: 0:01:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9005  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [330/431]  eta: 0:01:31  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9096  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [340/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9429  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [350/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9398  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [360/431]  eta: 0:01:04  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9068  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [370/431]  eta: 0:00:55  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.8414  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [380/431]  eta: 0:00:46  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8593  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [390/431]  eta: 0:00:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9440  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [400/431]  eta: 0:00:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9815  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9698  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:64]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0024  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0154  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:64] Total time: 0:06:35 (0.9185 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:64]  [ 0/14]  eta: 0:03:46  loss: 0.0024 (0.0024)  time: 16.1731  data: 0.7900  max mem: 39452\n",
      "Valid: [epoch:64]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.5100  data: 0.0565  max mem: 39452\n",
      "Valid: [epoch:64] Total time: 0:03:37 (15.5297 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_64_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:65]  [  0/431]  eta: 0:23:56  lr: 0.000200  loss: 0.0019 (0.0019)  time: 3.3340  data: 2.3140  max mem: 39452\n",
      "Train: [epoch:65]  [ 10/431]  eta: 0:08:05  lr: 0.000200  loss: 0.0025 (0.0025)  time: 1.1536  data: 0.2105  max mem: 39452\n",
      "Train: [epoch:65]  [ 20/431]  eta: 0:07:16  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9491  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [ 30/431]  eta: 0:06:49  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.9478  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:65]  [ 40/431]  eta: 0:06:33  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9458  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:65]  [ 50/431]  eta: 0:06:17  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9476  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [ 60/431]  eta: 0:06:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9587  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [ 70/431]  eta: 0:05:55  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9688  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:65]  [ 80/431]  eta: 0:05:42  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9348  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [ 90/431]  eta: 0:05:29  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8992  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [100/431]  eta: 0:05:19  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9124  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [110/431]  eta: 0:05:08  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9317  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [120/431]  eta: 0:04:59  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9503  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [130/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9406  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [140/431]  eta: 0:04:38  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9188  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [150/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8616  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [160/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8638  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [170/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9853  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [180/431]  eta: 0:03:57  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9501  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:65]  [190/431]  eta: 0:03:47  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9035  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [200/431]  eta: 0:03:38  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9422  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [210/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [220/431]  eta: 0:03:18  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9124  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [230/431]  eta: 0:03:08  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8725  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [240/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8843  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [250/431]  eta: 0:02:49  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9393  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [260/431]  eta: 0:02:39  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9095  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [270/431]  eta: 0:02:30  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9083  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [280/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8945  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [290/431]  eta: 0:02:11  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.9053  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [300/431]  eta: 0:02:02  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9557  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [310/431]  eta: 0:01:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9271  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:65]  [320/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9410  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [330/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9924  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [340/431]  eta: 0:01:25  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9761  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [350/431]  eta: 0:01:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9449  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [360/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9433  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [370/431]  eta: 0:00:57  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9459  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [380/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8974  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [390/431]  eta: 0:00:38  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9159  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [400/431]  eta: 0:00:29  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9670  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9761  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9524  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8977  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:65] Total time: 0:06:43 (0.9367 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:65]  [ 0/14]  eta: 0:03:48  loss: 0.0007 (0.0007)  time: 16.3481  data: 0.7321  max mem: 39452\n",
      "Valid: [epoch:65]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.5520  data: 0.0524  max mem: 39452\n",
      "Valid: [epoch:65] Total time: 0:03:38 (15.5719 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_65_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:66]  [  0/431]  eta: 0:20:59  lr: 0.000200  loss: 0.0011 (0.0011)  time: 2.9225  data: 1.9824  max mem: 39452\n",
      "Train: [epoch:66]  [ 10/431]  eta: 0:07:58  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.1359  data: 0.1803  max mem: 39452\n",
      "Train: [epoch:66]  [ 20/431]  eta: 0:07:09  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9503  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [ 30/431]  eta: 0:06:41  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9282  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66]  [ 40/431]  eta: 0:06:25  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9269  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66]  [ 50/431]  eta: 0:06:10  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.9272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [ 60/431]  eta: 0:05:58  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9236  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [ 70/431]  eta: 0:05:45  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9193  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [ 80/431]  eta: 0:05:32  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8895  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [ 90/431]  eta: 0:05:24  lr: 0.000200  loss: 0.0017 (0.0021)  time: 0.9347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [100/431]  eta: 0:05:12  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [110/431]  eta: 0:05:00  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8617  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [120/431]  eta: 0:04:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8810  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66]  [130/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8958  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66]  [140/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9377  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [150/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9938  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66]  [160/431]  eta: 0:04:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9951  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [170/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0111  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [180/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0078  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [190/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9632  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66]  [200/431]  eta: 0:03:39  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9664  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66]  [210/431]  eta: 0:03:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0151  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [220/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9585  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66]  [230/431]  eta: 0:03:10  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8981  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66]  [240/431]  eta: 0:03:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9130  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [250/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9094  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [260/431]  eta: 0:02:41  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9116  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [270/431]  eta: 0:02:32  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [280/431]  eta: 0:02:22  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9406  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [290/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [300/431]  eta: 0:02:03  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9371  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [310/431]  eta: 0:01:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8657  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [320/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8554  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [330/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8762  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [340/431]  eta: 0:01:25  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9272  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [350/431]  eta: 0:01:16  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9505  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [360/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9518  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:66]  [370/431]  eta: 0:00:57  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9385  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [380/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9461  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [390/431]  eta: 0:00:38  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9397  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [400/431]  eta: 0:00:29  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9121  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9262  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:66]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9261  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:66] Total time: 0:06:44 (0.9377 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:66]  [ 0/14]  eta: 0:03:44  loss: 0.0026 (0.0026)  time: 16.0488  data: 0.7727  max mem: 39452\n",
      "Valid: [epoch:66]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.4684  data: 0.0553  max mem: 39452\n",
      "Valid: [epoch:66] Total time: 0:03:36 (15.4870 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_66_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:67]  [  0/431]  eta: 0:18:59  lr: 0.000200  loss: 0.0042 (0.0042)  time: 2.6441  data: 1.8374  max mem: 39452\n",
      "Train: [epoch:67]  [ 10/431]  eta: 0:08:03  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1482  data: 0.1672  max mem: 39452\n",
      "Train: [epoch:67]  [ 20/431]  eta: 0:07:04  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9524  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [ 30/431]  eta: 0:06:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8955  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:67]  [ 40/431]  eta: 0:06:11  lr: 0.000200  loss: 0.0023 (0.0024)  time: 0.8639  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:67]  [ 50/431]  eta: 0:05:57  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.8666  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:67]  [ 60/431]  eta: 0:05:51  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9378  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [ 70/431]  eta: 0:05:39  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9433  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [ 80/431]  eta: 0:05:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9162  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [ 90/431]  eta: 0:05:19  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9242  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [100/431]  eta: 0:05:10  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9305  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [110/431]  eta: 0:05:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9385  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [120/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9374  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [130/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9419  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [140/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9331  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [150/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9374  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [160/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9375  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [170/431]  eta: 0:04:04  lr: 0.000200  loss: 0.0026 (0.0023)  time: 0.9430  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [180/431]  eta: 0:03:55  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9378  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [190/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9062  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:67]  [200/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8888  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:67]  [210/431]  eta: 0:03:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9014  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [220/431]  eta: 0:03:17  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9621  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [230/431]  eta: 0:03:07  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9646  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [240/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9919  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [250/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [260/431]  eta: 0:02:40  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9543  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [270/431]  eta: 0:02:31  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9066  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [280/431]  eta: 0:02:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9450  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [290/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9180  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [300/431]  eta: 0:02:02  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9052  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [310/431]  eta: 0:01:53  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9472  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [320/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9102  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [330/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8504  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [340/431]  eta: 0:01:24  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8403  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [350/431]  eta: 0:01:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9000  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [360/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9213  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [370/431]  eta: 0:00:56  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9618  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [380/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9842  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [390/431]  eta: 0:00:38  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9575  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [400/431]  eta: 0:00:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9597  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9919  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0355  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0132  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:67] Total time: 0:06:45 (0.9411 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:67]  [ 0/14]  eta: 0:03:56  loss: 0.0024 (0.0024)  time: 16.8775  data: 0.8663  max mem: 39452\n",
      "Valid: [epoch:67]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.2489  data: 0.0620  max mem: 39452\n",
      "Valid: [epoch:67] Total time: 0:03:47 (16.2659 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_67_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:68]  [  0/431]  eta: 0:18:49  lr: 0.000200  loss: 0.0012 (0.0012)  time: 2.6204  data: 1.8488  max mem: 39452\n",
      "Train: [epoch:68]  [ 10/431]  eta: 0:07:57  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.1336  data: 0.1682  max mem: 39452\n",
      "Train: [epoch:68]  [ 20/431]  eta: 0:07:40  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0457  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [ 30/431]  eta: 0:07:23  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0899  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [ 40/431]  eta: 0:07:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0330  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [ 50/431]  eta: 0:06:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9802  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:68]  [ 60/431]  eta: 0:06:23  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9409  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [ 70/431]  eta: 0:06:07  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9208  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [ 80/431]  eta: 0:05:56  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9589  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [ 90/431]  eta: 0:05:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9637  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [100/431]  eta: 0:05:32  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9702  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [110/431]  eta: 0:05:19  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9519  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [120/431]  eta: 0:05:10  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9632  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [130/431]  eta: 0:05:00  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0044  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [140/431]  eta: 0:04:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9972  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [150/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0243  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [160/431]  eta: 0:04:31  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0170  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [170/431]  eta: 0:04:19  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9314  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [180/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9000  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [190/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9471  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [200/431]  eta: 0:03:49  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0483  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [210/431]  eta: 0:03:39  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0466  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [220/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9847  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [230/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [240/431]  eta: 0:03:10  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0437  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [250/431]  eta: 0:03:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0518  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [260/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0517  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [270/431]  eta: 0:02:41  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [280/431]  eta: 0:02:31  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0240  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [290/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9978  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [300/431]  eta: 0:02:11  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9661  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [310/431]  eta: 0:02:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9389  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [320/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9611  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [330/431]  eta: 0:01:40  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9925  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [340/431]  eta: 0:01:30  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9821  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [350/431]  eta: 0:01:20  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9794  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [360/431]  eta: 0:01:10  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9858  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [370/431]  eta: 0:01:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9601  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [380/431]  eta: 0:00:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9481  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [390/431]  eta: 0:00:40  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9429  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [400/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8618  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [410/431]  eta: 0:00:20  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8596  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9001  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:68]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9167  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:68] Total time: 0:07:04 (0.9838 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0017 (0.0022)\n",
      "Valid: [epoch:68]  [ 0/14]  eta: 0:03:47  loss: 0.0025 (0.0025)  time: 16.2243  data: 0.7662  max mem: 39452\n",
      "Valid: [epoch:68]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.5703  data: 0.0548  max mem: 39452\n",
      "Valid: [epoch:68] Total time: 0:03:38 (15.5889 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_68_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:69]  [  0/431]  eta: 0:17:06  lr: 0.000200  loss: 0.0020 (0.0020)  time: 2.3827  data: 1.5284  max mem: 39452\n",
      "Train: [epoch:69]  [ 10/431]  eta: 0:08:01  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.1429  data: 0.1391  max mem: 39452\n",
      "Train: [epoch:69]  [ 20/431]  eta: 0:06:58  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9507  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [ 30/431]  eta: 0:06:41  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9220  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [ 40/431]  eta: 0:06:30  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9752  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [ 50/431]  eta: 0:06:23  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0171  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [ 60/431]  eta: 0:06:08  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.9875  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [ 70/431]  eta: 0:06:00  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9753  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [ 80/431]  eta: 0:05:45  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9490  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:69]  [ 90/431]  eta: 0:05:31  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8864  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [100/431]  eta: 0:05:24  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9689  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [110/431]  eta: 0:05:14  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0139  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [120/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9925  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [130/431]  eta: 0:04:56  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0062  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [140/431]  eta: 0:04:47  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0148  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [150/431]  eta: 0:04:35  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9444  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [160/431]  eta: 0:04:27  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9810  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [170/431]  eta: 0:04:19  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.1095  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [180/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0686  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:69]  [190/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9828  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [200/431]  eta: 0:03:50  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0235  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [210/431]  eta: 0:03:40  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0388  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [220/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9309  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:69]  [230/431]  eta: 0:03:19  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9506  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:69]  [240/431]  eta: 0:03:09  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9989  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:69]  [250/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9497  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [260/431]  eta: 0:02:49  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9718  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [270/431]  eta: 0:02:38  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [280/431]  eta: 0:02:28  lr: 0.000200  loss: 0.0026 (0.0023)  time: 0.8885  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [290/431]  eta: 0:02:18  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.9676  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [300/431]  eta: 0:02:09  lr: 0.000200  loss: 0.0018 (0.0023)  time: 1.0648  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [310/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0761  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:69]  [320/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0419  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:69]  [330/431]  eta: 0:01:40  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0303  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [340/431]  eta: 0:01:30  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9890  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [350/431]  eta: 0:01:20  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0030  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:69]  [360/431]  eta: 0:01:10  lr: 0.000200  loss: 0.0028 (0.0023)  time: 0.9712  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [370/431]  eta: 0:01:00  lr: 0.000200  loss: 0.0028 (0.0023)  time: 0.9142  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [380/431]  eta: 0:00:50  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9515  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [390/431]  eta: 0:00:40  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9919  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:69]  [400/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8925  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:69]  [410/431]  eta: 0:00:20  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9093  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.9451  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9055  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:69] Total time: 0:07:03 (0.9821 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0023)\n",
      "Valid: [epoch:69]  [ 0/14]  eta: 0:03:58  loss: 0.0007 (0.0007)  time: 17.0619  data: 0.7644  max mem: 39452\n",
      "Valid: [epoch:69]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.1066  data: 0.0547  max mem: 39452\n",
      "Valid: [epoch:69] Total time: 0:03:45 (16.1262 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_69_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:70]  [  0/431]  eta: 0:23:45  lr: 0.000200  loss: 0.0021 (0.0021)  time: 3.3084  data: 2.0554  max mem: 39452\n",
      "Train: [epoch:70]  [ 10/431]  eta: 0:08:12  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.1704  data: 0.1870  max mem: 39452\n",
      "Train: [epoch:70]  [ 20/431]  eta: 0:07:42  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0149  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [ 30/431]  eta: 0:07:08  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0134  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [ 40/431]  eta: 0:06:52  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.9822  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [ 50/431]  eta: 0:06:40  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0226  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [ 60/431]  eta: 0:06:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [ 70/431]  eta: 0:06:13  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9898  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [ 80/431]  eta: 0:05:53  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.8814  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [ 90/431]  eta: 0:05:47  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.9605  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:70]  [100/431]  eta: 0:05:36  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0587  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [110/431]  eta: 0:05:27  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [120/431]  eta: 0:05:17  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0386  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [130/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0173  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:70]  [140/431]  eta: 0:04:57  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0296  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:70]  [150/431]  eta: 0:04:45  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9871  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [160/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.9084  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [170/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.9784  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [180/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0237  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [190/431]  eta: 0:04:03  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0018  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:70]  [200/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9313  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:70]  [210/431]  eta: 0:03:41  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9222  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [220/431]  eta: 0:03:32  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0430  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [230/431]  eta: 0:03:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0591  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:70]  [240/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0139  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:70]  [250/431]  eta: 0:03:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9596  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [260/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9236  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [270/431]  eta: 0:02:41  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9891  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [280/431]  eta: 0:02:30  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9583  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [290/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.9205  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [300/431]  eta: 0:02:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9734  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [310/431]  eta: 0:02:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9768  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [320/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9822  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [330/431]  eta: 0:01:40  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9676  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:70]  [340/431]  eta: 0:01:30  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9847  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [350/431]  eta: 0:01:20  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.0197  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [360/431]  eta: 0:01:10  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9616  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [370/431]  eta: 0:01:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9664  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [380/431]  eta: 0:00:50  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0182  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [390/431]  eta: 0:00:40  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0588  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [400/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9872  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [410/431]  eta: 0:00:20  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9396  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:70]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9180  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9112  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:70] Total time: 0:07:06 (0.9905 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0022 (0.0022)\n",
      "Valid: [epoch:70]  [ 0/14]  eta: 0:04:00  loss: 0.0025 (0.0025)  time: 17.2084  data: 0.7997  max mem: 39452\n",
      "Valid: [epoch:70]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.2001  data: 0.0573  max mem: 39452\n",
      "Valid: [epoch:70] Total time: 0:03:47 (16.2233 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_70_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:71]  [  0/431]  eta: 0:19:14  lr: 0.000200  loss: 0.0022 (0.0022)  time: 2.6788  data: 1.8129  max mem: 39452\n",
      "Train: [epoch:71]  [ 10/431]  eta: 0:08:40  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.2375  data: 0.1650  max mem: 39452\n",
      "Train: [epoch:71]  [ 20/431]  eta: 0:07:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0276  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:71]  [ 30/431]  eta: 0:07:00  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9455  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [ 40/431]  eta: 0:06:42  lr: 0.000200  loss: 0.0026 (0.0023)  time: 0.9477  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [ 50/431]  eta: 0:06:26  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9581  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [ 60/431]  eta: 0:06:12  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9498  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [ 70/431]  eta: 0:06:04  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0006  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [ 80/431]  eta: 0:05:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0200  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [ 90/431]  eta: 0:05:43  lr: 0.000200  loss: 0.0016 (0.0022)  time: 1.0002  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [100/431]  eta: 0:05:32  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9939  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [110/431]  eta: 0:05:21  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9733  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [120/431]  eta: 0:05:10  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9664  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [130/431]  eta: 0:04:59  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9639  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:71]  [140/431]  eta: 0:04:47  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9327  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [150/431]  eta: 0:04:37  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9207  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [160/431]  eta: 0:04:26  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9558  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [170/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9832  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [180/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9903  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:71]  [190/431]  eta: 0:03:57  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9765  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:71]  [200/431]  eta: 0:03:46  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9394  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [210/431]  eta: 0:03:38  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0100  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [220/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0774  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [230/431]  eta: 0:03:19  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0551  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [240/431]  eta: 0:03:09  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0320  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [250/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9706  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:71]  [260/431]  eta: 0:02:49  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9676  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [270/431]  eta: 0:02:39  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0164  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [280/431]  eta: 0:02:29  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0203  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [290/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9938  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [300/431]  eta: 0:02:09  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9628  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [310/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9453  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [320/431]  eta: 0:01:49  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9817  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [330/431]  eta: 0:01:40  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9995  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [340/431]  eta: 0:01:30  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9798  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [350/431]  eta: 0:01:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9861  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [360/431]  eta: 0:01:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0148  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [370/431]  eta: 0:01:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0696  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [380/431]  eta: 0:00:50  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0999  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:71]  [390/431]  eta: 0:00:40  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0723  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [400/431]  eta: 0:00:30  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0223  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71]  [410/431]  eta: 0:00:20  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9876  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:71]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9889  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:71]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:71] Total time: 0:07:11 (1.0002 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0022 (0.0022)\n",
      "Valid: [epoch:71]  [ 0/14]  eta: 0:03:54  loss: 0.0019 (0.0019)  time: 16.7662  data: 0.7908  max mem: 39452\n",
      "Valid: [epoch:71]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.1218  data: 0.0566  max mem: 39452\n",
      "Valid: [epoch:71] Total time: 0:03:45 (16.1420 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_71_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:72]  [  0/431]  eta: 0:18:51  lr: 0.000200  loss: 0.0023 (0.0023)  time: 2.6252  data: 1.3595  max mem: 39452\n",
      "Train: [epoch:72]  [ 10/431]  eta: 0:07:14  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0316  data: 0.1237  max mem: 39452\n",
      "Train: [epoch:72]  [ 20/431]  eta: 0:06:52  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9217  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [ 30/431]  eta: 0:06:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [ 40/431]  eta: 0:06:30  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9968  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [ 50/431]  eta: 0:06:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0259  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [ 60/431]  eta: 0:06:06  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9630  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:72]  [ 70/431]  eta: 0:05:55  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9302  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [ 80/431]  eta: 0:05:45  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9766  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:72]  [ 90/431]  eta: 0:05:38  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0211  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:72]  [100/431]  eta: 0:05:26  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9961  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:72]  [110/431]  eta: 0:05:18  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9994  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [120/431]  eta: 0:05:10  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0557  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [130/431]  eta: 0:05:01  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.0444  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:72]  [140/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0229  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:72]  [150/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0524  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [160/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0536  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [170/431]  eta: 0:04:24  lr: 0.000200  loss: 0.0023 (0.0021)  time: 1.0435  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [180/431]  eta: 0:04:14  lr: 0.000200  loss: 0.0025 (0.0021)  time: 1.0605  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [190/431]  eta: 0:04:03  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0145  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [200/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9544  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [210/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0408  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [220/431]  eta: 0:03:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0772  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [230/431]  eta: 0:03:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9427  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [240/431]  eta: 0:03:11  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8430  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [250/431]  eta: 0:03:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8942  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [260/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9811  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [270/431]  eta: 0:02:40  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0005  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [280/431]  eta: 0:02:31  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0594  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:72]  [290/431]  eta: 0:02:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0052  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [300/431]  eta: 0:02:11  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9925  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [310/431]  eta: 0:02:01  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0360  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [320/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9630  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [330/431]  eta: 0:01:41  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9934  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [340/431]  eta: 0:01:31  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0493  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [350/431]  eta: 0:01:20  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9474  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:72]  [360/431]  eta: 0:01:10  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9131  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [370/431]  eta: 0:01:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9961  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [380/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0504  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [390/431]  eta: 0:00:41  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0609  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9921  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9655  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0158  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:72]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9949  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:72] Total time: 0:07:11 (1.0006 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:72]  [ 0/14]  eta: 0:03:54  loss: 0.0008 (0.0008)  time: 16.7589  data: 0.7928  max mem: 39452\n",
      "Valid: [epoch:72]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0248  data: 0.0567  max mem: 39452\n",
      "Valid: [epoch:72] Total time: 0:03:44 (16.0432 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_72_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:73]  [  0/431]  eta: 0:22:57  lr: 0.000200  loss: 0.0021 (0.0021)  time: 3.1950  data: 2.3658  max mem: 39452\n",
      "Train: [epoch:73]  [ 10/431]  eta: 0:08:01  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.1449  data: 0.2152  max mem: 39452\n",
      "Train: [epoch:73]  [ 20/431]  eta: 0:07:17  lr: 0.000200  loss: 0.0022 (0.0025)  time: 0.9588  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [ 30/431]  eta: 0:07:12  lr: 0.000200  loss: 0.0025 (0.0025)  time: 1.0426  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [ 40/431]  eta: 0:06:52  lr: 0.000200  loss: 0.0022 (0.0024)  time: 1.0448  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [ 50/431]  eta: 0:06:34  lr: 0.000200  loss: 0.0020 (0.0024)  time: 0.9687  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [ 60/431]  eta: 0:06:23  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9915  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [ 70/431]  eta: 0:06:14  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0422  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [ 80/431]  eta: 0:06:05  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0619  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [ 90/431]  eta: 0:05:54  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0404  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [100/431]  eta: 0:05:39  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9633  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [110/431]  eta: 0:05:28  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9643  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [120/431]  eta: 0:05:18  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0205  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:73]  [130/431]  eta: 0:05:08  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0249  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:73]  [140/431]  eta: 0:04:58  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0351  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [150/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0461  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [160/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0615  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [170/431]  eta: 0:04:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0453  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [180/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9931  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [190/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0239  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [200/431]  eta: 0:03:56  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0188  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [210/431]  eta: 0:03:46  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9818  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [220/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9944  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [230/431]  eta: 0:03:24  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [240/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9569  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [250/431]  eta: 0:03:04  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0222  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [260/431]  eta: 0:02:53  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0005  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:73]  [270/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0159  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [280/431]  eta: 0:02:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0550  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:73]  [290/431]  eta: 0:02:23  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0160  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [300/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0108  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [310/431]  eta: 0:02:03  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0754  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [320/431]  eta: 0:01:53  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0345  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [330/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0439  data: 0.0004  max mem: 39452\n",
      "Train: [epoch:73]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0879  data: 0.0004  max mem: 39452\n",
      "Train: [epoch:73]  [350/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0312  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [360/431]  eta: 0:01:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0187  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0741  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0052  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [390/431]  eta: 0:00:41  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9466  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:73]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0135  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0433  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:73]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0157  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:73]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:73] Total time: 0:07:21 (1.0234 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:73]  [ 0/14]  eta: 0:03:57  loss: 0.0014 (0.0014)  time: 16.9525  data: 0.8130  max mem: 39452\n",
      "Valid: [epoch:73]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0593  data: 0.0582  max mem: 39452\n",
      "Valid: [epoch:73] Total time: 0:03:45 (16.0783 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_73_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:74]  [  0/431]  eta: 0:19:48  lr: 0.000200  loss: 0.0021 (0.0021)  time: 2.7579  data: 1.6908  max mem: 39452\n",
      "Train: [epoch:74]  [ 10/431]  eta: 0:08:35  lr: 0.000200  loss: 0.0021 (0.0021)  time: 1.2256  data: 0.1538  max mem: 39452\n",
      "Train: [epoch:74]  [ 20/431]  eta: 0:07:56  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0799  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [ 30/431]  eta: 0:07:31  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0720  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [ 40/431]  eta: 0:07:15  lr: 0.000200  loss: 0.0018 (0.0021)  time: 1.0666  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [ 50/431]  eta: 0:06:58  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0532  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [ 60/431]  eta: 0:06:36  lr: 0.000200  loss: 0.0017 (0.0021)  time: 0.9766  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [ 70/431]  eta: 0:06:22  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9639  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [ 80/431]  eta: 0:06:14  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0560  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [ 90/431]  eta: 0:05:58  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0245  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [100/431]  eta: 0:05:48  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9976  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [110/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.9958  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [120/431]  eta: 0:05:26  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0273  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [130/431]  eta: 0:05:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0404  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [140/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9826  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [150/431]  eta: 0:04:52  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0363  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [160/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0661  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [170/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0959  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [180/431]  eta: 0:04:22  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0613  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [190/431]  eta: 0:04:12  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0432  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [200/431]  eta: 0:04:01  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0349  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [210/431]  eta: 0:03:50  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9931  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [220/431]  eta: 0:03:40  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0495  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [230/431]  eta: 0:03:29  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0358  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [240/431]  eta: 0:03:18  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9891  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [250/431]  eta: 0:03:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9793  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [260/431]  eta: 0:02:57  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9902  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [270/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9865  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [280/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9836  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [290/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9755  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [300/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9313  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [310/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0278  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [320/431]  eta: 0:01:53  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0417  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [330/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9634  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9898  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [350/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0015  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [360/431]  eta: 0:01:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0325  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0854  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0848  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0026 (0.0022)  time: 1.0650  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0088  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0084  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:74]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0588  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0380  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:74] Total time: 0:07:23 (1.0291 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:74]  [ 0/14]  eta: 0:03:53  loss: 0.0015 (0.0015)  time: 16.6714  data: 0.8127  max mem: 39452\n",
      "Valid: [epoch:74]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0958  data: 0.0582  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:74] Total time: 0:03:45 (16.1126 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_74_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:75]  [  0/431]  eta: 0:22:21  lr: 0.000200  loss: 0.0019 (0.0019)  time: 3.1130  data: 2.1129  max mem: 39452\n",
      "Train: [epoch:75]  [ 10/431]  eta: 0:07:56  lr: 0.000200  loss: 0.0019 (0.0020)  time: 1.1328  data: 0.1923  max mem: 39452\n",
      "Train: [epoch:75]  [ 20/431]  eta: 0:07:07  lr: 0.000200  loss: 0.0019 (0.0020)  time: 0.9358  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [ 30/431]  eta: 0:06:33  lr: 0.000200  loss: 0.0019 (0.0020)  time: 0.8988  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [ 40/431]  eta: 0:06:24  lr: 0.000200  loss: 0.0018 (0.0020)  time: 0.9237  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [ 50/431]  eta: 0:06:14  lr: 0.000200  loss: 0.0017 (0.0020)  time: 0.9823  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [ 60/431]  eta: 0:06:13  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0512  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [ 70/431]  eta: 0:06:08  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.1188  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [ 80/431]  eta: 0:05:57  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.0541  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [ 90/431]  eta: 0:05:47  lr: 0.000200  loss: 0.0017 (0.0020)  time: 1.0112  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [100/431]  eta: 0:05:35  lr: 0.000200  loss: 0.0019 (0.0020)  time: 0.9981  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [110/431]  eta: 0:05:24  lr: 0.000200  loss: 0.0021 (0.0021)  time: 0.9688  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [120/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0225  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [130/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0519  data: 0.0003  max mem: 39452\n",
      "Train: [epoch:75]  [140/431]  eta: 0:04:55  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0185  data: 0.0003  max mem: 39452\n",
      "Train: [epoch:75]  [150/431]  eta: 0:04:44  lr: 0.000200  loss: 0.0025 (0.0021)  time: 0.9979  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [160/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0028 (0.0022)  time: 0.9810  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [170/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9949  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [180/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0033  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [190/431]  eta: 0:04:04  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0218  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [200/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0089  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [210/431]  eta: 0:03:43  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9941  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [220/431]  eta: 0:03:34  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0812  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [230/431]  eta: 0:03:24  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1100  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [240/431]  eta: 0:03:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0912  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [250/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0759  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [260/431]  eta: 0:02:54  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0025  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [270/431]  eta: 0:02:44  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9557  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [280/431]  eta: 0:02:34  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0366  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [290/431]  eta: 0:02:24  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.1283  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [300/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0714  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [310/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0260  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:75]  [320/431]  eta: 0:01:53  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.0130  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [330/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0090  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9922  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [350/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0024  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [360/431]  eta: 0:01:12  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0470  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0096  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0417  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.1048  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0886  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0256  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0327  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:75] Total time: 0:07:23 (1.0283 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:75]  [ 0/14]  eta: 0:03:58  loss: 0.0019 (0.0019)  time: 17.0041  data: 0.8504  max mem: 39452\n",
      "Valid: [epoch:75]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0872  data: 0.0609  max mem: 39452\n",
      "Valid: [epoch:75] Total time: 0:03:45 (16.1129 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_75_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:76]  [  0/431]  eta: 0:25:09  lr: 0.000200  loss: 0.0015 (0.0015)  time: 3.5034  data: 2.1166  max mem: 39452\n",
      "Train: [epoch:76]  [ 10/431]  eta: 0:08:46  lr: 0.000200  loss: 0.0022 (0.0024)  time: 1.2508  data: 0.1925  max mem: 39452\n",
      "Train: [epoch:76]  [ 20/431]  eta: 0:07:53  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0356  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [ 30/431]  eta: 0:07:21  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0197  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [ 40/431]  eta: 0:07:04  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0131  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [ 50/431]  eta: 0:06:54  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0647  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [ 60/431]  eta: 0:06:36  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0350  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [ 70/431]  eta: 0:06:24  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0111  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [ 80/431]  eta: 0:06:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0149  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [ 90/431]  eta: 0:05:58  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0049  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [100/431]  eta: 0:05:48  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0437  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [110/431]  eta: 0:05:34  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9879  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [120/431]  eta: 0:05:22  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9593  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [130/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0817  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [140/431]  eta: 0:05:05  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1132  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:76]  [150/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0667  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [160/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0176  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [170/431]  eta: 0:04:32  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0160  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [180/431]  eta: 0:04:20  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9834  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [190/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9199  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [200/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0179  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [210/431]  eta: 0:03:49  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0898  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [220/431]  eta: 0:03:39  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0649  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [230/431]  eta: 0:03:28  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0313  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [240/431]  eta: 0:03:18  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0393  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [250/431]  eta: 0:03:07  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0102  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [260/431]  eta: 0:02:56  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9436  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [270/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9914  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [280/431]  eta: 0:02:35  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9951  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [290/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9953  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [300/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9963  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [310/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9916  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [320/431]  eta: 0:01:53  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9507  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [330/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9114  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0318  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [350/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0737  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [360/431]  eta: 0:01:12  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0188  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0041  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0646  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1071  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0585  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9951  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9986  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:76]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0035  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:76] Total time: 0:07:21 (1.0247 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:76]  [ 0/14]  eta: 0:03:56  loss: 0.0012 (0.0012)  time: 16.9204  data: 0.7932  max mem: 39452\n",
      "Valid: [epoch:76]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0572  data: 0.0568  max mem: 39452\n",
      "Valid: [epoch:76] Total time: 0:03:45 (16.0756 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_76_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:77]  [  0/431]  eta: 0:18:20  lr: 0.000200  loss: 0.0025 (0.0025)  time: 2.5532  data: 1.6009  max mem: 39452\n",
      "Train: [epoch:77]  [ 10/431]  eta: 0:08:19  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.1869  data: 0.1457  max mem: 39452\n",
      "Train: [epoch:77]  [ 20/431]  eta: 0:07:31  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [ 30/431]  eta: 0:07:13  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0238  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [ 40/431]  eta: 0:06:52  lr: 0.000200  loss: 0.0017 (0.0021)  time: 1.0090  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [ 50/431]  eta: 0:06:37  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.9829  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [ 60/431]  eta: 0:06:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0286  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [ 70/431]  eta: 0:06:15  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0304  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [ 80/431]  eta: 0:06:07  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0440  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [ 90/431]  eta: 0:05:57  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0787  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [100/431]  eta: 0:05:44  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0242  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [110/431]  eta: 0:05:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0042  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [120/431]  eta: 0:05:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0081  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [130/431]  eta: 0:05:09  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9623  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [140/431]  eta: 0:04:59  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9785  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [150/431]  eta: 0:04:49  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0451  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [160/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0469  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [170/431]  eta: 0:04:29  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0617  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [180/431]  eta: 0:04:19  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0557  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [190/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0307  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [200/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0135  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [210/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0234  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [220/431]  eta: 0:03:37  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0442  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [230/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0308  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [240/431]  eta: 0:03:16  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9863  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [250/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9764  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [260/431]  eta: 0:02:56  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0580  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [270/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.1042  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [280/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0660  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [290/431]  eta: 0:02:26  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0793  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [300/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0437  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [310/431]  eta: 0:02:05  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0047  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [320/431]  eta: 0:01:54  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0472  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:77]  [330/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0023  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9835  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [350/431]  eta: 0:01:23  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0395  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [360/431]  eta: 0:01:13  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0510  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0162  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9808  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9726  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:77]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9928  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0515  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0017 (0.0022)  time: 1.0207  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:77] Total time: 0:07:24 (1.0306 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0017 (0.0022)\n",
      "Valid: [epoch:77]  [ 0/14]  eta: 0:04:01  loss: 0.0014 (0.0014)  time: 17.2668  data: 0.8582  max mem: 39452\n",
      "Valid: [epoch:77]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.1660  data: 0.0614  max mem: 39452\n",
      "Valid: [epoch:77] Total time: 0:03:46 (16.1862 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_77_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:78]  [  0/431]  eta: 0:21:31  lr: 0.000200  loss: 0.0018 (0.0018)  time: 2.9955  data: 1.6543  max mem: 39452\n",
      "Train: [epoch:78]  [ 10/431]  eta: 0:08:29  lr: 0.000200  loss: 0.0016 (0.0020)  time: 1.2100  data: 0.1505  max mem: 39452\n",
      "Train: [epoch:78]  [ 20/431]  eta: 0:07:36  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0157  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [ 30/431]  eta: 0:07:23  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0498  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [ 40/431]  eta: 0:06:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0078  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [ 50/431]  eta: 0:06:37  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9453  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [ 60/431]  eta: 0:06:24  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9913  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [ 70/431]  eta: 0:06:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0134  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [ 80/431]  eta: 0:06:00  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0005  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [ 90/431]  eta: 0:05:49  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9829  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [100/431]  eta: 0:05:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9627  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [110/431]  eta: 0:05:25  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9722  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [120/431]  eta: 0:05:13  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9635  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [130/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9582  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [140/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9787  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [150/431]  eta: 0:04:42  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9983  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [160/431]  eta: 0:04:30  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9771  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [170/431]  eta: 0:04:21  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9721  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [180/431]  eta: 0:04:11  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0273  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [190/431]  eta: 0:04:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0207  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [200/431]  eta: 0:03:50  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9741  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [210/431]  eta: 0:03:40  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9710  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [220/431]  eta: 0:03:30  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9976  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [230/431]  eta: 0:03:20  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9898  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [240/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0713  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [250/431]  eta: 0:03:01  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0787  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [260/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [270/431]  eta: 0:02:39  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8297  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [280/431]  eta: 0:02:29  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8813  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [290/431]  eta: 0:02:20  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0142  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [300/431]  eta: 0:02:10  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0548  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [310/431]  eta: 0:02:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0815  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [320/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0656  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [330/431]  eta: 0:01:41  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0295  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [340/431]  eta: 0:01:31  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0041  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [350/431]  eta: 0:01:20  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9247  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [360/431]  eta: 0:01:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9354  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [370/431]  eta: 0:01:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0281  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [380/431]  eta: 0:00:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9708  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [390/431]  eta: 0:00:40  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9589  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.1318  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0726  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:78]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9667  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9973  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:78] Total time: 0:07:11 (1.0011 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0021 (0.0022)\n",
      "Valid: [epoch:78]  [ 0/14]  eta: 0:03:56  loss: 0.0012 (0.0012)  time: 16.8687  data: 0.8554  max mem: 39452\n",
      "Valid: [epoch:78]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.9662  data: 0.0612  max mem: 39452\n",
      "Valid: [epoch:78] Total time: 0:03:43 (15.9847 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_78_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:79]  [  0/431]  eta: 0:20:00  lr: 0.000200  loss: 0.0020 (0.0020)  time: 2.7859  data: 1.8834  max mem: 39452\n",
      "Train: [epoch:79]  [ 10/431]  eta: 0:08:49  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.2585  data: 0.1713  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:79]  [ 20/431]  eta: 0:08:02  lr: 0.000200  loss: 0.0024 (0.0024)  time: 1.0930  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [ 30/431]  eta: 0:07:26  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0329  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [ 40/431]  eta: 0:07:04  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9923  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [ 50/431]  eta: 0:06:55  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0529  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [ 60/431]  eta: 0:06:38  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0531  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [ 70/431]  eta: 0:06:20  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9686  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [ 80/431]  eta: 0:06:11  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0118  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [ 90/431]  eta: 0:05:58  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0416  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [100/431]  eta: 0:05:48  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [110/431]  eta: 0:05:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0231  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [120/431]  eta: 0:05:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9845  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [130/431]  eta: 0:05:11  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9655  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [140/431]  eta: 0:05:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9810  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [150/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9876  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [160/431]  eta: 0:04:37  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9503  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [170/431]  eta: 0:04:26  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9593  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [180/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [190/431]  eta: 0:04:06  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0488  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [200/431]  eta: 0:03:55  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9771  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [210/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0022  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [220/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [230/431]  eta: 0:03:24  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9933  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [240/431]  eta: 0:03:14  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0254  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [250/431]  eta: 0:03:04  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0323  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [260/431]  eta: 0:02:54  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [270/431]  eta: 0:02:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0029  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [280/431]  eta: 0:02:34  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0153  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [290/431]  eta: 0:02:23  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0519  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [300/431]  eta: 0:02:14  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0612  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [310/431]  eta: 0:02:03  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0169  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [320/431]  eta: 0:01:53  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0216  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [330/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0836  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [340/431]  eta: 0:01:32  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9848  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [350/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9811  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [360/431]  eta: 0:01:12  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0505  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9860  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [380/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9626  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [390/431]  eta: 0:00:41  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9989  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:79]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0343  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0775  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0571  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9867  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:79] Total time: 0:07:20 (1.0210 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:79]  [ 0/14]  eta: 0:03:56  loss: 0.0025 (0.0025)  time: 16.8592  data: 0.8583  max mem: 39452\n",
      "Valid: [epoch:79]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0060  data: 0.0614  max mem: 39452\n",
      "Valid: [epoch:79] Total time: 0:03:44 (16.0253 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_79_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:80]  [  0/431]  eta: 0:22:05  lr: 0.000200  loss: 0.0020 (0.0020)  time: 3.0757  data: 2.1674  max mem: 39452\n",
      "Train: [epoch:80]  [ 10/431]  eta: 0:08:37  lr: 0.000200  loss: 0.0018 (0.0020)  time: 1.2294  data: 0.1972  max mem: 39452\n",
      "Train: [epoch:80]  [ 20/431]  eta: 0:07:36  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0127  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [ 30/431]  eta: 0:07:10  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9891  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [ 40/431]  eta: 0:06:47  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [ 50/431]  eta: 0:06:41  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0189  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [ 60/431]  eta: 0:06:29  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0696  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [ 70/431]  eta: 0:06:17  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0308  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [ 80/431]  eta: 0:06:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0183  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [ 90/431]  eta: 0:05:54  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0137  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [100/431]  eta: 0:05:43  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0137  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [110/431]  eta: 0:05:33  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0406  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [120/431]  eta: 0:05:23  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0488  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [130/431]  eta: 0:05:12  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0396  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [140/431]  eta: 0:05:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0105  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [150/431]  eta: 0:04:50  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9873  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [160/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9997  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [170/431]  eta: 0:04:28  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0015  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [180/431]  eta: 0:04:20  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0806  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [190/431]  eta: 0:04:10  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.1107  data: 0.0002  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:80]  [200/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0300  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [210/431]  eta: 0:03:48  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0016  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [220/431]  eta: 0:03:38  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0350  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [230/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0245  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [240/431]  eta: 0:03:16  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9853  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [250/431]  eta: 0:03:05  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9389  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [260/431]  eta: 0:02:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9192  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [270/431]  eta: 0:02:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9813  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [280/431]  eta: 0:02:34  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0367  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [290/431]  eta: 0:02:23  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9567  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [300/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9401  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [310/431]  eta: 0:02:03  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9960  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [320/431]  eta: 0:01:52  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9865  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [330/431]  eta: 0:01:42  lr: 0.000200  loss: 0.0024 (0.0023)  time: 1.0286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [340/431]  eta: 0:01:32  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [350/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0166  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [360/431]  eta: 0:01:12  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0658  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0829  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0577  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [390/431]  eta: 0:00:41  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0439  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0710  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0411  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0199  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:80]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0377  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:80] Total time: 0:07:21 (1.0243 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:80]  [ 0/14]  eta: 0:03:55  loss: 0.0015 (0.0015)  time: 16.8479  data: 0.7607  max mem: 39452\n",
      "Valid: [epoch:80]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.9996  data: 0.0545  max mem: 39452\n",
      "Valid: [epoch:80] Total time: 0:03:44 (16.0177 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_80_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:81]  [  0/431]  eta: 0:24:25  lr: 0.000200  loss: 0.0025 (0.0025)  time: 3.3995  data: 2.2333  max mem: 39452\n",
      "Train: [epoch:81]  [ 10/431]  eta: 0:09:14  lr: 0.000200  loss: 0.0022 (0.0024)  time: 1.3172  data: 0.2031  max mem: 39452\n",
      "Train: [epoch:81]  [ 20/431]  eta: 0:08:23  lr: 0.000200  loss: 0.0022 (0.0024)  time: 1.1156  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [ 30/431]  eta: 0:07:51  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0996  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [ 40/431]  eta: 0:07:23  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0381  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [ 50/431]  eta: 0:07:01  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9964  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [ 60/431]  eta: 0:06:45  lr: 0.000200  loss: 0.0023 (0.0024)  time: 1.0106  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [ 70/431]  eta: 0:06:31  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0342  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [ 80/431]  eta: 0:06:19  lr: 0.000200  loss: 0.0019 (0.0023)  time: 1.0469  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [ 90/431]  eta: 0:06:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0513  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [100/431]  eta: 0:05:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0298  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [110/431]  eta: 0:05:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0112  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [120/431]  eta: 0:05:32  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0520  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [130/431]  eta: 0:05:21  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0896  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [140/431]  eta: 0:05:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1042  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [150/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.1169  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [160/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0890  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [170/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0206  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [180/431]  eta: 0:04:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0260  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [190/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0749  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [200/431]  eta: 0:04:06  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0467  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [210/431]  eta: 0:03:56  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0571  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [220/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.1055  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [230/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0846  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [240/431]  eta: 0:03:24  lr: 0.000200  loss: 0.0026 (0.0022)  time: 1.0871  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [250/431]  eta: 0:03:13  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0816  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [260/431]  eta: 0:03:02  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0033  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [270/431]  eta: 0:02:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [280/431]  eta: 0:02:41  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0583  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [290/431]  eta: 0:02:30  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0213  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [300/431]  eta: 0:02:19  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0295  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [310/431]  eta: 0:02:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0458  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [320/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0498  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [330/431]  eta: 0:01:47  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0717  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [340/431]  eta: 0:01:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0652  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [350/431]  eta: 0:01:26  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0641  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [360/431]  eta: 0:01:15  lr: 0.000200  loss: 0.0025 (0.0022)  time: 1.0684  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [370/431]  eta: 0:01:04  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0582  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:81]  [380/431]  eta: 0:00:54  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0746  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81]  [390/431]  eta: 0:00:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0433  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [400/431]  eta: 0:00:32  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9809  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [410/431]  eta: 0:00:22  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9902  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9886  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:81]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9491  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:81] Total time: 0:07:34 (1.0551 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:81]  [ 0/14]  eta: 0:03:53  loss: 0.0010 (0.0010)  time: 16.6978  data: 0.8298  max mem: 39452\n",
      "Valid: [epoch:81]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0320  data: 0.0594  max mem: 39452\n",
      "Valid: [epoch:81] Total time: 0:03:44 (16.0495 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_81_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:82]  [  0/431]  eta: 0:19:28  lr: 0.000200  loss: 0.0015 (0.0015)  time: 2.7121  data: 1.7252  max mem: 39452\n",
      "Train: [epoch:82]  [ 10/431]  eta: 0:07:56  lr: 0.000200  loss: 0.0024 (0.0024)  time: 1.1325  data: 0.1570  max mem: 39452\n",
      "Train: [epoch:82]  [ 20/431]  eta: 0:07:35  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0277  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [ 30/431]  eta: 0:07:11  lr: 0.000200  loss: 0.0020 (0.0021)  time: 1.0444  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [ 40/431]  eta: 0:06:46  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9702  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [ 50/431]  eta: 0:06:31  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9542  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [ 60/431]  eta: 0:06:13  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9339  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [ 70/431]  eta: 0:06:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9301  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [ 80/431]  eta: 0:05:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9834  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [ 90/431]  eta: 0:05:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0045  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [100/431]  eta: 0:05:31  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0100  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [110/431]  eta: 0:05:21  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0060  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [120/431]  eta: 0:05:10  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9857  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [130/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0480  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [140/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0871  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [150/431]  eta: 0:04:44  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0295  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [160/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0185  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [170/431]  eta: 0:04:24  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0144  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [180/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0053  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [190/431]  eta: 0:04:04  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0489  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [200/431]  eta: 0:03:55  lr: 0.000200  loss: 0.0026 (0.0022)  time: 1.1035  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [210/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0837  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [220/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0246  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [230/431]  eta: 0:03:25  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0328  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [240/431]  eta: 0:03:15  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0192  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [250/431]  eta: 0:03:04  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9711  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [260/431]  eta: 0:02:53  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9669  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [270/431]  eta: 0:02:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9966  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [280/431]  eta: 0:02:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0046  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [290/431]  eta: 0:02:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9965  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [300/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0627  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [310/431]  eta: 0:02:03  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0709  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [320/431]  eta: 0:01:53  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0425  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [330/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.1131  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [340/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0674  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [350/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9956  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [360/431]  eta: 0:01:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0201  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0022 (0.0022)  time: 1.0314  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0688  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:82]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0580  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.9781  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0393  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0642  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9836  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:82] Total time: 0:07:21 (1.0251 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0023 (0.0022)\n",
      "Valid: [epoch:82]  [ 0/14]  eta: 0:03:55  loss: 0.0025 (0.0025)  time: 16.8003  data: 0.7810  max mem: 39452\n",
      "Valid: [epoch:82]  [13/14]  eta: 0:00:16  loss: 0.0015 (0.0018)  time: 16.0939  data: 0.0559  max mem: 39452\n",
      "Valid: [epoch:82] Total time: 0:03:45 (16.1132 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_82_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:83]  [  0/431]  eta: 0:20:15  lr: 0.000200  loss: 0.0031 (0.0031)  time: 2.8213  data: 1.6135  max mem: 39452\n",
      "Train: [epoch:83]  [ 10/431]  eta: 0:08:02  lr: 0.000200  loss: 0.0023 (0.0025)  time: 1.1451  data: 0.1468  max mem: 39452\n",
      "Train: [epoch:83]  [ 20/431]  eta: 0:07:12  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.9649  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [ 30/431]  eta: 0:06:51  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9609  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [ 40/431]  eta: 0:06:37  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9755  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [ 50/431]  eta: 0:06:26  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9975  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [ 60/431]  eta: 0:06:14  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9992  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:83]  [ 70/431]  eta: 0:06:03  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.9897  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [ 80/431]  eta: 0:05:50  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9639  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [ 90/431]  eta: 0:05:42  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.9886  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [100/431]  eta: 0:05:33  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0484  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [110/431]  eta: 0:05:24  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0477  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [120/431]  eta: 0:05:16  lr: 0.000200  loss: 0.0024 (0.0022)  time: 1.0638  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [130/431]  eta: 0:05:07  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0715  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [140/431]  eta: 0:04:55  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9977  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [150/431]  eta: 0:04:45  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9815  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [160/431]  eta: 0:04:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0209  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [170/431]  eta: 0:04:25  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0349  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [180/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9794  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [190/431]  eta: 0:04:03  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9392  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [200/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9699  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [210/431]  eta: 0:03:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9746  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [220/431]  eta: 0:03:32  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0093  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [230/431]  eta: 0:03:23  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0524  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [240/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0023 (0.0022)  time: 1.0375  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [250/431]  eta: 0:03:02  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9888  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [260/431]  eta: 0:02:52  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0197  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [270/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0268  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [280/431]  eta: 0:02:32  lr: 0.000200  loss: 0.0023 (0.0023)  time: 1.0111  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [290/431]  eta: 0:02:22  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0116  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [300/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [310/431]  eta: 0:02:02  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0737  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [320/431]  eta: 0:01:52  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0661  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [330/431]  eta: 0:01:42  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0645  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [340/431]  eta: 0:01:32  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0611  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [350/431]  eta: 0:01:22  lr: 0.000200  loss: 0.0020 (0.0023)  time: 1.0288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [360/431]  eta: 0:01:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0484  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [370/431]  eta: 0:01:02  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0910  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [380/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0948  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [390/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0876  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [400/431]  eta: 0:00:31  lr: 0.000200  loss: 0.0022 (0.0023)  time: 1.0482  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:83]  [410/431]  eta: 0:00:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0496  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [420/431]  eta: 0:00:11  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0591  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83]  [430/431]  eta: 0:00:01  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0186  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:83] Total time: 0:07:22 (1.0267 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:83]  [ 0/14]  eta: 0:03:48  loss: 0.0026 (0.0026)  time: 16.3559  data: 0.5836  max mem: 39452\n",
      "Valid: [epoch:83]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.5821  data: 0.0418  max mem: 39452\n",
      "Valid: [epoch:83] Total time: 0:03:38 (15.6001 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_83_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:84]  [  0/431]  eta: 0:18:18  lr: 0.000200  loss: 0.0017 (0.0017)  time: 2.5492  data: 1.7323  max mem: 39452\n",
      "Train: [epoch:84]  [ 10/431]  eta: 0:07:39  lr: 0.000200  loss: 0.0019 (0.0021)  time: 1.0924  data: 0.1576  max mem: 39452\n",
      "Train: [epoch:84]  [ 20/431]  eta: 0:06:46  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.9120  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:84]  [ 30/431]  eta: 0:06:26  lr: 0.000200  loss: 0.0020 (0.0021)  time: 0.8913  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [ 40/431]  eta: 0:06:12  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9134  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [ 50/431]  eta: 0:06:11  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9942  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [ 60/431]  eta: 0:05:57  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9879  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [ 70/431]  eta: 0:05:45  lr: 0.000200  loss: 0.0017 (0.0021)  time: 0.9083  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [ 80/431]  eta: 0:05:35  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [ 90/431]  eta: 0:05:25  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9524  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [100/431]  eta: 0:05:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9433  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [110/431]  eta: 0:05:04  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9225  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [120/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9011  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [130/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.9005  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [140/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9190  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [150/431]  eta: 0:04:24  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9298  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [160/431]  eta: 0:04:14  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9194  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [170/431]  eta: 0:04:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9273  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [180/431]  eta: 0:03:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9203  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [190/431]  eta: 0:03:45  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8999  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [200/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9085  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [210/431]  eta: 0:03:27  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9644  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [220/431]  eta: 0:03:18  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9951  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [230/431]  eta: 0:03:09  lr: 0.000200  loss: 0.0026 (0.0023)  time: 0.9732  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [240/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9535  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:84]  [250/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9682  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [260/431]  eta: 0:02:41  lr: 0.000200  loss: 0.0019 (0.0022)  time: 1.0228  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [270/431]  eta: 0:02:32  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9947  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [280/431]  eta: 0:02:22  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8891  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [290/431]  eta: 0:02:12  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [300/431]  eta: 0:02:03  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8998  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [310/431]  eta: 0:01:53  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.9639  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [320/431]  eta: 0:01:44  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9134  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [330/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0026 (0.0022)  time: 0.8497  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [340/431]  eta: 0:01:24  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.8503  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [350/431]  eta: 0:01:15  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.8895  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [360/431]  eta: 0:01:06  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.8949  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [370/431]  eta: 0:00:56  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9143  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [380/431]  eta: 0:00:47  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.9423  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [390/431]  eta: 0:00:38  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9221  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [400/431]  eta: 0:00:28  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9393  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:84]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9554  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:84]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9292  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9887  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:84] Total time: 0:06:43 (0.9355 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:84]  [ 0/14]  eta: 0:03:45  loss: 0.0014 (0.0014)  time: 16.1008  data: 0.8033  max mem: 39452\n",
      "Valid: [epoch:84]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.5362  data: 0.0575  max mem: 39452\n",
      "Valid: [epoch:84] Total time: 0:03:37 (15.5531 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_84_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:85]  [  0/431]  eta: 0:19:30  lr: 0.000200  loss: 0.0014 (0.0014)  time: 2.7152  data: 1.6588  max mem: 39452\n",
      "Train: [epoch:85]  [ 10/431]  eta: 0:07:18  lr: 0.000200  loss: 0.0022 (0.0021)  time: 1.0416  data: 0.1509  max mem: 39452\n",
      "Train: [epoch:85]  [ 20/431]  eta: 0:07:07  lr: 0.000200  loss: 0.0024 (0.0025)  time: 0.9576  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:85]  [ 30/431]  eta: 0:07:00  lr: 0.000200  loss: 0.0024 (0.0024)  time: 1.0517  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [ 40/431]  eta: 0:06:35  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9791  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:85]  [ 50/431]  eta: 0:06:24  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9458  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [ 60/431]  eta: 0:06:07  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.9459  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [ 70/431]  eta: 0:05:49  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8658  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [ 80/431]  eta: 0:05:37  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8787  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [ 90/431]  eta: 0:05:25  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.9107  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [100/431]  eta: 0:05:16  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9330  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [110/431]  eta: 0:05:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9670  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:85]  [120/431]  eta: 0:04:59  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0050  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [130/431]  eta: 0:04:51  lr: 0.000200  loss: 0.0018 (0.0022)  time: 1.0253  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [140/431]  eta: 0:04:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9899  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [150/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0204  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [160/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9983  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [170/431]  eta: 0:04:13  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9345  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [180/431]  eta: 0:04:02  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9355  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [190/431]  eta: 0:03:52  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.9239  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [200/431]  eta: 0:03:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8924  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [210/431]  eta: 0:03:31  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8793  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [220/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9162  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [230/431]  eta: 0:03:11  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9353  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [240/431]  eta: 0:03:02  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9184  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [250/431]  eta: 0:02:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9149  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [260/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9437  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [270/431]  eta: 0:02:32  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9160  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [280/431]  eta: 0:02:23  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9139  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [290/431]  eta: 0:02:13  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9454  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:85]  [300/431]  eta: 0:02:04  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9208  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:85]  [310/431]  eta: 0:01:54  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.9339  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [320/431]  eta: 0:01:45  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.9299  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [330/431]  eta: 0:01:35  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.9373  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [340/431]  eta: 0:01:26  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9566  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [350/431]  eta: 0:01:16  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9388  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [360/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9074  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [370/431]  eta: 0:00:57  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9734  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [380/431]  eta: 0:00:48  lr: 0.000200  loss: 0.0020 (0.0022)  time: 1.0023  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [390/431]  eta: 0:00:38  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9258  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [400/431]  eta: 0:00:29  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9157  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [410/431]  eta: 0:00:19  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9288  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85]  [420/431]  eta: 0:00:10  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.9365  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:85]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.9785  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:85] Total time: 0:06:48 (0.9486 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0020 (0.0022)\n",
      "Valid: [epoch:85]  [ 0/14]  eta: 0:03:47  loss: 0.0012 (0.0012)  time: 16.2479  data: 0.7149  max mem: 39452\n",
      "Valid: [epoch:85]  [13/14]  eta: 0:00:15  loss: 0.0015 (0.0018)  time: 15.4962  data: 0.0512  max mem: 39452\n",
      "Valid: [epoch:85] Total time: 0:03:37 (15.5149 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_85_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:86]  [  0/431]  eta: 0:17:27  lr: 0.000200  loss: 0.0015 (0.0015)  time: 2.4300  data: 1.5670  max mem: 39452\n",
      "Train: [epoch:86]  [ 10/431]  eta: 0:07:24  lr: 0.000200  loss: 0.0021 (0.0023)  time: 1.0567  data: 0.1426  max mem: 39452\n",
      "Train: [epoch:86]  [ 20/431]  eta: 0:06:56  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.9429  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [ 30/431]  eta: 0:06:33  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.9391  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [ 40/431]  eta: 0:06:16  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9103  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:86]  [ 50/431]  eta: 0:06:01  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8992  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [ 60/431]  eta: 0:05:46  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8760  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [ 70/431]  eta: 0:05:31  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.8417  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:86]  [ 80/431]  eta: 0:05:17  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.8181  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [ 90/431]  eta: 0:05:06  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.8319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [100/431]  eta: 0:04:56  lr: 0.000200  loss: 0.0019 (0.0021)  time: 0.8490  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [110/431]  eta: 0:04:47  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8753  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [120/431]  eta: 0:04:37  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8832  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [130/431]  eta: 0:04:27  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8472  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [140/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [150/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8311  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [160/431]  eta: 0:03:57  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8296  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [170/431]  eta: 0:03:49  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8660  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [180/431]  eta: 0:03:40  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8981  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:86]  [190/431]  eta: 0:03:31  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8572  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [200/431]  eta: 0:03:21  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8309  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [210/431]  eta: 0:03:12  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8307  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [220/431]  eta: 0:03:04  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8494  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [230/431]  eta: 0:02:55  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8884  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [240/431]  eta: 0:02:46  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8386  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:86]  [250/431]  eta: 0:02:36  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7924  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [260/431]  eta: 0:02:27  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8068  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [270/431]  eta: 0:02:18  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8144  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [280/431]  eta: 0:02:10  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8430  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [290/431]  eta: 0:02:01  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8432  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [300/431]  eta: 0:01:52  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8223  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [310/431]  eta: 0:01:43  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8211  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [320/431]  eta: 0:01:35  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8359  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [330/431]  eta: 0:01:26  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8467  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [340/431]  eta: 0:01:18  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8739  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [350/431]  eta: 0:01:09  lr: 0.000200  loss: 0.0023 (0.0023)  time: 0.8860  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [360/431]  eta: 0:01:01  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8535  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [370/431]  eta: 0:00:52  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8611  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [380/431]  eta: 0:00:43  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.8648  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [390/431]  eta: 0:00:35  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8068  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [400/431]  eta: 0:00:26  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.7793  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [410/431]  eta: 0:00:17  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8142  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [420/431]  eta: 0:00:09  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8348  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8289  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:86] Total time: 0:06:08 (0.8547 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:86]  [ 0/14]  eta: 0:03:38  loss: 0.0012 (0.0012)  time: 15.5958  data: 0.7234  max mem: 39452\n",
      "Valid: [epoch:86]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.7319  data: 0.0518  max mem: 39452\n",
      "Valid: [epoch:86] Total time: 0:03:26 (14.7516 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_86_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:87]  [  0/431]  eta: 0:21:08  lr: 0.000200  loss: 0.0021 (0.0021)  time: 2.9422  data: 1.9289  max mem: 39452\n",
      "Train: [epoch:87]  [ 10/431]  eta: 0:06:58  lr: 0.000200  loss: 0.0022 (0.0021)  time: 0.9942  data: 0.1755  max mem: 39452\n",
      "Train: [epoch:87]  [ 20/431]  eta: 0:06:13  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8060  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [ 30/431]  eta: 0:05:52  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8139  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [ 40/431]  eta: 0:05:38  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8198  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [ 50/431]  eta: 0:05:27  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [ 60/431]  eta: 0:05:19  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8532  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [ 70/431]  eta: 0:05:09  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.8485  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [ 80/431]  eta: 0:05:00  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.8397  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [ 90/431]  eta: 0:04:52  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8623  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [100/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.8520  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [110/431]  eta: 0:04:34  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.8397  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:87]  [120/431]  eta: 0:04:23  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8103  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [130/431]  eta: 0:04:14  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.7968  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [140/431]  eta: 0:04:06  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8352  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [150/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8594  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [160/431]  eta: 0:03:49  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8562  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [170/431]  eta: 0:03:40  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8397  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [180/431]  eta: 0:03:32  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8290  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [190/431]  eta: 0:03:23  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8274  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [200/431]  eta: 0:03:15  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8519  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [210/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8488  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [220/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8439  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [230/431]  eta: 0:02:49  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8216  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [240/431]  eta: 0:02:41  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8237  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [250/431]  eta: 0:02:32  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8733  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [260/431]  eta: 0:02:24  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8687  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [270/431]  eta: 0:02:16  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8393  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [280/431]  eta: 0:02:07  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.8250  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [290/431]  eta: 0:01:59  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8600  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [300/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8927  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [310/431]  eta: 0:01:42  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8607  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [320/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8350  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [330/431]  eta: 0:01:25  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8110  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [340/431]  eta: 0:01:16  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7990  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [350/431]  eta: 0:01:08  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8136  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [360/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.8182  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [370/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8244  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [380/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8365  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [390/431]  eta: 0:00:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8368  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [400/431]  eta: 0:00:26  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8271  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [410/431]  eta: 0:00:17  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8217  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [420/431]  eta: 0:00:09  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8492  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.8973  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:87] Total time: 0:06:03 (0.8440 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0017 (0.0022)\n",
      "Valid: [epoch:87]  [ 0/14]  eta: 0:03:34  loss: 0.0024 (0.0024)  time: 15.3563  data: 0.7140  max mem: 39452\n",
      "Valid: [epoch:87]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.7351  data: 0.0511  max mem: 39452\n",
      "Valid: [epoch:87] Total time: 0:03:26 (14.7558 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_87_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:88]  [  0/431]  eta: 0:22:40  lr: 0.000200  loss: 0.0035 (0.0035)  time: 3.1565  data: 1.9513  max mem: 39452\n",
      "Train: [epoch:88]  [ 10/431]  eta: 0:07:11  lr: 0.000200  loss: 0.0022 (0.0025)  time: 1.0255  data: 0.1775  max mem: 39452\n",
      "Train: [epoch:88]  [ 20/431]  eta: 0:06:31  lr: 0.000200  loss: 0.0019 (0.0024)  time: 0.8420  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [ 30/431]  eta: 0:06:10  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8676  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [ 40/431]  eta: 0:05:59  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8863  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [ 50/431]  eta: 0:05:45  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.8829  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [ 60/431]  eta: 0:05:31  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8415  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [ 70/431]  eta: 0:05:20  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.8337  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [ 80/431]  eta: 0:05:08  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.8353  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [ 90/431]  eta: 0:04:58  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8286  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [100/431]  eta: 0:04:48  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8424  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [110/431]  eta: 0:04:39  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8478  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [120/431]  eta: 0:04:28  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8090  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [130/431]  eta: 0:04:18  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.7945  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [140/431]  eta: 0:04:08  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8083  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [150/431]  eta: 0:03:59  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8084  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [160/431]  eta: 0:03:50  lr: 0.000200  loss: 0.0026 (0.0023)  time: 0.8184  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [170/431]  eta: 0:03:42  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.8462  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [180/431]  eta: 0:03:33  lr: 0.000200  loss: 0.0024 (0.0023)  time: 0.8511  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [190/431]  eta: 0:03:24  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8348  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [200/431]  eta: 0:03:16  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8390  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [210/431]  eta: 0:03:06  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8179  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [220/431]  eta: 0:02:58  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8138  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [230/431]  eta: 0:02:49  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [240/431]  eta: 0:02:41  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8192  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [250/431]  eta: 0:02:32  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8509  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [260/431]  eta: 0:02:24  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8557  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [270/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8216  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [280/431]  eta: 0:02:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8354  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [290/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8404  data: 0.0001  max mem: 39452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:88]  [300/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8222  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [310/431]  eta: 0:01:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8204  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [320/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.8037  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [330/431]  eta: 0:01:24  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8160  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [340/431]  eta: 0:01:16  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8366  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [350/431]  eta: 0:01:07  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.8152  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [360/431]  eta: 0:00:59  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.8347  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [370/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0025 (0.0023)  time: 0.8872  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [380/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8820  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [390/431]  eta: 0:00:34  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8654  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [400/431]  eta: 0:00:26  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8555  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:88]  [410/431]  eta: 0:00:17  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8340  data: 0.0002  max mem: 39452\n",
      "Train: [epoch:88]  [420/431]  eta: 0:00:09  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8178  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8045  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:88] Total time: 0:06:02 (0.8410 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0018 (0.0022)\n",
      "Valid: [epoch:88]  [ 0/14]  eta: 0:03:37  loss: 0.0024 (0.0024)  time: 15.5393  data: 0.7066  max mem: 39452\n",
      "Valid: [epoch:88]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.6874  data: 0.0506  max mem: 39452\n",
      "Valid: [epoch:88] Total time: 0:03:25 (14.7055 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_88_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:89]  [  0/431]  eta: 0:15:09  lr: 0.000200  loss: 0.0029 (0.0029)  time: 2.1101  data: 1.3329  max mem: 39452\n",
      "Train: [epoch:89]  [ 10/431]  eta: 0:06:47  lr: 0.000200  loss: 0.0025 (0.0025)  time: 0.9669  data: 0.1213  max mem: 39452\n",
      "Train: [epoch:89]  [ 20/431]  eta: 0:06:24  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.8779  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [ 30/431]  eta: 0:06:06  lr: 0.000200  loss: 0.0021 (0.0023)  time: 0.8838  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [ 40/431]  eta: 0:05:51  lr: 0.000200  loss: 0.0022 (0.0023)  time: 0.8579  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [ 50/431]  eta: 0:05:33  lr: 0.000200  loss: 0.0020 (0.0023)  time: 0.8164  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [ 60/431]  eta: 0:05:25  lr: 0.000200  loss: 0.0019 (0.0023)  time: 0.8376  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [ 70/431]  eta: 0:05:12  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.8426  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [ 80/431]  eta: 0:05:02  lr: 0.000200  loss: 0.0017 (0.0022)  time: 0.8145  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [ 90/431]  eta: 0:04:53  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8381  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [100/431]  eta: 0:04:43  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8319  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [110/431]  eta: 0:04:33  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8244  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [120/431]  eta: 0:04:24  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8238  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [130/431]  eta: 0:04:16  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8376  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [140/431]  eta: 0:04:07  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8407  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [150/431]  eta: 0:03:58  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8412  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [160/431]  eta: 0:03:51  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8756  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [170/431]  eta: 0:03:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8581  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [180/431]  eta: 0:03:33  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8393  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [190/431]  eta: 0:03:25  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8658  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [200/431]  eta: 0:03:16  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8572  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [210/431]  eta: 0:03:08  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8402  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [220/431]  eta: 0:02:59  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8282  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [230/431]  eta: 0:02:50  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8189  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [240/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8373  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [250/431]  eta: 0:02:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8397  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [260/431]  eta: 0:02:24  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.7987  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [270/431]  eta: 0:02:15  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8010  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [280/431]  eta: 0:02:07  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8116  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [290/431]  eta: 0:01:58  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8098  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [300/431]  eta: 0:01:50  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8191  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [310/431]  eta: 0:01:41  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8579  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [320/431]  eta: 0:01:33  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8879  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [330/431]  eta: 0:01:25  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8641  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [340/431]  eta: 0:01:16  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8396  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [350/431]  eta: 0:01:08  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8370  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [360/431]  eta: 0:01:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8798  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [370/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8358  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [380/431]  eta: 0:00:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.7941  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [390/431]  eta: 0:00:34  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8451  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [400/431]  eta: 0:00:26  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8279  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [410/431]  eta: 0:00:17  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7907  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [420/431]  eta: 0:00:09  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8127  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8334  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:89] Total time: 0:06:02 (0.8413 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0019 (0.0022)\n",
      "Valid: [epoch:89]  [ 0/14]  eta: 0:03:37  loss: 0.0019 (0.0019)  time: 15.5543  data: 0.7394  max mem: 39452\n",
      "Valid: [epoch:89]  [13/14]  eta: 0:00:14  loss: 0.0015 (0.0018)  time: 14.5757  data: 0.0529  max mem: 39452\n",
      "Valid: [epoch:89] Total time: 0:03:24 (14.5920 s / it)\n",
      "Averaged stats: loss: 0.0015 (0.0018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/epoch_89_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:90]  [  0/431]  eta: 0:20:25  lr: 0.000200  loss: 0.0022 (0.0022)  time: 2.8424  data: 2.0443  max mem: 39452\n",
      "Train: [epoch:90]  [ 10/431]  eta: 0:07:05  lr: 0.000200  loss: 0.0021 (0.0022)  time: 1.0118  data: 0.1859  max mem: 39452\n",
      "Train: [epoch:90]  [ 20/431]  eta: 0:06:06  lr: 0.000200  loss: 0.0021 (0.0024)  time: 0.7942  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [ 30/431]  eta: 0:05:51  lr: 0.000200  loss: 0.0025 (0.0024)  time: 0.8039  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [ 40/431]  eta: 0:05:46  lr: 0.000200  loss: 0.0024 (0.0025)  time: 0.8789  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [ 50/431]  eta: 0:05:33  lr: 0.000200  loss: 0.0022 (0.0024)  time: 0.8727  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [ 60/431]  eta: 0:05:22  lr: 0.000200  loss: 0.0018 (0.0023)  time: 0.8367  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [ 70/431]  eta: 0:05:10  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8249  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [ 80/431]  eta: 0:05:03  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8528  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [ 90/431]  eta: 0:04:54  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8718  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [100/431]  eta: 0:04:46  lr: 0.000200  loss: 0.0017 (0.0021)  time: 0.8658  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [110/431]  eta: 0:04:38  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.8863  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [120/431]  eta: 0:04:28  lr: 0.000200  loss: 0.0022 (0.0021)  time: 0.8592  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [130/431]  eta: 0:04:17  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.7917  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [140/431]  eta: 0:04:09  lr: 0.000200  loss: 0.0018 (0.0021)  time: 0.8103  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [150/431]  eta: 0:04:02  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.9052  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [160/431]  eta: 0:03:53  lr: 0.000200  loss: 0.0025 (0.0022)  time: 0.8956  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [170/431]  eta: 0:03:44  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8434  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [180/431]  eta: 0:03:35  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8301  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [190/431]  eta: 0:03:26  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [200/431]  eta: 0:03:18  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8495  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [210/431]  eta: 0:03:09  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8565  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [220/431]  eta: 0:03:00  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8332  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [230/431]  eta: 0:02:51  lr: 0.000200  loss: 0.0024 (0.0022)  time: 0.8189  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [240/431]  eta: 0:02:42  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8218  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [250/431]  eta: 0:02:34  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8257  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [260/431]  eta: 0:02:25  lr: 0.000200  loss: 0.0023 (0.0022)  time: 0.8240  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [270/431]  eta: 0:02:17  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8673  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [280/431]  eta: 0:02:08  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8684  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [290/431]  eta: 0:02:00  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8339  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [300/431]  eta: 0:01:51  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8792  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [310/431]  eta: 0:01:42  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8270  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [320/431]  eta: 0:01:34  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.7873  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [330/431]  eta: 0:01:25  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8487  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [340/431]  eta: 0:01:17  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8414  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [350/431]  eta: 0:01:08  lr: 0.000200  loss: 0.0019 (0.0022)  time: 0.8264  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [360/431]  eta: 0:01:00  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8423  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [370/431]  eta: 0:00:51  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8732  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [380/431]  eta: 0:00:43  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8694  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [390/431]  eta: 0:00:34  lr: 0.000200  loss: 0.0018 (0.0022)  time: 0.8483  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [400/431]  eta: 0:00:26  lr: 0.000200  loss: 0.0020 (0.0022)  time: 0.8193  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [410/431]  eta: 0:00:17  lr: 0.000200  loss: 0.0021 (0.0022)  time: 0.8150  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [420/431]  eta: 0:00:09  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8651  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90]  [430/431]  eta: 0:00:00  lr: 0.000200  loss: 0.0022 (0.0022)  time: 0.8816  data: 0.0001  max mem: 39452\n",
      "Train: [epoch:90] Total time: 0:06:06 (0.8500 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 0.0022 (0.0022)\n",
      "Valid: [epoch:90]  [ 0/14]  eta: 0:03:35  loss: 0.0015 (0.0015)  time: 15.3944  data: 0.7410  max mem: 39452\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--batch-size 16 \\\n",
    "--epochs 1000 \\\n",
    "--min-lr 5e-6 \\\n",
    "--lr 2e-4 \\\n",
    "--data-set 'Sinogram_DCM' \\\n",
    "--model-name 'MAP_WCMT' \\\n",
    "--criterion 'Window Compound Loss' \\\n",
    "--output_dir '/workspace/sunggu/4.Dose_img2img/model/[Ours]MAP_WCMT_test' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MAP_WCMT_test/low2high/' \\\n",
    "--validate-every 1 \\\n",
    "--num_workers 4 \\\n",
    "--criterion_mode 'not balance' \\\n",
    "--multiple_GT \"False\" \\\n",
    "--patch_training \"True\" \\\n",
    "--multi-gpu-mode 'DataParallel' \n",
    "# --multi-gpu-mode 'DataParallel' \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_log(path):\n",
    "    log_list = []\n",
    "    lines = open(path, 'r').read().splitlines() \n",
    "    for i in range(len(lines)):\n",
    "        exec('log_list.append('+lines[i] + ')')\n",
    "    return  log_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = read_log(path = '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/log.txt')\n",
    "\n",
    "train_lr   = [ log_list[i]['train_lr'] for i in range(len(log_list)) ]\n",
    "train_loss = [ log_list[i]['train_loss'] for i in range(len(log_list)) ]\n",
    "valid_loss = [ log_list[i]['valid_loss'] for i in range(len(log_list)) ]\n",
    "epoch      = [ log_list[i]['epoch'] for i in range(len(log_list)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(train_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(valid_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(np.argsort(valid_loss)[:10]) & set(np.argsort(train_loss)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py \\\n",
    "--training-mode 'sinogram' \\\n",
    "--data-set 'TEST_Sinogram_DCM' \\\n",
    "--model-name 'ED_CNN' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Test/png/[Privious]ED_CNN/epoch_999/' \\\n",
    "--num_workers 4 \\\n",
    "--pin-mem \\\n",
    "--range-minus1-plus1 'False' \\\n",
    "--teacher_forcing \"False\" \\\n",
    "--resume '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/epoch_999_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 978 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Original === \n",
    "PSNR avg: 54.4628 \n",
    "SSIM avg: 0.9956 \n",
    "RMSE avg: 7.9607\n",
    "\n",
    "\n",
    "Predictions === \n",
    "PSNR avg: 57.6190 \n",
    "SSIM avg: 0.9980 \n",
    "RMSE avg: 5.5423\n",
    "***********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
