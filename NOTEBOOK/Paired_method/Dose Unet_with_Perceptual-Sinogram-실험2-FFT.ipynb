{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/MONAI'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/4.Dose_img2img'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/4.Dose_img2img/pix2pixHD'))\n",
    "\n",
    "from sunggu_utils import check_value, take_list, plot_confusion_matrix, list_sort_nicely, find_dir, plot_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import skimage\n",
    "import monai\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, GeneralizedDiceLoss, FocalLoss, TverskyLoss\n",
    "from monai.metrics import compute_meandice, DiceMetric, ConfusionMatrixMetric \n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet, highresnet\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadNiftid,\n",
    "    LoadNumpyd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Lambdad,\n",
    "    ToTensord,\n",
    "    CastToTyped,\n",
    "    DeleteItemsd,\n",
    "    AsDiscrete,\n",
    "    SpatialPadd,\n",
    "    CenterSpatialCropd,\n",
    "    RandSpatialCropd,\n",
    "    Resized,\n",
    ")\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 시드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "set_determinism(seed=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_low_images  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/sinogram_dataset/2D_dataset/Train/noise20_b50f_5.0/*/*.npy'))\n",
    "train_high_images = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/sinogram_dataset/2D_dataset/Train/noise100_b50f_5.0/*/*.npy'))\n",
    "\n",
    "valid_low_images  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/sinogram_dataset/2D_dataset/Valid/noise20_b50f_5.0/*/*.npy'))\n",
    "valid_high_images = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/sinogram_dataset/2D_dataset/Valid/noise100_b50f_5.0/*/*.npy'))\n",
    "\n",
    "total_low_list  = train_low_images  + valid_low_images\n",
    "total_high_list = train_high_images + valid_high_images\n",
    "\n",
    "train_files = [{\"low\": low_name, \"high\": high_name} for low_name, high_name in zip(total_low_list, total_high_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.fft as fft\n",
    "\n",
    "# FFT\n",
    "def torch_fft(x):\n",
    "    fshift = fft.fftshift(fft.fft2(x))\n",
    "    x      = torch.cat([fshift.real, fshift.imag], dim=0)\n",
    "    return x\n",
    "\n",
    "def torch_fft_check(x):\n",
    "    fshift = fft.fftshift(fft.fft2(x))\n",
    "    x      = torch.cat([fshift.real, fshift.imag], dim=0)\n",
    "    return 20*torch.log(torch.abs(fshift))\n",
    "\n",
    "def torch_dfft(x):\n",
    "    x = -torch.abs(fft.ifft2(fft.ifftshift(x)))\n",
    "\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CT에 맞는 Augmentation\n",
    "from torchvision import transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadNumpyd(keys=[\"low\", \"high\"]),\n",
    "        AddChanneld(keys=[\"low\", \"high\"]), \n",
    "#         Resized(keys=[\"low\", \"high\"], spatial_size=(256, 256), mode='bicubic', align_corners=True),\n",
    "        ToTensord(keys=[\"low\", \"high\"]),\n",
    "        Lambdad(keys=[\"low\", \"high\"], func=transforms.Normalize(mean=(0.5), std=(0.5))),\n",
    "        \n",
    "        ## FFT\n",
    "        Lambdad(keys=[\"low\", \"high\"], func=torch_fft),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_windowing(x):\n",
    "    x = (x * 0.5) + 0.5 \n",
    "    x = np.clip(x, a_min=0.250, a_max=0.270)\n",
    "    x -= x.min()\n",
    "    x /= x.max()  \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "# check_loader = DataLoader(check_ds, batch_size=1, shuffle=False)\n",
    "# check_data = next(iter(check_loader))\n",
    "\n",
    "check_data = check_ds[160]\n",
    "\n",
    "print(check_data['low_meta_dict']['filename_or_obj'])\n",
    "print(check_data['high_meta_dict']['filename_or_obj'])\n",
    "\n",
    "low = (check_data[\"low\"][0])\n",
    "high = (check_data[\"high\"][0])\n",
    "print(f\"image shape: {low.shape}\")\n",
    "\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"low\")\n",
    "# plt.imshow(visual_windowing(low), cmap=\"gray\")\n",
    "plt.imshow(low, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"high\")\n",
    "# plt.imshow(visual_windowing(high), cmap=\"gray\")\n",
    "plt.imshow(high, cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "# from torchsampler.imbalanced import ImbalancedDatasetSampler, sunggu_ImbalancedDatasetSampler\n",
    "\n",
    "# cf) use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())\n",
    "\n",
    "# Cachedataset 이거 뭔가 문제가 있음...\n",
    "train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer  Only Low -> High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Unet_sunggu.model import UNet\n",
    "\n",
    "device = 'cuda'\n",
    "model = UNet(input_nc=2, output_nc=2)      \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 이어서 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 불러오기\n",
    "checkpoint_dir = '/workspace/sunggu/4.Dose_img2img/model/Pix2Pix_2D_HD_512x512_local/epoch_115_model.pth'\n",
    "checkpoint = torch.load(checkpoint_dir)\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "\n",
    "## multi-gpu 사용\n",
    "if torch.cuda.device_count() > 1:\n",
    "    netG = torch.nn.DataParallel(netG)\n",
    "    netD = torch.nn.DataParallel(netD)\n",
    "    \n",
    "netG.to('cuda')  \n",
    "netD.to('cuda')  \n",
    "\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     24
    ]
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "class Vgg19(torch.nn.Module):\n",
    "    def __init__(self, requires_grad=False):\n",
    "        super(Vgg19, self).__init__()\n",
    "        vgg_pretrained_features = models.vgg19(pretrained=True).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        self.slice5 = torch.nn.Sequential()\n",
    "        for x in range(2):\n",
    "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(2, 7):\n",
    "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(7, 12):\n",
    "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(12, 21):\n",
    "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(21, 30):\n",
    "            self.slice5.add_module(str(x), vgg_pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        h_relu1 = self.slice1(X)\n",
    "        h_relu2 = self.slice2(h_relu1)        \n",
    "        h_relu3 = self.slice3(h_relu2)        \n",
    "        h_relu4 = self.slice4(h_relu3)        \n",
    "        h_relu5 = self.slice5(h_relu4)                \n",
    "        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]\n",
    "        return out\n",
    "\n",
    "    \n",
    "class VGGLoss(torch.nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(VGGLoss, self).__init__()        \n",
    "        self.vgg = Vgg19().to(device)\n",
    "        self.criterion = torch.nn.L1Loss()\n",
    "        self.weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]        \n",
    "\n",
    "    def forward(self, x, y):              \n",
    "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
    "        loss = 0\n",
    "        for i in range(len(x_vgg)):\n",
    "            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "L1_loss            = torch.nn.L1Loss()\n",
    "Perceptual_loss    = VGGLoss(device='cuda')\n",
    "\n",
    "learning_rate = 2e-4\n",
    "max_epochs = 1000\n",
    "\n",
    "# Optimizer 설정하기\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "def lambda_rule(epoch, start_decay_epoch=50, total_epoch=max_epochs):\n",
    "    lr = 1.0 - max(0, epoch - start_decay_epoch) / float(total_epoch)\n",
    "    return lr\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
    "\n",
    "scheduler.load_state_dict(checkpoint['scheduler_G'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그밖에 부수적인 functions 설정하기\n",
    "fn_tonumpy        = lambda x: x.cpu().detach().numpy().transpose(0, 2, 3, 1)\n",
    "fn_denorm         = lambda x: (x * 0.5) + 0.5\n",
    "fn_denorm_window  = visual_windowing\n",
    "fn_defft          = visual_windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "\n",
    "## 네트워크 학습시키기\n",
    "epoch_num = max_epochs\n",
    "val_interval = 5\n",
    "\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "\n",
    "writer = SummaryWriter(log_dir='/workspace/sunggu/4.Dose_img2img/runs/Unet_with_perceptual_FFT_experiment2')\n",
    "root_dir = '/workspace/sunggu/4.Dose_img2img/model/Unet_with_perceptual_FFT_experiment2/'\n",
    "\n",
    "low2high_png_dir = '/workspace/sunggu/4.Dose_img2img/Predictions/png/'+'Unet_with_perceptual_FFT_experiment2'+'/low2high/'\n",
    "\n",
    "# 모델 save폴더 만들기\n",
    "os.makedirs(root_dir, mode=0o777, exist_ok=True)\n",
    "os.makedirs(low2high_png_dir, mode=0o777, exist_ok=True)\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch}/{epoch_num}\")\n",
    "    \n",
    "    # Model 선언\n",
    "    model.train()    \n",
    "    \n",
    "    # Loss 선언    \n",
    "    loss_total_train = []\n",
    "    loss_fm_train    = []\n",
    "#     loss_vgg_train   = []    \n",
    "        \n",
    "    train_iterator = tqdm(train_loader, desc='Train', file=sys.stdout)    \n",
    "    for batch_data in train_iterator:\n",
    "        \n",
    "        input_low  = batch_data['low'].to(device)\n",
    "        input_high = batch_data['high'].to(device)\n",
    "        \n",
    "        # Generate fake\n",
    "        output = model(input_low)    \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Loss \n",
    "        loss = L1_loss(output, input_high)\n",
    "#         loss2 = Perceptual_loss(output.repeat(1,3,1,1), input_high.repeat(1,3,1,1)) * 10\n",
    "\n",
    "#         loss     = loss1 + loss2\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 기록        \n",
    "        loss_total_train  += [loss.item()]\n",
    "#         loss_fm_train     += [loss1.item()]\n",
    "#         loss_vgg_train    += [loss2.item()]\n",
    "\n",
    "        \n",
    "    print( \"Loss       [Total Loss]    = %.4f\" %np.mean(loss_total_train) ) \n",
    "    print( \"Loss       [FM    Loss]    = %.4f\" %np.mean(loss_fm_train) ) \n",
    "#     print( \"Loss       [VGG   Loss]    = %.4f\" %np.mean(loss_vgg_train) ) \n",
    "    \n",
    "    # Tensorboard 저장하기\n",
    "    output = output.permute(0, 2, 3, 1).contiguous()\n",
    "    fshift = torch.view_as_complex(output)\n",
    "    output = torch_dfft(fshift)\n",
    "    output = output.unsqueeze(1)\n",
    "    \n",
    "    input_low   = fn_denorm_window(fn_tonumpy((input_low)))\n",
    "    input_high  = fn_denorm_window(fn_tonumpy((input_high)))\n",
    "    output      = fn_denorm_window(fn_tonumpy((output)))\n",
    "\n",
    "    input_low   = np.clip(input_low, a_min=0, a_max=1)\n",
    "    input_high  = np.clip(input_high, a_min=0, a_max=1)\n",
    "    output      = np.clip(output, a_min=0, a_max=1)\n",
    "\n",
    "    # png Save\n",
    "#     plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_input_low.png',   input_low[0].squeeze(),   cmap=\"gray\")\n",
    "    plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_output_high.png', output[0].squeeze(),      cmap=\"gray\")\n",
    "    plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_ground_high.png', input_high[0].squeeze(),  cmap=\"gray\")\n",
    "    \n",
    "    # Loss Write    \n",
    "    writer.add_scalar('Train/loss_total',  np.mean(loss_total_train), epoch)\n",
    "    writer.add_scalar('Train/loss_fm',   np.mean(loss_fm_train), epoch)\n",
    "#     writer.add_scalar('Train/loss_vgg',  np.mean(loss_vgg_train), epoch)\n",
    "    \n",
    "    # 저장\n",
    "    if epoch % 5 == 0 or epoch == epoch_num:\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            checkpoint = {'epoch': epoch, \n",
    "                          'model_state_dict': model.module.state_dict(), \n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'scheduler': scheduler.state_dict(),\n",
    "                         }                    \n",
    "\n",
    "        else:\n",
    "            checkpoint = {'epoch': epoch, \n",
    "                          'model_state_dict': model.state_dict(), \n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'scheduler': scheduler.state_dict(),\n",
    "                         }                         \n",
    "\n",
    "            torch.save(checkpoint, os.path.join(root_dir, \"epoch_\" + str(epoch) + \"_model.pth\"))        \n",
    "    \n",
    "        \n",
    "    # Scheduler\n",
    "    writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch)\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    lr     = optimizer.param_groups[0]['lr']\n",
    "    print('Learning Rate %.10f -> %.10f' % (old_lr, lr))\n",
    "    scheduler.step()     \n",
    "    \n",
    "writer.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_input_low.png',   input_low[0].squeeze(),   cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_low[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output      = fn_denorm_window(fn_tonumpy((output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fshift.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch_dfft(fshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Tensorboard 저장하기\n",
    "    output = output.permute(0, 2, 3, 1).contiguous()\n",
    "    fshift = torch.view_as_complex(output)\n",
    "    output = torch_dfft(fshift)\n",
    "    \n",
    "    input_low   = fn_denorm_window(fn_tonumpy((input_low)))\n",
    "    input_high  = fn_denorm_window(fn_tonumpy((input_high)))\n",
    "    output      = fn_denorm_window(fn_tonumpy((output)))\n",
    "\n",
    "    input_low   = np.clip(input_low, a_min=0, a_max=1)\n",
    "    input_high  = np.clip(input_high, a_min=0, a_max=1)\n",
    "    output      = np.clip(output, a_min=0, a_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        output = model(input_low)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fshift = torch.view_as_complex(output)\n",
    "output = torch_dfft(fshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fshift = torch.view_as_complex(output.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#     with torch.no_grad():\n",
    "#         netG.eval()\n",
    "#         netD.eval()\n",
    "\n",
    "#         loss_G_gan_valid  = []\n",
    "#         loss_G_L1_valid   = []\n",
    "#         loss_D_real_valid = []\n",
    "#         loss_D_fake_valid = []\n",
    "        \n",
    "#         valid_iterator = tqdm(valid_loader, desc='Valid', file=sys.stdout)    \n",
    "#         for batch_data in valid_iterator:\n",
    "        \n",
    "#             input_low  = batch_data['low'].to(device)\n",
    "#             input_high = batch_data['high'].to(device)\n",
    "            \n",
    "#             output = netG(input_low)\n",
    "\n",
    "#             real = torch.cat([input_low, input_high], dim=1)\n",
    "#             fake = torch.cat([input_low, output], dim=1)      \n",
    "            \n",
    "#             # D\n",
    "#             pred_real = netD(real)        \n",
    "#             pred_fake = netD(fake.detach())\n",
    "\n",
    "#             loss_D_real = gan_loss(pred_real, torch.ones_like(pred_real))\n",
    "#             loss_D_fake = gan_loss(pred_fake, torch.zeros_like(pred_fake))\n",
    "\n",
    "#             # G\n",
    "#             pred_fake = netD(fake)        \n",
    "            \n",
    "#             loss_G_gan = gan_loss(pred_fake, torch.ones_like(pred_fake))\n",
    "#             loss_G_L1  = L1_loss(output, input_high)\n",
    "\n",
    "#             # 기록\n",
    "#             loss_D_real_valid += [loss_D_real.item()]\n",
    "#             loss_D_fake_valid += [loss_D_fake.item()]\n",
    "#             loss_G_gan_valid  += [loss_G_gan.item()]\n",
    "#             loss_G_L1_valid   += [loss_G_L1.item()]\n",
    "        \n",
    "        \n",
    "#     print( \"Generator Loss       [Gan Loss]    = %.4f\" %np.mean(loss_G_gan_valid) ) \n",
    "#     print( \"Generator Loss       [L1  Loss]    = %.4f\" %np.mean(loss_G_L1_valid) ) \n",
    "#     print( \"Discriminator Loss   [Real]        = %.4f\" %np.mean(loss_D_real_valid) )\n",
    "#     print( \"Discriminator Loss   [Fake]        = %.4f\" %np.mean(loss_D_fake_valid) )\n",
    "\n",
    "    \n",
    "#     # Tensorboard 저장하기\n",
    "#     input_low   = fn_denorm(fn_tonumpy((input_low)))\n",
    "#     input_high  = fn_denorm(fn_tonumpy((input_high)))\n",
    "#     output = fn_denorm(fn_tonumpy((output)))\n",
    "\n",
    "#     input_low   = np.clip(input_low, a_min=0, a_max=1)\n",
    "#     input_high  = np.clip(input_high, a_min=0, a_max=1)\n",
    "#     output = np.clip(output, a_min=0, a_max=1)\n",
    "\n",
    "#     # png Save\n",
    "#     plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_input_low.png',   input_low[0].squeeze(),   cmap=\"gray\")\n",
    "#     plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_output_high.png', output[0].squeeze(), cmap=\"gray\")\n",
    "#     plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_ground_high.png', input_high[0].squeeze(),  cmap=\"gray\")\n",
    "    \n",
    "#     # Loss Write    \n",
    "#     writer.add_scalar('Valid/loss_G_gan',  np.mean(loss_G_gan_valid), epoch)\n",
    "#     writer.add_scalar('Valid/loss_G_L1',   np.mean(loss_G_L1_valid), epoch)\n",
    "#     writer.add_scalar('Valid/loss_D_real', np.mean(loss_D_real_valid), epoch)\n",
    "#     writer.add_scalar('Valid/loss_D_fake', np.mean(loss_D_fake_valid), epoch)\n",
    "\n",
    "    \n",
    "#     # 저장\n",
    "#     if epoch % 5 == 0 or epoch == epoch_num:\n",
    "\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             checkpoint = {'epoch': epoch, \n",
    "#                           'netG_state_dict': netG.module.state_dict(), \n",
    "#                           'netD_state_dict': netD.module.state_dict(), \n",
    "#                           'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "#                           'optimizer_D_state_dict': optimizer_D.state_dict(),  \n",
    "#                           'scheduler_G': scheduler_G.state_dict(),\n",
    "#                           'scheduler_D': scheduler_D.state_dict(),\n",
    "#                          }                    \n",
    "\n",
    "#         else:\n",
    "#             checkpoint = {'epoch': epoch, \n",
    "#                           'netG_state_dict': netG.state_dict(), \n",
    "#                           'netD_state_dict': netD.state_dict(), \n",
    "#                           'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "#                           'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "#                           'scheduler_G': scheduler_G.state_dict(),\n",
    "#                           'scheduler_D': scheduler_D.state_dict(),\n",
    "#                          }                         \n",
    "\n",
    "#             torch.save(checkpoint, os.path.join(root_dir, \"epoch_\" + str(epoch) + \"_model.pth\"))        \n",
    "    \n",
    "#     # Scheduler\n",
    "#     writer.add_scalar('lr', optimizer_G.param_groups[0]['lr'], epoch)      \n",
    "#     old_lr = optimizer_G.param_groups[0]['lr']\n",
    "#     lr = optimizer_G.param_groups[0]['lr']\n",
    "#     print('Learning Rate %.10f -> %.10f' % (old_lr, lr))\n",
    "\n",
    "#     scheduler_G.step()    \n",
    "#     scheduler_D.step()    \n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_network(net, name='network'):\n",
    "    \"\"\"Calculate and print the mean of average absolute(gradients)\n",
    "    Parameters:\n",
    "        net (torch network) -- Torch network\n",
    "        name (str) -- the name of the network\n",
    "    \"\"\"\n",
    "    mean = 0.0\n",
    "    count = 0\n",
    "    for param in net.parameters():\n",
    "        if param.grad is not None:\n",
    "            mean += torch.mean(torch.abs(param.grad.data))\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        mean = mean / count\n",
    "    print(name)\n",
    "    print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223.016px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
