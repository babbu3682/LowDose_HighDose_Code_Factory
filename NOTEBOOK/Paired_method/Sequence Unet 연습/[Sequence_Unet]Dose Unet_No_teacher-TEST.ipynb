{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE -> MAE Loss 꿀팁!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/MONAI'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/4.Dose_img2img'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/4.Dose_img2img/utils'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/4.Dose_img2img/module'))\n",
    "\n",
    "from sunggu_utils import check_value, take_list, plot_confusion_matrix, list_sort_nicely, find_dir, plot_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import skimage\n",
    "import monai\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, GeneralizedDiceLoss, FocalLoss, TverskyLoss\n",
    "from monai.metrics import compute_meandice, DiceMetric, ConfusionMatrixMetric \n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet, highresnet\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadNiftid,\n",
    "    LoadNumpyd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandFlipd,\n",
    "    Lambdad,\n",
    "    ToTensord,\n",
    "    CastToTyped,\n",
    "    DeleteItemsd,\n",
    "    AsDiscrete,\n",
    "    SpatialPadd,\n",
    "    CenterSpatialCropd,\n",
    "    RandSpatialCropd,\n",
    "    Resized,\n",
    ")\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 시드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "set_determinism(seed=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_low_images      = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_NPY/Test/*/20/*/*/*.npy'))\n",
    "test_high_images     = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_NPY/Test/*/X/*/*/*.npy'))\n",
    "\n",
    "dcm_test_low_images  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Test/*/20/*/*/*.dcm'))\n",
    "dcm_test_high_images = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Test/*/X/*/*/*.dcm'))\n",
    "\n",
    "test_files = [{\"low\": low_name, \"high\": high_name, \"dcm_low\" : dcm_low, \"dcm_high\" : dcm_high} for low_name, high_name, dcm_low, dcm_high in zip(test_low_images,\n",
    "                                                                                                                                              test_high_images, \n",
    "                                                                                                                                              dcm_test_low_images, \n",
    "                                                                                                                                              dcm_test_high_images)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def MinMax_Normalize(x):\n",
    "    x -= x.min()\n",
    "    x /= x.max()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CT에 맞는 Augmentation\n",
    "from torchvision import transforms\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadNumpyd(keys=[\"low\", \"high\"]),\n",
    "        AddChanneld(keys=[\"low\", \"high\"]), \n",
    "        ToTensord(keys=[\"low\", \"high\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def visual_windowing_V2(x):\n",
    "    x = np.clip(x, a_min=0.250, a_max=0.270)\n",
    "    x -= x.min()\n",
    "    x /= x.max()  \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "# check_loader = DataLoader(check_ds, batch_size=1, shuffle=False)\n",
    "# check_data = next(iter(check_loader))\n",
    "\n",
    "check_data = check_ds[142]\n",
    "\n",
    "n_20 = (check_data[\"low\"][0])\n",
    "high = (check_data[\"high\"][0])\n",
    "print(f\"image shape: {n_20.shape}\")\n",
    "\n",
    "plt.figure(\"check\", (16, 12))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"low\")\n",
    "plt.imshow(visual_windowing_V2(n_20), cmap=\"gray\")\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"high\")\n",
    "plt.imshow(visual_windowing_V2(high), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())\n",
    "\n",
    "# Cachedataset 이거 뭔가 문제가 있음...\n",
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=8, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer  Only Low -> High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Unet_sunggu.model import Enhance_UNet\n",
    "\n",
    "class Seqeunce_UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seqeunce_UNet, self).__init__()        \n",
    "        self.unet = Enhance_UNet(input_nc=1, output_nc=1)\n",
    "\n",
    "    def forward(self, noise_20):\n",
    "        # noise 20이 noise 40보다 더 noise가 심함.\n",
    "        pred_noise_40, feat_n_40 = self.unet(noise_20)\n",
    "        pred_noise_60, feat_n_60 = self.unet(pred_noise_40)\n",
    "        pred_noise_80, feat_n_80 = self.unet(pred_noise_60)\n",
    "        pred_high,     feat_high = self.unet(pred_noise_80)\n",
    "        \n",
    "        return pred_noise_40, pred_noise_60, pred_noise_80, pred_high\n",
    "\n",
    "device = 'cuda'\n",
    "model  = Seqeunce_UNet()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 이어서 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 불러오기\n",
    "checkpoint_dir = '/workspace/sunggu/4.Dose_img2img/model/[Sequence_Unet]Dose Unet_No_teacher/epoch_130_model.pth'\n",
    "checkpoint = torch.load(checkpoint_dir)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "print(epoch)\n",
    "model.eval()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그밖에 부수적인 functions 설정하기\n",
    "fn_tonumpy        = lambda x: x.cpu().detach().numpy().transpose(0, 2, 3, 1)\n",
    "fn_denorm_window  = visual_windowing_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_preprocessing(x):\n",
    "    x = (4095.0)*x - 1024.0\n",
    "    return x\n",
    "\n",
    "def return_preprocessing_for_dcm(x): # pydicom에 자동으로 -1024를 해주는 부분이 있어서?\n",
    "    x = (4095.0)*x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "\n",
    "def save_dicom(original_dcm_path, np_img, save_path):\n",
    "    dcm = dcmread(original_dcm_path)\n",
    "    \n",
    "    print(np_img.max(), np_img.min(), np_img.dtype)\n",
    "    \n",
    "    dcm.PixelData = np_img.astype('uint16').squeeze().tobytes()\n",
    "    \n",
    "    dcm.save_as(save_path)\n",
    "    print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_low2high_save_folder = '/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/test_Sequence_no_teacher_epoch_'+str(epoch) + '/low2high/'\n",
    "test_low2high_png_folder  = '/workspace/sunggu/4.Dose_img2img/Predictions/Test/png/test_Sequence_no_teacher_epoch_'+str(epoch) + '/low2high/'\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Model 선언\n",
    "#     model.eval()\n",
    "    model.train()\n",
    "\n",
    "    test_iterator = tqdm(test_loader, desc='Test', file=sys.stdout)    \n",
    "    for batch_data in test_iterator:\n",
    "\n",
    "        os.makedirs(test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[7], mode=0o777, exist_ok=True)\n",
    "        os.makedirs(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[7], mode=0o777, exist_ok=True)\n",
    "        \n",
    "        # forward pass\n",
    "        input_low  = batch_data['low'].to(device)\n",
    "        input_high = batch_data['high'].to(device)\n",
    "        \n",
    "        # Forward Generator\n",
    "        pred_noise_40, pred_noise_60, pred_noise_80, pred_high = model(input_low)\n",
    "\n",
    "        # 저장하기\n",
    "        input_low_dcm       = fn_tonumpy(return_preprocessing_for_dcm(input_low))\n",
    "        input_high_dcm      = fn_tonumpy(return_preprocessing_for_dcm(input_high))\n",
    "        pred_noise_40_dcm   = fn_tonumpy(return_preprocessing_for_dcm(pred_noise_40))\n",
    "        pred_noise_60_dcm   = fn_tonumpy(return_preprocessing_for_dcm(pred_noise_60))\n",
    "        pred_noise_80_dcm   = fn_tonumpy(return_preprocessing_for_dcm(pred_noise_80))\n",
    "        pred_high_dcm       = fn_tonumpy(return_preprocessing_for_dcm(pred_high))\n",
    "\n",
    "        save_dicom(batch_data['dcm_low'][0],  input_low_dcm,   test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[7]+'/gt_low_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "        save_dicom(batch_data['dcm_high'][0], input_high_dcm,  test_low2high_save_folder+batch_data['dcm_high'][0].split('/')[7]+'/gt_high_' +batch_data['dcm_high'][0].split('/')[-1])\n",
    "        \n",
    "        save_dicom(batch_data['dcm_low'][0],  pred_noise_40_dcm, test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[7]+'/pred_n_40_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "        save_dicom(batch_data['dcm_low'][0],  pred_noise_60_dcm, test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[7]+'/pred_n_60_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "        save_dicom(batch_data['dcm_low'][0],  pred_noise_80_dcm, test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[7]+'/pred_n_80_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "        save_dicom(batch_data['dcm_low'][0],  pred_high_dcm, test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[7]+'/pred_n_100_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "        \n",
    "        # png Save\n",
    "        input_low     = fn_denorm_window(fn_tonumpy((input_low)))\n",
    "        input_high    = fn_denorm_window(fn_tonumpy((input_high)))\n",
    "        pred_noise_40 = fn_denorm_window(fn_tonumpy((pred_noise_40)))\n",
    "        pred_noise_60 = fn_denorm_window(fn_tonumpy((pred_noise_60)))\n",
    "        pred_noise_80 = fn_denorm_window(fn_tonumpy((pred_noise_80)))\n",
    "        pred_high     = fn_denorm_window(fn_tonumpy((pred_high)))\n",
    "\n",
    "        input_low       = np.clip(input_low, a_min=0, a_max=1)\n",
    "        input_high      = np.clip(input_high, a_min=0, a_max=1)\n",
    "        pred_noise_40   = np.clip(pred_noise_40, a_min=0, a_max=1)\n",
    "        pred_noise_60   = np.clip(pred_noise_60, a_min=0, a_max=1)\n",
    "        pred_noise_80   = np.clip(pred_noise_80, a_min=0, a_max=1)\n",
    "        pred_high       = np.clip(pred_high, a_min=0, a_max=1)\n",
    "        \n",
    "        \n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[7]+'/gt_low_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   input_low[0].squeeze(),   cmap=\"gray\")\n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_high'][0].split('/')[7]+'/gt_high_' +batch_data['dcm_high'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   input_high[0].squeeze(),   cmap=\"gray\")\n",
    "        \n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[7]+'/pred_n_40_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   pred_noise_40[0].squeeze(),   cmap=\"gray\")        \n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[7]+'/pred_n_60_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   pred_noise_60[0].squeeze(),   cmap=\"gray\")    \n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[7]+'/pred_n_80_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   pred_noise_80[0].squeeze(),   cmap=\"gray\")    \n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[7]+'/pred_n_100_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   pred_high[0].squeeze(),   cmap=\"gray\")            \n",
    "                \n",
    "                                     \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_network(net, name='network'):\n",
    "    \"\"\"Calculate and print the mean of average absolute(gradients)\n",
    "    Parameters:\n",
    "        net (torch network) -- Torch network\n",
    "        name (str) -- the name of the network\n",
    "    \"\"\"\n",
    "    mean = 0.0\n",
    "    count = 0\n",
    "    for param in net.parameters():\n",
    "        if param.grad is not None:\n",
    "            mean += torch.mean(torch.abs(param.grad.data))\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        mean = mean / count\n",
    "    print(name)\n",
    "    print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN image Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pred dcm 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_dcm_low_images  = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/goto_sinogram/brain/*/n*50/b40f/*/Brain*B40f_3.0*/*.dcm\"))\n",
    "# real_dcm_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/goto_sinogram/brain/*/n*100/b40f/*/Brain*B40f_3.0*/*.dcm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"test_Unet_L1_epoch_995\"\n",
    "dcm_low_images   = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/\"+model_dir+\"/low2high/*/gt_low*.dcm\"))\n",
    "dcm_high_images  = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/\"+model_dir+\"/low2high/*/gt_high*.dcm\"))\n",
    "pred_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/\"+model_dir+\"/low2high/*/pred*.dcm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CT_12bit_processing(x):\n",
    "    # H, W, D\n",
    "    x[x < -1024.0] = -1024.0\n",
    "    x[x > 3072.0] = 3072.0\n",
    "    x = (x + 1024.0) / 4095.0\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pydicom import dcmread\n",
    "import SimpleITK as sitk\n",
    "\n",
    "gt_tp_list   =[]\n",
    "pred_tp_list =[]\n",
    "input_tp_list =[]\n",
    "\n",
    "for dcm_high_path, pred_high_path, input_path in tqdm(zip(dcm_high_images, pred_high_images, dcm_low_images)):\n",
    "    \n",
    "    np_gt_H    = sitk.GetArrayFromImage(sitk.ReadImage(dcm_high_path))\n",
    "    np_pred_H  = sitk.GetArrayFromImage(sitk.ReadImage(pred_high_path))\n",
    "    np_input_L = sitk.GetArrayFromImage(sitk.ReadImage(input_path))\n",
    "    \n",
    "    np_gt_H    = CT_12bit_processing(np_gt_H)\n",
    "    np_pred_H  = CT_12bit_processing(np_pred_H)\n",
    "    np_input_L = CT_12bit_processing(np_input_L)\n",
    "    \n",
    "    tp_gt_H   = torch.from_numpy(np_gt_H)\n",
    "    tp_pred_H = torch.from_numpy(np_pred_H)  # 1, 512, 512\n",
    "    tp_pred_L = torch.from_numpy(np_input_L)  # 1, 512, 512\n",
    "    \n",
    "    gt_tp_list.append(tp_gt_H)\n",
    "    pred_tp_list.append(tp_pred_H)\n",
    "    input_tp_list.append(tp_pred_L)\n",
    "    \n",
    "gt_zip    = torch.stack(gt_tp_list, dim=0)\n",
    "pred_zip  = torch.stack(pred_tp_list, dim=0)\n",
    "input_zip = torch.stack(input_tp_list, dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: Tensor with shape 2D (H, W), 3D (C, H, W), 4D (N, C, H, W) or 5D (N, C, H, W, 2).\n",
    "# y: Tensor with shape 2D (H, W), 3D (C, H, W), 4D (N, C, H, W) or 5D (N, C, H, W, 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piq\n",
    "\n",
    "prediction  = pred_zip\n",
    "target      = gt_zip\n",
    "input       = input_zip\n",
    "\n",
    "# To compute SSIM index as a measure, use lower case function from the library:\n",
    "ssim_index = piq.ssim(prediction, target, data_range=1.0)\n",
    "# In order to use SSIM as a loss function, use corresponding PyTorch module:\n",
    "ssim_loss = piq.SSIMLoss(data_range=1.0)(prediction, target)\n",
    "print(f\"model SSIM index: {ssim_index.item():0.4f}, loss: {ssim_loss.item():0.4f}\")\n",
    "\n",
    "# To compute SSIM index as a measure, use lower case function from the library:\n",
    "ssim_index = piq.ssim(input, target, data_range=1.0)\n",
    "# In order to use SSIM as a loss function, use corresponding PyTorch module:\n",
    "ssim_loss: torch.Tensor = piq.SSIMLoss(data_range=1.0)(input, target)\n",
    "print(f\"Input SSIM index: {ssim_index.item():0.4f}, loss: {ssim_loss.item():0.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piq\n",
    "\n",
    "# To compute PSNR as a measure, use lower case function from the library.\n",
    "psnr_index = piq.psnr(prediction, target, data_range=1.0, reduction='none')\n",
    "print(f\"model PSNR index: {psnr_index.mean():0.4f}\")\n",
    "\n",
    "# To compute PSNR as a measure, use lower case function from the library.\n",
    "psnr_index = piq.psnr(input, target, data_range=1.0, reduction='none')\n",
    "print(f\"Input PSNR index: {psnr_index.mean():0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다시 PSNR 수정!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_PSNR(x):\n",
    "    peak_pixel = x.max()\n",
    "    patch_air  = x.squeeze()[30:60, 250:280]\n",
    "    score = 10*np.log10( peak_pixel ** 2 / np.var(patch_air.flatten()))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydicom import dcmread\n",
    "import SimpleITK as sitk\n",
    "\n",
    "gt_H_list   =[]\n",
    "pred_H_list =[]\n",
    "input_L_list =[]\n",
    "\n",
    "for dcm_high_path, pred_high_path, input_path in tqdm(zip(dcm_high_images, pred_high_images, dcm_low_images)):\n",
    "    \n",
    "    np_gt_H    = sitk.GetArrayFromImage(sitk.ReadImage(dcm_high_path))\n",
    "    np_pred_H  = sitk.GetArrayFromImage(sitk.ReadImage(pred_high_path))\n",
    "    np_input_L = sitk.GetArrayFromImage(sitk.ReadImage(input_path))\n",
    "    \n",
    "    gt_H_list    = cal_PSNR(np_gt_H)\n",
    "    pred_H_list  = cal_PSNR(np_pred_H)\n",
    "    input_L_list = cal_PSNR(np_input_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(gt_H_list))\n",
    "print(np.mean(pred_H_list))\n",
    "print(np.mean(input_L_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def MSE(inputs, target):\n",
    "    mse  = np.mean( (inputs - target) ** 2 )\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydicom import dcmread\n",
    "import SimpleITK as sitk\n",
    "\n",
    "pred_high_mse_list   =[]\n",
    "input_high_mse_list    =[]\n",
    "\n",
    "for dcm_high_path, pred_high_path, input_path in tqdm(zip(dcm_high_images, pred_high_images, dcm_low_images)):\n",
    "    \n",
    "    np_gt_H    = sitk.GetArrayFromImage(sitk.ReadImage(dcm_high_path))\n",
    "    np_pred_H  = sitk.GetArrayFromImage(sitk.ReadImage(pred_high_path))\n",
    "    np_input_L = sitk.GetArrayFromImage(sitk.ReadImage(input_path))\n",
    "\n",
    "    pred_high_mse    = MSE(np_gt_H, np_pred_H)\n",
    "    input_high_mse   = MSE(np_gt_H, np_input_L)\n",
    "    \n",
    "    pred_high_mse_list.append(pred_high_mse)\n",
    "    input_high_mse_list.append(input_high_mse)\n",
    "    \n",
    "print(f\"Model MSE = {np.mean(pred_high_mse_list):0.4f}\")\n",
    "print()\n",
    "print(f\"Input MSE = {np.mean(input_high_mse_list):0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 42\n",
    "np_gt_H    = sitk.GetArrayFromImage(sitk.ReadImage(dcm_high_images[i]))\n",
    "np_pred_H  = sitk.GetArrayFromImage(sitk.ReadImage(pred_high_images[i]))\n",
    "np_input_L = sitk.GetArrayFromImage(sitk.ReadImage(dcm_low_images[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_high_images[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_window(x):\n",
    "    x = np.clip(x, a_min=0.250, a_max=0.270)\n",
    "    x -= x.min()\n",
    "    x /= x.max()  \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(131)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_input_L[0])), 'gray')\n",
    "plt.title(\"Input Low\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"Input High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_pred_H[0])), 'gray')\n",
    "plt.title(\"Model High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/model_high_OT.png', pure_window(CT_12bit_processing(np_pred_H[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High vs Low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### low-high(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_input_L[0])) - pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"Low - High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_input_L[0])) - pure_window(CT_12bit_processing(np_pred_H[0])), 'gray')\n",
    "plt.title(\"Low - High(Pred)\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### high(pred) - low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_input_L[0])), 'gray')\n",
    "plt.title(\"High - Low\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_input_L[0])), 'gray')\n",
    "plt.title(\"High(Pred) - Low\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.abs(high(pred) - low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "\n",
    "img1 = np.abs(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_input_L[0])))\n",
    "img2 = np.abs(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_input_L[0])))\n",
    "\n",
    "plt.imshow(img1, 'gray')\n",
    "plt.title(\"np.abs(High - Low)\")\n",
    "plt.imsave('/workspace/sunggu/4.Dose_img2img/gt1.png', img1,   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2, 'gray')\n",
    "plt.title(\"np.abs(High(Pred) - Low)\")\n",
    "plt.imsave('/workspace/sunggu/4.Dose_img2img/pred1.png', img2,   cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIgh vs High"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### high-high(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"High - High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_pred_H[0])), 'gray')\n",
    "plt.title(\"High - High(Pred)\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### high(pred) - high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"High - High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"High(Pred) - High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.abs(high(pred) - high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "\n",
    "img1 = np.abs(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])))\n",
    "img2 = np.abs(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])))\n",
    "\n",
    "\n",
    "plt.imshow(np.abs(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0]))), 'gray')\n",
    "plt.title(\"np.abs(High - High)\")\n",
    "plt.imsave('/workspace/sunggu/4.Dose_img2img/gt1.png', img1,   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.abs(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0]))), 'gray')\n",
    "plt.title(\"np.abs(High(Pred) - High)\")\n",
    "plt.imsave('/workspace/sunggu/4.Dose_img2img/pred1.png', img2,   cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow dataset TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_low_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Brain_Dose_Follow_dataset/2D_dataset/Test/*/*Low Dose Neck*/*.npy\"))\n",
    "test_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Brain_Dose_Follow_dataset/2D_dataset/Test/*/*Neck Other*/*.npy\"))\n",
    "\n",
    "dcm_test_low_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Brain_Dose_Follow_dataset/Cleansing_dcm_dataset/Test/*/*Low Dose Neck*/*/*.dcm\"))\n",
    "dcm_test_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Brain_Dose_Follow_dataset/Cleansing_dcm_dataset/Test/*/*Neck Other*/*/*.dcm\"))\n",
    "\n",
    "test_files = [{\"low\": low_name, \"high\": high_name, \"dcm_low\" : dcm_low, \"dcm_high\" : dcm_high} for low_name, high_name, dcm_low, dcm_high in zip(test_low_images,\n",
    "                                                                                  test_high_images, \n",
    "                                                                                  dcm_test_low_images, \n",
    "                                                                                  dcm_test_high_images)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "# check_loader = DataLoader(check_ds, batch_size=1, shuffle=False)\n",
    "# check_data = next(iter(check_loader))\n",
    "\n",
    "check_data = check_ds[4]\n",
    "\n",
    "print(check_data['low_meta_dict']['filename_or_obj'])\n",
    "print(check_data['high_meta_dict']['filename_or_obj'])\n",
    "\n",
    "low = (check_data[\"low\"][0])\n",
    "high = (check_data[\"high\"][0])\n",
    "print(f\"image shape: {low.shape}\")\n",
    "print(low.max(), low.min(), low.dtype, low.shape)\n",
    "\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"low\")\n",
    "plt.imshow(visual_windowing(low), cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"high\")\n",
    "plt.imshow(visual_windowing(high), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())\n",
    "\n",
    "# Cachedataset 이거 뭔가 문제가 있음...\n",
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=16, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그밖에 부수적인 functions 설정하기\n",
    "fn_tonumpy = lambda x: x.cpu().detach().numpy().transpose(0, 2, 3, 1)\n",
    "fn_denorm  = lambda x: (x * 0.5) + 0.5\n",
    "fn_denorm_window  = visual_windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_preprocessing(x):\n",
    "    x = (4095.0)*x - 1024.0\n",
    "    return x\n",
    "\n",
    "def return_preprocessing_for_dcm(x):\n",
    "    x = (4095.0)*x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "\n",
    "def save_dicom(original_dcm_path, np_img, save_path):\n",
    "    dcm = dcmread(original_dcm_path)\n",
    "    \n",
    "    print(np_img.max(), np_img.min(), np_img.dtype)\n",
    "    \n",
    "    dcm.PixelData = np_img.astype('uint16').squeeze().tobytes()\n",
    "    \n",
    "    dcm.save_as(save_path)\n",
    "    print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_low2high_save_folder = '/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/Follow_test_Unet_L1_epoch_'+str(epoch) + '/low2high/'\n",
    "test_low2high_png_folder  = '/workspace/sunggu/4.Dose_img2img/Predictions/Test/png/Follow_test_Unet_L1_epoch_'+str(epoch) + '/low2high/'\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Model 선언\n",
    "    model.eval()\n",
    "\n",
    "    test_iterator = tqdm(test_loader, desc='Test', file=sys.stdout)    \n",
    "    for batch_data in test_iterator:\n",
    "\n",
    "        os.makedirs(test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[8], mode=0o777, exist_ok=True)\n",
    "        os.makedirs(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[8], mode=0o777, exist_ok=True)\n",
    "        \n",
    "        # forward pass\n",
    "        input_low  = batch_data['low'].to(device)\n",
    "        input_high = batch_data['high'].to(device)\n",
    "        \n",
    "        # Forward Generator\n",
    "        output_high = model(input_low)\n",
    "\n",
    "        # 저장하기\n",
    "        input_low_dcm   = fn_tonumpy(return_preprocessing_for_dcm(fn_denorm(input_low)))\n",
    "        output_high_dcm = fn_tonumpy(return_preprocessing_for_dcm(fn_denorm(output_high)))\n",
    "\n",
    "        save_dicom(batch_data['dcm_low'][0],  input_low_dcm,   test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[8]+'/gt_low_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "        save_dicom(batch_data['dcm_low'][0],  output_high_dcm, test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[8]+'/pred_high_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "\n",
    "        \n",
    "        # png Save\n",
    "        input_low   = fn_denorm_window(fn_tonumpy((input_low)))\n",
    "        output_high = fn_denorm_window(fn_tonumpy((output_high)))\n",
    "\n",
    "        input_low   = np.clip(input_low, a_min=0, a_max=1)\n",
    "        output_high = np.clip(output_high, a_min=0, a_max=1)\n",
    "        \n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[8]+'/gt_low_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   input_low[0].squeeze(),   cmap=\"gray\")\n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[8]+'/pred_high_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   output_high[0].squeeze(),   cmap=\"gray\")        \n",
    "                \n",
    "#         plt.figure(figsize=(12,12))\n",
    "#         plt.subplot(131)\n",
    "#         plt.imshow(input_low.squeeze(), 'gray')\n",
    "#         plt.subplot(132)\n",
    "#         plt.imshow(input_high.squeeze(), 'gray')\n",
    "#         plt.subplot(133)\n",
    "#         plt.imshow(output_high.squeeze(), 'gray')\n",
    "#         plt.show()\n",
    "                                     \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST\n",
    "\n",
    "## 그밖에 부수적인 functions 설정하기\n",
    "fn_tonumpy = lambda x: x.cpu().detach().numpy().transpose(0, 2, 3, 1)\n",
    "fn_denorm  = lambda x: (x * 0.5) + 0.5\n",
    "fn_denorm_window  = visual_windowing\n",
    "\n",
    "def return_preprocessing(x):\n",
    "    x = (4095.0)*x - 1024.0\n",
    "    return x\n",
    "\n",
    "def return_preprocessing_for_dcm(x):\n",
    "    x = (4095.0)*x\n",
    "    return x\n",
    "\n",
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "\n",
    "def save_dicom(original_dcm_path, np_img, save_path):\n",
    "    dcm = dcmread(original_dcm_path)\n",
    "    \n",
    "    print(np_img.max(), np_img.min(), np_img.dtype)\n",
    "    \n",
    "    dcm.PixelData = np_img.astype('uint16').squeeze().tobytes()\n",
    "    \n",
    "    dcm.save_as(save_path)\n",
    "    print(save_path)\n",
    "\n",
    "test_low2high_save_folder = '/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/test_Unet_L1_epoch_'+str(epoch) + '/low2high/'\n",
    "test_low2high_png_folder  = '/workspace/sunggu/4.Dose_img2img/Predictions/Test/png/test_Unet_L1_epoch_'+str(epoch) + '/low2high/'\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Model 선언\n",
    "    model.eval()\n",
    "\n",
    "    test_iterator = tqdm(test_loader, desc='Test', file=sys.stdout)    \n",
    "    for batch_data in test_iterator:\n",
    "\n",
    "        os.makedirs(test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[8], mode=0o777, exist_ok=True)\n",
    "        os.makedirs(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[8], mode=0o777, exist_ok=True)\n",
    "        \n",
    "        # forward pass\n",
    "        input_low  = batch_data['low'].to(device)\n",
    "        input_high = batch_data['high'].to(device)\n",
    "        \n",
    "        # Forward Generator\n",
    "        output_high = model(input_low)\n",
    "\n",
    "        # 저장하기\n",
    "#         print(input_low.min(), input_low.max())\n",
    "#         input_low[:, 128:128+256, 128:128+256, :] = 0\n",
    "        input_low_dcm   = fn_tonumpy(return_preprocessing_for_dcm(fn_denorm(input_low)))\n",
    "        input_high_dcm  = fn_tonumpy(return_preprocessing_for_dcm(fn_denorm(input_high)))\n",
    "        output_high_dcm = fn_tonumpy(return_preprocessing_for_dcm(fn_denorm(output_high)))\n",
    "\n",
    "        save_dicom(batch_data['dcm_low'][0],  input_low_dcm,   test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[8]+'/gt_low_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "        save_dicom(batch_data['dcm_high'][0], input_high_dcm,  test_low2high_save_folder+batch_data['dcm_high'][0].split('/')[8]+'/gt_high_' +batch_data['dcm_high'][0].split('/')[-1])\n",
    "        save_dicom(batch_data['dcm_low'][0],  output_high_dcm, test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[8]+'/pred_high_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "\n",
    "        \n",
    "        # png Save\n",
    "        input_low   = fn_denorm_window(fn_tonumpy((input_low)))\n",
    "        input_high  = fn_denorm_window(fn_tonumpy((input_high)))\n",
    "        output_high = fn_denorm_window(fn_tonumpy((output_high)))\n",
    "\n",
    "        input_low   = np.clip(input_low, a_min=0, a_max=1)\n",
    "        input_high  = np.clip(input_high, a_min=0, a_max=1)\n",
    "        output_high = np.clip(output_high, a_min=0, a_max=1)\n",
    "        \n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[8]+'/gt_low_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   input_low[0].squeeze(),   cmap=\"gray\")\n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_high'][0].split('/')[8]+'/gt_high_' +batch_data['dcm_high'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   input_high[0].squeeze(),   cmap=\"gray\")\n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[8]+'/pred_high_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   output_high[0].squeeze(),   cmap=\"gray\")        \n",
    "                \n",
    "#         plt.figure(figsize=(12,12))\n",
    "#         plt.subplot(131)\n",
    "#         plt.imshow(input_low.squeeze(), 'gray')\n",
    "#         plt.subplot(132)\n",
    "#         plt.imshow(input_high.squeeze(), 'gray')\n",
    "#         plt.subplot(133)\n",
    "#         plt.imshow(output_high.squeeze(), 'gray')\n",
    "#         plt.show()\n",
    "                                     \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "def diagnose_network(net, name='network'):\n",
    "    \"\"\"Calculate and print the mean of average absolute(gradients)\n",
    "    Parameters:\n",
    "        net (torch network) -- Torch network\n",
    "        name (str) -- the name of the network\n",
    "    \"\"\"\n",
    "    mean = 0.0\n",
    "    count = 0\n",
    "    for param in net.parameters():\n",
    "        if param.grad is not None:\n",
    "            mean += torch.mean(torch.abs(param.grad.data))\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        mean = mean / count\n",
    "    print(name)\n",
    "    print(mean)\n",
    "\n",
    "\n",
    "\n",
    "## GAN image Metric\n",
    "\n",
    "### Pred dcm 경로\n",
    "\n",
    "# real_dcm_low_images  = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/goto_sinogram/brain/*/n*50/b40f/*/Brain*B40f_3.0*/*.dcm\"))\n",
    "# real_dcm_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/goto_sinogram/brain/*/n*100/b40f/*/Brain*B40f_3.0*/*.dcm\"))\n",
    "\n",
    "model_dir = \"test_Unet_L1_epoch_995\"\n",
    "dcm_low_images   = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/\"+model_dir+\"/low2high/*/gt_low*.dcm\"))\n",
    "dcm_high_images  = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/\"+model_dir+\"/low2high/*/gt_high*.dcm\"))\n",
    "pred_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/\"+model_dir+\"/low2high/*/pred*.dcm\"))\n",
    "\n",
    "\n",
    "def CT_12bit_processing(x):\n",
    "    # H, W, D\n",
    "    x[x < -1024.0] = -1024.0\n",
    "    x[x > 3072.0] = 3072.0\n",
    "    x = (x + 1024.0) / 4095.0\n",
    "    \n",
    "    return x\n",
    "\n",
    "from pydicom import dcmread\n",
    "import SimpleITK as sitk\n",
    "\n",
    "gt_tp_list   =[]\n",
    "pred_tp_list =[]\n",
    "input_tp_list =[]\n",
    "\n",
    "for dcm_high_path, pred_high_path, input_path in tqdm(zip(dcm_high_images, pred_high_images, dcm_low_images)):\n",
    "    \n",
    "    np_gt_H    = sitk.GetArrayFromImage(sitk.ReadImage(dcm_high_path))\n",
    "    np_pred_H  = sitk.GetArrayFromImage(sitk.ReadImage(pred_high_path))\n",
    "    np_input_L = sitk.GetArrayFromImage(sitk.ReadImage(input_path))\n",
    "    \n",
    "    np_gt_H    = CT_12bit_processing(np_gt_H)\n",
    "    np_pred_H  = CT_12bit_processing(np_pred_H)\n",
    "    np_input_L = CT_12bit_processing(np_input_L)\n",
    "    \n",
    "    tp_gt_H   = torch.from_numpy(np_gt_H)\n",
    "    tp_pred_H = torch.from_numpy(np_pred_H)  # 1, 512, 512\n",
    "    tp_pred_L = torch.from_numpy(np_input_L)  # 1, 512, 512\n",
    "    \n",
    "    gt_tp_list.append(tp_gt_H)\n",
    "    pred_tp_list.append(tp_pred_H)\n",
    "    input_tp_list.append(tp_pred_L)\n",
    "    \n",
    "gt_zip    = torch.stack(gt_tp_list, dim=0)\n",
    "pred_zip  = torch.stack(pred_tp_list, dim=0)\n",
    "input_zip = torch.stack(input_tp_list, dim=0)\n",
    "\n",
    "\n",
    "### SSIM\n",
    "\n",
    "# x: Tensor with shape 2D (H, W), 3D (C, H, W), 4D (N, C, H, W) or 5D (N, C, H, W, 2).\n",
    "# y: Tensor with shape 2D (H, W), 3D (C, H, W), 4D (N, C, H, W) or 5D (N, C, H, W, 2).\n",
    "\n",
    "\n",
    "import piq\n",
    "\n",
    "prediction  = pred_zip\n",
    "target      = gt_zip\n",
    "input       = input_zip\n",
    "\n",
    "# To compute SSIM index as a measure, use lower case function from the library:\n",
    "ssim_index = piq.ssim(prediction, target, data_range=1.0)\n",
    "# In order to use SSIM as a loss function, use corresponding PyTorch module:\n",
    "ssim_loss = piq.SSIMLoss(data_range=1.0)(prediction, target)\n",
    "print(f\"model SSIM index: {ssim_index.item():0.4f}, loss: {ssim_loss.item():0.4f}\")\n",
    "\n",
    "# To compute SSIM index as a measure, use lower case function from the library:\n",
    "ssim_index = piq.ssim(input, target, data_range=1.0)\n",
    "# In order to use SSIM as a loss function, use corresponding PyTorch module:\n",
    "ssim_loss: torch.Tensor = piq.SSIMLoss(data_range=1.0)(input, target)\n",
    "print(f\"Input SSIM index: {ssim_index.item():0.4f}, loss: {ssim_loss.item():0.4f}\")\n",
    "\n",
    "\n",
    "### PSNR\n",
    "\n",
    "import piq\n",
    "\n",
    "# To compute PSNR as a measure, use lower case function from the library.\n",
    "psnr_index = piq.psnr(prediction, target, data_range=1.0, reduction='none')\n",
    "print(f\"model PSNR index: {psnr_index.mean():0.4f}\")\n",
    "\n",
    "# To compute PSNR as a measure, use lower case function from the library.\n",
    "psnr_index = piq.psnr(input, target, data_range=1.0, reduction='none')\n",
    "print(f\"Input PSNR index: {psnr_index.mean():0.4f}\")\n",
    "\n",
    "### 다시 PSNR 수정!\n",
    "\n",
    "def cal_PSNR(x):\n",
    "    peak_pixel = x.max()\n",
    "    patch_air  = x.squeeze()[30:60, 250:280]\n",
    "    score = 10*np.log10( peak_pixel ** 2 / np.var(patch_air.flatten()))\n",
    "    \n",
    "    return score\n",
    "\n",
    "from pydicom import dcmread\n",
    "import SimpleITK as sitk\n",
    "\n",
    "gt_H_list   =[]\n",
    "pred_H_list =[]\n",
    "input_L_list =[]\n",
    "\n",
    "for dcm_high_path, pred_high_path, input_path in tqdm(zip(dcm_high_images, pred_high_images, dcm_low_images)):\n",
    "    \n",
    "    np_gt_H    = sitk.GetArrayFromImage(sitk.ReadImage(dcm_high_path))\n",
    "    np_pred_H  = sitk.GetArrayFromImage(sitk.ReadImage(pred_high_path))\n",
    "    np_input_L = sitk.GetArrayFromImage(sitk.ReadImage(input_path))\n",
    "    \n",
    "    gt_H_list    = cal_PSNR(np_gt_H)\n",
    "    pred_H_list  = cal_PSNR(np_pred_H)\n",
    "    input_L_list = cal_PSNR(np_input_L)\n",
    "\n",
    "\n",
    "print(np.mean(gt_H_list))\n",
    "print(np.mean(pred_H_list))\n",
    "print(np.mean(input_L_list))\n",
    "\n",
    "\n",
    "\n",
    "## MSE\n",
    "\n",
    "import math\n",
    "\n",
    "def MSE(inputs, target):\n",
    "    mse  = np.mean( (inputs - target) ** 2 )\n",
    "    return mse\n",
    "\n",
    "from pydicom import dcmread\n",
    "import SimpleITK as sitk\n",
    "\n",
    "pred_high_mse_list   =[]\n",
    "input_high_mse_list    =[]\n",
    "\n",
    "for dcm_high_path, pred_high_path, input_path in tqdm(zip(dcm_high_images, pred_high_images, dcm_low_images)):\n",
    "    \n",
    "    np_gt_H    = sitk.GetArrayFromImage(sitk.ReadImage(dcm_high_path))\n",
    "    np_pred_H  = sitk.GetArrayFromImage(sitk.ReadImage(pred_high_path))\n",
    "    np_input_L = sitk.GetArrayFromImage(sitk.ReadImage(input_path))\n",
    "\n",
    "    pred_high_mse    = MSE(np_gt_H, np_pred_H)\n",
    "    input_high_mse   = MSE(np_gt_H, np_input_L)\n",
    "    \n",
    "    pred_high_mse_list.append(pred_high_mse)\n",
    "    input_high_mse_list.append(input_high_mse)\n",
    "    \n",
    "print(f\"Model MSE = {np.mean(pred_high_mse_list):0.4f}\")\n",
    "print()\n",
    "print(f\"Input MSE = {np.mean(input_high_mse_list):0.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "## Difference Map\n",
    "\n",
    "i = 42\n",
    "np_gt_H    = sitk.GetArrayFromImage(sitk.ReadImage(dcm_high_images[i]))\n",
    "np_pred_H  = sitk.GetArrayFromImage(sitk.ReadImage(pred_high_images[i]))\n",
    "np_input_L = sitk.GetArrayFromImage(sitk.ReadImage(dcm_low_images[i]))\n",
    "\n",
    "dcm_high_images[42]\n",
    "\n",
    "def pure_window(x):\n",
    "    x = np.clip(x, a_min=0.250, a_max=0.270)\n",
    "    x -= x.min()\n",
    "    x /= x.max()  \n",
    "    return x\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(131)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_input_L[0])), 'gray')\n",
    "plt.title(\"Input Low\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"Input High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_pred_H[0])), 'gray')\n",
    "plt.title(\"Model High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/model_high_OT.png', pure_window(CT_12bit_processing(np_pred_H[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### High vs Low\n",
    "\n",
    "#### low-high(pred)\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_input_L[0])) - pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"Low - High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_input_L[0])) - pure_window(CT_12bit_processing(np_pred_H[0])), 'gray')\n",
    "plt.title(\"Low - High(Pred)\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "#### high(pred) - low\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_input_L[0])), 'gray')\n",
    "plt.title(\"High - Low\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_input_L[0])), 'gray')\n",
    "plt.title(\"High(Pred) - Low\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "#### np.abs(high(pred) - low)\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "\n",
    "img1 = np.abs(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_input_L[0])))\n",
    "img2 = np.abs(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_input_L[0])))\n",
    "\n",
    "plt.imshow(img1, 'gray')\n",
    "plt.title(\"np.abs(High - Low)\")\n",
    "plt.imsave('/workspace/sunggu/4.Dose_img2img/gt1.png', img1,   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2, 'gray')\n",
    "plt.title(\"np.abs(High(Pred) - Low)\")\n",
    "plt.imsave('/workspace/sunggu/4.Dose_img2img/pred1.png', img2,   cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "### HIgh vs High\n",
    "\n",
    "#### high-high(pred)\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"High - High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_pred_H[0])), 'gray')\n",
    "plt.title(\"High - High(Pred)\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "#### high(pred) - high\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"High - High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_low.png', pure_window(CT_12bit_processing(np_input_L[0])),   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])), 'gray')\n",
    "plt.title(\"High(Pred) - High\")\n",
    "# plt.imsave('/workspace/sunggu/4.Dose_img2img/input_high.png', pure_window(CT_12bit_processing(np_gt_H[0])),   cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "#### np.abs(high(pred) - high)\n",
    "\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "\n",
    "img1 = np.abs(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])))\n",
    "img2 = np.abs(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0])))\n",
    "\n",
    "\n",
    "plt.imshow(np.abs(pure_window(CT_12bit_processing(np_gt_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0]))), 'gray')\n",
    "plt.title(\"np.abs(High - High)\")\n",
    "plt.imsave('/workspace/sunggu/4.Dose_img2img/gt1.png', img1,   cmap=\"gray\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.abs(pure_window(CT_12bit_processing(np_pred_H[0])) - pure_window(CT_12bit_processing(np_gt_H[0]))), 'gray')\n",
    "plt.title(\"np.abs(High(Pred) - High)\")\n",
    "plt.imsave('/workspace/sunggu/4.Dose_img2img/pred1.png', img2,   cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Follow dataset TEST\n",
    "\n",
    "## Set Train / Test\n",
    "\n",
    "test_low_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Brain_Dose_Follow_dataset/2D_dataset/Test/*/*Low Dose Neck*/*.npy\"))\n",
    "test_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Brain_Dose_Follow_dataset/2D_dataset/Test/*/*Neck Other*/*.npy\"))\n",
    "\n",
    "dcm_test_low_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Brain_Dose_Follow_dataset/Cleansing_dcm_dataset/Test/*/*Low Dose Neck*/*/*.dcm\"))\n",
    "dcm_test_high_images = list_sort_nicely(glob.glob(\"/workspace/sunggu/4.Dose_img2img/dataset/Brain_Dose_Follow_dataset/Cleansing_dcm_dataset/Test/*/*Neck Other*/*/*.dcm\"))\n",
    "\n",
    "test_files = [{\"low\": low_name, \"high\": high_name, \"dcm_low\" : dcm_low, \"dcm_high\" : dcm_high} for low_name, high_name, dcm_low, dcm_high in zip(test_low_images,\n",
    "                                                                                  test_high_images, \n",
    "                                                                                  dcm_test_low_images, \n",
    "                                                                                  dcm_test_high_images)]\n",
    "\n",
    "## Check transforms in DataLoader\n",
    "\n",
    "check_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "# check_loader = DataLoader(check_ds, batch_size=1, shuffle=False)\n",
    "# check_data = next(iter(check_loader))\n",
    "\n",
    "check_data = check_ds[4]\n",
    "\n",
    "print(check_data['low_meta_dict']['filename_or_obj'])\n",
    "print(check_data['high_meta_dict']['filename_or_obj'])\n",
    "\n",
    "low = (check_data[\"low\"][0])\n",
    "high = (check_data[\"high\"][0])\n",
    "print(f\"image shape: {low.shape}\")\n",
    "print(low.max(), low.min(), low.dtype, low.shape)\n",
    "\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"low\")\n",
    "plt.imshow(visual_windowing(low), cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"high\")\n",
    "plt.imshow(visual_windowing(high), cmap=\"gray\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())\n",
    "\n",
    "# Cachedataset 이거 뭔가 문제가 있음...\n",
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=16, drop_last=False)\n",
    "\n",
    "## TEST\n",
    "\n",
    "## 그밖에 부수적인 functions 설정하기\n",
    "fn_tonumpy = lambda x: x.cpu().detach().numpy().transpose(0, 2, 3, 1)\n",
    "fn_denorm  = lambda x: (x * 0.5) + 0.5\n",
    "fn_denorm_window  = visual_windowing\n",
    "\n",
    "def return_preprocessing(x):\n",
    "    x = (4095.0)*x - 1024.0\n",
    "    return x\n",
    "\n",
    "def return_preprocessing_for_dcm(x):\n",
    "    x = (4095.0)*x\n",
    "    return x\n",
    "\n",
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "\n",
    "def save_dicom(original_dcm_path, np_img, save_path):\n",
    "    dcm = dcmread(original_dcm_path)\n",
    "    \n",
    "    print(np_img.max(), np_img.min(), np_img.dtype)\n",
    "    \n",
    "    dcm.PixelData = np_img.astype('uint16').squeeze().tobytes()\n",
    "    \n",
    "    dcm.save_as(save_path)\n",
    "    print(save_path)\n",
    "\n",
    "test_low2high_save_folder = '/workspace/sunggu/4.Dose_img2img/Predictions/Test/dcm/Follow_test_Unet_L1_epoch_'+str(epoch) + '/low2high/'\n",
    "test_low2high_png_folder  = '/workspace/sunggu/4.Dose_img2img/Predictions/Test/png/Follow_test_Unet_L1_epoch_'+str(epoch) + '/low2high/'\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Model 선언\n",
    "    model.eval()\n",
    "\n",
    "    test_iterator = tqdm(test_loader, desc='Test', file=sys.stdout)    \n",
    "    for batch_data in test_iterator:\n",
    "\n",
    "        os.makedirs(test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[8], mode=0o777, exist_ok=True)\n",
    "        os.makedirs(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[8], mode=0o777, exist_ok=True)\n",
    "        \n",
    "        # forward pass\n",
    "        input_low  = batch_data['low'].to(device)\n",
    "        input_high = batch_data['high'].to(device)\n",
    "        \n",
    "        # Forward Generator\n",
    "        output_high = model(input_low)\n",
    "\n",
    "        # 저장하기\n",
    "        input_low_dcm   = fn_tonumpy(return_preprocessing_for_dcm(fn_denorm(input_low)))\n",
    "        output_high_dcm = fn_tonumpy(return_preprocessing_for_dcm(fn_denorm(output_high)))\n",
    "\n",
    "        save_dicom(batch_data['dcm_low'][0],  input_low_dcm,   test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[8]+'/gt_low_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "        save_dicom(batch_data['dcm_low'][0],  output_high_dcm, test_low2high_save_folder+batch_data['dcm_low'][0].split('/')[8]+'/pred_high_' +batch_data['dcm_low'][0].split('/')[-1])        \n",
    "\n",
    "        \n",
    "        # png Save\n",
    "        input_low   = fn_denorm_window(fn_tonumpy((input_low)))\n",
    "        output_high = fn_denorm_window(fn_tonumpy((output_high)))\n",
    "\n",
    "        input_low   = np.clip(input_low, a_min=0, a_max=1)\n",
    "        output_high = np.clip(output_high, a_min=0, a_max=1)\n",
    "        \n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[8]+'/gt_low_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   input_low[0].squeeze(),   cmap=\"gray\")\n",
    "        plt.imsave(test_low2high_png_folder+batch_data['dcm_low'][0].split('/')[8]+'/pred_high_' +batch_data['dcm_low'][0].split('/')[-1].replace('.dcm', '.png'),\n",
    "                   output_high[0].squeeze(),   cmap=\"gray\")        \n",
    "                \n",
    "#         plt.figure(figsize=(12,12))\n",
    "#         plt.subplot(131)\n",
    "#         plt.imshow(input_low.squeeze(), 'gray')\n",
    "#         plt.subplot(132)\n",
    "#         plt.imshow(input_high.squeeze(), 'gray')\n",
    "#         plt.subplot(133)\n",
    "#         plt.imshow(output_high.squeeze(), 'gray')\n",
    "#         plt.show()\n",
    "                                     \n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222.997px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
