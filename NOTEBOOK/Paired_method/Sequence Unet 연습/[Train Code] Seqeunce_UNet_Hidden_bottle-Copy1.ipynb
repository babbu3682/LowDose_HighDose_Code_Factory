{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CUDA 11.1\n",
    "# !pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE -> MAE Loss 꿀팁!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 24 11:07:40 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "| 33%   35C    P0    73W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 33%   61C    P2   269W / 260W |  40946MiB / 48601MiB |     75%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 33%   57C    P2   267W / 260W |  40410MiB / 48601MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 32%   34C    P0    60W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 8000     Off  | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   58C    P2   266W / 260W |  40446MiB / 48601MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 8000     Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "| 32%   34C    P0    61W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Quadro RTX 8000     Off  | 00000000:40:00.0 Off |                  Off |\n",
      "| 33%   58C    P2   264W / 260W |  40416MiB / 48601MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Quadro RTX 8000     Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| 32%   33C    P0    66W / 260W |      0MiB / 48601MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/sunggu/4.Dose_img2img/scripts study\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/sunggu/4.Dose_img2img/scripts study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 갯수 =  64\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seqeunce_UNet_Hidden_bottle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "***********************************************\n",
      "Dataset Name:  Sinogram\n",
      "---------- Model ----------\n",
      "Resume From:  \n",
      "Output To:  /workspace/sunggu/4.Dose_img2img/model/Seqeunce_UNet_Hidden_bottle\n",
      "Save   To:  /workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/\n",
      "---------- Optimizer ----------\n",
      "Learning Rate:  0.0002\n",
      "Weight Decay:  0.05\n",
      "Batchsize:  4\n",
      "Loading dataset ....\n",
      "Train [Total]  number =  6899\n",
      "Valid [Total]  number =  845\n",
      "Creating model: Seqeunce_UNet_Hidden_bottle\n",
      "Number of Learnable Params: 34916329\n",
      "Start training for 1000 epochs\n",
      "Train: [epoch:0]  [   0/1724]  eta: 5:07:32  lr: 0.000000  loss: 1779.3397 (1779.3397)  loss_n_40: 4.4679 (4.4679)  loss_n_60: 4.8006 (4.8006)  loss_n_80: 4.9384 (4.9384)  loss_n_100: 5.0105 (5.0105)  triple_100: 445.1714 (445.1714)  triple_80: 448.1945 (448.1945)  triple_60: 445.2329 (445.2329)  triple_40: 421.5234 (421.5234)  time: 10.7031  data: 3.2270  max mem: 46062\n",
      "Train: [epoch:0]  [  10/1724]  eta: 2:12:57  lr: 0.000000  loss: 1981.0061 (1990.2950)  loss_n_40: 4.2077 (4.1781)  loss_n_60: 4.6823 (4.5308)  loss_n_80: 4.8395 (4.6720)  loss_n_100: 4.8605 (4.7204)  triple_100: 496.1042 (498.8471)  triple_80: 498.7235 (501.4211)  triple_60: 496.0863 (498.2350)  triple_40: 471.1163 (473.6905)  time: 4.6542  data: 0.2935  max mem: 46473\n",
      "Train: [epoch:0]  [  20/1724]  eta: 2:02:04  lr: 0.000000  loss: 2012.8818 (2006.5858)  loss_n_40: 4.1949 (4.2136)  loss_n_60: 4.4789 (4.5586)  loss_n_80: 4.6083 (4.6934)  loss_n_100: 4.6626 (4.7469)  triple_100: 503.7203 (502.9186)  triple_80: 506.4340 (505.4752)  triple_60: 504.0016 (502.3111)  triple_40: 478.9103 (477.6684)  time: 3.9779  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [  30/1724]  eta: 1:57:58  lr: 0.000000  loss: 2012.8818 (2013.5157)  loss_n_40: 4.1948 (4.2084)  loss_n_60: 4.5368 (4.5779)  loss_n_80: 4.7141 (4.7157)  loss_n_100: 4.7587 (4.7617)  triple_100: 504.5898 (504.6488)  triple_80: 507.4659 (507.2994)  triple_60: 504.0016 (504.1138)  triple_40: 478.9103 (479.1900)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [  40/1724]  eta: 1:55:35  lr: 0.000000  loss: 2003.0712 (2011.1553)  loss_n_40: 4.2015 (4.2140)  loss_n_60: 4.6205 (4.5859)  loss_n_80: 4.7690 (4.7233)  loss_n_100: 4.8129 (4.7700)  triple_100: 502.4359 (504.0663)  triple_80: 505.6365 (506.7488)  triple_60: 501.7852 (503.5310)  triple_40: 474.5122 (478.5161)  time: 3.9297  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [  50/1724]  eta: 1:53:53  lr: 0.000000  loss: 2003.0712 (2011.4306)  loss_n_40: 4.2341 (4.2090)  loss_n_60: 4.6122 (4.5788)  loss_n_80: 4.7690 (4.7189)  loss_n_100: 4.8129 (4.7664)  triple_100: 502.7119 (504.1675)  triple_80: 505.6580 (506.8138)  triple_60: 501.7852 (503.5832)  triple_40: 474.5122 (478.5930)  time: 3.9330  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [  60/1724]  eta: 1:52:31  lr: 0.000000  loss: 2043.1761 (2011.5769)  loss_n_40: 4.1808 (4.2162)  loss_n_60: 4.4940 (4.5796)  loss_n_80: 4.6514 (4.7177)  loss_n_100: 4.6953 (4.7659)  triple_100: 511.0349 (504.1474)  triple_80: 513.7647 (506.7963)  triple_60: 511.5500 (503.5878)  triple_40: 484.4142 (478.7659)  time: 3.9325  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [  70/1724]  eta: 1:51:21  lr: 0.000000  loss: 2043.1761 (2015.5903)  loss_n_40: 4.2012 (4.2120)  loss_n_60: 4.4870 (4.5698)  loss_n_80: 4.6030 (4.7093)  loss_n_100: 4.6623 (4.7586)  triple_100: 513.3839 (505.1645)  triple_80: 515.9209 (507.7757)  triple_60: 511.6020 (504.5584)  triple_40: 489.3887 (479.8420)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [  80/1724]  eta: 1:50:18  lr: 0.000000  loss: 1948.2422 (2003.0029)  loss_n_40: 4.2463 (4.2232)  loss_n_60: 4.5705 (4.5809)  loss_n_80: 4.6810 (4.7209)  loss_n_100: 4.7315 (4.7701)  triple_100: 488.9221 (502.0167)  triple_80: 491.8472 (504.6396)  triple_60: 487.7315 (501.4053)  triple_40: 460.7022 (476.6461)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [  90/1724]  eta: 1:49:20  lr: 0.000000  loss: 1883.5403 (1997.5334)  loss_n_40: 4.2745 (4.2235)  loss_n_60: 4.6353 (4.5865)  loss_n_80: 4.7816 (4.7272)  loss_n_100: 4.8387 (4.7754)  triple_100: 472.1416 (500.6760)  triple_80: 475.2833 (503.3087)  triple_60: 471.6789 (500.0512)  triple_40: 444.9173 (475.1849)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 100/1724]  eta: 1:48:26  lr: 0.000000  loss: 1986.5721 (2000.3407)  loss_n_40: 4.2277 (4.2201)  loss_n_60: 4.6180 (4.5850)  loss_n_80: 4.7560 (4.7262)  loss_n_100: 4.8125 (4.7742)  triple_100: 498.5892 (501.3877)  triple_80: 501.3589 (504.0062)  triple_60: 497.7445 (500.7456)  triple_40: 469.7717 (475.8957)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 110/1724]  eta: 1:47:35  lr: 0.000000  loss: 1952.1373 (1994.3279)  loss_n_40: 4.2277 (4.2286)  loss_n_60: 4.6164 (4.5933)  loss_n_80: 4.7603 (4.7342)  loss_n_100: 4.8125 (4.7818)  triple_100: 488.6717 (499.8596)  triple_80: 491.2563 (502.4981)  triple_60: 488.5892 (499.2512)  triple_40: 463.5759 (474.3811)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 120/1724]  eta: 1:46:46  lr: 0.000000  loss: 1898.0815 (1988.1520)  loss_n_40: 4.3237 (4.2354)  loss_n_60: 4.6931 (4.6007)  loss_n_80: 4.8293 (4.7414)  loss_n_100: 4.8860 (4.7892)  triple_100: 476.0379 (498.3032)  triple_80: 478.8336 (500.9486)  triple_60: 475.2438 (497.7091)  triple_40: 449.3419 (472.8243)  time: 3.9299  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [ 130/1724]  eta: 1:45:58  lr: 0.000000  loss: 1902.8628 (1985.3782)  loss_n_40: 4.3338 (4.2388)  loss_n_60: 4.7030 (4.6052)  loss_n_80: 4.8434 (4.7461)  loss_n_100: 4.8975 (4.7935)  triple_100: 476.8989 (497.6166)  triple_80: 479.7040 (500.2656)  triple_60: 476.4285 (497.0111)  triple_40: 450.1029 (472.1013)  time: 3.9295  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [ 140/1724]  eta: 1:45:11  lr: 0.000000  loss: 1946.4417 (1986.8402)  loss_n_40: 4.2651 (4.2400)  loss_n_60: 4.5917 (4.6041)  loss_n_80: 4.7396 (4.7445)  loss_n_100: 4.7824 (4.7925)  triple_100: 488.3982 (497.9566)  triple_80: 490.8281 (500.6020)  triple_60: 487.2432 (497.3594)  triple_40: 460.6317 (472.5412)  time: 3.9290  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [ 150/1724]  eta: 1:44:25  lr: 0.000000  loss: 1988.1418 (1987.7638)  loss_n_40: 4.2427 (4.2405)  loss_n_60: 4.5897 (4.6029)  loss_n_80: 4.6952 (4.7437)  loss_n_100: 4.7338 (4.7915)  triple_100: 499.5201 (498.1892)  triple_80: 500.8133 (500.8442)  triple_60: 497.0757 (497.5928)  triple_40: 473.0513 (472.7590)  time: 3.9286  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [ 160/1724]  eta: 1:43:41  lr: 0.000000  loss: 1921.7112 (1986.6000)  loss_n_40: 4.2448 (4.2417)  loss_n_60: 4.6530 (4.6055)  loss_n_80: 4.8239 (4.7467)  loss_n_100: 4.8494 (4.7938)  triple_100: 482.0400 (497.9023)  triple_80: 485.0699 (500.5668)  triple_60: 481.3716 (497.3091)  triple_40: 454.5976 (472.4342)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 170/1724]  eta: 1:42:56  lr: 0.000000  loss: 1943.6718 (1989.4324)  loss_n_40: 4.1827 (4.2341)  loss_n_60: 4.5582 (4.5971)  loss_n_80: 4.6780 (4.7384)  loss_n_100: 4.7473 (4.7860)  triple_100: 488.3146 (498.6296)  triple_80: 491.0461 (501.2700)  triple_60: 486.9298 (498.0110)  triple_40: 458.8515 (473.1662)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 180/1724]  eta: 1:42:13  lr: 0.000000  loss: 2011.5319 (1991.2754)  loss_n_40: 4.1734 (4.2347)  loss_n_60: 4.5550 (4.5987)  loss_n_80: 4.6780 (4.7398)  loss_n_100: 4.7219 (4.7872)  triple_100: 503.6157 (499.0816)  triple_80: 506.6541 (501.7239)  triple_60: 503.7361 (498.4810)  triple_40: 478.2036 (473.6284)  time: 3.9283  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 190/1724]  eta: 1:41:29  lr: 0.000000  loss: 1970.8187 (1991.6184)  loss_n_40: 4.3214 (4.2387)  loss_n_60: 4.6028 (4.6006)  loss_n_80: 4.7522 (4.7412)  loss_n_100: 4.8278 (4.7889)  triple_100: 494.5724 (499.1472)  triple_80: 497.2220 (501.7893)  triple_60: 493.7336 (498.5596)  triple_40: 467.2474 (473.7530)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 200/1724]  eta: 1:40:46  lr: 0.000000  loss: 1943.7531 (1992.4631)  loss_n_40: 4.1516 (4.2364)  loss_n_60: 4.5410 (4.5991)  loss_n_80: 4.6909 (4.7399)  loss_n_100: 4.7315 (4.7879)  triple_100: 487.8789 (499.3810)  triple_80: 490.5901 (502.0098)  triple_60: 487.0118 (498.7772)  triple_40: 460.1770 (473.9319)  time: 3.9282  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [ 210/1724]  eta: 1:40:04  lr: 0.000000  loss: 1943.7531 (1991.6867)  loss_n_40: 4.1316 (4.2392)  loss_n_60: 4.5410 (4.6009)  loss_n_80: 4.6909 (4.7413)  loss_n_100: 4.7315 (4.7890)  triple_100: 487.8789 (499.1741)  triple_80: 490.5901 (501.8178)  triple_60: 487.0118 (498.5879)  triple_40: 460.1770 (473.7366)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 220/1724]  eta: 1:39:22  lr: 0.000000  loss: 1915.5104 (1988.6581)  loss_n_40: 4.2525 (4.2403)  loss_n_60: 4.6498 (4.6034)  loss_n_80: 4.7917 (4.7441)  loss_n_100: 4.8349 (4.7917)  triple_100: 480.0833 (498.4244)  triple_80: 482.8759 (501.0727)  triple_60: 480.0619 (497.8357)  triple_40: 453.6313 (472.9457)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 230/1724]  eta: 1:38:40  lr: 0.000000  loss: 1927.5958 (1988.6702)  loss_n_40: 4.2055 (4.2390)  loss_n_60: 4.6091 (4.6022)  loss_n_80: 4.7525 (4.7433)  loss_n_100: 4.8281 (4.7911)  triple_100: 482.2004 (498.4452)  triple_80: 485.9380 (501.0824)  triple_60: 483.2892 (497.8367)  triple_40: 456.3539 (472.9303)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 240/1724]  eta: 1:37:58  lr: 0.000000  loss: 1929.5863 (1986.1113)  loss_n_40: 4.1896 (4.2390)  loss_n_60: 4.5752 (4.6033)  loss_n_80: 4.7334 (4.7449)  loss_n_100: 4.7846 (4.7927)  triple_100: 483.7796 (497.8224)  triple_80: 486.7955 (500.4653)  triple_60: 483.2892 (497.2012)  triple_40: 457.0062 (472.2425)  time: 3.9290  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 250/1724]  eta: 1:37:17  lr: 0.000000  loss: 1945.8987 (1987.6116)  loss_n_40: 4.1896 (4.2367)  loss_n_60: 4.5752 (4.6021)  loss_n_80: 4.7276 (4.7438)  loss_n_100: 4.7846 (4.7917)  triple_100: 489.0906 (498.2027)  triple_80: 491.7456 (500.8435)  triple_60: 487.2317 (497.5785)  triple_40: 461.5798 (472.6125)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 260/1724]  eta: 1:36:35  lr: 0.000000  loss: 2033.7052 (1987.8406)  loss_n_40: 4.1841 (4.2367)  loss_n_60: 4.5511 (4.6021)  loss_n_80: 4.7202 (4.7442)  loss_n_100: 4.7625 (4.7921)  triple_100: 509.9743 (498.2676)  triple_80: 512.9749 (500.9051)  triple_60: 509.4415 (497.6311)  triple_40: 482.1692 (472.6617)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 270/1724]  eta: 1:35:54  lr: 0.000000  loss: 1971.0785 (1988.1183)  loss_n_40: 4.2196 (4.2371)  loss_n_60: 4.6495 (4.6031)  loss_n_80: 4.7937 (4.7454)  loss_n_100: 4.8439 (4.7932)  triple_100: 494.7009 (498.3390)  triple_80: 497.5276 (500.9782)  triple_60: 493.6104 (497.7035)  triple_40: 466.2719 (472.7188)  time: 3.9293  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 280/1724]  eta: 1:35:13  lr: 0.000000  loss: 1985.3962 (1987.4527)  loss_n_40: 4.3170 (4.2399)  loss_n_60: 4.6698 (4.6056)  loss_n_80: 4.8027 (4.7479)  loss_n_100: 4.8681 (4.7954)  triple_100: 496.8378 (498.1628)  triple_80: 499.3527 (500.8091)  triple_60: 496.6395 (497.5372)  triple_40: 472.9084 (472.5548)  time: 3.9293  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 290/1724]  eta: 1:34:32  lr: 0.000000  loss: 1985.3962 (1986.6300)  loss_n_40: 4.2822 (4.2405)  loss_n_60: 4.6516 (4.6052)  loss_n_80: 4.8093 (4.7474)  loss_n_100: 4.8754 (4.7952)  triple_100: 496.8378 (497.9593)  triple_80: 499.3527 (500.5969)  triple_60: 496.6395 (497.3250)  triple_40: 472.9084 (472.3605)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 300/1724]  eta: 1:33:51  lr: 0.000000  loss: 1935.1565 (1985.0651)  loss_n_40: 4.2204 (4.2397)  loss_n_60: 4.5902 (4.6057)  loss_n_80: 4.7543 (4.7481)  loss_n_100: 4.8083 (4.7960)  triple_100: 485.7036 (497.5870)  triple_80: 488.1016 (500.2245)  triple_60: 484.5042 (496.9328)  triple_40: 458.8446 (471.9314)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 310/1724]  eta: 1:33:11  lr: 0.000000  loss: 1923.0059 (1984.0945)  loss_n_40: 4.2690 (4.2406)  loss_n_60: 4.6240 (4.6076)  loss_n_80: 4.7745 (4.7501)  loss_n_100: 4.8451 (4.7980)  triple_100: 483.7177 (497.3548)  triple_80: 485.9384 (499.9915)  triple_60: 481.5214 (496.6950)  triple_40: 456.4562 (471.6568)  time: 3.9293  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 320/1724]  eta: 1:32:30  lr: 0.000000  loss: 1956.6385 (1984.2642)  loss_n_40: 4.2690 (4.2412)  loss_n_60: 4.6279 (4.6088)  loss_n_80: 4.7807 (4.7515)  loss_n_100: 4.8451 (4.7990)  triple_100: 490.3273 (497.3972)  triple_80: 493.7822 (500.0386)  triple_60: 489.9640 (496.7380)  triple_40: 463.3453 (471.6899)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 330/1724]  eta: 1:31:49  lr: 0.000000  loss: 1957.2598 (1983.6590)  loss_n_40: 4.2434 (4.2412)  loss_n_60: 4.6279 (4.6095)  loss_n_80: 4.7634 (4.7522)  loss_n_100: 4.7957 (4.7997)  triple_100: 490.8585 (497.2479)  triple_80: 493.7822 (499.8929)  triple_60: 490.2351 (496.5894)  triple_40: 463.3993 (471.5261)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 340/1724]  eta: 1:31:09  lr: 0.000000  loss: 1961.8906 (1985.1108)  loss_n_40: 4.2258 (4.2384)  loss_n_60: 4.5677 (4.6075)  loss_n_80: 4.7216 (4.7504)  loss_n_100: 4.7826 (4.7980)  triple_100: 492.6749 (497.6264)  triple_80: 495.4664 (500.2666)  triple_60: 491.5640 (496.9552)  triple_40: 464.2620 (471.8682)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 350/1724]  eta: 1:30:28  lr: 0.000000  loss: 2032.6278 (1985.2599)  loss_n_40: 4.1485 (4.2378)  loss_n_60: 4.5061 (4.6066)  loss_n_80: 4.6121 (4.7498)  loss_n_100: 4.6752 (4.7974)  triple_100: 509.3169 (497.6657)  triple_80: 511.3918 (500.3023)  triple_60: 508.5891 (496.9883)  triple_40: 484.6404 (471.9121)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 360/1724]  eta: 1:29:48  lr: 0.000000  loss: 1996.0973 (1986.8490)  loss_n_40: 4.1823 (4.2362)  loss_n_60: 4.5075 (4.6049)  loss_n_80: 4.6122 (4.7482)  loss_n_100: 4.6830 (4.7957)  triple_100: 500.0109 (498.0633)  triple_80: 502.7432 (500.6995)  triple_60: 499.8900 (497.3849)  triple_40: 474.4176 (472.3163)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 370/1724]  eta: 1:29:08  lr: 0.000000  loss: 1996.0973 (1988.1911)  loss_n_40: 4.1823 (4.2359)  loss_n_60: 4.5182 (4.6033)  loss_n_80: 4.6593 (4.7463)  loss_n_100: 4.7240 (4.7938)  triple_100: 500.0109 (498.3910)  triple_80: 502.7432 (501.0260)  triple_60: 499.8900 (497.7165)  triple_40: 474.4176 (472.6784)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 380/1724]  eta: 1:28:27  lr: 0.000000  loss: 2031.6237 (1989.3057)  loss_n_40: 4.1687 (4.2347)  loss_n_60: 4.5101 (4.6005)  loss_n_80: 4.6564 (4.7432)  loss_n_100: 4.7164 (4.7909)  triple_100: 508.3257 (498.6579)  triple_80: 510.8528 (501.2947)  triple_60: 508.0991 (497.9951)  triple_40: 484.8071 (472.9888)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 390/1724]  eta: 1:27:47  lr: 0.000000  loss: 1985.5352 (1989.1980)  loss_n_40: 4.1697 (4.2359)  loss_n_60: 4.5125 (4.6013)  loss_n_80: 4.6526 (4.7440)  loss_n_100: 4.7137 (4.7916)  triple_100: 497.2604 (498.6253)  triple_80: 499.6935 (501.2642)  triple_60: 496.7753 (497.9651)  triple_40: 473.7010 (472.9706)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 400/1724]  eta: 1:27:07  lr: 0.000000  loss: 1923.3890 (1988.8047)  loss_n_40: 4.2749 (4.2352)  loss_n_60: 4.6067 (4.5997)  loss_n_80: 4.7299 (4.7423)  loss_n_100: 4.7630 (4.7900)  triple_100: 482.1691 (498.5231)  triple_80: 485.1640 (501.1599)  triple_60: 481.6325 (497.8653)  triple_40: 455.4152 (472.8893)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 410/1724]  eta: 1:26:27  lr: 0.000000  loss: 1955.4324 (1989.0937)  loss_n_40: 4.3112 (4.2346)  loss_n_60: 4.6921 (4.5997)  loss_n_80: 4.8359 (4.7425)  loss_n_100: 4.8809 (4.7904)  triple_100: 490.4424 (498.6016)  triple_80: 493.2266 (501.2364)  triple_60: 489.4906 (497.9377)  triple_40: 463.4848 (472.9508)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 420/1724]  eta: 1:25:47  lr: 0.000000  loss: 1974.1792 (1990.4455)  loss_n_40: 4.2155 (4.2323)  loss_n_60: 4.5893 (4.5966)  loss_n_80: 4.7276 (4.7395)  loss_n_100: 4.7765 (4.7873)  triple_100: 495.6360 (498.9374)  triple_80: 498.3660 (501.5727)  triple_60: 494.5981 (498.2741)  triple_40: 467.0219 (473.3057)  time: 3.9271  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [ 430/1724]  eta: 1:25:07  lr: 0.000000  loss: 1970.5887 (1989.8873)  loss_n_40: 4.1913 (4.2328)  loss_n_60: 4.5545 (4.5967)  loss_n_80: 4.7084 (4.7395)  loss_n_100: 4.7709 (4.7875)  triple_100: 494.4446 (498.7950)  triple_80: 497.4431 (501.4313)  triple_60: 493.3724 (498.1326)  triple_40: 466.6645 (473.1718)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 440/1724]  eta: 1:24:27  lr: 0.000000  loss: 1923.0951 (1989.5005)  loss_n_40: 4.2431 (4.2333)  loss_n_60: 4.6614 (4.5981)  loss_n_80: 4.8141 (4.7410)  loss_n_100: 4.8638 (4.7889)  triple_100: 483.3161 (498.7060)  triple_80: 486.0119 (501.3430)  triple_60: 481.8960 (498.0366)  triple_40: 454.5225 (473.0538)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 450/1724]  eta: 1:23:47  lr: 0.000000  loss: 1942.5558 (1989.0678)  loss_n_40: 4.2466 (4.2343)  loss_n_60: 4.6614 (4.5988)  loss_n_80: 4.8050 (4.7417)  loss_n_100: 4.8531 (4.7897)  triple_100: 487.2858 (498.5981)  triple_80: 490.0448 (501.2358)  triple_60: 486.8203 (497.9307)  triple_40: 459.5812 (472.9388)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 460/1724]  eta: 1:23:07  lr: 0.000000  loss: 1894.3369 (1988.3605)  loss_n_40: 4.3362 (4.2363)  loss_n_60: 4.6665 (4.6008)  loss_n_80: 4.8050 (4.7439)  loss_n_100: 4.8531 (4.7917)  triple_100: 473.7327 (498.4186)  triple_80: 477.4755 (501.0574)  triple_60: 474.4068 (497.7536)  triple_40: 447.9409 (472.7581)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 470/1724]  eta: 1:22:27  lr: 0.000000  loss: 1894.3369 (1988.0331)  loss_n_40: 4.3107 (4.2378)  loss_n_60: 4.6789 (4.6019)  loss_n_80: 4.8055 (4.7448)  loss_n_100: 4.8419 (4.7924)  triple_100: 473.7327 (498.3286)  triple_80: 477.4755 (500.9715)  triple_60: 474.4068 (497.6710)  triple_40: 447.9409 (472.6850)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 480/1724]  eta: 1:21:47  lr: 0.000000  loss: 1950.5277 (1987.9946)  loss_n_40: 4.2791 (4.2390)  loss_n_60: 4.6789 (4.6033)  loss_n_80: 4.8055 (4.7459)  loss_n_100: 4.8419 (4.7936)  triple_100: 487.9249 (498.3169)  triple_80: 491.2372 (500.9626)  triple_60: 488.4072 (497.6624)  triple_40: 463.0688 (472.6709)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 490/1724]  eta: 1:21:07  lr: 0.000000  loss: 1911.0249 (1986.7138)  loss_n_40: 4.2979 (4.2408)  loss_n_60: 4.7522 (4.6058)  loss_n_80: 4.8879 (4.7485)  loss_n_100: 4.9391 (4.7960)  triple_100: 479.1481 (498.0014)  triple_80: 482.0597 (500.6478)  triple_60: 478.6162 (497.3435)  triple_40: 451.7580 (472.3299)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 500/1724]  eta: 1:20:27  lr: 0.000000  loss: 1916.6416 (1988.0850)  loss_n_40: 4.2443 (4.2392)  loss_n_60: 4.5260 (4.6031)  loss_n_80: 4.6975 (4.7457)  loss_n_100: 4.7583 (4.7934)  triple_100: 480.1049 (498.3357)  triple_80: 482.9471 (500.9802)  triple_60: 480.0203 (497.6840)  triple_40: 453.8289 (472.7038)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 510/1724]  eta: 1:19:47  lr: 0.000000  loss: 2011.1974 (1987.4079)  loss_n_40: 4.2092 (4.2399)  loss_n_60: 4.5095 (4.6034)  loss_n_80: 4.6547 (4.7459)  loss_n_100: 4.7079 (4.7936)  triple_100: 504.1061 (498.1625)  triple_80: 506.8848 (500.8070)  triple_60: 503.5959 (497.5139)  triple_40: 478.2427 (472.5415)  time: 3.9307  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 520/1724]  eta: 1:19:08  lr: 0.000000  loss: 1955.0531 (1986.8215)  loss_n_40: 4.2422 (4.2401)  loss_n_60: 4.6048 (4.6045)  loss_n_80: 4.7544 (4.7470)  loss_n_100: 4.7959 (4.7945)  triple_100: 490.0705 (498.0150)  triple_80: 493.1478 (500.6643)  triple_60: 489.6594 (497.3703)  triple_40: 463.4521 (472.3857)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 530/1724]  eta: 1:18:28  lr: 0.000000  loss: 1957.7662 (1987.5251)  loss_n_40: 4.2381 (4.2397)  loss_n_60: 4.6473 (4.6036)  loss_n_80: 4.7544 (4.7461)  loss_n_100: 4.7959 (4.7935)  triple_100: 491.3939 (498.1864)  triple_80: 494.0242 (500.8366)  triple_60: 490.3774 (497.5445)  triple_40: 463.6606 (472.5747)  time: 3.9307  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 540/1724]  eta: 1:17:48  lr: 0.000000  loss: 1960.8181 (1987.1231)  loss_n_40: 4.1913 (4.2391)  loss_n_60: 4.6428 (4.6035)  loss_n_80: 4.7706 (4.7461)  loss_n_100: 4.8117 (4.7935)  triple_100: 491.2098 (498.0904)  triple_80: 494.4903 (500.7416)  triple_60: 491.4557 (497.4467)  triple_40: 465.1827 (472.4622)  time: 3.9307  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 550/1724]  eta: 1:17:08  lr: 0.000000  loss: 1941.9683 (1986.6031)  loss_n_40: 4.2091 (4.2393)  loss_n_60: 4.6428 (4.6044)  loss_n_80: 4.7824 (4.7471)  loss_n_100: 4.8404 (4.7945)  triple_100: 487.0928 (497.9673)  triple_80: 489.7153 (500.6184)  triple_60: 486.4282 (497.3178)  triple_40: 460.5595 (472.3144)  time: 3.9297  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [ 560/1724]  eta: 1:16:29  lr: 0.000000  loss: 1938.7634 (1986.8757)  loss_n_40: 4.2835 (4.2391)  loss_n_60: 4.6569 (4.6043)  loss_n_80: 4.8142 (4.7468)  loss_n_100: 4.8650 (4.7943)  triple_100: 486.1096 (498.0328)  triple_80: 489.0266 (500.6847)  triple_60: 485.2889 (497.3860)  triple_40: 459.8729 (472.3878)  time: 3.9298  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [ 570/1724]  eta: 1:15:49  lr: 0.000000  loss: 1954.5840 (1987.1525)  loss_n_40: 4.2518 (4.2383)  loss_n_60: 4.6425 (4.6037)  loss_n_80: 4.8020 (4.7464)  loss_n_100: 4.8522 (4.7939)  triple_100: 491.2210 (498.1087)  triple_80: 493.6152 (500.7577)  triple_60: 489.4040 (497.4542)  triple_40: 462.5533 (472.4496)  time: 3.9307  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 580/1724]  eta: 1:15:09  lr: 0.000000  loss: 1971.6532 (1987.5665)  loss_n_40: 4.1351 (4.2366)  loss_n_60: 4.5472 (4.6028)  loss_n_80: 4.7113 (4.7456)  loss_n_100: 4.7689 (4.7930)  triple_100: 494.8844 (498.2179)  triple_80: 497.5533 (500.8653)  triple_60: 493.5818 (497.5601)  triple_40: 466.9141 (472.5452)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 590/1724]  eta: 1:14:30  lr: 0.000000  loss: 1981.1552 (1987.3852)  loss_n_40: 4.2251 (4.2369)  loss_n_60: 4.5449 (4.6027)  loss_n_80: 4.7101 (4.7455)  loss_n_100: 4.7480 (4.7929)  triple_100: 496.7181 (498.1745)  triple_80: 499.5684 (500.8204)  triple_60: 496.4232 (497.5146)  triple_40: 469.6710 (472.4977)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 600/1724]  eta: 1:13:50  lr: 0.000000  loss: 1981.7306 (1987.9551)  loss_n_40: 4.2492 (4.2361)  loss_n_60: 4.5875 (4.6012)  loss_n_80: 4.7400 (4.7440)  loss_n_100: 4.7882 (4.7915)  triple_100: 497.7568 (498.3140)  triple_80: 500.0468 (500.9579)  triple_60: 496.1907 (497.6553)  triple_40: 469.5074 (472.6551)  time: 3.9298  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [ 610/1724]  eta: 1:13:10  lr: 0.000000  loss: 1912.6561 (1986.8261)  loss_n_40: 4.2387 (4.2379)  loss_n_60: 4.6086 (4.6033)  loss_n_80: 4.7595 (4.7461)  loss_n_100: 4.8108 (4.7934)  triple_100: 479.7268 (498.0303)  triple_80: 482.4345 (500.6775)  triple_60: 478.8218 (497.3749)  triple_40: 453.1788 (472.3628)  time: 3.9304  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [ 620/1724]  eta: 1:12:31  lr: 0.000000  loss: 1912.6561 (1987.3897)  loss_n_40: 4.2313 (4.2375)  loss_n_60: 4.6086 (4.6023)  loss_n_80: 4.7595 (4.7450)  loss_n_100: 4.8108 (4.7924)  triple_100: 479.7268 (498.1716)  triple_80: 482.4345 (500.8155)  triple_60: 478.8218 (497.5145)  triple_40: 453.1788 (472.5109)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 630/1724]  eta: 1:11:51  lr: 0.000000  loss: 2005.8578 (1987.9594)  loss_n_40: 4.1404 (4.2372)  loss_n_60: 4.5024 (4.6021)  loss_n_80: 4.6697 (4.7448)  loss_n_100: 4.7339 (4.7922)  triple_100: 503.5273 (498.3130)  triple_80: 506.3020 (500.9556)  triple_60: 502.2792 (497.6570)  triple_40: 475.3962 (472.6575)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 640/1724]  eta: 1:11:12  lr: 0.000000  loss: 1991.1168 (1988.2596)  loss_n_40: 4.1404 (4.2364)  loss_n_60: 4.5243 (4.6012)  loss_n_80: 4.6793 (4.7440)  loss_n_100: 4.7365 (4.7913)  triple_100: 499.5400 (498.3878)  triple_80: 501.7053 (501.0312)  triple_60: 498.6020 (497.7317)  triple_40: 473.3067 (472.7359)  time: 3.9300  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [ 650/1724]  eta: 1:10:32  lr: 0.000000  loss: 1981.5380 (1988.5180)  loss_n_40: 4.2040 (4.2357)  loss_n_60: 4.5947 (4.6006)  loss_n_80: 4.7742 (4.7434)  loss_n_100: 4.7996 (4.7907)  triple_100: 497.6984 (498.4543)  triple_80: 500.0878 (501.0977)  triple_60: 496.1876 (497.7962)  triple_40: 469.5409 (472.7995)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 660/1724]  eta: 1:09:52  lr: 0.000000  loss: 1938.0424 (1988.4016)  loss_n_40: 4.1842 (4.2347)  loss_n_60: 4.5963 (4.5997)  loss_n_80: 4.7400 (4.7426)  loss_n_100: 4.7870 (4.7899)  triple_100: 487.1279 (498.4298)  triple_80: 489.5855 (501.0734)  triple_60: 485.1808 (497.7676)  triple_40: 458.4793 (472.7639)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 670/1724]  eta: 1:09:13  lr: 0.000000  loss: 1941.6409 (1987.5988)  loss_n_40: 4.2109 (4.2361)  loss_n_60: 4.6253 (4.6017)  loss_n_80: 4.7632 (4.7445)  loss_n_100: 4.8120 (4.7917)  triple_100: 487.1279 (498.2292)  triple_80: 489.5855 (500.8775)  triple_60: 486.3170 (497.5686)  triple_40: 458.6235 (472.5495)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 680/1724]  eta: 1:08:33  lr: 0.000000  loss: 1941.6409 (1987.7257)  loss_n_40: 4.2285 (4.2364)  loss_n_60: 4.6689 (4.6015)  loss_n_80: 4.7997 (4.7443)  loss_n_100: 4.8317 (4.7914)  triple_100: 485.3772 (498.2530)  triple_80: 489.3192 (500.9033)  triple_60: 486.3170 (497.5987)  triple_40: 459.1307 (472.5971)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 690/1724]  eta: 1:07:54  lr: 0.000000  loss: 2049.6765 (1988.7055)  loss_n_40: 4.1715 (4.2355)  loss_n_60: 4.5393 (4.5997)  loss_n_80: 4.6697 (4.7424)  loss_n_100: 4.7216 (4.7895)  triple_100: 512.5677 (498.4918)  triple_80: 515.2957 (501.1430)  triple_60: 512.4939 (497.8424)  triple_40: 490.1364 (472.8613)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 700/1724]  eta: 1:07:14  lr: 0.000000  loss: 2022.5481 (1989.0913)  loss_n_40: 4.1686 (4.2344)  loss_n_60: 4.5393 (4.5984)  loss_n_80: 4.6697 (4.7412)  loss_n_100: 4.7382 (4.7884)  triple_100: 508.4826 (498.5933)  triple_80: 511.2757 (501.2418)  triple_60: 506.7343 (497.9384)  triple_40: 477.7806 (472.9554)  time: 3.9303  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 710/1724]  eta: 1:06:35  lr: 0.000000  loss: 1989.2928 (1989.2453)  loss_n_40: 4.1779 (4.2348)  loss_n_60: 4.6034 (4.5995)  loss_n_80: 4.7679 (4.7423)  loss_n_100: 4.8017 (4.7894)  triple_100: 500.2241 (498.6331)  triple_80: 502.5620 (501.2842)  triple_60: 498.0765 (497.9781)  triple_40: 469.5934 (472.9838)  time: 3.9315  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:0]  [ 720/1724]  eta: 1:05:55  lr: 0.000000  loss: 1966.7567 (1989.0013)  loss_n_40: 4.2775 (4.2345)  loss_n_60: 4.6264 (4.5995)  loss_n_80: 4.7850 (4.7423)  loss_n_100: 4.8281 (4.7894)  triple_100: 493.4753 (498.5776)  triple_80: 496.3051 (501.2271)  triple_60: 492.4841 (497.9184)  triple_40: 466.1461 (472.9124)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 730/1724]  eta: 1:05:15  lr: 0.000000  loss: 1960.5839 (1988.8738)  loss_n_40: 4.2140 (4.2342)  loss_n_60: 4.6189 (4.5989)  loss_n_80: 4.7406 (4.7419)  loss_n_100: 4.7843 (4.7890)  triple_100: 491.3380 (498.5453)  triple_80: 494.0049 (501.1953)  triple_60: 491.3739 (497.8864)  triple_40: 465.3494 (472.8829)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 740/1724]  eta: 1:04:36  lr: 0.000000  loss: 1970.5646 (1989.2051)  loss_n_40: 4.2140 (4.2331)  loss_n_60: 4.5621 (4.5976)  loss_n_80: 4.7179 (4.7405)  loss_n_100: 4.7482 (4.7876)  triple_100: 494.8976 (498.6297)  triple_80: 497.5948 (501.2781)  triple_60: 493.6665 (497.9699)  triple_40: 468.2020 (472.9686)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 750/1724]  eta: 1:03:56  lr: 0.000000  loss: 1961.2113 (1989.0022)  loss_n_40: 4.2198 (4.2338)  loss_n_60: 4.5781 (4.5984)  loss_n_80: 4.7250 (4.7412)  loss_n_100: 4.7815 (4.7883)  triple_100: 492.6803 (498.5743)  triple_80: 495.1867 (501.2245)  triple_60: 490.9866 (497.9189)  triple_40: 464.4674 (472.9228)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 760/1724]  eta: 1:03:17  lr: 0.000000  loss: 1962.0105 (1989.0561)  loss_n_40: 4.1865 (4.2326)  loss_n_60: 4.5927 (4.5969)  loss_n_80: 4.7633 (4.7399)  loss_n_100: 4.7936 (4.7871)  triple_100: 492.7764 (498.5893)  triple_80: 495.7021 (501.2380)  triple_60: 491.3979 (497.9332)  triple_40: 463.8304 (472.9392)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 770/1724]  eta: 1:02:37  lr: 0.000000  loss: 1998.3301 (1989.3049)  loss_n_40: 4.1540 (4.2322)  loss_n_60: 4.5376 (4.5963)  loss_n_80: 4.7037 (4.7393)  loss_n_100: 4.7409 (4.7865)  triple_100: 501.8731 (498.6519)  triple_80: 504.2812 (501.2988)  triple_60: 500.5109 (497.9943)  triple_40: 473.6216 (473.0058)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 780/1724]  eta: 1:01:58  lr: 0.000000  loss: 1971.3269 (1988.8265)  loss_n_40: 4.2584 (4.2326)  loss_n_60: 4.6065 (4.5969)  loss_n_80: 4.7180 (4.7398)  loss_n_100: 4.7556 (4.7870)  triple_100: 493.5089 (498.5321)  triple_80: 496.2108 (501.1811)  triple_60: 493.1660 (497.8773)  triple_40: 469.3984 (472.8797)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 790/1724]  eta: 1:01:18  lr: 0.000000  loss: 1947.8796 (1988.4771)  loss_n_40: 4.2584 (4.2328)  loss_n_60: 4.6455 (4.5978)  loss_n_80: 4.7892 (4.7408)  loss_n_100: 4.8413 (4.7879)  triple_100: 488.5189 (498.4484)  triple_80: 491.3626 (501.0986)  triple_60: 488.0732 (497.7920)  triple_40: 460.4399 (472.7788)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 800/1724]  eta: 1:00:39  lr: 0.000000  loss: 1991.3743 (1989.1371)  loss_n_40: 4.2750 (4.2341)  loss_n_60: 4.6710 (4.5983)  loss_n_80: 4.7800 (4.7409)  loss_n_100: 4.7991 (4.7878)  triple_100: 499.1364 (498.5966)  triple_80: 502.2353 (501.2533)  triple_60: 498.9188 (497.9571)  triple_40: 471.7598 (472.9690)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 810/1724]  eta: 0:59:59  lr: 0.000000  loss: 2063.7971 (1989.9742)  loss_n_40: 4.2283 (4.2329)  loss_n_60: 4.5497 (4.5967)  loss_n_80: 4.6931 (4.7392)  loss_n_100: 4.7336 (4.7861)  triple_100: 515.9169 (498.8016)  triple_80: 519.1241 (501.4587)  triple_60: 516.4952 (498.1648)  triple_40: 493.8911 (473.1941)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 820/1724]  eta: 0:59:20  lr: 0.000000  loss: 2012.1888 (1989.7605)  loss_n_40: 4.1838 (4.2329)  loss_n_60: 4.5967 (4.5970)  loss_n_80: 4.7120 (4.7395)  loss_n_100: 4.7347 (4.7863)  triple_100: 504.3181 (498.7463)  triple_80: 507.1813 (501.4054)  triple_60: 503.8262 (498.1111)  triple_40: 477.9722 (473.1420)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 830/1724]  eta: 0:58:40  lr: 0.000000  loss: 1962.5558 (1990.1285)  loss_n_40: 4.2126 (4.2327)  loss_n_60: 4.6125 (4.5964)  loss_n_80: 4.7530 (4.7389)  loss_n_100: 4.7971 (4.7857)  triple_100: 491.9459 (498.8372)  triple_80: 495.2470 (501.4939)  triple_60: 491.2667 (498.2000)  triple_40: 464.7691 (473.2437)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 840/1724]  eta: 0:58:01  lr: 0.000000  loss: 2004.1462 (1990.0976)  loss_n_40: 4.1818 (4.2314)  loss_n_60: 4.5585 (4.5953)  loss_n_80: 4.6993 (4.7379)  loss_n_100: 4.7593 (4.7848)  triple_100: 502.4728 (498.8328)  triple_80: 504.5246 (501.4861)  triple_60: 501.5008 (498.1914)  triple_40: 477.2477 (473.2379)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 850/1724]  eta: 0:57:21  lr: 0.000000  loss: 2004.1462 (1990.1253)  loss_n_40: 4.1455 (4.2316)  loss_n_60: 4.5231 (4.5954)  loss_n_80: 4.6759 (4.7379)  loss_n_100: 4.7345 (4.7848)  triple_100: 502.4728 (498.8371)  triple_80: 504.5246 (501.4925)  triple_60: 501.5008 (498.1992)  triple_40: 477.2477 (473.2469)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 860/1724]  eta: 0:56:42  lr: 0.000000  loss: 1977.5465 (1989.8498)  loss_n_40: 4.1876 (4.2311)  loss_n_60: 4.5159 (4.5950)  loss_n_80: 4.7031 (4.7377)  loss_n_100: 4.7462 (4.7846)  triple_100: 495.4020 (498.7728)  triple_80: 498.6354 (501.4271)  triple_60: 495.3049 (498.1308)  triple_40: 469.6118 (473.1707)  time: 3.9253  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [ 870/1724]  eta: 0:56:02  lr: 0.000000  loss: 1940.5359 (1989.1980)  loss_n_40: 4.2321 (4.2316)  loss_n_60: 4.6852 (4.5963)  loss_n_80: 4.8343 (4.7390)  loss_n_100: 4.8686 (4.7858)  triple_100: 486.3297 (498.6129)  triple_80: 489.5112 (501.2703)  triple_60: 486.0931 (497.9704)  triple_40: 459.5973 (472.9918)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 880/1724]  eta: 0:55:23  lr: 0.000000  loss: 1937.4177 (1988.8763)  loss_n_40: 4.2341 (4.2314)  loss_n_60: 4.6784 (4.5965)  loss_n_80: 4.8266 (4.7393)  loss_n_100: 4.8648 (4.7861)  triple_100: 485.7974 (498.5351)  triple_80: 488.8268 (501.1914)  triple_60: 485.1289 (497.8913)  triple_40: 459.0521 (472.9051)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 890/1724]  eta: 0:54:43  lr: 0.000000  loss: 1974.8340 (1989.6398)  loss_n_40: 4.1782 (4.2317)  loss_n_60: 4.5858 (4.5966)  loss_n_80: 4.7314 (4.7392)  loss_n_100: 4.7851 (4.7859)  triple_100: 495.3770 (498.7200)  triple_80: 497.7841 (501.3793)  triple_60: 494.5104 (498.0843)  triple_40: 468.8576 (473.1028)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 900/1724]  eta: 0:54:04  lr: 0.000000  loss: 2020.1991 (1989.9516)  loss_n_40: 4.2153 (4.2322)  loss_n_60: 4.6045 (4.5973)  loss_n_80: 4.7292 (4.7399)  loss_n_100: 4.7851 (4.7865)  triple_100: 505.4024 (498.7967)  triple_80: 508.6849 (501.4571)  triple_60: 506.0827 (498.1622)  triple_40: 481.1816 (473.1797)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 910/1724]  eta: 0:53:24  lr: 0.000000  loss: 1954.0763 (1989.3163)  loss_n_40: 4.2394 (4.2331)  loss_n_60: 4.6495 (4.5983)  loss_n_80: 4.8086 (4.7409)  loss_n_100: 4.8574 (4.7876)  triple_100: 490.3530 (498.6357)  triple_80: 493.5280 (501.2989)  triple_60: 489.3293 (498.0034)  triple_40: 462.1920 (473.0184)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 920/1724]  eta: 0:52:45  lr: 0.000000  loss: 1925.0668 (1989.5442)  loss_n_40: 4.2394 (4.2327)  loss_n_60: 4.6720 (4.5981)  loss_n_80: 4.8253 (4.7406)  loss_n_100: 4.8635 (4.7872)  triple_100: 483.4869 (498.6925)  triple_80: 486.0790 (501.3565)  triple_60: 482.2900 (498.0602)  triple_40: 454.6683 (473.0765)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 930/1724]  eta: 0:52:05  lr: 0.000000  loss: 1935.0022 (1989.2311)  loss_n_40: 4.1945 (4.2328)  loss_n_60: 4.6416 (4.5985)  loss_n_80: 4.7795 (4.7411)  loss_n_100: 4.8181 (4.7876)  triple_100: 485.9027 (498.6173)  triple_80: 488.9010 (501.2820)  triple_60: 484.8092 (497.9830)  triple_40: 456.4278 (472.9888)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 940/1724]  eta: 0:51:26  lr: 0.000000  loss: 1934.1729 (1989.3686)  loss_n_40: 4.2388 (4.2337)  loss_n_60: 4.5999 (4.5990)  loss_n_80: 4.7795 (4.7415)  loss_n_100: 4.8181 (4.7879)  triple_100: 484.3835 (498.6461)  triple_80: 487.8160 (501.3136)  triple_60: 484.4141 (498.0162)  triple_40: 458.1475 (473.0306)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 950/1724]  eta: 0:50:46  lr: 0.000000  loss: 1992.2424 (1990.1254)  loss_n_40: 4.1777 (4.2323)  loss_n_60: 4.5273 (4.5977)  loss_n_80: 4.7137 (4.7403)  loss_n_100: 4.7541 (4.7868)  triple_100: 499.2479 (498.8359)  triple_80: 502.0576 (501.5015)  triple_60: 499.1920 (498.2058)  triple_40: 472.7489 (473.2250)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 960/1724]  eta: 0:50:07  lr: 0.000000  loss: 2015.3044 (1990.1637)  loss_n_40: 4.1333 (4.2325)  loss_n_60: 4.5454 (4.5980)  loss_n_80: 4.7137 (4.7405)  loss_n_100: 4.7541 (4.7870)  triple_100: 506.0759 (498.8425)  triple_80: 509.1015 (501.5097)  triple_60: 505.2532 (498.2160)  triple_40: 476.3189 (473.2375)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 970/1724]  eta: 0:49:27  lr: 0.000000  loss: 1962.6266 (1990.5023)  loss_n_40: 4.1904 (4.2315)  loss_n_60: 4.5871 (4.5970)  loss_n_80: 4.7230 (4.7395)  loss_n_100: 4.7656 (4.7860)  triple_100: 492.8645 (498.9286)  triple_80: 495.4301 (501.5955)  triple_60: 491.3198 (498.3010)  triple_40: 464.9118 (473.3233)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 980/1724]  eta: 0:48:48  lr: 0.000000  loss: 1968.4136 (1990.6623)  loss_n_40: 4.1411 (4.2309)  loss_n_60: 4.5758 (4.5966)  loss_n_80: 4.7230 (4.7392)  loss_n_100: 4.7656 (4.7856)  triple_100: 494.8458 (498.9740)  triple_80: 497.0597 (501.6388)  triple_60: 492.9798 (498.3421)  triple_40: 465.0091 (473.3551)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [ 990/1724]  eta: 0:48:09  lr: 0.000000  loss: 1970.5792 (1990.9586)  loss_n_40: 4.1844 (4.2306)  loss_n_60: 4.5945 (4.5966)  loss_n_80: 4.7316 (4.7393)  loss_n_100: 4.7682 (4.7857)  triple_100: 494.8458 (499.0508)  triple_80: 497.7140 (501.7158)  triple_60: 493.8942 (498.4169)  triple_40: 467.7826 (473.4229)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1000/1724]  eta: 0:47:29  lr: 0.000000  loss: 1970.5792 (1991.0898)  loss_n_40: 4.2659 (4.2314)  loss_n_60: 4.6904 (4.5975)  loss_n_80: 4.8303 (4.7401)  loss_n_100: 4.8820 (4.7866)  triple_100: 494.6759 (499.0806)  triple_80: 497.7140 (501.7471)  triple_60: 493.8942 (498.4497)  triple_40: 467.7826 (473.4567)  time: 3.9271  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1010/1724]  eta: 0:46:50  lr: 0.000000  loss: 1928.8894 (1990.4596)  loss_n_40: 4.2792 (4.2318)  loss_n_60: 4.6564 (4.5981)  loss_n_80: 4.8098 (4.7407)  loss_n_100: 4.8440 (4.7872)  triple_100: 484.8804 (498.9261)  triple_80: 487.3811 (501.5940)  triple_60: 483.2473 (498.2936)  triple_40: 455.5943 (473.2882)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1020/1724]  eta: 0:46:10  lr: 0.000000  loss: 1928.8894 (1990.3213)  loss_n_40: 4.2711 (4.2319)  loss_n_60: 4.6454 (4.5985)  loss_n_80: 4.8020 (4.7411)  loss_n_100: 4.8333 (4.7875)  triple_100: 484.3992 (498.8928)  triple_80: 487.1945 (501.5615)  triple_60: 483.2473 (498.2605)  triple_40: 455.5943 (473.2474)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1030/1724]  eta: 0:45:31  lr: 0.000000  loss: 1929.8346 (1990.1988)  loss_n_40: 4.2506 (4.2318)  loss_n_60: 4.6262 (4.5983)  loss_n_80: 4.7669 (4.7410)  loss_n_100: 4.7979 (4.7874)  triple_100: 484.3992 (498.8650)  triple_80: 487.1945 (501.5326)  triple_60: 483.4226 (498.2300)  triple_40: 455.7234 (473.2127)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1040/1724]  eta: 0:44:51  lr: 0.000000  loss: 1941.1062 (1990.1772)  loss_n_40: 4.2088 (4.2317)  loss_n_60: 4.6324 (4.5985)  loss_n_80: 4.7857 (4.7414)  loss_n_100: 4.8239 (4.7877)  triple_100: 487.2425 (498.8623)  triple_80: 489.8384 (501.5307)  triple_60: 486.5327 (498.2264)  triple_40: 458.6588 (473.1984)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1050/1724]  eta: 0:44:12  lr: 0.000000  loss: 2015.0797 (1990.8470)  loss_n_40: 4.1573 (4.2311)  loss_n_60: 4.5455 (4.5975)  loss_n_80: 4.6787 (4.7403)  loss_n_100: 4.7303 (4.7866)  triple_100: 505.3214 (499.0289)  triple_80: 508.3557 (501.6955)  triple_60: 504.7195 (498.3923)  triple_40: 478.1419 (473.3747)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1060/1724]  eta: 0:43:33  lr: 0.000000  loss: 2033.9675 (1991.2543)  loss_n_40: 4.1562 (4.2308)  loss_n_60: 4.5182 (4.5972)  loss_n_80: 4.6749 (4.7400)  loss_n_100: 4.7267 (4.7863)  triple_100: 510.1438 (499.1288)  triple_80: 512.9196 (501.7964)  triple_60: 509.2697 (498.4944)  triple_40: 483.5931 (473.4804)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1070/1724]  eta: 0:42:53  lr: 0.000000  loss: 1953.8090 (1991.7938)  loss_n_40: 4.1562 (4.2301)  loss_n_60: 4.5534 (4.5964)  loss_n_80: 4.6749 (4.7392)  loss_n_100: 4.7267 (4.7856)  triple_100: 490.3898 (499.2626)  triple_80: 493.0124 (501.9298)  triple_60: 489.1684 (498.6299)  triple_40: 464.3018 (473.6204)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1080/1724]  eta: 0:42:14  lr: 0.000000  loss: 1983.2780 (1991.8343)  loss_n_40: 4.1457 (4.2299)  loss_n_60: 4.5534 (4.5963)  loss_n_80: 4.6817 (4.7391)  loss_n_100: 4.7217 (4.7856)  triple_100: 496.9644 (499.2743)  triple_80: 500.1654 (501.9397)  triple_60: 496.8373 (498.6397)  triple_40: 470.3564 (473.6297)  time: 3.9269  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [1090/1724]  eta: 0:41:34  lr: 0.000000  loss: 1983.2780 (1992.0548)  loss_n_40: 4.1804 (4.2301)  loss_n_60: 4.6232 (4.5964)  loss_n_80: 4.7899 (4.7391)  loss_n_100: 4.8150 (4.7856)  triple_100: 496.9644 (499.3271)  triple_80: 500.1654 (501.9927)  triple_60: 496.8373 (498.6957)  triple_40: 470.2330 (473.6881)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1100/1724]  eta: 0:40:55  lr: 0.000000  loss: 1960.6202 (1991.7443)  loss_n_40: 4.2644 (4.2307)  loss_n_60: 4.6539 (4.5972)  loss_n_80: 4.8039 (4.7400)  loss_n_100: 4.8338 (4.7863)  triple_100: 492.1219 (499.2493)  triple_80: 494.6158 (501.9159)  triple_60: 491.1400 (498.6195)  triple_40: 464.7418 (473.6054)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1110/1724]  eta: 0:40:16  lr: 0.000000  loss: 1960.6202 (1991.7442)  loss_n_40: 4.2516 (4.2303)  loss_n_60: 4.6408 (4.5971)  loss_n_80: 4.8009 (4.7400)  loss_n_100: 4.8338 (4.7863)  triple_100: 492.1219 (499.2510)  triple_80: 494.6158 (501.9163)  triple_60: 491.1400 (498.6198)  triple_40: 464.7418 (473.6035)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1120/1724]  eta: 0:39:36  lr: 0.000000  loss: 1976.5850 (1991.7895)  loss_n_40: 4.2516 (4.2303)  loss_n_60: 4.6581 (4.5971)  loss_n_80: 4.7938 (4.7398)  loss_n_100: 4.8215 (4.7862)  triple_100: 495.5605 (499.2612)  triple_80: 497.9865 (501.9263)  triple_60: 494.4929 (498.6308)  triple_40: 469.6782 (473.6179)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1130/1724]  eta: 0:38:57  lr: 0.000000  loss: 1995.9163 (1991.9401)  loss_n_40: 4.2845 (4.2313)  loss_n_60: 4.6960 (4.5982)  loss_n_80: 4.8328 (4.7409)  loss_n_100: 4.8671 (4.7872)  triple_100: 500.8349 (499.2948)  triple_80: 504.0469 (501.9624)  triple_60: 500.0326 (498.6682)  triple_40: 475.0354 (473.6572)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1140/1724]  eta: 0:38:17  lr: 0.000000  loss: 2002.5325 (1992.0504)  loss_n_40: 4.2513 (4.2309)  loss_n_60: 4.6155 (4.5976)  loss_n_80: 4.7345 (4.7402)  loss_n_100: 4.7615 (4.7865)  triple_100: 501.4763 (499.3229)  triple_80: 504.9586 (501.9897)  triple_60: 501.2024 (498.6953)  triple_40: 475.0354 (473.6872)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1150/1724]  eta: 0:37:38  lr: 0.000000  loss: 1954.7466 (1991.9639)  loss_n_40: 4.1747 (4.2306)  loss_n_60: 4.5502 (4.5973)  loss_n_80: 4.7035 (4.7400)  loss_n_100: 4.7449 (4.7864)  triple_100: 490.5730 (499.3069)  triple_80: 493.4111 (501.9710)  triple_60: 489.5072 (498.6734)  triple_40: 463.1199 (473.6583)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1160/1724]  eta: 0:36:59  lr: 0.000000  loss: 1976.9724 (1992.1247)  loss_n_40: 4.2006 (4.2305)  loss_n_60: 4.5793 (4.5972)  loss_n_80: 4.7181 (4.7399)  loss_n_100: 4.7533 (4.7863)  triple_100: 496.8056 (499.3474)  triple_80: 499.5968 (502.0112)  triple_60: 495.1241 (498.7144)  triple_40: 467.1290 (473.6978)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1170/1724]  eta: 0:36:19  lr: 0.000000  loss: 1959.1342 (1991.9047)  loss_n_40: 4.2901 (4.2314)  loss_n_60: 4.6036 (4.5979)  loss_n_80: 4.7685 (4.7406)  loss_n_100: 4.8180 (4.7870)  triple_100: 491.8037 (499.2874)  triple_80: 494.1243 (501.9527)  triple_60: 490.5487 (498.6584)  triple_40: 465.9583 (473.6494)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1180/1724]  eta: 0:35:40  lr: 0.000000  loss: 1949.1279 (1991.8179)  loss_n_40: 4.2977 (4.2317)  loss_n_60: 4.6865 (4.5984)  loss_n_80: 4.8412 (4.7411)  loss_n_100: 4.8898 (4.7874)  triple_100: 488.2940 (499.2645)  triple_80: 490.8864 (501.9313)  triple_60: 487.8330 (498.6372)  triple_40: 463.4478 (473.6262)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1190/1724]  eta: 0:35:00  lr: 0.000000  loss: 1990.0422 (1991.8680)  loss_n_40: 4.2635 (4.2317)  loss_n_60: 4.6542 (4.5987)  loss_n_80: 4.8054 (4.7414)  loss_n_100: 4.8471 (4.7878)  triple_100: 498.9238 (499.2796)  triple_80: 501.5719 (501.9458)  triple_60: 498.1811 (498.6502)  triple_40: 472.4100 (473.6329)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1200/1724]  eta: 0:34:21  lr: 0.000000  loss: 1994.7924 (1991.5258)  loss_n_40: 4.2412 (4.2326)  loss_n_60: 4.6033 (4.5996)  loss_n_80: 4.7426 (4.7423)  loss_n_100: 4.7885 (4.7887)  triple_100: 499.2387 (499.1914)  triple_80: 501.8141 (501.8587)  triple_60: 499.2676 (498.5646)  triple_40: 476.2700 (473.5479)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1210/1724]  eta: 0:33:42  lr: 0.000000  loss: 1981.4714 (1991.4796)  loss_n_40: 4.2144 (4.2322)  loss_n_60: 4.5706 (4.5994)  loss_n_80: 4.7031 (4.7421)  loss_n_100: 4.7598 (4.7885)  triple_100: 497.7310 (499.1839)  triple_80: 499.7955 (501.8502)  triple_60: 495.8112 (498.5531)  triple_40: 470.3123 (473.5301)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1220/1724]  eta: 0:33:02  lr: 0.000000  loss: 1979.6970 (1991.5296)  loss_n_40: 4.1954 (4.2323)  loss_n_60: 4.5161 (4.5994)  loss_n_80: 4.6725 (4.7421)  loss_n_100: 4.7326 (4.7884)  triple_100: 496.1826 (499.1945)  triple_80: 499.6310 (501.8617)  triple_60: 495.8112 (498.5652)  triple_40: 468.4312 (473.5460)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1230/1724]  eta: 0:32:23  lr: 0.000000  loss: 1979.6970 (1991.6120)  loss_n_40: 4.2838 (4.2324)  loss_n_60: 4.6767 (4.5995)  loss_n_80: 4.8245 (4.7422)  loss_n_100: 4.8792 (4.7885)  triple_100: 496.1826 (499.2147)  triple_80: 499.3016 (501.8819)  triple_60: 496.0136 (498.5860)  triple_40: 468.4312 (473.5667)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1240/1724]  eta: 0:31:44  lr: 0.000000  loss: 1998.3978 (1991.5246)  loss_n_40: 4.2130 (4.2323)  loss_n_60: 4.6302 (4.5997)  loss_n_80: 4.7831 (4.7424)  loss_n_100: 4.8312 (4.7887)  triple_100: 499.9515 (499.1935)  triple_80: 502.8287 (501.8596)  triple_60: 500.5860 (498.5640)  triple_40: 476.7008 (473.5444)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1250/1724]  eta: 0:31:04  lr: 0.000000  loss: 1987.5347 (1991.3612)  loss_n_40: 4.1995 (4.2322)  loss_n_60: 4.6206 (4.5997)  loss_n_80: 4.7697 (4.7425)  loss_n_100: 4.7925 (4.7889)  triple_100: 497.8543 (499.1551)  triple_80: 500.1125 (501.8209)  triple_60: 497.7087 (498.5241)  triple_40: 473.7252 (473.4978)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1260/1724]  eta: 0:30:25  lr: 0.000000  loss: 1969.6442 (1991.4202)  loss_n_40: 4.1908 (4.2324)  loss_n_60: 4.5621 (4.5999)  loss_n_80: 4.7275 (4.7426)  loss_n_100: 4.7634 (4.7890)  triple_100: 493.5442 (499.1691)  triple_80: 496.6536 (501.8338)  triple_60: 493.2613 (498.5377)  triple_40: 467.1862 (473.5157)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1270/1724]  eta: 0:29:46  lr: 0.000000  loss: 1899.1899 (1990.9508)  loss_n_40: 4.3591 (4.2332)  loss_n_60: 4.7185 (4.6009)  loss_n_80: 4.8624 (4.7437)  loss_n_100: 4.9000 (4.7900)  triple_100: 476.0234 (499.0510)  triple_80: 479.0530 (501.7187)  triple_60: 475.5093 (498.4213)  triple_40: 448.9829 (473.3920)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1280/1724]  eta: 0:29:06  lr: 0.000000  loss: 1963.7817 (1991.1342)  loss_n_40: 4.2424 (4.2326)  loss_n_60: 4.6591 (4.6003)  loss_n_80: 4.8104 (4.7430)  loss_n_100: 4.8450 (4.7893)  triple_100: 492.0703 (499.0983)  triple_80: 495.2491 (501.7644)  triple_60: 491.7685 (498.4663)  triple_40: 465.3912 (473.4401)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1290/1724]  eta: 0:28:27  lr: 0.000000  loss: 1998.1776 (1991.2075)  loss_n_40: 4.2184 (4.2320)  loss_n_60: 4.5469 (4.5998)  loss_n_80: 4.7021 (4.7425)  loss_n_100: 4.7295 (4.7889)  triple_100: 501.4118 (499.1180)  triple_80: 503.9541 (501.7827)  triple_60: 500.5186 (498.4844)  triple_40: 473.9675 (473.4592)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1300/1724]  eta: 0:27:47  lr: 0.000000  loss: 1988.3232 (1991.4894)  loss_n_40: 4.2348 (4.2319)  loss_n_60: 4.6223 (4.5997)  loss_n_80: 4.7693 (4.7424)  loss_n_100: 4.8201 (4.7888)  triple_100: 498.3903 (499.1891)  triple_80: 500.7048 (501.8520)  triple_60: 497.6848 (498.5538)  triple_40: 473.0328 (473.5317)  time: 3.9287  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [1310/1724]  eta: 0:27:08  lr: 0.000000  loss: 2009.1057 (1991.3145)  loss_n_40: 4.1856 (4.2320)  loss_n_60: 4.5771 (4.6001)  loss_n_80: 4.7168 (4.7429)  loss_n_100: 4.7639 (4.7893)  triple_100: 502.8097 (499.1478)  triple_80: 506.0918 (501.8113)  triple_60: 503.4348 (498.5107)  triple_40: 477.5263 (473.4805)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1320/1724]  eta: 0:26:29  lr: 0.000000  loss: 1974.9828 (1991.3481)  loss_n_40: 4.1893 (4.2316)  loss_n_60: 4.5441 (4.5992)  loss_n_80: 4.7147 (4.7420)  loss_n_100: 4.7639 (4.7885)  triple_100: 495.4996 (499.1555)  triple_80: 498.0236 (501.8166)  triple_60: 494.5181 (498.5175)  triple_40: 468.9613 (473.4972)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1330/1724]  eta: 0:25:49  lr: 0.000000  loss: 1974.9828 (1991.4269)  loss_n_40: 4.0861 (4.2312)  loss_n_60: 4.4901 (4.5986)  loss_n_80: 4.6542 (4.7414)  loss_n_100: 4.7150 (4.7879)  triple_100: 495.4186 (499.1761)  triple_80: 497.6017 (501.8358)  triple_60: 494.5181 (498.5359)  triple_40: 468.9613 (473.5200)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1340/1724]  eta: 0:25:10  lr: 0.000000  loss: 1920.8647 (1991.2552)  loss_n_40: 4.1982 (4.2312)  loss_n_60: 4.5126 (4.5986)  loss_n_80: 4.6714 (4.7414)  loss_n_100: 4.7262 (4.7880)  triple_100: 483.5472 (499.1333)  triple_80: 485.6818 (501.7937)  triple_60: 480.8789 (498.4931)  triple_40: 452.8580 (473.4760)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1350/1724]  eta: 0:24:31  lr: 0.000000  loss: 1935.8688 (1990.9579)  loss_n_40: 4.2255 (4.2313)  loss_n_60: 4.6236 (4.5988)  loss_n_80: 4.7895 (4.7416)  loss_n_100: 4.8381 (4.7882)  triple_100: 484.5675 (499.0609)  triple_80: 487.6141 (501.7210)  triple_60: 484.7513 (498.4185)  triple_40: 459.7429 (473.3976)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1360/1724]  eta: 0:23:51  lr: 0.000000  loss: 1952.1786 (1991.0859)  loss_n_40: 4.1370 (4.2309)  loss_n_60: 4.5230 (4.5984)  loss_n_80: 4.6691 (4.7413)  loss_n_100: 4.7147 (4.7879)  triple_100: 488.8301 (499.0934)  triple_80: 492.0789 (501.7526)  triple_60: 488.8211 (498.4500)  triple_40: 462.4143 (473.4313)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1370/1724]  eta: 0:23:12  lr: 0.000000  loss: 1943.2826 (1990.9355)  loss_n_40: 4.1572 (4.2312)  loss_n_60: 4.5230 (4.5985)  loss_n_80: 4.6691 (4.7413)  loss_n_100: 4.7147 (4.7879)  triple_100: 488.6439 (499.0513)  triple_80: 490.9416 (501.7130)  triple_60: 486.4475 (498.4120)  triple_40: 459.3651 (473.4002)  time: 3.9293  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1380/1724]  eta: 0:22:33  lr: 0.000000  loss: 1921.1365 (1990.8441)  loss_n_40: 4.2416 (4.2311)  loss_n_60: 4.5645 (4.5985)  loss_n_80: 4.7190 (4.7413)  loss_n_100: 4.7581 (4.7880)  triple_100: 482.5168 (499.0307)  triple_80: 485.4475 (501.6918)  triple_60: 481.1515 (498.3887)  triple_40: 453.7098 (473.3741)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1390/1724]  eta: 0:21:53  lr: 0.000000  loss: 1933.8380 (1990.5355)  loss_n_40: 4.2145 (4.2314)  loss_n_60: 4.5926 (4.5989)  loss_n_80: 4.7395 (4.7417)  loss_n_100: 4.7939 (4.7884)  triple_100: 485.7325 (498.9540)  triple_80: 488.6751 (501.6154)  triple_60: 484.6131 (498.3116)  triple_40: 456.6259 (473.2940)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1400/1724]  eta: 0:21:14  lr: 0.000000  loss: 1934.4484 (1990.5486)  loss_n_40: 4.2145 (4.2315)  loss_n_60: 4.5882 (4.5989)  loss_n_80: 4.7395 (4.7417)  loss_n_100: 4.7858 (4.7884)  triple_100: 485.2748 (498.9551)  triple_80: 488.1888 (501.6169)  triple_60: 484.1444 (498.3142)  triple_40: 457.5290 (473.3018)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1410/1724]  eta: 0:20:35  lr: 0.000000  loss: 1988.1046 (1990.7106)  loss_n_40: 4.1938 (4.2313)  loss_n_60: 4.5722 (4.5987)  loss_n_80: 4.7114 (4.7415)  loss_n_100: 4.7641 (4.7881)  triple_100: 499.5955 (498.9945)  triple_80: 501.9812 (501.6567)  triple_60: 498.3288 (498.3543)  triple_40: 470.1887 (473.3456)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1420/1724]  eta: 0:19:55  lr: 0.000000  loss: 1975.1484 (1990.7086)  loss_n_40: 4.2376 (4.2316)  loss_n_60: 4.6132 (4.5990)  loss_n_80: 4.7719 (4.7418)  loss_n_100: 4.8329 (4.7884)  triple_100: 495.1080 (498.9956)  triple_80: 498.0920 (501.6569)  triple_60: 494.8556 (498.3538)  triple_40: 468.1907 (473.3416)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1430/1724]  eta: 0:19:16  lr: 0.000000  loss: 1926.5892 (1990.5260)  loss_n_40: 4.2521 (4.2317)  loss_n_60: 4.6589 (4.5991)  loss_n_80: 4.8032 (4.7419)  loss_n_100: 4.8584 (4.7885)  triple_100: 483.6414 (498.9487)  triple_80: 486.2066 (501.6102)  triple_60: 482.4582 (498.3078)  triple_40: 455.7138 (473.2982)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1440/1724]  eta: 0:18:37  lr: 0.000000  loss: 1996.2324 (1990.8721)  loss_n_40: 4.2011 (4.2311)  loss_n_60: 4.5364 (4.5980)  loss_n_80: 4.6829 (4.7408)  loss_n_100: 4.7368 (4.7875)  triple_100: 501.0216 (499.0343)  triple_80: 503.8309 (501.6950)  triple_60: 500.0305 (498.3944)  triple_40: 473.5794 (473.3909)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1450/1724]  eta: 0:17:57  lr: 0.000000  loss: 2049.2827 (1991.2480)  loss_n_40: 4.1977 (4.2309)  loss_n_60: 4.5028 (4.5977)  loss_n_80: 4.6406 (4.7405)  loss_n_100: 4.6846 (4.7872)  triple_100: 513.5219 (499.1270)  triple_80: 515.9760 (501.7869)  triple_60: 513.1281 (498.4881)  triple_40: 488.4459 (473.4897)  time: 3.9308  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1460/1724]  eta: 0:17:18  lr: 0.000000  loss: 2011.9208 (1991.2059)  loss_n_40: 4.2233 (4.2308)  loss_n_60: 4.5521 (4.5975)  loss_n_80: 4.6732 (4.7402)  loss_n_100: 4.7229 (4.7869)  triple_100: 505.8261 (499.1172)  triple_80: 508.0722 (501.7760)  triple_60: 503.9871 (498.4782)  triple_40: 476.0420 (473.4792)  time: 3.9311  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1470/1724]  eta: 0:16:39  lr: 0.000000  loss: 1985.9561 (1990.8798)  loss_n_40: 4.2588 (4.2315)  loss_n_60: 4.6502 (4.5983)  loss_n_80: 4.7782 (4.7410)  loss_n_100: 4.8214 (4.7876)  triple_100: 497.6629 (499.0342)  triple_80: 499.8402 (501.6945)  triple_60: 496.6389 (498.3964)  triple_40: 473.8665 (473.3963)  time: 3.9315  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1480/1724]  eta: 0:15:59  lr: 0.000000  loss: 2001.7509 (1990.9745)  loss_n_40: 4.2179 (4.2312)  loss_n_60: 4.6057 (4.5979)  loss_n_80: 4.7577 (4.7406)  loss_n_100: 4.7969 (4.7873)  triple_100: 501.2042 (499.0583)  triple_80: 504.0873 (501.7180)  triple_60: 501.0165 (498.4200)  triple_40: 474.3665 (473.4212)  time: 3.9331  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1490/1724]  eta: 0:15:20  lr: 0.000000  loss: 2003.9607 (1991.1514)  loss_n_40: 4.1538 (4.2307)  loss_n_60: 4.5709 (4.5978)  loss_n_80: 4.7390 (4.7406)  loss_n_100: 4.7870 (4.7872)  triple_100: 502.9042 (499.1048)  triple_80: 505.6711 (501.7645)  triple_60: 501.8506 (498.4643)  triple_40: 474.3665 (473.4616)  time: 3.9326  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1500/1724]  eta: 0:14:41  lr: 0.000000  loss: 1992.3118 (1991.1855)  loss_n_40: 4.1765 (4.2310)  loss_n_60: 4.5796 (4.5980)  loss_n_80: 4.7549 (4.7408)  loss_n_100: 4.7945 (4.7875)  triple_100: 499.1660 (499.1120)  triple_80: 501.5828 (501.7722)  triple_60: 498.9957 (498.4732)  triple_40: 472.8553 (473.4708)  time: 3.9296  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1510/1724]  eta: 0:14:01  lr: 0.000000  loss: 1992.3118 (1991.0132)  loss_n_40: 4.3595 (4.2316)  loss_n_60: 4.7165 (4.5988)  loss_n_80: 4.8577 (4.7416)  loss_n_100: 4.9007 (4.7882)  triple_100: 499.1660 (499.0678)  triple_80: 501.5828 (501.7287)  triple_60: 498.9957 (498.4300)  triple_40: 472.8553 (473.4264)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1520/1724]  eta: 0:13:22  lr: 0.000000  loss: 2029.6315 (1991.1929)  loss_n_40: 4.2341 (4.2312)  loss_n_60: 4.6387 (4.5984)  loss_n_80: 4.7641 (4.7413)  loss_n_100: 4.7852 (4.7879)  triple_100: 509.7642 (499.1152)  triple_80: 512.0146 (501.7748)  triple_60: 508.0898 (498.4748)  triple_40: 482.0464 (473.4694)  time: 3.9287  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [1530/1724]  eta: 0:12:43  lr: 0.000000  loss: 1959.8950 (1990.9102)  loss_n_40: 4.2341 (4.2313)  loss_n_60: 4.5869 (4.5985)  loss_n_80: 4.7268 (4.7414)  loss_n_100: 4.7717 (4.7880)  triple_100: 490.7089 (499.0441)  triple_80: 493.6964 (501.7038)  triple_60: 490.8183 (498.4035)  triple_40: 465.4245 (473.3995)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1540/1724]  eta: 0:12:03  lr: 0.000000  loss: 1971.8412 (1991.1233)  loss_n_40: 4.2582 (4.2314)  loss_n_60: 4.6343 (4.5986)  loss_n_80: 4.7777 (4.7415)  loss_n_100: 4.8192 (4.7881)  triple_100: 495.7890 (499.0981)  triple_80: 498.3055 (501.7583)  triple_60: 493.6073 (498.4566)  triple_40: 465.8057 (473.4508)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1550/1724]  eta: 0:11:24  lr: 0.000000  loss: 1961.1583 (1990.8295)  loss_n_40: 4.2341 (4.2315)  loss_n_60: 4.6343 (4.5988)  loss_n_80: 4.7777 (4.7417)  loss_n_100: 4.8192 (4.7883)  triple_100: 491.9676 (499.0255)  triple_80: 494.4406 (501.6858)  triple_60: 490.8053 (498.3837)  triple_40: 465.5458 (473.3742)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1560/1724]  eta: 0:10:45  lr: 0.000000  loss: 1953.7228 (1991.1114)  loss_n_40: 4.2098 (4.2313)  loss_n_60: 4.6293 (4.5985)  loss_n_80: 4.7857 (4.7413)  loss_n_100: 4.8190 (4.7879)  triple_100: 490.3782 (499.0933)  triple_80: 492.8048 (501.7549)  triple_60: 489.4312 (498.4541)  triple_40: 463.1257 (473.4500)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1570/1724]  eta: 0:10:05  lr: 0.000000  loss: 1946.0547 (1990.8192)  loss_n_40: 4.2327 (4.2319)  loss_n_60: 4.6378 (4.5989)  loss_n_80: 4.7918 (4.7416)  loss_n_100: 4.8339 (4.7882)  triple_100: 486.4542 (499.0169)  triple_80: 489.6267 (501.6795)  triple_60: 487.2957 (498.3809)  triple_40: 463.3921 (473.3814)  time: 3.9271  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1580/1724]  eta: 0:09:26  lr: 0.000000  loss: 1946.0547 (1990.8170)  loss_n_40: 4.3373 (4.2324)  loss_n_60: 4.6820 (4.5993)  loss_n_80: 4.8118 (4.7420)  loss_n_100: 4.8441 (4.7885)  triple_100: 486.2342 (499.0121)  triple_80: 489.6267 (501.6761)  triple_60: 487.2957 (498.3795)  triple_40: 463.3921 (473.3871)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1590/1724]  eta: 0:08:47  lr: 0.000000  loss: 2017.7545 (1991.0252)  loss_n_40: 4.2786 (4.2322)  loss_n_60: 4.6056 (4.5989)  loss_n_80: 4.7579 (4.7416)  loss_n_100: 4.8094 (4.7881)  triple_100: 503.3800 (499.0633)  triple_80: 507.1226 (501.7272)  triple_60: 505.0939 (498.4311)  triple_40: 482.6004 (473.4427)  time: 3.9283  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1600/1724]  eta: 0:08:07  lr: 0.000000  loss: 2018.5582 (1991.4778)  loss_n_40: 4.1268 (4.2315)  loss_n_60: 4.5217 (4.5980)  loss_n_80: 4.6288 (4.7407)  loss_n_100: 4.6722 (4.7873)  triple_100: 505.9967 (499.1760)  triple_80: 508.0915 (501.8386)  triple_60: 505.0939 (498.5438)  triple_40: 482.6004 (473.5620)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1610/1724]  eta: 0:07:28  lr: 0.000000  loss: 2018.5582 (1991.4687)  loss_n_40: 4.1715 (4.2313)  loss_n_60: 4.5450 (4.5977)  loss_n_80: 4.6688 (4.7404)  loss_n_100: 4.7221 (4.7870)  triple_100: 505.9967 (499.1725)  triple_80: 508.0915 (501.8346)  triple_60: 504.9672 (498.5401)  triple_40: 482.0464 (473.5650)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1620/1724]  eta: 0:06:49  lr: 0.000000  loss: 2031.4668 (1991.6971)  loss_n_40: 4.1937 (4.2308)  loss_n_60: 4.5460 (4.5970)  loss_n_80: 4.6756 (4.7397)  loss_n_100: 4.7324 (4.7864)  triple_100: 509.0764 (499.2308)  triple_80: 511.7441 (501.8914)  triple_60: 508.1374 (498.5961)  triple_40: 484.5848 (473.6247)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1630/1724]  eta: 0:06:09  lr: 0.000000  loss: 2026.8613 (1991.8499)  loss_n_40: 4.1853 (4.2309)  loss_n_60: 4.5525 (4.5969)  loss_n_80: 4.7170 (4.7396)  loss_n_100: 4.7700 (4.7863)  triple_100: 508.1824 (499.2677)  triple_80: 510.8927 (501.9283)  triple_60: 507.3853 (498.6343)  triple_40: 481.9597 (473.6659)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1640/1724]  eta: 0:05:30  lr: 0.000000  loss: 2016.0699 (1991.8448)  loss_n_40: 4.1782 (4.2306)  loss_n_60: 4.5453 (4.5965)  loss_n_80: 4.7051 (4.7392)  loss_n_100: 4.7609 (4.7859)  triple_100: 504.1037 (499.2667)  triple_80: 507.1498 (501.9273)  triple_60: 504.7280 (498.6334)  triple_40: 481.0272 (473.6652)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1650/1724]  eta: 0:04:51  lr: 0.000000  loss: 1930.0673 (1991.5810)  loss_n_40: 4.2141 (4.2311)  loss_n_60: 4.5881 (4.5970)  loss_n_80: 4.7264 (4.7397)  loss_n_100: 4.7647 (4.7864)  triple_100: 483.9200 (499.2022)  triple_80: 486.8123 (501.8637)  triple_60: 483.4486 (498.5680)  triple_40: 457.0573 (473.5930)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1660/1724]  eta: 0:04:11  lr: 0.000000  loss: 1930.0673 (1991.4355)  loss_n_40: 4.2885 (4.2312)  loss_n_60: 4.6996 (4.5975)  loss_n_80: 4.8435 (4.7402)  loss_n_100: 4.8881 (4.7869)  triple_100: 483.9200 (499.1678)  triple_80: 486.8123 (501.8297)  triple_60: 483.4486 (498.5323)  triple_40: 457.0573 (473.5500)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1670/1724]  eta: 0:03:32  lr: 0.000000  loss: 1962.3323 (1991.3649)  loss_n_40: 4.1862 (4.2308)  loss_n_60: 4.6385 (4.5972)  loss_n_80: 4.7913 (4.7400)  loss_n_100: 4.8229 (4.7868)  triple_100: 492.8094 (499.1533)  triple_80: 495.6190 (501.8148)  triple_60: 491.5358 (498.5143)  triple_40: 463.9781 (473.5276)  time: 3.9308  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1680/1724]  eta: 0:02:53  lr: 0.000000  loss: 2012.0391 (1991.7353)  loss_n_40: 4.1862 (4.2304)  loss_n_60: 4.5767 (4.5968)  loss_n_80: 4.7589 (4.7396)  loss_n_100: 4.7904 (4.7863)  triple_100: 503.8521 (499.2471)  triple_80: 506.8940 (501.9074)  triple_60: 503.6747 (498.6060)  triple_40: 479.8713 (473.6216)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1690/1724]  eta: 0:02:13  lr: 0.000000  loss: 2011.6106 (1991.5474)  loss_n_40: 4.2074 (4.2307)  loss_n_60: 4.6078 (4.5972)  loss_n_80: 4.7589 (4.7399)  loss_n_100: 4.7904 (4.7866)  triple_100: 503.7755 (499.2006)  triple_80: 506.2352 (501.8613)  triple_60: 503.0130 (498.5591)  triple_40: 478.5472 (473.5719)  time: 3.9297  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1700/1724]  eta: 0:01:34  lr: 0.000000  loss: 1931.3734 (1991.4897)  loss_n_40: 4.1779 (4.2303)  loss_n_60: 4.5809 (4.5966)  loss_n_80: 4.7363 (4.7394)  loss_n_100: 4.7849 (4.7862)  triple_100: 484.2824 (499.1862)  triple_80: 487.3435 (501.8456)  triple_60: 483.6026 (498.5440)  triple_40: 457.6035 (473.5612)  time: 3.9293  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1710/1724]  eta: 0:00:55  lr: 0.000000  loss: 1953.7223 (1991.4156)  loss_n_40: 4.1047 (4.2299)  loss_n_60: 4.5063 (4.5961)  loss_n_80: 4.6687 (4.7389)  loss_n_100: 4.7209 (4.7857)  triple_100: 488.9741 (499.1694)  triple_80: 491.2462 (501.8278)  triple_60: 488.7722 (498.5257)  triple_40: 466.1252 (473.5422)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1720/1724]  eta: 0:00:15  lr: 0.000000  loss: 1922.8508 (1991.1302)  loss_n_40: 4.1069 (4.2296)  loss_n_60: 4.5063 (4.5960)  loss_n_80: 4.6695 (4.7389)  loss_n_100: 4.7209 (4.7857)  triple_100: 483.6787 (499.1002)  triple_80: 485.3757 (501.7583)  triple_60: 481.2212 (498.4546)  triple_40: 456.6706 (473.4670)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0]  [1723/1724]  eta: 0:00:03  lr: 0.000000  loss: 1917.2306 (1990.9047)  loss_n_40: 4.1649 (4.2301)  loss_n_60: 4.5319 (4.5965)  loss_n_80: 4.6806 (4.7394)  loss_n_100: 4.7422 (4.7862)  triple_100: 481.6541 (499.0428)  triple_80: 484.3489 (501.7019)  triple_60: 480.2959 (498.3985)  triple_40: 452.9257 (473.4093)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:0] Total time: 1:53:00 (3.9328 s / it)\n",
      "Averaged stats: lr: 0.000000  loss: 1917.2306 (1990.9047)  loss_n_40: 4.1649 (4.2301)  loss_n_60: 4.5319 (4.5965)  loss_n_80: 4.6806 (4.7394)  loss_n_100: 4.7422 (4.7862)  triple_100: 481.6541 (499.0428)  triple_80: 484.3489 (501.7019)  triple_60: 480.2959 (498.3985)  triple_40: 452.9257 (473.4093)\n",
      "Valid: [epoch:0]  [  0/845]  eta: 0:09:48  loss: 2048.4312 (2048.4312)  loss_n_40: 4.0832 (4.0832)  loss_n_60: 4.6028 (4.6028)  loss_n_80: 4.8059 (4.8059)  loss_n_100: 4.8198 (4.8198)  triple_100: 514.9633 (514.9633)  triple_80: 517.3455 (517.3455)  triple_60: 512.7903 (512.7903)  triple_40: 485.0204 (485.0204)  time: 0.6965  data: 0.3604  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:0]  [ 10/845]  eta: 0:05:06  loss: 1983.4667 (2112.6789)  loss_n_40: 4.0753 (4.0011)  loss_n_60: 4.5065 (4.3172)  loss_n_80: 4.7022 (4.4704)  loss_n_100: 4.7420 (4.5341)  triple_100: 497.5216 (530.1279)  triple_80: 500.4344 (532.0821)  triple_60: 496.8157 (528.6332)  triple_40: 469.0607 (504.5129)  time: 0.3674  data: 0.0329  max mem: 46473\n",
      "Valid: [epoch:0]  [ 20/845]  eta: 0:04:50  loss: 1903.5430 (2035.6949)  loss_n_40: 4.1224 (4.1767)  loss_n_60: 4.5202 (4.5187)  loss_n_80: 4.7022 (4.6742)  loss_n_100: 4.7420 (4.7295)  triple_100: 479.7825 (510.6011)  triple_80: 481.6069 (512.8927)  triple_60: 476.8196 (509.5216)  triple_40: 449.9191 (484.5802)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [ 30/845]  eta: 0:04:42  loss: 1871.8983 (2018.2978)  loss_n_40: 4.2509 (4.1887)  loss_n_60: 4.5510 (4.5317)  loss_n_80: 4.7380 (4.6832)  loss_n_100: 4.7782 (4.7377)  triple_100: 470.7992 (506.2460)  triple_80: 472.9684 (508.5875)  triple_60: 469.0456 (505.2558)  triple_40: 440.8134 (480.0672)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [ 40/845]  eta: 0:04:36  loss: 1899.4661 (2039.2410)  loss_n_40: 4.2003 (4.1711)  loss_n_60: 4.5446 (4.4993)  loss_n_80: 4.6938 (4.6428)  loss_n_100: 4.7646 (4.6989)  triple_100: 474.3533 (511.2559)  triple_80: 478.1764 (513.6031)  triple_60: 476.2185 (510.4574)  triple_40: 450.6957 (485.9125)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [ 50/845]  eta: 0:04:31  loss: 2058.8149 (2063.3185)  loss_n_40: 4.0251 (4.1471)  loss_n_60: 4.4776 (4.4640)  loss_n_80: 4.6287 (4.6085)  loss_n_100: 4.6970 (4.6655)  triple_100: 517.3338 (517.2034)  triple_80: 519.9362 (519.5267)  triple_60: 515.7485 (516.3726)  triple_40: 487.2383 (492.3307)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [ 60/845]  eta: 0:04:27  loss: 1996.7024 (2062.2907)  loss_n_40: 4.0345 (4.1660)  loss_n_60: 4.5259 (4.4695)  loss_n_80: 4.6997 (4.6104)  loss_n_100: 4.7222 (4.6656)  triple_100: 500.9987 (516.7820)  triple_80: 503.8869 (519.1679)  triple_60: 499.9820 (516.1199)  triple_40: 471.3739 (492.3093)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [ 70/845]  eta: 0:04:23  loss: 1871.6254 (2042.1092)  loss_n_40: 4.0882 (4.1684)  loss_n_60: 4.5639 (4.4897)  loss_n_80: 4.7370 (4.6334)  loss_n_100: 4.7751 (4.6874)  triple_100: 468.7391 (511.8966)  triple_80: 472.2984 (514.2885)  triple_60: 468.9471 (511.1029)  triple_40: 440.9450 (486.8422)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [ 80/845]  eta: 0:04:19  loss: 1855.4419 (2026.4476)  loss_n_40: 4.1666 (4.1917)  loss_n_60: 4.5706 (4.5233)  loss_n_80: 4.7427 (4.6674)  loss_n_100: 4.7888 (4.7182)  triple_100: 465.6852 (507.9911)  triple_80: 468.2371 (510.4330)  triple_60: 464.4303 (507.2197)  triple_40: 439.9268 (482.7031)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [ 90/845]  eta: 0:04:15  loss: 1860.3789 (2025.3550)  loss_n_40: 4.4062 (4.2033)  loss_n_60: 4.6779 (4.5304)  loss_n_80: 4.8097 (4.6708)  loss_n_100: 4.8765 (4.7226)  triple_100: 466.2171 (507.6070)  triple_80: 469.3856 (510.1127)  triple_60: 466.1849 (506.9545)  triple_40: 439.7834 (482.5536)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [100/845]  eta: 0:04:12  loss: 1846.7933 (2018.5911)  loss_n_40: 4.3095 (4.2061)  loss_n_60: 4.6046 (4.5291)  loss_n_80: 4.7476 (4.6702)  loss_n_100: 4.7893 (4.7219)  triple_100: 464.4240 (505.9206)  triple_80: 466.5932 (508.4409)  triple_60: 462.2752 (505.2834)  triple_40: 439.0526 (480.8188)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [110/845]  eta: 0:04:08  loss: 1911.6005 (2025.7852)  loss_n_40: 4.2334 (4.1949)  loss_n_60: 4.5427 (4.5135)  loss_n_80: 4.7040 (4.6528)  loss_n_100: 4.7581 (4.7043)  triple_100: 479.8894 (507.7071)  triple_80: 482.6041 (510.2270)  triple_60: 478.3878 (507.0845)  triple_40: 452.1700 (482.7011)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [120/845]  eta: 0:04:04  loss: 1885.4819 (2011.5603)  loss_n_40: 4.1353 (4.1977)  loss_n_60: 4.5427 (4.5222)  loss_n_80: 4.6913 (4.6626)  loss_n_100: 4.7373 (4.7138)  triple_100: 472.6382 (504.2214)  triple_80: 475.6257 (506.7469)  triple_60: 472.5628 (503.5445)  triple_40: 442.8483 (478.9512)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [130/845]  eta: 0:04:01  loss: 1879.9594 (2006.4454)  loss_n_40: 4.2236 (4.2171)  loss_n_60: 4.5840 (4.5466)  loss_n_80: 4.7456 (4.6861)  loss_n_100: 4.8101 (4.7360)  triple_100: 472.6382 (502.9077)  triple_80: 475.1817 (505.4844)  triple_60: 470.1319 (502.2776)  triple_40: 443.1267 (477.5900)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [140/845]  eta: 0:03:57  loss: 1910.0212 (2003.5410)  loss_n_40: 4.3503 (4.2182)  loss_n_60: 4.6455 (4.5552)  loss_n_80: 4.8153 (4.6952)  loss_n_100: 4.8783 (4.7438)  triple_100: 480.5817 (502.2083)  triple_80: 482.6077 (504.7995)  triple_60: 477.8752 (501.5546)  triple_40: 450.6115 (476.7663)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [150/845]  eta: 0:03:54  loss: 1910.0212 (1996.5638)  loss_n_40: 4.3591 (4.2369)  loss_n_60: 4.6930 (4.5779)  loss_n_80: 4.8732 (4.7182)  loss_n_100: 4.8978 (4.7658)  triple_100: 480.5817 (500.4598)  triple_80: 482.6077 (503.0826)  triple_60: 477.8752 (499.8184)  triple_40: 450.6115 (474.9041)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [160/845]  eta: 0:03:50  loss: 1890.0282 (1999.2396)  loss_n_40: 4.3125 (4.2237)  loss_n_60: 4.6596 (4.5624)  loss_n_80: 4.8180 (4.7035)  loss_n_100: 4.8861 (4.7529)  triple_100: 474.2975 (501.1762)  triple_80: 477.2000 (503.7423)  triple_60: 473.4354 (500.4713)  triple_40: 446.0478 (475.6072)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [170/845]  eta: 0:03:47  loss: 1890.0282 (1997.2548)  loss_n_40: 4.1171 (4.2214)  loss_n_60: 4.5181 (4.5636)  loss_n_80: 4.6886 (4.7061)  loss_n_100: 4.7447 (4.7551)  triple_100: 475.2241 (500.7178)  triple_80: 477.2000 (503.2817)  triple_60: 473.0609 (499.9770)  triple_40: 446.0478 (475.0321)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [180/845]  eta: 0:03:43  loss: 1892.1882 (1994.5436)  loss_n_40: 4.1260 (4.2266)  loss_n_60: 4.5548 (4.5729)  loss_n_80: 4.7280 (4.7151)  loss_n_100: 4.7703 (4.7630)  triple_100: 475.2241 (500.0407)  triple_80: 477.8071 (502.6271)  triple_60: 473.8872 (499.3155)  triple_40: 447.3120 (474.2826)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [190/845]  eta: 0:03:40  loss: 1891.3206 (1989.5090)  loss_n_40: 4.2403 (4.2344)  loss_n_60: 4.6204 (4.5830)  loss_n_80: 4.7781 (4.7254)  loss_n_100: 4.8353 (4.7730)  triple_100: 474.4899 (498.7907)  triple_80: 477.0891 (501.3896)  triple_60: 473.9302 (498.0632)  triple_40: 447.5408 (472.9496)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [200/845]  eta: 0:03:37  loss: 1884.5027 (1990.5232)  loss_n_40: 4.2367 (4.2344)  loss_n_60: 4.5755 (4.5866)  loss_n_80: 4.7653 (4.7290)  loss_n_100: 4.7611 (4.7760)  triple_100: 471.0329 (499.0326)  triple_80: 474.5363 (501.6495)  triple_60: 471.6218 (498.3282)  triple_40: 447.3323 (473.1868)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [210/845]  eta: 0:03:33  loss: 1944.9332 (1993.8505)  loss_n_40: 4.0413 (4.2259)  loss_n_60: 4.5351 (4.5811)  loss_n_80: 4.7100 (4.7245)  loss_n_100: 4.7556 (4.7724)  triple_100: 486.4743 (499.8956)  triple_80: 489.8636 (502.4975)  triple_60: 487.0925 (499.1623)  triple_40: 460.7567 (473.9911)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [220/845]  eta: 0:03:30  loss: 1944.9332 (1996.6238)  loss_n_40: 4.0511 (4.2251)  loss_n_60: 4.5226 (4.5790)  loss_n_80: 4.6905 (4.7224)  loss_n_100: 4.7366 (4.7703)  triple_100: 486.4743 (500.6011)  triple_80: 489.8636 (503.1924)  triple_60: 487.0925 (499.8455)  triple_40: 460.5973 (474.6880)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [230/845]  eta: 0:03:26  loss: 1924.1069 (1997.8660)  loss_n_40: 4.0580 (4.2259)  loss_n_60: 4.5296 (4.5817)  loss_n_80: 4.6988 (4.7250)  loss_n_100: 4.7366 (4.7724)  triple_100: 481.1909 (500.8924)  triple_80: 484.9615 (503.4823)  triple_60: 481.7031 (500.1487)  triple_40: 455.1182 (475.0375)  time: 0.3348  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:0]  [240/845]  eta: 0:03:23  loss: 1872.1250 (1995.1662)  loss_n_40: 4.2307 (4.2323)  loss_n_60: 4.6040 (4.5859)  loss_n_80: 4.7762 (4.7289)  loss_n_100: 4.8201 (4.7765)  triple_100: 467.1151 (500.2022)  triple_80: 470.6974 (502.7975)  triple_60: 468.8766 (499.4729)  triple_40: 444.2668 (474.3701)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [250/845]  eta: 0:03:20  loss: 1875.1837 (1991.2167)  loss_n_40: 4.2769 (4.2335)  loss_n_60: 4.6040 (4.5891)  loss_n_80: 4.7762 (4.7326)  loss_n_100: 4.8239 (4.7801)  triple_100: 470.1454 (499.2324)  triple_80: 473.7277 (501.8362)  triple_60: 469.3795 (498.4872)  triple_40: 442.2248 (473.3256)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [260/845]  eta: 0:03:16  loss: 1904.8696 (1991.5446)  loss_n_40: 4.3227 (4.2395)  loss_n_60: 4.6523 (4.5961)  loss_n_80: 4.7925 (4.7391)  loss_n_100: 4.8775 (4.7859)  triple_100: 477.7754 (499.2953)  triple_80: 480.3401 (501.9162)  triple_60: 477.0475 (498.5775)  triple_40: 451.1259 (473.3950)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [270/845]  eta: 0:03:13  loss: 1926.5813 (1994.1332)  loss_n_40: 4.3125 (4.2352)  loss_n_60: 4.5990 (4.5885)  loss_n_80: 4.7763 (4.7316)  loss_n_100: 4.8198 (4.7788)  triple_100: 482.2239 (499.9334)  triple_80: 485.7092 (502.5550)  triple_60: 482.3180 (499.2196)  triple_40: 455.6984 (474.0911)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [280/845]  eta: 0:03:09  loss: 1897.0801 (1992.7414)  loss_n_40: 4.0710 (4.2310)  loss_n_60: 4.4995 (4.5855)  loss_n_80: 4.6624 (4.7287)  loss_n_100: 4.7197 (4.7762)  triple_100: 475.3441 (499.6064)  triple_80: 478.4704 (502.2253)  triple_60: 474.7341 (498.8774)  triple_40: 449.6949 (473.7109)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [290/845]  eta: 0:03:06  loss: 1884.3542 (1990.9563)  loss_n_40: 4.1330 (4.2346)  loss_n_60: 4.5152 (4.5906)  loss_n_80: 4.6703 (4.7334)  loss_n_100: 4.7329 (4.7809)  triple_100: 472.8517 (499.1615)  triple_80: 475.6776 (501.7856)  triple_60: 472.4044 (498.4398)  triple_40: 446.6611 (473.2298)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [300/845]  eta: 0:03:03  loss: 1871.8044 (1989.8200)  loss_n_40: 4.3266 (4.2360)  loss_n_60: 4.6669 (4.5918)  loss_n_80: 4.8157 (4.7339)  loss_n_100: 4.8843 (4.7814)  triple_100: 470.7357 (498.8593)  triple_80: 472.9560 (501.4961)  triple_60: 468.6170 (498.1596)  triple_40: 444.0313 (472.9620)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [310/845]  eta: 0:02:59  loss: 1883.8408 (1990.2982)  loss_n_40: 4.2272 (4.2366)  loss_n_60: 4.5587 (4.5907)  loss_n_80: 4.7127 (4.7326)  loss_n_100: 4.7913 (4.7803)  triple_100: 471.8437 (498.9713)  triple_80: 474.5906 (501.5992)  triple_60: 471.8232 (498.2782)  triple_40: 445.5646 (473.1094)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [320/845]  eta: 0:02:56  loss: 1899.7213 (1990.2731)  loss_n_40: 4.1933 (4.2358)  loss_n_60: 4.5522 (4.5911)  loss_n_80: 4.7127 (4.7333)  loss_n_100: 4.7705 (4.7808)  triple_100: 476.2328 (498.9716)  triple_80: 479.3041 (501.6046)  triple_60: 476.0944 (498.2801)  triple_40: 447.4991 (473.0758)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [330/845]  eta: 0:02:52  loss: 1941.5389 (1989.1973)  loss_n_40: 4.1933 (4.2404)  loss_n_60: 4.5666 (4.5981)  loss_n_80: 4.7490 (4.7402)  loss_n_100: 4.7736 (4.7871)  triple_100: 485.3242 (498.6870)  triple_80: 489.0265 (501.3384)  triple_60: 486.2156 (498.0134)  triple_40: 459.4558 (472.7927)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [340/845]  eta: 0:02:49  loss: 1925.8037 (1991.1214)  loss_n_40: 4.2196 (4.2402)  loss_n_60: 4.5627 (4.5960)  loss_n_80: 4.7003 (4.7372)  loss_n_100: 4.7668 (4.7844)  triple_100: 484.4495 (499.1500)  triple_80: 487.7632 (501.8002)  triple_60: 482.1234 (498.4878)  triple_40: 452.7382 (473.3255)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [350/845]  eta: 0:02:46  loss: 1895.3405 (1993.0235)  loss_n_40: 4.1561 (4.2350)  loss_n_60: 4.5407 (4.5887)  loss_n_80: 4.7003 (4.7301)  loss_n_100: 4.7668 (4.7783)  triple_100: 476.0732 (499.6378)  triple_80: 478.8237 (502.2731)  triple_60: 474.9709 (498.9648)  triple_40: 446.3395 (473.8157)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [360/845]  eta: 0:02:42  loss: 1891.2620 (1991.4261)  loss_n_40: 4.2090 (4.2377)  loss_n_60: 4.5530 (4.5915)  loss_n_80: 4.7317 (4.7328)  loss_n_100: 4.8114 (4.7809)  triple_100: 472.4241 (499.2471)  triple_80: 476.5735 (501.8799)  triple_60: 473.4662 (498.5663)  triple_40: 446.1076 (473.3899)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [370/845]  eta: 0:02:39  loss: 1868.8848 (1992.2313)  loss_n_40: 4.1610 (4.2362)  loss_n_60: 4.5649 (4.5897)  loss_n_80: 4.7292 (4.7307)  loss_n_100: 4.7656 (4.7789)  triple_100: 470.1413 (499.4290)  triple_80: 472.3588 (502.0656)  triple_60: 468.0741 (498.7636)  triple_40: 440.0267 (473.6376)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [380/845]  eta: 0:02:36  loss: 1895.4490 (1990.2903)  loss_n_40: 4.1297 (4.2372)  loss_n_60: 4.5486 (4.5916)  loss_n_80: 4.7100 (4.7332)  loss_n_100: 4.7545 (4.7813)  triple_100: 475.2198 (498.9558)  triple_80: 478.3302 (501.6006)  triple_60: 474.8477 (498.2826)  triple_40: 447.7777 (473.1081)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [390/845]  eta: 0:02:32  loss: 1903.9219 (1991.8409)  loss_n_40: 4.1808 (4.2374)  loss_n_60: 4.5918 (4.5908)  loss_n_80: 4.7571 (4.7320)  loss_n_100: 4.7948 (4.7801)  triple_100: 478.1493 (499.3331)  triple_80: 480.9103 (501.9785)  triple_60: 476.4543 (498.6620)  triple_40: 449.7843 (473.5270)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [400/845]  eta: 0:02:29  loss: 1916.5389 (1990.8659)  loss_n_40: 4.3887 (4.2400)  loss_n_60: 4.7025 (4.5955)  loss_n_80: 4.8336 (4.7370)  loss_n_100: 4.8860 (4.7848)  triple_100: 481.8369 (499.0930)  triple_80: 484.4882 (501.7471)  triple_60: 479.8223 (498.4236)  triple_40: 452.1635 (473.2450)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [410/845]  eta: 0:02:26  loss: 1937.1610 (1992.5895)  loss_n_40: 4.1443 (4.2377)  loss_n_60: 4.5685 (4.5933)  loss_n_80: 4.7351 (4.7348)  loss_n_100: 4.7929 (4.7824)  triple_100: 488.2779 (499.5270)  triple_80: 490.2974 (502.1789)  triple_60: 484.9110 (498.8585)  triple_40: 455.8736 (473.6770)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [420/845]  eta: 0:02:22  loss: 1937.1610 (1992.9794)  loss_n_40: 4.1037 (4.2374)  loss_n_60: 4.5758 (4.5940)  loss_n_80: 4.7351 (4.7358)  loss_n_100: 4.7936 (4.7835)  triple_100: 488.2779 (499.6299)  triple_80: 490.2974 (502.2808)  triple_60: 484.9110 (498.9589)  triple_40: 455.8736 (473.7590)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [430/845]  eta: 0:02:19  loss: 1925.0256 (1992.1335)  loss_n_40: 4.4854 (4.2416)  loss_n_60: 4.7706 (4.5993)  loss_n_80: 4.8617 (4.7408)  loss_n_100: 4.8959 (4.7882)  triple_100: 480.9434 (499.4027)  triple_80: 484.5778 (502.0673)  triple_60: 482.1902 (498.7486)  triple_40: 458.2494 (473.5450)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [440/845]  eta: 0:02:15  loss: 1935.6656 (1994.3472)  loss_n_40: 4.1668 (4.2395)  loss_n_60: 4.5262 (4.5963)  loss_n_80: 4.7089 (4.7378)  loss_n_100: 4.7526 (4.7848)  triple_100: 484.1941 (499.9548)  triple_80: 488.2042 (502.6179)  triple_60: 485.1337 (499.2959)  triple_40: 458.5449 (474.1203)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [450/845]  eta: 0:02:12  loss: 1925.1523 (1994.4357)  loss_n_40: 4.0387 (4.2367)  loss_n_60: 4.5168 (4.5935)  loss_n_80: 4.6966 (4.7350)  loss_n_100: 4.7468 (4.7824)  triple_100: 483.1359 (499.9777)  triple_80: 486.2886 (502.6371)  triple_60: 482.3016 (499.3178)  triple_40: 455.1135 (474.1556)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [460/845]  eta: 0:02:09  loss: 1946.0883 (1995.2368)  loss_n_40: 4.0860 (4.2387)  loss_n_60: 4.5343 (4.5955)  loss_n_80: 4.6966 (4.7370)  loss_n_100: 4.7865 (4.7841)  triple_100: 487.3548 (500.1734)  triple_80: 490.5234 (502.8374)  triple_60: 487.3041 (499.5136)  triple_40: 460.4868 (474.3570)  time: 0.3348  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:0]  [470/845]  eta: 0:02:05  loss: 1954.3937 (1996.8621)  loss_n_40: 4.0860 (4.2365)  loss_n_60: 4.5144 (4.5924)  loss_n_80: 4.6800 (4.7342)  loss_n_100: 4.7418 (4.7814)  triple_100: 488.8310 (500.5885)  triple_80: 492.1548 (503.2489)  triple_60: 489.7065 (499.9181)  triple_40: 464.4762 (474.7620)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [480/845]  eta: 0:02:02  loss: 1954.3937 (1997.8336)  loss_n_40: 4.0426 (4.2361)  loss_n_60: 4.5144 (4.5928)  loss_n_80: 4.6885 (4.7349)  loss_n_100: 4.7402 (4.7820)  triple_100: 491.2708 (500.8358)  triple_80: 494.2058 (503.4968)  triple_60: 489.7065 (500.1598)  triple_40: 464.4762 (474.9954)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [490/845]  eta: 0:01:59  loss: 1917.3025 (1998.5189)  loss_n_40: 4.0850 (4.2370)  loss_n_60: 4.5262 (4.5939)  loss_n_80: 4.7095 (4.7357)  loss_n_100: 4.7423 (4.7825)  triple_100: 479.4295 (500.9943)  triple_80: 482.9706 (503.6642)  triple_60: 479.9711 (500.3320)  triple_40: 453.9246 (475.1793)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [500/845]  eta: 0:01:55  loss: 1898.5435 (1996.5918)  loss_n_40: 4.5260 (4.2442)  loss_n_60: 4.9219 (4.6025)  loss_n_80: 5.0261 (4.7441)  loss_n_100: 5.0637 (4.7901)  triple_100: 475.2329 (500.4921)  triple_80: 478.0367 (503.1747)  triple_60: 475.3105 (499.8482)  triple_40: 447.9133 (474.6958)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [510/845]  eta: 0:01:52  loss: 1884.6650 (1996.6794)  loss_n_40: 4.2825 (4.2418)  loss_n_60: 4.6096 (4.6003)  loss_n_80: 4.7496 (4.7419)  loss_n_100: 4.8228 (4.7881)  triple_100: 473.9313 (500.5190)  triple_80: 476.8060 (503.1961)  triple_60: 471.7636 (499.8697)  triple_40: 446.9595 (474.7225)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [520/845]  eta: 0:01:49  loss: 1884.6650 (1996.5000)  loss_n_40: 4.1802 (4.2405)  loss_n_60: 4.5311 (4.5992)  loss_n_80: 4.6972 (4.7410)  loss_n_100: 4.7393 (4.7872)  triple_100: 473.9313 (500.4774)  triple_80: 476.8060 (503.1547)  triple_60: 471.7636 (499.8234)  triple_40: 445.4445 (474.6767)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [530/845]  eta: 0:01:45  loss: 1910.0566 (1997.1434)  loss_n_40: 4.2628 (4.2441)  loss_n_60: 4.6003 (4.6008)  loss_n_80: 4.7195 (4.7421)  loss_n_100: 4.7792 (4.7879)  triple_100: 477.7372 (500.6079)  triple_80: 481.1270 (503.2969)  triple_60: 478.0012 (499.9806)  triple_40: 452.5017 (474.8831)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [540/845]  eta: 0:01:42  loss: 1866.6926 (1995.0709)  loss_n_40: 4.4151 (4.2460)  loss_n_60: 4.6935 (4.6035)  loss_n_80: 4.8183 (4.7449)  loss_n_100: 4.8849 (4.7906)  triple_100: 466.2793 (500.0894)  triple_80: 470.3475 (502.7831)  triple_60: 467.4864 (499.4646)  triple_40: 442.2630 (474.3488)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [550/845]  eta: 0:01:38  loss: 1861.1707 (1993.2942)  loss_n_40: 4.3360 (4.2485)  loss_n_60: 4.6642 (4.6062)  loss_n_80: 4.8069 (4.7475)  loss_n_100: 4.8673 (4.7931)  triple_100: 466.2793 (499.6385)  triple_80: 469.4661 (502.3417)  triple_60: 466.6673 (499.0220)  triple_40: 439.9638 (473.8966)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [560/845]  eta: 0:01:35  loss: 1897.0679 (1994.4613)  loss_n_40: 4.1076 (4.2443)  loss_n_60: 4.5042 (4.6021)  loss_n_80: 4.6660 (4.7434)  loss_n_100: 4.7093 (4.7890)  triple_100: 475.9613 (499.9351)  triple_80: 479.7115 (502.6399)  triple_60: 474.5606 (499.3164)  triple_40: 447.9846 (474.1910)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [570/845]  eta: 0:01:32  loss: 1906.6545 (1993.7055)  loss_n_40: 4.0282 (4.2420)  loss_n_60: 4.5042 (4.6003)  loss_n_80: 4.6657 (4.7419)  loss_n_100: 4.7093 (4.7876)  triple_100: 479.6302 (499.7598)  triple_80: 481.7967 (502.4616)  triple_60: 477.2623 (499.1274)  triple_40: 449.8366 (473.9850)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [580/845]  eta: 0:01:28  loss: 1888.9613 (1992.8139)  loss_n_40: 4.2499 (4.2459)  loss_n_60: 4.5995 (4.6044)  loss_n_80: 4.7647 (4.7458)  loss_n_100: 4.8264 (4.7916)  triple_100: 472.4803 (499.5267)  triple_80: 476.0115 (502.2332)  triple_60: 472.8992 (498.9049)  triple_40: 447.1502 (473.7614)  time: 0.3353  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [590/845]  eta: 0:01:25  loss: 1844.1761 (1992.9245)  loss_n_40: 4.3364 (4.2450)  loss_n_60: 4.6850 (4.6033)  loss_n_80: 4.8387 (4.7448)  loss_n_100: 4.9178 (4.7906)  triple_100: 459.2866 (499.5570)  triple_80: 463.3691 (502.2604)  triple_60: 462.0283 (498.9319)  triple_40: 439.4145 (473.7914)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [600/845]  eta: 0:01:22  loss: 1892.7820 (1994.1952)  loss_n_40: 4.2737 (4.2454)  loss_n_60: 4.5739 (4.6019)  loss_n_80: 4.7335 (4.7429)  loss_n_100: 4.8005 (4.7888)  triple_100: 475.6521 (499.8512)  triple_80: 478.3649 (502.5632)  triple_60: 473.7432 (499.2515)  triple_40: 446.8252 (474.1503)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [610/845]  eta: 0:01:18  loss: 1892.7820 (1993.8953)  loss_n_40: 4.2105 (4.2440)  loss_n_60: 4.5393 (4.6009)  loss_n_80: 4.7094 (4.7421)  loss_n_100: 4.7602 (4.7880)  triple_100: 475.6521 (499.7853)  triple_80: 478.3649 (502.4931)  triple_60: 473.7432 (499.1792)  triple_40: 446.8252 (474.0628)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [620/845]  eta: 0:01:15  loss: 1925.0453 (1993.4695)  loss_n_40: 4.1363 (4.2442)  loss_n_60: 4.5393 (4.6019)  loss_n_80: 4.7094 (4.7431)  loss_n_100: 4.7517 (4.7890)  triple_100: 484.5048 (499.6817)  triple_80: 487.1397 (502.3893)  triple_60: 481.7645 (499.0735)  triple_40: 453.3719 (473.9468)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [630/845]  eta: 0:01:12  loss: 1902.7854 (1992.9742)  loss_n_40: 4.2790 (4.2451)  loss_n_60: 4.6369 (4.6029)  loss_n_80: 4.7668 (4.7442)  loss_n_100: 4.8582 (4.7901)  triple_100: 476.6908 (499.5564)  triple_80: 479.9931 (502.2648)  triple_60: 476.4512 (498.9493)  triple_40: 450.9012 (473.8213)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [640/845]  eta: 0:01:08  loss: 1902.7854 (1993.4667)  loss_n_40: 4.2790 (4.2450)  loss_n_60: 4.6435 (4.6026)  loss_n_80: 4.7734 (4.7439)  loss_n_100: 4.8509 (4.7897)  triple_100: 475.8188 (499.6774)  triple_80: 479.6072 (502.3887)  triple_60: 476.4512 (499.0712)  triple_40: 450.9012 (473.9482)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [650/845]  eta: 0:01:05  loss: 1904.7235 (1993.1447)  loss_n_40: 4.1488 (4.2435)  loss_n_60: 4.5761 (4.6009)  loss_n_80: 4.7134 (4.7424)  loss_n_100: 4.7740 (4.7883)  triple_100: 475.8188 (499.5996)  triple_80: 479.6072 (502.3102)  triple_60: 476.9942 (498.9924)  triple_40: 451.8961 (473.8673)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [660/845]  eta: 0:01:02  loss: 1940.0459 (1992.9659)  loss_n_40: 4.1707 (4.2441)  loss_n_60: 4.5808 (4.6026)  loss_n_80: 4.7601 (4.7441)  loss_n_100: 4.7975 (4.7897)  triple_100: 486.1900 (499.5588)  triple_80: 489.8494 (502.2706)  triple_60: 486.3503 (498.9499)  triple_40: 459.0223 (473.8062)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [670/845]  eta: 0:00:58  loss: 1898.2719 (1991.3885)  loss_n_40: 4.2386 (4.2461)  loss_n_60: 4.6403 (4.6052)  loss_n_80: 4.7907 (4.7466)  loss_n_100: 4.8315 (4.7921)  triple_100: 475.8976 (499.1641)  triple_80: 479.3871 (501.8816)  triple_60: 475.3472 (498.5578)  triple_40: 449.8518 (473.3950)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [680/845]  eta: 0:00:55  loss: 1877.8416 (1993.8388)  loss_n_40: 4.1775 (4.2423)  loss_n_60: 4.5728 (4.5991)  loss_n_80: 4.7511 (4.7404)  loss_n_100: 4.7847 (4.7864)  triple_100: 472.1599 (499.7750)  triple_80: 474.2809 (502.4810)  triple_60: 470.0261 (499.1629)  triple_40: 443.3597 (474.0517)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [690/845]  eta: 0:00:51  loss: 1978.2639 (1994.5180)  loss_n_40: 4.0281 (4.2407)  loss_n_60: 4.5214 (4.5980)  loss_n_80: 4.7039 (4.7395)  loss_n_100: 4.7530 (4.7855)  triple_100: 497.3822 (499.9460)  triple_80: 500.4191 (502.6555)  triple_60: 496.0017 (499.3365)  triple_40: 466.3817 (474.2163)  time: 0.3349  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:0]  [700/845]  eta: 0:00:48  loss: 1978.2639 (1993.6160)  loss_n_40: 4.0281 (4.2407)  loss_n_60: 4.5204 (4.5991)  loss_n_80: 4.7039 (4.7410)  loss_n_100: 4.7514 (4.7867)  triple_100: 497.3822 (499.7326)  triple_80: 500.4191 (502.4411)  triple_60: 496.0017 (499.1101)  triple_40: 466.3817 (473.9647)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [710/845]  eta: 0:00:45  loss: 1899.7766 (1992.7994)  loss_n_40: 4.1073 (4.2415)  loss_n_60: 4.5204 (4.6008)  loss_n_80: 4.7006 (4.7428)  loss_n_100: 4.7514 (4.7884)  triple_100: 477.1367 (499.5303)  triple_80: 479.8874 (502.2402)  triple_60: 475.6918 (498.9055)  triple_40: 449.1291 (473.7498)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [720/845]  eta: 0:00:41  loss: 1887.5066 (1992.1571)  loss_n_40: 4.1183 (4.2413)  loss_n_60: 4.5391 (4.6003)  loss_n_80: 4.7166 (4.7425)  loss_n_100: 4.7757 (4.7882)  triple_100: 474.4641 (499.3769)  triple_80: 476.9774 (502.0816)  triple_60: 472.3991 (498.7427)  triple_40: 445.1590 (473.5836)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [730/845]  eta: 0:00:38  loss: 1853.2148 (1992.3362)  loss_n_40: 4.3143 (4.2423)  loss_n_60: 4.6138 (4.6006)  loss_n_80: 4.7493 (4.7428)  loss_n_100: 4.8408 (4.7883)  triple_100: 466.0065 (499.4143)  triple_80: 467.8632 (502.1175)  triple_60: 464.3232 (498.7855)  triple_40: 439.3358 (473.6449)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [740/845]  eta: 0:00:35  loss: 1909.0771 (1991.5980)  loss_n_40: 4.4912 (4.2445)  loss_n_60: 4.8540 (4.6037)  loss_n_80: 4.9754 (4.7458)  loss_n_100: 5.0091 (4.7912)  triple_100: 476.8587 (499.2297)  triple_80: 480.6212 (501.9389)  triple_60: 478.0379 (498.6032)  triple_40: 452.8315 (473.4411)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [750/845]  eta: 0:00:31  loss: 1902.8899 (1992.5147)  loss_n_40: 4.2419 (4.2433)  loss_n_60: 4.5777 (4.6018)  loss_n_80: 4.7379 (4.7440)  loss_n_100: 4.8122 (4.7896)  triple_100: 479.2922 (499.4654)  triple_80: 481.1325 (502.1652)  triple_60: 476.4659 (498.8287)  triple_40: 451.0361 (473.6767)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [760/845]  eta: 0:00:28  loss: 1880.7052 (1991.9442)  loss_n_40: 4.1458 (4.2438)  loss_n_60: 4.5135 (4.6025)  loss_n_80: 4.6663 (4.7444)  loss_n_100: 4.7203 (4.7901)  triple_100: 471.5750 (499.3182)  triple_80: 474.6964 (502.0180)  triple_60: 470.5478 (498.6864)  triple_40: 445.6408 (473.5409)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [770/845]  eta: 0:00:25  loss: 1862.5449 (1993.2505)  loss_n_40: 4.1458 (4.2420)  loss_n_60: 4.5223 (4.5993)  loss_n_80: 4.6611 (4.7410)  loss_n_100: 4.7270 (4.7870)  triple_100: 466.8427 (499.6427)  triple_80: 469.8609 (502.3378)  triple_60: 466.4638 (499.0092)  triple_40: 440.0382 (473.8914)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [780/845]  eta: 0:00:21  loss: 1908.0845 (1993.0978)  loss_n_40: 4.0995 (4.2413)  loss_n_60: 4.4890 (4.5990)  loss_n_80: 4.6560 (4.7409)  loss_n_100: 4.7270 (4.7869)  triple_100: 478.3715 (499.6091)  triple_80: 481.3847 (502.3043)  triple_60: 477.2514 (498.9707)  triple_40: 450.2397 (473.8456)  time: 0.3353  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [790/845]  eta: 0:00:18  loss: 1890.1575 (1992.4924)  loss_n_40: 4.1653 (4.2413)  loss_n_60: 4.4972 (4.5986)  loss_n_80: 4.6916 (4.7405)  loss_n_100: 4.7421 (4.7863)  triple_100: 474.2098 (499.4548)  triple_80: 477.1433 (502.1545)  triple_60: 472.9382 (498.8184)  triple_40: 447.7870 (473.6979)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [800/845]  eta: 0:00:15  loss: 1890.1575 (1992.3902)  loss_n_40: 4.1852 (4.2422)  loss_n_60: 4.5339 (4.5998)  loss_n_80: 4.7069 (4.7416)  loss_n_100: 4.7607 (4.7873)  triple_100: 473.8203 (499.4202)  triple_80: 477.1433 (502.1278)  triple_60: 472.9382 (498.7961)  triple_40: 447.7870 (473.6752)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [810/845]  eta: 0:00:11  loss: 1901.6798 (1994.0534)  loss_n_40: 4.2335 (4.2415)  loss_n_60: 4.5838 (4.5974)  loss_n_80: 4.7324 (4.7389)  loss_n_100: 4.8049 (4.7846)  triple_100: 475.3857 (499.8239)  triple_80: 478.5413 (502.5311)  triple_60: 476.9643 (499.2106)  triple_40: 452.3331 (474.1255)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [820/845]  eta: 0:00:08  loss: 1932.6958 (1994.9088)  loss_n_40: 4.1394 (4.2414)  loss_n_60: 4.5560 (4.5968)  loss_n_80: 4.7071 (4.7381)  loss_n_100: 4.7610 (4.7838)  triple_100: 486.3541 (500.0367)  triple_80: 488.9353 (502.7461)  triple_60: 484.0053 (499.4251)  triple_40: 457.6995 (474.3408)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [830/845]  eta: 0:00:05  loss: 1932.6958 (1995.3744)  loss_n_40: 4.1028 (4.2421)  loss_n_60: 4.5516 (4.5973)  loss_n_80: 4.7071 (4.7386)  loss_n_100: 4.7610 (4.7843)  triple_100: 486.3541 (500.1455)  triple_80: 488.9353 (502.8587)  triple_60: 484.0053 (499.5426)  triple_40: 457.6995 (474.4654)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [840/845]  eta: 0:00:01  loss: 1880.0604 (1994.9812)  loss_n_40: 4.2021 (4.2416)  loss_n_60: 4.5418 (4.5969)  loss_n_80: 4.7262 (4.7383)  loss_n_100: 4.7660 (4.7841)  triple_100: 472.7724 (500.0503)  triple_80: 475.0703 (502.7649)  triple_60: 470.0569 (499.4461)  triple_40: 444.1701 (474.3591)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0]  [844/845]  eta: 0:00:00  loss: 1907.3833 (1995.3874)  loss_n_40: 4.0736 (4.2407)  loss_n_60: 4.5128 (4.5957)  loss_n_80: 4.6995 (4.7372)  loss_n_100: 4.7404 (4.7830)  triple_100: 476.0875 (500.1576)  triple_80: 479.9372 (502.8680)  triple_60: 477.9701 (499.5476)  triple_40: 451.6701 (474.4577)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:0] Total time: 0:04:43 (0.3355 s / it)\n",
      "Averaged stats: loss: 1907.3833 (1995.3874)  loss_n_40: 4.0736 (4.2407)  loss_n_60: 4.5128 (4.5957)  loss_n_80: 4.6995 (4.7372)  loss_n_100: 4.7404 (4.7830)  triple_100: 476.0875 (500.1576)  triple_80: 479.9372 (502.8680)  triple_60: 477.9701 (499.5476)  triple_40: 451.6701 (474.4577)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_0_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 4.783%\n",
      "Min loss_n_100: 4.783\n",
      "Best Epoch: 0.000\n",
      "/home/sunggu/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Train: [epoch:1]  [   0/1724]  eta: 1:59:38  lr: 0.000000  loss: 1826.8116 (1826.8116)  loss_n_40: 4.3003 (4.3003)  loss_n_60: 4.6628 (4.6628)  loss_n_80: 4.8304 (4.8304)  loss_n_100: 4.8853 (4.8853)  triple_100: 457.7603 (457.7603)  triple_80: 460.2428 (460.2428)  triple_60: 457.3535 (457.3535)  triple_40: 432.7764 (432.7764)  time: 4.1638  data: 0.4049  max mem: 46473\n",
      "Train: [epoch:1]  [  10/1724]  eta: 1:52:51  lr: 0.000000  loss: 1916.9027 (1942.1774)  loss_n_40: 4.3003 (4.3575)  loss_n_60: 4.7043 (4.7264)  loss_n_80: 4.8572 (4.8677)  loss_n_100: 4.9095 (4.9099)  triple_100: 479.5503 (486.5132)  triple_80: 483.2103 (489.3926)  triple_60: 480.1592 (486.2130)  triple_40: 454.0991 (461.1973)  time: 3.9505  data: 0.0370  max mem: 46473\n",
      "Train: [epoch:1]  [  20/1724]  eta: 1:51:52  lr: 0.000000  loss: 2020.1606 (2001.8483)  loss_n_40: 4.1768 (4.2009)  loss_n_60: 4.5445 (4.5669)  loss_n_80: 4.7155 (4.7124)  loss_n_100: 4.7531 (4.7606)  triple_100: 506.1678 (501.7666)  triple_80: 509.1818 (504.4216)  triple_60: 505.7285 (501.1586)  triple_40: 480.9041 (476.2606)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [  30/1724]  eta: 1:51:05  lr: 0.000000  loss: 2027.6046 (2001.1015)  loss_n_40: 4.0754 (4.1921)  loss_n_60: 4.3985 (4.5619)  loss_n_80: 4.5533 (4.7075)  loss_n_100: 4.5947 (4.7571)  triple_100: 507.3213 (501.6546)  triple_80: 509.9822 (504.2611)  triple_60: 507.3047 (500.9939)  triple_40: 482.1984 (475.9733)  time: 3.9263  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [  40/1724]  eta: 1:50:23  lr: 0.000000  loss: 1995.5972 (2003.9419)  loss_n_40: 4.2083 (4.1935)  loss_n_60: 4.5692 (4.5657)  loss_n_80: 4.7071 (4.7095)  loss_n_100: 4.7883 (4.7566)  triple_100: 500.0849 (502.3240)  triple_80: 503.4031 (504.9716)  triple_60: 500.1001 (501.7110)  triple_40: 474.7449 (476.7101)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [  50/1724]  eta: 1:49:42  lr: 0.000000  loss: 1927.5259 (1987.8045)  loss_n_40: 4.1761 (4.2172)  loss_n_60: 4.5627 (4.5894)  loss_n_80: 4.7279 (4.7346)  loss_n_100: 4.7834 (4.7813)  triple_100: 482.7700 (498.2846)  triple_80: 485.7393 (500.9506)  triple_60: 482.6232 (497.6649)  triple_40: 456.0959 (472.5820)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [  60/1724]  eta: 1:49:02  lr: 0.000000  loss: 1927.4167 (1982.9374)  loss_n_40: 4.2403 (4.2236)  loss_n_60: 4.6123 (4.5975)  loss_n_80: 4.7471 (4.7436)  loss_n_100: 4.8027 (4.7894)  triple_100: 482.4983 (497.0944)  triple_80: 485.7393 (499.7699)  triple_60: 482.6232 (496.4610)  triple_40: 456.0959 (471.2580)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [  70/1724]  eta: 1:48:22  lr: 0.000000  loss: 1939.2509 (1984.6366)  loss_n_40: 4.2466 (4.2255)  loss_n_60: 4.6708 (4.5956)  loss_n_80: 4.8067 (4.7418)  loss_n_100: 4.8377 (4.7881)  triple_100: 486.6962 (497.5095)  triple_80: 489.6879 (500.1707)  triple_60: 485.8574 (496.8700)  triple_40: 458.1508 (471.7353)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [  80/1724]  eta: 1:47:42  lr: 0.000000  loss: 2026.1226 (1990.9064)  loss_n_40: 4.1292 (4.2162)  loss_n_60: 4.5095 (4.5835)  loss_n_80: 4.6874 (4.7293)  loss_n_100: 4.7304 (4.7767)  triple_100: 508.6873 (499.0988)  triple_80: 510.9593 (501.7230)  triple_60: 507.3532 (498.4064)  triple_40: 481.5504 (473.3727)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [  90/1724]  eta: 1:47:02  lr: 0.000000  loss: 1907.6414 (1984.1578)  loss_n_40: 4.2512 (4.2285)  loss_n_60: 4.6003 (4.5979)  loss_n_80: 4.7453 (4.7420)  loss_n_100: 4.8040 (4.7889)  triple_100: 479.5036 (497.3679)  triple_80: 482.0154 (500.0250)  triple_60: 477.6327 (496.7317)  triple_40: 452.1074 (471.6758)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 100/1724]  eta: 1:46:22  lr: 0.000000  loss: 1919.6368 (1985.3590)  loss_n_40: 4.2558 (4.2297)  loss_n_60: 4.6853 (4.6028)  loss_n_80: 4.8232 (4.7468)  loss_n_100: 4.8686 (4.7931)  triple_100: 480.7602 (497.6644)  triple_80: 483.8437 (500.3310)  triple_60: 480.4955 (497.0344)  triple_40: 455.4521 (471.9566)  time: 3.9271  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 110/1724]  eta: 1:45:42  lr: 0.000000  loss: 1992.4082 (1988.7470)  loss_n_40: 4.2552 (4.2327)  loss_n_60: 4.6449 (4.6016)  loss_n_80: 4.7773 (4.7453)  loss_n_100: 4.8149 (4.7919)  triple_100: 499.1379 (498.4856)  triple_80: 501.9890 (501.1402)  triple_60: 498.7977 (497.8649)  triple_40: 474.4333 (472.8848)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 120/1724]  eta: 1:45:03  lr: 0.000000  loss: 1986.0846 (1985.8072)  loss_n_40: 4.2552 (4.2396)  loss_n_60: 4.6179 (4.6060)  loss_n_80: 4.7522 (4.7496)  loss_n_100: 4.8067 (4.7963)  triple_100: 499.1379 (497.7359)  triple_80: 501.9890 (500.3879)  triple_60: 497.4682 (497.1214)  triple_40: 469.0879 (472.1704)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 130/1724]  eta: 1:44:23  lr: 0.000000  loss: 1962.7815 (1985.4210)  loss_n_40: 4.2147 (4.2368)  loss_n_60: 4.6156 (4.6056)  loss_n_80: 4.7673 (4.7491)  loss_n_100: 4.8208 (4.7957)  triple_100: 492.6802 (497.6579)  triple_80: 495.5437 (500.3125)  triple_60: 491.7174 (497.0247)  triple_40: 463.9423 (472.0387)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 140/1724]  eta: 1:43:44  lr: 0.000000  loss: 1992.3207 (1987.2157)  loss_n_40: 4.1911 (4.2363)  loss_n_60: 4.6156 (4.6047)  loss_n_80: 4.7673 (4.7484)  loss_n_100: 4.8208 (4.7950)  triple_100: 500.1183 (498.1196)  triple_80: 502.6205 (500.7736)  triple_60: 499.0211 (497.4751)  triple_40: 472.1959 (472.4630)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 150/1724]  eta: 1:43:05  lr: 0.000000  loss: 1938.2002 (1983.2292)  loss_n_40: 4.3101 (4.2424)  loss_n_60: 4.6925 (4.6129)  loss_n_80: 4.8263 (4.7564)  loss_n_100: 4.8716 (4.8029)  triple_100: 486.7074 (497.1515)  triple_80: 489.2131 (499.8057)  triple_60: 485.3990 (496.4780)  triple_40: 458.9588 (471.3793)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 160/1724]  eta: 1:42:25  lr: 0.000000  loss: 1928.4630 (1984.8890)  loss_n_40: 4.3262 (4.2435)  loss_n_60: 4.6925 (4.6112)  loss_n_80: 4.8263 (4.7540)  loss_n_100: 4.8716 (4.8005)  triple_100: 483.4497 (497.5435)  triple_80: 485.9830 (500.2016)  triple_60: 482.9842 (496.8983)  triple_40: 457.6314 (471.8364)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 170/1724]  eta: 1:41:46  lr: 0.000000  loss: 2021.9336 (1984.9401)  loss_n_40: 4.2247 (4.2429)  loss_n_60: 4.5227 (4.6109)  loss_n_80: 4.6886 (4.7537)  loss_n_100: 4.7461 (4.8002)  triple_100: 507.2515 (497.5718)  triple_80: 509.2133 (500.2279)  triple_60: 505.6469 (496.9088)  triple_40: 480.9175 (471.8239)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 180/1724]  eta: 1:41:07  lr: 0.000000  loss: 1984.0134 (1984.8748)  loss_n_40: 4.2619 (4.2465)  loss_n_60: 4.6225 (4.6134)  loss_n_80: 4.7094 (4.7554)  loss_n_100: 4.7578 (4.8020)  triple_100: 496.3397 (497.5398)  triple_80: 499.5526 (500.1949)  triple_60: 496.8842 (496.8927)  triple_40: 472.1281 (471.8301)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 190/1724]  eta: 1:40:27  lr: 0.000000  loss: 1977.7516 (1984.7143)  loss_n_40: 4.3245 (4.2501)  loss_n_60: 4.6268 (4.6163)  loss_n_80: 4.7536 (4.7579)  loss_n_100: 4.8109 (4.8043)  triple_100: 496.0876 (497.4894)  triple_80: 498.0480 (500.1505)  triple_60: 494.9403 (496.8489)  triple_40: 471.0893 (471.7969)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 200/1724]  eta: 1:39:48  lr: 0.000000  loss: 1915.3370 (1985.0295)  loss_n_40: 4.2549 (4.2484)  loss_n_60: 4.6174 (4.6140)  loss_n_80: 4.7371 (4.7553)  loss_n_100: 4.7899 (4.8016)  triple_100: 480.3159 (497.5522)  triple_80: 483.5140 (500.2193)  triple_60: 479.7706 (496.9307)  triple_40: 452.2235 (471.9078)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 210/1724]  eta: 1:39:08  lr: 0.000000  loss: 1911.5389 (1983.7050)  loss_n_40: 4.2605 (4.2516)  loss_n_60: 4.6872 (4.6174)  loss_n_80: 4.8206 (4.7584)  loss_n_100: 4.8751 (4.8047)  triple_100: 480.0076 (497.2096)  triple_80: 482.9141 (499.8830)  triple_60: 478.8976 (496.6018)  triple_40: 450.8513 (471.5784)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 220/1724]  eta: 1:38:29  lr: 0.000000  loss: 1954.0905 (1984.8706)  loss_n_40: 4.2635 (4.2491)  loss_n_60: 4.6468 (4.6137)  loss_n_80: 4.7384 (4.7549)  loss_n_100: 4.7856 (4.8013)  triple_100: 489.4244 (497.5072)  triple_80: 492.4103 (500.1791)  triple_60: 489.2340 (496.8924)  triple_40: 463.6726 (471.8729)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 230/1724]  eta: 1:37:49  lr: 0.000000  loss: 2049.8435 (1987.7150)  loss_n_40: 4.2145 (4.2488)  loss_n_60: 4.5707 (4.6127)  loss_n_80: 4.6857 (4.7535)  loss_n_100: 4.7368 (4.7999)  triple_100: 513.2643 (498.2138)  triple_80: 515.9242 (500.8851)  triple_60: 512.8483 (497.5999)  triple_40: 489.5462 (472.6013)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 240/1724]  eta: 1:37:10  lr: 0.000000  loss: 2030.3718 (1988.0960)  loss_n_40: 4.2082 (4.2458)  loss_n_60: 4.6048 (4.6102)  loss_n_80: 4.6857 (4.7509)  loss_n_100: 4.7368 (4.7976)  triple_100: 508.4272 (498.3177)  triple_80: 511.2737 (500.9872)  triple_60: 508.1953 (497.6934)  triple_40: 483.8153 (472.6932)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 250/1724]  eta: 1:36:30  lr: 0.000000  loss: 1965.2917 (1988.4036)  loss_n_40: 4.2521 (4.2458)  loss_n_60: 4.6335 (4.6097)  loss_n_80: 4.7789 (4.7505)  loss_n_100: 4.8178 (4.7970)  triple_100: 493.4211 (498.3987)  triple_80: 496.1136 (501.0708)  triple_60: 492.1642 (497.7716)  triple_40: 465.6564 (472.7595)  time: 3.9257  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [ 260/1724]  eta: 1:35:51  lr: 0.000000  loss: 1960.5565 (1989.4933)  loss_n_40: 4.2090 (4.2445)  loss_n_60: 4.6063 (4.6076)  loss_n_80: 4.7175 (4.7486)  loss_n_100: 4.7729 (4.7950)  triple_100: 492.0698 (498.6640)  triple_80: 494.7997 (501.3341)  triple_60: 490.9991 (498.0392)  triple_40: 464.3430 (473.0603)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 270/1724]  eta: 1:35:11  lr: 0.000000  loss: 1958.3734 (1988.4200)  loss_n_40: 4.1835 (4.2452)  loss_n_60: 4.5696 (4.6080)  loss_n_80: 4.7091 (4.7492)  loss_n_100: 4.7619 (4.7956)  triple_100: 490.8475 (498.3977)  triple_80: 493.3010 (501.0643)  triple_60: 490.5745 (497.7697)  triple_40: 464.5360 (472.7904)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 280/1724]  eta: 1:34:32  lr: 0.000000  loss: 1984.3452 (1990.7783)  loss_n_40: 4.1844 (4.2422)  loss_n_60: 4.5674 (4.6048)  loss_n_80: 4.7222 (4.7458)  loss_n_100: 4.7705 (4.7925)  triple_100: 498.1057 (498.9866)  triple_80: 500.8956 (501.6534)  triple_60: 496.8557 (498.3595)  triple_40: 469.7436 (473.3935)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 290/1724]  eta: 1:33:53  lr: 0.000000  loss: 2017.3047 (1991.6133)  loss_n_40: 4.2406 (4.2422)  loss_n_60: 4.6047 (4.6045)  loss_n_80: 4.7319 (4.7455)  loss_n_100: 4.7788 (4.7921)  triple_100: 504.4227 (499.1901)  triple_80: 507.6068 (501.8599)  triple_60: 505.3392 (498.5660)  triple_40: 480.8317 (473.6128)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 300/1724]  eta: 1:33:13  lr: 0.000000  loss: 2000.9907 (1991.9034)  loss_n_40: 4.2367 (4.2422)  loss_n_60: 4.5021 (4.6024)  loss_n_80: 4.6343 (4.7430)  loss_n_100: 4.7019 (4.7899)  triple_100: 501.2773 (499.2400)  triple_80: 503.3798 (501.9147)  triple_60: 500.3463 (498.6343)  triple_40: 478.1576 (473.7368)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 310/1724]  eta: 1:32:34  lr: 0.000000  loss: 1971.4764 (1991.7296)  loss_n_40: 4.2367 (4.2426)  loss_n_60: 4.5021 (4.6031)  loss_n_80: 4.6343 (4.7437)  loss_n_100: 4.7019 (4.7906)  triple_100: 492.7180 (499.1998)  triple_80: 495.9696 (501.8758)  triple_60: 493.4172 (498.5917)  triple_40: 470.1821 (473.6823)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 320/1724]  eta: 1:31:55  lr: 0.000000  loss: 1965.5446 (1992.6627)  loss_n_40: 4.2315 (4.2439)  loss_n_60: 4.6436 (4.6035)  loss_n_80: 4.7868 (4.7439)  loss_n_100: 4.8177 (4.7907)  triple_100: 492.7180 (499.4183)  triple_80: 495.8574 (502.0987)  triple_60: 492.0494 (498.8263)  triple_40: 465.9795 (473.9374)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 330/1724]  eta: 1:31:15  lr: 0.000000  loss: 1958.9106 (1991.6222)  loss_n_40: 4.2315 (4.2439)  loss_n_60: 4.6436 (4.6046)  loss_n_80: 4.7868 (4.7452)  loss_n_100: 4.8177 (4.7917)  triple_100: 491.7857 (499.1610)  triple_80: 494.7416 (501.8437)  triple_60: 490.9784 (498.5690)  triple_40: 463.1566 (473.6632)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 340/1724]  eta: 1:30:36  lr: 0.000000  loss: 1958.9106 (1992.9832)  loss_n_40: 4.1663 (4.2407)  loss_n_60: 4.5757 (4.6008)  loss_n_80: 4.7337 (4.7413)  loss_n_100: 4.7850 (4.7880)  triple_100: 491.7857 (499.5088)  triple_80: 494.7416 (502.1860)  triple_60: 490.9784 (498.9096)  triple_40: 463.1566 (474.0080)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 350/1724]  eta: 1:29:57  lr: 0.000000  loss: 2014.6490 (1993.8368)  loss_n_40: 4.1663 (4.2397)  loss_n_60: 4.5388 (4.5986)  loss_n_80: 4.6839 (4.7392)  loss_n_100: 4.7220 (4.7861)  triple_100: 505.7572 (499.7185)  triple_80: 507.7587 (502.3877)  triple_60: 504.0747 (499.1169)  triple_40: 482.8794 (474.2502)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 360/1724]  eta: 1:29:17  lr: 0.000000  loss: 1954.8477 (1993.1913)  loss_n_40: 4.2197 (4.2397)  loss_n_60: 4.5978 (4.5999)  loss_n_80: 4.7452 (4.7405)  loss_n_100: 4.8224 (4.7876)  triple_100: 490.8091 (499.5651)  triple_80: 493.6462 (502.2345)  triple_60: 489.8385 (498.9595)  triple_40: 462.7112 (474.0644)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 370/1724]  eta: 1:28:38  lr: 0.000000  loss: 1950.3514 (1993.2667)  loss_n_40: 4.2167 (4.2391)  loss_n_60: 4.5978 (4.5999)  loss_n_80: 4.7678 (4.7408)  loss_n_100: 4.8319 (4.7879)  triple_100: 490.6977 (499.5880)  triple_80: 492.8634 (502.2569)  triple_60: 488.5479 (498.9787)  triple_40: 462.5427 (474.0753)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 380/1724]  eta: 1:27:59  lr: 0.000000  loss: 1979.5459 (1993.8682)  loss_n_40: 4.2167 (4.2367)  loss_n_60: 4.5731 (4.5970)  loss_n_80: 4.7264 (4.7382)  loss_n_100: 4.7755 (4.7855)  triple_100: 496.1264 (499.7435)  triple_80: 498.1162 (502.4069)  triple_60: 495.2790 (499.1269)  triple_40: 471.8568 (474.2334)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 390/1724]  eta: 1:27:19  lr: 0.000000  loss: 1993.1427 (1993.8920)  loss_n_40: 4.1748 (4.2356)  loss_n_60: 4.5372 (4.5964)  loss_n_80: 4.7046 (4.7380)  loss_n_100: 4.7383 (4.7854)  triple_100: 499.8335 (499.7569)  triple_80: 502.8441 (502.4177)  triple_60: 499.3916 (499.1336)  triple_40: 471.8568 (474.2284)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 400/1724]  eta: 1:26:40  lr: 0.000000  loss: 2039.5756 (1995.1478)  loss_n_40: 4.1708 (4.2338)  loss_n_60: 4.5372 (4.5942)  loss_n_80: 4.7047 (4.7357)  loss_n_100: 4.7583 (4.7833)  triple_100: 511.3611 (500.0748)  triple_80: 513.5468 (502.7330)  triple_60: 510.1841 (499.4457)  triple_40: 486.8431 (474.5474)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 410/1724]  eta: 1:26:01  lr: 0.000000  loss: 1939.8687 (1994.4033)  loss_n_40: 4.1532 (4.2336)  loss_n_60: 4.5326 (4.5940)  loss_n_80: 4.6877 (4.7357)  loss_n_100: 4.7434 (4.7832)  triple_100: 487.1721 (499.8986)  triple_80: 489.6400 (502.5540)  triple_60: 485.3737 (499.2606)  triple_40: 459.6364 (474.3436)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 420/1724]  eta: 1:25:21  lr: 0.000000  loss: 1914.2140 (1994.5634)  loss_n_40: 4.1482 (4.2336)  loss_n_60: 4.5631 (4.5937)  loss_n_80: 4.7243 (4.7354)  loss_n_100: 4.7616 (4.7829)  triple_100: 480.6248 (499.9331)  triple_80: 483.3394 (502.5878)  triple_60: 479.2270 (499.2979)  triple_40: 453.1775 (474.3990)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 430/1724]  eta: 1:24:42  lr: 0.000000  loss: 1938.0603 (1994.3020)  loss_n_40: 4.2867 (4.2336)  loss_n_60: 4.5631 (4.5931)  loss_n_80: 4.6934 (4.7348)  loss_n_100: 4.7368 (4.7823)  triple_100: 486.6170 (499.8595)  triple_80: 489.3478 (502.5129)  triple_60: 485.3666 (499.2321)  triple_40: 458.5459 (474.3538)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 440/1724]  eta: 1:24:03  lr: 0.000000  loss: 2000.2313 (1995.4105)  loss_n_40: 4.1852 (4.2318)  loss_n_60: 4.5496 (4.5914)  loss_n_80: 4.6865 (4.7331)  loss_n_100: 4.7331 (4.7807)  triple_100: 500.1313 (500.1403)  triple_80: 502.8939 (502.7917)  triple_60: 500.8572 (499.5097)  triple_40: 472.8716 (474.6316)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 450/1724]  eta: 1:23:24  lr: 0.000000  loss: 1987.9326 (1995.3674)  loss_n_40: 4.1852 (4.2307)  loss_n_60: 4.5806 (4.5907)  loss_n_80: 4.7303 (4.7324)  loss_n_100: 4.7797 (4.7801)  triple_100: 498.8538 (500.1377)  triple_80: 501.9076 (502.7843)  triple_60: 498.1205 (499.4984)  triple_40: 472.8716 (474.6132)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 460/1724]  eta: 1:22:44  lr: 0.000000  loss: 1984.3041 (1994.8007)  loss_n_40: 4.2211 (4.2316)  loss_n_60: 4.6255 (4.5920)  loss_n_80: 4.7804 (4.7335)  loss_n_100: 4.8205 (4.7810)  triple_100: 496.6212 (499.9868)  triple_80: 498.9577 (502.6388)  triple_60: 496.2569 (499.3576)  triple_40: 472.6368 (474.4794)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 470/1724]  eta: 1:22:05  lr: 0.000000  loss: 1933.7350 (1993.6454)  loss_n_40: 4.2302 (4.2324)  loss_n_60: 4.6491 (4.5937)  loss_n_80: 4.8076 (4.7353)  loss_n_100: 4.8396 (4.7827)  triple_100: 485.7831 (499.7003)  triple_80: 488.6490 (502.3530)  triple_60: 484.3517 (499.0724)  triple_40: 456.5254 (474.1758)  time: 3.9286  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [ 480/1724]  eta: 1:21:26  lr: 0.000000  loss: 1916.7520 (1994.1625)  loss_n_40: 4.2313 (4.2327)  loss_n_60: 4.6724 (4.5935)  loss_n_80: 4.8476 (4.7351)  loss_n_100: 4.8716 (4.7824)  triple_100: 480.7603 (499.8242)  triple_80: 483.8091 (502.4754)  triple_60: 480.0353 (499.1994)  triple_40: 453.0060 (474.3197)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 490/1724]  eta: 1:20:47  lr: 0.000000  loss: 2023.4459 (1995.0248)  loss_n_40: 4.1916 (4.2323)  loss_n_60: 4.5613 (4.5926)  loss_n_80: 4.7084 (4.7340)  loss_n_100: 4.7574 (4.7814)  triple_100: 507.1590 (500.0439)  triple_80: 510.0707 (502.6928)  triple_60: 506.7038 (499.4154)  triple_40: 480.9645 (474.5324)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 500/1724]  eta: 1:20:07  lr: 0.000000  loss: 2023.4459 (1995.6606)  loss_n_40: 4.1629 (4.2306)  loss_n_60: 4.5094 (4.5910)  loss_n_80: 4.6966 (4.7327)  loss_n_100: 4.7376 (4.7801)  triple_100: 507.1590 (500.2113)  triple_80: 510.0707 (502.8548)  triple_60: 506.7038 (499.5726)  triple_40: 480.9645 (474.6874)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 510/1724]  eta: 1:19:28  lr: 0.000000  loss: 1987.8611 (1995.2093)  loss_n_40: 4.2086 (4.2315)  loss_n_60: 4.6011 (4.5918)  loss_n_80: 4.7637 (4.7334)  loss_n_100: 4.8181 (4.7809)  triple_100: 498.7778 (500.0906)  triple_80: 501.3084 (502.7381)  triple_60: 497.6506 (499.4590)  triple_40: 471.1392 (474.5840)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 520/1724]  eta: 1:18:49  lr: 0.000000  loss: 1956.8907 (1994.5705)  loss_n_40: 4.2569 (4.2315)  loss_n_60: 4.6136 (4.5924)  loss_n_80: 4.7873 (4.7344)  loss_n_100: 4.8260 (4.7818)  triple_100: 490.6263 (499.9375)  triple_80: 493.3098 (502.5860)  triple_60: 490.1597 (499.3017)  triple_40: 464.8286 (474.4053)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 530/1724]  eta: 1:18:09  lr: 0.000000  loss: 1963.6772 (1995.0444)  loss_n_40: 4.1550 (4.2299)  loss_n_60: 4.5659 (4.5911)  loss_n_80: 4.7242 (4.7332)  loss_n_100: 4.7629 (4.7807)  triple_100: 493.1129 (500.0607)  triple_80: 495.7081 (502.7072)  triple_60: 491.7263 (499.4197)  triple_40: 467.1218 (474.5218)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 540/1724]  eta: 1:17:30  lr: 0.000000  loss: 2039.8938 (1995.4786)  loss_n_40: 4.1450 (4.2284)  loss_n_60: 4.4894 (4.5897)  loss_n_80: 4.6692 (4.7320)  loss_n_100: 4.7258 (4.7796)  triple_100: 510.8400 (500.1744)  triple_80: 513.1288 (502.8168)  triple_60: 510.1216 (499.5276)  triple_40: 485.2476 (474.6301)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 550/1724]  eta: 1:16:51  lr: 0.000000  loss: 1962.6149 (1995.5721)  loss_n_40: 4.1450 (4.2282)  loss_n_60: 4.5646 (4.5897)  loss_n_80: 4.7143 (4.7319)  loss_n_100: 4.7628 (4.7794)  triple_100: 493.3313 (500.1938)  triple_80: 495.7090 (502.8374)  triple_60: 491.2252 (499.5500)  triple_40: 464.0075 (474.6616)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 560/1724]  eta: 1:16:12  lr: 0.000000  loss: 1915.4937 (1994.6254)  loss_n_40: 4.2010 (4.2286)  loss_n_60: 4.6526 (4.5908)  loss_n_80: 4.8045 (4.7331)  loss_n_100: 4.8404 (4.7805)  triple_100: 480.4985 (499.9606)  triple_80: 483.4168 (502.6050)  triple_60: 479.7744 (499.3128)  triple_40: 452.6519 (474.4139)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 570/1724]  eta: 1:15:32  lr: 0.000000  loss: 1934.5608 (1993.9437)  loss_n_40: 4.2282 (4.2289)  loss_n_60: 4.6020 (4.5913)  loss_n_80: 4.7412 (4.7336)  loss_n_100: 4.8040 (4.7811)  triple_100: 484.3972 (499.7947)  triple_80: 487.2547 (502.4372)  triple_60: 484.5413 (499.1411)  triple_40: 459.3302 (474.2357)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 580/1724]  eta: 1:14:53  lr: 0.000000  loss: 1931.2217 (1993.0132)  loss_n_40: 4.2086 (4.2293)  loss_n_60: 4.5407 (4.5914)  loss_n_80: 4.7069 (4.7338)  loss_n_100: 4.7597 (4.7813)  triple_100: 484.3972 (499.5606)  triple_80: 486.5065 (502.2028)  triple_60: 482.8690 (498.9057)  triple_40: 459.1692 (474.0082)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 590/1724]  eta: 1:14:14  lr: 0.000000  loss: 1922.0728 (1991.7405)  loss_n_40: 4.2445 (4.2302)  loss_n_60: 4.5511 (4.5926)  loss_n_80: 4.7069 (4.7350)  loss_n_100: 4.7628 (4.7825)  triple_100: 481.5641 (499.2451)  triple_80: 484.6535 (501.8884)  triple_60: 481.1727 (498.5870)  triple_40: 454.9035 (473.6796)  time: 3.9283  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 600/1724]  eta: 1:13:34  lr: 0.000000  loss: 1979.2563 (1992.5797)  loss_n_40: 4.2445 (4.2287)  loss_n_60: 4.5511 (4.5906)  loss_n_80: 4.7018 (4.7330)  loss_n_100: 4.7628 (4.7806)  triple_100: 496.2328 (499.4601)  triple_80: 498.8276 (502.0979)  triple_60: 495.5647 (498.7950)  triple_40: 470.5645 (473.8939)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 610/1724]  eta: 1:12:55  lr: 0.000000  loss: 1988.9569 (1992.4592)  loss_n_40: 4.1087 (4.2277)  loss_n_60: 4.4596 (4.5897)  loss_n_80: 4.5919 (4.7320)  loss_n_100: 4.6567 (4.7798)  triple_100: 498.8438 (499.4333)  triple_80: 501.1121 (502.0676)  triple_60: 498.1309 (498.7661)  triple_40: 473.5789 (473.8630)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 620/1724]  eta: 1:12:16  lr: 0.000000  loss: 1952.5677 (1993.5083)  loss_n_40: 4.2140 (4.2283)  loss_n_60: 4.5310 (4.5897)  loss_n_80: 4.6708 (4.7320)  loss_n_100: 4.7215 (4.7796)  triple_100: 489.7030 (499.6867)  triple_80: 492.7438 (502.3243)  triple_60: 488.8315 (499.0280)  triple_40: 462.4572 (474.1398)  time: 3.9290  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 630/1724]  eta: 1:11:37  lr: 0.000000  loss: 1941.3516 (1993.4682)  loss_n_40: 4.2569 (4.2278)  loss_n_60: 4.6456 (4.5896)  loss_n_80: 4.7900 (4.7318)  loss_n_100: 4.8295 (4.7794)  triple_100: 485.8643 (499.6751)  triple_80: 488.9640 (502.3145)  triple_60: 486.0390 (499.0200)  triple_40: 461.4246 (474.1300)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 640/1724]  eta: 1:10:57  lr: 0.000000  loss: 1917.8571 (1992.7708)  loss_n_40: 4.2604 (4.2288)  loss_n_60: 4.6928 (4.5911)  loss_n_80: 4.8527 (4.7332)  loss_n_100: 4.8847 (4.7808)  triple_100: 481.3098 (499.5012)  triple_80: 484.6415 (502.1433)  triple_60: 480.6005 (498.8474)  triple_40: 453.2796 (473.9451)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 650/1724]  eta: 1:10:18  lr: 0.000000  loss: 1931.6658 (1992.2394)  loss_n_40: 4.2639 (4.2288)  loss_n_60: 4.6928 (4.5915)  loss_n_80: 4.8527 (4.7338)  loss_n_100: 4.8847 (4.7812)  triple_100: 485.0134 (499.3709)  triple_80: 487.8620 (502.0124)  triple_60: 483.6663 (498.7150)  triple_40: 456.4336 (473.8057)  time: 3.9317  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 660/1724]  eta: 1:09:39  lr: 0.000000  loss: 1972.4243 (1992.7139)  loss_n_40: 4.2639 (4.2298)  loss_n_60: 4.6622 (4.5924)  loss_n_80: 4.8064 (4.7345)  loss_n_100: 4.8499 (4.7819)  triple_100: 494.6815 (499.4825)  triple_80: 496.9529 (502.1287)  triple_60: 493.5969 (498.8346)  triple_40: 468.9062 (473.9294)  time: 3.9326  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 670/1724]  eta: 1:09:00  lr: 0.000000  loss: 1955.8085 (1992.2643)  loss_n_40: 4.2418 (4.2306)  loss_n_60: 4.6380 (4.5928)  loss_n_80: 4.7754 (4.7348)  loss_n_100: 4.8296 (4.7822)  triple_100: 491.0368 (499.3679)  triple_80: 494.2770 (502.0151)  triple_60: 490.1907 (498.7214)  triple_40: 461.7525 (473.8195)  time: 3.9325  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 680/1724]  eta: 1:08:21  lr: 0.000000  loss: 1936.2593 (1991.8113)  loss_n_40: 4.1950 (4.2300)  loss_n_60: 4.5893 (4.5925)  loss_n_80: 4.7299 (4.7346)  loss_n_100: 4.7820 (4.7821)  triple_100: 485.5679 (499.2602)  triple_80: 488.4281 (501.9050)  triple_60: 484.5952 (498.6091)  triple_40: 458.2695 (473.6978)  time: 3.9308  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 690/1724]  eta: 1:07:41  lr: 0.000000  loss: 1951.4286 (1991.8016)  loss_n_40: 4.1829 (4.2304)  loss_n_60: 4.5269 (4.5930)  loss_n_80: 4.6960 (4.7350)  loss_n_100: 4.7461 (4.7825)  triple_100: 490.2459 (499.2571)  triple_80: 492.5400 (501.9021)  triple_60: 488.6817 (498.6068)  triple_40: 461.9187 (473.6947)  time: 3.9286  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [ 700/1724]  eta: 1:07:02  lr: 0.000000  loss: 2023.2422 (1993.1261)  loss_n_40: 4.1067 (4.2283)  loss_n_60: 4.5269 (4.5905)  loss_n_80: 4.6686 (4.7324)  loss_n_100: 4.7126 (4.7799)  triple_100: 506.7628 (499.5843)  triple_80: 509.9882 (502.2276)  triple_60: 506.7659 (498.9367)  triple_40: 481.7026 (474.0466)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 710/1724]  eta: 1:06:23  lr: 0.000000  loss: 2033.3436 (1992.9751)  loss_n_40: 4.2024 (4.2285)  loss_n_60: 4.6216 (4.5912)  loss_n_80: 4.7720 (4.7332)  loss_n_100: 4.8185 (4.7806)  triple_100: 509.3298 (499.5489)  triple_80: 511.9809 (502.1935)  triple_60: 508.7921 (498.9005)  triple_40: 484.2256 (473.9988)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 720/1724]  eta: 1:05:43  lr: 0.000000  loss: 1933.6853 (1992.6663)  loss_n_40: 4.2661 (4.2281)  loss_n_60: 4.6758 (4.5904)  loss_n_80: 4.8099 (4.7324)  loss_n_100: 4.8468 (4.7799)  triple_100: 484.0709 (499.4729)  triple_80: 487.2895 (502.1181)  triple_60: 484.4284 (498.8239)  triple_40: 459.1219 (473.9205)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 730/1724]  eta: 1:05:04  lr: 0.000000  loss: 1917.9274 (1992.2433)  loss_n_40: 4.3241 (4.2294)  loss_n_60: 4.6835 (4.5916)  loss_n_80: 4.8283 (4.7335)  loss_n_100: 4.8814 (4.7809)  triple_100: 480.3663 (499.3644)  triple_80: 483.2449 (502.0110)  triple_60: 479.8518 (498.7176)  triple_40: 454.8893 (473.8150)  time: 3.9309  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 740/1724]  eta: 1:04:25  lr: 0.000000  loss: 1926.6257 (1992.2002)  loss_n_40: 4.2316 (4.2287)  loss_n_60: 4.6323 (4.5910)  loss_n_80: 4.7521 (4.7330)  loss_n_100: 4.8194 (4.7804)  triple_100: 482.6701 (499.3576)  triple_80: 485.0595 (502.0019)  triple_60: 481.9463 (498.7066)  triple_40: 459.4981 (473.8010)  time: 3.9307  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:1]  [ 750/1724]  eta: 1:03:46  lr: 0.000000  loss: 1980.0709 (1992.4334)  loss_n_40: 4.1927 (4.2291)  loss_n_60: 4.5049 (4.5912)  loss_n_80: 4.6488 (4.7332)  loss_n_100: 4.7103 (4.7805)  triple_100: 496.1968 (499.4108)  triple_80: 498.5968 (502.0571)  triple_60: 495.8137 (498.7649)  triple_40: 471.3239 (473.8666)  time: 3.9301  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:1]  [ 760/1724]  eta: 1:03:06  lr: 0.000000  loss: 1980.0709 (1992.4889)  loss_n_40: 4.2541 (4.2288)  loss_n_60: 4.5576 (4.5908)  loss_n_80: 4.7160 (4.7329)  loss_n_100: 4.7680 (4.7801)  triple_100: 496.1968 (499.4273)  triple_80: 498.5968 (502.0734)  triple_60: 495.8137 (498.7795)  triple_40: 470.9872 (473.8761)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 770/1724]  eta: 1:02:27  lr: 0.000000  loss: 1971.9486 (1992.3631)  loss_n_40: 4.2396 (4.2287)  loss_n_60: 4.5481 (4.5904)  loss_n_80: 4.6820 (4.7323)  loss_n_100: 4.7184 (4.7795)  triple_100: 495.1847 (499.3878)  triple_80: 497.9619 (502.0383)  triple_60: 493.7310 (498.7470)  triple_40: 467.0512 (473.8591)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 780/1724]  eta: 1:01:48  lr: 0.000000  loss: 1971.9486 (1992.9993)  loss_n_40: 4.2185 (4.2281)  loss_n_60: 4.5481 (4.5894)  loss_n_80: 4.6820 (4.7313)  loss_n_100: 4.7184 (4.7785)  triple_100: 495.1847 (499.5447)  triple_80: 497.9619 (502.1944)  triple_60: 493.7310 (498.9044)  triple_40: 467.0512 (474.0286)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 790/1724]  eta: 1:01:09  lr: 0.000000  loss: 1926.9078 (1991.9734)  loss_n_40: 4.2498 (4.2291)  loss_n_60: 4.6236 (4.5907)  loss_n_80: 4.7754 (4.7326)  loss_n_100: 4.8265 (4.7798)  triple_100: 484.3203 (499.2920)  triple_80: 487.0120 (501.9419)  triple_60: 482.5154 (498.6486)  triple_40: 454.0746 (473.7587)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 800/1724]  eta: 1:00:29  lr: 0.000000  loss: 1926.8574 (1991.4641)  loss_n_40: 4.2936 (4.2294)  loss_n_60: 4.6954 (4.5913)  loss_n_80: 4.7999 (4.7332)  loss_n_100: 4.8638 (4.7804)  triple_100: 483.2697 (499.1657)  triple_80: 485.9234 (501.8162)  triple_60: 482.3438 (498.5221)  triple_40: 456.3084 (473.6257)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 810/1724]  eta: 0:59:50  lr: 0.000000  loss: 1945.3691 (1991.6822)  loss_n_40: 4.2246 (4.2297)  loss_n_60: 4.6457 (4.5917)  loss_n_80: 4.7667 (4.7337)  loss_n_100: 4.8116 (4.7808)  triple_100: 488.5660 (499.2207)  triple_80: 491.0174 (501.8704)  triple_60: 486.9865 (498.5770)  triple_40: 461.0924 (473.6782)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 820/1724]  eta: 0:59:11  lr: 0.000000  loss: 1934.8447 (1991.3078)  loss_n_40: 4.2172 (4.2299)  loss_n_60: 4.6348 (4.5922)  loss_n_80: 4.7667 (4.7342)  loss_n_100: 4.8239 (4.7813)  triple_100: 486.1039 (499.1290)  triple_80: 488.4948 (501.7793)  triple_60: 484.4446 (498.4837)  triple_40: 457.0693 (473.5781)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 830/1724]  eta: 0:58:31  lr: 0.000000  loss: 1936.9800 (1991.5052)  loss_n_40: 4.2309 (4.2300)  loss_n_60: 4.6348 (4.5921)  loss_n_80: 4.7775 (4.7340)  loss_n_100: 4.8265 (4.7812)  triple_100: 487.1408 (499.1777)  triple_80: 489.4277 (501.8269)  triple_60: 484.8044 (498.5333)  triple_40: 457.0693 (473.6301)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 840/1724]  eta: 0:57:52  lr: 0.000000  loss: 1992.1448 (1990.9314)  loss_n_40: 4.2267 (4.2305)  loss_n_60: 4.6078 (4.5928)  loss_n_80: 4.7536 (4.7348)  loss_n_100: 4.8043 (4.7820)  triple_100: 499.5988 (499.0364)  triple_80: 502.4485 (501.6863)  triple_60: 499.3365 (498.3907)  triple_40: 471.6478 (473.4779)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 850/1724]  eta: 0:57:13  lr: 0.000000  loss: 1908.3815 (1990.5920)  loss_n_40: 4.2267 (4.2310)  loss_n_60: 4.6157 (4.5933)  loss_n_80: 4.7837 (4.7353)  loss_n_100: 4.8281 (4.7825)  triple_100: 478.7715 (498.9517)  triple_80: 481.4686 (501.6010)  triple_60: 477.8821 (498.3065)  triple_40: 451.8425 (473.3907)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 860/1724]  eta: 0:56:34  lr: 0.000000  loss: 1977.3490 (1990.7145)  loss_n_40: 4.2558 (4.2315)  loss_n_60: 4.6543 (4.5943)  loss_n_80: 4.8089 (4.7362)  loss_n_100: 4.8537 (4.7833)  triple_100: 495.9650 (498.9816)  triple_80: 498.4617 (501.6318)  triple_60: 494.8570 (498.3378)  triple_40: 469.5447 (473.4179)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 870/1724]  eta: 0:55:54  lr: 0.000000  loss: 2016.0719 (1990.7743)  loss_n_40: 4.2318 (4.2314)  loss_n_60: 4.6328 (4.5939)  loss_n_80: 4.7895 (4.7359)  loss_n_100: 4.8272 (4.7830)  triple_100: 506.2086 (498.9950)  triple_80: 508.3300 (501.6464)  triple_60: 504.3701 (498.3520)  triple_40: 479.0690 (473.4367)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 880/1724]  eta: 0:55:15  lr: 0.000000  loss: 2056.0735 (1991.2643)  loss_n_40: 4.1858 (4.2310)  loss_n_60: 4.5182 (4.5932)  loss_n_80: 4.6796 (4.7351)  loss_n_100: 4.7450 (4.7823)  triple_100: 514.8788 (499.1147)  triple_80: 517.4791 (501.7657)  triple_60: 515.0556 (498.4745)  triple_40: 488.3191 (473.5678)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 890/1724]  eta: 0:54:36  lr: 0.000000  loss: 1980.4351 (1990.9414)  loss_n_40: 4.2057 (4.2311)  loss_n_60: 4.6094 (4.5937)  loss_n_80: 4.7670 (4.7357)  loss_n_100: 4.7982 (4.7828)  triple_100: 496.1972 (499.0352)  triple_80: 498.9276 (501.6871)  triple_60: 495.8492 (498.3941)  triple_40: 467.9422 (473.4817)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 900/1724]  eta: 0:53:56  lr: 0.000000  loss: 1980.4351 (1991.3923)  loss_n_40: 4.2251 (4.2308)  loss_n_60: 4.6348 (4.5931)  loss_n_80: 4.7900 (4.7351)  loss_n_100: 4.8358 (4.7822)  triple_100: 496.1972 (499.1441)  triple_80: 498.9276 (501.7954)  triple_60: 495.8492 (498.5044)  triple_40: 467.9422 (473.6071)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 910/1724]  eta: 0:53:17  lr: 0.000000  loss: 2004.4177 (1991.5816)  loss_n_40: 4.1802 (4.2304)  loss_n_60: 4.5617 (4.5928)  loss_n_80: 4.6917 (4.7348)  loss_n_100: 4.7370 (4.7819)  triple_100: 503.7052 (499.1940)  triple_80: 505.6992 (501.8433)  triple_60: 501.6115 (498.5511)  triple_40: 475.3044 (473.6533)  time: 3.9275  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [ 920/1724]  eta: 0:52:38  lr: 0.000000  loss: 1924.0585 (1990.7509)  loss_n_40: 4.2518 (4.2320)  loss_n_60: 4.6667 (4.5947)  loss_n_80: 4.8226 (4.7366)  loss_n_100: 4.8704 (4.7837)  triple_100: 482.1208 (498.9848)  triple_80: 484.9930 (501.6375)  triple_60: 481.9087 (498.3449)  triple_40: 455.5065 (473.4367)  time: 3.9283  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 930/1724]  eta: 0:51:59  lr: 0.000000  loss: 1933.6565 (1990.9023)  loss_n_40: 4.2782 (4.2319)  loss_n_60: 4.6691 (4.5948)  loss_n_80: 4.8305 (4.7368)  loss_n_100: 4.8817 (4.7838)  triple_100: 484.8164 (499.0218)  triple_80: 488.0384 (501.6756)  triple_60: 484.2481 (498.3816)  triple_40: 457.9763 (473.4759)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 940/1724]  eta: 0:51:19  lr: 0.000000  loss: 1949.9790 (1990.3975)  loss_n_40: 4.2637 (4.2334)  loss_n_60: 4.6594 (4.5961)  loss_n_80: 4.7866 (4.7380)  loss_n_100: 4.8214 (4.7850)  triple_100: 488.3936 (498.8924)  triple_80: 491.2429 (501.5486)  triple_60: 487.9555 (498.2559)  triple_40: 463.8406 (473.3482)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 950/1724]  eta: 0:50:40  lr: 0.000000  loss: 1949.9790 (1990.3838)  loss_n_40: 4.2150 (4.2328)  loss_n_60: 4.5462 (4.5951)  loss_n_80: 4.6957 (4.7370)  loss_n_100: 4.7638 (4.7840)  triple_100: 488.3936 (498.8845)  triple_80: 491.2429 (501.5416)  triple_60: 487.9555 (498.2521)  triple_40: 463.8406 (473.3568)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 960/1724]  eta: 0:50:01  lr: 0.000000  loss: 1952.9408 (1989.9431)  loss_n_40: 4.2349 (4.2338)  loss_n_60: 4.5466 (4.5964)  loss_n_80: 4.7248 (4.7383)  loss_n_100: 4.7647 (4.7852)  triple_100: 489.0145 (498.7736)  triple_80: 491.6597 (501.4342)  triple_60: 488.5884 (498.1434)  triple_40: 464.9365 (473.2381)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 970/1724]  eta: 0:49:21  lr: 0.000000  loss: 1931.1536 (1989.6662)  loss_n_40: 4.2591 (4.2335)  loss_n_60: 4.5726 (4.5964)  loss_n_80: 4.7452 (4.7384)  loss_n_100: 4.7776 (4.7852)  triple_100: 484.9106 (498.7064)  triple_80: 487.6358 (501.3678)  triple_60: 483.4121 (498.0756)  triple_40: 457.1890 (473.1628)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 980/1724]  eta: 0:48:42  lr: 0.000000  loss: 1926.4198 (1989.7629)  loss_n_40: 4.2075 (4.2332)  loss_n_60: 4.5726 (4.5961)  loss_n_80: 4.7298 (4.7381)  loss_n_100: 4.7776 (4.7850)  triple_100: 483.5535 (498.7328)  triple_80: 485.6147 (501.3930)  triple_60: 482.2932 (498.1003)  triple_40: 456.6873 (473.1845)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [ 990/1724]  eta: 0:48:03  lr: 0.000000  loss: 1927.1771 (1989.4792)  loss_n_40: 4.1944 (4.2336)  loss_n_60: 4.5785 (4.5970)  loss_n_80: 4.7421 (4.7390)  loss_n_100: 4.7845 (4.7857)  triple_100: 483.7864 (498.6623)  triple_80: 486.4164 (501.3241)  triple_60: 482.3162 (498.0299)  triple_40: 456.5431 (473.1076)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1000/1724]  eta: 0:47:24  lr: 0.000000  loss: 1933.7827 (1989.3998)  loss_n_40: 4.1833 (4.2333)  loss_n_60: 4.5785 (4.5968)  loss_n_80: 4.7479 (4.7389)  loss_n_100: 4.7787 (4.7856)  triple_100: 484.4930 (498.6435)  triple_80: 487.8258 (501.3047)  triple_60: 484.2349 (498.0099)  triple_40: 457.1989 (473.0871)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1010/1724]  eta: 0:46:44  lr: 0.000000  loss: 2003.1384 (1990.2143)  loss_n_40: 4.1211 (4.2321)  loss_n_60: 4.5285 (4.5954)  loss_n_80: 4.6881 (4.7374)  loss_n_100: 4.7393 (4.7842)  triple_100: 502.3134 (498.8486)  triple_80: 505.0056 (501.5086)  triple_60: 501.7977 (498.2144)  triple_40: 475.9496 (473.2936)  time: 3.9293  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1020/1724]  eta: 0:46:05  lr: 0.000000  loss: 1950.1437 (1989.7558)  loss_n_40: 4.1425 (4.2322)  loss_n_60: 4.5595 (4.5957)  loss_n_80: 4.7097 (4.7378)  loss_n_100: 4.7741 (4.7846)  triple_100: 490.2872 (498.7371)  triple_80: 493.1384 (501.3966)  triple_60: 488.8245 (498.1006)  triple_40: 463.2484 (473.1713)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1030/1724]  eta: 0:45:26  lr: 0.000000  loss: 1945.2693 (1989.9602)  loss_n_40: 4.1503 (4.2317)  loss_n_60: 4.5595 (4.5950)  loss_n_80: 4.7097 (4.7371)  loss_n_100: 4.7741 (4.7839)  triple_100: 488.6389 (498.7883)  triple_80: 491.5283 (501.4468)  triple_60: 487.4402 (498.1524)  triple_40: 459.2079 (473.2249)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1040/1724]  eta: 0:44:47  lr: 0.000000  loss: 1938.5509 (1989.7609)  loss_n_40: 4.1824 (4.2316)  loss_n_60: 4.4973 (4.5951)  loss_n_80: 4.6554 (4.7372)  loss_n_100: 4.7217 (4.7840)  triple_100: 486.9978 (498.7372)  triple_80: 489.3605 (501.3966)  triple_60: 485.6749 (498.1028)  triple_40: 459.1459 (473.1765)  time: 3.9290  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1050/1724]  eta: 0:44:07  lr: 0.000000  loss: 1935.8374 (1989.9712)  loss_n_40: 4.2153 (4.2317)  loss_n_60: 4.6607 (4.5950)  loss_n_80: 4.8084 (4.7371)  loss_n_100: 4.8452 (4.7838)  triple_100: 484.6685 (498.7893)  triple_80: 487.6934 (501.4492)  triple_60: 484.9915 (498.1552)  triple_40: 459.1459 (473.2300)  time: 3.9303  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1060/1724]  eta: 0:43:28  lr: 0.000000  loss: 1994.3658 (1990.0324)  loss_n_40: 4.2954 (4.2322)  loss_n_60: 4.6766 (4.5959)  loss_n_80: 4.8022 (4.7379)  loss_n_100: 4.8523 (4.7846)  triple_100: 500.4955 (498.8023)  triple_80: 503.2854 (501.4631)  triple_60: 499.5894 (498.1710)  triple_40: 474.5046 (473.2455)  time: 3.9301  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1070/1724]  eta: 0:42:49  lr: 0.000000  loss: 2013.4796 (1990.7144)  loss_n_40: 4.2265 (4.2312)  loss_n_60: 4.5626 (4.5946)  loss_n_80: 4.6977 (4.7366)  loss_n_100: 4.7421 (4.7835)  triple_100: 504.2112 (498.9738)  triple_80: 507.4931 (501.6314)  triple_60: 504.1373 (498.3403)  triple_40: 480.1559 (473.4229)  time: 3.9297  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1080/1724]  eta: 0:42:09  lr: 0.000000  loss: 2013.4796 (1990.4527)  loss_n_40: 4.2265 (4.2317)  loss_n_60: 4.5254 (4.5948)  loss_n_80: 4.6505 (4.7368)  loss_n_100: 4.7083 (4.7837)  triple_100: 504.2112 (498.9064)  triple_80: 507.4931 (501.5646)  triple_60: 504.1373 (498.2754)  triple_40: 478.5108 (473.3593)  time: 3.9307  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1090/1724]  eta: 0:41:30  lr: 0.000000  loss: 1921.7579 (1990.1199)  loss_n_40: 4.2697 (4.2318)  loss_n_60: 4.5892 (4.5952)  loss_n_80: 4.7353 (4.7373)  loss_n_100: 4.7770 (4.7841)  triple_100: 481.1894 (498.8245)  triple_80: 483.3615 (501.4833)  triple_60: 480.7883 (498.1931)  triple_40: 457.4213 (473.2706)  time: 3.9303  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1100/1724]  eta: 0:40:51  lr: 0.000000  loss: 1957.4474 (1990.3520)  loss_n_40: 4.2144 (4.2316)  loss_n_60: 4.5545 (4.5951)  loss_n_80: 4.7198 (4.7372)  loss_n_100: 4.7484 (4.7841)  triple_100: 491.0109 (498.8840)  triple_80: 493.7028 (501.5410)  triple_60: 490.3279 (498.2507)  triple_40: 463.8115 (473.3282)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1110/1724]  eta: 0:40:12  lr: 0.000000  loss: 1978.8883 (1989.8802)  loss_n_40: 4.2030 (4.2318)  loss_n_60: 4.5675 (4.5953)  loss_n_80: 4.7414 (4.7374)  loss_n_100: 4.7908 (4.7842)  triple_100: 495.8777 (498.7652)  triple_80: 498.7789 (501.4234)  triple_60: 495.5210 (498.1336)  triple_40: 470.6770 (473.2094)  time: 3.9283  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1120/1724]  eta: 0:39:32  lr: 0.000000  loss: 1935.0066 (1989.8352)  loss_n_40: 4.2670 (4.2316)  loss_n_60: 4.6176 (4.5953)  loss_n_80: 4.7793 (4.7375)  loss_n_100: 4.8071 (4.7844)  triple_100: 486.1243 (498.7555)  triple_80: 488.8523 (501.4133)  triple_60: 484.6908 (498.1231)  triple_40: 456.9810 (473.1947)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1130/1724]  eta: 0:38:53  lr: 0.000000  loss: 1988.9008 (1989.8748)  loss_n_40: 4.2761 (4.2314)  loss_n_60: 4.6122 (4.5950)  loss_n_80: 4.7445 (4.7373)  loss_n_100: 4.7997 (4.7842)  triple_100: 498.2496 (498.7648)  triple_80: 500.7921 (501.4214)  triple_60: 497.5783 (498.1314)  triple_40: 471.7587 (473.2094)  time: 3.9307  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [1140/1724]  eta: 0:38:14  lr: 0.000000  loss: 1913.1772 (1989.5066)  loss_n_40: 4.2999 (4.2323)  loss_n_60: 4.6751 (4.5960)  loss_n_80: 4.8137 (4.7383)  loss_n_100: 4.8555 (4.7852)  triple_100: 480.1114 (498.6737)  triple_80: 482.8911 (501.3307)  triple_60: 479.1999 (498.0398)  triple_40: 451.3536 (473.1107)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1150/1724]  eta: 0:37:34  lr: 0.000000  loss: 1930.9399 (1989.8149)  loss_n_40: 4.2920 (4.2320)  loss_n_60: 4.7048 (4.5959)  loss_n_80: 4.8551 (4.7382)  loss_n_100: 4.8937 (4.7852)  triple_100: 483.1714 (498.7528)  triple_80: 485.7761 (501.4092)  triple_60: 483.1620 (498.1168)  triple_40: 456.3021 (473.1848)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1160/1724]  eta: 0:36:55  lr: 0.000000  loss: 1997.9260 (1989.6919)  loss_n_40: 4.1500 (4.2321)  loss_n_60: 4.5015 (4.5962)  loss_n_80: 4.6646 (4.7386)  loss_n_100: 4.6996 (4.7855)  triple_100: 500.4047 (498.7242)  triple_80: 503.7577 (501.3796)  triple_60: 500.3912 (498.0863)  triple_40: 474.6229 (473.1494)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1170/1724]  eta: 0:36:16  lr: 0.000000  loss: 1965.2390 (1989.8075)  loss_n_40: 4.2221 (4.2324)  loss_n_60: 4.6470 (4.5967)  loss_n_80: 4.8190 (4.7391)  loss_n_100: 4.8519 (4.7860)  triple_100: 494.5052 (498.7558)  triple_80: 496.6977 (501.4117)  triple_60: 492.0504 (498.1165)  triple_40: 463.6199 (473.1691)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1180/1724]  eta: 0:35:37  lr: 0.000000  loss: 1965.2390 (1989.6538)  loss_n_40: 4.2591 (4.2325)  loss_n_60: 4.6470 (4.5967)  loss_n_80: 4.7833 (4.7391)  loss_n_100: 4.8320 (4.7860)  triple_100: 491.9034 (498.7158)  triple_80: 495.2973 (501.3728)  triple_60: 492.0504 (498.0783)  triple_40: 465.5002 (473.1325)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1190/1724]  eta: 0:34:57  lr: 0.000000  loss: 1966.5188 (1990.1450)  loss_n_40: 4.2036 (4.2319)  loss_n_60: 4.5789 (4.5960)  loss_n_80: 4.7111 (4.7384)  loss_n_100: 4.7517 (4.7853)  triple_100: 491.9034 (498.8370)  triple_80: 495.2973 (501.4937)  triple_60: 492.1493 (498.2005)  triple_40: 469.8334 (473.2621)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1200/1724]  eta: 0:34:18  lr: 0.000000  loss: 1997.8959 (1990.2859)  loss_n_40: 4.1293 (4.2313)  loss_n_60: 4.4989 (4.5953)  loss_n_80: 4.6670 (4.7376)  loss_n_100: 4.7142 (4.7846)  triple_100: 499.5576 (498.8724)  triple_80: 502.9421 (501.5278)  triple_60: 500.2876 (498.2354)  triple_40: 475.2087 (473.3015)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1210/1724]  eta: 0:33:39  lr: 0.000000  loss: 1966.9620 (1990.1457)  loss_n_40: 4.1833 (4.2315)  loss_n_60: 4.5806 (4.5955)  loss_n_80: 4.7238 (4.7378)  loss_n_100: 4.7815 (4.7848)  triple_100: 492.1002 (498.8349)  triple_80: 494.9919 (501.4911)  triple_60: 492.6098 (498.2004)  triple_40: 468.9515 (473.2696)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1220/1724]  eta: 0:32:59  lr: 0.000000  loss: 1933.2192 (1989.9350)  loss_n_40: 4.2405 (4.2313)  loss_n_60: 4.5820 (4.5953)  loss_n_80: 4.7401 (4.7377)  loss_n_100: 4.7900 (4.7846)  triple_100: 484.4296 (498.7835)  triple_80: 487.5043 (501.4399)  triple_60: 483.8708 (498.1489)  triple_40: 458.9846 (473.2137)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1230/1724]  eta: 0:32:20  lr: 0.000000  loss: 1954.4292 (1990.1838)  loss_n_40: 4.1245 (4.2304)  loss_n_60: 4.5334 (4.5947)  loss_n_80: 4.6979 (4.7372)  loss_n_100: 4.7270 (4.7841)  triple_100: 490.7399 (498.8503)  triple_80: 493.8427 (501.5049)  triple_60: 489.5618 (498.2111)  triple_40: 462.2020 (473.2711)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1240/1724]  eta: 0:31:41  lr: 0.000000  loss: 1971.6162 (1990.0552)  loss_n_40: 4.1989 (4.2307)  loss_n_60: 4.5783 (4.5953)  loss_n_80: 4.7242 (4.7378)  loss_n_100: 4.7779 (4.7847)  triple_100: 493.7719 (498.8190)  triple_80: 497.3600 (501.4746)  triple_60: 493.8523 (498.1795)  triple_40: 466.2787 (473.2337)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1250/1724]  eta: 0:31:02  lr: 0.000000  loss: 1937.6829 (1990.2138)  loss_n_40: 4.2525 (4.2302)  loss_n_60: 4.6726 (4.5950)  loss_n_80: 4.8013 (4.7375)  loss_n_100: 4.8520 (4.7844)  triple_100: 485.9511 (498.8611)  triple_80: 488.3425 (501.5147)  triple_60: 484.9923 (498.2191)  triple_40: 459.5625 (473.2717)  time: 3.9305  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1260/1724]  eta: 0:30:22  lr: 0.000000  loss: 1969.8488 (1989.9664)  loss_n_40: 4.2143 (4.2308)  loss_n_60: 4.6726 (4.5958)  loss_n_80: 4.8013 (4.7384)  loss_n_100: 4.8520 (4.7853)  triple_100: 492.8413 (498.8014)  triple_80: 496.4389 (501.4558)  triple_60: 493.3663 (498.1583)  triple_40: 467.7411 (473.2005)  time: 3.9318  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1270/1724]  eta: 0:29:43  lr: 0.000000  loss: 1985.8286 (1990.1527)  loss_n_40: 4.2212 (4.2311)  loss_n_60: 4.5893 (4.5958)  loss_n_80: 4.7312 (4.7383)  loss_n_100: 4.7859 (4.7852)  triple_100: 499.0603 (498.8446)  triple_80: 501.4065 (501.4992)  triple_60: 496.9638 (498.2043)  triple_40: 472.8919 (473.2542)  time: 3.9320  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1280/1724]  eta: 0:29:04  lr: 0.000000  loss: 2009.1562 (1989.9784)  loss_n_40: 4.1880 (4.2308)  loss_n_60: 4.4961 (4.5956)  loss_n_80: 4.6497 (4.7382)  loss_n_100: 4.7140 (4.7852)  triple_100: 502.6436 (498.8021)  triple_80: 505.7274 (501.4564)  triple_60: 503.3093 (498.1611)  triple_40: 479.6895 (473.2090)  time: 3.9319  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1290/1724]  eta: 0:28:25  lr: 0.000000  loss: 1948.6045 (1989.6624)  loss_n_40: 4.1810 (4.2313)  loss_n_60: 4.6376 (4.5965)  loss_n_80: 4.7815 (4.7391)  loss_n_100: 4.8045 (4.7860)  triple_100: 489.6669 (498.7247)  triple_80: 492.4468 (501.3800)  triple_60: 488.2087 (498.0830)  triple_40: 461.8267 (473.1218)  time: 3.9318  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1300/1724]  eta: 0:27:45  lr: 0.000000  loss: 1937.6493 (1989.2379)  loss_n_40: 4.2579 (4.2314)  loss_n_60: 4.6648 (4.5968)  loss_n_80: 4.8285 (4.7395)  loss_n_100: 4.8661 (4.7865)  triple_100: 486.0118 (498.6218)  triple_80: 488.6755 (501.2767)  triple_60: 485.3793 (497.9775)  triple_40: 459.3806 (473.0078)  time: 3.9309  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1310/1724]  eta: 0:27:06  lr: 0.000000  loss: 1944.2783 (1989.2185)  loss_n_40: 4.2487 (4.2314)  loss_n_60: 4.6474 (4.5969)  loss_n_80: 4.8090 (4.7396)  loss_n_100: 4.8375 (4.7865)  triple_100: 487.0749 (498.6173)  triple_80: 490.2312 (501.2724)  triple_60: 486.9953 (497.9731)  triple_40: 460.5069 (473.0013)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1320/1724]  eta: 0:26:27  lr: 0.000000  loss: 2011.3364 (1989.4719)  loss_n_40: 4.1777 (4.2309)  loss_n_60: 4.5977 (4.5962)  loss_n_80: 4.7005 (4.7389)  loss_n_100: 4.7531 (4.7859)  triple_100: 504.5203 (498.6789)  triple_80: 506.4652 (501.3336)  triple_60: 503.2551 (498.0359)  triple_40: 477.3631 (473.0716)  time: 3.9283  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1330/1724]  eta: 0:25:47  lr: 0.000000  loss: 2037.8867 (1989.7702)  loss_n_40: 4.1546 (4.2307)  loss_n_60: 4.5346 (4.5959)  loss_n_80: 4.6920 (4.7386)  loss_n_100: 4.7399 (4.7855)  triple_100: 508.8997 (498.7529)  triple_80: 512.0666 (501.4077)  triple_60: 509.8904 (498.1110)  triple_40: 485.1699 (473.1479)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1340/1724]  eta: 0:25:08  lr: 0.000000  loss: 1973.7576 (1989.7580)  loss_n_40: 4.1546 (4.2306)  loss_n_60: 4.5214 (4.5955)  loss_n_80: 4.6591 (4.7382)  loss_n_100: 4.7241 (4.7852)  triple_100: 495.4316 (498.7487)  triple_80: 498.2844 (501.4025)  triple_60: 494.5785 (498.1068)  triple_40: 466.9153 (473.1504)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1350/1724]  eta: 0:24:29  lr: 0.000000  loss: 2000.3893 (1989.8441)  loss_n_40: 4.2067 (4.2306)  loss_n_60: 4.5193 (4.5957)  loss_n_80: 4.6607 (4.7384)  loss_n_100: 4.7201 (4.7854)  triple_100: 500.2192 (498.7701)  triple_80: 503.1190 (501.4239)  triple_60: 500.5970 (498.1285)  triple_40: 477.0462 (473.1715)  time: 3.9269  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [1360/1724]  eta: 0:23:49  lr: 0.000000  loss: 2005.8512 (1989.9008)  loss_n_40: 4.2301 (4.2307)  loss_n_60: 4.5654 (4.5956)  loss_n_80: 4.7184 (4.7384)  loss_n_100: 4.7824 (4.7854)  triple_100: 502.9863 (498.7834)  triple_80: 505.5444 (501.4376)  triple_60: 502.0543 (498.1431)  triple_40: 477.2285 (473.1866)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1370/1724]  eta: 0:23:10  lr: 0.000000  loss: 1992.0946 (1989.6434)  loss_n_40: 4.2222 (4.2304)  loss_n_60: 4.5668 (4.5954)  loss_n_80: 4.7184 (4.7381)  loss_n_100: 4.7806 (4.7852)  triple_100: 499.5812 (498.7224)  triple_80: 501.6229 (501.3749)  triple_60: 498.1107 (498.0783)  triple_40: 472.6076 (473.1188)  time: 3.9282  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:1]  [1380/1724]  eta: 0:22:31  lr: 0.000000  loss: 1938.7418 (1989.6144)  loss_n_40: 4.1555 (4.2304)  loss_n_60: 4.5668 (4.5953)  loss_n_80: 4.7182 (4.7381)  loss_n_100: 4.7535 (4.7851)  triple_100: 485.1615 (498.7163)  triple_80: 487.8023 (501.3672)  triple_60: 484.9151 (498.0705)  triple_40: 461.9158 (473.1114)  time: 3.9290  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1390/1724]  eta: 0:21:52  lr: 0.000000  loss: 1951.9376 (1989.5526)  loss_n_40: 4.1796 (4.2304)  loss_n_60: 4.5975 (4.5955)  loss_n_80: 4.7407 (4.7383)  loss_n_100: 4.7940 (4.7853)  triple_100: 489.7686 (498.7024)  triple_80: 492.5765 (501.3542)  triple_60: 488.8091 (498.0559)  triple_40: 461.9158 (473.0906)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1400/1724]  eta: 0:21:12  lr: 0.000000  loss: 1994.1241 (1989.8697)  loss_n_40: 4.2163 (4.2303)  loss_n_60: 4.5334 (4.5954)  loss_n_80: 4.6792 (4.7381)  loss_n_100: 4.7235 (4.7851)  triple_100: 500.2825 (498.7797)  triple_80: 502.8051 (501.4318)  triple_60: 499.2165 (498.1354)  triple_40: 473.8677 (473.1738)  time: 3.9308  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1410/1724]  eta: 0:20:33  lr: 0.000000  loss: 1960.3208 (1989.5236)  loss_n_40: 4.3412 (4.2312)  loss_n_60: 4.6908 (4.5962)  loss_n_80: 4.8155 (4.7389)  loss_n_100: 4.8522 (4.7859)  triple_100: 492.3579 (498.6914)  triple_80: 494.9692 (501.3447)  triple_60: 491.0102 (498.0492)  triple_40: 464.0952 (473.0862)  time: 3.9312  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1420/1724]  eta: 0:19:54  lr: 0.000000  loss: 1946.0878 (1989.6617)  loss_n_40: 4.3412 (4.2313)  loss_n_60: 4.6908 (4.5964)  loss_n_80: 4.8155 (4.7391)  loss_n_100: 4.8522 (4.7861)  triple_100: 487.6868 (498.7259)  triple_80: 490.7695 (501.3798)  triple_60: 487.5605 (498.0841)  triple_40: 460.8371 (473.1191)  time: 3.9303  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1430/1724]  eta: 0:19:15  lr: 0.000000  loss: 1990.5422 (1990.1037)  loss_n_40: 4.1816 (4.2305)  loss_n_60: 4.5349 (4.5957)  loss_n_80: 4.6781 (4.7385)  loss_n_100: 4.7265 (4.7854)  triple_100: 498.3658 (498.8380)  triple_80: 501.4171 (501.4910)  triple_60: 498.5887 (498.1953)  triple_40: 474.1088 (473.2293)  time: 3.9301  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1440/1724]  eta: 0:18:35  lr: 0.000000  loss: 1967.5658 (1990.2979)  loss_n_40: 4.1215 (4.2302)  loss_n_60: 4.5397 (4.5953)  loss_n_80: 4.7015 (4.7380)  loss_n_100: 4.7288 (4.7850)  triple_100: 493.5167 (498.8852)  triple_80: 496.1821 (501.5387)  triple_60: 492.5931 (498.2439)  triple_40: 468.4250 (473.2816)  time: 3.9313  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1450/1724]  eta: 0:17:56  lr: 0.000000  loss: 1939.3234 (1990.1715)  loss_n_40: 4.2452 (4.2301)  loss_n_60: 4.6565 (4.5955)  loss_n_80: 4.8162 (4.7383)  loss_n_100: 4.8525 (4.7852)  triple_100: 487.6973 (498.8565)  triple_80: 489.9498 (501.5095)  triple_60: 485.6488 (498.2122)  triple_40: 459.1142 (473.2443)  time: 3.9321  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1460/1724]  eta: 0:17:17  lr: 0.000000  loss: 1972.2795 (1990.1981)  loss_n_40: 4.2128 (4.2301)  loss_n_60: 4.6090 (4.5954)  loss_n_80: 4.7434 (4.7382)  loss_n_100: 4.7969 (4.7852)  triple_100: 495.3041 (498.8632)  triple_80: 497.7213 (501.5165)  triple_60: 494.5437 (498.2197)  triple_40: 466.6442 (473.2498)  time: 3.9303  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1470/1724]  eta: 0:16:37  lr: 0.000000  loss: 1986.4885 (1990.2911)  loss_n_40: 4.1547 (4.2296)  loss_n_60: 4.5186 (4.5949)  loss_n_80: 4.6713 (4.7377)  loss_n_100: 4.7217 (4.7847)  triple_100: 497.5747 (498.8867)  triple_80: 500.5265 (501.5395)  triple_60: 497.0052 (498.2429)  triple_40: 473.2402 (473.2751)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1480/1724]  eta: 0:15:58  lr: 0.000000  loss: 1947.4131 (1990.0620)  loss_n_40: 4.1819 (4.2296)  loss_n_60: 4.5644 (4.5951)  loss_n_80: 4.7413 (4.7380)  loss_n_100: 4.7773 (4.7849)  triple_100: 488.3268 (498.8321)  triple_80: 491.3776 (501.4855)  triple_60: 487.4963 (498.1864)  triple_40: 461.1395 (473.2104)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1490/1724]  eta: 0:15:19  lr: 0.000000  loss: 1960.6334 (1990.2192)  loss_n_40: 4.1819 (4.2295)  loss_n_60: 4.5735 (4.5950)  loss_n_80: 4.7378 (4.7379)  loss_n_100: 4.7698 (4.7848)  triple_100: 492.9226 (498.8723)  triple_80: 494.9681 (501.5258)  triple_60: 491.1861 (498.2256)  triple_40: 463.5495 (473.2484)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1500/1724]  eta: 0:14:40  lr: 0.000000  loss: 1985.9661 (1990.5063)  loss_n_40: 4.1856 (4.2294)  loss_n_60: 4.5840 (4.5948)  loss_n_80: 4.7168 (4.7377)  loss_n_100: 4.7698 (4.7847)  triple_100: 498.2448 (498.9432)  triple_80: 501.4327 (501.5961)  triple_60: 497.5128 (498.2959)  triple_40: 469.6548 (473.3244)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1510/1724]  eta: 0:14:00  lr: 0.000000  loss: 1964.2271 (1990.3524)  loss_n_40: 4.2131 (4.2295)  loss_n_60: 4.6107 (4.5950)  loss_n_80: 4.7511 (4.7379)  loss_n_100: 4.8218 (4.7849)  triple_100: 491.6439 (498.9053)  triple_80: 494.4310 (501.5581)  triple_60: 491.6746 (498.2575)  triple_40: 467.4355 (473.2843)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1520/1724]  eta: 0:13:21  lr: 0.000000  loss: 1964.2271 (1990.3075)  loss_n_40: 4.2453 (4.2296)  loss_n_60: 4.6446 (4.5952)  loss_n_80: 4.7819 (4.7381)  loss_n_100: 4.8302 (4.7851)  triple_100: 491.6439 (498.8935)  triple_80: 494.4310 (501.5469)  triple_60: 491.6746 (498.2466)  triple_40: 467.4355 (473.2725)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1530/1724]  eta: 0:12:42  lr: 0.000000  loss: 2045.2759 (1990.6765)  loss_n_40: 4.2339 (4.2292)  loss_n_60: 4.5956 (4.5946)  loss_n_80: 4.6842 (4.7374)  loss_n_100: 4.7391 (4.7844)  triple_100: 512.5850 (498.9858)  triple_80: 515.3071 (501.6385)  triple_60: 511.8375 (498.3391)  triple_40: 486.1217 (473.3674)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1540/1724]  eta: 0:12:02  lr: 0.000000  loss: 2063.8350 (1991.1041)  loss_n_40: 4.1652 (4.2294)  loss_n_60: 4.5171 (4.5947)  loss_n_80: 4.6608 (4.7375)  loss_n_100: 4.7228 (4.7844)  triple_100: 517.7267 (499.0888)  triple_80: 520.0381 (501.7426)  triple_60: 516.7366 (498.4461)  triple_40: 491.3889 (473.4807)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1550/1724]  eta: 0:11:23  lr: 0.000000  loss: 1942.7606 (1990.8396)  loss_n_40: 4.2978 (4.2297)  loss_n_60: 4.6608 (4.5951)  loss_n_80: 4.7842 (4.7378)  loss_n_100: 4.8301 (4.7847)  triple_100: 486.4493 (499.0225)  triple_80: 488.9909 (501.6770)  triple_60: 486.0628 (498.3802)  triple_40: 461.4076 (473.4124)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1560/1724]  eta: 0:10:44  lr: 0.000000  loss: 1956.7711 (1991.2059)  loss_n_40: 4.2570 (4.2296)  loss_n_60: 4.5682 (4.5947)  loss_n_80: 4.7311 (4.7373)  loss_n_100: 4.8041 (4.7844)  triple_100: 491.7635 (499.1130)  triple_80: 494.7104 (501.7667)  triple_60: 490.1810 (498.4706)  triple_40: 462.0915 (473.5095)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1570/1724]  eta: 0:10:05  lr: 0.000000  loss: 2093.0898 (1991.9419)  loss_n_40: 4.0828 (4.2285)  loss_n_60: 4.4201 (4.5934)  loss_n_80: 4.5692 (4.7360)  loss_n_100: 4.6396 (4.7830)  triple_100: 523.8505 (499.2964)  triple_80: 526.4806 (501.9490)  triple_60: 523.7929 (498.6544)  triple_40: 501.7817 (473.7013)  time: 3.9278  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [1580/1724]  eta: 0:09:25  lr: 0.000000  loss: 2062.5269 (1991.9090)  loss_n_40: 4.1380 (4.2290)  loss_n_60: 4.4684 (4.5940)  loss_n_80: 4.6059 (4.7366)  loss_n_100: 4.6720 (4.7836)  triple_100: 516.7838 (499.2879)  triple_80: 519.4800 (501.9409)  triple_60: 516.4351 (498.6462)  triple_40: 491.2744 (473.6909)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1590/1724]  eta: 0:08:46  lr: 0.000000  loss: 1951.7910 (1991.7449)  loss_n_40: 4.2935 (4.2297)  loss_n_60: 4.6779 (4.5947)  loss_n_80: 4.8167 (4.7372)  loss_n_100: 4.8628 (4.7842)  triple_100: 489.4798 (499.2457)  triple_80: 492.3859 (501.9001)  triple_60: 488.8874 (498.6055)  triple_40: 461.5864 (473.6479)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1600/1724]  eta: 0:08:07  lr: 0.000000  loss: 1921.2196 (1991.3871)  loss_n_40: 4.3008 (4.2305)  loss_n_60: 4.6779 (4.5957)  loss_n_80: 4.8167 (4.7383)  loss_n_100: 4.8628 (4.7852)  triple_100: 482.7525 (499.1556)  triple_80: 485.6913 (501.8126)  triple_60: 481.2686 (498.5171)  triple_40: 453.7303 (473.5521)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1610/1724]  eta: 0:07:27  lr: 0.000000  loss: 1952.3281 (1991.5737)  loss_n_40: 4.2138 (4.2300)  loss_n_60: 4.6319 (4.5954)  loss_n_80: 4.7865 (4.7381)  loss_n_100: 4.8179 (4.7850)  triple_100: 488.4119 (499.2054)  triple_80: 491.7328 (501.8613)  triple_60: 488.6981 (498.5634)  triple_40: 464.0815 (473.5952)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1620/1724]  eta: 0:06:48  lr: 0.000000  loss: 1927.0336 (1991.3784)  loss_n_40: 4.2187 (4.2303)  loss_n_60: 4.6319 (4.5957)  loss_n_80: 4.7865 (4.7384)  loss_n_100: 4.8147 (4.7853)  triple_100: 482.3198 (499.1566)  triple_80: 485.1615 (501.8133)  triple_60: 482.3487 (498.5142)  triple_40: 456.5820 (473.5446)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1630/1724]  eta: 0:06:09  lr: 0.000000  loss: 1927.0336 (1991.4314)  loss_n_40: 4.2251 (4.2299)  loss_n_60: 4.6075 (4.5953)  loss_n_80: 4.7711 (4.7380)  loss_n_100: 4.8100 (4.7849)  triple_100: 482.3198 (499.1711)  triple_80: 485.1615 (501.8270)  triple_60: 482.3487 (498.5269)  triple_40: 456.5820 (473.5582)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1640/1724]  eta: 0:05:30  lr: 0.000000  loss: 1969.8085 (1991.4222)  loss_n_40: 4.2257 (4.2298)  loss_n_60: 4.6046 (4.5953)  loss_n_80: 4.7711 (4.7380)  loss_n_100: 4.8054 (4.7849)  triple_100: 493.8334 (499.1694)  triple_80: 497.1742 (501.8251)  triple_60: 493.6109 (498.5246)  triple_40: 466.1311 (473.5550)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1650/1724]  eta: 0:04:50  lr: 0.000000  loss: 1969.8085 (1991.3465)  loss_n_40: 4.2387 (4.2302)  loss_n_60: 4.6273 (4.5959)  loss_n_80: 4.7835 (4.7386)  loss_n_100: 4.8199 (4.7855)  triple_100: 493.8334 (499.1497)  triple_80: 497.1742 (501.8065)  triple_60: 493.6109 (498.5056)  triple_40: 466.4174 (473.5345)  time: 3.9296  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1660/1724]  eta: 0:04:11  lr: 0.000000  loss: 1991.2979 (1991.5169)  loss_n_40: 4.1861 (4.2298)  loss_n_60: 4.5969 (4.5956)  loss_n_80: 4.7335 (4.7383)  loss_n_100: 4.8042 (4.7852)  triple_100: 499.7712 (499.1932)  triple_80: 502.2177 (501.8491)  triple_60: 498.4356 (498.5483)  triple_40: 472.3469 (473.5776)  time: 3.9309  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1670/1724]  eta: 0:03:32  lr: 0.000000  loss: 2000.3903 (1991.4453)  loss_n_40: 4.2014 (4.2301)  loss_n_60: 4.5969 (4.5962)  loss_n_80: 4.7335 (4.7389)  loss_n_100: 4.8058 (4.7858)  triple_100: 502.9038 (499.1751)  triple_80: 504.6562 (501.8324)  triple_60: 500.9362 (498.5305)  triple_40: 473.2377 (473.5563)  time: 3.9320  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1680/1724]  eta: 0:02:52  lr: 0.000000  loss: 1952.3574 (1991.1626)  loss_n_40: 4.2555 (4.2302)  loss_n_60: 4.6607 (4.5964)  loss_n_80: 4.8230 (4.7392)  loss_n_100: 4.8657 (4.7860)  triple_100: 489.5169 (499.1062)  triple_80: 492.4530 (501.7643)  triple_60: 489.1142 (498.4613)  triple_40: 462.3067 (473.4790)  time: 3.9319  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1690/1724]  eta: 0:02:13  lr: 0.000000  loss: 1898.3885 (1990.7521)  loss_n_40: 4.2478 (4.2306)  loss_n_60: 4.6695 (4.5970)  loss_n_80: 4.8432 (4.7398)  loss_n_100: 4.8737 (4.7865)  triple_100: 477.0014 (499.0027)  triple_80: 479.5114 (501.6626)  triple_60: 475.4123 (498.3591)  triple_40: 449.3619 (473.3739)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1700/1724]  eta: 0:01:34  lr: 0.000000  loss: 1927.8772 (1990.7081)  loss_n_40: 4.2309 (4.2308)  loss_n_60: 4.6370 (4.5972)  loss_n_80: 4.8097 (4.7400)  loss_n_100: 4.8763 (4.7867)  triple_100: 483.6465 (498.9917)  triple_80: 486.6230 (501.6512)  triple_60: 482.9058 (498.3482)  triple_40: 456.3053 (473.3624)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1710/1724]  eta: 0:00:55  lr: 0.000000  loss: 1969.6023 (1990.7804)  loss_n_40: 4.1858 (4.2308)  loss_n_60: 4.5728 (4.5972)  loss_n_80: 4.7413 (4.7400)  loss_n_100: 4.7936 (4.7868)  triple_100: 495.3802 (499.0102)  triple_80: 497.9666 (501.6699)  triple_60: 493.4522 (498.3667)  triple_40: 464.5838 (473.3789)  time: 3.9275  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:1]  [1720/1724]  eta: 0:00:15  lr: 0.000000  loss: 1992.6992 (1991.0112)  loss_n_40: 4.1498 (4.2302)  loss_n_60: 4.5048 (4.5966)  loss_n_80: 4.6308 (4.7394)  loss_n_100: 4.6836 (4.7862)  triple_100: 499.2910 (499.0686)  triple_80: 502.3546 (501.7273)  triple_60: 499.0233 (498.4245)  triple_40: 472.8076 (473.4383)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1]  [1723/1724]  eta: 0:00:03  lr: 0.000000  loss: 1948.1456 (1990.8857)  loss_n_40: 4.1498 (4.2302)  loss_n_60: 4.5626 (4.5967)  loss_n_80: 4.7198 (4.7395)  loss_n_100: 4.7704 (4.7863)  triple_100: 489.3134 (499.0374)  triple_80: 491.8691 (501.6967)  triple_60: 488.0864 (498.3936)  triple_40: 462.5110 (473.4052)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:1] Total time: 1:52:53 (3.9289 s / it)\n",
      "Averaged stats: lr: 0.000000  loss: 1948.1456 (1990.8857)  loss_n_40: 4.1498 (4.2302)  loss_n_60: 4.5626 (4.5967)  loss_n_80: 4.7198 (4.7395)  loss_n_100: 4.7704 (4.7863)  triple_100: 489.3134 (499.0374)  triple_80: 491.8691 (501.6967)  triple_60: 488.0864 (498.3936)  triple_40: 462.5110 (473.4052)\n",
      "Valid: [epoch:1]  [  0/845]  eta: 0:10:23  loss: 1775.3284 (1775.3284)  loss_n_40: 4.2679 (4.2679)  loss_n_60: 4.5794 (4.5794)  loss_n_80: 4.7411 (4.7411)  loss_n_100: 4.8161 (4.8161)  triple_100: 445.2107 (445.2107)  triple_80: 447.7355 (447.7355)  triple_60: 445.1697 (445.1697)  triple_40: 418.8079 (418.8079)  time: 0.7373  data: 0.4033  max mem: 46473\n",
      "Valid: [epoch:1]  [ 10/845]  eta: 0:05:09  loss: 2012.3871 (2022.8242)  loss_n_40: 4.1467 (4.1267)  loss_n_60: 4.5339 (4.5206)  loss_n_80: 4.7089 (4.6633)  loss_n_100: 4.7543 (4.7242)  triple_100: 505.6022 (507.4121)  triple_80: 507.8506 (509.8627)  triple_60: 503.5805 (506.3826)  triple_40: 476.6764 (481.1319)  time: 0.3708  data: 0.0368  max mem: 46473\n",
      "Valid: [epoch:1]  [ 20/845]  eta: 0:04:51  loss: 1897.8064 (1983.4108)  loss_n_40: 4.1509 (4.2354)  loss_n_60: 4.5556 (4.6311)  loss_n_80: 4.7166 (4.7690)  loss_n_100: 4.7607 (4.8173)  triple_100: 477.1367 (497.2944)  triple_80: 479.4506 (499.9789)  triple_60: 475.5383 (496.5503)  triple_40: 448.8239 (471.1345)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [ 30/845]  eta: 0:04:43  loss: 1887.5066 (1981.4501)  loss_n_40: 4.1183 (4.1795)  loss_n_60: 4.5076 (4.5583)  loss_n_80: 4.6785 (4.6959)  loss_n_100: 4.7224 (4.7454)  triple_100: 474.9636 (496.9803)  triple_80: 477.0316 (499.5502)  triple_60: 472.3991 (495.9818)  triple_40: 445.1590 (470.7587)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [ 40/845]  eta: 0:04:37  loss: 1880.0604 (1955.7205)  loss_n_40: 4.1396 (4.2512)  loss_n_60: 4.5162 (4.6358)  loss_n_80: 4.6854 (4.7740)  loss_n_100: 4.7224 (4.8193)  triple_100: 472.7724 (490.3926)  triple_80: 475.0703 (493.1099)  triple_60: 470.0569 (489.6103)  triple_40: 444.1701 (464.1274)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [ 50/845]  eta: 0:04:32  loss: 1845.5336 (1940.2435)  loss_n_40: 4.3550 (4.2584)  loss_n_60: 4.6669 (4.6462)  loss_n_80: 4.8295 (4.7866)  loss_n_100: 4.8843 (4.8298)  triple_100: 461.4659 (486.5850)  triple_80: 464.3564 (489.3155)  triple_60: 462.2752 (485.7745)  triple_40: 439.0526 (460.0474)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:1]  [ 60/845]  eta: 0:04:27  loss: 1864.7109 (1944.6016)  loss_n_40: 4.1702 (4.2530)  loss_n_60: 4.5739 (4.6352)  loss_n_80: 4.7335 (4.7760)  loss_n_100: 4.7726 (4.8204)  triple_100: 468.1911 (487.6331)  triple_80: 470.8727 (490.3635)  triple_60: 467.1064 (486.8493)  triple_40: 440.4126 (461.2710)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [ 70/845]  eta: 0:04:23  loss: 1870.8760 (1945.0830)  loss_n_40: 4.1672 (4.2428)  loss_n_60: 4.5585 (4.6230)  loss_n_80: 4.7290 (4.7660)  loss_n_100: 4.7797 (4.8111)  triple_100: 470.0632 (487.8325)  triple_80: 472.8559 (490.5341)  triple_60: 468.9736 (487.0036)  triple_40: 440.4774 (461.2698)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [ 80/845]  eta: 0:04:19  loss: 1852.6560 (1940.7210)  loss_n_40: 4.1836 (4.2488)  loss_n_60: 4.5634 (4.6197)  loss_n_80: 4.7062 (4.7599)  loss_n_100: 4.7644 (4.8050)  triple_100: 463.2102 (486.6612)  triple_80: 466.7195 (489.3859)  triple_60: 463.9275 (485.9010)  triple_40: 437.3939 (460.3394)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [ 90/845]  eta: 0:04:15  loss: 1846.7933 (1939.9953)  loss_n_40: 4.2367 (4.2578)  loss_n_60: 4.5870 (4.6292)  loss_n_80: 4.7165 (4.7703)  loss_n_100: 4.7792 (4.8170)  triple_100: 464.4240 (486.5235)  triple_80: 466.5932 (489.2338)  triple_60: 462.0233 (485.7125)  triple_40: 435.7579 (460.0513)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [100/845]  eta: 0:04:12  loss: 1903.9219 (1952.0713)  loss_n_40: 4.2779 (4.2627)  loss_n_60: 4.6286 (4.6246)  loss_n_80: 4.7570 (4.7641)  loss_n_100: 4.8246 (4.8102)  triple_100: 476.5128 (489.4555)  triple_80: 480.5687 (492.1770)  triple_60: 476.4441 (488.7346)  triple_40: 449.7843 (463.2427)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [110/845]  eta: 0:04:08  loss: 1924.0536 (1962.2647)  loss_n_40: 4.1923 (4.2523)  loss_n_60: 4.5758 (4.6067)  loss_n_80: 4.7324 (4.7460)  loss_n_100: 4.7607 (4.7930)  triple_100: 482.2883 (491.9672)  triple_80: 485.8068 (494.6560)  triple_60: 482.2633 (491.2626)  triple_40: 454.0364 (465.9810)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [120/845]  eta: 0:04:05  loss: 1877.8416 (1966.2672)  loss_n_40: 4.1923 (4.2495)  loss_n_60: 4.5567 (4.5948)  loss_n_80: 4.7324 (4.7336)  loss_n_100: 4.7607 (4.7815)  triple_100: 472.1599 (492.9387)  triple_80: 474.2809 (495.6073)  triple_60: 470.0261 (492.2694)  triple_40: 443.3597 (467.0923)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [130/845]  eta: 0:04:01  loss: 1902.8899 (1968.7815)  loss_n_40: 4.3236 (4.2534)  loss_n_60: 4.6518 (4.5963)  loss_n_80: 4.8096 (4.7349)  loss_n_100: 4.8655 (4.7827)  triple_100: 475.6949 (493.5161)  triple_80: 479.8243 (496.2071)  triple_60: 476.3225 (492.8923)  triple_40: 448.1795 (467.7987)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [140/845]  eta: 0:03:57  loss: 1905.1930 (1968.0274)  loss_n_40: 4.3646 (4.2592)  loss_n_60: 4.6572 (4.6068)  loss_n_80: 4.7778 (4.7451)  loss_n_100: 4.8570 (4.7925)  triple_100: 475.6949 (493.3147)  triple_80: 479.8243 (496.0243)  triple_60: 477.5643 (492.7060)  triple_40: 451.5496 (467.5790)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [150/845]  eta: 0:03:54  loss: 1880.7052 (1967.7860)  loss_n_40: 4.1614 (4.2511)  loss_n_60: 4.5325 (4.6001)  loss_n_80: 4.7146 (4.7395)  loss_n_100: 4.7529 (4.7874)  triple_100: 470.2285 (493.2979)  triple_80: 473.2463 (496.0056)  triple_60: 470.3952 (492.6555)  triple_40: 446.5276 (467.4487)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [160/845]  eta: 0:03:50  loss: 1891.3206 (1972.9689)  loss_n_40: 4.0644 (4.2477)  loss_n_60: 4.5325 (4.5945)  loss_n_80: 4.6937 (4.7335)  loss_n_100: 4.7491 (4.7819)  triple_100: 474.4899 (494.5615)  triple_80: 477.0891 (497.2587)  triple_60: 473.9302 (493.9497)  triple_40: 447.5408 (468.8416)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [170/845]  eta: 0:03:47  loss: 1929.6812 (1977.2077)  loss_n_40: 4.1100 (4.2405)  loss_n_60: 4.5647 (4.5876)  loss_n_80: 4.6937 (4.7273)  loss_n_100: 4.7611 (4.7756)  triple_100: 484.8617 (495.6357)  triple_80: 488.3209 (498.3254)  triple_60: 483.6890 (494.9987)  triple_40: 454.3823 (469.9169)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [180/845]  eta: 0:03:44  loss: 1952.1439 (1978.2262)  loss_n_40: 4.0882 (4.2439)  loss_n_60: 4.5042 (4.5967)  loss_n_80: 4.6708 (4.7372)  loss_n_100: 4.7455 (4.7849)  triple_100: 491.8102 (495.9128)  triple_80: 494.0809 (498.6086)  triple_60: 488.8117 (495.2650)  triple_40: 459.6702 (470.0771)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [190/845]  eta: 0:03:40  loss: 1986.0640 (1986.4135)  loss_n_40: 4.0053 (4.2355)  loss_n_60: 4.4656 (4.5845)  loss_n_80: 4.6559 (4.7242)  loss_n_100: 4.7071 (4.7724)  triple_100: 497.8353 (497.9428)  triple_80: 500.6843 (500.6316)  triple_60: 497.0493 (497.3083)  triple_40: 469.6415 (472.2142)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [200/845]  eta: 0:03:37  loss: 1947.8589 (1987.5505)  loss_n_40: 4.0053 (4.2309)  loss_n_60: 4.4824 (4.5841)  loss_n_80: 4.6559 (4.7251)  loss_n_100: 4.6743 (4.7727)  triple_100: 488.8310 (498.2568)  triple_80: 491.8179 (500.9481)  triple_60: 487.6605 (497.6007)  triple_40: 459.7243 (472.4321)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [210/845]  eta: 0:03:33  loss: 1936.9701 (1989.7001)  loss_n_40: 4.0695 (4.2269)  loss_n_60: 4.5115 (4.5818)  loss_n_80: 4.6845 (4.7234)  loss_n_100: 4.7375 (4.7713)  triple_100: 487.7422 (498.8140)  triple_80: 489.5947 (501.4931)  triple_60: 484.5287 (498.1377)  triple_40: 457.1625 (472.9519)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [220/845]  eta: 0:03:30  loss: 1950.5718 (1993.2270)  loss_n_40: 4.1305 (4.2291)  loss_n_60: 4.5597 (4.5809)  loss_n_80: 4.7139 (4.7214)  loss_n_100: 4.7705 (4.7687)  triple_100: 489.3421 (499.6420)  triple_80: 492.7215 (502.3368)  triple_60: 488.6354 (499.0243)  triple_40: 461.5767 (473.9239)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [230/845]  eta: 0:03:26  loss: 1917.3025 (1991.0226)  loss_n_40: 4.3172 (4.2377)  loss_n_60: 4.5987 (4.5912)  loss_n_80: 4.7756 (4.7315)  loss_n_100: 4.7825 (4.7781)  triple_100: 479.4295 (499.0775)  triple_80: 482.9706 (501.7830)  triple_60: 479.9711 (498.4710)  triple_40: 453.9246 (473.3528)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [240/845]  eta: 0:03:23  loss: 1900.6373 (1987.8443)  loss_n_40: 4.1885 (4.2396)  loss_n_60: 4.5530 (4.5973)  loss_n_80: 4.7176 (4.7376)  loss_n_100: 4.7935 (4.7841)  triple_100: 478.1379 (498.3128)  triple_80: 480.8217 (501.0245)  triple_60: 476.2038 (497.6760)  triple_40: 447.3312 (472.4724)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [250/845]  eta: 0:03:20  loss: 1917.4458 (1991.1849)  loss_n_40: 4.0527 (4.2379)  loss_n_60: 4.5343 (4.5966)  loss_n_80: 4.6966 (4.7365)  loss_n_100: 4.7401 (4.7825)  triple_100: 482.7546 (499.1296)  triple_80: 485.7217 (501.8548)  triple_60: 480.6652 (498.5192)  triple_40: 450.8620 (473.3277)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [260/845]  eta: 0:03:16  loss: 1953.4840 (1990.3932)  loss_n_40: 4.2825 (4.2429)  loss_n_60: 4.6096 (4.6028)  loss_n_80: 4.7496 (4.7429)  loss_n_100: 4.8228 (4.7886)  triple_100: 487.6666 (498.9185)  triple_80: 491.8601 (501.6484)  triple_60: 489.1922 (498.3178)  triple_40: 464.1044 (473.1314)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [270/845]  eta: 0:03:13  loss: 1879.1340 (1988.9536)  loss_n_40: 4.3263 (4.2432)  loss_n_60: 4.6595 (4.6037)  loss_n_80: 4.8053 (4.7441)  loss_n_100: 4.8441 (4.7896)  triple_100: 470.1454 (498.5712)  triple_80: 473.7520 (501.3017)  triple_60: 470.6920 (497.9656)  triple_40: 445.0494 (472.7343)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [280/845]  eta: 0:03:09  loss: 1847.9777 (1989.4314)  loss_n_40: 4.2223 (4.2403)  loss_n_60: 4.5223 (4.6028)  loss_n_80: 4.6899 (4.7435)  loss_n_100: 4.7270 (4.7893)  triple_100: 463.9984 (498.7098)  triple_80: 465.9385 (501.4287)  triple_60: 462.3428 (498.0939)  triple_40: 437.7245 (472.8230)  time: 0.3349  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:1]  [290/845]  eta: 0:03:06  loss: 1895.2759 (1988.9417)  loss_n_40: 4.2433 (4.2459)  loss_n_60: 4.5349 (4.6071)  loss_n_80: 4.6885 (4.7473)  loss_n_100: 4.7581 (4.7928)  triple_100: 475.2329 (498.5736)  triple_80: 477.5101 (501.3010)  triple_60: 474.7780 (497.9708)  triple_40: 447.9133 (472.7032)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [300/845]  eta: 0:03:03  loss: 1891.0868 (1985.7910)  loss_n_40: 4.3411 (4.2483)  loss_n_60: 4.6935 (4.6107)  loss_n_80: 4.8183 (4.7508)  loss_n_100: 4.8609 (4.7962)  triple_100: 475.2306 (497.7878)  triple_80: 477.5101 (500.5188)  triple_60: 473.6698 (497.1927)  triple_40: 446.6611 (471.8857)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [310/845]  eta: 0:02:59  loss: 1872.7299 (1984.6741)  loss_n_40: 4.2488 (4.2486)  loss_n_60: 4.6135 (4.6122)  loss_n_80: 4.7958 (4.7530)  loss_n_100: 4.8414 (4.7984)  triple_100: 470.4789 (497.5289)  triple_80: 473.0389 (500.2536)  triple_60: 468.6510 (496.9138)  triple_40: 442.5220 (471.5656)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [320/845]  eta: 0:02:56  loss: 1896.9222 (1985.9372)  loss_n_40: 4.1653 (4.2466)  loss_n_60: 4.5468 (4.6097)  loss_n_80: 4.7414 (4.7506)  loss_n_100: 4.7679 (4.7963)  triple_100: 475.3857 (497.8549)  triple_80: 478.4409 (500.5649)  triple_60: 474.9900 (497.2296)  triple_40: 447.7780 (471.8845)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [330/845]  eta: 0:02:52  loss: 1857.3588 (1983.3444)  loss_n_40: 4.3406 (4.2518)  loss_n_60: 4.6378 (4.6153)  loss_n_80: 4.7782 (4.7559)  loss_n_100: 4.8444 (4.8014)  triple_100: 468.3476 (497.1932)  triple_80: 469.9910 (499.9071)  triple_60: 465.0920 (496.5872)  triple_40: 436.5299 (471.2326)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [340/845]  eta: 0:02:49  loss: 1852.5277 (1982.5469)  loss_n_40: 4.3308 (4.2530)  loss_n_60: 4.6523 (4.6160)  loss_n_80: 4.7925 (4.7568)  loss_n_100: 4.8775 (4.8026)  triple_100: 464.8602 (496.9947)  triple_80: 467.7445 (499.7075)  triple_60: 464.1224 (496.3873)  triple_40: 437.4029 (471.0291)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [350/845]  eta: 0:02:46  loss: 1905.9991 (1982.8421)  loss_n_40: 4.3011 (4.2531)  loss_n_60: 4.6278 (4.6160)  loss_n_80: 4.7880 (4.7568)  loss_n_100: 4.8456 (4.8024)  triple_100: 478.3069 (497.0643)  triple_80: 480.9050 (499.7746)  triple_60: 476.9606 (496.4498)  triple_40: 451.1212 (471.1251)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [360/845]  eta: 0:02:42  loss: 1916.9922 (1983.4990)  loss_n_40: 4.1458 (4.2541)  loss_n_60: 4.5827 (4.6167)  loss_n_80: 4.7662 (4.7571)  loss_n_100: 4.7888 (4.8021)  triple_100: 479.2660 (497.2025)  triple_80: 483.4269 (499.9270)  triple_60: 480.6876 (496.6152)  triple_40: 452.9577 (471.3243)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [370/845]  eta: 0:02:39  loss: 1916.9922 (1983.3360)  loss_n_40: 4.3071 (4.2574)  loss_n_60: 4.6357 (4.6209)  loss_n_80: 4.7915 (4.7612)  loss_n_100: 4.8590 (4.8059)  triple_100: 479.2660 (497.1498)  triple_80: 483.4269 (499.8873)  triple_60: 480.6876 (496.5809)  triple_40: 452.9577 (471.2726)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [380/845]  eta: 0:02:36  loss: 1896.6938 (1983.0580)  loss_n_40: 4.0856 (4.2575)  loss_n_60: 4.5595 (4.6219)  loss_n_80: 4.7131 (4.7626)  loss_n_100: 4.7385 (4.8069)  triple_100: 476.6539 (497.0879)  triple_80: 479.5581 (499.8299)  triple_60: 475.5175 (496.5139)  triple_40: 449.1415 (471.1772)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [390/845]  eta: 0:02:32  loss: 1896.6938 (1984.6734)  loss_n_40: 4.0655 (4.2561)  loss_n_60: 4.5480 (4.6194)  loss_n_80: 4.7131 (4.7597)  loss_n_100: 4.7385 (4.8041)  triple_100: 476.9468 (497.4765)  triple_80: 479.5581 (500.2224)  triple_60: 474.6835 (496.9185)  triple_40: 447.4562 (471.6167)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [400/845]  eta: 0:02:29  loss: 1925.8037 (1986.6597)  loss_n_40: 4.2124 (4.2529)  loss_n_60: 4.5810 (4.6137)  loss_n_80: 4.7286 (4.7534)  loss_n_100: 4.7707 (4.7979)  triple_100: 485.1465 (497.9617)  triple_80: 487.7632 (500.7057)  triple_60: 482.1234 (497.4118)  triple_40: 452.7382 (472.1626)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [410/845]  eta: 0:02:26  loss: 1959.0554 (1992.4719)  loss_n_40: 3.9901 (4.2481)  loss_n_60: 4.4327 (4.6055)  loss_n_80: 4.6395 (4.7447)  loss_n_100: 4.6442 (4.7898)  triple_100: 491.1056 (499.3910)  triple_80: 493.9434 (502.1203)  triple_60: 490.7930 (498.8512)  triple_40: 463.3816 (473.7212)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [420/845]  eta: 0:02:22  loss: 1937.1610 (1994.0901)  loss_n_40: 3.9901 (4.2466)  loss_n_60: 4.4835 (4.6012)  loss_n_80: 4.6463 (4.7402)  loss_n_100: 4.6888 (4.7857)  triple_100: 488.2779 (499.7938)  triple_80: 490.2974 (502.5045)  triple_60: 484.9110 (499.2448)  triple_40: 455.8736 (474.1731)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [430/845]  eta: 0:02:19  loss: 1846.9111 (1994.0111)  loss_n_40: 4.1270 (4.2435)  loss_n_60: 4.5250 (4.5966)  loss_n_80: 4.7159 (4.7365)  loss_n_100: 4.7865 (4.7826)  triple_100: 460.6715 (499.7912)  triple_80: 464.5098 (502.4885)  triple_60: 462.4121 (499.2127)  triple_40: 438.7395 (474.1594)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [440/845]  eta: 0:02:15  loss: 1903.2863 (1995.7815)  loss_n_40: 4.1224 (4.2418)  loss_n_60: 4.5144 (4.5946)  loss_n_80: 4.7022 (4.7348)  loss_n_100: 4.7691 (4.7811)  triple_100: 479.7825 (500.2314)  triple_80: 481.6069 (502.9246)  triple_60: 476.8196 (499.6507)  triple_40: 447.0513 (474.6224)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [450/845]  eta: 0:02:12  loss: 1924.8739 (1995.2441)  loss_n_40: 4.1173 (4.2410)  loss_n_60: 4.5357 (4.5941)  loss_n_80: 4.7040 (4.7345)  loss_n_100: 4.7504 (4.7806)  triple_100: 484.4163 (500.0978)  triple_80: 486.6102 (502.7981)  triple_60: 482.1274 (499.5203)  triple_40: 453.6721 (474.4778)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [460/845]  eta: 0:02:09  loss: 1924.8739 (1997.0620)  loss_n_40: 4.1173 (4.2390)  loss_n_60: 4.5351 (4.5910)  loss_n_80: 4.6905 (4.7314)  loss_n_100: 4.7385 (4.7772)  triple_100: 483.1359 (500.5478)  triple_80: 486.2886 (503.2471)  triple_60: 482.1274 (499.9723)  triple_40: 453.7252 (474.9564)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [470/845]  eta: 0:02:05  loss: 1910.9211 (1996.5082)  loss_n_40: 4.0645 (4.2370)  loss_n_60: 4.5259 (4.5909)  loss_n_80: 4.6678 (4.7315)  loss_n_100: 4.7121 (4.7775)  triple_100: 478.0842 (500.4263)  triple_80: 481.1270 (503.1228)  triple_60: 478.0012 (499.8351)  triple_40: 453.7252 (474.7870)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [480/845]  eta: 0:02:02  loss: 1893.0446 (1996.5967)  loss_n_40: 4.0716 (4.2392)  loss_n_60: 4.5269 (4.5935)  loss_n_80: 4.6907 (4.7341)  loss_n_100: 4.7305 (4.7800)  triple_100: 475.7680 (500.4425)  triple_80: 477.6583 (503.1423)  triple_60: 473.6939 (499.8558)  triple_40: 446.9938 (474.8092)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [490/845]  eta: 0:01:59  loss: 1922.6313 (1995.3662)  loss_n_40: 4.2406 (4.2409)  loss_n_60: 4.5923 (4.5965)  loss_n_80: 4.7678 (4.7372)  loss_n_100: 4.8023 (4.7827)  triple_100: 481.7528 (500.1393)  triple_80: 485.0564 (502.8458)  triple_60: 481.7407 (499.5529)  triple_40: 453.2189 (474.4708)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [500/845]  eta: 0:01:55  loss: 1963.7427 (1997.4801)  loss_n_40: 4.1666 (4.2387)  loss_n_60: 4.5856 (4.5941)  loss_n_80: 4.7490 (4.7348)  loss_n_100: 4.7913 (4.7803)  triple_100: 491.4432 (500.6604)  triple_80: 494.8316 (503.3681)  triple_60: 491.7637 (500.0795)  triple_40: 464.9218 (475.0243)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [510/845]  eta: 0:01:52  loss: 1905.3136 (1995.2971)  loss_n_40: 4.1666 (4.2427)  loss_n_60: 4.5869 (4.5986)  loss_n_80: 4.7688 (4.7392)  loss_n_100: 4.8037 (4.7845)  triple_100: 476.0022 (500.1070)  triple_80: 479.8878 (502.8247)  triple_60: 477.4868 (499.5358)  triple_40: 452.5017 (474.4646)  time: 0.3349  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:1]  [520/845]  eta: 0:01:49  loss: 1877.4595 (1995.3228)  loss_n_40: 4.2213 (4.2449)  loss_n_60: 4.6408 (4.6004)  loss_n_80: 4.7994 (4.7407)  loss_n_100: 4.8597 (4.7856)  triple_100: 472.6453 (500.0934)  triple_80: 474.8516 (502.8219)  triple_60: 470.1155 (499.5410)  triple_40: 441.6333 (474.4948)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [530/845]  eta: 0:01:45  loss: 1871.6254 (1995.1218)  loss_n_40: 4.1411 (4.2422)  loss_n_60: 4.5393 (4.5980)  loss_n_80: 4.7057 (4.7385)  loss_n_100: 4.7504 (4.7838)  triple_100: 470.7341 (500.0538)  triple_80: 472.9492 (502.7751)  triple_60: 468.9471 (499.4937)  triple_40: 442.5163 (474.4367)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [540/845]  eta: 0:01:42  loss: 1871.6254 (1995.0646)  loss_n_40: 4.1223 (4.2425)  loss_n_60: 4.5326 (4.5988)  loss_n_80: 4.6747 (4.7393)  loss_n_100: 4.7504 (4.7845)  triple_100: 470.7341 (500.0375)  triple_80: 472.9492 (502.7577)  triple_60: 468.9471 (499.4769)  triple_40: 442.5163 (474.4275)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [550/845]  eta: 0:01:38  loss: 1938.2744 (1996.2696)  loss_n_40: 4.1076 (4.2418)  loss_n_60: 4.5639 (4.5978)  loss_n_80: 4.7262 (4.7380)  loss_n_100: 4.7929 (4.7830)  triple_100: 484.5048 (500.3284)  triple_80: 488.3758 (503.0578)  triple_60: 485.6149 (499.7785)  triple_40: 459.2362 (474.7442)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [560/845]  eta: 0:01:35  loss: 1942.6375 (1997.6891)  loss_n_40: 4.0850 (4.2402)  loss_n_60: 4.5406 (4.5961)  loss_n_80: 4.7095 (4.7364)  loss_n_100: 4.7668 (4.7813)  triple_100: 486.1247 (500.6889)  triple_80: 490.1763 (503.4143)  triple_60: 487.1548 (500.1314)  triple_40: 460.2187 (475.1005)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [570/845]  eta: 0:01:32  loss: 1981.1794 (1998.6880)  loss_n_40: 4.0847 (4.2401)  loss_n_60: 4.5616 (4.5962)  loss_n_80: 4.7095 (4.7363)  loss_n_100: 4.7668 (4.7809)  triple_100: 496.9748 (500.9253)  triple_80: 500.0795 (503.6549)  triple_60: 496.4026 (500.3858)  triple_40: 469.4141 (475.3685)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [580/845]  eta: 0:01:28  loss: 1935.6656 (1999.9911)  loss_n_40: 4.0925 (4.2389)  loss_n_60: 4.5616 (4.5938)  loss_n_80: 4.6938 (4.7339)  loss_n_100: 4.7551 (4.7788)  triple_100: 484.1941 (501.2498)  triple_80: 488.2042 (503.9745)  triple_60: 485.1337 (500.7071)  triple_40: 458.5449 (475.7142)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [590/845]  eta: 0:01:25  loss: 1960.4310 (2002.2395)  loss_n_40: 4.0925 (4.2363)  loss_n_60: 4.4805 (4.5900)  loss_n_80: 4.6575 (4.7305)  loss_n_100: 4.7093 (4.7756)  triple_100: 493.0198 (501.8273)  triple_80: 495.7574 (504.5397)  triple_60: 491.1423 (501.2635)  triple_40: 462.4413 (476.2767)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [600/845]  eta: 0:01:22  loss: 1922.7822 (2000.5478)  loss_n_40: 4.1190 (4.2390)  loss_n_60: 4.5951 (4.5930)  loss_n_80: 4.7527 (4.7335)  loss_n_100: 4.7883 (4.7785)  triple_100: 482.7420 (501.4040)  triple_80: 485.7852 (504.1180)  triple_60: 481.6707 (500.8438)  triple_40: 453.2184 (475.8380)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [610/845]  eta: 0:01:18  loss: 1844.5432 (1998.4275)  loss_n_40: 4.3807 (4.2423)  loss_n_60: 4.6872 (4.5965)  loss_n_80: 4.8387 (4.7370)  loss_n_100: 4.8871 (4.7820)  triple_100: 461.2058 (500.8700)  triple_80: 464.4615 (503.5898)  triple_60: 461.9276 (500.3160)  triple_40: 437.3568 (475.2940)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [620/845]  eta: 0:01:15  loss: 1855.4419 (1997.1379)  loss_n_40: 4.3334 (4.2436)  loss_n_60: 4.6425 (4.5994)  loss_n_80: 4.7930 (4.7401)  loss_n_100: 4.8528 (4.7848)  triple_100: 463.1109 (500.5498)  triple_80: 467.0764 (503.2752)  triple_60: 464.4303 (499.9935)  triple_40: 439.9268 (474.9514)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [630/845]  eta: 0:01:12  loss: 1895.1384 (1997.2856)  loss_n_40: 4.2737 (4.2436)  loss_n_60: 4.5777 (4.5991)  loss_n_80: 4.7347 (4.7397)  loss_n_100: 4.8005 (4.7846)  triple_100: 474.6898 (500.5823)  triple_80: 478.7321 (503.3071)  triple_60: 474.6750 (500.0298)  triple_40: 447.3268 (474.9994)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [640/845]  eta: 0:01:08  loss: 1897.9752 (1997.1123)  loss_n_40: 4.2923 (4.2447)  loss_n_60: 4.6191 (4.5996)  loss_n_80: 4.7679 (4.7400)  loss_n_100: 4.8215 (4.7850)  triple_100: 476.2191 (500.5357)  triple_80: 479.0984 (503.2593)  triple_60: 475.6312 (499.9835)  triple_40: 447.9540 (474.9645)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [650/845]  eta: 0:01:05  loss: 1911.6005 (1997.8101)  loss_n_40: 4.2923 (4.2451)  loss_n_60: 4.6382 (4.6005)  loss_n_80: 4.7833 (4.7411)  loss_n_100: 4.8422 (4.7860)  triple_100: 479.8894 (500.7172)  triple_80: 482.6041 (503.4398)  triple_60: 478.3878 (500.1572)  triple_40: 452.1700 (475.1232)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [660/845]  eta: 0:01:02  loss: 1932.6958 (1997.6559)  loss_n_40: 4.1593 (4.2448)  loss_n_60: 4.5654 (4.6001)  loss_n_80: 4.7177 (4.7407)  loss_n_100: 4.7610 (4.7856)  triple_100: 486.3541 (500.6777)  triple_80: 488.9353 (503.4007)  triple_60: 484.0053 (500.1157)  triple_40: 455.2825 (475.0906)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [670/845]  eta: 0:00:58  loss: 1866.6926 (1996.6243)  loss_n_40: 4.2569 (4.2457)  loss_n_60: 4.6066 (4.6003)  loss_n_80: 4.7533 (4.7409)  loss_n_100: 4.7997 (4.7860)  triple_100: 466.1825 (500.4212)  triple_80: 470.3475 (503.1398)  triple_60: 467.4864 (499.8535)  triple_40: 442.2630 (474.8370)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [680/845]  eta: 0:00:55  loss: 1880.3893 (1996.3246)  loss_n_40: 4.2711 (4.2462)  loss_n_60: 4.6135 (4.6010)  loss_n_80: 4.7659 (4.7417)  loss_n_100: 4.8367 (4.7868)  triple_100: 471.5750 (500.3506)  triple_80: 474.5906 (503.0708)  triple_60: 470.5478 (499.7801)  triple_40: 445.5646 (474.7475)  time: 0.3353  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [690/845]  eta: 0:00:51  loss: 1906.6938 (1997.5979)  loss_n_40: 4.1041 (4.2440)  loss_n_60: 4.5152 (4.5997)  loss_n_80: 4.7005 (4.7406)  loss_n_100: 4.7463 (4.7857)  triple_100: 480.2589 (500.6761)  triple_80: 482.3708 (503.3954)  triple_60: 477.5703 (500.0977)  triple_40: 449.2520 (475.0588)  time: 0.3354  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [700/845]  eta: 0:00:48  loss: 1914.5465 (1997.2140)  loss_n_40: 4.0747 (4.2418)  loss_n_60: 4.5142 (4.5976)  loss_n_80: 4.6818 (4.7388)  loss_n_100: 4.7344 (4.7841)  triple_100: 482.0046 (500.5911)  triple_80: 484.3426 (503.3079)  triple_60: 480.0560 (500.0026)  triple_40: 451.8835 (474.9500)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [710/845]  eta: 0:00:45  loss: 1876.3411 (1995.8323)  loss_n_40: 4.1792 (4.2435)  loss_n_60: 4.5262 (4.5999)  loss_n_80: 4.6863 (4.7410)  loss_n_100: 4.7656 (4.7862)  triple_100: 470.0092 (500.2452)  triple_80: 473.2476 (502.9661)  triple_60: 470.0199 (499.6618)  triple_40: 443.5147 (474.5885)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [720/845]  eta: 0:00:41  loss: 1876.3411 (1995.4415)  loss_n_40: 4.3592 (4.2447)  loss_n_60: 4.6538 (4.6006)  loss_n_80: 4.8127 (4.7415)  loss_n_100: 4.8836 (4.7868)  triple_100: 470.0092 (500.1418)  triple_80: 473.2476 (502.8660)  triple_60: 470.0199 (499.5654)  triple_40: 443.5147 (474.4946)  time: 0.3354  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [730/845]  eta: 0:00:38  loss: 1899.7766 (1994.9335)  loss_n_40: 4.2021 (4.2443)  loss_n_60: 4.6138 (4.6002)  loss_n_80: 4.7806 (4.7415)  loss_n_100: 4.7975 (4.7866)  triple_100: 475.0338 (500.0236)  triple_80: 478.8466 (502.7482)  triple_60: 475.6918 (499.4400)  triple_40: 448.8472 (474.3492)  time: 0.3353  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [740/845]  eta: 0:00:35  loss: 1899.7766 (1994.9093)  loss_n_40: 4.1668 (4.2439)  loss_n_60: 4.5418 (4.5999)  loss_n_80: 4.7145 (4.7412)  loss_n_100: 4.7527 (4.7862)  triple_100: 475.0338 (500.0180)  triple_80: 478.8466 (502.7452)  triple_60: 475.6918 (499.4345)  triple_40: 449.1291 (474.3405)  time: 0.3351  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:1]  [750/845]  eta: 0:00:31  loss: 1900.3879 (1993.9170)  loss_n_40: 4.2908 (4.2455)  loss_n_60: 4.6330 (4.6020)  loss_n_80: 4.7896 (4.7433)  loss_n_100: 4.8531 (4.7883)  triple_100: 476.7171 (499.7681)  triple_80: 479.8306 (502.4963)  triple_60: 476.4185 (499.1877)  triple_40: 448.5347 (474.0857)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [760/845]  eta: 0:00:28  loss: 1901.5781 (1993.9454)  loss_n_40: 4.3102 (4.2451)  loss_n_60: 4.6619 (4.6014)  loss_n_80: 4.8084 (4.7427)  loss_n_100: 4.8627 (4.7878)  triple_100: 477.6144 (499.7818)  triple_80: 480.5489 (502.5076)  triple_60: 476.4185 (499.1929)  triple_40: 448.5347 (474.0861)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [770/845]  eta: 0:00:25  loss: 1903.5430 (1993.2206)  loss_n_40: 4.1821 (4.2455)  loss_n_60: 4.5807 (4.6027)  loss_n_80: 4.7793 (4.7443)  loss_n_100: 4.8235 (4.7894)  triple_100: 478.2913 (499.6066)  triple_80: 481.0743 (502.3338)  triple_60: 476.7882 (499.0145)  triple_40: 449.9191 (473.8839)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [780/845]  eta: 0:00:21  loss: 1898.5907 (1993.7711)  loss_n_40: 4.3087 (4.2459)  loss_n_60: 4.5807 (4.6025)  loss_n_80: 4.7793 (4.7440)  loss_n_100: 4.8235 (4.7892)  triple_100: 476.7795 (499.7391)  triple_80: 479.6140 (502.4646)  triple_60: 475.3105 (499.1483)  triple_40: 450.0576 (474.0375)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [790/845]  eta: 0:00:18  loss: 1987.9045 (1995.3155)  loss_n_40: 4.3186 (4.2460)  loss_n_60: 4.5918 (4.6015)  loss_n_80: 4.7571 (4.7429)  loss_n_100: 4.7860 (4.7881)  triple_100: 498.3407 (500.1130)  triple_80: 501.2000 (502.8416)  triple_60: 497.5601 (499.5331)  triple_40: 470.0870 (474.4494)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [800/845]  eta: 0:00:15  loss: 1985.2250 (1996.5102)  loss_n_40: 4.1181 (4.2438)  loss_n_60: 4.5395 (4.5986)  loss_n_80: 4.6961 (4.7400)  loss_n_100: 4.7451 (4.7853)  triple_100: 498.3407 (500.4181)  triple_80: 501.2000 (503.1369)  triple_60: 497.1545 (499.8295)  triple_40: 468.7374 (474.7580)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [810/845]  eta: 0:00:11  loss: 1899.5197 (1997.3220)  loss_n_40: 4.0643 (4.2423)  loss_n_60: 4.5004 (4.5969)  loss_n_80: 4.6324 (4.7381)  loss_n_100: 4.7109 (4.7835)  triple_100: 477.0104 (500.6183)  triple_80: 479.5133 (503.3381)  triple_60: 475.4211 (500.0313)  triple_40: 447.0962 (474.9735)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [820/845]  eta: 0:00:08  loss: 1879.9594 (1996.9204)  loss_n_40: 4.0792 (4.2423)  loss_n_60: 4.5413 (4.5968)  loss_n_80: 4.7118 (4.7381)  loss_n_100: 4.7646 (4.7836)  triple_100: 471.1296 (500.5233)  triple_80: 474.7491 (503.2406)  triple_60: 470.1319 (499.9300)  triple_40: 444.7990 (474.8658)  time: 0.3355  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [830/845]  eta: 0:00:05  loss: 1868.2249 (1996.5755)  loss_n_40: 4.1516 (4.2408)  loss_n_60: 4.5446 (4.5950)  loss_n_80: 4.7178 (4.7364)  loss_n_100: 4.7703 (4.7822)  triple_100: 468.0928 (500.4456)  triple_80: 471.1215 (503.1538)  triple_60: 467.9182 (499.8397)  triple_40: 440.8134 (474.7819)  time: 0.3353  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [840/845]  eta: 0:00:01  loss: 1875.1837 (1995.9760)  loss_n_40: 4.1224 (4.2403)  loss_n_60: 4.5452 (4.5951)  loss_n_80: 4.7217 (4.7367)  loss_n_100: 4.7512 (4.7825)  triple_100: 471.1496 (500.3066)  triple_80: 473.6760 (503.0157)  triple_60: 469.3795 (499.6952)  triple_40: 442.2248 (474.6039)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1]  [844/845]  eta: 0:00:00  loss: 1875.1837 (1995.3874)  loss_n_40: 4.1330 (4.2407)  loss_n_60: 4.5452 (4.5957)  loss_n_80: 4.7217 (4.7372)  loss_n_100: 4.7512 (4.7830)  triple_100: 471.1496 (500.1576)  triple_80: 473.6760 (502.8680)  triple_60: 469.3795 (499.5476)  triple_40: 442.2248 (474.4577)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:1] Total time: 0:04:43 (0.3356 s / it)\n",
      "Averaged stats: loss: 1875.1837 (1995.3874)  loss_n_40: 4.1330 (4.2407)  loss_n_60: 4.5452 (4.5957)  loss_n_80: 4.7217 (4.7372)  loss_n_100: 4.7512 (4.7830)  triple_100: 471.1496 (500.1576)  triple_80: 473.6760 (502.8680)  triple_60: 469.3795 (499.5476)  triple_40: 442.2248 (474.4577)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_1_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 4.783%\n",
      "Min loss_n_100: 4.783\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:2]  [   0/1724]  eta: 2:01:17  lr: 0.000020  loss: 2049.6926 (2049.6926)  loss_n_40: 4.2900 (4.2900)  loss_n_60: 4.6675 (4.6675)  loss_n_80: 4.8229 (4.8229)  loss_n_100: 4.8600 (4.8600)  triple_100: 513.0549 (513.0549)  triple_80: 516.2518 (516.2518)  triple_60: 512.8323 (512.8323)  triple_40: 488.9135 (488.9135)  time: 4.2213  data: 0.4588  max mem: 46473\n",
      "Train: [epoch:2]  [  10/1724]  eta: 1:53:07  lr: 0.000020  loss: 2022.2627 (1974.9251)  loss_n_40: 4.2608 (4.2651)  loss_n_60: 4.6242 (4.5720)  loss_n_80: 4.7142 (4.6769)  loss_n_100: 4.7676 (4.7339)  triple_100: 506.3989 (495.3414)  triple_80: 508.9196 (497.8584)  triple_60: 506.5053 (494.9643)  triple_40: 482.4986 (468.5130)  time: 3.9600  data: 0.0419  max mem: 46473\n",
      "Train: [epoch:2]  [  20/1724]  eta: 1:52:03  lr: 0.000020  loss: 1896.9713 (1946.5817)  loss_n_40: 4.2506 (4.2534)  loss_n_60: 4.6242 (4.5864)  loss_n_80: 4.7142 (4.6674)  loss_n_100: 4.7676 (4.7320)  triple_100: 476.9805 (489.2504)  triple_80: 479.4797 (491.3889)  triple_60: 475.8506 (488.4652)  triple_40: 446.3045 (459.2382)  time: 3.9321  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [  30/1724]  eta: 1:51:14  lr: 0.000020  loss: 1891.4849 (1934.2671)  loss_n_40: 4.2262 (4.2389)  loss_n_60: 4.6192 (4.5694)  loss_n_80: 4.6398 (4.6400)  loss_n_100: 4.7294 (4.7102)  triple_100: 477.7296 (486.6267)  triple_80: 479.1340 (488.4870)  triple_60: 475.0655 (485.7397)  triple_40: 441.1112 (455.2551)  time: 3.9293  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [  40/1724]  eta: 1:50:29  lr: 0.000020  loss: 1765.3658 (1885.9058)  loss_n_40: 4.2527 (4.2640)  loss_n_60: 4.6491 (4.6160)  loss_n_80: 4.6955 (4.6874)  loss_n_100: 4.7859 (4.7545)  triple_100: 448.2486 (475.4681)  triple_80: 448.9321 (477.0262)  triple_60: 445.4961 (474.2201)  triple_40: 404.5772 (440.8695)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [  50/1724]  eta: 1:49:47  lr: 0.000020  loss: 1740.5481 (1878.2284)  loss_n_40: 4.2527 (4.2603)  loss_n_60: 4.6341 (4.6182)  loss_n_80: 4.6871 (4.6857)  loss_n_100: 4.7359 (4.7497)  triple_100: 445.6285 (474.3823)  triple_80: 445.2582 (475.5480)  triple_60: 440.9308 (472.7218)  triple_40: 397.0665 (437.2624)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [  60/1724]  eta: 1:49:06  lr: 0.000020  loss: 1678.7847 (1828.7618)  loss_n_40: 4.2920 (4.2769)  loss_n_60: 4.7565 (4.6668)  loss_n_80: 4.8795 (4.7499)  loss_n_100: 4.8047 (4.7864)  triple_100: 430.5970 (463.3753)  triple_80: 429.4120 (464.1437)  triple_60: 425.1756 (460.8765)  triple_40: 374.5197 (421.8863)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [  70/1724]  eta: 1:48:25  lr: 0.000020  loss: 1532.5271 (1777.5370)  loss_n_40: 4.4828 (4.3200)  loss_n_60: 5.0773 (4.7518)  loss_n_80: 5.2536 (4.8491)  loss_n_100: 5.1090 (4.8556)  triple_100: 396.9579 (451.9633)  triple_80: 396.4131 (452.5902)  triple_60: 390.1283 (448.4375)  triple_40: 326.7463 (405.7694)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [  80/1724]  eta: 1:47:45  lr: 0.000020  loss: 1367.3680 (1710.6882)  loss_n_40: 4.5658 (4.3651)  loss_n_60: 5.3274 (4.8538)  loss_n_80: 5.5492 (4.9620)  loss_n_100: 5.3558 (4.9408)  triple_100: 363.1310 (437.5907)  triple_80: 360.5161 (437.8546)  triple_60: 346.8440 (431.6480)  triple_40: 272.3669 (384.4732)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [  90/1724]  eta: 1:47:05  lr: 0.000020  loss: 1099.1736 (1635.0115)  loss_n_40: 4.7973 (4.4254)  loss_n_60: 5.8407 (4.9775)  loss_n_80: 6.1044 (5.1092)  loss_n_100: 5.7503 (5.0519)  triple_100: 298.9495 (421.2274)  triple_80: 298.9960 (421.0387)  triple_60: 275.1066 (411.3671)  triple_40: 203.8757 (361.8144)  time: 3.9302  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [ 100/1724]  eta: 1:46:25  lr: 0.000020  loss: 922.6646 (1555.9293)  loss_n_40: 4.9466 (4.4897)  loss_n_60: 6.0466 (5.1015)  loss_n_80: 6.3860 (5.2584)  loss_n_100: 6.1097 (5.1782)  triple_100: 265.1029 (403.9602)  triple_80: 260.5461 (403.2274)  triple_60: 215.1538 (388.7397)  triple_40: 149.4640 (339.9742)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 110/1724]  eta: 1:45:46  lr: 0.000020  loss: 746.0799 (1476.4909)  loss_n_40: 5.0578 (4.5453)  loss_n_60: 6.3387 (5.2249)  loss_n_80: 6.8458 (5.4108)  loss_n_100: 6.3784 (5.2982)  triple_100: 214.8027 (385.8557)  triple_80: 219.9671 (384.9040)  triple_60: 152.1118 (365.2323)  triple_40: 114.3768 (320.0197)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 120/1724]  eta: 1:45:06  lr: 0.000020  loss: 608.7460 (1405.6365)  loss_n_40: 5.1101 (4.5977)  loss_n_60: 6.5354 (5.3519)  loss_n_80: 7.0801 (5.5658)  loss_n_100: 6.6181 (5.4224)  triple_100: 180.8643 (369.2848)  triple_80: 177.6582 (368.1748)  triple_60: 109.9865 (344.3242)  triple_40: 102.9316 (302.9150)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 130/1724]  eta: 1:44:26  lr: 0.000020  loss: 604.9573 (1343.7204)  loss_n_40: 5.2353 (4.6469)  loss_n_60: 6.9083 (5.4767)  loss_n_80: 7.4421 (5.7175)  loss_n_100: 6.9116 (5.5428)  triple_100: 172.3281 (354.0598)  triple_80: 169.8159 (352.7934)  triple_60: 112.1216 (326.5769)  triple_40: 119.0092 (288.9064)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 140/1724]  eta: 1:43:46  lr: 0.000020  loss: 557.7627 (1281.7758)  loss_n_40: 5.2469 (4.6880)  loss_n_60: 7.0135 (5.5862)  loss_n_80: 7.5964 (5.8531)  loss_n_100: 7.1126 (5.6610)  triple_100: 157.6318 (339.4836)  triple_80: 151.2307 (337.3393)  triple_60: 101.8643 (308.9123)  triple_40: 99.6339 (274.2522)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 150/1724]  eta: 1:43:07  lr: 0.000020  loss: 484.7840 (1230.4085)  loss_n_40: 5.2851 (4.7293)  loss_n_60: 7.1039 (5.6927)  loss_n_80: 7.7396 (5.9814)  loss_n_100: 7.2976 (5.7765)  triple_100: 149.2701 (327.2371)  triple_80: 137.5272 (324.4038)  triple_60: 84.8344 (294.5962)  triple_40: 87.6445 (261.9915)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 160/1724]  eta: 1:42:27  lr: 0.000020  loss: 450.4060 (1177.7112)  loss_n_40: 5.2936 (4.7704)  loss_n_60: 7.2092 (5.7940)  loss_n_80: 7.8530 (6.1045)  loss_n_100: 7.4585 (5.8918)  triple_100: 133.0444 (314.7585)  triple_80: 120.6389 (310.8889)  triple_60: 78.0653 (279.7888)  triple_40: 70.9282 (249.7143)  time: 3.9293  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 170/1724]  eta: 1:41:48  lr: 0.000020  loss: 380.0864 (1133.5614)  loss_n_40: 5.4014 (4.8138)  loss_n_60: 7.3661 (5.8949)  loss_n_80: 8.0777 (6.2227)  loss_n_100: 7.6704 (6.0001)  triple_100: 122.2825 (304.1142)  triple_80: 105.4306 (299.6608)  triple_60: 45.2008 (267.5201)  triple_40: 50.9732 (239.3347)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 180/1724]  eta: 1:41:08  lr: 0.000020  loss: 355.6980 (1091.0499)  loss_n_40: 5.4329 (4.8503)  loss_n_60: 7.4629 (5.9825)  loss_n_80: 8.0871 (6.3274)  loss_n_100: 7.7843 (6.1020)  triple_100: 124.2928 (294.4124)  triple_80: 106.3166 (289.0827)  triple_60: 44.9599 (255.5401)  triple_40: 41.8260 (228.7523)  time: 3.9293  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 190/1724]  eta: 1:40:29  lr: 0.000020  loss: 343.8773 (1052.4174)  loss_n_40: 5.4329 (4.8870)  loss_n_60: 7.4629 (6.0669)  loss_n_80: 8.1134 (6.4270)  loss_n_100: 7.7523 (6.1956)  triple_100: 120.3916 (285.1513)  triple_80: 101.2348 (279.3328)  triple_60: 44.9599 (244.8667)  triple_40: 41.8180 (219.4902)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 200/1724]  eta: 1:39:50  lr: 0.000020  loss: 332.4919 (1016.0251)  loss_n_40: 5.5687 (4.9244)  loss_n_60: 7.6178 (6.1491)  loss_n_80: 8.1942 (6.5195)  loss_n_100: 7.8662 (6.2811)  triple_100: 111.4543 (276.3624)  triple_80: 100.0758 (270.1880)  triple_60: 48.0567 (234.8583)  triple_40: 38.3980 (210.7422)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 210/1724]  eta: 1:39:11  lr: 0.000020  loss: 314.1219 (981.1744)  loss_n_40: 5.7450 (4.9696)  loss_n_60: 7.8780 (6.2387)  loss_n_80: 8.4197 (6.6177)  loss_n_100: 8.0481 (6.3736)  triple_100: 106.8064 (267.9272)  triple_80: 91.8866 (261.3842)  triple_60: 44.4317 (225.3642)  triple_40: 35.7963 (202.2992)  time: 3.9318  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 220/1724]  eta: 1:38:31  lr: 0.000020  loss: 309.3629 (950.6042)  loss_n_40: 5.7754 (5.0022)  loss_n_60: 7.8655 (6.3081)  loss_n_80: 8.4197 (6.6972)  loss_n_100: 8.0969 (6.4477)  triple_100: 105.8297 (260.7339)  triple_80: 91.8177 (253.9415)  triple_60: 41.2352 (216.8825)  triple_40: 26.6505 (194.5911)  time: 3.9325  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 230/1724]  eta: 1:37:52  lr: 0.000020  loss: 259.9467 (920.0532)  loss_n_40: 5.7832 (5.0418)  loss_n_60: 7.8927 (6.3843)  loss_n_80: 8.4952 (6.7808)  loss_n_100: 8.1014 (6.5248)  triple_100: 94.1599 (253.2749)  triple_80: 82.4898 (246.3119)  triple_60: 29.6981 (208.5263)  triple_40: 18.9766 (187.2083)  time: 3.9313  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 240/1724]  eta: 1:37:13  lr: 0.000020  loss: 193.5260 (892.2493)  loss_n_40: 5.8590 (5.0765)  loss_n_60: 7.9928 (6.4530)  loss_n_80: 8.6073 (6.8579)  loss_n_100: 8.2129 (6.5946)  triple_100: 81.0614 (246.3503)  triple_80: 63.8874 (239.3214)  triple_60: 12.4881 (201.0340)  triple_40: 13.6896 (180.5614)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 250/1724]  eta: 1:36:33  lr: 0.000020  loss: 251.0873 (866.8325)  loss_n_40: 5.9280 (5.1127)  loss_n_60: 8.1149 (6.5227)  loss_n_80: 8.6563 (6.9328)  loss_n_100: 8.1712 (6.6578)  triple_100: 79.3259 (239.7757)  triple_80: 78.3680 (232.9543)  triple_60: 32.9002 (194.2917)  triple_40: 30.9518 (174.5847)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 260/1724]  eta: 1:35:54  lr: 0.000020  loss: 251.0873 (843.1822)  loss_n_40: 5.8946 (5.1393)  loss_n_60: 8.0340 (6.5773)  loss_n_80: 8.6505 (6.9965)  loss_n_100: 8.0936 (6.7097)  triple_100: 78.0873 (233.7056)  triple_80: 78.3680 (227.1804)  triple_60: 29.1147 (187.9346)  triple_40: 30.9518 (168.9388)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 270/1724]  eta: 1:35:14  lr: 0.000020  loss: 216.7968 (820.5242)  loss_n_40: 5.8793 (5.1701)  loss_n_60: 7.9476 (6.6353)  loss_n_80: 8.6454 (7.0623)  loss_n_100: 8.0598 (6.7640)  triple_100: 74.3039 (227.7610)  triple_80: 77.2606 (221.7120)  triple_60: 16.3112 (181.8856)  triple_40: 10.3225 (163.5338)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 280/1724]  eta: 1:34:35  lr: 0.000020  loss: 166.5642 (797.3897)  loss_n_40: 5.9762 (5.1996)  loss_n_60: 8.1990 (6.6908)  loss_n_80: 8.7669 (7.1250)  loss_n_100: 8.1456 (6.8133)  triple_100: 57.7464 (221.7132)  triple_80: 57.1169 (215.9744)  triple_60: 7.7435 (175.8052)  triple_40: 6.1251 (158.0683)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 290/1724]  eta: 1:33:55  lr: 0.000020  loss: 166.5642 (777.3690)  loss_n_40: 5.9411 (5.2222)  loss_n_60: 8.0915 (6.7359)  loss_n_80: 8.8242 (7.1800)  loss_n_100: 8.1338 (6.8567)  triple_100: 60.4723 (216.4348)  triple_80: 57.4072 (211.0703)  triple_60: 8.8745 (170.5377)  triple_40: 6.6914 (153.3313)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 300/1724]  eta: 1:33:16  lr: 0.000020  loss: 177.7359 (758.7093)  loss_n_40: 5.8433 (5.2410)  loss_n_60: 7.9667 (6.7745)  loss_n_80: 8.7349 (7.2304)  loss_n_100: 8.0982 (6.8954)  triple_100: 63.4157 (211.4881)  triple_80: 65.4507 (206.4860)  triple_60: 12.9575 (165.6575)  triple_40: 12.2945 (148.9363)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 310/1724]  eta: 1:32:36  lr: 0.000020  loss: 196.1408 (741.2606)  loss_n_40: 5.7720 (5.2598)  loss_n_60: 7.8840 (6.8130)  loss_n_80: 8.7349 (7.2797)  loss_n_100: 7.9562 (6.9323)  triple_100: 63.4157 (206.7716)  triple_80: 67.4734 (202.2145)  triple_60: 21.5171 (161.1439)  triple_40: 10.2848 (144.8458)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 320/1724]  eta: 1:31:57  lr: 0.000020  loss: 202.7843 (724.4039)  loss_n_40: 5.7846 (5.2773)  loss_n_60: 7.9178 (6.8500)  loss_n_80: 8.7937 (7.3278)  loss_n_100: 8.0495 (6.9682)  triple_100: 62.2838 (202.2172)  triple_80: 69.1480 (198.0652)  triple_60: 21.7416 (156.8071)  triple_40: 10.2848 (140.8910)  time: 3.9283  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [ 330/1724]  eta: 1:31:18  lr: 0.000020  loss: 196.9863 (708.2432)  loss_n_40: 5.9672 (5.3003)  loss_n_60: 8.1669 (6.8936)  loss_n_80: 8.8712 (7.3772)  loss_n_100: 8.1863 (7.0058)  triple_100: 58.1774 (197.6357)  triple_80: 68.5695 (194.0574)  triple_60: 22.0278 (152.6908)  triple_40: 10.3321 (137.2824)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 340/1724]  eta: 1:30:38  lr: 0.000020  loss: 164.7229 (692.7831)  loss_n_40: 6.0035 (5.3187)  loss_n_60: 8.1891 (6.9297)  loss_n_80: 8.9830 (7.4226)  loss_n_100: 8.2123 (7.0415)  triple_100: 47.6898 (193.4489)  triple_80: 57.7083 (190.1427)  triple_60: 14.9389 (148.7807)  triple_40: 14.4134 (133.6982)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 350/1724]  eta: 1:29:59  lr: 0.000020  loss: 176.7464 (679.3243)  loss_n_40: 5.8797 (5.3344)  loss_n_60: 8.1064 (6.9619)  loss_n_80: 8.9396 (7.4634)  loss_n_100: 8.0827 (7.0697)  triple_100: 52.9295 (189.5455)  triple_80: 57.3304 (186.8392)  triple_60: 18.0826 (145.3230)  triple_40: 14.4134 (130.7871)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 360/1724]  eta: 1:29:19  lr: 0.000020  loss: 221.9450 (666.5442)  loss_n_40: 5.9006 (5.3501)  loss_n_60: 8.1293 (6.9931)  loss_n_80: 8.8733 (7.5040)  loss_n_100: 8.0827 (7.1029)  triple_100: 58.6674 (185.9994)  triple_80: 74.2770 (183.7094)  triple_60: 28.1011 (142.0738)  triple_40: 24.3541 (127.8115)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 370/1724]  eta: 1:28:40  lr: 0.000020  loss: 199.0257 (653.5837)  loss_n_40: 5.9258 (5.3677)  loss_n_60: 8.1293 (7.0252)  loss_n_80: 8.9529 (7.5454)  loss_n_100: 8.2237 (7.1342)  triple_100: 57.4238 (182.2919)  triple_80: 68.4610 (180.4648)  triple_60: 25.0351 (138.7783)  triple_40: 18.3415 (124.9763)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 380/1724]  eta: 1:28:01  lr: 0.000020  loss: 144.4894 (640.1938)  loss_n_40: 6.0341 (5.3870)  loss_n_60: 8.2543 (7.0591)  loss_n_80: 9.0899 (7.5880)  loss_n_100: 8.3620 (7.1685)  triple_100: 42.9159 (178.5622)  triple_80: 54.1125 (177.1065)  triple_60: 11.5667 (135.4534)  triple_40: 4.7367 (121.8692)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 390/1724]  eta: 1:27:21  lr: 0.000020  loss: 139.7810 (627.8244)  loss_n_40: 6.0406 (5.4034)  loss_n_60: 8.2543 (7.0894)  loss_n_80: 9.1280 (7.6272)  loss_n_100: 8.3876 (7.1966)  triple_100: 34.7074 (174.9949)  triple_80: 48.7578 (173.9722)  triple_60: 8.8851 (132.3952)  triple_40: 4.2530 (119.1456)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 400/1724]  eta: 1:26:42  lr: 0.000020  loss: 126.4656 (615.8021)  loss_n_40: 5.9662 (5.4162)  loss_n_60: 8.1583 (7.1146)  loss_n_80: 9.0827 (7.6629)  loss_n_100: 8.1751 (7.2204)  triple_100: 34.7074 (171.5625)  triple_80: 47.1008 (170.9117)  triple_60: 7.6089 (129.4115)  triple_40: 3.9529 (116.5024)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 410/1724]  eta: 1:26:03  lr: 0.000020  loss: 138.3856 (604.8849)  loss_n_40: 5.9662 (5.4317)  loss_n_60: 8.1583 (7.1421)  loss_n_80: 9.0080 (7.6978)  loss_n_100: 8.2215 (7.2493)  triple_100: 39.4411 (168.3892)  triple_80: 46.7759 (168.1142)  triple_60: 13.0113 (126.7540)  triple_40: 2.6535 (114.1066)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 420/1724]  eta: 1:25:23  lr: 0.000020  loss: 138.3856 (593.7430)  loss_n_40: 5.9882 (5.4435)  loss_n_60: 8.1853 (7.1657)  loss_n_80: 9.1295 (7.7313)  loss_n_100: 8.3330 (7.2746)  triple_100: 41.5349 (165.2299)  triple_80: 43.7049 (165.1717)  triple_60: 14.4778 (124.0837)  triple_40: 4.1064 (111.6426)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 430/1724]  eta: 1:24:44  lr: 0.000020  loss: 135.7160 (583.6649)  loss_n_40: 5.9096 (5.4569)  loss_n_60: 8.1032 (7.1906)  loss_n_80: 9.1130 (7.7633)  loss_n_100: 8.3330 (7.3031)  triple_100: 41.5349 (162.3657)  triple_80: 42.1024 (162.5036)  triple_60: 14.3221 (121.6876)  triple_40: 3.5506 (109.3940)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 440/1724]  eta: 1:24:05  lr: 0.000020  loss: 136.4148 (573.4788)  loss_n_40: 6.0005 (5.4728)  loss_n_60: 8.1968 (7.2168)  loss_n_80: 9.1362 (7.7957)  loss_n_100: 8.4955 (7.3297)  triple_100: 32.7210 (159.3722)  triple_80: 44.3564 (159.7870)  triple_60: 14.3221 (119.2532)  triple_40: 3.9790 (107.2514)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 450/1724]  eta: 1:23:25  lr: 0.000020  loss: 98.9969 (562.9691)  loss_n_40: 6.0267 (5.4848)  loss_n_60: 8.1977 (7.2389)  loss_n_80: 9.2113 (7.8269)  loss_n_100: 8.5159 (7.3563)  triple_100: 30.4934 (156.4435)  triple_80: 30.5350 (156.9033)  triple_60: 8.9975 (116.7711)  triple_40: 1.4490 (104.9442)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 460/1724]  eta: 1:22:46  lr: 0.000020  loss: 107.4893 (554.2227)  loss_n_40: 6.0655 (5.4983)  loss_n_60: 8.2595 (7.2634)  loss_n_80: 9.0806 (7.8542)  loss_n_100: 8.5304 (7.3829)  triple_100: 33.7741 (153.8456)  triple_80: 31.1832 (154.4699)  triple_60: 9.3418 (114.8094)  triple_40: 3.0387 (103.0991)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 470/1724]  eta: 1:22:07  lr: 0.000020  loss: 156.5371 (545.6916)  loss_n_40: 6.1793 (5.5114)  loss_n_60: 8.4062 (7.2865)  loss_n_80: 9.0357 (7.8794)  loss_n_100: 8.5943 (7.4101)  triple_100: 34.7216 (151.4125)  triple_80: 39.9923 (151.9948)  triple_60: 25.6932 (112.8552)  triple_40: 20.0157 (101.3416)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 480/1724]  eta: 1:21:27  lr: 0.000020  loss: 114.8174 (536.3445)  loss_n_40: 6.1050 (5.5216)  loss_n_60: 8.3031 (7.3064)  loss_n_80: 9.0658 (7.9026)  loss_n_100: 8.5943 (7.4362)  triple_100: 32.0409 (148.8924)  triple_80: 23.0730 (149.1830)  triple_60: 15.3516 (110.7506)  triple_40: 11.6402 (99.3516)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 490/1724]  eta: 1:20:48  lr: 0.000020  loss: 88.6508 (527.2484)  loss_n_40: 5.9829 (5.5332)  loss_n_60: 8.2293 (7.3275)  loss_n_80: 9.0331 (7.9247)  loss_n_100: 8.8070 (7.4661)  triple_100: 28.4072 (146.4674)  triple_80: 14.2096 (146.3868)  triple_60: 10.7267 (108.7205)  triple_40: 0.0000 (97.4221)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 500/1724]  eta: 1:20:09  lr: 0.000020  loss: 78.5843 (518.2520)  loss_n_40: 6.1124 (5.5459)  loss_n_60: 8.3822 (7.3500)  loss_n_80: 9.0388 (7.9473)  loss_n_100: 8.9148 (7.4959)  triple_100: 25.3179 (144.0013)  triple_80: 9.2854 (143.6461)  triple_60: 10.7267 (106.7258)  triple_40: 1.3668 (95.5398)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 510/1724]  eta: 1:19:29  lr: 0.000020  loss: 75.1561 (510.2513)  loss_n_40: 6.1945 (5.5604)  loss_n_60: 8.4864 (7.3737)  loss_n_80: 9.0388 (7.9680)  loss_n_100: 8.9440 (7.5247)  triple_100: 21.6371 (141.6881)  triple_80: 8.1636 (141.1518)  triple_60: 11.4332 (105.0532)  triple_40: 1.0353 (93.9314)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 520/1724]  eta: 1:18:50  lr: 0.000020  loss: 82.2453 (502.3939)  loss_n_40: 6.2071 (5.5715)  loss_n_60: 8.5043 (7.3937)  loss_n_80: 8.8907 (7.9866)  loss_n_100: 8.9500 (7.5516)  triple_100: 24.3107 (139.4643)  triple_80: 10.4033 (138.7242)  triple_60: 15.2655 (103.4077)  triple_40: 4.5478 (92.2942)  time: 3.9271  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:2]  [ 530/1724]  eta: 1:18:11  lr: 0.000020  loss: 80.3108 (494.6044)  loss_n_40: 6.1211 (5.5841)  loss_n_60: 8.4328 (7.4142)  loss_n_80: 8.9367 (8.0054)  loss_n_100: 8.8712 (7.5763)  triple_100: 19.8814 (137.2427)  triple_80: 9.7150 (136.3457)  triple_60: 14.4269 (101.7397)  triple_40: 2.9141 (90.6963)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 540/1724]  eta: 1:17:31  lr: 0.000020  loss: 71.8885 (486.9525)  loss_n_40: 6.1453 (5.5957)  loss_n_60: 8.4328 (7.4341)  loss_n_80: 8.9916 (8.0251)  loss_n_100: 8.8377 (7.6011)  triple_100: 16.0840 (135.0300)  triple_80: 8.4999 (134.0213)  triple_60: 8.8668 (100.1251)  triple_40: 0.9776 (89.1201)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 550/1724]  eta: 1:16:52  lr: 0.000020  loss: 81.0175 (479.6091)  loss_n_40: 6.3242 (5.6083)  loss_n_60: 8.5567 (7.4543)  loss_n_80: 9.0013 (8.0444)  loss_n_100: 8.8642 (7.6259)  triple_100: 16.7434 (132.8855)  triple_80: 10.6590 (131.8033)  triple_60: 15.4421 (98.5823)  triple_40: 1.4492 (87.6050)  time: 3.9282  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [ 560/1724]  eta: 1:16:13  lr: 0.000020  loss: 66.2182 (472.4898)  loss_n_40: 6.3350 (5.6203)  loss_n_60: 8.5711 (7.4736)  loss_n_80: 9.0926 (8.0638)  loss_n_100: 8.9506 (7.6528)  triple_100: 15.2157 (130.8032)  triple_80: 7.9641 (129.6327)  triple_60: 11.5584 (97.0802)  triple_40: 1.2268 (86.1632)  time: 3.9296  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 570/1724]  eta: 1:15:33  lr: 0.000020  loss: 67.0234 (465.6398)  loss_n_40: 6.3101 (5.6319)  loss_n_60: 8.5711 (7.4927)  loss_n_80: 9.0834 (8.0809)  loss_n_100: 9.0387 (7.6776)  triple_100: 13.3435 (128.8024)  triple_80: 6.9733 (127.5319)  triple_60: 12.0148 (95.6708)  triple_40: 0.6220 (84.7515)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 580/1724]  eta: 1:14:54  lr: 0.000020  loss: 67.0234 (458.8647)  loss_n_40: 6.2887 (5.6421)  loss_n_60: 8.5578 (7.5113)  loss_n_80: 9.0518 (8.0985)  loss_n_100: 9.0732 (7.7029)  triple_100: 13.3435 (126.7993)  triple_80: 7.6933 (125.4873)  triple_60: 13.2654 (94.2816)  triple_40: 0.4268 (83.3418)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 590/1724]  eta: 1:14:15  lr: 0.000020  loss: 52.4572 (452.0620)  loss_n_40: 6.2005 (5.6522)  loss_n_60: 8.5204 (7.5288)  loss_n_80: 9.0003 (8.1136)  loss_n_100: 9.0798 (7.7248)  triple_100: 9.0715 (124.8061)  triple_80: 3.9562 (123.4319)  triple_60: 8.5775 (92.8443)  triple_40: 0.0000 (81.9604)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 600/1724]  eta: 1:13:36  lr: 0.000020  loss: 45.2141 (445.7993)  loss_n_40: 6.2875 (5.6647)  loss_n_60: 8.6317 (7.5482)  loss_n_80: 9.0150 (8.1290)  loss_n_100: 9.1282 (7.7478)  triple_100: 5.4644 (122.9245)  triple_80: 1.7080 (121.5329)  triple_60: 5.0350 (91.5534)  triple_40: 0.0000 (80.6988)  time: 3.9301  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 610/1724]  eta: 1:12:56  lr: 0.000020  loss: 61.8992 (439.9216)  loss_n_40: 6.3794 (5.6761)  loss_n_60: 8.6523 (7.5661)  loss_n_80: 9.0191 (8.1421)  loss_n_100: 9.0540 (7.7693)  triple_100: 9.2073 (121.1510)  triple_80: 6.2339 (119.7190)  triple_60: 12.4034 (90.3577)  triple_40: 1.1375 (79.5404)  time: 3.9290  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 620/1724]  eta: 1:12:17  lr: 0.000020  loss: 64.2370 (434.2236)  loss_n_40: 6.3225 (5.6862)  loss_n_60: 8.5669 (7.5822)  loss_n_80: 8.9601 (8.1556)  loss_n_100: 9.0540 (7.7906)  triple_100: 8.4046 (119.4090)  triple_80: 4.0304 (117.9844)  triple_60: 13.5636 (89.1996)  triple_40: 1.5838 (78.4159)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 630/1724]  eta: 1:11:38  lr: 0.000020  loss: 64.2370 (428.5985)  loss_n_40: 6.3434 (5.6962)  loss_n_60: 8.6383 (7.5986)  loss_n_80: 8.9388 (8.1665)  loss_n_100: 8.9348 (7.8084)  triple_100: 7.1803 (117.7240)  triple_80: 4.0304 (116.2678)  triple_60: 13.5636 (88.0825)  triple_40: 0.5312 (77.2546)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 640/1724]  eta: 1:10:58  lr: 0.000020  loss: 53.6854 (422.8647)  loss_n_40: 6.3307 (5.7065)  loss_n_60: 8.5955 (7.6142)  loss_n_80: 8.8851 (8.1787)  loss_n_100: 8.8908 (7.8260)  triple_100: 6.3754 (116.0117)  triple_80: 3.3189 (114.5309)  triple_60: 10.1447 (86.8759)  triple_40: 0.2386 (76.1207)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 650/1724]  eta: 1:10:19  lr: 0.000020  loss: 48.5522 (417.2721)  loss_n_40: 6.3613 (5.7170)  loss_n_60: 8.5624 (7.6298)  loss_n_80: 8.9151 (8.1907)  loss_n_100: 8.8549 (7.8430)  triple_100: 5.0225 (114.3437)  triple_80: 2.9544 (112.8341)  triple_60: 9.1368 (85.7139)  triple_40: 0.0000 (74.9998)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 660/1724]  eta: 1:09:40  lr: 0.000020  loss: 37.3344 (411.6331)  loss_n_40: 6.3300 (5.7266)  loss_n_60: 8.5495 (7.6440)  loss_n_80: 9.0127 (8.2042)  loss_n_100: 8.9416 (7.8616)  triple_100: 1.7971 (112.6578)  triple_80: 0.0000 (111.1574)  triple_60: 3.1316 (84.4864)  triple_40: 0.0000 (73.8950)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 670/1724]  eta: 1:09:00  lr: 0.000020  loss: 35.7912 (406.1452)  loss_n_40: 6.3308 (5.7364)  loss_n_60: 8.5446 (7.6579)  loss_n_80: 9.0283 (8.2172)  loss_n_100: 9.0973 (7.8807)  triple_100: 1.0420 (111.0341)  triple_80: 0.0000 (109.5195)  triple_60: 0.6997 (83.3004)  triple_40: 0.0000 (72.7990)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 680/1724]  eta: 1:08:21  lr: 0.000020  loss: 37.8230 (401.0011)  loss_n_40: 6.3877 (5.7472)  loss_n_60: 8.5805 (7.6727)  loss_n_80: 9.0114 (8.2297)  loss_n_100: 9.1362 (7.8984)  triple_100: 3.5012 (109.4874)  triple_80: 0.0000 (107.9664)  triple_60: 2.5569 (82.2021)  triple_40: 0.0000 (71.7972)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 690/1724]  eta: 1:07:42  lr: 0.000020  loss: 53.8232 (396.1315)  loss_n_40: 6.3654 (5.7577)  loss_n_60: 8.5874 (7.6871)  loss_n_80: 8.9412 (8.2394)  loss_n_100: 8.9014 (7.9133)  triple_100: 4.4845 (108.0170)  triple_80: 3.3464 (106.4831)  triple_60: 10.1371 (81.2038)  triple_40: 0.0000 (70.8302)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 700/1724]  eta: 1:07:03  lr: 0.000020  loss: 55.0176 (391.3174)  loss_n_40: 6.3800 (5.7682)  loss_n_60: 8.6397 (7.7017)  loss_n_80: 8.9952 (8.2499)  loss_n_100: 9.0227 (7.9312)  triple_100: 8.2007 (106.5738)  triple_80: 4.2966 (105.0145)  triple_60: 10.5181 (80.2051)  triple_40: 0.0000 (69.8729)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 710/1724]  eta: 1:06:23  lr: 0.000020  loss: 48.9452 (386.6346)  loss_n_40: 6.3631 (5.7767)  loss_n_60: 8.6052 (7.7142)  loss_n_80: 8.9329 (8.2590)  loss_n_100: 9.0437 (7.9464)  triple_100: 3.4475 (105.1458)  triple_80: 2.4021 (103.5965)  triple_60: 10.0310 (79.2493)  triple_40: 0.0000 (68.9468)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 720/1724]  eta: 1:05:44  lr: 0.000020  loss: 46.9458 (382.1497)  loss_n_40: 6.4226 (5.7870)  loss_n_60: 8.6418 (7.7282)  loss_n_80: 8.7891 (8.2674)  loss_n_100: 8.9643 (7.9621)  triple_100: 2.5009 (103.7971)  triple_80: 1.5931 (102.2325)  triple_60: 9.3780 (78.3232)  triple_40: 0.0000 (68.0522)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 730/1724]  eta: 1:05:05  lr: 0.000020  loss: 53.5867 (377.8073)  loss_n_40: 6.4728 (5.7966)  loss_n_60: 8.7284 (7.7412)  loss_n_80: 8.7829 (8.2762)  loss_n_100: 8.9842 (7.9768)  triple_100: 5.5848 (102.4762)  triple_80: 2.7853 (100.9148)  triple_60: 10.6145 (77.4385)  triple_40: 0.0000 (67.1871)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 740/1724]  eta: 1:04:25  lr: 0.000020  loss: 55.1007 (373.5117)  loss_n_40: 6.4305 (5.8063)  loss_n_60: 8.6888 (7.7540)  loss_n_80: 8.8729 (8.2834)  loss_n_100: 9.1002 (7.9915)  triple_100: 5.7685 (101.1769)  triple_80: 3.3537 (99.6059)  triple_60: 11.2792 (76.5589)  triple_40: 0.6898 (66.3349)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 750/1724]  eta: 1:03:46  lr: 0.000020  loss: 53.4797 (369.3863)  loss_n_40: 6.4369 (5.8150)  loss_n_60: 8.6932 (7.7662)  loss_n_80: 8.8729 (8.2923)  loss_n_100: 9.1002 (8.0067)  triple_100: 2.6614 (99.9051)  triple_80: 2.0218 (98.3541)  triple_60: 8.8253 (75.7274)  triple_40: 0.0000 (65.5196)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 760/1724]  eta: 1:03:07  lr: 0.000020  loss: 40.7421 (365.1175)  loss_n_40: 6.4369 (5.8238)  loss_n_60: 8.6873 (7.7779)  loss_n_80: 8.9757 (8.3014)  loss_n_100: 9.0883 (8.0219)  triple_100: 0.6333 (98.6218)  triple_80: 0.9077 (97.0798)  triple_60: 7.3697 (74.8095)  triple_40: 0.0000 (64.6814)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 770/1724]  eta: 1:02:27  lr: 0.000020  loss: 42.6697 (361.4073)  loss_n_40: 6.3900 (5.8315)  loss_n_60: 8.6711 (7.7887)  loss_n_80: 8.8152 (8.3071)  loss_n_100: 9.0174 (8.0338)  triple_100: 2.4253 (97.4712)  triple_80: 1.6988 (95.9316)  triple_60: 7.7233 (74.0727)  triple_40: 0.0000 (63.9708)  time: 3.9271  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 780/1724]  eta: 1:01:48  lr: 0.000020  loss: 72.6111 (357.7953)  loss_n_40: 6.5017 (5.8413)  loss_n_60: 8.6755 (7.8010)  loss_n_80: 8.8152 (8.3136)  loss_n_100: 8.9482 (8.0467)  triple_100: 6.5857 (96.3607)  triple_80: 6.5181 (94.8284)  triple_60: 17.2172 (73.3559)  triple_40: 4.2963 (63.2477)  time: 3.9279  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [ 790/1724]  eta: 1:01:09  lr: 0.000020  loss: 58.1388 (354.1761)  loss_n_40: 6.4918 (5.8484)  loss_n_60: 8.5989 (7.8103)  loss_n_80: 8.7703 (8.3192)  loss_n_100: 8.9793 (8.0588)  triple_100: 5.1394 (95.2443)  triple_80: 4.0731 (93.7199)  triple_60: 14.7654 (72.6303)  triple_40: 3.5665 (62.5450)  time: 3.9283  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 800/1724]  eta: 1:00:30  lr: 0.000020  loss: 49.2660 (350.3301)  loss_n_40: 6.3453 (5.8556)  loss_n_60: 8.5348 (7.8199)  loss_n_80: 8.7859 (8.3265)  loss_n_100: 8.9700 (8.0706)  triple_100: 3.0481 (94.0895)  triple_80: 2.6783 (92.5748)  triple_60: 10.2043 (71.8090)  triple_40: 0.0000 (61.7842)  time: 3.9271  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 810/1724]  eta: 0:59:50  lr: 0.000020  loss: 34.9025 (346.6461)  loss_n_40: 6.4633 (5.8632)  loss_n_60: 8.6371 (7.8299)  loss_n_80: 8.8809 (8.3340)  loss_n_100: 9.0675 (8.0834)  triple_100: 1.0139 (92.9788)  triple_80: 0.0000 (91.4768)  triple_60: 1.3822 (71.0214)  triple_40: 0.0000 (61.0586)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 820/1724]  eta: 0:59:11  lr: 0.000020  loss: 35.1361 (343.0955)  loss_n_40: 6.4633 (5.8707)  loss_n_60: 8.5829 (7.8401)  loss_n_80: 8.8001 (8.3398)  loss_n_100: 8.9689 (8.0942)  triple_100: 1.2059 (91.9019)  triple_80: 0.0000 (90.4072)  triple_60: 1.3822 (70.2747)  triple_40: 0.0000 (60.3669)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 830/1724]  eta: 0:58:32  lr: 0.000020  loss: 41.2896 (339.6858)  loss_n_40: 6.4675 (5.8776)  loss_n_60: 8.6312 (7.8498)  loss_n_80: 8.7671 (8.3453)  loss_n_100: 8.9357 (8.1045)  triple_100: 1.9777 (90.8712)  triple_80: 0.0000 (89.3749)  triple_60: 6.7014 (69.5839)  triple_40: 0.0000 (59.6785)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 840/1724]  eta: 0:57:52  lr: 0.000020  loss: 45.7906 (336.3654)  loss_n_40: 6.5110 (5.8863)  loss_n_60: 8.7336 (7.8603)  loss_n_80: 8.8174 (8.3512)  loss_n_100: 8.8602 (8.1151)  triple_100: 2.0207 (89.8544)  triple_80: 0.0000 (88.3660)  triple_60: 10.3678 (68.9005)  triple_40: 0.0000 (59.0315)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 850/1724]  eta: 0:57:13  lr: 0.000020  loss: 45.9258 (333.0424)  loss_n_40: 6.5436 (5.8933)  loss_n_60: 8.7600 (7.8699)  loss_n_80: 8.8320 (8.3578)  loss_n_100: 9.0315 (8.1263)  triple_100: 2.0207 (88.8372)  triple_80: 3.5759 (87.3770)  triple_60: 10.3678 (68.2211)  triple_40: 0.0000 (58.3598)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 860/1724]  eta: 0:56:34  lr: 0.000020  loss: 53.3066 (329.9331)  loss_n_40: 6.4729 (5.9009)  loss_n_60: 8.7129 (7.8791)  loss_n_80: 8.8371 (8.3638)  loss_n_100: 9.0315 (8.1375)  triple_100: 3.0089 (87.8768)  triple_80: 3.2087 (86.4401)  triple_60: 8.1297 (67.5586)  triple_40: 0.7724 (57.7762)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 870/1724]  eta: 0:55:54  lr: 0.000020  loss: 43.8498 (326.6450)  loss_n_40: 6.4972 (5.9075)  loss_n_60: 8.6608 (7.8874)  loss_n_80: 8.8101 (8.3694)  loss_n_100: 9.0209 (8.1483)  triple_100: 3.0089 (86.8914)  triple_80: 1.0398 (85.4614)  triple_60: 7.0267 (66.8538)  triple_40: 0.0000 (57.1257)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 880/1724]  eta: 0:55:15  lr: 0.000020  loss: 37.4950 (323.5184)  loss_n_40: 6.4694 (5.9139)  loss_n_60: 8.6103 (7.8959)  loss_n_80: 8.8191 (8.3754)  loss_n_100: 9.0863 (8.1598)  triple_100: 1.1565 (85.9522)  triple_80: 0.0000 (84.5287)  triple_60: 4.0011 (66.1853)  triple_40: 0.0000 (56.5073)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 890/1724]  eta: 0:54:36  lr: 0.000020  loss: 38.6424 (320.3483)  loss_n_40: 6.4709 (5.9206)  loss_n_60: 8.6789 (7.9048)  loss_n_80: 8.8191 (8.3807)  loss_n_100: 9.0960 (8.1706)  triple_100: 1.0922 (85.0068)  triple_80: 0.0000 (83.5890)  triple_60: 3.9210 (65.4927)  triple_40: 0.0000 (55.8831)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 900/1724]  eta: 0:53:57  lr: 0.000020  loss: 34.7187 (317.1907)  loss_n_40: 6.5359 (5.9271)  loss_n_60: 8.6789 (7.9130)  loss_n_80: 8.7695 (8.3860)  loss_n_100: 9.0945 (8.1811)  triple_100: 0.0000 (84.0689)  triple_80: 0.0000 (82.6643)  triple_60: 0.6085 (64.7792)  triple_40: 0.0000 (55.2710)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 910/1724]  eta: 0:53:17  lr: 0.000020  loss: 33.8819 (314.1959)  loss_n_40: 6.5382 (5.9331)  loss_n_60: 8.6662 (7.9211)  loss_n_80: 8.8429 (8.3903)  loss_n_100: 9.0782 (8.1906)  triple_100: 0.0000 (83.1709)  triple_80: 0.0000 (81.7781)  triple_60: 0.0000 (64.1247)  triple_40: 0.0000 (54.6870)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 920/1724]  eta: 0:52:38  lr: 0.000020  loss: 36.0207 (311.2555)  loss_n_40: 6.5607 (5.9400)  loss_n_60: 8.6824 (7.9294)  loss_n_80: 8.8429 (8.3948)  loss_n_100: 9.0753 (8.2007)  triple_100: 0.6215 (82.2879)  triple_80: 0.0000 (80.8999)  triple_60: 1.8769 (63.4821)  triple_40: 0.0000 (54.1208)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 930/1724]  eta: 0:51:59  lr: 0.000020  loss: 35.1632 (308.4347)  loss_n_40: 6.5982 (5.9465)  loss_n_60: 8.7337 (7.9376)  loss_n_80: 8.8387 (8.3999)  loss_n_100: 9.1806 (8.2120)  triple_100: 0.0829 (81.4391)  triple_80: 0.0000 (80.0614)  triple_60: 0.6668 (62.8627)  triple_40: 0.0000 (53.5755)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 940/1724]  eta: 0:51:19  lr: 0.000020  loss: 34.9064 (305.5480)  loss_n_40: 6.5728 (5.9523)  loss_n_60: 8.7287 (7.9456)  loss_n_80: 8.8308 (8.4044)  loss_n_100: 9.1679 (8.2226)  triple_100: 0.0829 (80.5838)  triple_80: 0.0000 (79.2127)  triple_60: 0.6668 (62.2192)  triple_40: 0.0000 (53.0072)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 950/1724]  eta: 0:50:40  lr: 0.000020  loss: 34.9064 (302.7665)  loss_n_40: 6.5209 (5.9593)  loss_n_60: 8.6805 (7.9543)  loss_n_80: 8.7813 (8.4095)  loss_n_100: 9.1475 (8.2327)  triple_100: 0.0000 (79.7467)  triple_80: 0.0000 (78.3912)  triple_60: 0.0000 (61.6069)  triple_40: 0.0000 (52.4661)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 960/1724]  eta: 0:50:01  lr: 0.000020  loss: 35.9143 (300.0954)  loss_n_40: 6.5851 (5.9662)  loss_n_60: 8.7254 (7.9627)  loss_n_80: 8.8156 (8.4137)  loss_n_100: 9.1467 (8.2414)  triple_100: 0.0000 (78.9434)  triple_80: 0.0000 (77.5879)  triple_60: 0.9385 (61.0475)  triple_40: 0.0000 (51.9326)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 970/1724]  eta: 0:49:21  lr: 0.000020  loss: 36.4160 (297.4446)  loss_n_40: 6.5450 (5.9716)  loss_n_60: 8.7207 (7.9696)  loss_n_80: 8.8156 (8.4170)  loss_n_100: 9.0085 (8.2494)  triple_100: 0.3287 (78.1501)  triple_80: 0.0000 (76.8018)  triple_60: 2.8062 (60.4709)  triple_40: 0.0000 (51.4141)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 980/1724]  eta: 0:48:42  lr: 0.000020  loss: 36.4160 (294.8694)  loss_n_40: 6.5591 (5.9777)  loss_n_60: 8.6788 (7.9768)  loss_n_80: 8.8166 (8.4215)  loss_n_100: 9.1676 (8.2583)  triple_100: 0.0000 (77.3799)  triple_80: 0.0000 (76.0453)  triple_60: 2.8600 (59.9094)  triple_40: 0.0000 (50.9006)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [ 990/1724]  eta: 0:48:03  lr: 0.000020  loss: 40.7207 (292.3647)  loss_n_40: 6.6306 (5.9835)  loss_n_60: 8.6788 (7.9838)  loss_n_80: 8.8166 (8.4242)  loss_n_100: 9.0378 (8.2653)  triple_100: 0.7004 (76.6229)  triple_80: 0.7478 (75.2964)  triple_60: 5.7388 (59.3834)  triple_40: 0.0000 (50.4054)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1000/1724]  eta: 0:47:24  lr: 0.000020  loss: 37.1663 (289.8297)  loss_n_40: 6.6410 (5.9891)  loss_n_60: 8.6622 (7.9907)  loss_n_80: 8.6475 (8.4283)  loss_n_100: 8.9474 (8.2730)  triple_100: 0.0316 (75.8645)  triple_80: 0.0000 (74.5534)  triple_60: 4.0674 (58.8260)  triple_40: 0.0000 (49.9048)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1010/1724]  eta: 0:46:44  lr: 0.000020  loss: 34.6600 (287.3869)  loss_n_40: 6.5189 (5.9949)  loss_n_60: 8.7103 (7.9977)  loss_n_80: 8.7944 (8.4313)  loss_n_100: 9.0721 (8.2813)  triple_100: 0.1391 (75.1333)  triple_80: 0.0000 (73.8246)  triple_60: 1.3241 (58.2972)  triple_40: 0.0000 (49.4267)  time: 3.9270  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [1020/1724]  eta: 0:46:05  lr: 0.000020  loss: 35.5327 (284.9859)  loss_n_40: 6.5189 (6.0006)  loss_n_60: 8.7103 (8.0044)  loss_n_80: 8.7989 (8.4350)  loss_n_100: 9.1307 (8.2901)  triple_100: 0.4295 (74.4140)  triple_80: 0.0000 (73.1160)  triple_60: 1.3241 (57.7658)  triple_40: 0.0000 (48.9601)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1030/1724]  eta: 0:45:26  lr: 0.000020  loss: 35.1450 (282.5903)  loss_n_40: 6.6197 (6.0070)  loss_n_60: 8.7371 (8.0116)  loss_n_80: 8.8569 (8.4396)  loss_n_100: 9.1806 (8.2991)  triple_100: 0.0000 (73.6990)  triple_80: 0.0000 (72.4129)  triple_60: 1.1620 (57.2359)  triple_40: 0.0000 (48.4852)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1040/1724]  eta: 0:44:46  lr: 0.000020  loss: 37.6337 (280.3733)  loss_n_40: 6.6197 (6.0129)  loss_n_60: 8.7481 (8.0187)  loss_n_80: 8.8569 (8.4433)  loss_n_100: 9.1703 (8.3070)  triple_100: 1.2275 (73.0229)  triple_80: 0.0000 (71.7497)  triple_60: 1.5026 (56.7662)  triple_40: 0.0000 (48.0526)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1050/1724]  eta: 0:44:07  lr: 0.000020  loss: 37.6337 (278.1414)  loss_n_40: 6.5933 (6.0184)  loss_n_60: 8.7481 (8.0254)  loss_n_80: 8.8086 (8.4471)  loss_n_100: 9.0774 (8.3147)  triple_100: 0.9161 (72.3488)  triple_80: 0.0000 (71.0880)  triple_60: 2.1890 (56.2737)  triple_40: 0.0000 (47.6253)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1060/1724]  eta: 0:43:28  lr: 0.000020  loss: 35.9748 (275.9821)  loss_n_40: 6.6401 (6.0247)  loss_n_60: 8.7478 (8.0323)  loss_n_80: 8.8242 (8.4510)  loss_n_100: 9.1609 (8.3226)  triple_100: 0.1467 (71.6815)  triple_80: 0.0000 (70.4444)  triple_60: 2.1890 (55.8101)  triple_40: 0.0000 (47.2154)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1070/1724]  eta: 0:42:49  lr: 0.000020  loss: 41.7797 (273.7987)  loss_n_40: 6.6187 (6.0292)  loss_n_60: 8.6843 (8.0380)  loss_n_80: 8.8019 (8.4536)  loss_n_100: 9.1622 (8.3304)  triple_100: 0.2801 (71.0276)  triple_80: 0.9458 (69.8017)  triple_60: 5.7142 (55.3347)  triple_40: 0.0000 (46.7836)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1080/1724]  eta: 0:42:09  lr: 0.000020  loss: 40.1694 (271.6562)  loss_n_40: 6.5399 (6.0345)  loss_n_60: 8.7143 (8.0447)  loss_n_80: 8.6836 (8.4565)  loss_n_100: 9.1565 (8.3378)  triple_100: 0.4682 (70.3884)  triple_80: 0.6434 (69.1663)  triple_60: 5.1870 (54.8721)  triple_40: 0.0000 (46.3559)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1090/1724]  eta: 0:41:30  lr: 0.000020  loss: 38.0170 (269.5338)  loss_n_40: 6.6126 (6.0398)  loss_n_60: 8.7143 (8.0507)  loss_n_80: 8.8253 (8.4602)  loss_n_100: 9.1872 (8.3458)  triple_100: 0.0907 (69.7530)  triple_80: 0.0000 (68.5405)  triple_60: 3.0860 (54.4017)  triple_40: 0.0000 (45.9421)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1100/1724]  eta: 0:40:51  lr: 0.000020  loss: 34.0781 (267.4035)  loss_n_40: 6.5591 (6.0438)  loss_n_60: 8.6805 (8.0560)  loss_n_80: 8.8318 (8.4632)  loss_n_100: 9.1040 (8.3524)  triple_100: 0.0000 (69.1222)  triple_80: 0.0000 (67.9189)  triple_60: 0.3888 (53.9223)  triple_40: 0.0000 (45.5248)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1110/1724]  eta: 0:40:11  lr: 0.000020  loss: 34.7783 (265.6327)  loss_n_40: 6.5327 (6.0493)  loss_n_60: 8.7011 (8.0627)  loss_n_80: 8.7561 (8.4659)  loss_n_100: 9.0572 (8.3590)  triple_100: 0.0841 (68.5660)  triple_80: 0.0000 (67.3868)  triple_60: 1.8610 (53.5539)  triple_40: 0.0000 (45.1890)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1120/1724]  eta: 0:39:32  lr: 0.000020  loss: 37.2006 (263.6624)  loss_n_40: 6.6370 (6.0549)  loss_n_60: 8.7561 (8.0689)  loss_n_80: 8.7810 (8.4697)  loss_n_100: 9.0618 (8.3665)  triple_100: 0.8222 (67.9732)  triple_80: 0.0000 (66.8038)  triple_60: 2.2829 (53.1184)  triple_40: 0.0000 (44.8069)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1130/1724]  eta: 0:38:53  lr: 0.000020  loss: 36.1445 (261.7164)  loss_n_40: 6.5090 (6.0588)  loss_n_60: 8.6605 (8.0736)  loss_n_80: 8.8208 (8.4722)  loss_n_100: 9.1034 (8.3727)  triple_100: 0.0000 (67.3886)  triple_80: 0.0000 (66.2313)  triple_60: 0.8442 (52.6899)  triple_40: 0.0000 (44.4292)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1140/1724]  eta: 0:38:13  lr: 0.000020  loss: 33.4721 (259.8352)  loss_n_40: 6.4922 (6.0632)  loss_n_60: 8.5939 (8.0787)  loss_n_80: 8.7103 (8.4742)  loss_n_100: 9.1020 (8.3785)  triple_100: 0.0000 (66.8239)  triple_80: 0.0000 (65.6794)  triple_60: 0.0000 (52.2780)  triple_40: 0.0000 (44.0594)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1150/1724]  eta: 0:37:34  lr: 0.000020  loss: 33.8682 (257.9217)  loss_n_40: 6.5712 (6.0680)  loss_n_60: 8.6433 (8.0843)  loss_n_80: 8.8055 (8.4781)  loss_n_100: 9.1714 (8.3858)  triple_100: 0.0000 (66.2501)  triple_80: 0.0000 (65.1166)  triple_60: 0.3932 (51.8563)  triple_40: 0.0000 (43.6826)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1160/1724]  eta: 0:36:55  lr: 0.000020  loss: 35.5642 (256.1107)  loss_n_40: 6.5971 (6.0724)  loss_n_60: 8.6639 (8.0891)  loss_n_80: 8.8055 (8.4804)  loss_n_100: 9.1348 (8.3920)  triple_100: 0.0141 (65.7044)  triple_80: 0.0000 (64.5803)  triple_60: 0.4372 (51.4566)  triple_40: 0.0000 (43.3355)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1170/1724]  eta: 0:36:16  lr: 0.000020  loss: 36.4027 (254.2560)  loss_n_40: 6.6235 (6.0766)  loss_n_60: 8.5960 (8.0941)  loss_n_80: 8.6729 (8.4826)  loss_n_100: 9.0209 (8.3979)  triple_100: 0.7383 (65.1506)  triple_80: 0.0000 (64.0350)  triple_60: 2.0096 (51.0464)  triple_40: 0.0000 (42.9728)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1180/1724]  eta: 0:35:36  lr: 0.000020  loss: 34.4169 (252.4940)  loss_n_40: 6.7795 (6.0813)  loss_n_60: 8.6487 (8.0993)  loss_n_80: 8.7257 (8.4854)  loss_n_100: 9.1182 (8.4049)  triple_100: 0.0000 (64.6203)  triple_80: 0.0000 (63.5155)  triple_60: 0.0000 (50.6473)  triple_40: 0.0000 (42.6400)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1190/1724]  eta: 0:34:57  lr: 0.000020  loss: 34.0588 (250.6766)  loss_n_40: 6.7434 (6.0860)  loss_n_60: 8.7518 (8.1046)  loss_n_80: 8.7212 (8.4875)  loss_n_100: 9.1340 (8.4114)  triple_100: 0.0000 (64.0840)  triple_80: 0.0000 (62.9854)  triple_60: 0.0000 (50.2303)  triple_40: 0.0000 (42.2873)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1200/1724]  eta: 0:34:18  lr: 0.000020  loss: 34.4535 (248.9682)  loss_n_40: 6.6875 (6.0912)  loss_n_60: 8.7964 (8.1105)  loss_n_80: 8.7275 (8.4906)  loss_n_100: 9.1615 (8.4184)  triple_100: 0.0000 (63.5690)  triple_80: 0.0000 (62.4832)  triple_60: 0.0075 (49.8554)  triple_40: 0.0000 (41.9499)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1210/1724]  eta: 0:33:38  lr: 0.000020  loss: 37.1104 (247.3123)  loss_n_40: 6.5570 (6.0950)  loss_n_60: 8.7154 (8.1148)  loss_n_80: 8.7520 (8.4924)  loss_n_100: 9.1615 (8.4238)  triple_100: 0.0000 (63.0673)  triple_80: 0.5157 (62.0002)  triple_60: 3.2694 (49.4864)  triple_40: 0.0000 (41.6325)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1220/1724]  eta: 0:32:59  lr: 0.000020  loss: 35.7411 (245.6987)  loss_n_40: 6.5277 (6.0988)  loss_n_60: 8.5681 (8.1190)  loss_n_80: 8.6773 (8.4939)  loss_n_100: 8.9813 (8.4288)  triple_100: 0.0705 (62.5737)  triple_80: 0.0000 (61.5192)  triple_60: 3.2694 (49.1481)  triple_40: 0.0000 (41.3172)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1230/1724]  eta: 0:32:20  lr: 0.000020  loss: 35.1818 (244.0053)  loss_n_40: 6.5629 (6.1034)  loss_n_60: 8.6165 (8.1241)  loss_n_80: 8.6888 (8.4970)  loss_n_100: 9.1229 (8.4359)  triple_100: 0.0000 (62.0710)  triple_80: 0.0000 (61.0245)  triple_60: 0.8552 (48.7612)  triple_40: 0.0000 (40.9882)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1240/1724]  eta: 0:31:41  lr: 0.000020  loss: 34.1289 (242.3696)  loss_n_40: 6.5629 (6.1073)  loss_n_60: 8.6554 (8.1284)  loss_n_80: 8.6643 (8.4980)  loss_n_100: 9.0455 (8.4404)  triple_100: 0.0000 (61.5827)  triple_80: 0.0000 (60.5442)  triple_60: 0.0000 (48.4001)  triple_40: 0.0000 (40.6684)  time: 3.9272  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [1250/1724]  eta: 0:31:01  lr: 0.000020  loss: 34.1289 (240.7547)  loss_n_40: 6.6738 (6.1123)  loss_n_60: 8.6554 (8.1333)  loss_n_80: 8.6260 (8.4998)  loss_n_100: 8.9876 (8.4457)  triple_100: 0.0504 (61.0994)  triple_80: 0.0000 (60.0699)  triple_60: 0.0000 (48.0364)  triple_40: 0.0000 (40.3578)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1260/1724]  eta: 0:30:22  lr: 0.000020  loss: 35.3603 (239.2196)  loss_n_40: 6.7016 (6.1174)  loss_n_60: 8.7201 (8.1381)  loss_n_80: 8.6724 (8.5016)  loss_n_100: 9.1088 (8.4514)  triple_100: 0.4758 (60.6333)  triple_80: 0.0000 (59.6107)  triple_60: 2.4249 (47.7114)  triple_40: 0.0000 (40.0557)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1270/1724]  eta: 0:29:43  lr: 0.000020  loss: 39.3939 (237.6632)  loss_n_40: 6.6803 (6.1214)  loss_n_60: 8.6319 (8.1421)  loss_n_80: 8.7864 (8.5038)  loss_n_100: 9.1529 (8.4575)  triple_100: 1.0044 (60.1681)  triple_80: 0.4467 (59.1546)  triple_60: 2.1166 (47.3636)  triple_40: 0.0000 (39.7520)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1280/1724]  eta: 0:29:03  lr: 0.000020  loss: 34.3718 (236.1025)  loss_n_40: 6.4915 (6.1247)  loss_n_60: 8.5765 (8.1457)  loss_n_80: 8.6931 (8.5053)  loss_n_100: 9.1730 (8.4632)  triple_100: 0.2853 (59.7041)  triple_80: 0.0000 (58.6998)  triple_60: 0.9610 (47.0113)  triple_40: 0.0000 (39.4485)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1290/1724]  eta: 0:28:24  lr: 0.000020  loss: 36.4760 (234.6284)  loss_n_40: 6.4635 (6.1277)  loss_n_60: 8.5143 (8.1486)  loss_n_80: 8.6402 (8.5059)  loss_n_100: 9.0710 (8.4680)  triple_100: 0.2853 (59.2586)  triple_80: 0.0000 (58.2597)  triple_60: 2.2361 (46.6899)  triple_40: 0.0000 (39.1699)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1300/1724]  eta: 0:27:45  lr: 0.000020  loss: 36.8332 (233.1356)  loss_n_40: 6.5091 (6.1306)  loss_n_60: 8.5545 (8.1515)  loss_n_80: 8.5899 (8.5067)  loss_n_100: 9.0475 (8.4727)  triple_100: 1.2441 (58.8136)  triple_80: 0.0000 (57.8213)  triple_60: 2.2361 (46.3629)  triple_40: 0.0000 (38.8764)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1310/1724]  eta: 0:27:06  lr: 0.000020  loss: 34.3345 (231.6589)  loss_n_40: 6.6401 (6.1349)  loss_n_60: 8.6317 (8.1557)  loss_n_80: 8.6701 (8.5086)  loss_n_100: 9.1288 (8.4784)  triple_100: 0.0000 (58.3717)  triple_80: 0.0000 (57.3866)  triple_60: 0.8123 (46.0325)  triple_40: 0.0000 (38.5905)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1320/1724]  eta: 0:26:26  lr: 0.000020  loss: 35.7840 (230.2126)  loss_n_40: 6.6401 (6.1387)  loss_n_60: 8.6740 (8.1595)  loss_n_80: 8.7271 (8.5101)  loss_n_100: 9.1801 (8.4843)  triple_100: 0.0000 (57.9380)  triple_80: 0.0000 (56.9615)  triple_60: 2.7414 (45.7102)  triple_40: 0.0000 (38.3103)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1330/1724]  eta: 0:25:47  lr: 0.000020  loss: 34.7676 (228.7484)  loss_n_40: 6.6138 (6.1423)  loss_n_60: 8.6659 (8.1633)  loss_n_80: 8.8133 (8.5120)  loss_n_100: 9.2736 (8.4901)  triple_100: 0.0000 (57.5080)  triple_80: 0.0000 (56.5342)  triple_60: 0.3620 (45.3761)  triple_40: 0.0000 (38.0225)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1340/1724]  eta: 0:25:08  lr: 0.000020  loss: 34.4340 (227.3102)  loss_n_40: 6.5923 (6.1448)  loss_n_60: 8.5718 (8.1660)  loss_n_80: 8.6732 (8.5133)  loss_n_100: 9.1536 (8.4954)  triple_100: 0.0000 (57.0818)  triple_80: 0.0000 (56.1150)  triple_60: 0.1756 (45.0510)  triple_40: 0.0000 (37.7430)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1350/1724]  eta: 0:24:29  lr: 0.000020  loss: 34.4770 (225.8998)  loss_n_40: 6.5572 (6.1481)  loss_n_60: 8.5689 (8.1694)  loss_n_80: 8.6595 (8.5148)  loss_n_100: 9.1444 (8.5010)  triple_100: 0.0000 (56.6645)  triple_80: 0.0000 (55.7021)  triple_60: 0.6502 (44.7329)  triple_40: 0.0000 (37.4671)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1360/1724]  eta: 0:23:49  lr: 0.000020  loss: 36.7444 (224.5936)  loss_n_40: 6.6076 (6.1518)  loss_n_60: 8.6180 (8.1732)  loss_n_80: 8.7079 (8.5156)  loss_n_100: 9.1962 (8.5052)  triple_100: 0.4485 (56.2695)  triple_80: 0.0000 (55.3119)  triple_60: 1.6417 (44.4514)  triple_40: 0.0000 (37.2149)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1370/1724]  eta: 0:23:10  lr: 0.000020  loss: 36.1596 (223.2150)  loss_n_40: 6.6076 (6.1547)  loss_n_60: 8.6327 (8.1763)  loss_n_80: 8.7023 (8.5167)  loss_n_100: 9.0528 (8.5099)  triple_100: 0.1489 (55.8615)  triple_80: 0.0000 (54.9119)  triple_60: 1.7969 (44.1404)  triple_40: 0.0000 (36.9436)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1380/1724]  eta: 0:22:31  lr: 0.000020  loss: 34.9992 (221.9306)  loss_n_40: 6.4933 (6.1575)  loss_n_60: 8.5506 (8.1791)  loss_n_80: 8.6460 (8.5173)  loss_n_100: 9.0220 (8.5137)  triple_100: 0.0000 (55.4706)  triple_80: 0.0000 (54.5366)  triple_60: 1.7969 (43.8642)  triple_40: 0.0000 (36.6915)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1390/1724]  eta: 0:21:51  lr: 0.000020  loss: 33.1416 (220.5757)  loss_n_40: 6.4228 (6.1597)  loss_n_60: 8.4930 (8.1815)  loss_n_80: 8.5955 (8.5183)  loss_n_100: 9.0220 (8.5180)  triple_100: 0.0000 (55.0723)  triple_80: 0.0000 (54.1446)  triple_60: 0.0000 (43.5536)  triple_40: 0.0000 (36.4278)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1400/1724]  eta: 0:21:12  lr: 0.000020  loss: 32.7536 (219.2516)  loss_n_40: 6.4365 (6.1621)  loss_n_60: 8.4930 (8.1843)  loss_n_80: 8.6129 (8.5195)  loss_n_100: 9.1551 (8.5228)  triple_100: 0.0000 (54.6818)  triple_80: 0.0000 (53.7606)  triple_60: 0.0000 (43.2496)  triple_40: 0.0000 (36.1709)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1410/1724]  eta: 0:20:33  lr: 0.000020  loss: 33.6699 (217.9920)  loss_n_40: 6.5751 (6.1654)  loss_n_60: 8.5428 (8.1873)  loss_n_80: 8.6622 (8.5206)  loss_n_100: 9.1796 (8.5272)  triple_100: 0.0000 (54.3052)  triple_80: 0.0000 (53.3900)  triple_60: 0.2736 (42.9739)  triple_40: 0.0000 (35.9225)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1420/1724]  eta: 0:19:54  lr: 0.000020  loss: 34.3894 (216.7265)  loss_n_40: 6.5924 (6.1682)  loss_n_60: 8.5821 (8.1898)  loss_n_80: 8.6622 (8.5215)  loss_n_100: 9.0649 (8.5313)  triple_100: 0.0719 (53.9286)  triple_80: 0.0000 (53.0209)  triple_60: 0.5547 (42.6860)  triple_40: 0.0000 (35.6801)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1430/1724]  eta: 0:19:14  lr: 0.000020  loss: 34.0331 (215.4834)  loss_n_40: 6.4805 (6.1710)  loss_n_60: 8.5375 (8.1926)  loss_n_80: 8.6184 (8.5226)  loss_n_100: 9.0649 (8.5358)  triple_100: 0.0021 (53.5565)  triple_80: 0.0000 (52.6551)  triple_60: 0.4282 (42.4124)  triple_40: 0.0000 (35.4374)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1440/1724]  eta: 0:18:35  lr: 0.000020  loss: 35.2428 (214.2716)  loss_n_40: 6.6755 (6.1745)  loss_n_60: 8.6103 (8.1958)  loss_n_80: 8.6184 (8.5234)  loss_n_100: 9.1534 (8.5406)  triple_100: 0.0021 (53.1912)  triple_80: 0.0000 (52.2973)  triple_60: 1.6239 (42.1428)  triple_40: 0.0000 (35.2059)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1450/1724]  eta: 0:17:56  lr: 0.000020  loss: 34.4729 (213.0507)  loss_n_40: 6.6755 (6.1771)  loss_n_60: 8.6400 (8.1986)  loss_n_80: 8.5997 (8.5244)  loss_n_100: 9.1766 (8.5454)  triple_100: 0.0000 (52.8325)  triple_80: 0.0000 (51.9390)  triple_60: 1.1686 (41.8700)  triple_40: 0.0000 (34.9637)  time: 3.9256  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:2]  [1460/1724]  eta: 0:17:16  lr: 0.000020  loss: 33.9324 (211.8538)  loss_n_40: 6.6235 (6.1803)  loss_n_60: 8.6400 (8.2017)  loss_n_80: 8.6086 (8.5252)  loss_n_100: 9.2091 (8.5502)  triple_100: 0.0000 (52.4778)  triple_80: 0.0000 (51.5907)  triple_60: 0.0000 (41.6000)  triple_40: 0.0000 (34.7276)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1470/1724]  eta: 0:16:37  lr: 0.000020  loss: 33.6240 (210.6889)  loss_n_40: 6.6235 (6.1834)  loss_n_60: 8.6193 (8.2048)  loss_n_80: 8.5739 (8.5256)  loss_n_100: 9.1542 (8.5539)  triple_100: 0.0000 (52.1294)  triple_80: 0.0000 (51.2499)  triple_60: 0.0000 (41.3371)  triple_40: 0.0000 (34.5048)  time: 3.9277  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [1480/1724]  eta: 0:15:58  lr: 0.000020  loss: 33.8584 (209.5712)  loss_n_40: 6.5768 (6.1861)  loss_n_60: 8.6037 (8.2073)  loss_n_80: 8.5618 (8.5263)  loss_n_100: 9.0278 (8.5577)  triple_100: 0.0000 (51.7919)  triple_80: 0.0000 (50.9260)  triple_60: 0.0958 (41.0919)  triple_40: 0.0000 (34.2841)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1490/1724]  eta: 0:15:19  lr: 0.000020  loss: 34.2768 (208.3941)  loss_n_40: 6.5473 (6.1892)  loss_n_60: 8.6037 (8.2105)  loss_n_80: 8.5883 (8.5273)  loss_n_100: 9.1118 (8.5621)  triple_100: 0.0000 (51.4464)  triple_80: 0.0000 (50.5844)  triple_60: 0.0000 (40.8200)  triple_40: 0.0000 (34.0542)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1500/1724]  eta: 0:14:39  lr: 0.000020  loss: 34.2572 (207.2481)  loss_n_40: 6.6322 (6.1919)  loss_n_60: 8.6483 (8.2133)  loss_n_80: 8.7326 (8.5292)  loss_n_100: 9.2553 (8.5668)  triple_100: 0.0000 (51.1054)  triple_80: 0.0000 (50.2501)  triple_60: 0.0000 (40.5614)  triple_40: 0.0000 (33.8300)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1510/1724]  eta: 0:14:00  lr: 0.000020  loss: 33.8953 (206.1053)  loss_n_40: 6.5559 (6.1938)  loss_n_60: 8.5639 (8.2153)  loss_n_80: 8.7326 (8.5302)  loss_n_100: 9.2658 (8.5710)  triple_100: 0.0000 (50.7688)  triple_80: 0.0000 (49.9195)  triple_60: 0.0000 (40.2978)  triple_40: 0.0000 (33.6089)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1520/1724]  eta: 0:13:21  lr: 0.000020  loss: 33.4721 (205.0258)  loss_n_40: 6.5891 (6.1966)  loss_n_60: 8.5667 (8.2180)  loss_n_80: 8.6236 (8.5308)  loss_n_100: 9.1681 (8.5748)  triple_100: 0.0000 (50.4425)  triple_80: 0.0000 (49.6013)  triple_60: 0.0000 (40.0543)  triple_40: 0.0000 (33.4074)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1530/1724]  eta: 0:12:41  lr: 0.000020  loss: 33.5531 (203.9139)  loss_n_40: 6.6157 (6.1993)  loss_n_60: 8.6108 (8.2206)  loss_n_80: 8.5629 (8.5317)  loss_n_100: 9.1539 (8.5791)  triple_100: 0.0000 (50.1156)  triple_80: 0.0000 (49.2785)  triple_60: 0.0000 (39.7990)  triple_40: 0.0000 (33.1902)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1540/1724]  eta: 0:12:02  lr: 0.000020  loss: 33.8324 (202.8502)  loss_n_40: 6.6239 (6.2018)  loss_n_60: 8.6066 (8.2229)  loss_n_80: 8.5629 (8.5317)  loss_n_100: 9.1539 (8.5830)  triple_100: 0.0000 (49.7982)  triple_80: 0.0000 (48.9671)  triple_60: 0.0000 (39.5612)  triple_40: 0.0000 (32.9843)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1550/1724]  eta: 0:11:23  lr: 0.000020  loss: 33.2545 (201.7664)  loss_n_40: 6.5540 (6.2035)  loss_n_60: 8.5497 (8.2246)  loss_n_80: 8.4897 (8.5320)  loss_n_100: 9.1576 (8.5870)  triple_100: 0.0000 (49.4798)  triple_80: 0.0000 (48.6548)  triple_60: 0.0000 (39.3111)  triple_40: 0.0000 (32.7738)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1560/1724]  eta: 0:10:44  lr: 0.000020  loss: 33.7454 (200.7022)  loss_n_40: 6.5540 (6.2064)  loss_n_60: 8.5578 (8.2275)  loss_n_80: 8.6238 (8.5334)  loss_n_100: 9.2383 (8.5915)  triple_100: 0.0000 (49.1668)  triple_80: 0.0000 (48.3454)  triple_60: 0.0000 (39.0674)  triple_40: 0.0000 (32.5638)  time: 3.9260  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:2]  [1570/1724]  eta: 0:10:04  lr: 0.000020  loss: 34.1397 (199.6562)  loss_n_40: 6.5990 (6.2088)  loss_n_60: 8.5846 (8.2298)  loss_n_80: 8.7111 (8.5347)  loss_n_100: 9.3031 (8.5957)  triple_100: 0.0000 (48.8571)  triple_80: 0.0000 (48.0405)  triple_60: 0.0151 (38.8302)  triple_40: 0.0000 (32.3594)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1580/1724]  eta: 0:09:25  lr: 0.000020  loss: 33.8449 (198.6388)  loss_n_40: 6.6059 (6.2118)  loss_n_60: 8.5338 (8.2322)  loss_n_80: 8.6198 (8.5352)  loss_n_100: 9.2207 (8.5992)  triple_100: 0.0000 (48.5510)  triple_80: 0.0000 (47.7423)  triple_60: 0.1246 (38.6025)  triple_40: 0.0000 (32.1647)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1590/1724]  eta: 0:08:46  lr: 0.000020  loss: 33.3084 (197.6239)  loss_n_40: 6.5631 (6.2138)  loss_n_60: 8.5588 (8.2342)  loss_n_80: 8.4858 (8.5347)  loss_n_100: 9.0546 (8.6026)  triple_100: 0.0000 (48.2494)  triple_80: 0.0000 (47.4476)  triple_60: 0.0000 (38.3713)  triple_40: 0.0000 (31.9703)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1600/1724]  eta: 0:08:07  lr: 0.000020  loss: 33.6983 (196.6086)  loss_n_40: 6.5702 (6.2167)  loss_n_60: 8.5620 (8.2368)  loss_n_80: 8.5705 (8.5352)  loss_n_100: 9.1606 (8.6064)  triple_100: 0.0000 (47.9510)  triple_80: 0.0000 (47.1518)  triple_60: 0.0000 (38.1388)  triple_40: 0.0000 (31.7719)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1610/1724]  eta: 0:07:27  lr: 0.000020  loss: 34.2222 (195.6183)  loss_n_40: 6.6978 (6.2192)  loss_n_60: 8.6640 (8.2391)  loss_n_80: 8.6394 (8.5363)  loss_n_100: 9.1796 (8.6101)  triple_100: 0.0000 (47.6565)  triple_80: 0.0000 (46.8648)  triple_60: 0.0000 (37.9137)  triple_40: 0.0000 (31.5785)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1620/1724]  eta: 0:06:48  lr: 0.000020  loss: 33.9302 (194.6275)  loss_n_40: 6.5031 (6.2209)  loss_n_60: 8.5132 (8.2407)  loss_n_80: 8.5679 (8.5368)  loss_n_100: 9.1117 (8.6132)  triple_100: 0.0000 (47.3637)  triple_80: 0.0000 (46.5785)  triple_60: 0.0000 (37.6891)  triple_40: 0.0000 (31.3848)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1630/1724]  eta: 0:06:09  lr: 0.000020  loss: 33.0608 (193.6378)  loss_n_40: 6.5283 (6.2234)  loss_n_60: 8.5157 (8.2429)  loss_n_80: 8.5039 (8.5373)  loss_n_100: 9.0787 (8.6164)  triple_100: 0.0000 (47.0736)  triple_80: 0.0000 (46.2929)  triple_60: 0.0000 (37.4589)  triple_40: 0.0000 (31.1923)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1640/1724]  eta: 0:05:29  lr: 0.000020  loss: 33.8005 (192.7727)  loss_n_40: 6.6896 (6.2265)  loss_n_60: 8.6073 (8.2452)  loss_n_80: 8.5374 (8.5370)  loss_n_100: 9.0110 (8.6190)  triple_100: 0.0000 (46.8062)  triple_80: 0.0000 (46.0351)  triple_60: 0.0000 (37.2646)  triple_40: 0.0000 (31.0391)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1650/1724]  eta: 0:04:50  lr: 0.000020  loss: 33.9067 (191.8346)  loss_n_40: 6.6466 (6.2286)  loss_n_60: 8.5688 (8.2471)  loss_n_80: 8.5424 (8.5371)  loss_n_100: 9.0322 (8.6218)  triple_100: 0.1820 (46.5299)  triple_80: 0.0000 (45.7632)  triple_60: 0.4708 (37.0503)  triple_40: 0.0000 (30.8565)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1660/1724]  eta: 0:04:11  lr: 0.000020  loss: 33.1146 (190.8989)  loss_n_40: 6.5423 (6.2305)  loss_n_60: 8.5359 (8.2486)  loss_n_80: 8.5439 (8.5371)  loss_n_100: 9.0750 (8.6246)  triple_100: 0.0000 (46.2523)  triple_80: 0.0000 (45.4906)  triple_60: 0.0000 (36.8364)  triple_40: 0.0000 (30.6787)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1670/1724]  eta: 0:03:32  lr: 0.000020  loss: 33.1253 (189.9844)  loss_n_40: 6.5914 (6.2334)  loss_n_60: 8.5627 (8.2510)  loss_n_80: 8.4795 (8.5369)  loss_n_100: 9.0912 (8.6277)  triple_100: 0.0000 (45.9812)  triple_80: 0.0000 (45.2238)  triple_60: 0.0000 (36.6303)  triple_40: 0.0000 (30.5001)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1680/1724]  eta: 0:02:52  lr: 0.000020  loss: 33.4403 (189.0711)  loss_n_40: 6.6845 (6.2360)  loss_n_60: 8.6323 (8.2534)  loss_n_80: 8.4795 (8.5364)  loss_n_100: 9.1072 (8.6306)  triple_100: 0.0000 (45.7117)  triple_80: 0.0000 (44.9568)  triple_60: 0.0000 (36.4215)  triple_40: 0.0000 (30.3249)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1690/1724]  eta: 0:02:13  lr: 0.000020  loss: 33.9138 (188.1969)  loss_n_40: 6.6845 (6.2388)  loss_n_60: 8.6312 (8.2558)  loss_n_80: 8.3701 (8.5350)  loss_n_100: 9.0305 (8.6328)  triple_100: 0.5778 (45.4488)  triple_80: 0.0000 (44.6961)  triple_60: 0.3824 (36.2278)  triple_40: 0.0000 (30.1617)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1700/1724]  eta: 0:01:34  lr: 0.000020  loss: 34.1058 (187.3203)  loss_n_40: 6.6236 (6.2409)  loss_n_60: 8.6203 (8.2577)  loss_n_80: 8.3701 (8.5352)  loss_n_100: 9.0549 (8.6358)  triple_100: 0.4450 (45.1859)  triple_80: 0.0000 (44.4412)  triple_60: 0.3824 (36.0313)  triple_40: 0.0000 (29.9923)  time: 3.9257  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [1710/1724]  eta: 0:00:54  lr: 0.000020  loss: 33.1679 (186.4199)  loss_n_40: 6.5673 (6.2431)  loss_n_60: 8.5487 (8.2596)  loss_n_80: 8.4778 (8.5353)  loss_n_100: 9.0549 (8.6384)  triple_100: 0.0000 (44.9226)  triple_80: 0.0000 (44.1817)  triple_60: 0.0000 (35.8223)  triple_40: 0.0000 (29.8170)  time: 3.9252  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:2]  [1720/1724]  eta: 0:00:15  lr: 0.000020  loss: 33.2564 (185.5463)  loss_n_40: 6.4836 (6.2449)  loss_n_60: 8.5129 (8.2611)  loss_n_80: 8.4451 (8.5346)  loss_n_100: 8.9761 (8.6403)  triple_100: 0.0000 (44.6645)  triple_80: 0.0000 (43.9288)  triple_60: 0.0000 (35.6243)  triple_40: 0.0000 (29.6478)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2]  [1723/1724]  eta: 0:00:03  lr: 0.000020  loss: 33.6099 (185.2846)  loss_n_40: 6.5486 (6.2459)  loss_n_60: 8.4906 (8.2619)  loss_n_80: 8.5702 (8.5351)  loss_n_100: 9.0359 (8.6415)  triple_100: 0.0000 (44.5874)  triple_80: 0.0000 (43.8523)  triple_60: 0.0000 (35.5642)  triple_40: 0.0000 (29.5962)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:2] Total time: 1:52:51 (3.9276 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 33.6099 (185.2846)  loss_n_40: 6.5486 (6.2459)  loss_n_60: 8.4906 (8.2619)  loss_n_80: 8.5702 (8.5351)  loss_n_100: 9.0359 (8.6415)  triple_100: 0.0000 (44.5874)  triple_80: 0.0000 (43.8523)  triple_60: 0.0000 (35.5642)  triple_40: 0.0000 (29.5962)\n",
      "Valid: [epoch:2]  [  0/845]  eta: 0:09:39  loss: 31.3411 (31.3411)  loss_n_40: 5.7141 (5.7141)  loss_n_60: 8.1778 (8.1778)  loss_n_80: 8.4917 (8.4917)  loss_n_100: 8.9576 (8.9576)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.6853  data: 0.3500  max mem: 46473\n",
      "Valid: [epoch:2]  [ 10/845]  eta: 0:05:05  loss: 32.5788 (33.1551)  loss_n_40: 6.4178 (6.4280)  loss_n_60: 8.4661 (8.4608)  loss_n_80: 8.4917 (8.4365)  loss_n_100: 9.0538 (9.0468)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.7831)  triple_40: 0.0000 (0.0000)  time: 0.3663  data: 0.0319  max mem: 46473\n",
      "Valid: [epoch:2]  [ 20/845]  eta: 0:04:49  loss: 32.8624 (35.5723)  loss_n_40: 6.5952 (6.5561)  loss_n_60: 8.5953 (8.5264)  loss_n_80: 8.3804 (8.3886)  loss_n_100: 9.0027 (9.0141)  triple_100: 0.0000 (0.2095)  triple_80: 0.0000 (0.6228)  triple_60: 0.0000 (2.1131)  triple_40: 0.0000 (0.1416)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [ 30/845]  eta: 0:04:41  loss: 32.8624 (34.7644)  loss_n_40: 6.6344 (6.5604)  loss_n_60: 8.6056 (8.5477)  loss_n_80: 8.3804 (8.4250)  loss_n_100: 8.9907 (9.0360)  triple_100: 0.0000 (0.1420)  triple_80: 0.0000 (0.4219)  triple_60: 0.0000 (1.5356)  triple_40: 0.0000 (0.0960)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [ 40/845]  eta: 0:04:35  loss: 32.3854 (34.2443)  loss_n_40: 6.5344 (6.5427)  loss_n_60: 8.4743 (8.5315)  loss_n_80: 8.4231 (8.4500)  loss_n_100: 9.0147 (9.0601)  triple_100: 0.0000 (0.1073)  triple_80: 0.0000 (0.3190)  triple_60: 0.0000 (1.1611)  triple_40: 0.0000 (0.0725)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [ 50/845]  eta: 0:04:31  loss: 33.3879 (35.1128)  loss_n_40: 6.6722 (6.6263)  loss_n_60: 8.5842 (8.5858)  loss_n_80: 8.5683 (8.4824)  loss_n_100: 9.1390 (9.0966)  triple_100: 0.0000 (0.2679)  triple_80: 0.0000 (0.4651)  triple_60: 0.0000 (1.1899)  triple_40: 0.0000 (0.3989)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [ 60/845]  eta: 0:04:26  loss: 33.3879 (34.6964)  loss_n_40: 6.7511 (6.6025)  loss_n_60: 8.6179 (8.5698)  loss_n_80: 8.5683 (8.4802)  loss_n_100: 9.0750 (9.1028)  triple_100: 0.0000 (0.2240)  triple_80: 0.0000 (0.3888)  triple_60: 0.0000 (0.9948)  triple_40: 0.0000 (0.3335)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [ 70/845]  eta: 0:04:22  loss: 33.1439 (34.5234)  loss_n_40: 6.5967 (6.6121)  loss_n_60: 8.5563 (8.5736)  loss_n_80: 8.6328 (8.5090)  loss_n_100: 9.1784 (9.1265)  triple_100: 0.0000 (0.2071)  triple_80: 0.0000 (0.3341)  triple_60: 0.0000 (0.8746)  triple_40: 0.0000 (0.2865)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [ 80/845]  eta: 0:04:19  loss: 33.1580 (34.3626)  loss_n_40: 6.6817 (6.6212)  loss_n_60: 8.6142 (8.5836)  loss_n_80: 8.6345 (8.5135)  loss_n_100: 9.2572 (9.1346)  triple_100: 0.0000 (0.1815)  triple_80: 0.0000 (0.2928)  triple_60: 0.0000 (0.7666)  triple_40: 0.0000 (0.2688)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [ 90/845]  eta: 0:04:15  loss: 32.5230 (34.1709)  loss_n_40: 6.6644 (6.6061)  loss_n_60: 8.5910 (8.5734)  loss_n_80: 8.3366 (8.5121)  loss_n_100: 8.9691 (9.1354)  triple_100: 0.0000 (0.1616)  triple_80: 0.0000 (0.2606)  triple_60: 0.0000 (0.6824)  triple_40: 0.0000 (0.2393)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [100/845]  eta: 0:04:11  loss: 32.2729 (33.9941)  loss_n_40: 6.4539 (6.5920)  loss_n_60: 8.4301 (8.5608)  loss_n_80: 8.3601 (8.5038)  loss_n_100: 8.8992 (9.1259)  triple_100: 0.0000 (0.1456)  triple_80: 0.0000 (0.2348)  triple_60: 0.0000 (0.6156)  triple_40: 0.0000 (0.2156)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [110/845]  eta: 0:04:08  loss: 32.3884 (34.6762)  loss_n_40: 6.3574 (6.5964)  loss_n_60: 8.3408 (8.5559)  loss_n_80: 8.3601 (8.5063)  loss_n_100: 8.8640 (9.1293)  triple_100: 0.0000 (0.1912)  triple_80: 0.0000 (0.3209)  triple_60: 0.0000 (0.9407)  triple_40: 0.0000 (0.4356)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [120/845]  eta: 0:04:04  loss: 33.0162 (34.5594)  loss_n_40: 6.7528 (6.6044)  loss_n_60: 8.6333 (8.5617)  loss_n_80: 8.4187 (8.5201)  loss_n_100: 8.9628 (9.1344)  triple_100: 0.0000 (0.1754)  triple_80: 0.0000 (0.2943)  triple_60: 0.0000 (0.8696)  triple_40: 0.0000 (0.3996)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [130/845]  eta: 0:04:00  loss: 33.0162 (34.4781)  loss_n_40: 6.6123 (6.5991)  loss_n_60: 8.5858 (8.5611)  loss_n_80: 8.2395 (8.5267)  loss_n_100: 8.9659 (9.1359)  triple_100: 0.0000 (0.1620)  triple_80: 0.0000 (0.2719)  triple_60: 0.0000 (0.8523)  triple_40: 0.0000 (0.3691)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [140/845]  eta: 0:03:57  loss: 32.4270 (34.4034)  loss_n_40: 6.3747 (6.5953)  loss_n_60: 8.3896 (8.5597)  loss_n_80: 8.2395 (8.5342)  loss_n_100: 8.9659 (9.1352)  triple_100: 0.0000 (0.1723)  triple_80: 0.0000 (0.2718)  triple_60: 0.0000 (0.7919)  triple_40: 0.0000 (0.3429)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [150/845]  eta: 0:03:53  loss: 32.0025 (34.3344)  loss_n_40: 6.3747 (6.5958)  loss_n_60: 8.4057 (8.5601)  loss_n_80: 8.1887 (8.5188)  loss_n_100: 8.9388 (9.1225)  triple_100: 0.0000 (0.1642)  triple_80: 0.0000 (0.2538)  triple_60: 0.0000 (0.7556)  triple_40: 0.0000 (0.3635)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [160/845]  eta: 0:03:50  loss: 32.7140 (34.5117)  loss_n_40: 6.5284 (6.5852)  loss_n_60: 8.4057 (8.5539)  loss_n_80: 8.2308 (8.5231)  loss_n_100: 8.8229 (9.1254)  triple_100: 0.0000 (0.1592)  triple_80: 0.0000 (0.2499)  triple_60: 0.0000 (0.8785)  triple_40: 0.0000 (0.4365)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [170/845]  eta: 0:03:47  loss: 33.3656 (34.5885)  loss_n_40: 6.6528 (6.5937)  loss_n_60: 8.6077 (8.5596)  loss_n_80: 8.6488 (8.5366)  loss_n_100: 9.0834 (9.1369)  triple_100: 0.0000 (0.1499)  triple_80: 0.0000 (0.2426)  triple_60: 0.0000 (0.9379)  triple_40: 0.0000 (0.4312)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [180/845]  eta: 0:03:43  loss: 33.5148 (34.7277)  loss_n_40: 6.6988 (6.6019)  loss_n_60: 8.6093 (8.5635)  loss_n_80: 8.6104 (8.5352)  loss_n_100: 9.0819 (9.1361)  triple_100: 0.0000 (0.1416)  triple_80: 0.0000 (0.2442)  triple_60: 0.0000 (0.9875)  triple_40: 0.0000 (0.5176)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [190/845]  eta: 0:03:40  loss: 33.4871 (34.7095)  loss_n_40: 6.7738 (6.6169)  loss_n_60: 8.6879 (8.5773)  loss_n_80: 8.5860 (8.5504)  loss_n_100: 9.1270 (9.1492)  triple_100: 0.0000 (0.1581)  triple_80: 0.0000 (0.2314)  triple_60: 0.0000 (0.9358)  triple_40: 0.0000 (0.4905)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [200/845]  eta: 0:03:36  loss: 32.6581 (34.5774)  loss_n_40: 6.6465 (6.6045)  loss_n_60: 8.6633 (8.5697)  loss_n_80: 8.4950 (8.5398)  loss_n_100: 9.0892 (9.1379)  triple_100: 0.0000 (0.1502)  triple_80: 0.0000 (0.2199)  triple_60: 0.0000 (0.8892)  triple_40: 0.0000 (0.4661)  time: 0.3346  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:2]  [210/845]  eta: 0:03:33  loss: 32.2870 (34.5899)  loss_n_40: 6.5536 (6.6082)  loss_n_60: 8.5164 (8.5700)  loss_n_80: 8.2156 (8.5336)  loss_n_100: 8.9258 (9.1364)  triple_100: 0.0000 (0.1431)  triple_80: 0.0000 (0.2299)  triple_60: 0.0000 (0.8873)  triple_40: 0.0000 (0.4815)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [220/845]  eta: 0:03:30  loss: 32.4690 (34.6217)  loss_n_40: 6.6311 (6.6039)  loss_n_60: 8.4791 (8.5642)  loss_n_80: 8.2156 (8.5356)  loss_n_100: 8.9779 (9.1402)  triple_100: 0.0000 (0.1366)  triple_80: 0.0000 (0.2350)  triple_60: 0.0000 (0.9083)  triple_40: 0.0000 (0.4978)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [230/845]  eta: 0:03:26  loss: 33.0625 (34.6969)  loss_n_40: 6.6311 (6.6113)  loss_n_60: 8.5071 (8.5689)  loss_n_80: 8.3637 (8.5329)  loss_n_100: 9.0204 (9.1401)  triple_100: 0.0000 (0.1350)  triple_80: 0.0000 (0.2486)  triple_60: 0.0000 (0.9580)  triple_40: 0.0000 (0.5019)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [240/845]  eta: 0:03:23  loss: 33.2329 (34.8462)  loss_n_40: 6.5956 (6.6106)  loss_n_60: 8.5418 (8.5675)  loss_n_80: 8.5102 (8.5410)  loss_n_100: 9.0953 (9.1453)  triple_100: 0.0000 (0.1416)  triple_80: 0.0000 (0.2627)  triple_60: 0.0000 (1.0088)  triple_40: 0.0000 (0.5686)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [250/845]  eta: 0:03:19  loss: 33.9001 (35.0259)  loss_n_40: 6.7445 (6.6215)  loss_n_60: 8.5418 (8.5728)  loss_n_80: 8.7410 (8.5416)  loss_n_100: 9.1575 (9.1472)  triple_100: 0.0000 (0.1680)  triple_80: 0.0000 (0.2742)  triple_60: 0.0000 (1.1059)  triple_40: 0.0000 (0.5946)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [260/845]  eta: 0:03:16  loss: 33.4640 (34.9274)  loss_n_40: 6.6523 (6.6200)  loss_n_60: 8.5116 (8.5721)  loss_n_80: 8.2965 (8.5334)  loss_n_100: 8.9566 (9.1413)  triple_100: 0.0000 (0.1616)  triple_80: 0.0000 (0.2637)  triple_60: 0.0000 (1.0635)  triple_40: 0.0000 (0.5718)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [270/845]  eta: 0:03:13  loss: 32.4554 (34.9035)  loss_n_40: 6.4982 (6.6226)  loss_n_60: 8.5452 (8.5749)  loss_n_80: 8.1773 (8.5393)  loss_n_100: 8.8888 (9.1466)  triple_100: 0.0000 (0.1556)  triple_80: 0.0000 (0.2540)  triple_60: 0.0000 (1.0598)  triple_40: 0.0000 (0.5507)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [280/845]  eta: 0:03:09  loss: 33.7789 (34.8639)  loss_n_40: 6.7583 (6.6306)  loss_n_60: 8.6950 (8.5809)  loss_n_80: 8.3871 (8.5410)  loss_n_100: 8.9715 (9.1473)  triple_100: 0.0000 (0.1526)  triple_80: 0.0000 (0.2449)  triple_60: 0.0000 (1.0355)  triple_40: 0.0000 (0.5311)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [290/845]  eta: 0:03:06  loss: 34.0564 (35.3371)  loss_n_40: 6.8899 (6.6339)  loss_n_60: 8.5603 (8.5799)  loss_n_80: 8.3958 (8.5455)  loss_n_100: 9.0605 (9.1532)  triple_100: 0.0000 (0.1756)  triple_80: 0.0000 (0.3335)  triple_60: 0.0000 (1.2469)  triple_40: 0.0000 (0.6685)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [300/845]  eta: 0:03:02  loss: 34.5262 (35.3684)  loss_n_40: 6.6854 (6.6333)  loss_n_60: 8.5087 (8.5780)  loss_n_80: 8.3958 (8.5440)  loss_n_100: 9.0497 (9.1512)  triple_100: 0.0000 (0.1697)  triple_80: 0.0000 (0.3418)  triple_60: 0.0000 (1.2893)  triple_40: 0.0000 (0.6610)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [310/845]  eta: 0:02:59  loss: 33.9730 (35.3216)  loss_n_40: 6.6514 (6.6370)  loss_n_60: 8.6441 (8.5831)  loss_n_80: 8.7580 (8.5588)  loss_n_100: 9.0497 (9.1600)  triple_100: 0.0000 (0.1643)  triple_80: 0.0000 (0.3308)  triple_60: 0.0000 (1.2478)  triple_40: 0.0000 (0.6397)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [320/845]  eta: 0:02:56  loss: 33.8969 (35.2658)  loss_n_40: 6.6001 (6.6336)  loss_n_60: 8.6441 (8.5813)  loss_n_80: 8.9118 (8.5600)  loss_n_100: 9.1691 (9.1606)  triple_100: 0.0000 (0.1687)  triple_80: 0.0000 (0.3205)  triple_60: 0.0000 (1.2213)  triple_40: 0.0000 (0.6198)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [330/845]  eta: 0:02:52  loss: 32.2470 (35.2189)  loss_n_40: 6.4185 (6.6295)  loss_n_60: 8.4029 (8.5783)  loss_n_80: 8.3042 (8.5505)  loss_n_100: 8.8610 (9.1519)  triple_100: 0.0000 (0.1744)  triple_80: 0.0000 (0.3167)  triple_60: 0.0000 (1.2166)  triple_40: 0.0000 (0.6011)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [340/845]  eta: 0:02:49  loss: 32.4007 (35.1618)  loss_n_40: 6.4637 (6.6262)  loss_n_60: 8.4112 (8.5763)  loss_n_80: 8.3060 (8.5535)  loss_n_100: 8.9247 (9.1549)  triple_100: 0.0000 (0.1791)  triple_80: 0.0000 (0.3075)  triple_60: 0.0000 (1.1809)  triple_40: 0.0000 (0.5834)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [350/845]  eta: 0:02:46  loss: 32.8154 (35.2446)  loss_n_40: 6.5991 (6.6294)  loss_n_60: 8.5469 (8.5781)  loss_n_80: 8.5001 (8.5551)  loss_n_100: 9.0901 (9.1545)  triple_100: 0.0000 (0.1753)  triple_80: 0.0000 (0.3111)  triple_60: 0.0000 (1.2207)  triple_40: 0.0000 (0.6205)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [360/845]  eta: 0:02:42  loss: 33.6377 (35.1984)  loss_n_40: 6.6994 (6.6334)  loss_n_60: 8.6759 (8.5818)  loss_n_80: 8.6937 (8.5606)  loss_n_100: 9.3023 (9.1594)  triple_100: 0.0000 (0.1704)  triple_80: 0.0000 (0.3025)  triple_60: 0.0000 (1.1869)  triple_40: 0.0000 (0.6033)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [370/845]  eta: 0:02:39  loss: 32.8185 (35.1177)  loss_n_40: 6.5719 (6.6277)  loss_n_60: 8.5897 (8.5786)  loss_n_80: 8.4664 (8.5551)  loss_n_100: 8.9397 (9.1542)  triple_100: 0.0000 (0.1658)  triple_80: 0.0000 (0.2943)  triple_60: 0.0000 (1.1549)  triple_40: 0.0000 (0.5870)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [380/845]  eta: 0:02:35  loss: 32.2898 (35.0680)  loss_n_40: 6.5974 (6.6292)  loss_n_60: 8.5897 (8.5806)  loss_n_80: 8.2538 (8.5569)  loss_n_100: 8.9278 (9.1571)  triple_100: 0.0000 (0.1615)  triple_80: 0.0000 (0.2866)  triple_60: 0.0000 (1.1246)  triple_40: 0.0000 (0.5716)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [390/845]  eta: 0:02:32  loss: 32.6873 (35.0206)  loss_n_40: 6.6055 (6.6306)  loss_n_60: 8.6587 (8.5825)  loss_n_80: 8.3535 (8.5558)  loss_n_100: 8.9849 (9.1563)  triple_100: 0.0000 (0.1573)  triple_80: 0.0000 (0.2793)  triple_60: 0.0000 (1.1019)  triple_40: 0.0000 (0.5570)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [400/845]  eta: 0:02:29  loss: 33.1043 (34.9909)  loss_n_40: 6.6205 (6.6333)  loss_n_60: 8.6245 (8.5838)  loss_n_80: 8.4550 (8.5555)  loss_n_100: 8.9542 (9.1575)  triple_100: 0.0000 (0.1534)  triple_80: 0.0000 (0.2723)  triple_60: 0.0000 (1.0920)  triple_40: 0.0000 (0.5431)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [410/845]  eta: 0:02:25  loss: 33.5930 (34.9649)  loss_n_40: 6.7884 (6.6371)  loss_n_60: 8.6447 (8.5878)  loss_n_80: 8.6240 (8.5578)  loss_n_100: 9.0021 (9.1571)  triple_100: 0.0000 (0.1497)  triple_80: 0.0000 (0.2657)  triple_60: 0.0000 (1.0798)  triple_40: 0.0000 (0.5299)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [420/845]  eta: 0:02:22  loss: 33.5930 (34.9515)  loss_n_40: 6.7847 (6.6377)  loss_n_60: 8.6447 (8.5880)  loss_n_80: 8.6240 (8.5581)  loss_n_100: 9.0848 (9.1562)  triple_100: 0.0000 (0.1576)  triple_80: 0.0000 (0.2594)  triple_60: 0.0000 (1.0772)  triple_40: 0.0000 (0.5173)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [430/845]  eta: 0:02:19  loss: 34.3425 (34.9582)  loss_n_40: 6.7847 (6.6444)  loss_n_60: 8.7067 (8.5942)  loss_n_80: 8.7094 (8.5651)  loss_n_100: 9.0848 (9.1606)  triple_100: 0.0000 (0.1539)  triple_80: 0.0000 (0.2533)  triple_60: 0.0000 (1.0570)  triple_40: 0.0000 (0.5297)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [440/845]  eta: 0:02:15  loss: 32.6055 (34.8914)  loss_n_40: 6.5554 (6.6377)  loss_n_60: 8.6061 (8.5883)  loss_n_80: 8.3419 (8.5606)  loss_n_100: 8.9874 (9.1561)  triple_100: 0.0000 (0.1504)  triple_80: 0.0000 (0.2476)  triple_60: 0.0000 (1.0330)  triple_40: 0.0000 (0.5177)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [450/845]  eta: 0:02:12  loss: 32.3687 (35.1020)  loss_n_40: 6.6954 (6.6406)  loss_n_60: 8.5162 (8.5894)  loss_n_80: 8.2944 (8.5583)  loss_n_100: 8.9206 (9.1527)  triple_100: 0.0000 (0.1559)  triple_80: 0.0000 (0.2708)  triple_60: 0.0000 (1.1348)  triple_40: 0.0000 (0.5995)  time: 0.3347  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:2]  [460/845]  eta: 0:02:09  loss: 32.7528 (35.1366)  loss_n_40: 6.6954 (6.6374)  loss_n_60: 8.4564 (8.5853)  loss_n_80: 8.2719 (8.5554)  loss_n_100: 8.9750 (9.1515)  triple_100: 0.0000 (0.1525)  triple_80: 0.0000 (0.2787)  triple_60: 0.0000 (1.1580)  triple_40: 0.0000 (0.6177)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [470/845]  eta: 0:02:05  loss: 32.1562 (35.1842)  loss_n_40: 6.3918 (6.6370)  loss_n_60: 8.3204 (8.5842)  loss_n_80: 8.3373 (8.5538)  loss_n_100: 9.0117 (9.1499)  triple_100: 0.0000 (0.1493)  triple_80: 0.0000 (0.2789)  triple_60: 0.0000 (1.1730)  triple_40: 0.0000 (0.6582)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [480/845]  eta: 0:02:02  loss: 32.9618 (35.1450)  loss_n_40: 6.7614 (6.6397)  loss_n_60: 8.4848 (8.5859)  loss_n_80: 8.5521 (8.5558)  loss_n_100: 9.0647 (9.1512)  triple_100: 0.0000 (0.1462)  triple_80: 0.0000 (0.2731)  triple_60: 0.0000 (1.1486)  triple_40: 0.0000 (0.6445)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [490/845]  eta: 0:01:59  loss: 33.0846 (35.1870)  loss_n_40: 6.7655 (6.6416)  loss_n_60: 8.6390 (8.5872)  loss_n_80: 8.5521 (8.5581)  loss_n_100: 9.0190 (9.1522)  triple_100: 0.0000 (0.1515)  triple_80: 0.0000 (0.2787)  triple_60: 0.0000 (1.1864)  triple_40: 0.0000 (0.6314)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [500/845]  eta: 0:01:55  loss: 33.0497 (35.1452)  loss_n_40: 6.7057 (6.6416)  loss_n_60: 8.6390 (8.5883)  loss_n_80: 8.3736 (8.5582)  loss_n_100: 8.9726 (9.1519)  triple_100: 0.0000 (0.1485)  triple_80: 0.0000 (0.2731)  triple_60: 0.0000 (1.1650)  triple_40: 0.0000 (0.6187)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [510/845]  eta: 0:01:52  loss: 32.8491 (35.1239)  loss_n_40: 6.7651 (6.6456)  loss_n_60: 8.7269 (8.5922)  loss_n_80: 8.4089 (8.5655)  loss_n_100: 9.0873 (9.1585)  triple_100: 0.0000 (0.1456)  triple_80: 0.0000 (0.2677)  triple_60: 0.0000 (1.1422)  triple_40: 0.0000 (0.6066)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [520/845]  eta: 0:01:48  loss: 32.7337 (35.3037)  loss_n_40: 6.7425 (6.6450)  loss_n_60: 8.6533 (8.5896)  loss_n_80: 8.4089 (8.5604)  loss_n_100: 9.0682 (9.1535)  triple_100: 0.0000 (0.1513)  triple_80: 0.0000 (0.2983)  triple_60: 0.0000 (1.2371)  triple_40: 0.0000 (0.6685)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [530/845]  eta: 0:01:45  loss: 32.7337 (35.4225)  loss_n_40: 6.6177 (6.6438)  loss_n_60: 8.4316 (8.5887)  loss_n_80: 8.3511 (8.5614)  loss_n_100: 8.9587 (9.1542)  triple_100: 0.0000 (0.1676)  triple_80: 0.0000 (0.3380)  triple_60: 0.0000 (1.2721)  triple_40: 0.0000 (0.6967)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [540/845]  eta: 0:01:42  loss: 33.2771 (35.4027)  loss_n_40: 6.7685 (6.6436)  loss_n_60: 8.4864 (8.5880)  loss_n_80: 8.4530 (8.5616)  loss_n_100: 9.0151 (9.1543)  triple_100: 0.0000 (0.1801)  triple_80: 0.0000 (0.3402)  triple_60: 0.0000 (1.2510)  triple_40: 0.0000 (0.6838)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [550/845]  eta: 0:01:38  loss: 33.4656 (35.3832)  loss_n_40: 6.8056 (6.6466)  loss_n_60: 8.7014 (8.5907)  loss_n_80: 8.6169 (8.5662)  loss_n_100: 9.2554 (9.1586)  triple_100: 0.0000 (0.1769)  triple_80: 0.0000 (0.3340)  triple_60: 0.0000 (1.2387)  triple_40: 0.0000 (0.6714)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [560/845]  eta: 0:01:35  loss: 32.9712 (35.3655)  loss_n_40: 6.7169 (6.6436)  loss_n_60: 8.7001 (8.5892)  loss_n_80: 8.4709 (8.5635)  loss_n_100: 8.9480 (9.1554)  triple_100: 0.0000 (0.1737)  triple_80: 0.0000 (0.3281)  triple_60: 0.0000 (1.2383)  triple_40: 0.0000 (0.6737)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [570/845]  eta: 0:01:32  loss: 32.4475 (35.3278)  loss_n_40: 6.4278 (6.6446)  loss_n_60: 8.5382 (8.5902)  loss_n_80: 8.3144 (8.5631)  loss_n_100: 8.8710 (9.1556)  triple_100: 0.0000 (0.1707)  triple_80: 0.0000 (0.3223)  triple_60: 0.0000 (1.2193)  triple_40: 0.0000 (0.6619)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [580/845]  eta: 0:01:28  loss: 32.8642 (35.2995)  loss_n_40: 6.7123 (6.6451)  loss_n_60: 8.6596 (8.5909)  loss_n_80: 8.2766 (8.5594)  loss_n_100: 8.8710 (9.1515)  triple_100: 0.0000 (0.1710)  triple_80: 0.0000 (0.3202)  triple_60: 0.0000 (1.2109)  triple_40: 0.0000 (0.6505)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [590/845]  eta: 0:01:25  loss: 32.2147 (35.3275)  loss_n_40: 6.5377 (6.6415)  loss_n_60: 8.4620 (8.5876)  loss_n_80: 8.2524 (8.5547)  loss_n_100: 8.9486 (9.1480)  triple_100: 0.0000 (0.1711)  triple_80: 0.0000 (0.3189)  triple_60: 0.0000 (1.2424)  triple_40: 0.0000 (0.6635)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [600/845]  eta: 0:01:22  loss: 32.9104 (35.3021)  loss_n_40: 6.5981 (6.6456)  loss_n_60: 8.5853 (8.5899)  loss_n_80: 8.3787 (8.5585)  loss_n_100: 9.0212 (9.1522)  triple_100: 0.0000 (0.1683)  triple_80: 0.0000 (0.3136)  triple_60: 0.0000 (1.2217)  triple_40: 0.0000 (0.6524)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [610/845]  eta: 0:01:18  loss: 33.7080 (35.2719)  loss_n_40: 6.7117 (6.6463)  loss_n_60: 8.6598 (8.5901)  loss_n_80: 8.7747 (8.5617)  loss_n_100: 9.3224 (9.1551)  triple_100: 0.0000 (0.1667)  triple_80: 0.0000 (0.3084)  triple_60: 0.0000 (1.2017)  triple_40: 0.0000 (0.6418)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [620/845]  eta: 0:01:15  loss: 33.1181 (35.2320)  loss_n_40: 6.6894 (6.6469)  loss_n_60: 8.5662 (8.5906)  loss_n_80: 8.5992 (8.5596)  loss_n_100: 9.2364 (9.1536)  triple_100: 0.0000 (0.1640)  triple_80: 0.0000 (0.3035)  triple_60: 0.0000 (1.1823)  triple_40: 0.0000 (0.6314)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [630/845]  eta: 0:01:12  loss: 32.9962 (35.3966)  loss_n_40: 6.8137 (6.6502)  loss_n_60: 8.5662 (8.5914)  loss_n_80: 8.3304 (8.5555)  loss_n_100: 8.9977 (9.1508)  triple_100: 0.0000 (0.1815)  triple_80: 0.0000 (0.3308)  triple_60: 0.0000 (1.2683)  triple_40: 0.0000 (0.6680)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [640/845]  eta: 0:01:08  loss: 33.2426 (35.3848)  loss_n_40: 6.6132 (6.6514)  loss_n_60: 8.5321 (8.5925)  loss_n_80: 8.4729 (8.5588)  loss_n_100: 9.1336 (9.1537)  triple_100: 0.0000 (0.1787)  triple_80: 0.0000 (0.3256)  triple_60: 0.0000 (1.2665)  triple_40: 0.0000 (0.6576)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [650/845]  eta: 0:01:05  loss: 32.6805 (35.3477)  loss_n_40: 6.5997 (6.6510)  loss_n_60: 8.5321 (8.5927)  loss_n_80: 8.4689 (8.5588)  loss_n_100: 9.0310 (9.1541)  triple_100: 0.0000 (0.1760)  triple_80: 0.0000 (0.3206)  triple_60: 0.0000 (1.2470)  triple_40: 0.0000 (0.6475)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [660/845]  eta: 0:01:01  loss: 32.6232 (35.3181)  loss_n_40: 6.6548 (6.6530)  loss_n_60: 8.6965 (8.5950)  loss_n_80: 8.4689 (8.5596)  loss_n_100: 9.0158 (9.1541)  triple_100: 0.0000 (0.1733)  triple_80: 0.0000 (0.3158)  triple_60: 0.0000 (1.2297)  triple_40: 0.0000 (0.6377)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [670/845]  eta: 0:00:58  loss: 32.7460 (35.2815)  loss_n_40: 6.6258 (6.6519)  loss_n_60: 8.6679 (8.5946)  loss_n_80: 8.3989 (8.5593)  loss_n_100: 9.0158 (9.1545)  triple_100: 0.0000 (0.1707)  triple_80: 0.0000 (0.3111)  triple_60: 0.0000 (1.2113)  triple_40: 0.0000 (0.6282)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [680/845]  eta: 0:00:55  loss: 33.1168 (35.2575)  loss_n_40: 6.5789 (6.6535)  loss_n_60: 8.5688 (8.5957)  loss_n_80: 8.3689 (8.5614)  loss_n_100: 9.0997 (9.1570)  triple_100: 0.0000 (0.1685)  triple_80: 0.0000 (0.3065)  triple_60: 0.0000 (1.1960)  triple_40: 0.0000 (0.6190)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [690/845]  eta: 0:00:51  loss: 33.1168 (35.2221)  loss_n_40: 6.6210 (6.6514)  loss_n_60: 8.5101 (8.5940)  loss_n_80: 8.4866 (8.5623)  loss_n_100: 9.1852 (9.1577)  triple_100: 0.0000 (0.1660)  triple_80: 0.0000 (0.3021)  triple_60: 0.0000 (1.1787)  triple_40: 0.0000 (0.6100)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [700/845]  eta: 0:00:48  loss: 32.1648 (35.2989)  loss_n_40: 6.5086 (6.6495)  loss_n_60: 8.4943 (8.5920)  loss_n_80: 8.3753 (8.5634)  loss_n_100: 9.0415 (9.1588)  triple_100: 0.0000 (0.1735)  triple_80: 0.0000 (0.3236)  triple_60: 0.0000 (1.2077)  triple_40: 0.0000 (0.6304)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:2]  [710/845]  eta: 0:00:45  loss: 32.3552 (35.2978)  loss_n_40: 6.5374 (6.6501)  loss_n_60: 8.4789 (8.5920)  loss_n_80: 8.3298 (8.5624)  loss_n_100: 9.0246 (9.1565)  triple_100: 0.0000 (0.1750)  triple_80: 0.0000 (0.3277)  triple_60: 0.0000 (1.2078)  triple_40: 0.0000 (0.6262)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [720/845]  eta: 0:00:41  loss: 34.0691 (35.4031)  loss_n_40: 6.7266 (6.6530)  loss_n_60: 8.5991 (8.5938)  loss_n_80: 8.3889 (8.5622)  loss_n_100: 8.9772 (9.1553)  triple_100: 0.0000 (0.1757)  triple_80: 0.0000 (0.3348)  triple_60: 0.0000 (1.2502)  triple_40: 0.0000 (0.6782)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [730/845]  eta: 0:00:38  loss: 33.8335 (35.4319)  loss_n_40: 6.8387 (6.6532)  loss_n_60: 8.6729 (8.5934)  loss_n_80: 8.3889 (8.5615)  loss_n_100: 8.9841 (9.1542)  triple_100: 0.0000 (0.1769)  triple_80: 0.0000 (0.3340)  triple_60: 0.0000 (1.2634)  triple_40: 0.0000 (0.6952)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [740/845]  eta: 0:00:35  loss: 33.1029 (35.4495)  loss_n_40: 6.5332 (6.6535)  loss_n_60: 8.4189 (8.5930)  loss_n_80: 8.2318 (8.5587)  loss_n_100: 8.9410 (9.1512)  triple_100: 0.0000 (0.1772)  triple_80: 0.0000 (0.3390)  triple_60: 0.0000 (1.2873)  triple_40: 0.0000 (0.6896)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [750/845]  eta: 0:00:31  loss: 32.7957 (35.4858)  loss_n_40: 6.5785 (6.6544)  loss_n_60: 8.4370 (8.5930)  loss_n_80: 8.1850 (8.5591)  loss_n_100: 8.8362 (9.1512)  triple_100: 0.0000 (0.1773)  triple_80: 0.0000 (0.3402)  triple_60: 0.0000 (1.3143)  triple_40: 0.0000 (0.6963)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [760/845]  eta: 0:00:28  loss: 32.8622 (35.4971)  loss_n_40: 6.8108 (6.6551)  loss_n_60: 8.5304 (8.5935)  loss_n_80: 8.3316 (8.5594)  loss_n_100: 9.0174 (9.1511)  triple_100: 0.0000 (0.1793)  triple_80: 0.0000 (0.3459)  triple_60: 0.0000 (1.3217)  triple_40: 0.0000 (0.6913)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [770/845]  eta: 0:00:25  loss: 33.9400 (35.4768)  loss_n_40: 6.8179 (6.6572)  loss_n_60: 8.6689 (8.5950)  loss_n_80: 8.7836 (8.5641)  loss_n_100: 9.1746 (9.1553)  triple_100: 0.0000 (0.1769)  triple_80: 0.0000 (0.3414)  triple_60: 0.0000 (1.3045)  triple_40: 0.0000 (0.6823)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [780/845]  eta: 0:00:21  loss: 33.3581 (35.4441)  loss_n_40: 6.6882 (6.6568)  loss_n_60: 8.6156 (8.5943)  loss_n_80: 8.5884 (8.5636)  loss_n_100: 9.1461 (9.1553)  triple_100: 0.0000 (0.1747)  triple_80: 0.0000 (0.3370)  triple_60: 0.0000 (1.2888)  triple_40: 0.0000 (0.6736)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [790/845]  eta: 0:00:18  loss: 32.6581 (35.4168)  loss_n_40: 6.6193 (6.6567)  loss_n_60: 8.5976 (8.5944)  loss_n_80: 8.3905 (8.5652)  loss_n_100: 9.1010 (9.1570)  triple_100: 0.0000 (0.1725)  triple_80: 0.0000 (0.3327)  triple_60: 0.0000 (1.2731)  triple_40: 0.0000 (0.6651)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [800/845]  eta: 0:00:15  loss: 33.5649 (35.4140)  loss_n_40: 6.6842 (6.6584)  loss_n_60: 8.6580 (8.5961)  loss_n_80: 8.3515 (8.5653)  loss_n_100: 9.0623 (9.1571)  triple_100: 0.0000 (0.1706)  triple_80: 0.0000 (0.3328)  triple_60: 0.0000 (1.2768)  triple_40: 0.0000 (0.6568)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [810/845]  eta: 0:00:11  loss: 33.4297 (35.4239)  loss_n_40: 6.6387 (6.6573)  loss_n_60: 8.5672 (8.5956)  loss_n_80: 8.3515 (8.5629)  loss_n_100: 9.0111 (9.1552)  triple_100: 0.0000 (0.1857)  triple_80: 0.0000 (0.3374)  triple_60: 0.0000 (1.2790)  triple_40: 0.0000 (0.6508)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [820/845]  eta: 0:00:08  loss: 32.9359 (35.4031)  loss_n_40: 6.6146 (6.6579)  loss_n_60: 8.5673 (8.5968)  loss_n_80: 8.4750 (8.5643)  loss_n_100: 9.0172 (9.1552)  triple_100: 0.0000 (0.1834)  triple_80: 0.0000 (0.3333)  triple_60: 0.0000 (1.2692)  triple_40: 0.0000 (0.6429)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [830/845]  eta: 0:00:05  loss: 33.5469 (35.5811)  loss_n_40: 6.8182 (6.6621)  loss_n_60: 8.6710 (8.5983)  loss_n_80: 8.5098 (8.5635)  loss_n_100: 9.1035 (9.1554)  triple_100: 0.0000 (0.1938)  triple_80: 0.0000 (0.3606)  triple_60: 0.0000 (1.3562)  triple_40: 0.0000 (0.6910)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [840/845]  eta: 0:00:01  loss: 33.7957 (35.5580)  loss_n_40: 6.8405 (6.6627)  loss_n_60: 8.6710 (8.5988)  loss_n_80: 8.5579 (8.5664)  loss_n_100: 9.2447 (9.1581)  triple_100: 0.0000 (0.1915)  triple_80: 0.0000 (0.3564)  triple_60: 0.0000 (1.3413)  triple_40: 0.0000 (0.6828)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2]  [844/845]  eta: 0:00:00  loss: 33.1089 (35.6232)  loss_n_40: 6.6643 (6.6628)  loss_n_60: 8.5822 (8.5983)  loss_n_80: 8.5177 (8.5658)  loss_n_100: 9.1266 (9.1576)  triple_100: 0.0000 (0.1928)  triple_80: 0.0000 (0.3680)  triple_60: 0.0000 (1.3674)  triple_40: 0.0000 (0.7105)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:2] Total time: 0:04:43 (0.3351 s / it)\n",
      "Averaged stats: loss: 33.1089 (35.6232)  loss_n_40: 6.6643 (6.6628)  loss_n_60: 8.5822 (8.5983)  loss_n_80: 8.5177 (8.5658)  loss_n_100: 9.1266 (9.1576)  triple_100: 0.0000 (0.1928)  triple_80: 0.0000 (0.3680)  triple_60: 0.0000 (1.3674)  triple_40: 0.0000 (0.7105)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_2_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 9.158%\n",
      "Min loss_n_100: 4.783\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:3]  [   0/1724]  eta: 2:00:31  lr: 0.000040  loss: 32.0957 (32.0957)  loss_n_40: 6.4661 (6.4661)  loss_n_60: 8.4076 (8.4076)  loss_n_80: 8.2929 (8.2929)  loss_n_100: 8.9292 (8.9292)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1944  data: 0.4327  max mem: 46473\n",
      "Train: [epoch:3]  [  10/1724]  eta: 1:52:50  lr: 0.000040  loss: 33.1908 (37.4968)  loss_n_40: 6.5823 (6.6605)  loss_n_60: 8.5764 (8.6106)  loss_n_80: 8.4164 (8.4558)  loss_n_100: 9.2029 (9.1532)  triple_100: 0.1077 (0.5891)  triple_80: 0.0000 (0.4785)  triple_60: 0.0000 (2.1904)  triple_40: 0.0000 (1.3587)  time: 3.9500  data: 0.0395  max mem: 46473\n",
      "Train: [epoch:3]  [  20/1724]  eta: 1:51:51  lr: 0.000040  loss: 33.3456 (37.0188)  loss_n_40: 6.6523 (6.6671)  loss_n_60: 8.6304 (8.6221)  loss_n_80: 8.4421 (8.4835)  loss_n_100: 9.2029 (9.1685)  triple_100: 0.1636 (0.6674)  triple_80: 0.0000 (0.3821)  triple_60: 0.0000 (1.9081)  triple_40: 0.0000 (1.1200)  time: 3.9260  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:3]  [  30/1724]  eta: 1:51:05  lr: 0.000040  loss: 34.2136 (38.1534)  loss_n_40: 6.6870 (6.6781)  loss_n_60: 8.6375 (8.6159)  loss_n_80: 8.4798 (8.4789)  loss_n_100: 9.0864 (9.1277)  triple_100: 0.2142 (0.8372)  triple_80: 0.0000 (0.8956)  triple_60: 0.7561 (2.3367)  triple_40: 0.0000 (1.1831)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [  40/1724]  eta: 1:50:22  lr: 0.000040  loss: 33.4781 (37.3397)  loss_n_40: 6.6365 (6.6629)  loss_n_60: 8.6375 (8.6060)  loss_n_80: 8.4798 (8.5061)  loss_n_100: 9.0750 (9.1378)  triple_100: 0.0000 (0.6932)  triple_80: 0.0000 (0.7900)  triple_60: 0.2115 (1.9984)  triple_40: 0.0000 (0.9453)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [  50/1724]  eta: 1:49:40  lr: 0.000040  loss: 33.3569 (36.8885)  loss_n_40: 6.6365 (6.6576)  loss_n_60: 8.6483 (8.6112)  loss_n_80: 8.4821 (8.5302)  loss_n_100: 9.2092 (9.1685)  triple_100: 0.0000 (0.5712)  triple_80: 0.0000 (0.6371)  triple_60: 0.0000 (1.8126)  triple_40: 0.0000 (0.9001)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [  60/1724]  eta: 1:48:59  lr: 0.000040  loss: 33.6875 (37.0760)  loss_n_40: 6.6626 (6.6650)  loss_n_60: 8.6592 (8.6251)  loss_n_80: 8.5482 (8.5392)  loss_n_100: 9.3552 (9.2044)  triple_100: 0.0000 (0.6265)  triple_80: 0.0000 (0.6038)  triple_60: 0.0000 (1.7678)  triple_40: 0.0000 (1.0442)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [  70/1724]  eta: 1:48:19  lr: 0.000040  loss: 33.5567 (36.8205)  loss_n_40: 6.6436 (6.6618)  loss_n_60: 8.6419 (8.6216)  loss_n_80: 8.5489 (8.5177)  loss_n_100: 9.1997 (9.1837)  triple_100: 0.0000 (0.5487)  triple_80: 0.0000 (0.5580)  triple_60: 0.0000 (1.7319)  triple_40: 0.0000 (0.9971)  time: 3.9259  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [  80/1724]  eta: 1:47:39  lr: 0.000040  loss: 33.2210 (36.3908)  loss_n_40: 6.7203 (6.6655)  loss_n_60: 8.6785 (8.6249)  loss_n_80: 8.3387 (8.4948)  loss_n_100: 8.9929 (9.1610)  triple_100: 0.0000 (0.4881)  triple_80: 0.0000 (0.5023)  triple_60: 0.0000 (1.5749)  triple_40: 0.0000 (0.8793)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [  90/1724]  eta: 1:46:59  lr: 0.000040  loss: 32.9521 (36.1182)  loss_n_40: 6.7852 (6.6704)  loss_n_60: 8.7146 (8.6277)  loss_n_80: 8.3608 (8.4823)  loss_n_100: 8.9866 (9.1462)  triple_100: 0.0000 (0.4344)  triple_80: 0.0000 (0.4512)  triple_60: 0.0000 (1.4642)  triple_40: 0.0000 (0.8418)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 100/1724]  eta: 1:46:18  lr: 0.000040  loss: 33.3669 (36.0507)  loss_n_40: 6.7832 (6.6822)  loss_n_60: 8.7029 (8.6371)  loss_n_80: 8.3758 (8.4773)  loss_n_100: 8.9901 (9.1364)  triple_100: 0.0000 (0.4411)  triple_80: 0.0000 (0.4332)  triple_60: 0.0000 (1.4379)  triple_40: 0.0000 (0.8056)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 110/1724]  eta: 1:45:39  lr: 0.000040  loss: 33.5817 (36.0740)  loss_n_40: 6.6719 (6.6800)  loss_n_60: 8.6257 (8.6317)  loss_n_80: 8.5376 (8.4876)  loss_n_100: 9.0943 (9.1387)  triple_100: 0.0000 (0.4529)  triple_80: 0.0000 (0.4381)  triple_60: 0.0000 (1.4573)  triple_40: 0.0000 (0.7875)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 120/1724]  eta: 1:44:59  lr: 0.000040  loss: 33.7624 (36.1068)  loss_n_40: 6.6625 (6.6831)  loss_n_60: 8.5781 (8.6355)  loss_n_80: 8.5376 (8.4845)  loss_n_100: 9.0943 (9.1342)  triple_100: 0.2112 (0.4867)  triple_80: 0.0000 (0.4622)  triple_60: 0.0000 (1.4407)  triple_40: 0.0000 (0.7799)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 130/1724]  eta: 1:44:20  lr: 0.000040  loss: 33.1118 (36.1411)  loss_n_40: 6.5892 (6.6750)  loss_n_60: 8.5840 (8.6324)  loss_n_80: 8.4743 (8.4886)  loss_n_100: 9.0670 (9.1376)  triple_100: 0.0000 (0.5103)  triple_80: 0.0000 (0.4690)  triple_60: 0.0000 (1.4066)  triple_40: 0.0000 (0.8218)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 140/1724]  eta: 1:43:40  lr: 0.000040  loss: 32.7984 (36.0490)  loss_n_40: 6.5824 (6.6748)  loss_n_60: 8.5484 (8.6320)  loss_n_80: 8.4398 (8.4837)  loss_n_100: 9.0642 (9.1353)  triple_100: 0.0000 (0.4892)  triple_80: 0.0000 (0.4865)  triple_60: 0.0000 (1.3610)  triple_40: 0.0000 (0.7863)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 150/1724]  eta: 1:43:01  lr: 0.000040  loss: 33.3744 (36.1110)  loss_n_40: 6.6322 (6.6818)  loss_n_60: 8.6312 (8.6350)  loss_n_80: 8.4000 (8.4814)  loss_n_100: 9.0475 (9.1311)  triple_100: 0.0000 (0.4953)  triple_80: 0.0000 (0.4987)  triple_60: 0.0000 (1.3963)  triple_40: 0.0000 (0.7914)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 160/1724]  eta: 1:42:21  lr: 0.000040  loss: 33.0741 (35.9203)  loss_n_40: 6.6322 (6.6779)  loss_n_60: 8.6275 (8.6323)  loss_n_80: 8.4050 (8.4793)  loss_n_100: 9.0102 (9.1250)  triple_100: 0.0000 (0.4664)  triple_80: 0.0000 (0.4677)  triple_60: 0.0000 (1.3166)  triple_40: 0.0000 (0.7551)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 170/1724]  eta: 1:41:42  lr: 0.000040  loss: 32.9807 (35.7864)  loss_n_40: 6.6291 (6.6761)  loss_n_60: 8.5767 (8.6305)  loss_n_80: 8.3766 (8.4738)  loss_n_100: 8.9690 (9.1165)  triple_100: 0.0000 (0.4575)  triple_80: 0.0000 (0.4482)  triple_60: 0.0000 (1.2728)  triple_40: 0.0000 (0.7110)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 180/1724]  eta: 1:41:02  lr: 0.000040  loss: 32.7059 (35.6828)  loss_n_40: 6.6198 (6.6672)  loss_n_60: 8.5327 (8.6209)  loss_n_80: 8.3766 (8.4629)  loss_n_100: 8.9407 (9.1052)  triple_100: 0.0000 (0.4386)  triple_80: 0.0000 (0.4307)  triple_60: 0.0000 (1.2465)  triple_40: 0.0000 (0.7108)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 190/1724]  eta: 1:40:23  lr: 0.000040  loss: 32.7524 (35.7185)  loss_n_40: 6.6335 (6.6730)  loss_n_60: 8.5611 (8.6250)  loss_n_80: 8.3684 (8.4608)  loss_n_100: 8.9690 (9.1027)  triple_100: 0.0000 (0.4251)  triple_80: 0.0000 (0.4487)  triple_60: 0.0000 (1.2727)  triple_40: 0.0000 (0.7106)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 200/1724]  eta: 1:39:43  lr: 0.000040  loss: 33.2299 (35.6440)  loss_n_40: 6.6688 (6.6702)  loss_n_60: 8.6010 (8.6190)  loss_n_80: 8.4180 (8.4556)  loss_n_100: 8.9562 (9.0934)  triple_100: 0.0000 (0.4190)  triple_80: 0.0000 (0.4399)  triple_60: 0.0000 (1.2593)  triple_40: 0.0000 (0.6875)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 210/1724]  eta: 1:39:04  lr: 0.000040  loss: 32.5449 (35.5100)  loss_n_40: 6.6738 (6.6713)  loss_n_60: 8.5593 (8.6163)  loss_n_80: 8.4180 (8.4566)  loss_n_100: 8.8441 (9.0878)  triple_100: 0.0000 (0.4008)  triple_80: 0.0000 (0.4190)  triple_60: 0.0000 (1.2026)  triple_40: 0.0000 (0.6557)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 220/1724]  eta: 1:38:25  lr: 0.000040  loss: 32.6183 (35.3939)  loss_n_40: 6.6781 (6.6670)  loss_n_60: 8.5361 (8.6076)  loss_n_80: 8.3484 (8.4486)  loss_n_100: 8.8441 (9.0783)  triple_100: 0.0000 (0.3875)  triple_80: 0.0000 (0.4018)  triple_60: 0.0000 (1.1678)  triple_40: 0.0000 (0.6352)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 230/1724]  eta: 1:37:45  lr: 0.000040  loss: 32.1548 (35.4028)  loss_n_40: 6.5485 (6.6642)  loss_n_60: 8.4123 (8.6025)  loss_n_80: 8.2509 (8.4396)  loss_n_100: 8.8670 (9.0686)  triple_100: 0.0000 (0.4027)  triple_80: 0.0000 (0.4171)  triple_60: 0.0000 (1.1491)  triple_40: 0.0000 (0.6590)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 240/1724]  eta: 1:37:06  lr: 0.000040  loss: 32.1915 (35.3361)  loss_n_40: 6.5808 (6.6640)  loss_n_60: 8.4453 (8.5984)  loss_n_80: 8.2564 (8.4389)  loss_n_100: 8.8670 (9.0647)  triple_100: 0.0000 (0.3862)  triple_80: 0.0000 (0.4090)  triple_60: 0.0000 (1.1293)  triple_40: 0.0000 (0.6456)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 250/1724]  eta: 1:36:27  lr: 0.000040  loss: 32.1915 (35.2201)  loss_n_40: 6.6225 (6.6610)  loss_n_60: 8.4002 (8.5914)  loss_n_80: 8.2227 (8.4290)  loss_n_100: 8.8249 (9.0546)  triple_100: 0.0000 (0.3729)  triple_80: 0.0000 (0.4006)  triple_60: 0.0000 (1.0907)  triple_40: 0.0000 (0.6199)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 260/1724]  eta: 1:35:47  lr: 0.000040  loss: 32.1036 (35.1666)  loss_n_40: 6.5082 (6.6584)  loss_n_60: 8.3777 (8.5856)  loss_n_80: 8.1897 (8.4245)  loss_n_100: 8.7870 (9.0465)  triple_100: 0.0000 (0.3598)  triple_80: 0.0000 (0.3852)  triple_60: 0.0000 (1.0891)  triple_40: 0.0000 (0.6174)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 270/1724]  eta: 1:35:08  lr: 0.000040  loss: 32.4605 (35.1390)  loss_n_40: 6.5623 (6.6589)  loss_n_60: 8.4211 (8.5830)  loss_n_80: 8.3537 (8.4187)  loss_n_100: 8.8433 (9.0382)  triple_100: 0.0000 (0.3576)  triple_80: 0.0000 (0.3850)  triple_60: 0.0000 (1.0938)  triple_40: 0.0000 (0.6039)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 280/1724]  eta: 1:34:29  lr: 0.000040  loss: 32.1255 (35.0646)  loss_n_40: 6.5623 (6.6564)  loss_n_60: 8.4678 (8.5779)  loss_n_80: 8.2866 (8.4147)  loss_n_100: 8.8407 (9.0327)  triple_100: 0.0000 (0.3452)  triple_80: 0.0000 (0.3714)  triple_60: 0.0000 (1.0757)  triple_40: 0.0000 (0.5906)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 290/1724]  eta: 1:33:49  lr: 0.000040  loss: 32.2395 (35.0124)  loss_n_40: 6.5357 (6.6551)  loss_n_60: 8.4089 (8.5742)  loss_n_80: 8.2866 (8.4107)  loss_n_100: 8.8407 (9.0273)  triple_100: 0.0000 (0.3370)  triple_80: 0.0000 (0.3612)  triple_60: 0.0000 (1.0744)  triple_40: 0.0000 (0.5725)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 300/1724]  eta: 1:33:10  lr: 0.000040  loss: 32.1399 (34.9108)  loss_n_40: 6.5082 (6.6505)  loss_n_60: 8.4089 (8.5685)  loss_n_80: 8.1889 (8.4008)  loss_n_100: 8.8339 (9.0171)  triple_100: 0.0000 (0.3287)  triple_80: 0.0000 (0.3492)  triple_60: 0.0000 (1.0426)  triple_40: 0.0000 (0.5535)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 310/1724]  eta: 1:32:31  lr: 0.000040  loss: 32.1399 (34.8533)  loss_n_40: 6.6274 (6.6522)  loss_n_60: 8.4886 (8.5679)  loss_n_80: 8.1230 (8.3944)  loss_n_100: 8.7594 (9.0098)  triple_100: 0.0000 (0.3211)  triple_80: 0.0000 (0.3379)  triple_60: 0.0000 (1.0262)  triple_40: 0.0000 (0.5438)  time: 3.9254  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [ 320/1724]  eta: 1:31:51  lr: 0.000040  loss: 32.6391 (34.8549)  loss_n_40: 6.6710 (6.6530)  loss_n_60: 8.4920 (8.5655)  loss_n_80: 8.3101 (8.3910)  loss_n_100: 8.8899 (9.0041)  triple_100: 0.0000 (0.3175)  triple_80: 0.0000 (0.3476)  triple_60: 0.0000 (1.0302)  triple_40: 0.0000 (0.5459)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 330/1724]  eta: 1:31:12  lr: 0.000040  loss: 32.2400 (34.7705)  loss_n_40: 6.5435 (6.6477)  loss_n_60: 8.3485 (8.5573)  loss_n_80: 8.3101 (8.3824)  loss_n_100: 8.8707 (8.9942)  triple_100: 0.0000 (0.3195)  triple_80: 0.0000 (0.3398)  triple_60: 0.0000 (1.0002)  triple_40: 0.0000 (0.5294)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 340/1724]  eta: 1:30:33  lr: 0.000040  loss: 31.4682 (34.8295)  loss_n_40: 6.4576 (6.6447)  loss_n_60: 8.2403 (8.5501)  loss_n_80: 8.0779 (8.3751)  loss_n_100: 8.6026 (8.9836)  triple_100: 0.0000 (0.3385)  triple_80: 0.0000 (0.3645)  triple_60: 0.0000 (1.0090)  triple_40: 0.0000 (0.5639)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 350/1724]  eta: 1:29:54  lr: 0.000040  loss: 32.0182 (34.8592)  loss_n_40: 6.5501 (6.6452)  loss_n_60: 8.3195 (8.5469)  loss_n_80: 8.2382 (8.3733)  loss_n_100: 8.7133 (8.9778)  triple_100: 0.0000 (0.3589)  triple_80: 0.0000 (0.3865)  triple_60: 0.0000 (1.0094)  triple_40: 0.0000 (0.5613)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 360/1724]  eta: 1:29:14  lr: 0.000040  loss: 32.2307 (34.7820)  loss_n_40: 6.6783 (6.6450)  loss_n_60: 8.3921 (8.5427)  loss_n_80: 8.1907 (8.3651)  loss_n_100: 8.7133 (8.9678)  triple_100: 0.0000 (0.3544)  triple_80: 0.0000 (0.3778)  triple_60: 0.0000 (0.9835)  triple_40: 0.0000 (0.5457)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 370/1724]  eta: 1:28:35  lr: 0.000040  loss: 31.8883 (34.7166)  loss_n_40: 6.6359 (6.6436)  loss_n_60: 8.3921 (8.5381)  loss_n_80: 8.0819 (8.3587)  loss_n_100: 8.6306 (8.9604)  triple_100: 0.0000 (0.3448)  triple_80: 0.0000 (0.3686)  triple_60: 0.0000 (0.9667)  triple_40: 0.0000 (0.5357)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 380/1724]  eta: 1:27:56  lr: 0.000040  loss: 31.8883 (34.6519)  loss_n_40: 6.6370 (6.6427)  loss_n_60: 8.3594 (8.5323)  loss_n_80: 8.0902 (8.3502)  loss_n_100: 8.5899 (8.9509)  triple_100: 0.0000 (0.3386)  triple_80: 0.0000 (0.3618)  triple_60: 0.0000 (0.9538)  triple_40: 0.0000 (0.5216)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 390/1724]  eta: 1:27:16  lr: 0.000040  loss: 31.5160 (34.6439)  loss_n_40: 6.5632 (6.6379)  loss_n_60: 8.2589 (8.5243)  loss_n_80: 7.9712 (8.3400)  loss_n_100: 8.5136 (8.9390)  triple_100: 0.0000 (0.3437)  triple_80: 0.0000 (0.3757)  triple_60: 0.0000 (0.9589)  triple_40: 0.0000 (0.5244)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 400/1724]  eta: 1:26:37  lr: 0.000040  loss: 31.8204 (34.5977)  loss_n_40: 6.5087 (6.6384)  loss_n_60: 8.2566 (8.5206)  loss_n_80: 7.9810 (8.3378)  loss_n_100: 8.5627 (8.9345)  triple_100: 0.0000 (0.3372)  triple_80: 0.0000 (0.3678)  triple_60: 0.0000 (0.9445)  triple_40: 0.0000 (0.5169)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 410/1724]  eta: 1:25:58  lr: 0.000040  loss: 31.7353 (34.5263)  loss_n_40: 6.5100 (6.6348)  loss_n_60: 8.2618 (8.5140)  loss_n_80: 8.0808 (8.3313)  loss_n_100: 8.5901 (8.9260)  triple_100: 0.0000 (0.3299)  triple_80: 0.0000 (0.3589)  triple_60: 0.0000 (0.9267)  triple_40: 0.0000 (0.5049)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 420/1724]  eta: 1:25:19  lr: 0.000040  loss: 31.7353 (34.4908)  loss_n_40: 6.5100 (6.6358)  loss_n_60: 8.2618 (8.5114)  loss_n_80: 8.0243 (8.3251)  loss_n_100: 8.5667 (8.9181)  triple_100: 0.0000 (0.3301)  triple_80: 0.0000 (0.3519)  triple_60: 0.0000 (0.9221)  triple_40: 0.0000 (0.4964)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 430/1724]  eta: 1:24:39  lr: 0.000040  loss: 31.9826 (34.4687)  loss_n_40: 6.6694 (6.6361)  loss_n_60: 8.4420 (8.5087)  loss_n_80: 8.0437 (8.3190)  loss_n_100: 8.5669 (8.9105)  triple_100: 0.0000 (0.3236)  triple_80: 0.0000 (0.3501)  triple_60: 0.0000 (0.9265)  triple_40: 0.0000 (0.4941)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 440/1724]  eta: 1:24:00  lr: 0.000040  loss: 31.6998 (34.4033)  loss_n_40: 6.6044 (6.6336)  loss_n_60: 8.3633 (8.5033)  loss_n_80: 8.0846 (8.3129)  loss_n_100: 8.6158 (8.9032)  triple_100: 0.0000 (0.3174)  triple_80: 0.0000 (0.3422)  triple_60: 0.0000 (0.9077)  triple_40: 0.0000 (0.4829)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 450/1724]  eta: 1:23:21  lr: 0.000040  loss: 31.7310 (34.4155)  loss_n_40: 6.6044 (6.6358)  loss_n_60: 8.3416 (8.5009)  loss_n_80: 8.1212 (8.3100)  loss_n_100: 8.6839 (8.8981)  triple_100: 0.0000 (0.3172)  triple_80: 0.0000 (0.3464)  triple_60: 0.0000 (0.9215)  triple_40: 0.0000 (0.4855)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 460/1724]  eta: 1:22:42  lr: 0.000040  loss: 32.0195 (34.3830)  loss_n_40: 6.6937 (6.6384)  loss_n_60: 8.3825 (8.4988)  loss_n_80: 8.0979 (8.3042)  loss_n_100: 8.6422 (8.8900)  triple_100: 0.0000 (0.3148)  triple_80: 0.0000 (0.3390)  triple_60: 0.0000 (0.9172)  triple_40: 0.0000 (0.4807)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 470/1724]  eta: 1:22:02  lr: 0.000040  loss: 31.5926 (34.3240)  loss_n_40: 6.5876 (6.6364)  loss_n_60: 8.2478 (8.4923)  loss_n_80: 7.9541 (8.2990)  loss_n_100: 8.4996 (8.8821)  triple_100: 0.0000 (0.3091)  triple_80: 0.0000 (0.3318)  triple_60: 0.0000 (0.9029)  triple_40: 0.0000 (0.4704)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 480/1724]  eta: 1:21:23  lr: 0.000040  loss: 31.0912 (34.2562)  loss_n_40: 6.5047 (6.6328)  loss_n_60: 8.1763 (8.4849)  loss_n_80: 8.0938 (8.2928)  loss_n_100: 8.4610 (8.8734)  triple_100: 0.0000 (0.3027)  triple_80: 0.0000 (0.3249)  triple_60: 0.0000 (0.8841)  triple_40: 0.0000 (0.4607)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 490/1724]  eta: 1:20:44  lr: 0.000040  loss: 31.1636 (34.2532)  loss_n_40: 6.4775 (6.6299)  loss_n_60: 8.1111 (8.4784)  loss_n_80: 8.0849 (8.2879)  loss_n_100: 8.4711 (8.8665)  triple_100: 0.0000 (0.3098)  triple_80: 0.0000 (0.3342)  triple_60: 0.0000 (0.8860)  triple_40: 0.0000 (0.4604)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 500/1724]  eta: 1:20:05  lr: 0.000040  loss: 31.7126 (34.2207)  loss_n_40: 6.5855 (6.6299)  loss_n_60: 8.1822 (8.4740)  loss_n_80: 7.9667 (8.2815)  loss_n_100: 8.4962 (8.8580)  triple_100: 0.0000 (0.3101)  triple_80: 0.0000 (0.3380)  triple_60: 0.0000 (0.8781)  triple_40: 0.0000 (0.4512)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 510/1724]  eta: 1:19:25  lr: 0.000040  loss: 31.6199 (34.2033)  loss_n_40: 6.5693 (6.6269)  loss_n_60: 8.1822 (8.4678)  loss_n_80: 7.9325 (8.2746)  loss_n_100: 8.4110 (8.8484)  triple_100: 0.0000 (0.3085)  triple_80: 0.0000 (0.3362)  triple_60: 0.0000 (0.8891)  triple_40: 0.0000 (0.4517)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 520/1724]  eta: 1:18:46  lr: 0.000040  loss: 31.9671 (34.2038)  loss_n_40: 6.5467 (6.6267)  loss_n_60: 8.1876 (8.4633)  loss_n_80: 8.0014 (8.2703)  loss_n_100: 8.4242 (8.8419)  triple_100: 0.0000 (0.3099)  triple_80: 0.0000 (0.3380)  triple_60: 0.0000 (0.9022)  triple_40: 0.0000 (0.4514)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 530/1724]  eta: 1:18:07  lr: 0.000040  loss: 31.9388 (34.1773)  loss_n_40: 6.5701 (6.6272)  loss_n_60: 8.2459 (8.4600)  loss_n_80: 8.0126 (8.2630)  loss_n_100: 8.4568 (8.8333)  triple_100: 0.0000 (0.3091)  triple_80: 0.0000 (0.3323)  triple_60: 0.4041 (0.9006)  triple_40: 0.0000 (0.4518)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 540/1724]  eta: 1:17:27  lr: 0.000040  loss: 31.9070 (34.2842)  loss_n_40: 6.6388 (6.6293)  loss_n_60: 8.2958 (8.4585)  loss_n_80: 7.9500 (8.2603)  loss_n_100: 8.4563 (8.8285)  triple_100: 0.0000 (0.3359)  triple_80: 0.0000 (0.3584)  triple_60: 0.0000 (0.9134)  triple_40: 0.0000 (0.5000)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 550/1724]  eta: 1:16:48  lr: 0.000040  loss: 31.9842 (34.2407)  loss_n_40: 6.7307 (6.6294)  loss_n_60: 8.3135 (8.4550)  loss_n_80: 8.0387 (8.2558)  loss_n_100: 8.4681 (8.8214)  triple_100: 0.0000 (0.3370)  triple_80: 0.0000 (0.3520)  triple_60: 0.0000 (0.8991)  triple_40: 0.0000 (0.4909)  time: 3.9244  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [ 560/1724]  eta: 1:16:09  lr: 0.000040  loss: 31.7297 (34.2435)  loss_n_40: 6.6491 (6.6286)  loss_n_60: 8.2424 (8.4511)  loss_n_80: 8.0283 (8.2515)  loss_n_100: 8.4557 (8.8146)  triple_100: 0.0000 (0.3444)  triple_80: 0.0000 (0.3579)  triple_60: 0.0000 (0.8945)  triple_40: 0.0000 (0.5007)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 570/1724]  eta: 1:15:30  lr: 0.000040  loss: 31.7297 (34.2218)  loss_n_40: 6.6491 (6.6308)  loss_n_60: 8.2444 (8.4491)  loss_n_80: 8.0105 (8.2484)  loss_n_100: 8.5139 (8.8091)  triple_100: 0.0000 (0.3410)  triple_80: 0.0000 (0.3545)  triple_60: 0.0000 (0.8919)  triple_40: 0.0000 (0.4971)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 580/1724]  eta: 1:14:50  lr: 0.000040  loss: 31.7513 (34.1801)  loss_n_40: 6.6367 (6.6290)  loss_n_60: 8.2444 (8.4448)  loss_n_80: 8.0090 (8.2453)  loss_n_100: 8.5139 (8.8026)  triple_100: 0.0000 (0.3365)  triple_80: 0.0000 (0.3490)  triple_60: 0.0000 (0.8822)  triple_40: 0.0000 (0.4908)  time: 3.9270  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:3]  [ 590/1724]  eta: 1:14:11  lr: 0.000040  loss: 31.8727 (34.1419)  loss_n_40: 6.6458 (6.6322)  loss_n_60: 8.2666 (8.4440)  loss_n_80: 8.0629 (8.2428)  loss_n_100: 8.4298 (8.7975)  triple_100: 0.0000 (0.3308)  triple_80: 0.0000 (0.3431)  triple_60: 0.0000 (0.8672)  triple_40: 0.0000 (0.4841)  time: 3.9249  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:3]  [ 600/1724]  eta: 1:13:32  lr: 0.000040  loss: 31.7697 (34.0966)  loss_n_40: 6.6138 (6.6298)  loss_n_60: 8.2316 (8.4385)  loss_n_80: 8.0581 (8.2366)  loss_n_100: 8.3932 (8.7888)  triple_100: 0.0000 (0.3264)  triple_80: 0.0000 (0.3377)  triple_60: 0.0000 (0.8627)  triple_40: 0.0000 (0.4761)  time: 3.9256  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:3]  [ 610/1724]  eta: 1:12:53  lr: 0.000040  loss: 30.8080 (34.0616)  loss_n_40: 6.4816 (6.6306)  loss_n_60: 8.1147 (8.4352)  loss_n_80: 7.8476 (8.2297)  loss_n_100: 8.1639 (8.7795)  triple_100: 0.0000 (0.3217)  triple_80: 0.0000 (0.3322)  triple_60: 0.0000 (0.8604)  triple_40: 0.0000 (0.4723)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 620/1724]  eta: 1:12:13  lr: 0.000040  loss: 31.3055 (34.0172)  loss_n_40: 6.5438 (6.6289)  loss_n_60: 8.1577 (8.4300)  loss_n_80: 7.9207 (8.2264)  loss_n_100: 8.3342 (8.7744)  triple_100: 0.0000 (0.3174)  triple_80: 0.0000 (0.3268)  triple_60: 0.0000 (0.8486)  triple_40: 0.0000 (0.4646)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 630/1724]  eta: 1:11:34  lr: 0.000040  loss: 31.3787 (33.9812)  loss_n_40: 6.5580 (6.6290)  loss_n_60: 8.1669 (8.4270)  loss_n_80: 7.9536 (8.2207)  loss_n_100: 8.4190 (8.7675)  triple_100: 0.0000 (0.3129)  triple_80: 0.0000 (0.3216)  triple_60: 0.0000 (0.8431)  triple_40: 0.0000 (0.4594)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 640/1724]  eta: 1:10:55  lr: 0.000040  loss: 31.3787 (33.9383)  loss_n_40: 6.5853 (6.6282)  loss_n_60: 8.1897 (8.4230)  loss_n_80: 7.8945 (8.2164)  loss_n_100: 8.3309 (8.7614)  triple_100: 0.0000 (0.3081)  triple_80: 0.0000 (0.3166)  triple_60: 0.0000 (0.8324)  triple_40: 0.0000 (0.4522)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 650/1724]  eta: 1:10:15  lr: 0.000040  loss: 30.8834 (33.8936)  loss_n_40: 6.6086 (6.6281)  loss_n_60: 8.1471 (8.4189)  loss_n_80: 7.9020 (8.2116)  loss_n_100: 8.2887 (8.7545)  triple_100: 0.0000 (0.3039)  triple_80: 0.0000 (0.3117)  triple_60: 0.0000 (0.8196)  triple_40: 0.0000 (0.4453)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 660/1724]  eta: 1:09:36  lr: 0.000040  loss: 31.0327 (33.8532)  loss_n_40: 6.6372 (6.6277)  loss_n_60: 8.1468 (8.4145)  loss_n_80: 7.9020 (8.2066)  loss_n_100: 8.2625 (8.7474)  triple_100: 0.0000 (0.3024)  triple_80: 0.0000 (0.3080)  triple_60: 0.0000 (0.8079)  triple_40: 0.0000 (0.4386)  time: 3.9242  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:3]  [ 670/1724]  eta: 1:08:57  lr: 0.000040  loss: 30.5705 (33.8033)  loss_n_40: 6.4407 (6.6247)  loss_n_60: 8.0195 (8.4083)  loss_n_80: 7.8573 (8.1997)  loss_n_100: 8.2498 (8.7379)  triple_100: 0.0000 (0.2987)  triple_80: 0.0000 (0.3034)  triple_60: 0.0000 (0.7986)  triple_40: 0.0000 (0.4320)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 680/1724]  eta: 1:08:18  lr: 0.000040  loss: 30.5705 (33.7594)  loss_n_40: 6.4038 (6.6230)  loss_n_60: 8.0067 (8.4031)  loss_n_80: 7.7777 (8.1950)  loss_n_100: 8.1594 (8.7313)  triple_100: 0.0000 (0.2948)  triple_80: 0.0000 (0.2991)  triple_60: 0.0000 (0.7875)  triple_40: 0.0000 (0.4257)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 690/1724]  eta: 1:07:38  lr: 0.000040  loss: 30.9894 (33.7503)  loss_n_40: 6.5672 (6.6220)  loss_n_60: 8.0971 (8.3981)  loss_n_80: 7.7892 (8.1894)  loss_n_100: 8.1875 (8.7240)  triple_100: 0.0000 (0.2955)  triple_80: 0.0000 (0.3046)  triple_60: 0.0000 (0.7906)  triple_40: 0.0000 (0.4262)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 700/1724]  eta: 1:06:59  lr: 0.000040  loss: 31.1406 (33.7261)  loss_n_40: 6.5545 (6.6215)  loss_n_60: 8.0798 (8.3937)  loss_n_80: 7.8598 (8.1853)  loss_n_100: 8.2093 (8.7182)  triple_100: 0.0000 (0.2920)  triple_80: 0.0000 (0.3003)  triple_60: 0.0000 (0.7903)  triple_40: 0.0000 (0.4249)  time: 3.9243  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 710/1724]  eta: 1:06:20  lr: 0.000040  loss: 30.9382 (33.7077)  loss_n_40: 6.5545 (6.6208)  loss_n_60: 8.0734 (8.3887)  loss_n_80: 7.8617 (8.1808)  loss_n_100: 8.3267 (8.7123)  triple_100: 0.0000 (0.2905)  triple_80: 0.0000 (0.2996)  triple_60: 0.0000 (0.7916)  triple_40: 0.0000 (0.4233)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 720/1724]  eta: 1:05:41  lr: 0.000040  loss: 30.7972 (33.6813)  loss_n_40: 6.5399 (6.6199)  loss_n_60: 7.9829 (8.3832)  loss_n_80: 7.7890 (8.1750)  loss_n_100: 8.2492 (8.7053)  triple_100: 0.0000 (0.2870)  triple_80: 0.0000 (0.2969)  triple_60: 0.0000 (0.7930)  triple_40: 0.0000 (0.4210)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 730/1724]  eta: 1:05:01  lr: 0.000040  loss: 31.2916 (33.6546)  loss_n_40: 6.5776 (6.6199)  loss_n_60: 8.0063 (8.3795)  loss_n_80: 7.8868 (8.1720)  loss_n_100: 8.2765 (8.7008)  triple_100: 0.0000 (0.2837)  triple_80: 0.0000 (0.2929)  triple_60: 0.0000 (0.7891)  triple_40: 0.0000 (0.4167)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 740/1724]  eta: 1:04:22  lr: 0.000040  loss: 31.5967 (33.6247)  loss_n_40: 6.6703 (6.6198)  loss_n_60: 8.1362 (8.3763)  loss_n_80: 7.8868 (8.1673)  loss_n_100: 8.2765 (8.6949)  triple_100: 0.0000 (0.2818)  triple_80: 0.0000 (0.2897)  triple_60: 0.0000 (0.7838)  triple_40: 0.0000 (0.4110)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 750/1724]  eta: 1:03:43  lr: 0.000040  loss: 30.9601 (33.5875)  loss_n_40: 6.6023 (6.6182)  loss_n_60: 8.0572 (8.3714)  loss_n_80: 7.8625 (8.1640)  loss_n_100: 8.3247 (8.6904)  triple_100: 0.0000 (0.2780)  triple_80: 0.0000 (0.2859)  triple_60: 0.0000 (0.7740)  triple_40: 0.0000 (0.4056)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 760/1724]  eta: 1:03:04  lr: 0.000040  loss: 30.6525 (33.5841)  loss_n_40: 6.5087 (6.6176)  loss_n_60: 7.9492 (8.3665)  loss_n_80: 7.8194 (8.1578)  loss_n_100: 8.1733 (8.6826)  triple_100: 0.0000 (0.2781)  triple_80: 0.0000 (0.2889)  triple_60: 0.0000 (0.7809)  triple_40: 0.0000 (0.4117)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 770/1724]  eta: 1:02:24  lr: 0.000040  loss: 30.3806 (33.5415)  loss_n_40: 6.4380 (6.6157)  loss_n_60: 7.9492 (8.3610)  loss_n_80: 7.6242 (8.1511)  loss_n_100: 8.1052 (8.6748)  triple_100: 0.0000 (0.2764)  triple_80: 0.0000 (0.2853)  triple_60: 0.0000 (0.7709)  triple_40: 0.0000 (0.4063)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 780/1724]  eta: 1:01:45  lr: 0.000040  loss: 30.1832 (33.5150)  loss_n_40: 6.4211 (6.6136)  loss_n_60: 7.9189 (8.3553)  loss_n_80: 7.6197 (8.1447)  loss_n_100: 8.0526 (8.6674)  triple_100: 0.0000 (0.2765)  triple_80: 0.0000 (0.2831)  triple_60: 0.0000 (0.7709)  triple_40: 0.0000 (0.4034)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 790/1724]  eta: 1:01:06  lr: 0.000040  loss: 30.7675 (33.5022)  loss_n_40: 6.5110 (6.6136)  loss_n_60: 8.0025 (8.3520)  loss_n_80: 7.7025 (8.1401)  loss_n_100: 8.1634 (8.6610)  triple_100: 0.0000 (0.2749)  triple_80: 0.0000 (0.2835)  triple_60: 0.0000 (0.7735)  triple_40: 0.0000 (0.4035)  time: 3.9258  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [ 800/1724]  eta: 1:00:27  lr: 0.000040  loss: 30.7907 (33.5002)  loss_n_40: 6.5953 (6.6127)  loss_n_60: 8.0244 (8.3472)  loss_n_80: 7.7101 (8.1341)  loss_n_100: 8.0947 (8.6535)  triple_100: 0.0000 (0.2781)  triple_80: 0.0000 (0.2913)  triple_60: 0.0000 (0.7789)  triple_40: 0.0000 (0.4043)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 810/1724]  eta: 0:59:47  lr: 0.000040  loss: 30.2637 (33.4651)  loss_n_40: 6.5620 (6.6113)  loss_n_60: 7.9795 (8.3426)  loss_n_80: 7.6914 (8.1307)  loss_n_100: 8.0856 (8.6484)  triple_100: 0.0000 (0.2747)  triple_80: 0.0000 (0.2877)  triple_60: 0.0000 (0.7702)  triple_40: 0.0000 (0.3993)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 820/1724]  eta: 0:59:08  lr: 0.000040  loss: 30.5254 (33.4725)  loss_n_40: 6.4369 (6.6101)  loss_n_60: 7.9046 (8.3378)  loss_n_80: 7.6905 (8.1259)  loss_n_100: 8.1508 (8.6421)  triple_100: 0.0000 (0.2819)  triple_80: 0.0000 (0.2942)  triple_60: 0.0000 (0.7808)  triple_40: 0.0000 (0.3998)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 830/1724]  eta: 0:58:29  lr: 0.000040  loss: 30.4974 (33.4397)  loss_n_40: 6.3987 (6.6085)  loss_n_60: 7.9046 (8.3330)  loss_n_80: 7.6692 (8.1202)  loss_n_100: 8.0174 (8.6343)  triple_100: 0.0000 (0.2814)  triple_80: 0.0000 (0.2914)  triple_60: 0.0000 (0.7760)  triple_40: 0.0000 (0.3950)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 840/1724]  eta: 0:57:50  lr: 0.000040  loss: 30.1710 (33.4046)  loss_n_40: 6.5078 (6.6075)  loss_n_60: 7.9239 (8.3283)  loss_n_80: 7.7397 (8.1157)  loss_n_100: 8.1101 (8.6279)  triple_100: 0.0000 (0.2780)  triple_80: 0.0000 (0.2879)  triple_60: 0.0000 (0.7690)  triple_40: 0.0000 (0.3903)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 850/1724]  eta: 0:57:10  lr: 0.000040  loss: 30.6293 (33.4264)  loss_n_40: 6.5180 (6.6072)  loss_n_60: 7.9542 (8.3241)  loss_n_80: 7.7109 (8.1118)  loss_n_100: 8.0838 (8.6223)  triple_100: 0.0000 (0.2873)  triple_80: 0.0000 (0.2930)  triple_60: 0.0000 (0.7752)  triple_40: 0.0000 (0.4053)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 860/1724]  eta: 0:56:31  lr: 0.000040  loss: 30.3960 (33.3868)  loss_n_40: 6.4830 (6.6045)  loss_n_60: 7.8770 (8.3184)  loss_n_80: 7.6843 (8.1050)  loss_n_100: 7.9831 (8.6143)  triple_100: 0.0000 (0.2849)  triple_80: 0.0000 (0.2896)  triple_60: 0.0000 (0.7694)  triple_40: 0.0000 (0.4006)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 870/1724]  eta: 0:55:52  lr: 0.000040  loss: 30.3646 (33.3535)  loss_n_40: 6.3456 (6.6032)  loss_n_60: 7.8350 (8.3135)  loss_n_80: 7.7280 (8.0999)  loss_n_100: 8.0431 (8.6089)  triple_100: 0.0000 (0.2819)  triple_80: 0.0000 (0.2863)  triple_60: 0.0000 (0.7638)  triple_40: 0.0000 (0.3960)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 880/1724]  eta: 0:55:13  lr: 0.000040  loss: 30.3646 (33.3287)  loss_n_40: 6.3351 (6.6007)  loss_n_60: 7.8273 (8.3077)  loss_n_80: 7.5557 (8.0938)  loss_n_100: 8.0431 (8.6024)  triple_100: 0.0000 (0.2812)  triple_80: 0.0000 (0.2856)  triple_60: 0.0000 (0.7634)  triple_40: 0.0000 (0.3939)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 890/1724]  eta: 0:54:33  lr: 0.000040  loss: 29.9811 (33.3324)  loss_n_40: 6.4331 (6.6002)  loss_n_60: 7.7945 (8.3036)  loss_n_80: 7.5557 (8.0890)  loss_n_100: 7.9805 (8.5967)  triple_100: 0.0000 (0.2863)  triple_80: 0.0000 (0.2884)  triple_60: 0.0000 (0.7690)  triple_40: 0.0000 (0.3992)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 900/1724]  eta: 0:53:54  lr: 0.000040  loss: 30.5933 (33.3053)  loss_n_40: 6.5577 (6.5998)  loss_n_60: 7.9106 (8.2996)  loss_n_80: 7.5861 (8.0835)  loss_n_100: 8.0430 (8.5901)  triple_100: 0.0000 (0.2860)  triple_80: 0.0000 (0.2852)  triple_60: 0.0000 (0.7664)  triple_40: 0.0000 (0.3949)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 910/1724]  eta: 0:53:15  lr: 0.000040  loss: 30.2834 (33.2707)  loss_n_40: 6.4848 (6.5979)  loss_n_60: 7.8887 (8.2941)  loss_n_80: 7.5592 (8.0777)  loss_n_100: 7.9751 (8.5836)  triple_100: 0.0000 (0.2830)  triple_80: 0.0000 (0.2823)  triple_60: 0.0000 (0.7610)  triple_40: 0.0000 (0.3912)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 920/1724]  eta: 0:52:36  lr: 0.000040  loss: 30.1947 (33.2371)  loss_n_40: 6.4912 (6.5973)  loss_n_60: 7.8762 (8.2895)  loss_n_80: 7.4894 (8.0721)  loss_n_100: 7.9751 (8.5774)  triple_100: 0.0000 (0.2800)  triple_80: 0.0000 (0.2792)  triple_60: 0.0000 (0.7547)  triple_40: 0.0000 (0.3870)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 930/1724]  eta: 0:51:56  lr: 0.000040  loss: 29.9466 (33.2098)  loss_n_40: 6.4912 (6.5956)  loss_n_60: 7.8704 (8.2842)  loss_n_80: 7.5874 (8.0673)  loss_n_100: 7.9555 (8.5716)  triple_100: 0.0000 (0.2774)  triple_80: 0.0000 (0.2771)  triple_60: 0.0000 (0.7524)  triple_40: 0.0000 (0.3842)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 940/1724]  eta: 0:51:17  lr: 0.000040  loss: 29.7386 (33.1697)  loss_n_40: 6.3685 (6.5922)  loss_n_60: 7.8046 (8.2775)  loss_n_80: 7.5801 (8.0610)  loss_n_100: 7.9555 (8.5650)  triple_100: 0.0000 (0.2749)  triple_80: 0.0000 (0.2742)  triple_60: 0.0000 (0.7447)  triple_40: 0.0000 (0.3801)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 950/1724]  eta: 0:50:38  lr: 0.000040  loss: 29.6938 (33.1370)  loss_n_40: 6.3100 (6.5902)  loss_n_60: 7.6659 (8.2723)  loss_n_80: 7.4690 (8.0554)  loss_n_100: 7.9634 (8.5589)  triple_100: 0.0000 (0.2727)  triple_80: 0.0000 (0.2713)  triple_60: 0.0000 (0.7399)  triple_40: 0.0000 (0.3764)  time: 3.9267  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:3]  [ 960/1724]  eta: 0:49:59  lr: 0.000040  loss: 29.7513 (33.1048)  loss_n_40: 6.3388 (6.5889)  loss_n_60: 7.6766 (8.2673)  loss_n_80: 7.4534 (8.0491)  loss_n_100: 7.9197 (8.5522)  triple_100: 0.0000 (0.2715)  triple_80: 0.0000 (0.2685)  triple_60: 0.0000 (0.7328)  triple_40: 0.0000 (0.3745)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 970/1724]  eta: 0:49:19  lr: 0.000040  loss: 29.7513 (33.0738)  loss_n_40: 6.4574 (6.5879)  loss_n_60: 7.7826 (8.2625)  loss_n_80: 7.4534 (8.0439)  loss_n_100: 7.8972 (8.5465)  triple_100: 0.0000 (0.2699)  triple_80: 0.0000 (0.2657)  triple_60: 0.0000 (0.7268)  triple_40: 0.0000 (0.3706)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 980/1724]  eta: 0:48:40  lr: 0.000040  loss: 29.6555 (33.0371)  loss_n_40: 6.3034 (6.5857)  loss_n_60: 7.6815 (8.2569)  loss_n_80: 7.4445 (8.0378)  loss_n_100: 7.9217 (8.5403)  triple_100: 0.0000 (0.2672)  triple_80: 0.0000 (0.2630)  triple_60: 0.0000 (0.7194)  triple_40: 0.0000 (0.3669)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [ 990/1724]  eta: 0:48:01  lr: 0.000040  loss: 29.2392 (33.0026)  loss_n_40: 6.2970 (6.5840)  loss_n_60: 7.6160 (8.2514)  loss_n_80: 7.3818 (8.0318)  loss_n_100: 7.9149 (8.5346)  triple_100: 0.0000 (0.2653)  triple_80: 0.0000 (0.2604)  triple_60: 0.0000 (0.7121)  triple_40: 0.0000 (0.3632)  time: 3.9263  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:3]  [1000/1724]  eta: 0:47:22  lr: 0.000040  loss: 29.1249 (32.9754)  loss_n_40: 6.3367 (6.5816)  loss_n_60: 7.6018 (8.2457)  loss_n_80: 7.3617 (8.0258)  loss_n_100: 7.8689 (8.5279)  triple_100: 0.0000 (0.2649)  triple_80: 0.0000 (0.2580)  triple_60: 0.0000 (0.7081)  triple_40: 0.0000 (0.3632)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1010/1724]  eta: 0:46:42  lr: 0.000040  loss: 29.4767 (32.9440)  loss_n_40: 6.3367 (6.5805)  loss_n_60: 7.6708 (8.2408)  loss_n_80: 7.3935 (8.0199)  loss_n_100: 7.8286 (8.5215)  triple_100: 0.0000 (0.2639)  triple_80: 0.0000 (0.2555)  triple_60: 0.0000 (0.7021)  triple_40: 0.0000 (0.3596)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1020/1724]  eta: 0:46:03  lr: 0.000040  loss: 29.4767 (32.9089)  loss_n_40: 6.5143 (6.5798)  loss_n_60: 7.6883 (8.2361)  loss_n_80: 7.3168 (8.0128)  loss_n_100: 7.7970 (8.5145)  triple_100: 0.0000 (0.2614)  triple_80: 0.0000 (0.2530)  triple_60: 0.0000 (0.6952)  triple_40: 0.0000 (0.3561)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1030/1724]  eta: 0:45:24  lr: 0.000040  loss: 29.8456 (32.9240)  loss_n_40: 6.6070 (6.5797)  loss_n_60: 7.7142 (8.2312)  loss_n_80: 7.3770 (8.0077)  loss_n_100: 7.7875 (8.5093)  triple_100: 0.0000 (0.2687)  triple_80: 0.0000 (0.2615)  triple_60: 0.0000 (0.7048)  triple_40: 0.0000 (0.3611)  time: 3.9270  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [1040/1724]  eta: 0:44:45  lr: 0.000040  loss: 30.1988 (32.8946)  loss_n_40: 6.5931 (6.5793)  loss_n_60: 7.7493 (8.2265)  loss_n_80: 7.3786 (8.0020)  loss_n_100: 7.8231 (8.5036)  triple_100: 0.0000 (0.2665)  triple_80: 0.0000 (0.2590)  triple_60: 0.0000 (0.7000)  triple_40: 0.0000 (0.3577)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1050/1724]  eta: 0:44:05  lr: 0.000040  loss: 29.4190 (32.8598)  loss_n_40: 6.5045 (6.5777)  loss_n_60: 7.7269 (8.2214)  loss_n_80: 7.2900 (7.9951)  loss_n_100: 7.7733 (8.4968)  triple_100: 0.0000 (0.2640)  triple_80: 0.0000 (0.2565)  triple_60: 0.0000 (0.6940)  triple_40: 0.0000 (0.3543)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1060/1724]  eta: 0:43:26  lr: 0.000040  loss: 28.7003 (32.8278)  loss_n_40: 6.4264 (6.5749)  loss_n_60: 7.6526 (8.2152)  loss_n_80: 7.1963 (7.9876)  loss_n_100: 7.6742 (8.4890)  triple_100: 0.0000 (0.2623)  triple_80: 0.0000 (0.2565)  triple_60: 0.0000 (0.6905)  triple_40: 0.0000 (0.3519)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1070/1724]  eta: 0:42:47  lr: 0.000040  loss: 28.7955 (32.7997)  loss_n_40: 6.2997 (6.5728)  loss_n_60: 7.5971 (8.2091)  loss_n_80: 7.1560 (7.9809)  loss_n_100: 7.6343 (8.4824)  triple_100: 0.0000 (0.2608)  triple_80: 0.0000 (0.2549)  triple_60: 0.0000 (0.6893)  triple_40: 0.0000 (0.3497)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1080/1724]  eta: 0:42:08  lr: 0.000040  loss: 28.8269 (32.7727)  loss_n_40: 6.3470 (6.5708)  loss_n_60: 7.5435 (8.2032)  loss_n_80: 7.1238 (7.9738)  loss_n_100: 7.6343 (8.4753)  triple_100: 0.0000 (0.2595)  triple_80: 0.0000 (0.2526)  triple_60: 0.0000 (0.6892)  triple_40: 0.0000 (0.3485)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1090/1724]  eta: 0:41:28  lr: 0.000040  loss: 29.1358 (32.7514)  loss_n_40: 6.4035 (6.5694)  loss_n_60: 7.6255 (8.1984)  loss_n_80: 7.2439 (7.9680)  loss_n_100: 7.7161 (8.4690)  triple_100: 0.0000 (0.2607)  triple_80: 0.0000 (0.2520)  triple_60: 0.0000 (0.6882)  triple_40: 0.0000 (0.3457)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1100/1724]  eta: 0:40:49  lr: 0.000040  loss: 29.6290 (32.7267)  loss_n_40: 6.4016 (6.5683)  loss_n_60: 7.6187 (8.1935)  loss_n_80: 7.3033 (7.9629)  loss_n_100: 7.8384 (8.4636)  triple_100: 0.0000 (0.2588)  triple_80: 0.0000 (0.2501)  triple_60: 0.0000 (0.6861)  triple_40: 0.0000 (0.3434)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1110/1724]  eta: 0:40:10  lr: 0.000040  loss: 29.6290 (32.7067)  loss_n_40: 6.4016 (6.5670)  loss_n_60: 7.6159 (8.1884)  loss_n_80: 7.3764 (7.9575)  loss_n_100: 7.8307 (8.4577)  triple_100: 0.0000 (0.2579)  triple_80: 0.0000 (0.2493)  triple_60: 0.0000 (0.6876)  triple_40: 0.0000 (0.3412)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1120/1724]  eta: 0:39:31  lr: 0.000040  loss: 29.6873 (32.6804)  loss_n_40: 6.4886 (6.5660)  loss_n_60: 7.6757 (8.1838)  loss_n_80: 7.3028 (7.9526)  loss_n_100: 7.7577 (8.4526)  triple_100: 0.0000 (0.2556)  triple_80: 0.0000 (0.2470)  triple_60: 0.0000 (0.6846)  triple_40: 0.0000 (0.3382)  time: 3.9265  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:3]  [1130/1724]  eta: 0:38:51  lr: 0.000040  loss: 29.4104 (32.6547)  loss_n_40: 6.4924 (6.5647)  loss_n_60: 7.7023 (8.1793)  loss_n_80: 7.3028 (7.9466)  loss_n_100: 7.7417 (8.4465)  triple_100: 0.0000 (0.2533)  triple_80: 0.0000 (0.2449)  triple_60: 0.0000 (0.6837)  triple_40: 0.0000 (0.3357)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1140/1724]  eta: 0:38:12  lr: 0.000040  loss: 29.2274 (32.6237)  loss_n_40: 6.2639 (6.5620)  loss_n_60: 7.5891 (8.1732)  loss_n_80: 7.2030 (7.9401)  loss_n_100: 7.6781 (8.4401)  triple_100: 0.0000 (0.2512)  triple_80: 0.0000 (0.2430)  triple_60: 0.0000 (0.6813)  triple_40: 0.0000 (0.3327)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1150/1724]  eta: 0:37:33  lr: 0.000040  loss: 29.0508 (32.6052)  loss_n_40: 6.3435 (6.5609)  loss_n_60: 7.5955 (8.1689)  loss_n_80: 7.1296 (7.9338)  loss_n_100: 7.6781 (8.4336)  triple_100: 0.0000 (0.2527)  triple_80: 0.0000 (0.2431)  triple_60: 0.0000 (0.6824)  triple_40: 0.0000 (0.3298)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1160/1724]  eta: 0:36:54  lr: 0.000040  loss: 29.0114 (32.5730)  loss_n_40: 6.3137 (6.5579)  loss_n_60: 7.5691 (8.1632)  loss_n_80: 7.1927 (7.9283)  loss_n_100: 7.7116 (8.4279)  triple_100: 0.0000 (0.2509)  triple_80: 0.0000 (0.2410)  triple_60: 0.0000 (0.6768)  triple_40: 0.0000 (0.3270)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1170/1724]  eta: 0:36:14  lr: 0.000040  loss: 29.1154 (32.5458)  loss_n_40: 6.3709 (6.5572)  loss_n_60: 7.6026 (8.1591)  loss_n_80: 7.2924 (7.9228)  loss_n_100: 7.7726 (8.4229)  triple_100: 0.0000 (0.2496)  triple_80: 0.0000 (0.2390)  triple_60: 0.0000 (0.6710)  triple_40: 0.0000 (0.3242)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1180/1724]  eta: 0:35:35  lr: 0.000040  loss: 29.2607 (32.5187)  loss_n_40: 6.4710 (6.5564)  loss_n_60: 7.6694 (8.1554)  loss_n_80: 7.2702 (7.9177)  loss_n_100: 7.7629 (8.4172)  triple_100: 0.0000 (0.2483)  triple_80: 0.0000 (0.2369)  triple_60: 0.0000 (0.6653)  triple_40: 0.0000 (0.3215)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1190/1724]  eta: 0:34:56  lr: 0.000040  loss: 28.8877 (32.4878)  loss_n_40: 6.3931 (6.5542)  loss_n_60: 7.6366 (8.1503)  loss_n_80: 7.1175 (7.9110)  loss_n_100: 7.6498 (8.4106)  triple_100: 0.0000 (0.2462)  triple_80: 0.0000 (0.2349)  triple_60: 0.0000 (0.6616)  triple_40: 0.0000 (0.3189)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1200/1724]  eta: 0:34:16  lr: 0.000040  loss: 28.3895 (32.4632)  loss_n_40: 6.2251 (6.5523)  loss_n_60: 7.4428 (8.1452)  loss_n_80: 7.1091 (7.9048)  loss_n_100: 7.5736 (8.4041)  triple_100: 0.0000 (0.2455)  triple_80: 0.0000 (0.2330)  triple_60: 0.0000 (0.6598)  triple_40: 0.0000 (0.3183)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1210/1724]  eta: 0:33:37  lr: 0.000040  loss: 28.7499 (32.4342)  loss_n_40: 6.2861 (6.5508)  loss_n_60: 7.4579 (8.1399)  loss_n_80: 6.9897 (7.8977)  loss_n_100: 7.5629 (8.3974)  triple_100: 0.0000 (0.2456)  triple_80: 0.0000 (0.2311)  triple_60: 0.0000 (0.6556)  triple_40: 0.0000 (0.3162)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1220/1724]  eta: 0:32:58  lr: 0.000040  loss: 28.5215 (32.4037)  loss_n_40: 6.3206 (6.5490)  loss_n_60: 7.4805 (8.1347)  loss_n_80: 7.0402 (7.8916)  loss_n_100: 7.5906 (8.3916)  triple_100: 0.0000 (0.2438)  triple_80: 0.0000 (0.2292)  triple_60: 0.0000 (0.6502)  triple_40: 0.0000 (0.3136)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1230/1724]  eta: 0:32:19  lr: 0.000040  loss: 28.5215 (32.3754)  loss_n_40: 6.2278 (6.5463)  loss_n_60: 7.4343 (8.1290)  loss_n_80: 7.1798 (7.8872)  loss_n_100: 7.7007 (8.3866)  triple_100: 0.0000 (0.2418)  triple_80: 0.0000 (0.2273)  triple_60: 0.0000 (0.6460)  triple_40: 0.0000 (0.3111)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1240/1724]  eta: 0:31:39  lr: 0.000040  loss: 28.5742 (32.3434)  loss_n_40: 6.1989 (6.5441)  loss_n_60: 7.3809 (8.1235)  loss_n_80: 7.1943 (7.8809)  loss_n_100: 7.6428 (8.3800)  triple_100: 0.0000 (0.2400)  triple_80: 0.0000 (0.2255)  triple_60: 0.0000 (0.6409)  triple_40: 0.0000 (0.3086)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1250/1724]  eta: 0:31:00  lr: 0.000040  loss: 28.1913 (32.3098)  loss_n_40: 6.3410 (6.5421)  loss_n_60: 7.4590 (8.1180)  loss_n_80: 6.9338 (7.8734)  loss_n_100: 7.4574 (8.3726)  triple_100: 0.0000 (0.2381)  triple_80: 0.0000 (0.2237)  triple_60: 0.0000 (0.6358)  triple_40: 0.0000 (0.3061)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1260/1724]  eta: 0:30:21  lr: 0.000040  loss: 28.1913 (32.2814)  loss_n_40: 6.3769 (6.5398)  loss_n_60: 7.4488 (8.1124)  loss_n_80: 6.9339 (7.8674)  loss_n_100: 7.4402 (8.3661)  triple_100: 0.0000 (0.2376)  triple_80: 0.0000 (0.2220)  triple_60: 0.0000 (0.6324)  triple_40: 0.0000 (0.3037)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1270/1724]  eta: 0:29:42  lr: 0.000040  loss: 29.0763 (32.2628)  loss_n_40: 6.3769 (6.5392)  loss_n_60: 7.4488 (8.1085)  loss_n_80: 7.1516 (7.8629)  loss_n_100: 7.6372 (8.3617)  triple_100: 0.0000 (0.2366)  triple_80: 0.0000 (0.2210)  triple_60: 0.0000 (0.6315)  triple_40: 0.0000 (0.3014)  time: 3.9259  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [1280/1724]  eta: 0:29:02  lr: 0.000040  loss: 29.2894 (32.2375)  loss_n_40: 6.3436 (6.5369)  loss_n_60: 7.4440 (8.1028)  loss_n_80: 7.1635 (7.8582)  loss_n_100: 7.7544 (8.3568)  triple_100: 0.0000 (0.2357)  triple_80: 0.0000 (0.2193)  triple_60: 0.0000 (0.6287)  triple_40: 0.0000 (0.2991)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1290/1724]  eta: 0:28:23  lr: 0.000040  loss: 28.4741 (32.2083)  loss_n_40: 6.2627 (6.5344)  loss_n_60: 7.3418 (8.0968)  loss_n_80: 7.1266 (7.8526)  loss_n_100: 7.6911 (8.3509)  triple_100: 0.0000 (0.2341)  triple_80: 0.0000 (0.2176)  triple_60: 0.0000 (0.6252)  triple_40: 0.0000 (0.2969)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1300/1724]  eta: 0:27:44  lr: 0.000040  loss: 28.3096 (32.1774)  loss_n_40: 6.1800 (6.5318)  loss_n_60: 7.2962 (8.0909)  loss_n_80: 6.9586 (7.8463)  loss_n_100: 7.4275 (8.3442)  triple_100: 0.0000 (0.2323)  triple_80: 0.0000 (0.2159)  triple_60: 0.0000 (0.6214)  triple_40: 0.0000 (0.2946)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1310/1724]  eta: 0:27:05  lr: 0.000040  loss: 28.1391 (32.1506)  loss_n_40: 6.2222 (6.5301)  loss_n_60: 7.2962 (8.0854)  loss_n_80: 7.0050 (7.8405)  loss_n_100: 7.4275 (8.3385)  triple_100: 0.0000 (0.2325)  triple_80: 0.0000 (0.2143)  triple_60: 0.0000 (0.6170)  triple_40: 0.0000 (0.2924)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1320/1724]  eta: 0:26:25  lr: 0.000040  loss: 28.3551 (32.1236)  loss_n_40: 6.1952 (6.5276)  loss_n_60: 7.2654 (8.0792)  loss_n_80: 7.0050 (7.8347)  loss_n_100: 7.5245 (8.3327)  triple_100: 0.0000 (0.2316)  triple_80: 0.0000 (0.2126)  triple_60: 0.0000 (0.6150)  triple_40: 0.0000 (0.2902)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1330/1724]  eta: 0:25:46  lr: 0.000040  loss: 28.1816 (32.0947)  loss_n_40: 6.1952 (6.5255)  loss_n_60: 7.2654 (8.0736)  loss_n_80: 6.8674 (7.8285)  loss_n_100: 7.4788 (8.3266)  triple_100: 0.0000 (0.2299)  triple_80: 0.0000 (0.2110)  triple_60: 0.0000 (0.6109)  triple_40: 0.0000 (0.2886)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1340/1724]  eta: 0:25:07  lr: 0.000040  loss: 28.4475 (32.0857)  loss_n_40: 6.2371 (6.5240)  loss_n_60: 7.3561 (8.0684)  loss_n_80: 6.9511 (7.8234)  loss_n_100: 7.4788 (8.3212)  triple_100: 0.0000 (0.2325)  triple_80: 0.0000 (0.2114)  triple_60: 0.0000 (0.6120)  triple_40: 0.0000 (0.2928)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1350/1724]  eta: 0:24:28  lr: 0.000040  loss: 28.4730 (32.0580)  loss_n_40: 6.3392 (6.5222)  loss_n_60: 7.3601 (8.0635)  loss_n_80: 7.0306 (7.8175)  loss_n_100: 7.5208 (8.3151)  triple_100: 0.0000 (0.2312)  triple_80: 0.0000 (0.2098)  triple_60: 0.0000 (0.6081)  triple_40: 0.0000 (0.2906)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1360/1724]  eta: 0:23:48  lr: 0.000040  loss: 28.2743 (32.0282)  loss_n_40: 6.2665 (6.5195)  loss_n_60: 7.3229 (8.0575)  loss_n_80: 7.0345 (7.8113)  loss_n_100: 7.5205 (8.3093)  triple_100: 0.0000 (0.2295)  triple_80: 0.0000 (0.2083)  triple_60: 0.0000 (0.6043)  triple_40: 0.0000 (0.2885)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1370/1724]  eta: 0:23:09  lr: 0.000040  loss: 28.2743 (32.0144)  loss_n_40: 6.1705 (6.5176)  loss_n_60: 7.3061 (8.0525)  loss_n_80: 7.0345 (7.8053)  loss_n_100: 7.5138 (8.3025)  triple_100: 0.0000 (0.2321)  triple_80: 0.0000 (0.2082)  triple_60: 0.0000 (0.6058)  triple_40: 0.0000 (0.2904)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1380/1724]  eta: 0:22:30  lr: 0.000040  loss: 28.2925 (31.9959)  loss_n_40: 6.2422 (6.5158)  loss_n_60: 7.3168 (8.0475)  loss_n_80: 7.0967 (7.7999)  loss_n_100: 7.5849 (8.2970)  triple_100: 0.0000 (0.2329)  triple_80: 0.0000 (0.2084)  triple_60: 0.0000 (0.6053)  triple_40: 0.0000 (0.2893)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1390/1724]  eta: 0:21:51  lr: 0.000040  loss: 28.3032 (31.9744)  loss_n_40: 6.2809 (6.5148)  loss_n_60: 7.3338 (8.0430)  loss_n_80: 7.1112 (7.7949)  loss_n_100: 7.5929 (8.2920)  triple_100: 0.0000 (0.2312)  triple_80: 0.0000 (0.2069)  triple_60: 0.0000 (0.6042)  triple_40: 0.0000 (0.2874)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1400/1724]  eta: 0:21:11  lr: 0.000040  loss: 28.1649 (31.9442)  loss_n_40: 6.2696 (6.5119)  loss_n_60: 7.3079 (8.0372)  loss_n_80: 6.8880 (7.7883)  loss_n_100: 7.4176 (8.2858)  triple_100: 0.0000 (0.2304)  triple_80: 0.0000 (0.2054)  triple_60: 0.0000 (0.5999)  triple_40: 0.0000 (0.2854)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1410/1724]  eta: 0:20:32  lr: 0.000040  loss: 27.8527 (31.9238)  loss_n_40: 6.1589 (6.5101)  loss_n_60: 7.2344 (8.0322)  loss_n_80: 6.8880 (7.7822)  loss_n_100: 7.3966 (8.2796)  triple_100: 0.0000 (0.2292)  triple_80: 0.0000 (0.2043)  triple_60: 0.0000 (0.6013)  triple_40: 0.0000 (0.2849)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1420/1724]  eta: 0:19:53  lr: 0.000040  loss: 28.0886 (31.8975)  loss_n_40: 6.1657 (6.5088)  loss_n_60: 7.2964 (8.0279)  loss_n_80: 6.9355 (7.7765)  loss_n_100: 7.3797 (8.2738)  triple_100: 0.0000 (0.2276)  triple_80: 0.0000 (0.2028)  triple_60: 0.0000 (0.5970)  triple_40: 0.0000 (0.2829)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1430/1724]  eta: 0:19:14  lr: 0.000040  loss: 27.8645 (31.8696)  loss_n_40: 6.1611 (6.5065)  loss_n_60: 7.2693 (8.0225)  loss_n_80: 6.8316 (7.7709)  loss_n_100: 7.4242 (8.2682)  triple_100: 0.0000 (0.2260)  triple_80: 0.0000 (0.2014)  triple_60: 0.0000 (0.5932)  triple_40: 0.0000 (0.2809)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1440/1724]  eta: 0:18:34  lr: 0.000040  loss: 27.7641 (31.8488)  loss_n_40: 6.1619 (6.5053)  loss_n_60: 7.2523 (8.0177)  loss_n_80: 6.8598 (7.7645)  loss_n_100: 7.3951 (8.2620)  triple_100: 0.0000 (0.2264)  triple_80: 0.0000 (0.2015)  triple_60: 0.0000 (0.5923)  triple_40: 0.0000 (0.2791)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1450/1724]  eta: 0:17:55  lr: 0.000040  loss: 27.6347 (31.8260)  loss_n_40: 6.1330 (6.5025)  loss_n_60: 7.1931 (8.0120)  loss_n_80: 6.8730 (7.7583)  loss_n_100: 7.3599 (8.2558)  triple_100: 0.0000 (0.2286)  triple_80: 0.0000 (0.2008)  triple_60: 0.0000 (0.5908)  triple_40: 0.0000 (0.2771)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1460/1724]  eta: 0:17:16  lr: 0.000040  loss: 27.6395 (31.8001)  loss_n_40: 6.0806 (6.5005)  loss_n_60: 7.2221 (8.0072)  loss_n_80: 6.8785 (7.7525)  loss_n_100: 7.3958 (8.2502)  triple_100: 0.0000 (0.2272)  triple_80: 0.0000 (0.1995)  triple_60: 0.0000 (0.5867)  triple_40: 0.0000 (0.2764)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1470/1724]  eta: 0:16:37  lr: 0.000040  loss: 27.6574 (31.7788)  loss_n_40: 6.1926 (6.4985)  loss_n_60: 7.2454 (8.0021)  loss_n_80: 6.9861 (7.7472)  loss_n_100: 7.5084 (8.2450)  triple_100: 0.0000 (0.2268)  triple_80: 0.0000 (0.1983)  triple_60: 0.0000 (0.5856)  triple_40: 0.0000 (0.2753)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1480/1724]  eta: 0:15:57  lr: 0.000040  loss: 27.7431 (31.7529)  loss_n_40: 6.1129 (6.4963)  loss_n_60: 7.1769 (7.9968)  loss_n_80: 6.9062 (7.7411)  loss_n_100: 7.4619 (8.2396)  triple_100: 0.0000 (0.2257)  triple_80: 0.0000 (0.1970)  triple_60: 0.0000 (0.5823)  triple_40: 0.0000 (0.2740)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1490/1724]  eta: 0:15:18  lr: 0.000040  loss: 28.0016 (31.7345)  loss_n_40: 6.0899 (6.4937)  loss_n_60: 7.1769 (7.9911)  loss_n_80: 6.9505 (7.7361)  loss_n_100: 7.4717 (8.2348)  triple_100: 0.0000 (0.2250)  triple_80: 0.0000 (0.1964)  triple_60: 0.0000 (0.5847)  triple_40: 0.0000 (0.2726)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1500/1724]  eta: 0:14:39  lr: 0.000040  loss: 28.0892 (31.7090)  loss_n_40: 5.9891 (6.4909)  loss_n_60: 7.0321 (7.9855)  loss_n_80: 6.9059 (7.7305)  loss_n_100: 7.4717 (8.2294)  triple_100: 0.0000 (0.2255)  triple_80: 0.0000 (0.1951)  triple_60: 0.0000 (0.5813)  triple_40: 0.0000 (0.2708)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1510/1724]  eta: 0:13:59  lr: 0.000040  loss: 27.3281 (31.6830)  loss_n_40: 6.0250 (6.4885)  loss_n_60: 7.1089 (7.9803)  loss_n_80: 6.7306 (7.7238)  loss_n_100: 7.3117 (8.2229)  triple_100: 0.0000 (0.2241)  triple_80: 0.0000 (0.1938)  triple_60: 0.0000 (0.5806)  triple_40: 0.0000 (0.2690)  time: 3.9226  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [1520/1724]  eta: 0:13:20  lr: 0.000040  loss: 27.4602 (31.6584)  loss_n_40: 6.0928 (6.4871)  loss_n_60: 7.1638 (7.9759)  loss_n_80: 6.7277 (7.7185)  loss_n_100: 7.3186 (8.2178)  triple_100: 0.0000 (0.2226)  triple_80: 0.0000 (0.1926)  triple_60: 0.0000 (0.5767)  triple_40: 0.0000 (0.2672)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1530/1724]  eta: 0:12:41  lr: 0.000040  loss: 27.7838 (31.6363)  loss_n_40: 6.2091 (6.4860)  loss_n_60: 7.2306 (7.9713)  loss_n_80: 6.9396 (7.7139)  loss_n_100: 7.4379 (8.2128)  triple_100: 0.0000 (0.2213)  triple_80: 0.0000 (0.1913)  triple_60: 0.0000 (0.5743)  triple_40: 0.0000 (0.2655)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1540/1724]  eta: 0:12:02  lr: 0.000040  loss: 28.2765 (31.6174)  loss_n_40: 6.2570 (6.4847)  loss_n_60: 7.3037 (7.9673)  loss_n_80: 6.8997 (7.7083)  loss_n_100: 7.2727 (8.2066)  triple_100: 0.0000 (0.2202)  triple_80: 0.0000 (0.1910)  triple_60: 0.0000 (0.5751)  triple_40: 0.0000 (0.2642)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1550/1724]  eta: 0:11:22  lr: 0.000040  loss: 28.2801 (31.5949)  loss_n_40: 6.2407 (6.4828)  loss_n_60: 7.3263 (7.9630)  loss_n_80: 6.9044 (7.7042)  loss_n_100: 7.2727 (8.2023)  triple_100: 0.0000 (0.2188)  triple_80: 0.0000 (0.1898)  triple_60: 0.0000 (0.5714)  triple_40: 0.0000 (0.2625)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1560/1724]  eta: 0:10:43  lr: 0.000040  loss: 28.0083 (31.5792)  loss_n_40: 6.2442 (6.4819)  loss_n_60: 7.3156 (7.9592)  loss_n_80: 6.9170 (7.6991)  loss_n_100: 7.4701 (8.1971)  triple_100: 0.0000 (0.2177)  triple_80: 0.0000 (0.1886)  triple_60: 0.0000 (0.5718)  triple_40: 0.0000 (0.2638)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1570/1724]  eta: 0:10:04  lr: 0.000040  loss: 27.9251 (31.5542)  loss_n_40: 6.2369 (6.4798)  loss_n_60: 7.2363 (7.9541)  loss_n_80: 6.9100 (7.6938)  loss_n_100: 7.3488 (8.1920)  triple_100: 0.0000 (0.2165)  triple_80: 0.0000 (0.1874)  triple_60: 0.0000 (0.5681)  triple_40: 0.0000 (0.2625)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1580/1724]  eta: 0:09:25  lr: 0.000040  loss: 27.5161 (31.5304)  loss_n_40: 6.1325 (6.4776)  loss_n_60: 7.1487 (7.9489)  loss_n_80: 6.8081 (7.6886)  loss_n_100: 7.3045 (8.1866)  triple_100: 0.0000 (0.2158)  triple_80: 0.0000 (0.1862)  triple_60: 0.0000 (0.5653)  triple_40: 0.0000 (0.2613)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1590/1724]  eta: 0:08:45  lr: 0.000040  loss: 27.5161 (31.5045)  loss_n_40: 6.1050 (6.4750)  loss_n_60: 7.1024 (7.9433)  loss_n_80: 6.8162 (7.6828)  loss_n_100: 7.2893 (8.1810)  triple_100: 0.0000 (0.2145)  triple_80: 0.0000 (0.1850)  triple_60: 0.0000 (0.5630)  triple_40: 0.0000 (0.2600)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1600/1724]  eta: 0:08:06  lr: 0.000040  loss: 27.8504 (31.4944)  loss_n_40: 6.1444 (6.4731)  loss_n_60: 7.1024 (7.9384)  loss_n_80: 6.8825 (7.6783)  loss_n_100: 7.2974 (8.1762)  triple_100: 0.0000 (0.2169)  triple_80: 0.0000 (0.1848)  triple_60: 0.0000 (0.5651)  triple_40: 0.0000 (0.2617)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1610/1724]  eta: 0:07:27  lr: 0.000040  loss: 27.2938 (31.4764)  loss_n_40: 6.1400 (6.4713)  loss_n_60: 7.1492 (7.9340)  loss_n_80: 6.7670 (7.6732)  loss_n_100: 7.3762 (8.1713)  triple_100: 0.0000 (0.2179)  triple_80: 0.0000 (0.1836)  triple_60: 0.0000 (0.5640)  triple_40: 0.0000 (0.2611)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1620/1724]  eta: 0:06:48  lr: 0.000040  loss: 27.7159 (31.4690)  loss_n_40: 6.0740 (6.4699)  loss_n_60: 7.1304 (7.9296)  loss_n_80: 6.8465 (7.6696)  loss_n_100: 7.4415 (8.1679)  triple_100: 0.0000 (0.2200)  triple_80: 0.0000 (0.1851)  triple_60: 0.0000 (0.5658)  triple_40: 0.0000 (0.2611)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1630/1724]  eta: 0:06:08  lr: 0.000040  loss: 28.4022 (31.4486)  loss_n_40: 6.1438 (6.4684)  loss_n_60: 7.1640 (7.9254)  loss_n_80: 6.9209 (7.6654)  loss_n_100: 7.4415 (8.1637)  triple_100: 0.0000 (0.2189)  triple_80: 0.0000 (0.1840)  triple_60: 0.0000 (0.5633)  triple_40: 0.0000 (0.2595)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1640/1724]  eta: 0:05:29  lr: 0.000040  loss: 27.5918 (31.4239)  loss_n_40: 6.0910 (6.4659)  loss_n_60: 7.1066 (7.9203)  loss_n_80: 6.8832 (7.6604)  loss_n_100: 7.4146 (8.1589)  triple_100: 0.0000 (0.2176)  triple_80: 0.0000 (0.1829)  triple_60: 0.0000 (0.5599)  triple_40: 0.0000 (0.2579)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1650/1724]  eta: 0:04:50  lr: 0.000040  loss: 27.6872 (31.4102)  loss_n_40: 6.0866 (6.4640)  loss_n_60: 7.1350 (7.9160)  loss_n_80: 6.9463 (7.6564)  loss_n_100: 7.4794 (8.1548)  triple_100: 0.0000 (0.2187)  triple_80: 0.0000 (0.1824)  triple_60: 0.0000 (0.5605)  triple_40: 0.0000 (0.2574)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1660/1724]  eta: 0:04:11  lr: 0.000040  loss: 27.6872 (31.3844)  loss_n_40: 6.0789 (6.4615)  loss_n_60: 7.1706 (7.9113)  loss_n_80: 6.7068 (7.6502)  loss_n_100: 7.2895 (8.1490)  triple_100: 0.0000 (0.2174)  triple_80: 0.0000 (0.1813)  triple_60: 0.0000 (0.5579)  triple_40: 0.0000 (0.2559)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1670/1724]  eta: 0:03:31  lr: 0.000040  loss: 26.8415 (31.3575)  loss_n_40: 6.0491 (6.4586)  loss_n_60: 7.0535 (7.9059)  loss_n_80: 6.5966 (7.6443)  loss_n_100: 7.1765 (8.1436)  triple_100: 0.0000 (0.2161)  triple_80: 0.0000 (0.1802)  triple_60: 0.0000 (0.5545)  triple_40: 0.0000 (0.2543)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1680/1724]  eta: 0:02:52  lr: 0.000040  loss: 26.8123 (31.3303)  loss_n_40: 5.8944 (6.4552)  loss_n_60: 6.9528 (7.9001)  loss_n_80: 6.5966 (7.6381)  loss_n_100: 7.1765 (8.1380)  triple_100: 0.0000 (0.2154)  triple_80: 0.0000 (0.1791)  triple_60: 0.0000 (0.5517)  triple_40: 0.0000 (0.2528)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1690/1724]  eta: 0:02:13  lr: 0.000040  loss: 26.8369 (31.3084)  loss_n_40: 6.0043 (6.4526)  loss_n_60: 6.9771 (7.8951)  loss_n_80: 6.6166 (7.6333)  loss_n_100: 7.1756 (8.1332)  triple_100: 0.0000 (0.2147)  triple_80: 0.0000 (0.1780)  triple_60: 0.0000 (0.5501)  triple_40: 0.0000 (0.2513)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1700/1724]  eta: 0:01:34  lr: 0.000040  loss: 27.5604 (31.2867)  loss_n_40: 6.1130 (6.4509)  loss_n_60: 7.1304 (7.8911)  loss_n_80: 6.6561 (7.6282)  loss_n_100: 7.1751 (8.1282)  triple_100: 0.0000 (0.2139)  triple_80: 0.0000 (0.1770)  triple_60: 0.0000 (0.5472)  triple_40: 0.0000 (0.2502)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1710/1724]  eta: 0:00:54  lr: 0.000040  loss: 27.6865 (31.2655)  loss_n_40: 6.1477 (6.4485)  loss_n_60: 7.1557 (7.8863)  loss_n_80: 6.8110 (7.6234)  loss_n_100: 7.2242 (8.1235)  triple_100: 0.0000 (0.2129)  triple_80: 0.0000 (0.1766)  triple_60: 0.0000 (0.5456)  triple_40: 0.0000 (0.2487)  time: 3.9250  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:3]  [1720/1724]  eta: 0:00:15  lr: 0.000040  loss: 27.6807 (31.2440)  loss_n_40: 6.0429 (6.4460)  loss_n_60: 7.0830 (7.8814)  loss_n_80: 6.8827 (7.6192)  loss_n_100: 7.3473 (8.1192)  triple_100: 0.0000 (0.2118)  triple_80: 0.0000 (0.1756)  triple_60: 0.0000 (0.5436)  triple_40: 0.0000 (0.2472)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3]  [1723/1724]  eta: 0:00:03  lr: 0.000040  loss: 27.8241 (31.2410)  loss_n_40: 6.1413 (6.4461)  loss_n_60: 7.1557 (7.8805)  loss_n_80: 6.8922 (7.6182)  loss_n_100: 7.3473 (8.1179)  triple_100: 0.0000 (0.2114)  triple_80: 0.0000 (0.1752)  triple_60: 0.0000 (0.5437)  triple_40: 0.0000 (0.2480)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:3] Total time: 1:52:47 (3.9253 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 27.8241 (31.2410)  loss_n_40: 6.1413 (6.4461)  loss_n_60: 7.1557 (7.8805)  loss_n_80: 6.8922 (7.6182)  loss_n_100: 7.3473 (8.1179)  triple_100: 0.0000 (0.2114)  triple_80: 0.0000 (0.1752)  triple_60: 0.0000 (0.5437)  triple_40: 0.0000 (0.2480)\n",
      "Valid: [epoch:3]  [  0/845]  eta: 0:12:41  loss: 25.0981 (25.0981)  loss_n_40: 5.3836 (5.3836)  loss_n_60: 6.4204 (6.4204)  loss_n_80: 6.2388 (6.2388)  loss_n_100: 7.0553 (7.0553)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.9014  data: 0.5667  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:3]  [ 10/845]  eta: 0:05:21  loss: 28.5741 (27.8229)  loss_n_40: 6.2540 (6.1667)  loss_n_60: 7.1672 (7.0975)  loss_n_80: 7.0838 (6.9958)  loss_n_100: 7.6413 (7.5155)  triple_100: 0.0000 (0.0474)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3855  data: 0.0516  max mem: 46473\n",
      "Valid: [epoch:3]  [ 20/845]  eta: 0:04:57  loss: 27.2102 (27.2162)  loss_n_40: 6.1770 (6.1334)  loss_n_60: 7.1136 (7.0896)  loss_n_80: 6.6785 (6.7012)  loss_n_100: 7.2886 (7.2671)  triple_100: 0.0000 (0.0248)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [ 30/845]  eta: 0:04:47  loss: 25.7974 (26.8625)  loss_n_40: 6.1047 (6.0749)  loss_n_60: 7.0625 (7.0430)  loss_n_80: 6.0761 (6.5726)  loss_n_100: 6.8322 (7.1552)  triple_100: 0.0000 (0.0168)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [ 40/845]  eta: 0:04:40  loss: 25.9419 (26.9598)  loss_n_40: 6.0629 (6.0859)  loss_n_60: 7.0625 (7.0583)  loss_n_80: 6.1954 (6.6100)  loss_n_100: 6.8555 (7.1929)  triple_100: 0.0000 (0.0127)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [ 50/845]  eta: 0:04:34  loss: 27.5004 (27.0286)  loss_n_40: 6.0629 (6.0813)  loss_n_60: 7.0512 (7.0339)  loss_n_80: 6.9176 (6.6605)  loss_n_100: 7.3098 (7.2161)  triple_100: 0.0000 (0.0102)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0265)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [ 60/845]  eta: 0:04:29  loss: 27.2165 (27.3482)  loss_n_40: 6.0964 (6.0773)  loss_n_60: 6.9610 (7.0208)  loss_n_80: 6.9766 (6.7008)  loss_n_100: 7.3061 (7.2203)  triple_100: 0.0000 (0.0085)  triple_80: 0.0000 (0.0635)  triple_60: 0.0000 (0.2570)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [ 70/845]  eta: 0:04:25  loss: 27.2165 (27.4712)  loss_n_40: 6.2451 (6.1048)  loss_n_60: 7.0980 (7.0351)  loss_n_80: 7.1867 (6.7688)  loss_n_100: 7.2553 (7.2798)  triple_100: 0.0000 (0.0073)  triple_80: 0.0000 (0.0545)  triple_60: 0.0000 (0.2208)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [ 80/845]  eta: 0:04:21  loss: 27.1523 (27.6488)  loss_n_40: 6.2451 (6.0997)  loss_n_60: 7.0337 (7.0261)  loss_n_80: 6.8202 (6.7483)  loss_n_100: 7.0979 (7.2485)  triple_100: 0.0000 (0.0064)  triple_80: 0.0000 (0.1100)  triple_60: 0.0000 (0.4098)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [ 90/845]  eta: 0:04:17  loss: 28.0944 (27.6901)  loss_n_40: 6.3278 (6.1259)  loss_n_60: 7.0337 (7.0374)  loss_n_80: 6.6977 (6.7789)  loss_n_100: 7.2831 (7.2794)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0979)  triple_60: 0.0000 (0.3648)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [100/845]  eta: 0:04:13  loss: 28.0944 (27.7503)  loss_n_40: 6.3278 (6.1388)  loss_n_60: 7.0911 (7.0410)  loss_n_80: 7.1405 (6.7873)  loss_n_100: 7.4441 (7.2743)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0882)  triple_60: 0.0000 (0.4155)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [110/845]  eta: 0:04:09  loss: 27.4685 (27.7903)  loss_n_40: 5.9312 (6.1452)  loss_n_60: 7.0519 (7.0534)  loss_n_80: 6.7873 (6.7769)  loss_n_100: 7.1272 (7.2634)  triple_100: 0.0000 (0.0047)  triple_80: 0.0000 (0.0803)  triple_60: 0.0000 (0.3975)  triple_40: 0.0000 (0.0689)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [120/845]  eta: 0:04:05  loss: 27.4429 (27.7906)  loss_n_40: 6.2106 (6.1492)  loss_n_60: 7.1028 (7.0534)  loss_n_80: 6.9308 (6.7913)  loss_n_100: 7.1283 (7.2776)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0737)  triple_60: 0.0000 (0.3779)  triple_40: 0.0000 (0.0632)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [130/845]  eta: 0:04:02  loss: 27.6839 (27.7473)  loss_n_40: 6.1748 (6.1435)  loss_n_60: 7.0959 (7.0511)  loss_n_80: 6.9744 (6.7901)  loss_n_100: 7.5646 (7.2832)  triple_100: 0.0000 (0.0040)  triple_80: 0.0000 (0.0680)  triple_60: 0.0000 (0.3491)  triple_40: 0.0000 (0.0583)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [140/845]  eta: 0:03:58  loss: 27.8445 (27.7177)  loss_n_40: 6.1042 (6.1419)  loss_n_60: 7.0401 (7.0524)  loss_n_80: 7.0754 (6.7946)  loss_n_100: 7.5444 (7.2834)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0632)  triple_60: 0.0000 (0.3243)  triple_40: 0.0000 (0.0542)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [150/845]  eta: 0:03:54  loss: 25.7656 (27.6454)  loss_n_40: 6.0318 (6.1394)  loss_n_60: 6.9895 (7.0528)  loss_n_80: 6.0918 (6.7695)  loss_n_100: 6.7650 (7.2677)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0590)  triple_60: 0.0000 (0.3028)  triple_40: 0.0000 (0.0506)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [160/845]  eta: 0:03:51  loss: 25.5965 (27.5674)  loss_n_40: 6.0241 (6.1283)  loss_n_60: 6.9486 (7.0409)  loss_n_80: 6.2562 (6.7542)  loss_n_100: 6.8030 (7.2540)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0554)  triple_60: 0.0000 (0.2840)  triple_40: 0.0000 (0.0475)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [170/845]  eta: 0:03:47  loss: 26.4998 (27.5553)  loss_n_40: 6.0273 (6.1356)  loss_n_60: 6.9920 (7.0479)  loss_n_80: 6.3029 (6.7448)  loss_n_100: 6.9345 (7.2476)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0521)  triple_60: 0.0000 (0.2785)  triple_40: 0.0000 (0.0447)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [180/845]  eta: 0:03:44  loss: 26.8690 (27.8072)  loss_n_40: 6.3061 (6.1355)  loss_n_60: 7.2056 (7.0515)  loss_n_80: 6.5829 (6.7405)  loss_n_100: 6.8371 (7.2399)  triple_100: 0.0000 (0.0230)  triple_80: 0.0000 (0.1104)  triple_60: 0.0000 (0.4492)  triple_40: 0.0000 (0.0570)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [190/845]  eta: 0:03:40  loss: 27.4028 (27.8701)  loss_n_40: 6.3061 (6.1411)  loss_n_60: 7.2373 (7.0590)  loss_n_80: 6.7168 (6.7429)  loss_n_100: 7.0936 (7.2437)  triple_100: 0.0000 (0.0218)  triple_80: 0.0000 (0.1046)  triple_60: 0.0000 (0.4961)  triple_40: 0.0000 (0.0607)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [200/845]  eta: 0:03:37  loss: 27.0287 (27.7922)  loss_n_40: 6.0048 (6.1346)  loss_n_60: 7.1446 (7.0552)  loss_n_80: 6.5283 (6.7243)  loss_n_100: 7.0936 (7.2287)  triple_100: 0.0000 (0.0208)  triple_80: 0.0000 (0.0994)  triple_60: 0.0000 (0.4714)  triple_40: 0.0000 (0.0577)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [210/845]  eta: 0:03:33  loss: 25.7375 (27.7460)  loss_n_40: 6.0654 (6.1339)  loss_n_60: 7.0968 (7.0546)  loss_n_80: 6.2003 (6.7162)  loss_n_100: 6.8378 (7.2228)  triple_100: 0.0000 (0.0198)  triple_80: 0.0000 (0.0947)  triple_60: 0.0000 (0.4490)  triple_40: 0.0000 (0.0550)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [220/845]  eta: 0:03:30  loss: 26.3324 (27.7405)  loss_n_40: 6.1615 (6.1356)  loss_n_60: 7.0968 (7.0547)  loss_n_80: 6.3358 (6.7204)  loss_n_100: 6.9414 (7.2266)  triple_100: 0.0000 (0.0189)  triple_80: 0.0000 (0.0904)  triple_60: 0.0000 (0.4415)  triple_40: 0.0000 (0.0525)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [230/845]  eta: 0:03:27  loss: 26.4744 (27.6998)  loss_n_40: 6.2733 (6.1324)  loss_n_60: 6.9366 (7.0500)  loss_n_80: 6.3167 (6.7162)  loss_n_100: 7.0647 (7.2241)  triple_100: 0.0000 (0.0181)  triple_80: 0.0000 (0.0865)  triple_60: 0.0000 (0.4224)  triple_40: 0.0000 (0.0502)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [240/845]  eta: 0:03:23  loss: 26.8606 (27.6738)  loss_n_40: 6.2009 (6.1306)  loss_n_60: 6.9992 (7.0489)  loss_n_80: 6.4081 (6.7146)  loss_n_100: 7.0765 (7.2265)  triple_100: 0.0000 (0.0173)  triple_80: 0.0000 (0.0829)  triple_60: 0.0000 (0.4048)  triple_40: 0.0000 (0.0481)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [250/845]  eta: 0:03:20  loss: 27.1680 (27.6611)  loss_n_40: 6.2009 (6.1292)  loss_n_60: 7.1429 (7.0503)  loss_n_80: 6.6648 (6.7192)  loss_n_100: 7.2007 (7.2296)  triple_100: 0.0000 (0.0182)  triple_80: 0.0000 (0.0796)  triple_60: 0.0000 (0.3887)  triple_40: 0.0000 (0.0462)  time: 0.3348  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:3]  [260/845]  eta: 0:03:16  loss: 27.9687 (27.6925)  loss_n_40: 6.2307 (6.1353)  loss_n_60: 7.1980 (7.0561)  loss_n_80: 6.9737 (6.7331)  loss_n_100: 7.3673 (7.2368)  triple_100: 0.0000 (0.0175)  triple_80: 0.0000 (0.0766)  triple_60: 0.0000 (0.3828)  triple_40: 0.0000 (0.0544)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [270/845]  eta: 0:03:13  loss: 27.9687 (27.6442)  loss_n_40: 6.2302 (6.1277)  loss_n_60: 7.0390 (7.0493)  loss_n_80: 6.8239 (6.7229)  loss_n_100: 7.1914 (7.2326)  triple_100: 0.0000 (0.0169)  triple_80: 0.0000 (0.0738)  triple_60: 0.0000 (0.3687)  triple_40: 0.0000 (0.0524)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [280/845]  eta: 0:03:10  loss: 27.1355 (27.6344)  loss_n_40: 6.0573 (6.1234)  loss_n_60: 7.0156 (7.0490)  loss_n_80: 6.5027 (6.7244)  loss_n_100: 7.1914 (7.2348)  triple_100: 0.0000 (0.0163)  triple_80: 0.0000 (0.0711)  triple_60: 0.0000 (0.3649)  triple_40: 0.0000 (0.0505)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [290/845]  eta: 0:03:06  loss: 27.1355 (27.6195)  loss_n_40: 5.8664 (6.1193)  loss_n_60: 6.9503 (7.0454)  loss_n_80: 6.5717 (6.7171)  loss_n_100: 7.1815 (7.2301)  triple_100: 0.0000 (0.0157)  triple_80: 0.0000 (0.0687)  triple_60: 0.0000 (0.3523)  triple_40: 0.0000 (0.0709)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [300/845]  eta: 0:03:03  loss: 25.4644 (27.5776)  loss_n_40: 5.8595 (6.1166)  loss_n_60: 6.7958 (7.0437)  loss_n_80: 6.1287 (6.7054)  loss_n_100: 6.7494 (7.2211)  triple_100: 0.0000 (0.0152)  triple_80: 0.0000 (0.0664)  triple_60: 0.0000 (0.3406)  triple_40: 0.0000 (0.0686)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [310/845]  eta: 0:02:59  loss: 25.7574 (27.6210)  loss_n_40: 6.1142 (6.1179)  loss_n_60: 6.9271 (7.0424)  loss_n_80: 6.1287 (6.7056)  loss_n_100: 6.7410 (7.2193)  triple_100: 0.0000 (0.0155)  triple_80: 0.0000 (0.0754)  triple_60: 0.0000 (0.3786)  triple_40: 0.0000 (0.0664)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [320/845]  eta: 0:02:56  loss: 27.7741 (27.6227)  loss_n_40: 6.1520 (6.1227)  loss_n_60: 7.1480 (7.0430)  loss_n_80: 6.9792 (6.7128)  loss_n_100: 7.3146 (7.2251)  triple_100: 0.0000 (0.0150)  triple_80: 0.0000 (0.0730)  triple_60: 0.0000 (0.3668)  triple_40: 0.0000 (0.0643)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [330/845]  eta: 0:02:53  loss: 27.6453 (27.5982)  loss_n_40: 5.8224 (6.1150)  loss_n_60: 6.6443 (7.0341)  loss_n_80: 6.8860 (6.7166)  loss_n_100: 7.3851 (7.2291)  triple_100: 0.0000 (0.0145)  triple_80: 0.0000 (0.0708)  triple_60: 0.0000 (0.3558)  triple_40: 0.0000 (0.0623)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [340/845]  eta: 0:02:49  loss: 26.2572 (27.6020)  loss_n_40: 5.8014 (6.1120)  loss_n_60: 6.7531 (7.0329)  loss_n_80: 6.7103 (6.7192)  loss_n_100: 7.1889 (7.2303)  triple_100: 0.0000 (0.0141)  triple_80: 0.0000 (0.0778)  triple_60: 0.0000 (0.3552)  triple_40: 0.0000 (0.0605)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [350/845]  eta: 0:02:46  loss: 27.1214 (27.5898)  loss_n_40: 5.9328 (6.1119)  loss_n_60: 6.9591 (7.0313)  loss_n_80: 6.8123 (6.7186)  loss_n_100: 7.1146 (7.2297)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0756)  triple_60: 0.0000 (0.3450)  triple_40: 0.0000 (0.0640)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [360/845]  eta: 0:02:42  loss: 28.1436 (27.5852)  loss_n_40: 6.0635 (6.1124)  loss_n_60: 7.0475 (7.0329)  loss_n_80: 7.0196 (6.7227)  loss_n_100: 7.4552 (7.2325)  triple_100: 0.0000 (0.0133)  triple_80: 0.0000 (0.0735)  triple_60: 0.0000 (0.3355)  triple_40: 0.0000 (0.0622)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [370/845]  eta: 0:02:39  loss: 28.1750 (27.5871)  loss_n_40: 6.1520 (6.1145)  loss_n_60: 7.0779 (7.0330)  loss_n_80: 7.0976 (6.7300)  loss_n_100: 7.5278 (7.2381)  triple_100: 0.0000 (0.0130)  triple_80: 0.0000 (0.0715)  triple_60: 0.0000 (0.3264)  triple_40: 0.0000 (0.0606)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [380/845]  eta: 0:02:36  loss: 27.7267 (27.5900)  loss_n_40: 6.2383 (6.1190)  loss_n_60: 7.1765 (7.0368)  loss_n_80: 7.0976 (6.7334)  loss_n_100: 7.6060 (7.2406)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0697)  triple_60: 0.0000 (0.3179)  triple_40: 0.0000 (0.0590)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [390/845]  eta: 0:02:32  loss: 28.3959 (27.6727)  loss_n_40: 6.3938 (6.1270)  loss_n_60: 7.2445 (7.0449)  loss_n_80: 6.6856 (6.7325)  loss_n_100: 7.0815 (7.2368)  triple_100: 0.0000 (0.0292)  triple_80: 0.0000 (0.0900)  triple_60: 0.0000 (0.3543)  triple_40: 0.0000 (0.0579)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [400/845]  eta: 0:02:29  loss: 27.5105 (27.6588)  loss_n_40: 6.2705 (6.1264)  loss_n_60: 7.2126 (7.0436)  loss_n_80: 6.6856 (6.7325)  loss_n_100: 7.0815 (7.2373)  triple_100: 0.0000 (0.0292)  triple_80: 0.0000 (0.0878)  triple_60: 0.0000 (0.3455)  triple_40: 0.0000 (0.0565)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [410/845]  eta: 0:02:26  loss: 27.5881 (27.6701)  loss_n_40: 6.1721 (6.1320)  loss_n_60: 7.0771 (7.0462)  loss_n_80: 6.9439 (6.7378)  loss_n_100: 7.4343 (7.2412)  triple_100: 0.0000 (0.0285)  triple_80: 0.0000 (0.0856)  triple_60: 0.0000 (0.3437)  triple_40: 0.0000 (0.0551)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [420/845]  eta: 0:02:22  loss: 27.7285 (27.6559)  loss_n_40: 6.1701 (6.1289)  loss_n_60: 7.0771 (7.0453)  loss_n_80: 6.9681 (6.7370)  loss_n_100: 7.3762 (7.2415)  triple_100: 0.0000 (0.0303)  triple_80: 0.0000 (0.0836)  triple_60: 0.0000 (0.3355)  triple_40: 0.0000 (0.0538)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [430/845]  eta: 0:02:19  loss: 26.2912 (27.6222)  loss_n_40: 6.0403 (6.1230)  loss_n_60: 7.0349 (7.0431)  loss_n_80: 6.5620 (6.7291)  loss_n_100: 7.0628 (7.2355)  triple_100: 0.0000 (0.0296)  triple_80: 0.0000 (0.0817)  triple_60: 0.0000 (0.3277)  triple_40: 0.0000 (0.0526)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [440/845]  eta: 0:02:15  loss: 26.0922 (27.6151)  loss_n_40: 6.1730 (6.1260)  loss_n_60: 7.1152 (7.0454)  loss_n_80: 6.4772 (6.7284)  loss_n_100: 7.0628 (7.2349)  triple_100: 0.0000 (0.0290)  triple_80: 0.0000 (0.0798)  triple_60: 0.0000 (0.3203)  triple_40: 0.0000 (0.0514)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [450/845]  eta: 0:02:12  loss: 26.4233 (27.5997)  loss_n_40: 6.1730 (6.1220)  loss_n_60: 7.1034 (7.0426)  loss_n_80: 6.6633 (6.7269)  loss_n_100: 7.1157 (7.2334)  triple_100: 0.0000 (0.0334)  triple_80: 0.0000 (0.0780)  triple_60: 0.0000 (0.3132)  triple_40: 0.0000 (0.0502)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [460/845]  eta: 0:02:09  loss: 25.9723 (27.5700)  loss_n_40: 5.9902 (6.1193)  loss_n_60: 6.9326 (7.0408)  loss_n_80: 6.2401 (6.7190)  loss_n_100: 6.8972 (7.2263)  triple_100: 0.0000 (0.0327)  triple_80: 0.0000 (0.0763)  triple_60: 0.0000 (0.3064)  triple_40: 0.0000 (0.0491)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [470/845]  eta: 0:02:05  loss: 26.7449 (27.5917)  loss_n_40: 6.1332 (6.1252)  loss_n_60: 7.1094 (7.0452)  loss_n_80: 6.5267 (6.7224)  loss_n_100: 6.9360 (7.2285)  triple_100: 0.0000 (0.0320)  triple_80: 0.0000 (0.0747)  triple_60: 0.0000 (0.3098)  triple_40: 0.0000 (0.0540)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [480/845]  eta: 0:02:02  loss: 27.4897 (27.5767)  loss_n_40: 6.1580 (6.1195)  loss_n_60: 7.1013 (7.0393)  loss_n_80: 6.8984 (6.7253)  loss_n_100: 7.3197 (7.2306)  triple_100: 0.0000 (0.0325)  triple_80: 0.0000 (0.0732)  triple_60: 0.0000 (0.3034)  triple_40: 0.0000 (0.0528)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [490/845]  eta: 0:01:59  loss: 26.7705 (27.5674)  loss_n_40: 5.9970 (6.1198)  loss_n_60: 6.9398 (7.0393)  loss_n_80: 7.0167 (6.7259)  loss_n_100: 7.1834 (7.2300)  triple_100: 0.0000 (0.0319)  triple_80: 0.0000 (0.0717)  triple_60: 0.0000 (0.2972)  triple_40: 0.0000 (0.0518)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [500/845]  eta: 0:01:55  loss: 26.3115 (27.5503)  loss_n_40: 5.9970 (6.1169)  loss_n_60: 6.8995 (7.0361)  loss_n_80: 6.7343 (6.7238)  loss_n_100: 7.1667 (7.2297)  triple_100: 0.0000 (0.0315)  triple_80: 0.0000 (0.0702)  triple_60: 0.0000 (0.2913)  triple_40: 0.0000 (0.0507)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:3]  [510/845]  eta: 0:01:52  loss: 25.6153 (27.5290)  loss_n_40: 6.0632 (6.1149)  loss_n_60: 6.8483 (7.0354)  loss_n_80: 6.1523 (6.7182)  loss_n_100: 6.7825 (7.2254)  triple_100: 0.0000 (0.0309)  triple_80: 0.0000 (0.0689)  triple_60: 0.0000 (0.2856)  triple_40: 0.0000 (0.0497)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [520/845]  eta: 0:01:49  loss: 25.8544 (27.5385)  loss_n_40: 6.0847 (6.1153)  loss_n_60: 7.0927 (7.0354)  loss_n_80: 6.3611 (6.7160)  loss_n_100: 6.9763 (7.2230)  triple_100: 0.0000 (0.0303)  triple_80: 0.0000 (0.0675)  triple_60: 0.0000 (0.2907)  triple_40: 0.0000 (0.0602)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [530/845]  eta: 0:01:45  loss: 26.5270 (27.5340)  loss_n_40: 6.0057 (6.1132)  loss_n_60: 6.9275 (7.0338)  loss_n_80: 6.7091 (6.7200)  loss_n_100: 7.2500 (7.2267)  triple_100: 0.0000 (0.0297)  triple_80: 0.0000 (0.0663)  triple_60: 0.0000 (0.2852)  triple_40: 0.0000 (0.0590)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [540/845]  eta: 0:01:42  loss: 26.7875 (27.5454)  loss_n_40: 5.9995 (6.1149)  loss_n_60: 7.0131 (7.0351)  loss_n_80: 6.8993 (6.7180)  loss_n_100: 7.3881 (7.2262)  triple_100: 0.0000 (0.0292)  triple_80: 0.0000 (0.0651)  triple_60: 0.0000 (0.2929)  triple_40: 0.0000 (0.0641)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [550/845]  eta: 0:01:38  loss: 26.9136 (27.5513)  loss_n_40: 6.1253 (6.1155)  loss_n_60: 7.0719 (7.0347)  loss_n_80: 6.4563 (6.7165)  loss_n_100: 6.9148 (7.2225)  triple_100: 0.0000 (0.0286)  triple_80: 0.0000 (0.0657)  triple_60: 0.0000 (0.3049)  triple_40: 0.0000 (0.0630)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [560/845]  eta: 0:01:35  loss: 27.0045 (27.5401)  loss_n_40: 6.1453 (6.1140)  loss_n_60: 7.1305 (7.0336)  loss_n_80: 6.5671 (6.7154)  loss_n_100: 7.0828 (7.2232)  triple_100: 0.0000 (0.0281)  triple_80: 0.0000 (0.0645)  triple_60: 0.0000 (0.2994)  triple_40: 0.0000 (0.0618)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [570/845]  eta: 0:01:32  loss: 27.4241 (27.5515)  loss_n_40: 6.1453 (6.1180)  loss_n_60: 7.1584 (7.0370)  loss_n_80: 6.7492 (6.7167)  loss_n_100: 7.1332 (7.2235)  triple_100: 0.0000 (0.0276)  triple_80: 0.0000 (0.0638)  triple_60: 0.0000 (0.3040)  triple_40: 0.0000 (0.0608)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [580/845]  eta: 0:01:28  loss: 27.4241 (27.5412)  loss_n_40: 6.1047 (6.1155)  loss_n_60: 7.0873 (7.0350)  loss_n_80: 6.8009 (6.7164)  loss_n_100: 7.3556 (7.2239)  triple_100: 0.0000 (0.0291)  triple_80: 0.0000 (0.0627)  triple_60: 0.0000 (0.2988)  triple_40: 0.0000 (0.0597)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [590/845]  eta: 0:01:25  loss: 27.1135 (27.5366)  loss_n_40: 6.0456 (6.1151)  loss_n_60: 7.0389 (7.0358)  loss_n_80: 6.8009 (6.7176)  loss_n_100: 7.3556 (7.2254)  triple_100: 0.0000 (0.0286)  triple_80: 0.0000 (0.0616)  triple_60: 0.0000 (0.2937)  triple_40: 0.0000 (0.0587)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [600/845]  eta: 0:01:22  loss: 27.4622 (27.5400)  loss_n_40: 6.3357 (6.1193)  loss_n_60: 7.3409 (7.0403)  loss_n_80: 6.8545 (6.7186)  loss_n_100: 7.3543 (7.2265)  triple_100: 0.0000 (0.0281)  triple_80: 0.0000 (0.0606)  triple_60: 0.0000 (0.2889)  triple_40: 0.0000 (0.0577)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [610/845]  eta: 0:01:18  loss: 27.3470 (27.5316)  loss_n_40: 6.4435 (6.1203)  loss_n_60: 7.2888 (7.0417)  loss_n_80: 6.4463 (6.7159)  loss_n_100: 7.0854 (7.2256)  triple_100: 0.0000 (0.0276)  triple_80: 0.0000 (0.0596)  triple_60: 0.0000 (0.2841)  triple_40: 0.0000 (0.0568)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [620/845]  eta: 0:01:15  loss: 26.1176 (27.5061)  loss_n_40: 5.8398 (6.1135)  loss_n_60: 6.8132 (7.0356)  loss_n_80: 6.3760 (6.7120)  loss_n_100: 7.0143 (7.2237)  triple_100: 0.0000 (0.0272)  triple_80: 0.0000 (0.0586)  triple_60: 0.0000 (0.2795)  triple_40: 0.0000 (0.0559)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [630/845]  eta: 0:01:12  loss: 25.7834 (27.5111)  loss_n_40: 5.7010 (6.1132)  loss_n_60: 6.6629 (7.0352)  loss_n_80: 6.3941 (6.7066)  loss_n_100: 6.9567 (7.2185)  triple_100: 0.0000 (0.0270)  triple_80: 0.0000 (0.0643)  triple_60: 0.0000 (0.2914)  triple_40: 0.0000 (0.0550)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [640/845]  eta: 0:01:08  loss: 26.1166 (27.5180)  loss_n_40: 6.1066 (6.1133)  loss_n_60: 7.0250 (7.0347)  loss_n_80: 6.4369 (6.7074)  loss_n_100: 7.0867 (7.2184)  triple_100: 0.0000 (0.0266)  triple_80: 0.0000 (0.0633)  triple_60: 0.0000 (0.2937)  triple_40: 0.0000 (0.0606)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [650/845]  eta: 0:01:05  loss: 26.8909 (27.5112)  loss_n_40: 6.2833 (6.1137)  loss_n_60: 7.1444 (7.0358)  loss_n_80: 6.4906 (6.7060)  loss_n_100: 7.1747 (7.2183)  triple_100: 0.0000 (0.0262)  triple_80: 0.0000 (0.0623)  triple_60: 0.0000 (0.2892)  triple_40: 0.0000 (0.0597)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [660/845]  eta: 0:01:02  loss: 25.7516 (27.4874)  loss_n_40: 5.9171 (6.1094)  loss_n_60: 6.9881 (7.0321)  loss_n_80: 6.3459 (6.7013)  loss_n_100: 6.9573 (7.2139)  triple_100: 0.0000 (0.0258)  triple_80: 0.0000 (0.0613)  triple_60: 0.0000 (0.2849)  triple_40: 0.0000 (0.0587)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [670/845]  eta: 0:00:58  loss: 25.7516 (27.4691)  loss_n_40: 5.9072 (6.1067)  loss_n_60: 6.8955 (7.0306)  loss_n_80: 6.0880 (6.6973)  loss_n_100: 6.6409 (7.2102)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0604)  triple_60: 0.0000 (0.2806)  triple_40: 0.0000 (0.0579)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [680/845]  eta: 0:00:55  loss: 25.9937 (27.4532)  loss_n_40: 6.0350 (6.1050)  loss_n_60: 7.0186 (7.0296)  loss_n_80: 6.0880 (6.6925)  loss_n_100: 6.7404 (7.2074)  triple_100: 0.0000 (0.0256)  triple_80: 0.0000 (0.0595)  triple_60: 0.0000 (0.2765)  triple_40: 0.0000 (0.0570)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [690/845]  eta: 0:00:51  loss: 27.1371 (27.4608)  loss_n_40: 6.2586 (6.1079)  loss_n_60: 7.1846 (7.0318)  loss_n_80: 6.5041 (6.6973)  loss_n_100: 7.0444 (7.2101)  triple_100: 0.0000 (0.0253)  triple_80: 0.0000 (0.0587)  triple_60: 0.0000 (0.2725)  triple_40: 0.0000 (0.0574)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [700/845]  eta: 0:00:48  loss: 27.8738 (27.4840)  loss_n_40: 6.3345 (6.1156)  loss_n_60: 7.2788 (7.0371)  loss_n_80: 6.9230 (6.6998)  loss_n_100: 7.3469 (7.2115)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0578)  triple_60: 0.0000 (0.2765)  triple_40: 0.0000 (0.0607)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [710/845]  eta: 0:00:45  loss: 28.2996 (27.5092)  loss_n_40: 6.5785 (6.1208)  loss_n_60: 7.3403 (7.0404)  loss_n_80: 6.9230 (6.7032)  loss_n_100: 7.3150 (7.2136)  triple_100: 0.0000 (0.0246)  triple_80: 0.0000 (0.0570)  triple_60: 0.0000 (0.2897)  triple_40: 0.0000 (0.0598)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [720/845]  eta: 0:00:41  loss: 27.6469 (27.5040)  loss_n_40: 6.1951 (6.1188)  loss_n_60: 7.1144 (7.0394)  loss_n_80: 7.0708 (6.7040)  loss_n_100: 7.3392 (7.2154)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0562)  triple_60: 0.0000 (0.2857)  triple_40: 0.0000 (0.0590)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [730/845]  eta: 0:00:38  loss: 26.9863 (27.4947)  loss_n_40: 5.9712 (6.1170)  loss_n_60: 6.8427 (7.0373)  loss_n_80: 6.7748 (6.7036)  loss_n_100: 7.3392 (7.2160)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0555)  triple_60: 0.0000 (0.2818)  triple_40: 0.0000 (0.0582)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [740/845]  eta: 0:00:35  loss: 26.0960 (27.4813)  loss_n_40: 5.8480 (6.1138)  loss_n_60: 6.7547 (7.0348)  loss_n_80: 6.4539 (6.7025)  loss_n_100: 7.1740 (7.2150)  triple_100: 0.0000 (0.0250)  triple_80: 0.0000 (0.0547)  triple_60: 0.0000 (0.2780)  triple_40: 0.0000 (0.0574)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [750/845]  eta: 0:00:31  loss: 26.0712 (27.5123)  loss_n_40: 5.9885 (6.1116)  loss_n_60: 6.7660 (7.0336)  loss_n_80: 6.4894 (6.7040)  loss_n_100: 7.0500 (7.2164)  triple_100: 0.0000 (0.0247)  triple_80: 0.0000 (0.0628)  triple_60: 0.0000 (0.3025)  triple_40: 0.0000 (0.0567)  time: 0.3346  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:3]  [760/845]  eta: 0:00:28  loss: 27.5887 (27.5132)  loss_n_40: 6.2909 (6.1136)  loss_n_60: 7.2379 (7.0350)  loss_n_80: 6.8097 (6.7058)  loss_n_100: 7.1590 (7.2180)  triple_100: 0.0000 (0.0244)  triple_80: 0.0000 (0.0620)  triple_60: 0.0000 (0.2985)  triple_40: 0.0000 (0.0559)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [770/845]  eta: 0:00:25  loss: 27.2658 (27.5097)  loss_n_40: 6.2202 (6.1161)  loss_n_60: 7.2889 (7.0376)  loss_n_80: 6.7127 (6.7040)  loss_n_100: 7.1590 (7.2169)  triple_100: 0.0000 (0.0241)  triple_80: 0.0000 (0.0612)  triple_60: 0.0000 (0.2946)  triple_40: 0.0000 (0.0552)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [780/845]  eta: 0:00:21  loss: 27.1415 (27.5193)  loss_n_40: 6.2258 (6.1190)  loss_n_60: 7.2018 (7.0407)  loss_n_80: 6.7905 (6.7074)  loss_n_100: 7.3096 (7.2202)  triple_100: 0.0000 (0.0262)  triple_80: 0.0000 (0.0604)  triple_60: 0.0000 (0.2908)  triple_40: 0.0000 (0.0545)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [790/845]  eta: 0:00:18  loss: 27.1415 (27.5109)  loss_n_40: 6.2095 (6.1176)  loss_n_60: 7.1269 (7.0386)  loss_n_80: 6.7968 (6.7076)  loss_n_100: 7.3096 (7.2206)  triple_100: 0.0000 (0.0259)  triple_80: 0.0000 (0.0596)  triple_60: 0.0000 (0.2872)  triple_40: 0.0000 (0.0538)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [800/845]  eta: 0:00:15  loss: 26.0280 (27.5048)  loss_n_40: 5.9243 (6.1161)  loss_n_60: 6.8081 (7.0371)  loss_n_80: 6.5934 (6.7081)  loss_n_100: 7.2224 (7.2222)  triple_100: 0.0000 (0.0256)  triple_80: 0.0000 (0.0589)  triple_60: 0.0000 (0.2836)  triple_40: 0.0000 (0.0531)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [810/845]  eta: 0:00:11  loss: 26.6094 (27.5014)  loss_n_40: 6.1094 (6.1160)  loss_n_60: 6.9732 (7.0375)  loss_n_80: 6.5934 (6.7093)  loss_n_100: 7.2098 (7.2226)  triple_100: 0.0000 (0.0252)  triple_80: 0.0000 (0.0582)  triple_60: 0.0000 (0.2801)  triple_40: 0.0000 (0.0525)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [820/845]  eta: 0:00:08  loss: 27.6224 (27.5010)  loss_n_40: 6.1788 (6.1179)  loss_n_60: 7.0750 (7.0388)  loss_n_80: 6.7256 (6.7102)  loss_n_100: 7.2098 (7.2229)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0575)  triple_60: 0.0000 (0.2767)  triple_40: 0.0000 (0.0521)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [830/845]  eta: 0:00:05  loss: 27.6175 (27.4978)  loss_n_40: 6.0286 (6.1185)  loss_n_60: 7.0210 (7.0386)  loss_n_80: 6.7488 (6.7108)  loss_n_100: 7.2818 (7.2238)  triple_100: 0.0000 (0.0246)  triple_80: 0.0000 (0.0568)  triple_60: 0.0000 (0.2733)  triple_40: 0.0000 (0.0515)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [840/845]  eta: 0:00:01  loss: 27.5818 (27.5037)  loss_n_40: 6.1003 (6.1207)  loss_n_60: 7.0429 (7.0405)  loss_n_80: 6.7751 (6.7135)  loss_n_100: 7.4771 (7.2263)  triple_100: 0.0000 (0.0256)  triple_80: 0.0000 (0.0561)  triple_60: 0.0000 (0.2701)  triple_40: 0.0000 (0.0509)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3]  [844/845]  eta: 0:00:00  loss: 27.5293 (27.5036)  loss_n_40: 6.1003 (6.1213)  loss_n_60: 7.0429 (7.0406)  loss_n_80: 6.7751 (6.7140)  loss_n_100: 7.4771 (7.2269)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0558)  triple_60: 0.0000 (0.2688)  triple_40: 0.0000 (0.0506)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:3] Total time: 0:04:43 (0.3353 s / it)\n",
      "Averaged stats: loss: 27.5293 (27.5036)  loss_n_40: 6.1003 (6.1213)  loss_n_60: 7.0429 (7.0406)  loss_n_80: 6.7751 (6.7140)  loss_n_100: 7.4771 (7.2269)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0558)  triple_60: 0.0000 (0.2688)  triple_40: 0.0000 (0.0506)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_3_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 7.227%\n",
      "Min loss_n_100: 4.783\n",
      "Best Epoch: 0.000\n",
      "Train: [epoch:4]  [   0/1724]  eta: 2:00:39  lr: 0.000060  loss: 27.9914 (27.9914)  loss_n_40: 6.0476 (6.0476)  loss_n_60: 7.0671 (7.0671)  loss_n_80: 7.1782 (7.1782)  loss_n_100: 7.6985 (7.6985)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1991  data: 0.4367  max mem: 46473\n",
      "Train: [epoch:4]  [  10/1724]  eta: 1:52:53  lr: 0.000060  loss: 27.8419 (27.6024)  loss_n_40: 6.0476 (6.1426)  loss_n_60: 7.0671 (7.0860)  loss_n_80: 6.9218 (6.8932)  loss_n_100: 7.2706 (7.3375)  triple_100: 0.0000 (0.0416)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1016)  triple_40: 0.0000 (0.0000)  time: 3.9518  data: 0.0399  max mem: 46473\n",
      "Train: [epoch:4]  [  20/1724]  eta: 1:51:52  lr: 0.000060  loss: 27.0478 (27.2905)  loss_n_40: 5.9826 (6.0833)  loss_n_60: 7.0004 (7.0494)  loss_n_80: 6.7348 (6.8131)  loss_n_100: 7.2332 (7.2697)  triple_100: 0.0000 (0.0218)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0532)  triple_40: 0.0000 (0.0000)  time: 3.9261  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [  30/1724]  eta: 1:51:04  lr: 0.000060  loss: 27.0421 (27.3522)  loss_n_40: 6.0023 (6.0778)  loss_n_60: 6.9678 (7.0341)  loss_n_80: 6.7124 (6.8111)  loss_n_100: 7.2332 (7.2557)  triple_100: 0.0000 (0.0502)  triple_80: 0.0000 (0.0254)  triple_60: 0.0000 (0.0977)  triple_40: 0.0000 (0.0000)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [  40/1724]  eta: 1:50:21  lr: 0.000060  loss: 27.0351 (27.3282)  loss_n_40: 6.0843 (6.0747)  loss_n_60: 6.9678 (7.0233)  loss_n_80: 6.7599 (6.8031)  loss_n_100: 7.2483 (7.2489)  triple_100: 0.0000 (0.0498)  triple_80: 0.0000 (0.0192)  triple_60: 0.0000 (0.0739)  triple_40: 0.0000 (0.0353)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [  50/1724]  eta: 1:49:38  lr: 0.000060  loss: 27.2021 (27.3310)  loss_n_40: 6.0937 (6.0642)  loss_n_60: 7.0280 (7.0253)  loss_n_80: 6.6396 (6.7610)  loss_n_100: 7.1136 (7.2219)  triple_100: 0.0000 (0.0433)  triple_80: 0.0000 (0.0355)  triple_60: 0.0000 (0.1515)  triple_40: 0.0000 (0.0284)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [  60/1724]  eta: 1:48:58  lr: 0.000060  loss: 27.3444 (27.2770)  loss_n_40: 6.0579 (6.0522)  loss_n_60: 7.0280 (7.0175)  loss_n_80: 6.5753 (6.7416)  loss_n_100: 7.0985 (7.2162)  triple_100: 0.0000 (0.0368)  triple_80: 0.0000 (0.0297)  triple_60: 0.0000 (0.1592)  triple_40: 0.0000 (0.0238)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [  70/1724]  eta: 1:48:17  lr: 0.000060  loss: 27.0943 (27.3514)  loss_n_40: 5.9357 (6.0390)  loss_n_60: 6.8824 (7.0148)  loss_n_80: 6.6367 (6.7322)  loss_n_100: 7.0941 (7.1978)  triple_100: 0.0000 (0.0344)  triple_80: 0.0000 (0.0288)  triple_60: 0.0000 (0.2548)  triple_40: 0.0000 (0.0496)  time: 3.9243  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [  80/1724]  eta: 1:47:37  lr: 0.000060  loss: 26.5992 (27.2625)  loss_n_40: 5.9013 (6.0212)  loss_n_60: 6.9121 (7.0059)  loss_n_80: 6.6096 (6.7008)  loss_n_100: 7.0328 (7.1733)  triple_100: 0.0000 (0.0454)  triple_80: 0.0000 (0.0326)  triple_60: 0.0000 (0.2260)  triple_40: 0.0000 (0.0574)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [  90/1724]  eta: 1:46:56  lr: 0.000060  loss: 26.3987 (27.1787)  loss_n_40: 5.8262 (6.0022)  loss_n_60: 6.9029 (6.9902)  loss_n_80: 6.5432 (6.6848)  loss_n_100: 7.0307 (7.1638)  triple_100: 0.0000 (0.0416)  triple_80: 0.0000 (0.0290)  triple_60: 0.0000 (0.2130)  triple_40: 0.0000 (0.0541)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 100/1724]  eta: 1:46:17  lr: 0.000060  loss: 26.8973 (27.3092)  loss_n_40: 5.9744 (6.0070)  loss_n_60: 6.9046 (6.9977)  loss_n_80: 6.5792 (6.6922)  loss_n_100: 7.1348 (7.1736)  triple_100: 0.0000 (0.0375)  triple_80: 0.0000 (0.0272)  triple_60: 0.0000 (0.2950)  triple_40: 0.0000 (0.0791)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 110/1724]  eta: 1:45:36  lr: 0.000060  loss: 27.0950 (27.2943)  loss_n_40: 6.0356 (6.0052)  loss_n_60: 7.0995 (7.0027)  loss_n_80: 6.6882 (6.6858)  loss_n_100: 7.2217 (7.1716)  triple_100: 0.0000 (0.0412)  triple_80: 0.0000 (0.0318)  triple_60: 0.0000 (0.2841)  triple_40: 0.0000 (0.0719)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 120/1724]  eta: 1:44:57  lr: 0.000060  loss: 26.8224 (27.2460)  loss_n_40: 5.9362 (5.9984)  loss_n_60: 7.0136 (7.0042)  loss_n_80: 6.5924 (6.6793)  loss_n_100: 7.1574 (7.1697)  triple_100: 0.0000 (0.0386)  triple_80: 0.0000 (0.0292)  triple_60: 0.0000 (0.2606)  triple_40: 0.0000 (0.0660)  time: 3.9222  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [ 130/1724]  eta: 1:44:17  lr: 0.000060  loss: 26.3450 (27.1380)  loss_n_40: 5.8020 (5.9737)  loss_n_60: 6.9288 (6.9890)  loss_n_80: 6.5038 (6.6562)  loss_n_100: 7.0126 (7.1498)  triple_100: 0.0000 (0.0388)  triple_80: 0.0000 (0.0270)  triple_60: 0.0000 (0.2425)  triple_40: 0.0000 (0.0609)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 140/1724]  eta: 1:43:37  lr: 0.000060  loss: 25.9917 (27.1027)  loss_n_40: 5.7628 (5.9664)  loss_n_60: 6.7855 (6.9848)  loss_n_80: 6.4459 (6.6438)  loss_n_100: 6.9322 (7.1355)  triple_100: 0.0000 (0.0361)  triple_80: 0.0000 (0.0250)  triple_60: 0.0000 (0.2253)  triple_40: 0.0000 (0.0857)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 150/1724]  eta: 1:42:58  lr: 0.000060  loss: 26.5780 (27.2003)  loss_n_40: 5.8605 (5.9721)  loss_n_60: 6.9811 (6.9877)  loss_n_80: 6.4898 (6.6477)  loss_n_100: 7.0416 (7.1384)  triple_100: 0.0000 (0.0631)  triple_80: 0.0000 (0.0328)  triple_60: 0.0000 (0.2547)  triple_40: 0.0000 (0.1039)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 160/1724]  eta: 1:42:18  lr: 0.000060  loss: 27.1990 (27.1921)  loss_n_40: 6.0035 (5.9767)  loss_n_60: 7.0405 (6.9951)  loss_n_80: 6.7023 (6.6439)  loss_n_100: 7.1864 (7.1362)  triple_100: 0.0000 (0.0591)  triple_80: 0.0000 (0.0308)  triple_60: 0.0000 (0.2527)  triple_40: 0.0000 (0.0975)  time: 3.9212  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 170/1724]  eta: 1:41:39  lr: 0.000060  loss: 26.1674 (27.1263)  loss_n_40: 5.8295 (5.9613)  loss_n_60: 6.9826 (6.9827)  loss_n_80: 6.4766 (6.6333)  loss_n_100: 7.1088 (7.1301)  triple_100: 0.0000 (0.0587)  triple_80: 0.0000 (0.0290)  triple_60: 0.0000 (0.2395)  triple_40: 0.0000 (0.0918)  time: 3.9214  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [ 180/1724]  eta: 1:40:59  lr: 0.000060  loss: 26.3187 (27.1285)  loss_n_40: 5.8157 (5.9683)  loss_n_60: 6.8781 (6.9880)  loss_n_80: 6.6086 (6.6391)  loss_n_100: 7.1547 (7.1359)  triple_100: 0.0000 (0.0561)  triple_80: 0.0000 (0.0274)  triple_60: 0.0000 (0.2265)  triple_40: 0.0000 (0.0871)  time: 3.9225  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [ 190/1724]  eta: 1:40:20  lr: 0.000060  loss: 27.0593 (27.1432)  loss_n_40: 6.1016 (5.9712)  loss_n_60: 7.0242 (6.9846)  loss_n_80: 6.7480 (6.6394)  loss_n_100: 7.1789 (7.1354)  triple_100: 0.0000 (0.0595)  triple_80: 0.0000 (0.0272)  triple_60: 0.0000 (0.2422)  triple_40: 0.0000 (0.0837)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 200/1724]  eta: 1:39:40  lr: 0.000060  loss: 27.0800 (27.1317)  loss_n_40: 6.0830 (5.9737)  loss_n_60: 7.0242 (6.9842)  loss_n_80: 6.7786 (6.6440)  loss_n_100: 7.0651 (7.1343)  triple_100: 0.0000 (0.0569)  triple_80: 0.0000 (0.0258)  triple_60: 0.0000 (0.2334)  triple_40: 0.0000 (0.0795)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 210/1724]  eta: 1:39:01  lr: 0.000060  loss: 26.9505 (27.1408)  loss_n_40: 5.9698 (5.9728)  loss_n_60: 7.0171 (6.9839)  loss_n_80: 6.7231 (6.6384)  loss_n_100: 7.0379 (7.1284)  triple_100: 0.0000 (0.0554)  triple_80: 0.0000 (0.0304)  triple_60: 0.0000 (0.2556)  triple_40: 0.0000 (0.0757)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 220/1724]  eta: 1:38:21  lr: 0.000060  loss: 26.6774 (27.1679)  loss_n_40: 5.9397 (5.9711)  loss_n_60: 6.9804 (6.9828)  loss_n_80: 6.5192 (6.6390)  loss_n_100: 7.0944 (7.1298)  triple_100: 0.0000 (0.0702)  triple_80: 0.0000 (0.0302)  triple_60: 0.0000 (0.2618)  triple_40: 0.0000 (0.0830)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 230/1724]  eta: 1:37:42  lr: 0.000060  loss: 26.2186 (27.1289)  loss_n_40: 5.8693 (5.9644)  loss_n_60: 6.8633 (6.9764)  loss_n_80: 6.4967 (6.6311)  loss_n_100: 7.0548 (7.1257)  triple_100: 0.0000 (0.0697)  triple_80: 0.0000 (0.0289)  triple_60: 0.0000 (0.2533)  triple_40: 0.0000 (0.0794)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 240/1724]  eta: 1:37:02  lr: 0.000060  loss: 25.9754 (27.0781)  loss_n_40: 5.7650 (5.9564)  loss_n_60: 6.7334 (6.9675)  loss_n_80: 6.3972 (6.6214)  loss_n_100: 7.0306 (7.1187)  triple_100: 0.0000 (0.0675)  triple_80: 0.0000 (0.0277)  triple_60: 0.0000 (0.2428)  triple_40: 0.0000 (0.0761)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 250/1724]  eta: 1:36:23  lr: 0.000060  loss: 26.0300 (27.0412)  loss_n_40: 5.7256 (5.9479)  loss_n_60: 6.6959 (6.9570)  loss_n_80: 6.4373 (6.6155)  loss_n_100: 7.0394 (7.1170)  triple_100: 0.0000 (0.0653)  triple_80: 0.0000 (0.0266)  triple_60: 0.0000 (0.2388)  triple_40: 0.0000 (0.0731)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 260/1724]  eta: 1:35:44  lr: 0.000060  loss: 26.0533 (26.9955)  loss_n_40: 5.7284 (5.9435)  loss_n_60: 6.7276 (6.9522)  loss_n_80: 6.3762 (6.6028)  loss_n_100: 6.9759 (7.1035)  triple_100: 0.0000 (0.0628)  triple_80: 0.0000 (0.0256)  triple_60: 0.0000 (0.2348)  triple_40: 0.0000 (0.0703)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 270/1724]  eta: 1:35:04  lr: 0.000060  loss: 25.8572 (26.9739)  loss_n_40: 5.8305 (5.9420)  loss_n_60: 6.8382 (6.9485)  loss_n_80: 6.3762 (6.5972)  loss_n_100: 6.7732 (7.0952)  triple_100: 0.0000 (0.0618)  triple_80: 0.0000 (0.0246)  triple_60: 0.0000 (0.2320)  triple_40: 0.0000 (0.0726)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 280/1724]  eta: 1:34:25  lr: 0.000060  loss: 25.7747 (26.9196)  loss_n_40: 5.8168 (5.9352)  loss_n_60: 6.8366 (6.9421)  loss_n_80: 6.3080 (6.5827)  loss_n_100: 6.8366 (7.0823)  triple_100: 0.0000 (0.0598)  triple_80: 0.0000 (0.0238)  triple_60: 0.0000 (0.2238)  triple_40: 0.0000 (0.0700)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 290/1724]  eta: 1:33:46  lr: 0.000060  loss: 25.3064 (26.8834)  loss_n_40: 5.8386 (5.9331)  loss_n_60: 6.7771 (6.9386)  loss_n_80: 6.2756 (6.5733)  loss_n_100: 6.7875 (7.0703)  triple_100: 0.0000 (0.0584)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.2183)  triple_40: 0.0000 (0.0676)  time: 3.9214  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 300/1724]  eta: 1:33:06  lr: 0.000060  loss: 25.4920 (26.8467)  loss_n_40: 5.8582 (5.9297)  loss_n_60: 6.7716 (6.9317)  loss_n_80: 6.2756 (6.5669)  loss_n_100: 6.7273 (7.0610)  triple_100: 0.0000 (0.0581)  triple_80: 0.0000 (0.0231)  triple_60: 0.0000 (0.2111)  triple_40: 0.0000 (0.0654)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 310/1724]  eta: 1:32:27  lr: 0.000060  loss: 25.4026 (26.8232)  loss_n_40: 5.8414 (5.9224)  loss_n_60: 6.7088 (6.9246)  loss_n_80: 6.2116 (6.5529)  loss_n_100: 6.6146 (7.0452)  triple_100: 0.0000 (0.0586)  triple_80: 0.0000 (0.0251)  triple_60: 0.0000 (0.2256)  triple_40: 0.0000 (0.0687)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 320/1724]  eta: 1:31:48  lr: 0.000060  loss: 25.5011 (26.8258)  loss_n_40: 5.8681 (5.9188)  loss_n_60: 6.8160 (6.9225)  loss_n_80: 6.2251 (6.5439)  loss_n_100: 6.6025 (7.0359)  triple_100: 0.0000 (0.0638)  triple_80: 0.0000 (0.0313)  triple_60: 0.0000 (0.2419)  triple_40: 0.0000 (0.0678)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 330/1724]  eta: 1:31:09  lr: 0.000060  loss: 26.1216 (26.8052)  loss_n_40: 5.9237 (5.9181)  loss_n_60: 6.9204 (6.9221)  loss_n_80: 6.2837 (6.5395)  loss_n_100: 6.8107 (7.0326)  triple_100: 0.0000 (0.0623)  triple_80: 0.0000 (0.0303)  triple_60: 0.0000 (0.2346)  triple_40: 0.0000 (0.0657)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 340/1724]  eta: 1:30:29  lr: 0.000060  loss: 26.2842 (26.7922)  loss_n_40: 5.9776 (5.9194)  loss_n_60: 6.9900 (6.9217)  loss_n_80: 6.3860 (6.5381)  loss_n_100: 6.9067 (7.0296)  triple_100: 0.0000 (0.0624)  triple_80: 0.0000 (0.0294)  triple_60: 0.0000 (0.2277)  triple_40: 0.0000 (0.0638)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 350/1724]  eta: 1:29:50  lr: 0.000060  loss: 25.6350 (26.7619)  loss_n_40: 5.8230 (5.9172)  loss_n_60: 6.7252 (6.9160)  loss_n_80: 6.3386 (6.5278)  loss_n_100: 6.7858 (7.0182)  triple_100: 0.0000 (0.0608)  triple_80: 0.0000 (0.0286)  triple_60: 0.0000 (0.2286)  triple_40: 0.0000 (0.0648)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 360/1724]  eta: 1:29:11  lr: 0.000060  loss: 25.2377 (26.7219)  loss_n_40: 5.6544 (5.9105)  loss_n_60: 6.6399 (6.9096)  loss_n_80: 6.1634 (6.5200)  loss_n_100: 6.6875 (7.0096)  triple_100: 0.0000 (0.0591)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.2223)  triple_40: 0.0000 (0.0630)  time: 3.9221  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [ 370/1724]  eta: 1:28:32  lr: 0.000060  loss: 25.2377 (26.7210)  loss_n_40: 5.7119 (5.9086)  loss_n_60: 6.6665 (6.9065)  loss_n_80: 6.1362 (6.5103)  loss_n_100: 6.6849 (7.0010)  triple_100: 0.0000 (0.0679)  triple_80: 0.0000 (0.0285)  triple_60: 0.0000 (0.2281)  triple_40: 0.0000 (0.0700)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 380/1724]  eta: 1:27:52  lr: 0.000060  loss: 25.9443 (26.7089)  loss_n_40: 5.9161 (5.9061)  loss_n_60: 6.6664 (6.9007)  loss_n_80: 6.3717 (6.5061)  loss_n_100: 6.7851 (6.9978)  triple_100: 0.0000 (0.0690)  triple_80: 0.0000 (0.0305)  triple_60: 0.0000 (0.2304)  triple_40: 0.0000 (0.0682)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 390/1724]  eta: 1:27:13  lr: 0.000060  loss: 25.9443 (26.6886)  loss_n_40: 5.8863 (5.9038)  loss_n_60: 6.6664 (6.8960)  loss_n_80: 6.2725 (6.5015)  loss_n_100: 6.7851 (6.9925)  triple_100: 0.0000 (0.0685)  triple_80: 0.0000 (0.0297)  triple_60: 0.0000 (0.2301)  triple_40: 0.0000 (0.0664)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 400/1724]  eta: 1:26:34  lr: 0.000060  loss: 25.6293 (26.6631)  loss_n_40: 5.7435 (5.8994)  loss_n_60: 6.6963 (6.8923)  loss_n_80: 6.1364 (6.4924)  loss_n_100: 6.6602 (6.9837)  triple_100: 0.0000 (0.0674)  triple_80: 0.0000 (0.0293)  triple_60: 0.0000 (0.2338)  triple_40: 0.0000 (0.0648)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 410/1724]  eta: 1:25:54  lr: 0.000060  loss: 25.7102 (26.6554)  loss_n_40: 5.7163 (5.8937)  loss_n_60: 6.6660 (6.8856)  loss_n_80: 6.1971 (6.4885)  loss_n_100: 6.7653 (6.9803)  triple_100: 0.0000 (0.0719)  triple_80: 0.0000 (0.0298)  triple_60: 0.0000 (0.2413)  triple_40: 0.0000 (0.0644)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 420/1724]  eta: 1:25:15  lr: 0.000060  loss: 25.5869 (26.6214)  loss_n_40: 5.7163 (5.8866)  loss_n_60: 6.6660 (6.8797)  loss_n_80: 6.2925 (6.4835)  loss_n_100: 6.7745 (6.9736)  triple_100: 0.0000 (0.0704)  triple_80: 0.0000 (0.0291)  triple_60: 0.0000 (0.2356)  triple_40: 0.0000 (0.0629)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 430/1724]  eta: 1:24:36  lr: 0.000060  loss: 25.3681 (26.6077)  loss_n_40: 5.7395 (5.8855)  loss_n_60: 6.7057 (6.8773)  loss_n_80: 6.2909 (6.4786)  loss_n_100: 6.7398 (6.9681)  triple_100: 0.0000 (0.0696)  triple_80: 0.0000 (0.0284)  triple_60: 0.0000 (0.2358)  triple_40: 0.0000 (0.0643)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 440/1724]  eta: 1:23:57  lr: 0.000060  loss: 25.9718 (26.5927)  loss_n_40: 5.8536 (5.8842)  loss_n_60: 6.8365 (6.8764)  loss_n_80: 6.3762 (6.4790)  loss_n_100: 6.7461 (6.9639)  triple_100: 0.0000 (0.0681)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.2305)  triple_40: 0.0000 (0.0629)  time: 3.9213  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 450/1724]  eta: 1:23:17  lr: 0.000060  loss: 25.5731 (26.5610)  loss_n_40: 5.7781 (5.8780)  loss_n_60: 6.6796 (6.8699)  loss_n_80: 6.3762 (6.4740)  loss_n_100: 6.7152 (6.9561)  triple_100: 0.0000 (0.0666)  triple_80: 0.0000 (0.0271)  triple_60: 0.0000 (0.2267)  triple_40: 0.0000 (0.0627)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 460/1724]  eta: 1:22:38  lr: 0.000060  loss: 25.3259 (26.5352)  loss_n_40: 5.6093 (5.8746)  loss_n_60: 6.6572 (6.8675)  loss_n_80: 6.2778 (6.4693)  loss_n_100: 6.6118 (6.9478)  triple_100: 0.0000 (0.0651)  triple_80: 0.0000 (0.0265)  triple_60: 0.0000 (0.2229)  triple_40: 0.0000 (0.0614)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 470/1724]  eta: 1:21:59  lr: 0.000060  loss: 25.5687 (26.5145)  loss_n_40: 5.7118 (5.8727)  loss_n_60: 6.6572 (6.8627)  loss_n_80: 6.3295 (6.4667)  loss_n_100: 6.6545 (6.9437)  triple_100: 0.0000 (0.0644)  triple_80: 0.0000 (0.0260)  triple_60: 0.0000 (0.2182)  triple_40: 0.0000 (0.0601)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 480/1724]  eta: 1:21:20  lr: 0.000060  loss: 25.0583 (26.4795)  loss_n_40: 5.5968 (5.8649)  loss_n_60: 6.5144 (6.8549)  loss_n_80: 6.2703 (6.4605)  loss_n_100: 6.6561 (6.9350)  triple_100: 0.0000 (0.0636)  triple_80: 0.0000 (0.0266)  triple_60: 0.0000 (0.2153)  triple_40: 0.0000 (0.0588)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 490/1724]  eta: 1:20:40  lr: 0.000060  loss: 25.0583 (26.4585)  loss_n_40: 5.5747 (5.8611)  loss_n_60: 6.5719 (6.8512)  loss_n_80: 6.2863 (6.4565)  loss_n_100: 6.6010 (6.9273)  triple_100: 0.0000 (0.0624)  triple_80: 0.0000 (0.0260)  triple_60: 0.0000 (0.2154)  triple_40: 0.0000 (0.0586)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 500/1724]  eta: 1:20:01  lr: 0.000060  loss: 25.5554 (26.4594)  loss_n_40: 5.6933 (5.8593)  loss_n_60: 6.7064 (6.8487)  loss_n_80: 6.3128 (6.4524)  loss_n_100: 6.6048 (6.9212)  triple_100: 0.0000 (0.0638)  triple_80: 0.0000 (0.0286)  triple_60: 0.0000 (0.2232)  triple_40: 0.0000 (0.0622)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 510/1724]  eta: 1:19:22  lr: 0.000060  loss: 26.1864 (26.4641)  loss_n_40: 5.7841 (5.8567)  loss_n_60: 6.7367 (6.8491)  loss_n_80: 6.4225 (6.4554)  loss_n_100: 6.7987 (6.9231)  triple_100: 0.0000 (0.0651)  triple_80: 0.0000 (0.0281)  triple_60: 0.0000 (0.2256)  triple_40: 0.0000 (0.0610)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 520/1724]  eta: 1:18:42  lr: 0.000060  loss: 26.0101 (26.4487)  loss_n_40: 5.7841 (5.8531)  loss_n_60: 6.8684 (6.8460)  loss_n_80: 6.4135 (6.4525)  loss_n_100: 6.8653 (6.9221)  triple_100: 0.0000 (0.0660)  triple_80: 0.0000 (0.0275)  triple_60: 0.0000 (0.2217)  triple_40: 0.0000 (0.0599)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 530/1724]  eta: 1:18:03  lr: 0.000060  loss: 25.8042 (26.4319)  loss_n_40: 5.7314 (5.8511)  loss_n_60: 6.6751 (6.8433)  loss_n_80: 6.3987 (6.4499)  loss_n_100: 6.8233 (6.9192)  triple_100: 0.0000 (0.0647)  triple_80: 0.0000 (0.0270)  triple_60: 0.0000 (0.2180)  triple_40: 0.0000 (0.0588)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 540/1724]  eta: 1:17:24  lr: 0.000060  loss: 25.2775 (26.4129)  loss_n_40: 5.6168 (5.8449)  loss_n_60: 6.6249 (6.8380)  loss_n_80: 5.9672 (6.4425)  loss_n_100: 6.5513 (6.9122)  triple_100: 0.0000 (0.0652)  triple_80: 0.0000 (0.0285)  triple_60: 0.0000 (0.2239)  triple_40: 0.0000 (0.0577)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 550/1724]  eta: 1:16:45  lr: 0.000060  loss: 24.4279 (26.3861)  loss_n_40: 5.5117 (5.8408)  loss_n_60: 6.5715 (6.8343)  loss_n_80: 5.9348 (6.4344)  loss_n_100: 6.5010 (6.9038)  triple_100: 0.0000 (0.0640)  triple_80: 0.0000 (0.0280)  triple_60: 0.0000 (0.2242)  triple_40: 0.0000 (0.0567)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 560/1724]  eta: 1:16:05  lr: 0.000060  loss: 25.4166 (26.3757)  loss_n_40: 5.6980 (5.8405)  loss_n_60: 6.6308 (6.8322)  loss_n_80: 6.2461 (6.4351)  loss_n_100: 6.6263 (6.9018)  triple_100: 0.0000 (0.0629)  triple_80: 0.0000 (0.0275)  triple_60: 0.0000 (0.2202)  triple_40: 0.0000 (0.0556)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 570/1724]  eta: 1:15:26  lr: 0.000060  loss: 25.2673 (26.3522)  loss_n_40: 5.6989 (5.8379)  loss_n_60: 6.6308 (6.8292)  loss_n_80: 6.2496 (6.4266)  loss_n_100: 6.6391 (6.8933)  triple_100: 0.0000 (0.0624)  triple_80: 0.0000 (0.0270)  triple_60: 0.0000 (0.2171)  triple_40: 0.0000 (0.0586)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 580/1724]  eta: 1:14:47  lr: 0.000060  loss: 24.8080 (26.3462)  loss_n_40: 5.6286 (5.8358)  loss_n_60: 6.6282 (6.8267)  loss_n_80: 6.0811 (6.4249)  loss_n_100: 6.3643 (6.8879)  triple_100: 0.0000 (0.0617)  triple_80: 0.0000 (0.0265)  triple_60: 0.0000 (0.2235)  triple_40: 0.0000 (0.0592)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 590/1724]  eta: 1:14:08  lr: 0.000060  loss: 25.3759 (26.3321)  loss_n_40: 5.6804 (5.8334)  loss_n_60: 6.6573 (6.8234)  loss_n_80: 6.4214 (6.4229)  loss_n_100: 6.6458 (6.8833)  triple_100: 0.0000 (0.0627)  triple_80: 0.0000 (0.0261)  triple_60: 0.0000 (0.2220)  triple_40: 0.0000 (0.0583)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 600/1724]  eta: 1:13:28  lr: 0.000060  loss: 25.2360 (26.3171)  loss_n_40: 5.7776 (5.8327)  loss_n_60: 6.7176 (6.8211)  loss_n_80: 6.2689 (6.4187)  loss_n_100: 6.5214 (6.8776)  triple_100: 0.0000 (0.0629)  triple_80: 0.0000 (0.0266)  triple_60: 0.0000 (0.2202)  triple_40: 0.0000 (0.0574)  time: 3.9226  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [ 610/1724]  eta: 1:12:49  lr: 0.000060  loss: 25.0262 (26.3038)  loss_n_40: 5.7184 (5.8306)  loss_n_60: 6.6431 (6.8191)  loss_n_80: 6.1101 (6.4156)  loss_n_100: 6.4523 (6.8724)  triple_100: 0.0000 (0.0634)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.2202)  triple_40: 0.0000 (0.0564)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 620/1724]  eta: 1:12:10  lr: 0.000060  loss: 24.8572 (26.2840)  loss_n_40: 5.4512 (5.8254)  loss_n_60: 6.4662 (6.8137)  loss_n_80: 6.0375 (6.4095)  loss_n_100: 6.4523 (6.8670)  triple_100: 0.0000 (0.0649)  triple_80: 0.0000 (0.0259)  triple_60: 0.0000 (0.2214)  triple_40: 0.0000 (0.0562)  time: 3.9214  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 630/1724]  eta: 1:11:31  lr: 0.000060  loss: 25.0069 (26.3039)  loss_n_40: 5.5894 (5.8248)  loss_n_60: 6.5106 (6.8115)  loss_n_80: 6.0423 (6.4066)  loss_n_100: 6.4984 (6.8634)  triple_100: 0.0000 (0.0746)  triple_80: 0.0000 (0.0381)  triple_60: 0.0000 (0.2286)  triple_40: 0.0000 (0.0563)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 640/1724]  eta: 1:10:51  lr: 0.000060  loss: 24.9424 (26.2759)  loss_n_40: 5.5917 (5.8203)  loss_n_60: 6.5449 (6.8063)  loss_n_80: 6.0037 (6.4003)  loss_n_100: 6.4712 (6.8575)  triple_100: 0.0000 (0.0734)  triple_80: 0.0000 (0.0375)  triple_60: 0.0000 (0.2251)  triple_40: 0.0000 (0.0555)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 650/1724]  eta: 1:10:12  lr: 0.000060  loss: 24.8397 (26.2589)  loss_n_40: 5.5917 (5.8182)  loss_n_60: 6.5305 (6.8039)  loss_n_80: 5.9555 (6.3971)  loss_n_100: 6.4712 (6.8532)  triple_100: 0.0000 (0.0726)  triple_80: 0.0000 (0.0369)  triple_60: 0.0000 (0.2226)  triple_40: 0.0000 (0.0546)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 660/1724]  eta: 1:09:33  lr: 0.000060  loss: 25.0110 (26.2364)  loss_n_40: 5.6697 (5.8156)  loss_n_60: 6.5616 (6.8006)  loss_n_80: 6.1762 (6.3927)  loss_n_100: 6.5384 (6.8467)  triple_100: 0.0000 (0.0715)  triple_80: 0.0000 (0.0363)  triple_60: 0.0000 (0.2192)  triple_40: 0.0000 (0.0538)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 670/1724]  eta: 1:08:53  lr: 0.000060  loss: 24.3481 (26.2066)  loss_n_40: 5.5674 (5.8113)  loss_n_60: 6.5136 (6.7959)  loss_n_80: 5.8847 (6.3844)  loss_n_100: 6.1948 (6.8369)  triple_100: 0.0000 (0.0704)  triple_80: 0.0000 (0.0363)  triple_60: 0.0000 (0.2169)  triple_40: 0.0000 (0.0546)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 680/1724]  eta: 1:08:14  lr: 0.000060  loss: 24.0407 (26.1770)  loss_n_40: 5.5674 (5.8066)  loss_n_60: 6.5092 (6.7911)  loss_n_80: 5.8610 (6.3771)  loss_n_100: 6.1835 (6.8284)  triple_100: 0.0000 (0.0694)  triple_80: 0.0000 (0.0357)  triple_60: 0.0000 (0.2149)  triple_40: 0.0000 (0.0538)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 690/1724]  eta: 1:07:35  lr: 0.000060  loss: 24.4524 (26.1532)  loss_n_40: 5.5377 (5.8029)  loss_n_60: 6.4633 (6.7870)  loss_n_80: 5.8975 (6.3718)  loss_n_100: 6.3496 (6.8217)  triple_100: 0.0000 (0.0689)  triple_80: 0.0000 (0.0352)  triple_60: 0.0000 (0.2126)  triple_40: 0.0000 (0.0530)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 700/1724]  eta: 1:06:56  lr: 0.000060  loss: 24.6720 (26.1362)  loss_n_40: 5.5775 (5.8016)  loss_n_60: 6.4633 (6.7849)  loss_n_80: 6.0243 (6.3681)  loss_n_100: 6.3516 (6.8155)  triple_100: 0.0000 (0.0679)  triple_80: 0.0000 (0.0347)  triple_60: 0.0000 (0.2101)  triple_40: 0.0000 (0.0534)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 710/1724]  eta: 1:06:17  lr: 0.000060  loss: 24.6720 (26.1104)  loss_n_40: 5.5308 (5.7975)  loss_n_60: 6.4587 (6.7795)  loss_n_80: 5.9122 (6.3605)  loss_n_100: 6.2742 (6.8078)  triple_100: 0.0000 (0.0670)  triple_80: 0.0000 (0.0342)  triple_60: 0.0000 (0.2107)  triple_40: 0.0000 (0.0533)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 720/1724]  eta: 1:05:37  lr: 0.000060  loss: 24.3124 (26.0876)  loss_n_40: 5.5217 (5.7940)  loss_n_60: 6.4380 (6.7751)  loss_n_80: 5.8847 (6.3556)  loss_n_100: 6.2439 (6.8012)  triple_100: 0.0000 (0.0666)  triple_80: 0.0000 (0.0340)  triple_60: 0.0000 (0.2085)  triple_40: 0.0000 (0.0525)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 730/1724]  eta: 1:04:58  lr: 0.000060  loss: 24.3840 (26.0649)  loss_n_40: 5.5477 (5.7908)  loss_n_60: 6.4539 (6.7709)  loss_n_80: 6.0212 (6.3516)  loss_n_100: 6.3099 (6.7948)  triple_100: 0.0000 (0.0659)  triple_80: 0.0000 (0.0335)  triple_60: 0.0000 (0.2056)  triple_40: 0.0000 (0.0518)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 740/1724]  eta: 1:04:19  lr: 0.000060  loss: 23.8203 (26.0374)  loss_n_40: 5.3854 (5.7865)  loss_n_60: 6.3737 (6.7658)  loss_n_80: 5.8419 (6.3441)  loss_n_100: 6.1720 (6.7861)  triple_100: 0.0000 (0.0660)  triple_80: 0.0000 (0.0331)  triple_60: 0.0000 (0.2047)  triple_40: 0.0000 (0.0511)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 750/1724]  eta: 1:03:39  lr: 0.000060  loss: 23.7888 (26.0058)  loss_n_40: 5.3683 (5.7798)  loss_n_60: 6.2748 (6.7585)  loss_n_80: 5.8041 (6.3366)  loss_n_100: 6.1686 (6.7785)  triple_100: 0.0000 (0.0659)  triple_80: 0.0000 (0.0326)  triple_60: 0.0000 (0.2024)  triple_40: 0.0000 (0.0513)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 760/1724]  eta: 1:03:00  lr: 0.000060  loss: 23.3224 (25.9734)  loss_n_40: 5.2152 (5.7740)  loss_n_60: 6.1381 (6.7527)  loss_n_80: 5.7096 (6.3291)  loss_n_100: 6.0644 (6.7689)  triple_100: 0.0000 (0.0651)  triple_80: 0.0000 (0.0327)  triple_60: 0.0000 (0.1999)  triple_40: 0.0000 (0.0510)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 770/1724]  eta: 1:02:21  lr: 0.000060  loss: 23.4244 (25.9454)  loss_n_40: 5.3025 (5.7684)  loss_n_60: 6.2245 (6.7468)  loss_n_80: 5.8151 (6.3236)  loss_n_100: 6.0644 (6.7610)  triple_100: 0.0000 (0.0642)  triple_80: 0.0000 (0.0323)  triple_60: 0.0000 (0.1977)  triple_40: 0.0000 (0.0516)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 780/1724]  eta: 1:01:42  lr: 0.000060  loss: 23.7531 (25.9230)  loss_n_40: 5.4408 (5.7661)  loss_n_60: 6.4027 (6.7437)  loss_n_80: 5.8692 (6.3169)  loss_n_100: 6.1442 (6.7528)  triple_100: 0.0000 (0.0640)  triple_80: 0.0000 (0.0336)  triple_60: 0.0000 (0.1952)  triple_40: 0.0000 (0.0509)  time: 3.9212  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 790/1724]  eta: 1:01:03  lr: 0.000060  loss: 24.0092 (25.9317)  loss_n_40: 5.5249 (5.7629)  loss_n_60: 6.5416 (6.7408)  loss_n_80: 5.8718 (6.3118)  loss_n_100: 6.2205 (6.7471)  triple_100: 0.0000 (0.0722)  triple_80: 0.0000 (0.0382)  triple_60: 0.0000 (0.2046)  triple_40: 0.0000 (0.0541)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 800/1724]  eta: 1:00:23  lr: 0.000060  loss: 24.0751 (25.9131)  loss_n_40: 5.4324 (5.7589)  loss_n_60: 6.5052 (6.7374)  loss_n_80: 5.9364 (6.3069)  loss_n_100: 6.3241 (6.7428)  triple_100: 0.0000 (0.0713)  triple_80: 0.0000 (0.0377)  triple_60: 0.0000 (0.2046)  triple_40: 0.0000 (0.0534)  time: 3.9213  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 810/1724]  eta: 0:59:44  lr: 0.000060  loss: 24.0220 (25.8906)  loss_n_40: 5.4099 (5.7543)  loss_n_60: 6.3671 (6.7327)  loss_n_80: 5.9848 (6.3018)  loss_n_100: 6.3638 (6.7378)  triple_100: 0.0000 (0.0710)  triple_80: 0.0000 (0.0372)  triple_60: 0.0000 (0.2021)  triple_40: 0.0000 (0.0535)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 820/1724]  eta: 0:59:05  lr: 0.000060  loss: 23.5868 (25.8609)  loss_n_40: 5.3800 (5.7496)  loss_n_60: 6.3320 (6.7283)  loss_n_80: 5.8444 (6.2939)  loss_n_100: 6.2621 (6.7294)  triple_100: 0.0000 (0.0702)  triple_80: 0.0000 (0.0368)  triple_60: 0.0000 (0.1999)  triple_40: 0.0000 (0.0529)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 830/1724]  eta: 0:58:26  lr: 0.000060  loss: 23.6372 (25.8531)  loss_n_40: 5.5141 (5.7467)  loss_n_60: 6.3824 (6.7246)  loss_n_80: 5.8444 (6.2916)  loss_n_100: 6.1850 (6.7254)  triple_100: 0.0000 (0.0715)  triple_80: 0.0000 (0.0378)  triple_60: 0.0000 (0.2010)  triple_40: 0.0000 (0.0545)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 840/1724]  eta: 0:57:46  lr: 0.000060  loss: 24.0939 (25.8387)  loss_n_40: 5.5085 (5.7437)  loss_n_60: 6.3824 (6.7212)  loss_n_80: 6.0564 (6.2885)  loss_n_100: 6.2968 (6.7208)  triple_100: 0.0000 (0.0707)  triple_80: 0.0000 (0.0374)  triple_60: 0.0000 (0.2009)  triple_40: 0.0000 (0.0556)  time: 3.9202  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [ 850/1724]  eta: 0:57:07  lr: 0.000060  loss: 23.9642 (25.8127)  loss_n_40: 5.4582 (5.7396)  loss_n_60: 6.4411 (6.7178)  loss_n_80: 5.8356 (6.2819)  loss_n_100: 6.2108 (6.7131)  triple_100: 0.0000 (0.0699)  triple_80: 0.0000 (0.0370)  triple_60: 0.0000 (0.1985)  triple_40: 0.0000 (0.0550)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 860/1724]  eta: 0:56:28  lr: 0.000060  loss: 24.0804 (25.7984)  loss_n_40: 5.5167 (5.7381)  loss_n_60: 6.4593 (6.7151)  loss_n_80: 5.8356 (6.2790)  loss_n_100: 6.1616 (6.7088)  triple_100: 0.0000 (0.0693)  triple_80: 0.0000 (0.0365)  triple_60: 0.0000 (0.1972)  triple_40: 0.0000 (0.0543)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 870/1724]  eta: 0:55:49  lr: 0.000060  loss: 24.2505 (25.7858)  loss_n_40: 5.5884 (5.7347)  loss_n_60: 6.3903 (6.7103)  loss_n_80: 5.9358 (6.2744)  loss_n_100: 6.3188 (6.7034)  triple_100: 0.0000 (0.0714)  triple_80: 0.0000 (0.0387)  triple_60: 0.0000 (0.1992)  triple_40: 0.0000 (0.0537)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 880/1724]  eta: 0:55:09  lr: 0.000060  loss: 23.6628 (25.7681)  loss_n_40: 5.4470 (5.7306)  loss_n_60: 6.2848 (6.7055)  loss_n_80: 5.8399 (6.2683)  loss_n_100: 6.0347 (6.6958)  triple_100: 0.0000 (0.0734)  triple_80: 0.0000 (0.0386)  triple_60: 0.0000 (0.2017)  triple_40: 0.0000 (0.0542)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 890/1724]  eta: 0:54:30  lr: 0.000060  loss: 23.6628 (25.7538)  loss_n_40: 5.4772 (5.7286)  loss_n_60: 6.3814 (6.7023)  loss_n_80: 5.8395 (6.2634)  loss_n_100: 6.1009 (6.6896)  triple_100: 0.0000 (0.0725)  triple_80: 0.0000 (0.0396)  triple_60: 0.0000 (0.2023)  triple_40: 0.0000 (0.0555)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 900/1724]  eta: 0:53:51  lr: 0.000060  loss: 24.3904 (25.7498)  loss_n_40: 5.5459 (5.7272)  loss_n_60: 6.4997 (6.7024)  loss_n_80: 5.9381 (6.2625)  loss_n_100: 6.2301 (6.6888)  triple_100: 0.0000 (0.0725)  triple_80: 0.0000 (0.0401)  triple_60: 0.0000 (0.2014)  triple_40: 0.0000 (0.0549)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 910/1724]  eta: 0:53:12  lr: 0.000060  loss: 24.6312 (25.7436)  loss_n_40: 5.5704 (5.7254)  loss_n_60: 6.6446 (6.7018)  loss_n_80: 6.1469 (6.2595)  loss_n_100: 6.5561 (6.6857)  triple_100: 0.0000 (0.0729)  triple_80: 0.0000 (0.0396)  triple_60: 0.0000 (0.2045)  triple_40: 0.0000 (0.0543)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 920/1724]  eta: 0:52:33  lr: 0.000060  loss: 24.2047 (25.7245)  loss_n_40: 5.4417 (5.7220)  loss_n_60: 6.5937 (6.6985)  loss_n_80: 5.8822 (6.2550)  loss_n_100: 6.3223 (6.6814)  triple_100: 0.0000 (0.0721)  triple_80: 0.0000 (0.0392)  triple_60: 0.0000 (0.2025)  triple_40: 0.0000 (0.0537)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 930/1724]  eta: 0:51:53  lr: 0.000060  loss: 23.7988 (25.7168)  loss_n_40: 5.4407 (5.7209)  loss_n_60: 6.3887 (6.6967)  loss_n_80: 5.7599 (6.2498)  loss_n_100: 6.1570 (6.6759)  triple_100: 0.0000 (0.0723)  triple_80: 0.0000 (0.0389)  triple_60: 0.0000 (0.2083)  triple_40: 0.0000 (0.0540)  time: 3.9221  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [ 940/1724]  eta: 0:51:14  lr: 0.000060  loss: 23.8098 (25.6988)  loss_n_40: 5.5689 (5.7183)  loss_n_60: 6.3887 (6.6940)  loss_n_80: 5.7840 (6.2459)  loss_n_100: 6.1366 (6.6707)  triple_100: 0.0000 (0.0716)  triple_80: 0.0000 (0.0385)  triple_60: 0.0000 (0.2064)  triple_40: 0.0000 (0.0534)  time: 3.9224  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [ 950/1724]  eta: 0:50:35  lr: 0.000060  loss: 23.8098 (25.6781)  loss_n_40: 5.3955 (5.7141)  loss_n_60: 6.3672 (6.6897)  loss_n_80: 5.8145 (6.2419)  loss_n_100: 6.1579 (6.6657)  triple_100: 0.0000 (0.0715)  triple_80: 0.0000 (0.0381)  triple_60: 0.0000 (0.2042)  triple_40: 0.0000 (0.0529)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 960/1724]  eta: 0:49:56  lr: 0.000060  loss: 23.9644 (25.6649)  loss_n_40: 5.4478 (5.7130)  loss_n_60: 6.3779 (6.6869)  loss_n_80: 5.9536 (6.2399)  loss_n_100: 6.2343 (6.6617)  triple_100: 0.0000 (0.0709)  triple_80: 0.0000 (0.0380)  triple_60: 0.0000 (0.2022)  triple_40: 0.0000 (0.0523)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 970/1724]  eta: 0:49:16  lr: 0.000060  loss: 23.8715 (25.6410)  loss_n_40: 5.3384 (5.7093)  loss_n_60: 6.3485 (6.6824)  loss_n_80: 5.9136 (6.2347)  loss_n_100: 6.1302 (6.6551)  triple_100: 0.0000 (0.0701)  triple_80: 0.0000 (0.0376)  triple_60: 0.0000 (0.2002)  triple_40: 0.0000 (0.0518)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 980/1724]  eta: 0:48:37  lr: 0.000060  loss: 23.8164 (25.6257)  loss_n_40: 5.3384 (5.7074)  loss_n_60: 6.3069 (6.6794)  loss_n_80: 5.7289 (6.2301)  loss_n_100: 6.1188 (6.6499)  triple_100: 0.0000 (0.0697)  triple_80: 0.0000 (0.0372)  triple_60: 0.0000 (0.1993)  triple_40: 0.0000 (0.0527)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [ 990/1724]  eta: 0:47:58  lr: 0.000060  loss: 23.7503 (25.6019)  loss_n_40: 5.3711 (5.7026)  loss_n_60: 6.3613 (6.6747)  loss_n_80: 5.7184 (6.2246)  loss_n_100: 6.0645 (6.6430)  triple_100: 0.0000 (0.0695)  triple_80: 0.0000 (0.0368)  triple_60: 0.0000 (0.1985)  triple_40: 0.0000 (0.0522)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1000/1724]  eta: 0:47:19  lr: 0.000060  loss: 23.4416 (25.5821)  loss_n_40: 5.3711 (5.7003)  loss_n_60: 6.3563 (6.6719)  loss_n_80: 5.6611 (6.2201)  loss_n_100: 5.9423 (6.6360)  triple_100: 0.0000 (0.0688)  triple_80: 0.0000 (0.0369)  triple_60: 0.0000 (0.1965)  triple_40: 0.0000 (0.0516)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1010/1724]  eta: 0:46:40  lr: 0.000060  loss: 23.1683 (25.5585)  loss_n_40: 5.3917 (5.6961)  loss_n_60: 6.2197 (6.6669)  loss_n_80: 5.6611 (6.2142)  loss_n_100: 5.9228 (6.6288)  triple_100: 0.0000 (0.0681)  triple_80: 0.0000 (0.0367)  triple_60: 0.0000 (0.1946)  triple_40: 0.0000 (0.0530)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1020/1724]  eta: 0:46:00  lr: 0.000060  loss: 22.7648 (25.5361)  loss_n_40: 5.1563 (5.6919)  loss_n_60: 6.1745 (6.6620)  loss_n_80: 5.5673 (6.2086)  loss_n_100: 5.9088 (6.6224)  triple_100: 0.0000 (0.0675)  triple_80: 0.0000 (0.0364)  triple_60: 0.0000 (0.1942)  triple_40: 0.0000 (0.0532)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1030/1724]  eta: 0:45:21  lr: 0.000060  loss: 22.8597 (25.5119)  loss_n_40: 5.2519 (5.6884)  loss_n_60: 6.2145 (6.6585)  loss_n_80: 5.5410 (6.2021)  loss_n_100: 5.9088 (6.6151)  triple_100: 0.0000 (0.0668)  triple_80: 0.0000 (0.0360)  triple_60: 0.0000 (0.1923)  triple_40: 0.0000 (0.0527)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1040/1724]  eta: 0:44:42  lr: 0.000060  loss: 23.5786 (25.5011)  loss_n_40: 5.3241 (5.6862)  loss_n_60: 6.2827 (6.6556)  loss_n_80: 5.6326 (6.1982)  loss_n_100: 5.9435 (6.6100)  triple_100: 0.0000 (0.0675)  triple_80: 0.0000 (0.0357)  triple_60: 0.0000 (0.1940)  triple_40: 0.0000 (0.0539)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1050/1724]  eta: 0:44:03  lr: 0.000060  loss: 22.8355 (25.4763)  loss_n_40: 5.3548 (5.6810)  loss_n_60: 6.1296 (6.6507)  loss_n_80: 5.6174 (6.1915)  loss_n_100: 5.9786 (6.6031)  triple_100: 0.0000 (0.0669)  triple_80: 0.0000 (0.0368)  triple_60: 0.0000 (0.1930)  triple_40: 0.0000 (0.0534)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1060/1724]  eta: 0:43:23  lr: 0.000060  loss: 22.7041 (25.4535)  loss_n_40: 5.0614 (5.6772)  loss_n_60: 6.0638 (6.6469)  loss_n_80: 5.4636 (6.1852)  loss_n_100: 5.8497 (6.5964)  triple_100: 0.0000 (0.0662)  triple_80: 0.0000 (0.0364)  triple_60: 0.0000 (0.1923)  triple_40: 0.0000 (0.0529)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [1070/1724]  eta: 0:42:44  lr: 0.000060  loss: 23.2042 (25.4446)  loss_n_40: 5.3162 (5.6749)  loss_n_60: 6.3152 (6.6452)  loss_n_80: 5.4898 (6.1820)  loss_n_100: 5.8661 (6.5914)  triple_100: 0.0000 (0.0659)  triple_80: 0.0000 (0.0361)  triple_60: 0.0000 (0.1957)  triple_40: 0.0000 (0.0534)  time: 3.9198  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [1080/1724]  eta: 0:42:05  lr: 0.000060  loss: 23.4489 (25.4259)  loss_n_40: 5.2372 (5.6700)  loss_n_60: 6.3688 (6.6423)  loss_n_80: 5.8452 (6.1791)  loss_n_100: 6.0512 (6.5865)  triple_100: 0.0000 (0.0655)  triple_80: 0.0000 (0.0357)  triple_60: 0.0000 (0.1939)  triple_40: 0.0000 (0.0529)  time: 3.9205  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [1090/1724]  eta: 0:41:26  lr: 0.000060  loss: 23.1309 (25.4015)  loss_n_40: 5.1687 (5.6654)  loss_n_60: 6.2093 (6.6383)  loss_n_80: 5.6928 (6.1733)  loss_n_100: 5.9014 (6.5785)  triple_100: 0.0000 (0.0649)  triple_80: 0.0000 (0.0365)  triple_60: 0.0000 (0.1921)  triple_40: 0.0000 (0.0524)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1100/1724]  eta: 0:40:47  lr: 0.000060  loss: 22.7301 (25.3806)  loss_n_40: 5.2267 (5.6616)  loss_n_60: 6.1750 (6.6342)  loss_n_80: 5.3101 (6.1656)  loss_n_100: 5.6499 (6.5706)  triple_100: 0.0000 (0.0699)  triple_80: 0.0000 (0.0361)  triple_60: 0.0000 (0.1904)  triple_40: 0.0000 (0.0521)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1110/1724]  eta: 0:40:07  lr: 0.000060  loss: 23.0165 (25.3608)  loss_n_40: 5.2831 (5.6582)  loss_n_60: 6.2576 (6.6302)  loss_n_80: 5.5520 (6.1616)  loss_n_100: 5.7552 (6.5645)  triple_100: 0.0000 (0.0693)  triple_80: 0.0000 (0.0364)  triple_60: 0.0000 (0.1889)  triple_40: 0.0000 (0.0517)  time: 3.9218  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1120/1724]  eta: 0:39:28  lr: 0.000060  loss: 23.0165 (25.3335)  loss_n_40: 5.1756 (5.6527)  loss_n_60: 5.9989 (6.6250)  loss_n_80: 5.6424 (6.1557)  loss_n_100: 5.7297 (6.5567)  triple_100: 0.0000 (0.0687)  triple_80: 0.0000 (0.0361)  triple_60: 0.0000 (0.1876)  triple_40: 0.0000 (0.0512)  time: 3.9213  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [1130/1724]  eta: 0:38:49  lr: 0.000060  loss: 22.3108 (25.3106)  loss_n_40: 5.0514 (5.6485)  loss_n_60: 5.9760 (6.6206)  loss_n_80: 5.4376 (6.1502)  loss_n_100: 5.7175 (6.5502)  triple_100: 0.0000 (0.0681)  triple_80: 0.0000 (0.0359)  triple_60: 0.0000 (0.1864)  triple_40: 0.0000 (0.0507)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1140/1724]  eta: 0:38:10  lr: 0.000060  loss: 22.4479 (25.2874)  loss_n_40: 5.1313 (5.6449)  loss_n_60: 6.1356 (6.6166)  loss_n_80: 5.4580 (6.1447)  loss_n_100: 5.7023 (6.5431)  triple_100: 0.0000 (0.0675)  triple_80: 0.0000 (0.0356)  triple_60: 0.0000 (0.1848)  triple_40: 0.0000 (0.0503)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1150/1724]  eta: 0:37:30  lr: 0.000060  loss: 22.9778 (25.2753)  loss_n_40: 5.1313 (5.6420)  loss_n_60: 6.1348 (6.6128)  loss_n_80: 5.5923 (6.1407)  loss_n_100: 5.7925 (6.5373)  triple_100: 0.0000 (0.0678)  triple_80: 0.0000 (0.0353)  triple_60: 0.0000 (0.1879)  triple_40: 0.0000 (0.0515)  time: 3.9213  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1160/1724]  eta: 0:36:51  lr: 0.000060  loss: 23.2711 (25.2552)  loss_n_40: 5.1893 (5.6386)  loss_n_60: 6.1348 (6.6094)  loss_n_80: 5.5849 (6.1356)  loss_n_100: 5.8381 (6.5307)  triple_100: 0.0000 (0.0672)  triple_80: 0.0000 (0.0350)  triple_60: 0.0000 (0.1863)  triple_40: 0.0000 (0.0525)  time: 3.9218  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1170/1724]  eta: 0:36:12  lr: 0.000060  loss: 23.1891 (25.2378)  loss_n_40: 5.2285 (5.6359)  loss_n_60: 6.1914 (6.6063)  loss_n_80: 5.4715 (6.1301)  loss_n_100: 5.7895 (6.5246)  triple_100: 0.0000 (0.0666)  triple_80: 0.0000 (0.0347)  triple_60: 0.0000 (0.1872)  triple_40: 0.0000 (0.0523)  time: 3.9214  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1180/1724]  eta: 0:35:33  lr: 0.000060  loss: 23.1409 (25.2199)  loss_n_40: 5.3144 (5.6332)  loss_n_60: 6.2638 (6.6031)  loss_n_80: 5.4715 (6.1246)  loss_n_100: 5.8259 (6.5186)  triple_100: 0.0000 (0.0669)  triple_80: 0.0000 (0.0344)  triple_60: 0.0000 (0.1872)  triple_40: 0.0000 (0.0518)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1190/1724]  eta: 0:34:54  lr: 0.000060  loss: 22.6039 (25.2035)  loss_n_40: 5.3144 (5.6303)  loss_n_60: 6.2499 (6.6000)  loss_n_80: 5.5031 (6.1203)  loss_n_100: 5.8259 (6.5123)  triple_100: 0.0000 (0.0667)  triple_80: 0.0000 (0.0343)  triple_60: 0.0000 (0.1881)  triple_40: 0.0000 (0.0514)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1200/1724]  eta: 0:34:14  lr: 0.000060  loss: 22.7681 (25.1823)  loss_n_40: 5.2480 (5.6267)  loss_n_60: 6.1743 (6.5959)  loss_n_80: 5.5928 (6.1157)  loss_n_100: 5.7462 (6.5058)  triple_100: 0.0000 (0.0662)  triple_80: 0.0000 (0.0340)  triple_60: 0.0000 (0.1868)  triple_40: 0.0000 (0.0512)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1210/1724]  eta: 0:33:35  lr: 0.000060  loss: 22.7692 (25.1639)  loss_n_40: 5.3170 (5.6242)  loss_n_60: 6.2070 (6.5936)  loss_n_80: 5.5928 (6.1117)  loss_n_100: 5.7327 (6.4988)  triple_100: 0.0000 (0.0656)  triple_80: 0.0000 (0.0337)  triple_60: 0.0000 (0.1856)  triple_40: 0.0000 (0.0508)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1220/1724]  eta: 0:32:56  lr: 0.000060  loss: 22.5260 (25.1428)  loss_n_40: 5.1916 (5.6201)  loss_n_60: 6.1318 (6.5890)  loss_n_80: 5.4203 (6.1050)  loss_n_100: 5.5440 (6.4906)  triple_100: 0.0000 (0.0653)  triple_80: 0.0000 (0.0334)  triple_60: 0.0000 (0.1881)  triple_40: 0.0000 (0.0512)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1230/1724]  eta: 0:32:17  lr: 0.000060  loss: 22.1092 (25.1314)  loss_n_40: 5.1348 (5.6174)  loss_n_60: 6.0540 (6.5861)  loss_n_80: 5.3645 (6.1006)  loss_n_100: 5.5052 (6.4841)  triple_100: 0.0000 (0.0659)  triple_80: 0.0000 (0.0361)  triple_60: 0.0000 (0.1895)  triple_40: 0.0000 (0.0517)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1240/1724]  eta: 0:31:37  lr: 0.000060  loss: 23.1703 (25.1165)  loss_n_40: 5.1330 (5.6132)  loss_n_60: 6.0107 (6.5815)  loss_n_80: 5.5953 (6.0962)  loss_n_100: 5.8804 (6.4802)  triple_100: 0.0000 (0.0662)  triple_80: 0.0000 (0.0363)  triple_60: 0.0000 (0.1901)  triple_40: 0.0000 (0.0529)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1250/1724]  eta: 0:30:58  lr: 0.000060  loss: 23.1600 (25.1017)  loss_n_40: 5.2262 (5.6106)  loss_n_60: 6.1757 (6.5792)  loss_n_80: 5.5392 (6.0919)  loss_n_100: 5.9275 (6.4763)  triple_100: 0.0000 (0.0665)  triple_80: 0.0000 (0.0360)  triple_60: 0.0000 (0.1885)  triple_40: 0.0000 (0.0525)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1260/1724]  eta: 0:30:19  lr: 0.000060  loss: 22.7898 (25.0802)  loss_n_40: 5.2282 (5.6068)  loss_n_60: 6.1869 (6.5758)  loss_n_80: 5.4362 (6.0855)  loss_n_100: 5.8748 (6.4712)  triple_100: 0.0000 (0.0660)  triple_80: 0.0000 (0.0358)  triple_60: 0.0000 (0.1871)  triple_40: 0.0000 (0.0521)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1270/1724]  eta: 0:29:40  lr: 0.000060  loss: 22.0648 (25.0574)  loss_n_40: 5.0532 (5.6028)  loss_n_60: 5.9796 (6.5714)  loss_n_80: 5.1606 (6.0786)  loss_n_100: 5.7356 (6.4648)  triple_100: 0.0000 (0.0670)  triple_80: 0.0000 (0.0355)  triple_60: 0.0000 (0.1856)  triple_40: 0.0000 (0.0518)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1280/1724]  eta: 0:29:01  lr: 0.000060  loss: 21.8912 (25.0346)  loss_n_40: 4.9795 (5.5988)  loss_n_60: 5.9477 (6.5674)  loss_n_80: 5.1977 (6.0730)  loss_n_100: 5.5618 (6.4577)  triple_100: 0.0000 (0.0664)  triple_80: 0.0000 (0.0352)  triple_60: 0.0000 (0.1847)  triple_40: 0.0000 (0.0514)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1290/1724]  eta: 0:28:21  lr: 0.000060  loss: 21.5872 (25.0112)  loss_n_40: 4.9448 (5.5945)  loss_n_60: 5.9432 (6.5633)  loss_n_80: 5.2141 (6.0661)  loss_n_100: 5.3806 (6.4486)  triple_100: 0.0000 (0.0662)  triple_80: 0.0000 (0.0349)  triple_60: 0.0000 (0.1852)  triple_40: 0.0000 (0.0523)  time: 3.9213  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [1300/1724]  eta: 0:27:42  lr: 0.000060  loss: 21.0782 (24.9809)  loss_n_40: 4.9391 (5.5889)  loss_n_60: 5.9432 (6.5582)  loss_n_80: 5.0669 (6.0590)  loss_n_100: 5.2331 (6.4389)  triple_100: 0.0000 (0.0657)  triple_80: 0.0000 (0.0347)  triple_60: 0.0000 (0.1838)  triple_40: 0.0000 (0.0519)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1310/1724]  eta: 0:27:03  lr: 0.000060  loss: 21.1710 (24.9569)  loss_n_40: 4.9039 (5.5838)  loss_n_60: 5.9091 (6.5536)  loss_n_80: 5.1279 (6.0529)  loss_n_100: 5.2439 (6.4303)  triple_100: 0.0000 (0.0659)  triple_80: 0.0000 (0.0344)  triple_60: 0.0000 (0.1844)  triple_40: 0.0000 (0.0515)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1320/1724]  eta: 0:26:24  lr: 0.000060  loss: 21.5168 (24.9301)  loss_n_40: 4.9621 (5.5793)  loss_n_60: 5.9317 (6.5489)  loss_n_80: 5.1333 (6.0462)  loss_n_100: 5.3435 (6.4218)  triple_100: 0.0000 (0.0657)  triple_80: 0.0000 (0.0343)  triple_60: 0.0000 (0.1830)  triple_40: 0.0000 (0.0511)  time: 3.9226  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [1330/1724]  eta: 0:25:45  lr: 0.000060  loss: 21.4514 (24.9123)  loss_n_40: 5.0358 (5.5754)  loss_n_60: 5.9801 (6.5453)  loss_n_80: 5.1333 (6.0397)  loss_n_100: 5.3212 (6.4133)  triple_100: 0.0000 (0.0657)  triple_80: 0.0000 (0.0351)  triple_60: 0.0000 (0.1866)  triple_40: 0.0000 (0.0513)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1340/1724]  eta: 0:25:05  lr: 0.000060  loss: 21.1181 (24.8849)  loss_n_40: 4.9872 (5.5703)  loss_n_60: 5.9801 (6.5407)  loss_n_80: 5.1232 (6.0329)  loss_n_100: 5.2134 (6.4049)  triple_100: 0.0000 (0.0652)  triple_80: 0.0000 (0.0349)  triple_60: 0.0000 (0.1852)  triple_40: 0.0000 (0.0509)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1350/1724]  eta: 0:24:26  lr: 0.000060  loss: 20.9448 (24.8576)  loss_n_40: 4.8606 (5.5656)  loss_n_60: 5.8227 (6.5357)  loss_n_80: 5.0828 (6.0255)  loss_n_100: 5.2134 (6.3966)  triple_100: 0.0000 (0.0652)  triple_80: 0.0000 (0.0346)  triple_60: 0.0000 (0.1838)  triple_40: 0.0000 (0.0505)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1360/1724]  eta: 0:23:47  lr: 0.000060  loss: 21.3694 (24.8339)  loss_n_40: 5.0078 (5.5623)  loss_n_60: 5.9516 (6.5323)  loss_n_80: 5.1218 (6.0193)  loss_n_100: 5.2740 (6.3884)  triple_100: 0.0000 (0.0647)  triple_80: 0.0000 (0.0343)  triple_60: 0.0000 (0.1825)  triple_40: 0.0000 (0.0501)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1370/1724]  eta: 0:23:08  lr: 0.000060  loss: 21.5795 (24.8085)  loss_n_40: 5.1682 (5.5586)  loss_n_60: 6.0313 (6.5283)  loss_n_80: 5.1815 (6.0122)  loss_n_100: 5.2069 (6.3797)  triple_100: 0.0000 (0.0642)  triple_80: 0.0000 (0.0341)  triple_60: 0.0000 (0.1816)  triple_40: 0.0000 (0.0498)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1380/1724]  eta: 0:22:28  lr: 0.000060  loss: 21.1767 (24.7848)  loss_n_40: 5.0659 (5.5555)  loss_n_60: 6.0465 (6.5250)  loss_n_80: 5.0121 (6.0056)  loss_n_100: 5.1913 (6.3712)  triple_100: 0.0000 (0.0640)  triple_80: 0.0000 (0.0338)  triple_60: 0.0000 (0.1803)  triple_40: 0.0000 (0.0495)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1390/1724]  eta: 0:21:49  lr: 0.000060  loss: 21.8922 (24.7667)  loss_n_40: 5.2126 (5.5533)  loss_n_60: 6.0745 (6.5225)  loss_n_80: 5.1335 (5.9997)  loss_n_100: 5.2460 (6.3637)  triple_100: 0.0000 (0.0656)  triple_80: 0.0000 (0.0336)  triple_60: 0.0000 (0.1790)  triple_40: 0.0000 (0.0493)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1400/1724]  eta: 0:21:10  lr: 0.000060  loss: 21.7843 (24.7427)  loss_n_40: 5.1249 (5.5490)  loss_n_60: 6.0745 (6.5181)  loss_n_80: 5.2070 (5.9944)  loss_n_100: 5.3864 (6.3559)  triple_100: 0.0000 (0.0651)  triple_80: 0.0000 (0.0335)  triple_60: 0.0000 (0.1778)  triple_40: 0.0000 (0.0490)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1410/1724]  eta: 0:20:31  lr: 0.000060  loss: 21.7843 (24.7238)  loss_n_40: 5.0408 (5.5462)  loss_n_60: 6.0018 (6.5150)  loss_n_80: 5.2025 (5.9889)  loss_n_100: 5.4314 (6.3491)  triple_100: 0.0000 (0.0653)  triple_80: 0.0000 (0.0342)  triple_60: 0.0000 (0.1765)  triple_40: 0.0000 (0.0486)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1420/1724]  eta: 0:19:52  lr: 0.000060  loss: 22.1523 (24.7118)  loss_n_40: 5.1003 (5.5434)  loss_n_60: 6.1064 (6.5127)  loss_n_80: 5.1990 (5.9847)  loss_n_100: 5.4867 (6.3435)  triple_100: 0.0000 (0.0658)  triple_80: 0.0000 (0.0354)  triple_60: 0.0000 (0.1769)  triple_40: 0.0000 (0.0494)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1430/1724]  eta: 0:19:12  lr: 0.000060  loss: 22.8404 (24.6980)  loss_n_40: 5.0171 (5.5390)  loss_n_60: 6.1403 (6.5099)  loss_n_80: 5.4574 (5.9819)  loss_n_100: 5.8536 (6.3416)  triple_100: 0.0000 (0.0659)  triple_80: 0.0000 (0.0352)  triple_60: 0.0000 (0.1757)  triple_40: 0.0000 (0.0490)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1440/1724]  eta: 0:18:33  lr: 0.000060  loss: 22.5062 (24.6826)  loss_n_40: 4.9506 (5.5358)  loss_n_60: 6.1205 (6.5076)  loss_n_80: 5.4448 (5.9774)  loss_n_100: 6.0308 (6.3379)  triple_100: 0.0000 (0.0656)  triple_80: 0.0000 (0.0349)  triple_60: 0.0000 (0.1746)  triple_40: 0.0000 (0.0487)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1450/1724]  eta: 0:17:54  lr: 0.000060  loss: 21.7113 (24.6585)  loss_n_40: 4.9506 (5.5312)  loss_n_60: 6.0765 (6.5035)  loss_n_80: 5.1081 (5.9706)  loss_n_100: 5.5671 (6.3308)  triple_100: 0.0000 (0.0655)  triple_80: 0.0000 (0.0347)  triple_60: 0.0000 (0.1738)  triple_40: 0.0000 (0.0484)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1460/1724]  eta: 0:17:15  lr: 0.000060  loss: 21.4670 (24.6535)  loss_n_40: 4.9672 (5.5279)  loss_n_60: 6.0121 (6.4999)  loss_n_80: 5.0696 (5.9648)  loss_n_100: 5.3363 (6.3243)  triple_100: 0.0000 (0.0704)  triple_80: 0.0000 (0.0355)  triple_60: 0.0000 (0.1794)  triple_40: 0.0000 (0.0515)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1470/1724]  eta: 0:16:35  lr: 0.000060  loss: 21.3560 (24.6298)  loss_n_40: 4.9301 (5.5235)  loss_n_60: 5.9737 (6.4956)  loss_n_80: 5.1404 (5.9588)  loss_n_100: 5.3125 (6.3175)  triple_100: 0.0000 (0.0699)  triple_80: 0.0000 (0.0352)  triple_60: 0.0000 (0.1782)  triple_40: 0.0000 (0.0511)  time: 3.9213  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1480/1724]  eta: 0:15:56  lr: 0.000060  loss: 21.0097 (24.6097)  loss_n_40: 4.8934 (5.5200)  loss_n_60: 5.8899 (6.4923)  loss_n_80: 5.1189 (5.9537)  loss_n_100: 5.2892 (6.3110)  triple_100: 0.0000 (0.0694)  triple_80: 0.0000 (0.0352)  triple_60: 0.0000 (0.1772)  triple_40: 0.0000 (0.0508)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1490/1724]  eta: 0:15:17  lr: 0.000060  loss: 21.1057 (24.5878)  loss_n_40: 4.8187 (5.5152)  loss_n_60: 5.8122 (6.4875)  loss_n_80: 4.9274 (5.9472)  loss_n_100: 5.0781 (6.3034)  triple_100: 0.0000 (0.0690)  triple_80: 0.0000 (0.0349)  triple_60: 0.0000 (0.1795)  triple_40: 0.0000 (0.0509)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1500/1724]  eta: 0:14:38  lr: 0.000060  loss: 20.7374 (24.5647)  loss_n_40: 4.6907 (5.5113)  loss_n_60: 5.7457 (6.4844)  loss_n_80: 4.9314 (5.9410)  loss_n_100: 5.0781 (6.2959)  triple_100: 0.0000 (0.0685)  triple_80: 0.0000 (0.0347)  triple_60: 0.0000 (0.1783)  triple_40: 0.0000 (0.0506)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1510/1724]  eta: 0:13:59  lr: 0.000060  loss: 20.8201 (24.5421)  loss_n_40: 4.9699 (5.5081)  loss_n_60: 5.9608 (6.4811)  loss_n_80: 4.9779 (5.9346)  loss_n_100: 5.0696 (6.2883)  triple_100: 0.0000 (0.0681)  triple_80: 0.0000 (0.0345)  triple_60: 0.0000 (0.1772)  triple_40: 0.0000 (0.0503)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1520/1724]  eta: 0:13:19  lr: 0.000060  loss: 20.5336 (24.5136)  loss_n_40: 4.9007 (5.5034)  loss_n_60: 5.8398 (6.4763)  loss_n_80: 4.7715 (5.9266)  loss_n_100: 4.9713 (6.2792)  triple_100: 0.0000 (0.0677)  triple_80: 0.0000 (0.0342)  triple_60: 0.0000 (0.1760)  triple_40: 0.0000 (0.0501)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1530/1724]  eta: 0:12:40  lr: 0.000060  loss: 20.6510 (24.4948)  loss_n_40: 4.8103 (5.4986)  loss_n_60: 5.7813 (6.4717)  loss_n_80: 4.8560 (5.9210)  loss_n_100: 5.0886 (6.2734)  triple_100: 0.0000 (0.0683)  triple_80: 0.0000 (0.0353)  triple_60: 0.0000 (0.1760)  triple_40: 0.0000 (0.0504)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1540/1724]  eta: 0:12:01  lr: 0.000060  loss: 21.8811 (24.4767)  loss_n_40: 4.9130 (5.4950)  loss_n_60: 5.9669 (6.4691)  loss_n_80: 5.0486 (5.9161)  loss_n_100: 5.4430 (6.2682)  triple_100: 0.0000 (0.0683)  triple_80: 0.0000 (0.0351)  triple_60: 0.0000 (0.1750)  triple_40: 0.0000 (0.0500)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1550/1724]  eta: 0:11:22  lr: 0.000060  loss: 21.3126 (24.4511)  loss_n_40: 4.9059 (5.4904)  loss_n_60: 5.9816 (6.4648)  loss_n_80: 4.9885 (5.9096)  loss_n_100: 5.0299 (6.2593)  triple_100: 0.0000 (0.0679)  triple_80: 0.0000 (0.0348)  triple_60: 0.0000 (0.1745)  triple_40: 0.0000 (0.0497)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1560/1724]  eta: 0:10:43  lr: 0.000060  loss: 20.2837 (24.4282)  loss_n_40: 4.6974 (5.4866)  loss_n_60: 5.7067 (6.4606)  loss_n_80: 4.8879 (5.9034)  loss_n_100: 4.8037 (6.2507)  triple_100: 0.0000 (0.0680)  triple_80: 0.0000 (0.0348)  triple_60: 0.0000 (0.1746)  triple_40: 0.0000 (0.0496)  time: 3.9210  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [1570/1724]  eta: 0:10:03  lr: 0.000060  loss: 20.5453 (24.4056)  loss_n_40: 4.8713 (5.4831)  loss_n_60: 5.8272 (6.4568)  loss_n_80: 4.8879 (5.8970)  loss_n_100: 4.8042 (6.2421)  triple_100: 0.0000 (0.0676)  triple_80: 0.0000 (0.0347)  triple_60: 0.0000 (0.1736)  triple_40: 0.0000 (0.0506)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1580/1724]  eta: 0:09:24  lr: 0.000060  loss: 20.5559 (24.3833)  loss_n_40: 4.8713 (5.4789)  loss_n_60: 5.8147 (6.4531)  loss_n_80: 4.8281 (5.8908)  loss_n_100: 4.9573 (6.2355)  triple_100: 0.0000 (0.0674)  triple_80: 0.0000 (0.0345)  triple_60: 0.0000 (0.1729)  triple_40: 0.0000 (0.0503)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1590/1724]  eta: 0:08:45  lr: 0.000060  loss: 20.6692 (24.3639)  loss_n_40: 4.6768 (5.4745)  loss_n_60: 5.6917 (6.4485)  loss_n_80: 4.9589 (5.8852)  loss_n_100: 5.3381 (6.2295)  triple_100: 0.0000 (0.0669)  triple_80: 0.0000 (0.0348)  triple_60: 0.0000 (0.1744)  triple_40: 0.0000 (0.0500)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1600/1724]  eta: 0:08:06  lr: 0.000060  loss: 20.6692 (24.3388)  loss_n_40: 4.6768 (5.4704)  loss_n_60: 5.7007 (6.4446)  loss_n_80: 4.9589 (5.8786)  loss_n_100: 5.0432 (6.2210)  triple_100: 0.0000 (0.0665)  triple_80: 0.0000 (0.0346)  triple_60: 0.0000 (0.1733)  triple_40: 0.0000 (0.0497)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1610/1724]  eta: 0:07:27  lr: 0.000060  loss: 20.8762 (24.3210)  loss_n_40: 4.9494 (5.4670)  loss_n_60: 5.7959 (6.4404)  loss_n_80: 4.9163 (5.8727)  loss_n_100: 4.9131 (6.2139)  triple_100: 0.0000 (0.0671)  triple_80: 0.0000 (0.0344)  triple_60: 0.0000 (0.1757)  triple_40: 0.0000 (0.0498)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1620/1724]  eta: 0:06:47  lr: 0.000060  loss: 20.8762 (24.3027)  loss_n_40: 4.9174 (5.4628)  loss_n_60: 5.7959 (6.4363)  loss_n_80: 4.9497 (5.8675)  loss_n_100: 4.9184 (6.2060)  triple_100: 0.0000 (0.0684)  triple_80: 0.0000 (0.0358)  triple_60: 0.0000 (0.1764)  triple_40: 0.0000 (0.0495)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1630/1724]  eta: 0:06:08  lr: 0.000060  loss: 20.3475 (24.2815)  loss_n_40: 4.7751 (5.4584)  loss_n_60: 5.7796 (6.4318)  loss_n_80: 4.9451 (5.8616)  loss_n_100: 5.0034 (6.1988)  triple_100: 0.0000 (0.0688)  triple_80: 0.0000 (0.0359)  triple_60: 0.0000 (0.1761)  triple_40: 0.0000 (0.0500)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1640/1724]  eta: 0:05:29  lr: 0.000060  loss: 20.4716 (24.2603)  loss_n_40: 4.7534 (5.4549)  loss_n_60: 5.6714 (6.4280)  loss_n_80: 4.9200 (5.8564)  loss_n_100: 4.9644 (6.1918)  triple_100: 0.0000 (0.0684)  triple_80: 0.0000 (0.0360)  triple_60: 0.0000 (0.1751)  triple_40: 0.0000 (0.0497)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1650/1724]  eta: 0:04:50  lr: 0.000060  loss: 20.6413 (24.2384)  loss_n_40: 4.8387 (5.4517)  loss_n_60: 5.8255 (6.4246)  loss_n_80: 4.9394 (5.8509)  loss_n_100: 4.8643 (6.1837)  triple_100: 0.0000 (0.0680)  triple_80: 0.0000 (0.0358)  triple_60: 0.0000 (0.1743)  triple_40: 0.0000 (0.0494)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1660/1724]  eta: 0:04:10  lr: 0.000060  loss: 20.0871 (24.2145)  loss_n_40: 4.7247 (5.4470)  loss_n_60: 5.7363 (6.4199)  loss_n_80: 4.8450 (5.8444)  loss_n_100: 4.6653 (6.1746)  triple_100: 0.0000 (0.0676)  triple_80: 0.0000 (0.0358)  triple_60: 0.0000 (0.1756)  triple_40: 0.0000 (0.0497)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [1670/1724]  eta: 0:03:31  lr: 0.000060  loss: 20.0168 (24.1932)  loss_n_40: 4.6695 (5.4434)  loss_n_60: 5.6707 (6.4164)  loss_n_80: 4.7739 (5.8392)  loss_n_100: 4.6700 (6.1673)  triple_100: 0.0000 (0.0671)  triple_80: 0.0000 (0.0359)  triple_60: 0.0000 (0.1746)  triple_40: 0.0000 (0.0494)  time: 3.9193  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [1680/1724]  eta: 0:02:52  lr: 0.000060  loss: 20.3917 (24.1695)  loss_n_40: 4.7124 (5.4398)  loss_n_60: 5.7503 (6.4124)  loss_n_80: 4.8837 (5.8329)  loss_n_100: 4.8016 (6.1590)  triple_100: 0.0000 (0.0668)  triple_80: 0.0000 (0.0357)  triple_60: 0.0000 (0.1735)  triple_40: 0.0000 (0.0494)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1690/1724]  eta: 0:02:13  lr: 0.000060  loss: 20.4496 (24.1446)  loss_n_40: 4.8988 (5.4359)  loss_n_60: 5.7648 (6.4084)  loss_n_80: 4.8175 (5.8265)  loss_n_100: 4.7681 (6.1501)  triple_100: 0.0000 (0.0664)  triple_80: 0.0000 (0.0356)  triple_60: 0.0000 (0.1725)  triple_40: 0.0000 (0.0491)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1700/1724]  eta: 0:01:34  lr: 0.000060  loss: 20.4496 (24.1210)  loss_n_40: 4.7281 (5.4318)  loss_n_60: 5.7841 (6.4045)  loss_n_80: 4.7528 (5.8203)  loss_n_100: 4.6366 (6.1414)  triple_100: 0.0000 (0.0662)  triple_80: 0.0000 (0.0354)  triple_60: 0.0000 (0.1720)  triple_40: 0.0000 (0.0495)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4]  [1710/1724]  eta: 0:00:54  lr: 0.000060  loss: 19.8943 (24.0949)  loss_n_40: 4.7193 (5.4269)  loss_n_60: 5.7721 (6.3997)  loss_n_80: 4.7528 (5.8141)  loss_n_100: 4.6114 (6.1330)  triple_100: 0.0000 (0.0658)  triple_80: 0.0000 (0.0352)  triple_60: 0.0000 (0.1710)  triple_40: 0.0000 (0.0492)  time: 3.9202  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [1720/1724]  eta: 0:00:15  lr: 0.000060  loss: 19.7864 (24.0700)  loss_n_40: 4.6708 (5.4222)  loss_n_60: 5.5247 (6.3948)  loss_n_80: 4.6823 (5.8076)  loss_n_100: 4.6854 (6.1248)  triple_100: 0.0000 (0.0655)  triple_80: 0.0000 (0.0351)  triple_60: 0.0000 (0.1706)  triple_40: 0.0000 (0.0494)  time: 3.9183  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:4]  [1723/1724]  eta: 0:00:03  lr: 0.000060  loss: 19.6509 (24.0610)  loss_n_40: 4.6708 (5.4204)  loss_n_60: 5.5247 (6.3932)  loss_n_80: 4.6457 (5.8054)  loss_n_100: 4.6114 (6.1219)  triple_100: 0.0000 (0.0654)  triple_80: 0.0000 (0.0350)  triple_60: 0.0000 (0.1703)  triple_40: 0.0000 (0.0493)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:4] Total time: 1:52:40 (3.9213 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 19.6509 (24.0610)  loss_n_40: 4.6708 (5.4204)  loss_n_60: 5.5247 (6.3932)  loss_n_80: 4.6457 (5.8054)  loss_n_100: 4.6114 (6.1219)  triple_100: 0.0000 (0.0654)  triple_80: 0.0000 (0.0350)  triple_60: 0.0000 (0.1703)  triple_40: 0.0000 (0.0493)\n",
      "Valid: [epoch:4]  [  0/845]  eta: 0:11:11  loss: 21.0390 (21.0390)  loss_n_40: 5.1742 (5.1742)  loss_n_60: 6.3149 (6.3149)  loss_n_80: 4.9105 (4.9105)  loss_n_100: 4.6393 (4.6393)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7952  data: 0.4585  max mem: 46473\n",
      "Valid: [epoch:4]  [ 10/845]  eta: 0:05:13  loss: 18.1659 (18.4688)  loss_n_40: 3.9701 (4.3331)  loss_n_60: 5.0397 (5.3468)  loss_n_80: 4.2058 (4.4020)  loss_n_100: 4.1849 (4.3870)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3758  data: 0.0418  max mem: 46473\n",
      "Valid: [epoch:4]  [ 20/845]  eta: 0:04:53  loss: 18.5497 (18.8249)  loss_n_40: 4.2806 (4.4169)  loss_n_60: 5.2167 (5.4333)  loss_n_80: 4.2058 (4.4623)  loss_n_100: 4.1849 (4.4290)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0834)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [ 30/845]  eta: 0:04:44  loss: 19.0352 (19.1985)  loss_n_40: 4.5119 (4.4657)  loss_n_60: 5.4236 (5.4304)  loss_n_80: 4.5938 (4.5429)  loss_n_100: 4.4685 (4.5741)  triple_100: 0.0000 (0.0993)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0862)  triple_40: 0.0000 (0.0000)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [ 40/845]  eta: 0:04:37  loss: 19.0352 (19.3673)  loss_n_40: 4.5707 (4.4919)  loss_n_60: 5.2770 (5.4335)  loss_n_80: 4.6550 (4.5643)  loss_n_100: 4.9103 (4.5747)  triple_100: 0.0000 (0.1243)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1786)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [ 50/845]  eta: 0:04:32  loss: 19.3279 (19.8710)  loss_n_40: 4.7067 (4.5840)  loss_n_60: 5.5750 (5.5157)  loss_n_80: 4.6550 (4.6153)  loss_n_100: 4.6160 (4.6273)  triple_100: 0.0000 (0.1869)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.3418)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:4]  [ 60/845]  eta: 0:04:27  loss: 20.0572 (20.0975)  loss_n_40: 4.7435 (4.5904)  loss_n_60: 5.7533 (5.5292)  loss_n_80: 4.5839 (4.6361)  loss_n_100: 4.4829 (4.6316)  triple_100: 0.0000 (0.1563)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.4761)  triple_40: 0.0000 (0.0780)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [ 70/845]  eta: 0:04:23  loss: 19.0087 (20.2281)  loss_n_40: 4.5794 (4.5749)  loss_n_60: 5.4287 (5.5090)  loss_n_80: 4.4984 (4.6332)  loss_n_100: 4.3929 (4.6380)  triple_100: 0.0000 (0.2529)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.5531)  triple_40: 0.0000 (0.0670)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [ 80/845]  eta: 0:04:19  loss: 18.8393 (20.0869)  loss_n_40: 4.5131 (4.5732)  loss_n_60: 5.4397 (5.5216)  loss_n_80: 4.3837 (4.6178)  loss_n_100: 4.2851 (4.6090)  triple_100: 0.0000 (0.2217)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.4848)  triple_40: 0.0000 (0.0587)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [ 90/845]  eta: 0:04:15  loss: 19.2719 (20.0277)  loss_n_40: 4.6275 (4.5801)  loss_n_60: 5.5381 (5.5270)  loss_n_80: 4.4136 (4.6192)  loss_n_100: 4.3126 (4.6179)  triple_100: 0.0000 (0.1998)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.4315)  triple_40: 0.0000 (0.0523)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [100/845]  eta: 0:04:12  loss: 19.2719 (19.9849)  loss_n_40: 4.5523 (4.5715)  loss_n_60: 5.1649 (5.5042)  loss_n_80: 4.4884 (4.6220)  loss_n_100: 4.4729 (4.6376)  triple_100: 0.0000 (0.1893)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.4134)  triple_40: 0.0000 (0.0471)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [110/845]  eta: 0:04:08  loss: 18.7450 (19.9509)  loss_n_40: 4.4448 (4.5709)  loss_n_60: 5.4366 (5.5100)  loss_n_80: 4.4703 (4.6238)  loss_n_100: 4.4729 (4.6421)  triple_100: 0.0000 (0.1851)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.3761)  triple_40: 0.0000 (0.0428)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [120/845]  eta: 0:04:04  loss: 19.3978 (19.9848)  loss_n_40: 4.5276 (4.5978)  loss_n_60: 5.5856 (5.5259)  loss_n_80: 4.6146 (4.6339)  loss_n_100: 4.6856 (4.6669)  triple_100: 0.0000 (0.1759)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.3451)  triple_40: 0.0000 (0.0393)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [130/845]  eta: 0:04:01  loss: 21.3021 (20.0659)  loss_n_40: 5.0342 (4.6278)  loss_n_60: 5.8636 (5.5578)  loss_n_80: 5.0056 (4.6614)  loss_n_100: 4.8702 (4.6932)  triple_100: 0.0000 (0.1706)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.3187)  triple_40: 0.0000 (0.0363)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [140/845]  eta: 0:03:57  loss: 20.8284 (20.0558)  loss_n_40: 5.0311 (4.6198)  loss_n_60: 5.8636 (5.5536)  loss_n_80: 4.8719 (4.6713)  loss_n_100: 4.8515 (4.7018)  triple_100: 0.0000 (0.1796)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.2961)  triple_40: 0.0000 (0.0337)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [150/845]  eta: 0:03:54  loss: 19.3792 (20.0271)  loss_n_40: 4.6579 (4.6160)  loss_n_60: 5.6701 (5.5597)  loss_n_80: 4.5769 (4.6690)  loss_n_100: 4.5040 (4.6917)  triple_100: 0.0000 (0.1828)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.2765)  triple_40: 0.0000 (0.0315)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [160/845]  eta: 0:03:50  loss: 19.0861 (19.9727)  loss_n_40: 4.6509 (4.6137)  loss_n_60: 5.7687 (5.5613)  loss_n_80: 4.4694 (4.6623)  loss_n_100: 4.4917 (4.6751)  triple_100: 0.0000 (0.1714)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.2593)  triple_40: 0.0000 (0.0295)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [170/845]  eta: 0:03:47  loss: 19.0831 (19.9300)  loss_n_40: 4.5101 (4.6086)  loss_n_60: 5.4843 (5.5609)  loss_n_80: 4.4694 (4.6557)  loss_n_100: 4.3270 (4.6663)  triple_100: 0.0000 (0.1665)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.2442)  triple_40: 0.0000 (0.0278)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [180/845]  eta: 0:03:43  loss: 19.1994 (19.8875)  loss_n_40: 4.4789 (4.5979)  loss_n_60: 5.4143 (5.5516)  loss_n_80: 4.5797 (4.6507)  loss_n_100: 4.3789 (4.6615)  triple_100: 0.0000 (0.1689)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.2307)  triple_40: 0.0000 (0.0263)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [190/845]  eta: 0:03:40  loss: 18.9597 (19.8338)  loss_n_40: 4.4789 (4.5893)  loss_n_60: 5.3776 (5.5490)  loss_n_80: 4.3633 (4.6444)  loss_n_100: 4.3095 (4.6475)  triple_100: 0.0000 (0.1600)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.2186)  triple_40: 0.0000 (0.0249)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [200/845]  eta: 0:03:36  loss: 18.7135 (19.7991)  loss_n_40: 4.4410 (4.5839)  loss_n_60: 5.6018 (5.5522)  loss_n_80: 4.4478 (4.6432)  loss_n_100: 4.2133 (4.6363)  triple_100: 0.0000 (0.1521)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.2077)  triple_40: 0.0000 (0.0237)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [210/845]  eta: 0:03:33  loss: 18.9746 (19.7691)  loss_n_40: 4.6610 (4.5854)  loss_n_60: 5.7142 (5.5586)  loss_n_80: 4.4478 (4.6351)  loss_n_100: 4.2610 (4.6246)  triple_100: 0.0000 (0.1449)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1979)  triple_40: 0.0000 (0.0225)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [220/845]  eta: 0:03:30  loss: 18.5136 (19.7552)  loss_n_40: 4.4605 (4.5865)  loss_n_60: 5.5681 (5.5633)  loss_n_80: 4.2753 (4.6315)  loss_n_100: 4.2590 (4.6209)  triple_100: 0.0000 (0.1425)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1889)  triple_40: 0.0000 (0.0215)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [230/845]  eta: 0:03:26  loss: 18.5016 (19.7277)  loss_n_40: 4.4453 (4.5799)  loss_n_60: 5.4833 (5.5540)  loss_n_80: 4.3387 (4.6318)  loss_n_100: 4.3615 (4.6244)  triple_100: 0.0000 (0.1363)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1807)  triple_40: 0.0000 (0.0206)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [240/845]  eta: 0:03:23  loss: 18.7029 (19.7341)  loss_n_40: 4.5110 (4.5813)  loss_n_60: 5.4329 (5.5584)  loss_n_80: 4.6506 (4.6370)  loss_n_100: 4.4050 (4.6263)  triple_100: 0.0000 (0.1381)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1732)  triple_40: 0.0000 (0.0197)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [250/845]  eta: 0:03:19  loss: 19.3542 (19.6985)  loss_n_40: 4.6538 (4.5763)  loss_n_60: 5.5282 (5.5585)  loss_n_80: 4.6506 (4.6315)  loss_n_100: 4.3633 (4.6143)  triple_100: 0.0000 (0.1326)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1663)  triple_40: 0.0000 (0.0189)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [260/845]  eta: 0:03:16  loss: 19.1712 (19.6923)  loss_n_40: 4.4676 (4.5759)  loss_n_60: 5.5282 (5.5564)  loss_n_80: 4.4931 (4.6301)  loss_n_100: 4.4601 (4.6179)  triple_100: 0.0000 (0.1339)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1600)  triple_40: 0.0000 (0.0182)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [270/845]  eta: 0:03:13  loss: 19.1712 (19.6691)  loss_n_40: 4.4676 (4.5726)  loss_n_60: 5.5861 (5.5594)  loss_n_80: 4.4286 (4.6275)  loss_n_100: 4.3893 (4.6090)  triple_100: 0.0000 (0.1289)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1541)  triple_40: 0.0000 (0.0175)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [280/845]  eta: 0:03:09  loss: 19.0857 (19.6387)  loss_n_40: 4.5606 (4.5676)  loss_n_60: 5.5200 (5.5543)  loss_n_80: 4.3222 (4.6233)  loss_n_100: 4.3141 (4.6036)  triple_100: 0.0000 (0.1243)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1486)  triple_40: 0.0000 (0.0169)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [290/845]  eta: 0:03:06  loss: 19.0857 (19.6468)  loss_n_40: 4.6738 (4.5746)  loss_n_60: 5.7993 (5.5635)  loss_n_80: 4.3142 (4.6223)  loss_n_100: 4.3366 (4.6008)  triple_100: 0.0000 (0.1201)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1492)  triple_40: 0.0000 (0.0163)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [300/845]  eta: 0:03:02  loss: 18.9309 (19.6719)  loss_n_40: 4.5819 (4.5760)  loss_n_60: 5.6280 (5.5651)  loss_n_80: 4.2981 (4.6203)  loss_n_100: 4.2036 (4.6005)  triple_100: 0.0000 (0.1161)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1782)  triple_40: 0.0000 (0.0158)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:4]  [310/845]  eta: 0:02:59  loss: 18.7031 (19.6911)  loss_n_40: 4.5454 (4.5851)  loss_n_60: 5.5136 (5.5765)  loss_n_80: 4.1892 (4.6262)  loss_n_100: 4.2090 (4.6031)  triple_100: 0.0000 (0.1123)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1725)  triple_40: 0.0000 (0.0153)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [320/845]  eta: 0:02:56  loss: 19.1339 (19.6800)  loss_n_40: 4.6581 (4.5844)  loss_n_60: 5.7763 (5.5795)  loss_n_80: 4.5347 (4.6257)  loss_n_100: 4.3921 (4.5989)  triple_100: 0.0000 (0.1096)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1671)  triple_40: 0.0000 (0.0148)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [330/845]  eta: 0:02:52  loss: 19.4878 (19.7069)  loss_n_40: 4.7034 (4.5954)  loss_n_60: 5.8110 (5.5915)  loss_n_80: 4.5828 (4.6309)  loss_n_100: 4.5049 (4.6064)  triple_100: 0.0000 (0.1063)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1621)  triple_40: 0.0000 (0.0144)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [340/845]  eta: 0:02:49  loss: 19.4878 (19.6834)  loss_n_40: 4.6823 (4.5906)  loss_n_60: 5.8108 (5.5897)  loss_n_80: 4.5278 (4.6270)  loss_n_100: 4.3980 (4.6016)  triple_100: 0.0000 (0.1032)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1573)  triple_40: 0.0000 (0.0139)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [350/845]  eta: 0:02:46  loss: 18.9983 (19.7053)  loss_n_40: 4.5627 (4.5997)  loss_n_60: 5.6852 (5.5959)  loss_n_80: 4.4204 (4.6317)  loss_n_100: 4.3370 (4.6089)  triple_100: 0.0000 (0.1002)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1553)  triple_40: 0.0000 (0.0135)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [360/845]  eta: 0:02:42  loss: 19.0088 (19.6951)  loss_n_40: 4.5627 (4.6003)  loss_n_60: 5.6852 (5.5975)  loss_n_80: 4.7364 (4.6315)  loss_n_100: 4.3938 (4.6041)  triple_100: 0.0000 (0.0974)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1510)  triple_40: 0.0000 (0.0132)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [370/845]  eta: 0:02:39  loss: 19.1332 (19.7137)  loss_n_40: 4.6267 (4.6065)  loss_n_60: 5.7131 (5.6011)  loss_n_80: 4.6615 (4.6337)  loss_n_100: 4.3938 (4.6093)  triple_100: 0.0000 (0.1035)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1469)  triple_40: 0.0000 (0.0128)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [380/845]  eta: 0:02:35  loss: 19.8957 (19.7286)  loss_n_40: 4.8364 (4.6124)  loss_n_60: 5.8877 (5.6105)  loss_n_80: 4.7219 (4.6390)  loss_n_100: 4.5101 (4.6104)  triple_100: 0.0000 (0.1008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1431)  triple_40: 0.0000 (0.0125)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [390/845]  eta: 0:02:32  loss: 20.0865 (19.7644)  loss_n_40: 4.8775 (4.6207)  loss_n_60: 6.0051 (5.6176)  loss_n_80: 4.9024 (4.6447)  loss_n_100: 4.6222 (4.6174)  triple_100: 0.0000 (0.0982)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1537)  triple_40: 0.0000 (0.0122)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [400/845]  eta: 0:02:29  loss: 19.5111 (19.7396)  loss_n_40: 4.6774 (4.6150)  loss_n_60: 5.7127 (5.6140)  loss_n_80: 4.6650 (4.6412)  loss_n_100: 4.4870 (4.6118)  triple_100: 0.0000 (0.0957)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1499)  triple_40: 0.0000 (0.0119)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [410/845]  eta: 0:02:25  loss: 19.4495 (19.7554)  loss_n_40: 4.5850 (4.6151)  loss_n_60: 5.5698 (5.6149)  loss_n_80: 4.5804 (4.6475)  loss_n_100: 4.4873 (4.6160)  triple_100: 0.0000 (0.0997)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1508)  triple_40: 0.0000 (0.0116)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [420/845]  eta: 0:02:22  loss: 19.3863 (19.7866)  loss_n_40: 4.6618 (4.6186)  loss_n_60: 5.7498 (5.6180)  loss_n_80: 4.5072 (4.6466)  loss_n_100: 4.4873 (4.6146)  triple_100: 0.0000 (0.1089)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1685)  triple_40: 0.0000 (0.0113)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [430/845]  eta: 0:02:19  loss: 19.2407 (19.7922)  loss_n_40: 4.7600 (4.6200)  loss_n_60: 5.8847 (5.6198)  loss_n_80: 4.4947 (4.6512)  loss_n_100: 4.4073 (4.6179)  triple_100: 0.0000 (0.1075)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1646)  triple_40: 0.0000 (0.0110)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [440/845]  eta: 0:02:15  loss: 20.4466 (19.8216)  loss_n_40: 4.8961 (4.6266)  loss_n_60: 5.9351 (5.6267)  loss_n_80: 4.8986 (4.6555)  loss_n_100: 4.6310 (4.6248)  triple_100: 0.0000 (0.1051)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1722)  triple_40: 0.0000 (0.0108)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [450/845]  eta: 0:02:12  loss: 19.7512 (19.8212)  loss_n_40: 4.8036 (4.6289)  loss_n_60: 5.7558 (5.6285)  loss_n_80: 4.6792 (4.6564)  loss_n_100: 4.3971 (4.6257)  triple_100: 0.0000 (0.1027)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1684)  triple_40: 0.0000 (0.0105)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [460/845]  eta: 0:02:08  loss: 18.3423 (19.8054)  loss_n_40: 4.4945 (4.6246)  loss_n_60: 5.5690 (5.6273)  loss_n_80: 4.3272 (4.6561)  loss_n_100: 4.2642 (4.6220)  triple_100: 0.0000 (0.1005)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1647)  triple_40: 0.0000 (0.0103)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [470/845]  eta: 0:02:05  loss: 19.2810 (19.8125)  loss_n_40: 4.8090 (4.6278)  loss_n_60: 5.9807 (5.6329)  loss_n_80: 4.3666 (4.6604)  loss_n_100: 4.3056 (4.6218)  triple_100: 0.0000 (0.0984)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1612)  triple_40: 0.0000 (0.0101)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [480/845]  eta: 0:02:02  loss: 19.7657 (19.8476)  loss_n_40: 4.9848 (4.6317)  loss_n_60: 5.8732 (5.6344)  loss_n_80: 4.8442 (4.6645)  loss_n_100: 4.6517 (4.6299)  triple_100: 0.0000 (0.1114)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1659)  triple_40: 0.0000 (0.0099)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [490/845]  eta: 0:01:58  loss: 19.7657 (19.8524)  loss_n_40: 4.6957 (4.6331)  loss_n_60: 5.6994 (5.6364)  loss_n_80: 4.8442 (4.6659)  loss_n_100: 4.6073 (4.6289)  triple_100: 0.0000 (0.1111)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1672)  triple_40: 0.0000 (0.0097)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [500/845]  eta: 0:01:55  loss: 18.8244 (19.8268)  loss_n_40: 4.3989 (4.6256)  loss_n_60: 5.5503 (5.6275)  loss_n_80: 4.3053 (4.6628)  loss_n_100: 4.3086 (4.6273)  triple_100: 0.0000 (0.1103)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1639)  triple_40: 0.0000 (0.0095)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [510/845]  eta: 0:01:52  loss: 19.3147 (19.8283)  loss_n_40: 4.4450 (4.6270)  loss_n_60: 5.5503 (5.6294)  loss_n_80: 4.5825 (4.6647)  loss_n_100: 4.5056 (4.6290)  triple_100: 0.0000 (0.1082)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1607)  triple_40: 0.0000 (0.0093)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [520/845]  eta: 0:01:48  loss: 19.5946 (19.8252)  loss_n_40: 4.7887 (4.6286)  loss_n_60: 5.9008 (5.6333)  loss_n_80: 4.3894 (4.6630)  loss_n_100: 4.3723 (4.6274)  triple_100: 0.0000 (0.1061)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1576)  triple_40: 0.0000 (0.0091)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [530/845]  eta: 0:01:45  loss: 18.7572 (19.8102)  loss_n_40: 4.5074 (4.6217)  loss_n_60: 5.6208 (5.6263)  loss_n_80: 4.2051 (4.6604)  loss_n_100: 4.2023 (4.6240)  triple_100: 0.0000 (0.1041)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1648)  triple_40: 0.0000 (0.0090)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [540/845]  eta: 0:01:42  loss: 18.7217 (19.8167)  loss_n_40: 4.5074 (4.6247)  loss_n_60: 5.6208 (5.6268)  loss_n_80: 4.2051 (4.6622)  loss_n_100: 4.2251 (4.6300)  triple_100: 0.0000 (0.1024)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1617)  triple_40: 0.0000 (0.0088)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [550/845]  eta: 0:01:38  loss: 19.5288 (19.8378)  loss_n_40: 4.7017 (4.6283)  loss_n_60: 5.8056 (5.6287)  loss_n_80: 4.7968 (4.6682)  loss_n_100: 4.7897 (4.6357)  triple_100: 0.0000 (0.1025)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1658)  triple_40: 0.0000 (0.0086)  time: 0.3340  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:4]  [560/845]  eta: 0:01:35  loss: 19.4465 (19.8228)  loss_n_40: 4.4909 (4.6249)  loss_n_60: 5.5628 (5.6266)  loss_n_80: 4.7100 (4.6672)  loss_n_100: 4.5714 (4.6322)  triple_100: 0.0000 (0.1006)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1628)  triple_40: 0.0000 (0.0085)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [570/845]  eta: 0:01:32  loss: 19.8357 (19.8184)  loss_n_40: 4.4120 (4.6226)  loss_n_60: 5.5628 (5.6258)  loss_n_80: 4.7100 (4.6674)  loss_n_100: 4.5365 (4.6297)  triple_100: 0.0000 (0.1046)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1600)  triple_40: 0.0000 (0.0083)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [580/845]  eta: 0:01:28  loss: 19.4666 (19.8094)  loss_n_40: 4.3910 (4.6220)  loss_n_60: 5.4808 (5.6271)  loss_n_80: 4.6329 (4.6653)  loss_n_100: 4.5365 (4.6266)  triple_100: 0.0000 (0.1028)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1572)  triple_40: 0.0000 (0.0082)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [590/845]  eta: 0:01:25  loss: 19.4666 (19.8297)  loss_n_40: 4.4545 (4.6235)  loss_n_60: 5.4808 (5.6281)  loss_n_80: 4.8341 (4.6696)  loss_n_100: 4.5649 (4.6315)  triple_100: 0.0000 (0.1014)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1676)  triple_40: 0.0000 (0.0080)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [600/845]  eta: 0:01:22  loss: 20.2705 (19.8347)  loss_n_40: 4.8119 (4.6254)  loss_n_60: 5.9022 (5.6322)  loss_n_80: 4.8870 (4.6733)  loss_n_100: 4.7152 (4.6314)  triple_100: 0.0000 (0.0997)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1648)  triple_40: 0.0000 (0.0079)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [610/845]  eta: 0:01:18  loss: 20.1696 (19.8287)  loss_n_40: 4.6676 (4.6250)  loss_n_60: 5.8524 (5.6333)  loss_n_80: 4.6825 (4.6728)  loss_n_100: 4.5706 (4.6292)  triple_100: 0.0000 (0.0981)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1624)  triple_40: 0.0000 (0.0078)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [620/845]  eta: 0:01:15  loss: 20.0675 (19.8276)  loss_n_40: 4.6676 (4.6241)  loss_n_60: 5.7008 (5.6323)  loss_n_80: 4.7872 (4.6749)  loss_n_100: 4.6799 (4.6302)  triple_100: 0.0000 (0.0986)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1598)  triple_40: 0.0000 (0.0077)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [630/845]  eta: 0:01:11  loss: 19.2420 (19.8353)  loss_n_40: 4.6442 (4.6263)  loss_n_60: 5.7101 (5.6333)  loss_n_80: 4.6275 (4.6743)  loss_n_100: 4.4658 (4.6331)  triple_100: 0.0000 (0.1035)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1572)  triple_40: 0.0000 (0.0075)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [640/845]  eta: 0:01:08  loss: 18.7668 (19.8236)  loss_n_40: 4.5644 (4.6256)  loss_n_60: 5.7631 (5.6338)  loss_n_80: 4.3139 (4.6702)  loss_n_100: 4.2611 (4.6300)  triple_100: 0.0000 (0.1019)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1548)  triple_40: 0.0000 (0.0074)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [650/845]  eta: 0:01:05  loss: 19.4315 (19.8219)  loss_n_40: 4.6615 (4.6243)  loss_n_60: 5.6777 (5.6316)  loss_n_80: 4.3139 (4.6679)  loss_n_100: 4.2354 (4.6317)  triple_100: 0.0000 (0.1068)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1524)  triple_40: 0.0000 (0.0073)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [660/845]  eta: 0:01:01  loss: 19.6330 (19.8208)  loss_n_40: 4.8535 (4.6250)  loss_n_60: 5.6777 (5.6323)  loss_n_80: 4.4169 (4.6690)  loss_n_100: 4.3503 (4.6320)  triple_100: 0.0000 (0.1052)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1501)  triple_40: 0.0000 (0.0072)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [670/845]  eta: 0:00:58  loss: 20.6365 (19.8339)  loss_n_40: 4.9208 (4.6286)  loss_n_60: 6.0331 (5.6365)  loss_n_80: 4.9423 (4.6743)  loss_n_100: 4.7057 (4.6360)  triple_100: 0.0000 (0.1036)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1479)  triple_40: 0.0000 (0.0071)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [680/845]  eta: 0:00:55  loss: 21.0448 (19.8465)  loss_n_40: 4.9542 (4.6307)  loss_n_60: 6.0591 (5.6388)  loss_n_80: 4.9567 (4.6774)  loss_n_100: 4.7506 (4.6408)  triple_100: 0.0000 (0.1060)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1457)  triple_40: 0.0000 (0.0070)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [690/845]  eta: 0:00:51  loss: 19.3176 (19.8436)  loss_n_40: 4.6201 (4.6307)  loss_n_60: 5.8228 (5.6413)  loss_n_80: 4.6952 (4.6777)  loss_n_100: 4.6036 (4.6389)  triple_100: 0.0000 (0.1044)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1436)  triple_40: 0.0000 (0.0069)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [700/845]  eta: 0:00:48  loss: 20.1188 (19.8570)  loss_n_40: 4.6811 (4.6346)  loss_n_60: 5.8228 (5.6446)  loss_n_80: 4.7897 (4.6810)  loss_n_100: 4.6485 (4.6427)  triple_100: 0.0000 (0.1034)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1439)  triple_40: 0.0000 (0.0068)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [710/845]  eta: 0:00:45  loss: 19.8525 (19.8425)  loss_n_40: 4.6811 (4.6318)  loss_n_60: 5.8136 (5.6429)  loss_n_80: 4.6759 (4.6765)  loss_n_100: 4.5452 (4.6381)  triple_100: 0.0000 (0.1047)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1419)  triple_40: 0.0000 (0.0067)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [720/845]  eta: 0:00:41  loss: 19.8241 (19.8740)  loss_n_40: 4.6835 (4.6375)  loss_n_60: 5.8677 (5.6484)  loss_n_80: 4.6759 (4.6800)  loss_n_100: 4.4787 (4.6417)  triple_100: 0.0000 (0.1193)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1405)  triple_40: 0.0000 (0.0066)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [730/845]  eta: 0:00:38  loss: 20.8442 (19.8783)  loss_n_40: 4.9929 (4.6401)  loss_n_60: 5.8871 (5.6510)  loss_n_80: 4.8722 (4.6809)  loss_n_100: 4.6476 (4.6436)  triple_100: 0.0000 (0.1177)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1386)  triple_40: 0.0000 (0.0065)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [740/845]  eta: 0:00:35  loss: 18.3961 (19.8544)  loss_n_40: 4.5625 (4.6339)  loss_n_60: 5.3670 (5.6434)  loss_n_80: 4.1728 (4.6759)  loss_n_100: 4.1556 (4.6409)  triple_100: 0.0000 (0.1170)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1367)  triple_40: 0.0000 (0.0064)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [750/845]  eta: 0:00:31  loss: 18.2398 (19.8398)  loss_n_40: 4.2343 (4.6288)  loss_n_60: 5.1295 (5.6366)  loss_n_80: 4.1728 (4.6729)  loss_n_100: 4.0803 (4.6392)  triple_100: 0.0000 (0.1155)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1404)  triple_40: 0.0000 (0.0063)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [760/845]  eta: 0:00:28  loss: 18.8794 (19.8440)  loss_n_40: 4.2754 (4.6279)  loss_n_60: 5.2269 (5.6341)  loss_n_80: 4.6689 (4.6742)  loss_n_100: 4.4294 (4.6444)  triple_100: 0.0000 (0.1185)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1386)  triple_40: 0.0000 (0.0062)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [770/845]  eta: 0:00:25  loss: 19.0325 (19.8526)  loss_n_40: 4.6013 (4.6276)  loss_n_60: 5.6943 (5.6320)  loss_n_80: 4.4151 (4.6737)  loss_n_100: 4.3364 (4.6461)  triple_100: 0.0000 (0.1266)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1404)  triple_40: 0.0000 (0.0062)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [780/845]  eta: 0:00:21  loss: 18.3992 (19.8321)  loss_n_40: 4.5457 (4.6242)  loss_n_60: 5.6253 (5.6299)  loss_n_80: 4.1695 (4.6685)  loss_n_100: 4.1123 (4.6399)  triple_100: 0.0000 (0.1250)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1386)  triple_40: 0.0000 (0.0061)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [790/845]  eta: 0:00:18  loss: 18.0793 (19.8138)  loss_n_40: 4.4120 (4.6192)  loss_n_60: 5.4677 (5.6257)  loss_n_80: 4.1658 (4.6656)  loss_n_100: 4.1123 (4.6364)  triple_100: 0.0000 (0.1241)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1369)  triple_40: 0.0000 (0.0060)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [800/845]  eta: 0:00:15  loss: 18.0793 (19.8065)  loss_n_40: 4.1637 (4.6180)  loss_n_60: 5.1975 (5.6248)  loss_n_80: 4.3951 (4.6647)  loss_n_100: 4.3125 (4.6353)  triple_100: 0.0000 (0.1226)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1352)  triple_40: 0.0000 (0.0059)  time: 0.3343  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:4]  [810/845]  eta: 0:00:11  loss: 19.3972 (19.8051)  loss_n_40: 4.6800 (4.6197)  loss_n_60: 5.6967 (5.6265)  loss_n_80: 4.4651 (4.6637)  loss_n_100: 4.3661 (4.6348)  triple_100: 0.0000 (0.1211)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1335)  triple_40: 0.0000 (0.0059)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [820/845]  eta: 0:00:08  loss: 19.9971 (19.8224)  loss_n_40: 4.8197 (4.6234)  loss_n_60: 5.9862 (5.6308)  loss_n_80: 4.7218 (4.6694)  loss_n_100: 4.8651 (4.6406)  triple_100: 0.0000 (0.1206)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.1319)  triple_40: 0.0000 (0.0058)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [830/845]  eta: 0:00:05  loss: 21.0366 (19.8697)  loss_n_40: 4.8197 (4.6226)  loss_n_60: 5.9406 (5.6294)  loss_n_80: 5.2615 (4.6681)  loss_n_100: 4.8415 (4.6392)  triple_100: 0.0000 (0.1241)  triple_80: 0.0000 (0.0004)  triple_60: 0.0000 (0.1642)  triple_40: 0.0000 (0.0215)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [840/845]  eta: 0:00:01  loss: 19.8062 (19.8688)  loss_n_40: 4.6973 (4.6218)  loss_n_60: 5.7501 (5.6281)  loss_n_80: 4.7315 (4.6685)  loss_n_100: 4.5155 (4.6394)  triple_100: 0.0000 (0.1271)  triple_80: 0.0000 (0.0004)  triple_60: 0.0000 (0.1623)  triple_40: 0.0000 (0.0213)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4]  [844/845]  eta: 0:00:00  loss: 19.8062 (19.8609)  loss_n_40: 4.3173 (4.6205)  loss_n_60: 5.3984 (5.6271)  loss_n_80: 4.7315 (4.6667)  loss_n_100: 4.5155 (4.6370)  triple_100: 0.0000 (0.1265)  triple_80: 0.0000 (0.0004)  triple_60: 0.0000 (0.1615)  triple_40: 0.0000 (0.0212)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:4] Total time: 0:04:42 (0.3349 s / it)\n",
      "Averaged stats: loss: 19.8062 (19.8609)  loss_n_40: 4.3173 (4.6205)  loss_n_60: 5.3984 (5.6271)  loss_n_80: 4.7315 (4.6667)  loss_n_100: 4.5155 (4.6370)  triple_100: 0.0000 (0.1265)  triple_80: 0.0000 (0.0004)  triple_60: 0.0000 (0.1615)  triple_40: 0.0000 (0.0212)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_4_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 4.637%\n",
      "Min loss_n_100: 4.637\n",
      "Best Epoch: 4.000\n",
      "Train: [epoch:5]  [   0/1724]  eta: 1:59:11  lr: 0.000080  loss: 18.6479 (18.6479)  loss_n_40: 4.4401 (4.4401)  loss_n_60: 5.4799 (5.4799)  loss_n_80: 4.3930 (4.3930)  loss_n_100: 4.3350 (4.3350)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1482  data: 0.3956  max mem: 46473\n",
      "Train: [epoch:5]  [  10/1724]  eta: 1:52:33  lr: 0.000080  loss: 19.6331 (19.3887)  loss_n_40: 4.5758 (4.5568)  loss_n_60: 5.5816 (5.5865)  loss_n_80: 4.6717 (4.6574)  loss_n_100: 4.3350 (4.4322)  triple_100: 0.0000 (0.0358)  triple_80: 0.0000 (0.0467)  triple_60: 0.0000 (0.0733)  triple_40: 0.0000 (0.0000)  time: 3.9405  data: 0.0361  max mem: 46473\n",
      "Train: [epoch:5]  [  20/1724]  eta: 1:51:38  lr: 0.000080  loss: 20.0435 (20.4821)  loss_n_40: 4.7200 (4.6507)  loss_n_60: 5.7452 (5.6933)  loss_n_80: 4.7589 (4.7720)  loss_n_100: 4.6599 (4.6754)  triple_100: 0.0000 (0.0483)  triple_80: 0.0000 (0.0245)  triple_60: 0.0000 (0.4200)  triple_40: 0.0000 (0.1979)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [  30/1724]  eta: 1:50:53  lr: 0.000080  loss: 20.5708 (20.4211)  loss_n_40: 4.7453 (4.6467)  loss_n_60: 5.8137 (5.6973)  loss_n_80: 4.8402 (4.7913)  loss_n_100: 4.8612 (4.7735)  triple_100: 0.0000 (0.0683)  triple_80: 0.0000 (0.0166)  triple_60: 0.0000 (0.2933)  triple_40: 0.0000 (0.1341)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [  40/1724]  eta: 1:50:10  lr: 0.000080  loss: 20.1655 (20.2884)  loss_n_40: 4.6494 (4.6409)  loss_n_60: 5.6196 (5.6677)  loss_n_80: 4.8527 (4.8002)  loss_n_100: 4.5647 (4.7250)  triple_100: 0.0000 (0.0516)  triple_80: 0.0000 (0.0367)  triple_60: 0.0000 (0.2649)  triple_40: 0.0000 (0.1014)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [  50/1724]  eta: 1:49:28  lr: 0.000080  loss: 19.7572 (20.2339)  loss_n_40: 4.6269 (4.6579)  loss_n_60: 5.5999 (5.6570)  loss_n_80: 4.8103 (4.7965)  loss_n_100: 4.5427 (4.7245)  triple_100: 0.0000 (0.0415)  triple_80: 0.0000 (0.0366)  triple_60: 0.0000 (0.2281)  triple_40: 0.0000 (0.0918)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [  60/1724]  eta: 1:48:47  lr: 0.000080  loss: 19.7054 (20.1299)  loss_n_40: 4.7159 (4.6637)  loss_n_60: 5.6642 (5.6705)  loss_n_80: 4.7338 (4.7823)  loss_n_100: 4.5427 (4.6806)  triple_100: 0.0000 (0.0347)  triple_80: 0.0000 (0.0306)  triple_60: 0.0000 (0.1907)  triple_40: 0.0000 (0.0767)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [  70/1724]  eta: 1:48:07  lr: 0.000080  loss: 19.7054 (20.0463)  loss_n_40: 4.6646 (4.6428)  loss_n_60: 5.5719 (5.6333)  loss_n_80: 4.7042 (4.7545)  loss_n_100: 4.4960 (4.6555)  triple_100: 0.0000 (0.0298)  triple_80: 0.0000 (0.0480)  triple_60: 0.0000 (0.2156)  triple_40: 0.0000 (0.0670)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [  80/1724]  eta: 1:47:27  lr: 0.000080  loss: 19.1900 (19.9459)  loss_n_40: 4.4407 (4.6112)  loss_n_60: 5.3566 (5.6017)  loss_n_80: 4.6032 (4.7275)  loss_n_100: 4.4960 (4.6534)  triple_100: 0.0000 (0.0619)  triple_80: 0.0000 (0.0420)  triple_60: 0.0000 (0.1890)  triple_40: 0.0000 (0.0591)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [  90/1724]  eta: 1:46:47  lr: 0.000080  loss: 19.9991 (20.2467)  loss_n_40: 4.3485 (4.5936)  loss_n_60: 5.3914 (5.6038)  loss_n_80: 4.8724 (4.8118)  loss_n_100: 5.4026 (4.8087)  triple_100: 0.0000 (0.1239)  triple_80: 0.0000 (0.0447)  triple_60: 0.0000 (0.2076)  triple_40: 0.0000 (0.0526)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 100/1724]  eta: 1:46:08  lr: 0.000080  loss: 22.3490 (20.6040)  loss_n_40: 4.5216 (4.5996)  loss_n_60: 5.6807 (5.6228)  loss_n_80: 5.5899 (4.8984)  loss_n_100: 6.0187 (4.9323)  triple_100: 0.0000 (0.1283)  triple_80: 0.0000 (0.0793)  triple_60: 0.0000 (0.2510)  triple_40: 0.0000 (0.0923)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 110/1724]  eta: 1:45:28  lr: 0.000080  loss: 21.8729 (20.7055)  loss_n_40: 4.5216 (4.5863)  loss_n_60: 5.6807 (5.6215)  loss_n_80: 5.6292 (4.9793)  loss_n_100: 5.9666 (5.0171)  triple_100: 0.0000 (0.1167)  triple_80: 0.0000 (0.0721)  triple_60: 0.0000 (0.2284)  triple_40: 0.0000 (0.0840)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 120/1724]  eta: 1:44:49  lr: 0.000080  loss: 21.1750 (20.7027)  loss_n_40: 4.4822 (4.5788)  loss_n_60: 5.6160 (5.6162)  loss_n_80: 5.4536 (4.9963)  loss_n_100: 5.5751 (5.0490)  triple_100: 0.0000 (0.1071)  triple_80: 0.0000 (0.0662)  triple_60: 0.0000 (0.2121)  triple_40: 0.0000 (0.0770)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 130/1724]  eta: 1:44:09  lr: 0.000080  loss: 20.6828 (20.7412)  loss_n_40: 4.5109 (4.5830)  loss_n_60: 5.6160 (5.6124)  loss_n_80: 5.0360 (5.0048)  loss_n_100: 5.3023 (5.0666)  triple_100: 0.0000 (0.0992)  triple_80: 0.0000 (0.0611)  triple_60: 0.0000 (0.2143)  triple_40: 0.0000 (0.0998)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 140/1724]  eta: 1:43:30  lr: 0.000080  loss: 21.0847 (20.8563)  loss_n_40: 4.5960 (4.5743)  loss_n_60: 5.6331 (5.6031)  loss_n_80: 5.1842 (5.0463)  loss_n_100: 5.7040 (5.1736)  triple_100: 0.0000 (0.1098)  triple_80: 0.0000 (0.0575)  triple_60: 0.0000 (0.1991)  triple_40: 0.0000 (0.0927)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 150/1724]  eta: 1:42:51  lr: 0.000080  loss: 21.3782 (20.9094)  loss_n_40: 4.6181 (4.5797)  loss_n_60: 5.6618 (5.6063)  loss_n_80: 5.2836 (5.0565)  loss_n_100: 6.1555 (5.2165)  triple_100: 0.0000 (0.1034)  triple_80: 0.0000 (0.0592)  triple_60: 0.0000 (0.1867)  triple_40: 0.0000 (0.1011)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 160/1724]  eta: 1:42:12  lr: 0.000080  loss: 19.9494 (20.8249)  loss_n_40: 4.5004 (4.5664)  loss_n_60: 5.5419 (5.5916)  loss_n_80: 5.0080 (5.0347)  loss_n_100: 5.1551 (5.1994)  triple_100: 0.0000 (0.1008)  triple_80: 0.0000 (0.0555)  triple_60: 0.0000 (0.1818)  triple_40: 0.0000 (0.0948)  time: 3.9210  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [ 170/1724]  eta: 1:41:32  lr: 0.000080  loss: 19.5398 (20.7780)  loss_n_40: 4.4034 (4.5617)  loss_n_60: 5.3769 (5.5847)  loss_n_80: 4.7985 (5.0260)  loss_n_100: 4.8128 (5.1769)  triple_100: 0.0000 (0.0977)  triple_80: 0.0000 (0.0544)  triple_60: 0.0000 (0.1811)  triple_40: 0.0000 (0.0956)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 180/1724]  eta: 1:40:53  lr: 0.000080  loss: 19.4925 (20.7130)  loss_n_40: 4.4287 (4.5513)  loss_n_60: 5.3769 (5.5711)  loss_n_80: 4.8313 (5.0068)  loss_n_100: 4.7759 (5.1586)  triple_100: 0.0000 (0.0948)  triple_80: 0.0000 (0.0514)  triple_60: 0.0000 (0.1803)  triple_40: 0.0000 (0.0987)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 190/1724]  eta: 1:40:14  lr: 0.000080  loss: 19.4925 (20.6621)  loss_n_40: 4.4789 (4.5499)  loss_n_60: 5.4848 (5.5704)  loss_n_80: 4.7692 (4.9950)  loss_n_100: 4.7466 (5.1409)  triple_100: 0.0000 (0.0901)  triple_80: 0.0000 (0.0515)  triple_60: 0.0000 (0.1709)  triple_40: 0.0000 (0.0935)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 200/1724]  eta: 1:39:35  lr: 0.000080  loss: 20.1092 (20.6444)  loss_n_40: 4.5405 (4.5494)  loss_n_60: 5.6054 (5.5694)  loss_n_80: 4.8251 (4.9833)  loss_n_100: 4.8316 (5.1240)  triple_100: 0.0000 (0.0930)  triple_80: 0.0000 (0.0549)  triple_60: 0.0000 (0.1799)  triple_40: 0.0000 (0.0904)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 210/1724]  eta: 1:38:55  lr: 0.000080  loss: 20.1364 (20.6095)  loss_n_40: 4.5538 (4.5501)  loss_n_60: 5.6054 (5.5702)  loss_n_80: 4.8601 (4.9752)  loss_n_100: 4.7222 (5.1021)  triple_100: 0.0000 (0.0925)  triple_80: 0.0000 (0.0543)  triple_60: 0.0000 (0.1790)  triple_40: 0.0000 (0.0861)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 220/1724]  eta: 1:38:16  lr: 0.000080  loss: 19.9028 (20.5544)  loss_n_40: 4.5995 (4.5471)  loss_n_60: 5.5121 (5.5649)  loss_n_80: 4.8021 (4.9598)  loss_n_100: 4.5498 (5.0776)  triple_100: 0.0000 (0.0897)  triple_80: 0.0000 (0.0562)  triple_60: 0.0000 (0.1738)  triple_40: 0.0000 (0.0853)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 230/1724]  eta: 1:37:37  lr: 0.000080  loss: 19.1789 (20.4772)  loss_n_40: 4.3762 (4.5356)  loss_n_60: 5.3690 (5.5498)  loss_n_80: 4.5483 (4.9409)  loss_n_100: 4.4901 (5.0515)  triple_100: 0.0000 (0.0876)  triple_80: 0.0000 (0.0537)  triple_60: 0.0000 (0.1765)  triple_40: 0.0000 (0.0816)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 240/1724]  eta: 1:36:57  lr: 0.000080  loss: 18.3984 (20.3814)  loss_n_40: 4.3030 (4.5247)  loss_n_60: 5.2677 (5.5359)  loss_n_80: 4.3488 (4.9174)  loss_n_100: 4.4057 (5.0194)  triple_100: 0.0000 (0.0845)  triple_80: 0.0000 (0.0521)  triple_60: 0.0000 (0.1692)  triple_40: 0.0000 (0.0782)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 250/1724]  eta: 1:36:18  lr: 0.000080  loss: 18.3655 (20.3039)  loss_n_40: 4.3567 (4.5188)  loss_n_60: 5.2251 (5.5265)  loss_n_80: 4.3181 (4.8988)  loss_n_100: 4.2082 (4.9873)  triple_100: 0.0000 (0.0827)  triple_80: 0.0000 (0.0501)  triple_60: 0.0000 (0.1647)  triple_40: 0.0000 (0.0751)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 260/1724]  eta: 1:35:39  lr: 0.000080  loss: 18.4472 (20.2462)  loss_n_40: 4.3967 (4.5146)  loss_n_60: 5.3280 (5.5176)  loss_n_80: 4.3905 (4.8812)  loss_n_100: 4.2526 (4.9596)  triple_100: 0.0000 (0.0796)  triple_80: 0.0000 (0.0501)  triple_60: 0.0000 (0.1664)  triple_40: 0.0000 (0.0773)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 270/1724]  eta: 1:35:00  lr: 0.000080  loss: 18.6878 (20.2305)  loss_n_40: 4.3306 (4.5039)  loss_n_60: 5.1748 (5.5029)  loss_n_80: 4.5035 (4.8692)  loss_n_100: 4.3581 (4.9495)  triple_100: 0.0000 (0.0939)  triple_80: 0.0000 (0.0524)  triple_60: 0.0000 (0.1813)  triple_40: 0.0000 (0.0773)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 280/1724]  eta: 1:34:20  lr: 0.000080  loss: 19.2556 (20.2323)  loss_n_40: 4.3306 (4.5032)  loss_n_60: 5.2397 (5.5019)  loss_n_80: 4.6218 (4.8707)  loss_n_100: 4.9463 (4.9594)  triple_100: 0.0000 (0.0905)  triple_80: 0.0000 (0.0505)  triple_60: 0.0000 (0.1749)  triple_40: 0.0000 (0.0812)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 290/1724]  eta: 1:33:41  lr: 0.000080  loss: 19.3857 (20.1997)  loss_n_40: 4.4310 (4.4996)  loss_n_60: 5.3690 (5.4953)  loss_n_80: 4.7621 (4.8640)  loss_n_100: 4.8898 (4.9484)  triple_100: 0.0000 (0.0888)  triple_80: 0.0000 (0.0520)  triple_60: 0.0000 (0.1733)  triple_40: 0.0000 (0.0784)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 300/1724]  eta: 1:33:02  lr: 0.000080  loss: 18.9385 (20.1644)  loss_n_40: 4.4278 (4.4981)  loss_n_60: 5.3729 (5.4911)  loss_n_80: 4.6440 (4.8580)  loss_n_100: 4.5752 (4.9349)  triple_100: 0.0000 (0.0858)  triple_80: 0.0000 (0.0532)  triple_60: 0.0000 (0.1675)  triple_40: 0.0000 (0.0758)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 310/1724]  eta: 1:32:23  lr: 0.000080  loss: 19.0454 (20.1212)  loss_n_40: 4.2781 (4.4845)  loss_n_60: 5.2517 (5.4805)  loss_n_80: 4.6308 (4.8508)  loss_n_100: 4.4496 (4.9193)  triple_100: 0.0000 (0.0831)  triple_80: 0.0000 (0.0675)  triple_60: 0.0000 (0.1622)  triple_40: 0.0000 (0.0733)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 320/1724]  eta: 1:31:44  lr: 0.000080  loss: 19.0454 (20.0853)  loss_n_40: 4.1695 (4.4803)  loss_n_60: 5.2016 (5.4759)  loss_n_80: 4.4865 (4.8424)  loss_n_100: 4.4496 (4.9057)  triple_100: 0.0000 (0.0820)  triple_80: 0.0000 (0.0654)  triple_60: 0.0000 (0.1601)  triple_40: 0.0000 (0.0735)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 330/1724]  eta: 1:31:04  lr: 0.000080  loss: 18.0117 (20.0024)  loss_n_40: 4.1324 (4.4663)  loss_n_60: 5.1272 (5.4602)  loss_n_80: 4.4157 (4.8249)  loss_n_100: 4.1896 (4.8804)  triple_100: 0.0000 (0.0795)  triple_80: 0.0000 (0.0635)  triple_60: 0.0000 (0.1564)  triple_40: 0.0000 (0.0713)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 340/1724]  eta: 1:30:25  lr: 0.000080  loss: 17.2761 (19.9654)  loss_n_40: 4.0351 (4.4616)  loss_n_60: 4.9550 (5.4515)  loss_n_80: 4.3518 (4.8129)  loss_n_100: 4.1257 (4.8644)  triple_100: 0.0000 (0.0784)  triple_80: 0.0000 (0.0616)  triple_60: 0.0000 (0.1611)  triple_40: 0.0000 (0.0740)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 350/1724]  eta: 1:29:46  lr: 0.000080  loss: 17.8227 (19.8918)  loss_n_40: 4.1539 (4.4521)  loss_n_60: 5.0678 (5.4401)  loss_n_80: 4.2425 (4.7945)  loss_n_100: 4.0225 (4.8384)  triple_100: 0.0000 (0.0785)  triple_80: 0.0000 (0.0599)  triple_60: 0.0000 (0.1565)  triple_40: 0.0000 (0.0719)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 360/1724]  eta: 1:29:07  lr: 0.000080  loss: 17.8227 (19.8570)  loss_n_40: 4.1260 (4.4472)  loss_n_60: 5.0527 (5.4323)  loss_n_80: 4.2904 (4.7851)  loss_n_100: 4.0934 (4.8244)  triple_100: 0.0000 (0.0764)  triple_80: 0.0000 (0.0603)  triple_60: 0.0000 (0.1593)  triple_40: 0.0000 (0.0719)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 370/1724]  eta: 1:28:27  lr: 0.000080  loss: 18.2908 (19.8379)  loss_n_40: 4.1774 (4.4428)  loss_n_60: 5.1125 (5.4263)  loss_n_80: 4.4705 (4.7782)  loss_n_100: 4.2634 (4.8106)  triple_100: 0.0000 (0.0764)  triple_80: 0.0000 (0.0587)  triple_60: 0.0000 (0.1685)  triple_40: 0.0000 (0.0764)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 380/1724]  eta: 1:27:48  lr: 0.000080  loss: 17.9674 (19.7812)  loss_n_40: 4.1507 (4.4340)  loss_n_60: 5.1573 (5.4170)  loss_n_80: 4.4312 (4.7652)  loss_n_100: 4.2634 (4.7906)  triple_100: 0.0000 (0.0787)  triple_80: 0.0000 (0.0571)  triple_60: 0.0000 (0.1640)  triple_40: 0.0000 (0.0744)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 390/1724]  eta: 1:27:09  lr: 0.000080  loss: 17.8328 (19.7243)  loss_n_40: 4.1067 (4.4242)  loss_n_60: 4.9498 (5.4039)  loss_n_80: 4.3004 (4.7517)  loss_n_100: 4.1332 (4.7759)  triple_100: 0.0000 (0.0789)  triple_80: 0.0000 (0.0573)  triple_60: 0.0000 (0.1600)  triple_40: 0.0000 (0.0725)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 400/1724]  eta: 1:26:30  lr: 0.000080  loss: 17.1826 (19.6616)  loss_n_40: 3.9971 (4.4154)  loss_n_60: 4.8384 (5.3930)  loss_n_80: 4.1667 (4.7379)  loss_n_100: 3.9533 (4.7549)  triple_100: 0.0000 (0.0769)  triple_80: 0.0000 (0.0565)  triple_60: 0.0000 (0.1563)  triple_40: 0.0000 (0.0707)  time: 3.9188  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [ 410/1724]  eta: 1:25:50  lr: 0.000080  loss: 16.8710 (19.6013)  loss_n_40: 3.9989 (4.4070)  loss_n_60: 4.8902 (5.3822)  loss_n_80: 4.1661 (4.7245)  loss_n_100: 3.8419 (4.7331)  triple_100: 0.0000 (0.0758)  triple_80: 0.0000 (0.0572)  triple_60: 0.0000 (0.1525)  triple_40: 0.0000 (0.0690)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 420/1724]  eta: 1:25:11  lr: 0.000080  loss: 17.3717 (19.5928)  loss_n_40: 4.1108 (4.4026)  loss_n_60: 4.9339 (5.3753)  loss_n_80: 4.2960 (4.7190)  loss_n_100: 3.9327 (4.7238)  triple_100: 0.0000 (0.0740)  triple_80: 0.0000 (0.0601)  triple_60: 0.0000 (0.1578)  triple_40: 0.0000 (0.0802)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 430/1724]  eta: 1:24:32  lr: 0.000080  loss: 18.3308 (19.5568)  loss_n_40: 4.1629 (4.3978)  loss_n_60: 5.1478 (5.3705)  loss_n_80: 4.4449 (4.7105)  loss_n_100: 4.2310 (4.7123)  triple_100: 0.0000 (0.0732)  triple_80: 0.0000 (0.0587)  triple_60: 0.0000 (0.1553)  triple_40: 0.0000 (0.0783)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 440/1724]  eta: 1:23:53  lr: 0.000080  loss: 17.6017 (19.5191)  loss_n_40: 4.1472 (4.3920)  loss_n_60: 5.1071 (5.3640)  loss_n_80: 4.2000 (4.6996)  loss_n_100: 3.9973 (4.6956)  triple_100: 0.0000 (0.0723)  triple_80: 0.0000 (0.0580)  triple_60: 0.0000 (0.1577)  triple_40: 0.0000 (0.0799)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 450/1724]  eta: 1:23:14  lr: 0.000080  loss: 17.0199 (19.4654)  loss_n_40: 4.0367 (4.3846)  loss_n_60: 5.0391 (5.3569)  loss_n_80: 4.1231 (4.6855)  loss_n_100: 3.7805 (4.6747)  triple_100: 0.0000 (0.0721)  triple_80: 0.0000 (0.0567)  triple_60: 0.0000 (0.1568)  triple_40: 0.0000 (0.0781)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 460/1724]  eta: 1:22:35  lr: 0.000080  loss: 17.0199 (19.4211)  loss_n_40: 4.0315 (4.3791)  loss_n_60: 5.0353 (5.3494)  loss_n_80: 4.0553 (4.6749)  loss_n_100: 3.7908 (4.6619)  triple_100: 0.0000 (0.0705)  triple_80: 0.0000 (0.0555)  triple_60: 0.0000 (0.1534)  triple_40: 0.0000 (0.0764)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 470/1724]  eta: 1:21:55  lr: 0.000080  loss: 17.1145 (19.3728)  loss_n_40: 4.1209 (4.3720)  loss_n_60: 5.0555 (5.3406)  loss_n_80: 4.1620 (4.6640)  loss_n_100: 3.8712 (4.6457)  triple_100: 0.0000 (0.0695)  triple_80: 0.0000 (0.0551)  triple_60: 0.0000 (0.1512)  triple_40: 0.0000 (0.0748)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 480/1724]  eta: 1:21:16  lr: 0.000080  loss: 17.0148 (19.3286)  loss_n_40: 4.0336 (4.3656)  loss_n_60: 4.9425 (5.3316)  loss_n_80: 4.1438 (4.6538)  loss_n_100: 3.9229 (4.6302)  triple_100: 0.0000 (0.0719)  triple_80: 0.0000 (0.0542)  triple_60: 0.0000 (0.1480)  triple_40: 0.0000 (0.0733)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 490/1724]  eta: 1:20:37  lr: 0.000080  loss: 17.3279 (19.3008)  loss_n_40: 3.9922 (4.3597)  loss_n_60: 4.9175 (5.3243)  loss_n_80: 4.2350 (4.6460)  loss_n_100: 4.0910 (4.6232)  triple_100: 0.0000 (0.0728)  triple_80: 0.0000 (0.0531)  triple_60: 0.0000 (0.1473)  triple_40: 0.0000 (0.0744)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 500/1724]  eta: 1:19:58  lr: 0.000080  loss: 17.3872 (19.2627)  loss_n_40: 4.0164 (4.3530)  loss_n_60: 4.9345 (5.3165)  loss_n_80: 4.2609 (4.6378)  loss_n_100: 4.2571 (4.6138)  triple_100: 0.0000 (0.0714)  triple_80: 0.0000 (0.0521)  triple_60: 0.0000 (0.1453)  triple_40: 0.0000 (0.0729)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 510/1724]  eta: 1:19:19  lr: 0.000080  loss: 17.0972 (19.2212)  loss_n_40: 3.9955 (4.3464)  loss_n_60: 4.8833 (5.3091)  loss_n_80: 4.2053 (4.6291)  loss_n_100: 3.9768 (4.6014)  triple_100: 0.0000 (0.0700)  triple_80: 0.0000 (0.0512)  triple_60: 0.0000 (0.1425)  triple_40: 0.0000 (0.0717)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 520/1724]  eta: 1:18:39  lr: 0.000080  loss: 17.0515 (19.1743)  loss_n_40: 3.9822 (4.3397)  loss_n_60: 4.8750 (5.3001)  loss_n_80: 4.1099 (4.6174)  loss_n_100: 3.9483 (4.5870)  triple_100: 0.0000 (0.0695)  triple_80: 0.0000 (0.0504)  triple_60: 0.0000 (0.1397)  triple_40: 0.0000 (0.0705)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:5]  [ 530/1724]  eta: 1:18:00  lr: 0.000080  loss: 17.0657 (19.1443)  loss_n_40: 3.9822 (4.3331)  loss_n_60: 4.8107 (5.2904)  loss_n_80: 4.1099 (4.6072)  loss_n_100: 3.9845 (4.5751)  triple_100: 0.0000 (0.0738)  triple_80: 0.0000 (0.0543)  triple_60: 0.0000 (0.1406)  triple_40: 0.0000 (0.0699)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 540/1724]  eta: 1:17:21  lr: 0.000080  loss: 17.0657 (19.1139)  loss_n_40: 3.9477 (4.3266)  loss_n_60: 4.7531 (5.2813)  loss_n_80: 4.1535 (4.5988)  loss_n_100: 4.1450 (4.5676)  triple_100: 0.0000 (0.0737)  triple_80: 0.0000 (0.0533)  triple_60: 0.0000 (0.1380)  triple_40: 0.0000 (0.0747)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 550/1724]  eta: 1:16:42  lr: 0.000080  loss: 16.3604 (19.0652)  loss_n_40: 3.7273 (4.3172)  loss_n_60: 4.6909 (5.2729)  loss_n_80: 4.0332 (4.5882)  loss_n_100: 3.9923 (4.5526)  triple_100: 0.0000 (0.0728)  triple_80: 0.0000 (0.0526)  triple_60: 0.0000 (0.1355)  triple_40: 0.0000 (0.0733)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 560/1724]  eta: 1:16:02  lr: 0.000080  loss: 16.0285 (19.0101)  loss_n_40: 3.6903 (4.3062)  loss_n_60: 4.6683 (5.2615)  loss_n_80: 3.9107 (4.5760)  loss_n_100: 3.6822 (4.5368)  triple_100: 0.0000 (0.0715)  triple_80: 0.0000 (0.0517)  triple_60: 0.0000 (0.1344)  triple_40: 0.0000 (0.0720)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 570/1724]  eta: 1:15:23  lr: 0.000080  loss: 16.0821 (18.9689)  loss_n_40: 3.7399 (4.2974)  loss_n_60: 4.6592 (5.2517)  loss_n_80: 3.9107 (4.5644)  loss_n_100: 3.6923 (4.5218)  triple_100: 0.0000 (0.0725)  triple_80: 0.0000 (0.0508)  triple_60: 0.0000 (0.1363)  triple_40: 0.0000 (0.0740)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 580/1724]  eta: 1:14:44  lr: 0.000080  loss: 17.3478 (18.9560)  loss_n_40: 3.8434 (4.2908)  loss_n_60: 4.7004 (5.2442)  loss_n_80: 4.3008 (4.5636)  loss_n_100: 4.1942 (4.5270)  triple_100: 0.0000 (0.0727)  triple_80: 0.0000 (0.0509)  triple_60: 0.0000 (0.1340)  triple_40: 0.0000 (0.0727)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 590/1724]  eta: 1:14:05  lr: 0.000080  loss: 17.3478 (18.9235)  loss_n_40: 3.9072 (4.2850)  loss_n_60: 4.8103 (5.2359)  loss_n_80: 4.3300 (4.5563)  loss_n_100: 4.4372 (4.5203)  triple_100: 0.0000 (0.0715)  triple_80: 0.0000 (0.0511)  triple_60: 0.0000 (0.1317)  triple_40: 0.0000 (0.0716)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 600/1724]  eta: 1:13:26  lr: 0.000080  loss: 16.8171 (18.8901)  loss_n_40: 3.9071 (4.2799)  loss_n_60: 4.8188 (5.2292)  loss_n_80: 4.1840 (4.5491)  loss_n_100: 4.0839 (4.5108)  triple_100: 0.0000 (0.0709)  triple_80: 0.0000 (0.0502)  triple_60: 0.0000 (0.1295)  triple_40: 0.0000 (0.0704)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 610/1724]  eta: 1:12:46  lr: 0.000080  loss: 16.4997 (18.8525)  loss_n_40: 3.9182 (4.2734)  loss_n_60: 4.8811 (5.2212)  loss_n_80: 4.0367 (4.5413)  loss_n_100: 3.8621 (4.5005)  triple_100: 0.0000 (0.0698)  triple_80: 0.0000 (0.0494)  triple_60: 0.0000 (0.1275)  triple_40: 0.0000 (0.0693)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 620/1724]  eta: 1:12:07  lr: 0.000080  loss: 16.4342 (18.8180)  loss_n_40: 3.8151 (4.2655)  loss_n_60: 4.6745 (5.2124)  loss_n_80: 4.1403 (4.5334)  loss_n_100: 3.8621 (4.4883)  triple_100: 0.0000 (0.0687)  triple_80: 0.0000 (0.0486)  triple_60: 0.0000 (0.1302)  triple_40: 0.0000 (0.0708)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 630/1724]  eta: 1:11:28  lr: 0.000080  loss: 16.0381 (18.7730)  loss_n_40: 3.7521 (4.2574)  loss_n_60: 4.6518 (5.2035)  loss_n_80: 4.0018 (4.5239)  loss_n_100: 3.7272 (4.4748)  triple_100: 0.0000 (0.0676)  triple_80: 0.0000 (0.0478)  triple_60: 0.0000 (0.1282)  triple_40: 0.0000 (0.0697)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 640/1724]  eta: 1:10:49  lr: 0.000080  loss: 16.5429 (18.7395)  loss_n_40: 3.7817 (4.2521)  loss_n_60: 4.6733 (5.1964)  loss_n_80: 4.0018 (4.5169)  loss_n_100: 3.8274 (4.4644)  triple_100: 0.0000 (0.0670)  triple_80: 0.0000 (0.0479)  triple_60: 0.0000 (0.1262)  triple_40: 0.0000 (0.0686)  time: 3.9210  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [ 650/1724]  eta: 1:10:10  lr: 0.000080  loss: 16.5429 (18.7085)  loss_n_40: 3.7498 (4.2434)  loss_n_60: 4.6911 (5.1868)  loss_n_80: 4.1413 (4.5093)  loss_n_100: 3.8818 (4.4525)  triple_100: 0.0000 (0.0695)  triple_80: 0.0000 (0.0519)  triple_60: 0.0000 (0.1268)  triple_40: 0.0000 (0.0683)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 660/1724]  eta: 1:09:30  lr: 0.000080  loss: 16.5182 (18.6814)  loss_n_40: 3.7498 (4.2375)  loss_n_60: 4.6911 (5.1800)  loss_n_80: 4.0289 (4.5019)  loss_n_100: 3.9099 (4.4446)  triple_100: 0.0000 (0.0719)  triple_80: 0.0000 (0.0512)  triple_60: 0.0000 (0.1252)  triple_40: 0.0000 (0.0690)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 670/1724]  eta: 1:08:51  lr: 0.000080  loss: 16.3993 (18.6460)  loss_n_40: 3.7792 (4.2310)  loss_n_60: 4.6909 (5.1734)  loss_n_80: 3.9469 (4.4913)  loss_n_100: 3.7676 (4.4332)  triple_100: 0.0000 (0.0720)  triple_80: 0.0000 (0.0504)  triple_60: 0.0000 (0.1267)  triple_40: 0.0000 (0.0681)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 680/1724]  eta: 1:08:12  lr: 0.000080  loss: 15.5861 (18.6002)  loss_n_40: 3.6811 (4.2225)  loss_n_60: 4.6289 (5.1649)  loss_n_80: 3.7707 (4.4808)  loss_n_100: 3.5502 (4.4196)  triple_100: 0.0000 (0.0709)  triple_80: 0.0000 (0.0496)  triple_60: 0.0000 (0.1248)  triple_40: 0.0000 (0.0671)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 690/1724]  eta: 1:07:33  lr: 0.000080  loss: 15.5861 (18.5587)  loss_n_40: 3.6442 (4.2146)  loss_n_60: 4.6289 (5.1566)  loss_n_80: 3.7872 (4.4709)  loss_n_100: 3.4346 (4.4074)  triple_100: 0.0000 (0.0699)  triple_80: 0.0000 (0.0492)  triple_60: 0.0000 (0.1230)  triple_40: 0.0000 (0.0671)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 700/1724]  eta: 1:06:54  lr: 0.000080  loss: 15.1454 (18.5197)  loss_n_40: 3.5505 (4.2065)  loss_n_60: 4.4138 (5.1475)  loss_n_80: 3.6573 (4.4615)  loss_n_100: 3.4362 (4.3963)  triple_100: 0.0000 (0.0697)  triple_80: 0.0000 (0.0488)  triple_60: 0.0000 (0.1224)  triple_40: 0.0000 (0.0668)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 710/1724]  eta: 1:06:14  lr: 0.000080  loss: 15.1728 (18.4761)  loss_n_40: 3.5370 (4.1976)  loss_n_60: 4.4026 (5.1391)  loss_n_80: 3.7178 (4.4518)  loss_n_100: 3.4362 (4.3839)  triple_100: 0.0000 (0.0687)  triple_80: 0.0000 (0.0481)  triple_60: 0.0000 (0.1209)  triple_40: 0.0000 (0.0659)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 720/1724]  eta: 1:05:35  lr: 0.000080  loss: 15.1728 (18.4301)  loss_n_40: 3.5370 (4.1887)  loss_n_60: 4.4367 (5.1304)  loss_n_80: 3.6855 (4.4401)  loss_n_100: 3.3535 (4.3700)  triple_100: 0.0000 (0.0679)  triple_80: 0.0000 (0.0476)  triple_60: 0.0000 (0.1205)  triple_40: 0.0000 (0.0649)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 730/1724]  eta: 1:04:56  lr: 0.000080  loss: 15.3199 (18.3875)  loss_n_40: 3.5789 (4.1808)  loss_n_60: 4.5461 (5.1215)  loss_n_80: 3.6766 (4.4298)  loss_n_100: 3.3350 (4.3561)  triple_100: 0.0000 (0.0669)  triple_80: 0.0000 (0.0486)  triple_60: 0.0000 (0.1197)  triple_40: 0.0000 (0.0641)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 740/1724]  eta: 1:04:17  lr: 0.000080  loss: 15.0998 (18.3485)  loss_n_40: 3.5789 (4.1733)  loss_n_60: 4.3951 (5.1123)  loss_n_80: 3.6690 (4.4192)  loss_n_100: 3.3350 (4.3433)  triple_100: 0.0000 (0.0660)  triple_80: 0.0000 (0.0479)  triple_60: 0.0000 (0.1209)  triple_40: 0.0000 (0.0656)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 750/1724]  eta: 1:03:38  lr: 0.000080  loss: 15.0777 (18.3104)  loss_n_40: 3.5420 (4.1654)  loss_n_60: 4.3948 (5.1028)  loss_n_80: 3.6092 (4.4087)  loss_n_100: 3.3926 (4.3324)  triple_100: 0.0000 (0.0691)  triple_80: 0.0000 (0.0476)  triple_60: 0.0000 (0.1193)  triple_40: 0.0000 (0.0651)  time: 3.9212  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 760/1724]  eta: 1:02:58  lr: 0.000080  loss: 15.0517 (18.2705)  loss_n_40: 3.4992 (4.1574)  loss_n_60: 4.3340 (5.0926)  loss_n_80: 3.6283 (4.3994)  loss_n_100: 3.4472 (4.3214)  triple_100: 0.0000 (0.0704)  triple_80: 0.0000 (0.0470)  triple_60: 0.0000 (0.1178)  triple_40: 0.0000 (0.0646)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 770/1724]  eta: 1:02:19  lr: 0.000080  loss: 15.0517 (18.2352)  loss_n_40: 3.4992 (4.1517)  loss_n_60: 4.3038 (5.0840)  loss_n_80: 3.6748 (4.3909)  loss_n_100: 3.5513 (4.3106)  triple_100: 0.0000 (0.0704)  triple_80: 0.0000 (0.0463)  triple_60: 0.0000 (0.1173)  triple_40: 0.0000 (0.0639)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 780/1724]  eta: 1:01:40  lr: 0.000080  loss: 14.4519 (18.1924)  loss_n_40: 3.4740 (4.1439)  loss_n_60: 4.3109 (5.0745)  loss_n_80: 3.5396 (4.3808)  loss_n_100: 3.1549 (4.2986)  triple_100: 0.0000 (0.0695)  triple_80: 0.0000 (0.0462)  triple_60: 0.0000 (0.1158)  triple_40: 0.0000 (0.0631)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 790/1724]  eta: 1:01:01  lr: 0.000080  loss: 14.3195 (18.1485)  loss_n_40: 3.4386 (4.1359)  loss_n_60: 4.2837 (5.0643)  loss_n_80: 3.5273 (4.3700)  loss_n_100: 3.0919 (4.2852)  triple_100: 0.0000 (0.0694)  triple_80: 0.0000 (0.0456)  triple_60: 0.0000 (0.1151)  triple_40: 0.0000 (0.0629)  time: 3.9214  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 800/1724]  eta: 1:00:22  lr: 0.000080  loss: 14.4896 (18.1022)  loss_n_40: 3.3797 (4.1270)  loss_n_60: 4.1821 (5.0525)  loss_n_80: 3.5127 (4.3591)  loss_n_100: 3.2460 (4.2722)  triple_100: 0.0000 (0.0694)  triple_80: 0.0000 (0.0456)  triple_60: 0.0000 (0.1142)  triple_40: 0.0000 (0.0622)  time: 3.9218  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 810/1724]  eta: 0:59:43  lr: 0.000080  loss: 14.4896 (18.0579)  loss_n_40: 3.3230 (4.1187)  loss_n_60: 4.0548 (5.0424)  loss_n_80: 3.5027 (4.3485)  loss_n_100: 3.2213 (4.2594)  triple_100: 0.0000 (0.0686)  triple_80: 0.0000 (0.0451)  triple_60: 0.0000 (0.1138)  triple_40: 0.0000 (0.0614)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 820/1724]  eta: 0:59:03  lr: 0.000080  loss: 14.3708 (18.0141)  loss_n_40: 3.3495 (4.1106)  loss_n_60: 4.2324 (5.0323)  loss_n_80: 3.5027 (4.3382)  loss_n_100: 3.2213 (4.2477)  triple_100: 0.0000 (0.0677)  triple_80: 0.0000 (0.0445)  triple_60: 0.0000 (0.1124)  triple_40: 0.0000 (0.0607)  time: 3.9222  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:5]  [ 830/1724]  eta: 0:58:24  lr: 0.000080  loss: 14.8772 (17.9789)  loss_n_40: 3.4571 (4.1040)  loss_n_60: 4.1673 (5.0230)  loss_n_80: 3.5306 (4.3287)  loss_n_100: 3.4379 (4.2392)  triple_100: 0.0000 (0.0682)  triple_80: 0.0000 (0.0444)  triple_60: 0.0000 (0.1113)  triple_40: 0.0000 (0.0600)  time: 3.9221  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:5]  [ 840/1724]  eta: 0:57:45  lr: 0.000080  loss: 15.1236 (17.9496)  loss_n_40: 3.4667 (4.0986)  loss_n_60: 4.2636 (5.0151)  loss_n_80: 3.6675 (4.3215)  loss_n_100: 3.4490 (4.2315)  triple_100: 0.0000 (0.0685)  triple_80: 0.0000 (0.0439)  triple_60: 0.0000 (0.1100)  triple_40: 0.0000 (0.0606)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 850/1724]  eta: 0:57:06  lr: 0.000080  loss: 15.1077 (17.9084)  loss_n_40: 3.5150 (4.0906)  loss_n_60: 4.2507 (5.0047)  loss_n_80: 3.6794 (4.3119)  loss_n_100: 3.4102 (4.2212)  triple_100: 0.0000 (0.0679)  triple_80: 0.0000 (0.0434)  triple_60: 0.0000 (0.1087)  triple_40: 0.0000 (0.0601)  time: 3.9224  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:5]  [ 860/1724]  eta: 0:56:27  lr: 0.000080  loss: 14.2954 (17.8627)  loss_n_40: 3.3160 (4.0811)  loss_n_60: 4.0780 (4.9941)  loss_n_80: 3.4665 (4.3016)  loss_n_100: 3.3064 (4.2085)  triple_100: 0.0000 (0.0671)  triple_80: 0.0000 (0.0435)  triple_60: 0.0000 (0.1075)  triple_40: 0.0000 (0.0594)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 870/1724]  eta: 0:55:47  lr: 0.000080  loss: 13.9127 (17.8227)  loss_n_40: 3.2467 (4.0725)  loss_n_60: 4.0627 (4.9836)  loss_n_80: 3.4359 (4.2921)  loss_n_100: 3.2195 (4.1989)  triple_100: 0.0000 (0.0676)  triple_80: 0.0000 (0.0430)  triple_60: 0.0000 (0.1062)  triple_40: 0.0000 (0.0587)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 880/1724]  eta: 0:55:08  lr: 0.000080  loss: 13.8209 (17.7768)  loss_n_40: 3.1638 (4.0629)  loss_n_60: 4.0177 (4.9722)  loss_n_80: 3.3651 (4.2811)  loss_n_100: 3.1565 (4.1858)  triple_100: 0.0000 (0.0669)  triple_80: 0.0000 (0.0425)  triple_60: 0.0000 (0.1073)  triple_40: 0.0000 (0.0581)  time: 3.9216  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [ 890/1724]  eta: 0:54:29  lr: 0.000080  loss: 13.7669 (17.7364)  loss_n_40: 3.1531 (4.0551)  loss_n_60: 3.9792 (4.9621)  loss_n_80: 3.3906 (4.2716)  loss_n_100: 3.1491 (4.1745)  triple_100: 0.0000 (0.0661)  triple_80: 0.0000 (0.0420)  triple_60: 0.0000 (0.1069)  triple_40: 0.0000 (0.0580)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 900/1724]  eta: 0:53:50  lr: 0.000080  loss: 13.2914 (17.6892)  loss_n_40: 3.1620 (4.0464)  loss_n_60: 3.8772 (4.9503)  loss_n_80: 3.2577 (4.2599)  loss_n_100: 2.8897 (4.1616)  triple_100: 0.0000 (0.0664)  triple_80: 0.0000 (0.0416)  triple_60: 0.0000 (0.1057)  triple_40: 0.0000 (0.0573)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 910/1724]  eta: 0:53:11  lr: 0.000080  loss: 13.2361 (17.6437)  loss_n_40: 3.1620 (4.0376)  loss_n_60: 3.8772 (4.9391)  loss_n_80: 3.1995 (4.2487)  loss_n_100: 2.8402 (4.1491)  triple_100: 0.0000 (0.0663)  triple_80: 0.0000 (0.0413)  triple_60: 0.0000 (0.1046)  triple_40: 0.0000 (0.0570)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 920/1724]  eta: 0:52:32  lr: 0.000080  loss: 13.5179 (17.6106)  loss_n_40: 3.1715 (4.0305)  loss_n_60: 3.8622 (4.9294)  loss_n_80: 3.3012 (4.2401)  loss_n_100: 3.1161 (4.1403)  triple_100: 0.0000 (0.0667)  triple_80: 0.0000 (0.0417)  triple_60: 0.0000 (0.1039)  triple_40: 0.0000 (0.0580)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 930/1724]  eta: 0:51:52  lr: 0.000080  loss: 14.1463 (17.5682)  loss_n_40: 3.2370 (4.0211)  loss_n_60: 3.9018 (4.9175)  loss_n_80: 3.3505 (4.2307)  loss_n_100: 3.2152 (4.1302)  triple_100: 0.0000 (0.0666)  triple_80: 0.0000 (0.0412)  triple_60: 0.0000 (0.1028)  triple_40: 0.0000 (0.0580)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 940/1724]  eta: 0:51:13  lr: 0.000080  loss: 13.2839 (17.5225)  loss_n_40: 3.0657 (4.0112)  loss_n_60: 3.8255 (4.9059)  loss_n_80: 3.3505 (4.2203)  loss_n_100: 2.9840 (4.1183)  triple_100: 0.0000 (0.0659)  triple_80: 0.0000 (0.0408)  triple_60: 0.0000 (0.1019)  triple_40: 0.0000 (0.0580)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 950/1724]  eta: 0:50:34  lr: 0.000080  loss: 13.4497 (17.4865)  loss_n_40: 3.1096 (4.0046)  loss_n_60: 3.8681 (4.8966)  loss_n_80: 3.2932 (4.2119)  loss_n_100: 3.0038 (4.1093)  triple_100: 0.0000 (0.0656)  triple_80: 0.0000 (0.0404)  triple_60: 0.0000 (0.1008)  triple_40: 0.0000 (0.0575)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 960/1724]  eta: 0:49:55  lr: 0.000080  loss: 13.5640 (17.4498)  loss_n_40: 3.2681 (3.9957)  loss_n_60: 3.9472 (4.8863)  loss_n_80: 3.2872 (4.2021)  loss_n_100: 3.1457 (4.1009)  triple_100: 0.0000 (0.0651)  triple_80: 0.0000 (0.0418)  triple_60: 0.0000 (0.1007)  triple_40: 0.0000 (0.0573)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 970/1724]  eta: 0:49:16  lr: 0.000080  loss: 14.0386 (17.4190)  loss_n_40: 3.2635 (3.9889)  loss_n_60: 3.9666 (4.8776)  loss_n_80: 3.2795 (4.1946)  loss_n_100: 3.2765 (4.0950)  triple_100: 0.0000 (0.0644)  triple_80: 0.0000 (0.0413)  triple_60: 0.0000 (0.0997)  triple_40: 0.0000 (0.0576)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 980/1724]  eta: 0:48:36  lr: 0.000080  loss: 14.3335 (17.3895)  loss_n_40: 3.3089 (3.9823)  loss_n_60: 3.9808 (4.8686)  loss_n_80: 3.4210 (4.1870)  loss_n_100: 3.4783 (4.0885)  triple_100: 0.0000 (0.0655)  triple_80: 0.0000 (0.0409)  triple_60: 0.0000 (0.0997)  triple_40: 0.0000 (0.0570)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [ 990/1724]  eta: 0:47:57  lr: 0.000080  loss: 14.0150 (17.3495)  loss_n_40: 3.1715 (3.9737)  loss_n_60: 3.8996 (4.8579)  loss_n_80: 3.3684 (4.1779)  loss_n_100: 3.2944 (4.0788)  triple_100: 0.0000 (0.0649)  triple_80: 0.0000 (0.0405)  triple_60: 0.0000 (0.0987)  triple_40: 0.0000 (0.0573)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1000/1724]  eta: 0:47:18  lr: 0.000080  loss: 13.8511 (17.3217)  loss_n_40: 3.2310 (3.9674)  loss_n_60: 3.9609 (4.8496)  loss_n_80: 3.3603 (4.1703)  loss_n_100: 3.1441 (4.0702)  triple_100: 0.0000 (0.0642)  triple_80: 0.0000 (0.0404)  triple_60: 0.0000 (0.1017)  triple_40: 0.0000 (0.0580)  time: 3.9213  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1010/1724]  eta: 0:46:39  lr: 0.000080  loss: 13.0566 (17.2762)  loss_n_40: 3.1211 (3.9584)  loss_n_60: 3.7558 (4.8382)  loss_n_80: 3.1697 (4.1594)  loss_n_100: 2.8910 (4.0576)  triple_100: 0.0000 (0.0644)  triple_80: 0.0000 (0.0400)  triple_60: 0.0000 (0.1007)  triple_40: 0.0000 (0.0574)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1020/1724]  eta: 0:46:00  lr: 0.000080  loss: 12.6516 (17.2329)  loss_n_40: 3.0077 (3.9497)  loss_n_60: 3.7108 (4.8278)  loss_n_80: 3.1108 (4.1498)  loss_n_100: 2.8010 (4.0456)  triple_100: 0.0000 (0.0638)  triple_80: 0.0000 (0.0396)  triple_60: 0.0000 (0.0999)  triple_40: 0.0000 (0.0568)  time: 3.9212  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1030/1724]  eta: 0:45:20  lr: 0.000080  loss: 12.8492 (17.2006)  loss_n_40: 2.9674 (3.9419)  loss_n_60: 3.7080 (4.8178)  loss_n_80: 3.1984 (4.1415)  loss_n_100: 2.9149 (4.0365)  triple_100: 0.0000 (0.0632)  triple_80: 0.0000 (0.0392)  triple_60: 0.0000 (0.1036)  triple_40: 0.0000 (0.0570)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1040/1724]  eta: 0:44:41  lr: 0.000080  loss: 13.1554 (17.1694)  loss_n_40: 3.0734 (3.9352)  loss_n_60: 3.7080 (4.8082)  loss_n_80: 3.2066 (4.1340)  loss_n_100: 3.0793 (4.0311)  triple_100: 0.0000 (0.0627)  triple_80: 0.0000 (0.0392)  triple_60: 0.0000 (0.1026)  triple_40: 0.0000 (0.0564)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1050/1724]  eta: 0:44:02  lr: 0.000080  loss: 13.9335 (17.1418)  loss_n_40: 3.1624 (3.9279)  loss_n_60: 3.8694 (4.7999)  loss_n_80: 3.3875 (4.1276)  loss_n_100: 3.3348 (4.0235)  triple_100: 0.0000 (0.0645)  triple_80: 0.0000 (0.0409)  triple_60: 0.0000 (0.1016)  triple_40: 0.0000 (0.0559)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1060/1724]  eta: 0:43:23  lr: 0.000080  loss: 13.6510 (17.1103)  loss_n_40: 3.1795 (3.9213)  loss_n_60: 3.9487 (4.7920)  loss_n_80: 3.3832 (4.1208)  loss_n_100: 3.1361 (4.0154)  triple_100: 0.0000 (0.0643)  triple_80: 0.0000 (0.0405)  triple_60: 0.0000 (0.1007)  triple_40: 0.0000 (0.0553)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1070/1724]  eta: 0:42:43  lr: 0.000080  loss: 13.0997 (17.0671)  loss_n_40: 3.1445 (3.9125)  loss_n_60: 3.7244 (4.7807)  loss_n_80: 3.1495 (4.1105)  loss_n_100: 2.9216 (4.0040)  triple_100: 0.0000 (0.0637)  triple_80: 0.0000 (0.0401)  triple_60: 0.0000 (0.0997)  triple_40: 0.0000 (0.0560)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1080/1724]  eta: 0:42:04  lr: 0.000080  loss: 12.6233 (17.0324)  loss_n_40: 2.9713 (3.9045)  loss_n_60: 3.6234 (4.7710)  loss_n_80: 2.9729 (4.1010)  loss_n_100: 2.7356 (3.9931)  triple_100: 0.0000 (0.0634)  triple_80: 0.0000 (0.0398)  triple_60: 0.0000 (0.1033)  triple_40: 0.0000 (0.0563)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1090/1724]  eta: 0:41:25  lr: 0.000080  loss: 12.7502 (16.9947)  loss_n_40: 2.9635 (3.8954)  loss_n_60: 3.6097 (4.7598)  loss_n_80: 3.0622 (4.0917)  loss_n_100: 2.8664 (3.9849)  triple_100: 0.0000 (0.0643)  triple_80: 0.0000 (0.0394)  triple_60: 0.0000 (0.1033)  triple_40: 0.0000 (0.0558)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1100/1724]  eta: 0:40:46  lr: 0.000080  loss: 12.2912 (16.9514)  loss_n_40: 2.8814 (3.8871)  loss_n_60: 3.5240 (4.7489)  loss_n_80: 3.0173 (4.0811)  loss_n_100: 2.8386 (3.9737)  triple_100: 0.0000 (0.0637)  triple_80: 0.0000 (0.0390)  triple_60: 0.0000 (0.1024)  triple_40: 0.0000 (0.0553)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1110/1724]  eta: 0:40:07  lr: 0.000080  loss: 12.2912 (16.9177)  loss_n_40: 2.9054 (3.8796)  loss_n_60: 3.5407 (4.7387)  loss_n_80: 3.0173 (4.0718)  loss_n_100: 2.7606 (3.9644)  triple_100: 0.0000 (0.0646)  triple_80: 0.0000 (0.0390)  triple_60: 0.0000 (0.1028)  triple_40: 0.0000 (0.0568)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1120/1724]  eta: 0:39:27  lr: 0.000080  loss: 12.6881 (16.8847)  loss_n_40: 2.9676 (3.8722)  loss_n_60: 3.5190 (4.7289)  loss_n_80: 3.0366 (4.0629)  loss_n_100: 2.9524 (3.9565)  triple_100: 0.0000 (0.0659)  triple_80: 0.0000 (0.0402)  triple_60: 0.0000 (0.1018)  triple_40: 0.0000 (0.0563)  time: 3.9196  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [1130/1724]  eta: 0:38:48  lr: 0.000080  loss: 13.0317 (16.8585)  loss_n_40: 3.0728 (3.8664)  loss_n_60: 3.6682 (4.7206)  loss_n_80: 3.0547 (4.0559)  loss_n_100: 3.1496 (3.9519)  triple_100: 0.0000 (0.0656)  triple_80: 0.0000 (0.0413)  triple_60: 0.0000 (0.1009)  triple_40: 0.0000 (0.0558)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1140/1724]  eta: 0:38:09  lr: 0.000080  loss: 12.9060 (16.8203)  loss_n_40: 3.0728 (3.8586)  loss_n_60: 3.6682 (4.7107)  loss_n_80: 3.0752 (4.0466)  loss_n_100: 3.1217 (3.9426)  triple_100: 0.0000 (0.0654)  triple_80: 0.0000 (0.0410)  triple_60: 0.0000 (0.1001)  triple_40: 0.0000 (0.0553)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1150/1724]  eta: 0:37:30  lr: 0.000080  loss: 11.7742 (16.7731)  loss_n_40: 2.8446 (3.8490)  loss_n_60: 3.4603 (4.6989)  loss_n_80: 2.8117 (4.0347)  loss_n_100: 2.5894 (3.9300)  triple_100: 0.0000 (0.0654)  triple_80: 0.0000 (0.0406)  triple_60: 0.0000 (0.0992)  triple_40: 0.0000 (0.0552)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1160/1724]  eta: 0:36:51  lr: 0.000080  loss: 11.9227 (16.7408)  loss_n_40: 2.8573 (3.8421)  loss_n_60: 3.4270 (4.6893)  loss_n_80: 2.8117 (4.0257)  loss_n_100: 2.4434 (3.9210)  triple_100: 0.0000 (0.0669)  triple_80: 0.0000 (0.0413)  triple_60: 0.0000 (0.0998)  triple_40: 0.0000 (0.0547)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1170/1724]  eta: 0:36:11  lr: 0.000080  loss: 12.3703 (16.7011)  loss_n_40: 2.9436 (3.8338)  loss_n_60: 3.5063 (4.6786)  loss_n_80: 2.9836 (4.0162)  loss_n_100: 2.8097 (3.9113)  triple_100: 0.0000 (0.0664)  triple_80: 0.0000 (0.0417)  triple_60: 0.0000 (0.0989)  triple_40: 0.0000 (0.0542)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1180/1724]  eta: 0:35:32  lr: 0.000080  loss: 12.0768 (16.6645)  loss_n_40: 2.8147 (3.8257)  loss_n_60: 3.3728 (4.6679)  loss_n_80: 2.8549 (4.0070)  loss_n_100: 2.9060 (3.9026)  triple_100: 0.0000 (0.0658)  triple_80: 0.0000 (0.0413)  triple_60: 0.0000 (0.0994)  triple_40: 0.0000 (0.0549)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1190/1724]  eta: 0:34:53  lr: 0.000080  loss: 11.7093 (16.6267)  loss_n_40: 2.8147 (3.8183)  loss_n_60: 3.3717 (4.6578)  loss_n_80: 2.8443 (3.9979)  loss_n_100: 2.7788 (3.8935)  triple_100: 0.0000 (0.0652)  triple_80: 0.0000 (0.0410)  triple_60: 0.0000 (0.0986)  triple_40: 0.0000 (0.0544)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1200/1724]  eta: 0:34:14  lr: 0.000080  loss: 11.6431 (16.5846)  loss_n_40: 2.7370 (3.8091)  loss_n_60: 3.3034 (4.6461)  loss_n_80: 2.7870 (3.9874)  loss_n_100: 2.6360 (3.8821)  triple_100: 0.0000 (0.0676)  triple_80: 0.0000 (0.0406)  triple_60: 0.0000 (0.0978)  triple_40: 0.0000 (0.0540)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1210/1724]  eta: 0:33:35  lr: 0.000080  loss: 11.2909 (16.5466)  loss_n_40: 2.6872 (3.8009)  loss_n_60: 3.2341 (4.6355)  loss_n_80: 2.7285 (3.9777)  loss_n_100: 2.4378 (3.8709)  triple_100: 0.0000 (0.0675)  triple_80: 0.0000 (0.0406)  triple_60: 0.0000 (0.0999)  triple_40: 0.0000 (0.0535)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1220/1724]  eta: 0:32:55  lr: 0.000080  loss: 11.4061 (16.5089)  loss_n_40: 2.6959 (3.7935)  loss_n_60: 3.2567 (4.6249)  loss_n_80: 2.9101 (3.9687)  loss_n_100: 2.6127 (3.8615)  triple_100: 0.0000 (0.0670)  triple_80: 0.0000 (0.0410)  triple_60: 0.0000 (0.0991)  triple_40: 0.0000 (0.0531)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1230/1724]  eta: 0:32:16  lr: 0.000080  loss: 11.5868 (16.4712)  loss_n_40: 2.8709 (3.7856)  loss_n_60: 3.3124 (4.6139)  loss_n_80: 2.8925 (3.9593)  loss_n_100: 2.6650 (3.8517)  triple_100: 0.0000 (0.0664)  triple_80: 0.0000 (0.0407)  triple_60: 0.0000 (0.0999)  triple_40: 0.0000 (0.0536)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1240/1724]  eta: 0:31:37  lr: 0.000080  loss: 11.2390 (16.4297)  loss_n_40: 2.6846 (3.7772)  loss_n_60: 3.1414 (4.6026)  loss_n_80: 2.7182 (3.9490)  loss_n_100: 2.4960 (3.8413)  triple_100: 0.0000 (0.0667)  triple_80: 0.0000 (0.0406)  triple_60: 0.0000 (0.0991)  triple_40: 0.0000 (0.0532)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1250/1724]  eta: 0:30:58  lr: 0.000080  loss: 10.6316 (16.3896)  loss_n_40: 2.5156 (3.7678)  loss_n_60: 3.0567 (4.5906)  loss_n_80: 2.5781 (3.9377)  loss_n_100: 2.3266 (3.8298)  triple_100: 0.0000 (0.0670)  triple_80: 0.0000 (0.0405)  triple_60: 0.0000 (0.1016)  triple_40: 0.0000 (0.0547)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1260/1724]  eta: 0:30:19  lr: 0.000080  loss: 11.0346 (16.3576)  loss_n_40: 2.5221 (3.7601)  loss_n_60: 3.0805 (4.5801)  loss_n_80: 2.7151 (3.9292)  loss_n_100: 2.6960 (3.8236)  triple_100: 0.0000 (0.0676)  triple_80: 0.0000 (0.0419)  triple_60: 0.0000 (0.1008)  triple_40: 0.0000 (0.0543)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1270/1724]  eta: 0:29:39  lr: 0.000080  loss: 11.6390 (16.3216)  loss_n_40: 2.6755 (3.7531)  loss_n_60: 3.2382 (4.5706)  loss_n_80: 2.8125 (3.9201)  loss_n_100: 2.8149 (3.8152)  triple_100: 0.0000 (0.0670)  triple_80: 0.0000 (0.0416)  triple_60: 0.0000 (0.1000)  triple_40: 0.0000 (0.0540)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1280/1724]  eta: 0:29:00  lr: 0.000080  loss: 11.2598 (16.2857)  loss_n_40: 2.6561 (3.7459)  loss_n_60: 3.2024 (4.5608)  loss_n_80: 2.6072 (3.9108)  loss_n_100: 2.6718 (3.8065)  triple_100: 0.0000 (0.0670)  triple_80: 0.0000 (0.0417)  triple_60: 0.0000 (0.0995)  triple_40: 0.0000 (0.0536)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1290/1724]  eta: 0:28:21  lr: 0.000080  loss: 10.4360 (16.2441)  loss_n_40: 2.5954 (3.7374)  loss_n_60: 3.1394 (4.5496)  loss_n_80: 2.4734 (3.9006)  loss_n_100: 2.3126 (3.7966)  triple_100: 0.0000 (0.0664)  triple_80: 0.0000 (0.0414)  triple_60: 0.0000 (0.0989)  triple_40: 0.0000 (0.0531)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1300/1724]  eta: 0:27:42  lr: 0.000080  loss: 10.4697 (16.2080)  loss_n_40: 2.5303 (3.7298)  loss_n_60: 3.0935 (4.5392)  loss_n_80: 2.5074 (3.8916)  loss_n_100: 2.3835 (3.7876)  triple_100: 0.0000 (0.0664)  triple_80: 0.0000 (0.0424)  triple_60: 0.0000 (0.0981)  triple_40: 0.0000 (0.0529)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1310/1724]  eta: 0:27:02  lr: 0.000080  loss: 11.3624 (16.1741)  loss_n_40: 2.6548 (3.7216)  loss_n_60: 3.1810 (4.5287)  loss_n_80: 2.5949 (3.8811)  loss_n_100: 2.6314 (3.7776)  triple_100: 0.0000 (0.0662)  triple_80: 0.0000 (0.0421)  triple_60: 0.0000 (0.1032)  triple_40: 0.0000 (0.0536)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1320/1724]  eta: 0:26:23  lr: 0.000080  loss: 11.3705 (16.1398)  loss_n_40: 2.6922 (3.7150)  loss_n_60: 3.1804 (4.5195)  loss_n_80: 2.4918 (3.8717)  loss_n_100: 2.3893 (3.7689)  triple_100: 0.0000 (0.0657)  triple_80: 0.0000 (0.0433)  triple_60: 0.0000 (0.1024)  triple_40: 0.0000 (0.0532)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1330/1724]  eta: 0:25:44  lr: 0.000080  loss: 10.8656 (16.0999)  loss_n_40: 2.6497 (3.7064)  loss_n_60: 3.1047 (4.5082)  loss_n_80: 2.4517 (3.8617)  loss_n_100: 2.4163 (3.7595)  triple_100: 0.0000 (0.0667)  triple_80: 0.0000 (0.0430)  triple_60: 0.0000 (0.1017)  triple_40: 0.0000 (0.0528)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1340/1724]  eta: 0:25:05  lr: 0.000080  loss: 10.8111 (16.0641)  loss_n_40: 2.5456 (3.6985)  loss_n_60: 3.0033 (4.4980)  loss_n_80: 2.4981 (3.8530)  loss_n_100: 2.5082 (3.7516)  triple_100: 0.0000 (0.0662)  triple_80: 0.0000 (0.0429)  triple_60: 0.0000 (0.1014)  triple_40: 0.0000 (0.0525)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1350/1724]  eta: 0:24:26  lr: 0.000080  loss: 10.6938 (16.0313)  loss_n_40: 2.4887 (3.6907)  loss_n_60: 2.9844 (4.4877)  loss_n_80: 2.5511 (3.8433)  loss_n_100: 2.5082 (3.7420)  triple_100: 0.0000 (0.0657)  triple_80: 0.0000 (0.0436)  triple_60: 0.0000 (0.1036)  triple_40: 0.0000 (0.0545)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1360/1724]  eta: 0:23:46  lr: 0.000080  loss: 10.7519 (16.0003)  loss_n_40: 2.5442 (3.6836)  loss_n_60: 3.0182 (4.4782)  loss_n_80: 2.6269 (3.8360)  loss_n_100: 2.5348 (3.7355)  triple_100: 0.0000 (0.0662)  triple_80: 0.0000 (0.0434)  triple_60: 0.0000 (0.1031)  triple_40: 0.0000 (0.0541)  time: 3.9200  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [1370/1724]  eta: 0:23:07  lr: 0.000080  loss: 10.7519 (15.9614)  loss_n_40: 2.5442 (3.6751)  loss_n_60: 3.0182 (4.4667)  loss_n_80: 2.5826 (3.8264)  loss_n_100: 2.5023 (3.7262)  triple_100: 0.0000 (0.0669)  triple_80: 0.0000 (0.0431)  triple_60: 0.0000 (0.1035)  triple_40: 0.0000 (0.0537)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1380/1724]  eta: 0:22:28  lr: 0.000080  loss: 10.6568 (15.9288)  loss_n_40: 2.5933 (3.6680)  loss_n_60: 2.9142 (4.4562)  loss_n_80: 2.5531 (3.8186)  loss_n_100: 2.4494 (3.7178)  triple_100: 0.0000 (0.0673)  triple_80: 0.0000 (0.0438)  triple_60: 0.0000 (0.1027)  triple_40: 0.0000 (0.0543)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1390/1724]  eta: 0:21:49  lr: 0.000080  loss: 10.8446 (15.8948)  loss_n_40: 2.5933 (3.6609)  loss_n_60: 2.9792 (4.4465)  loss_n_80: 2.6320 (3.8105)  loss_n_100: 2.4732 (3.7094)  triple_100: 0.0000 (0.0676)  triple_80: 0.0000 (0.0436)  triple_60: 0.0000 (0.1021)  triple_40: 0.0000 (0.0542)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1400/1724]  eta: 0:21:10  lr: 0.000080  loss: 10.6950 (15.8573)  loss_n_40: 2.4594 (3.6526)  loss_n_60: 2.9792 (4.4364)  loss_n_80: 2.4846 (3.8015)  loss_n_100: 2.4326 (3.7009)  triple_100: 0.0000 (0.0671)  triple_80: 0.0000 (0.0435)  triple_60: 0.0000 (0.1014)  triple_40: 0.0000 (0.0539)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1410/1724]  eta: 0:20:30  lr: 0.000080  loss: 10.2392 (15.8169)  loss_n_40: 2.4551 (3.6440)  loss_n_60: 2.9599 (4.4254)  loss_n_80: 2.4256 (3.7914)  loss_n_100: 2.3193 (3.6912)  triple_100: 0.0000 (0.0673)  triple_80: 0.0000 (0.0432)  triple_60: 0.0000 (0.1009)  triple_40: 0.0000 (0.0535)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1420/1724]  eta: 0:19:51  lr: 0.000080  loss: 9.1506 (15.7728)  loss_n_40: 2.3168 (3.6352)  loss_n_60: 2.7033 (4.4137)  loss_n_80: 2.1651 (3.7803)  loss_n_100: 2.1159 (3.6803)  triple_100: 0.0000 (0.0670)  triple_80: 0.0000 (0.0429)  triple_60: 0.0000 (0.1002)  triple_40: 0.0000 (0.0532)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1430/1724]  eta: 0:19:12  lr: 0.000080  loss: 8.8209 (15.7294)  loss_n_40: 2.2348 (3.6261)  loss_n_60: 2.6393 (4.4021)  loss_n_80: 2.0888 (3.7699)  loss_n_100: 1.9806 (3.6694)  triple_100: 0.0000 (0.0668)  triple_80: 0.0000 (0.0426)  triple_60: 0.0000 (0.0995)  triple_40: 0.0000 (0.0529)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1440/1724]  eta: 0:18:33  lr: 0.000080  loss: 9.3935 (15.6879)  loss_n_40: 2.3388 (3.6176)  loss_n_60: 2.7357 (4.3910)  loss_n_80: 2.1901 (3.7593)  loss_n_100: 1.9916 (3.6584)  triple_100: 0.0000 (0.0673)  triple_80: 0.0000 (0.0424)  triple_60: 0.0000 (0.0991)  triple_40: 0.0000 (0.0526)  time: 3.9173  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:5]  [1450/1724]  eta: 0:17:54  lr: 0.000080  loss: 9.6793 (15.6518)  loss_n_40: 2.3922 (3.6107)  loss_n_60: 2.8592 (4.3814)  loss_n_80: 2.2728 (3.7507)  loss_n_100: 2.0845 (3.6494)  triple_100: 0.0000 (0.0669)  triple_80: 0.0000 (0.0421)  triple_60: 0.0000 (0.0985)  triple_40: 0.0000 (0.0523)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1460/1724]  eta: 0:17:14  lr: 0.000080  loss: 9.5160 (15.6098)  loss_n_40: 2.3719 (3.6022)  loss_n_60: 2.8109 (4.3699)  loss_n_80: 2.2468 (3.7405)  loss_n_100: 2.1187 (3.6392)  triple_100: 0.0000 (0.0664)  triple_80: 0.0000 (0.0420)  triple_60: 0.0000 (0.0978)  triple_40: 0.0000 (0.0519)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1470/1724]  eta: 0:16:35  lr: 0.000080  loss: 9.7453 (15.5751)  loss_n_40: 2.3719 (3.5953)  loss_n_60: 2.8001 (4.3600)  loss_n_80: 2.3447 (3.7314)  loss_n_100: 2.1976 (3.6300)  triple_100: 0.0000 (0.0660)  triple_80: 0.0000 (0.0417)  triple_60: 0.0000 (0.0990)  triple_40: 0.0000 (0.0517)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1480/1724]  eta: 0:15:56  lr: 0.000080  loss: 9.5125 (15.5319)  loss_n_40: 2.3350 (3.5867)  loss_n_60: 2.7479 (4.3486)  loss_n_80: 2.3027 (3.7209)  loss_n_100: 2.0797 (3.6189)  triple_100: 0.0000 (0.0656)  triple_80: 0.0000 (0.0415)  triple_60: 0.0000 (0.0983)  triple_40: 0.0000 (0.0514)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1490/1724]  eta: 0:15:17  lr: 0.000080  loss: 9.2338 (15.4943)  loss_n_40: 2.3350 (3.5795)  loss_n_60: 2.6646 (4.3383)  loss_n_80: 2.2426 (3.7112)  loss_n_100: 2.0525 (3.6093)  triple_100: 0.0000 (0.0652)  triple_80: 0.0000 (0.0412)  triple_60: 0.0000 (0.0977)  triple_40: 0.0000 (0.0520)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1500/1724]  eta: 0:14:38  lr: 0.000080  loss: 8.9614 (15.4521)  loss_n_40: 2.2668 (3.5709)  loss_n_60: 2.5611 (4.3267)  loss_n_80: 2.1207 (3.7007)  loss_n_100: 1.9980 (3.5989)  triple_100: 0.0000 (0.0650)  triple_80: 0.0000 (0.0410)  triple_60: 0.0000 (0.0972)  triple_40: 0.0000 (0.0516)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1510/1724]  eta: 0:13:58  lr: 0.000080  loss: 8.6175 (15.4082)  loss_n_40: 2.1513 (3.5622)  loss_n_60: 2.4800 (4.3150)  loss_n_80: 2.0312 (3.6898)  loss_n_100: 1.9099 (3.5878)  triple_100: 0.0000 (0.0648)  triple_80: 0.0000 (0.0407)  triple_60: 0.0000 (0.0965)  triple_40: 0.0000 (0.0513)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1520/1724]  eta: 0:13:19  lr: 0.000080  loss: 9.0453 (15.3756)  loss_n_40: 2.2735 (3.5548)  loss_n_60: 2.6107 (4.3049)  loss_n_80: 2.0954 (3.6803)  loss_n_100: 1.9976 (3.5788)  triple_100: 0.0000 (0.0644)  triple_80: 0.0000 (0.0406)  triple_60: 0.0000 (0.1004)  triple_40: 0.0000 (0.0514)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1530/1724]  eta: 0:12:40  lr: 0.000080  loss: 9.9847 (15.3405)  loss_n_40: 2.4546 (3.5475)  loss_n_60: 2.7439 (4.2946)  loss_n_80: 2.2322 (3.6715)  loss_n_100: 2.3297 (3.5714)  triple_100: 0.0000 (0.0640)  triple_80: 0.0000 (0.0403)  triple_60: 0.0000 (0.0997)  triple_40: 0.0000 (0.0514)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1540/1724]  eta: 0:12:01  lr: 0.000080  loss: 9.9922 (15.3072)  loss_n_40: 2.3235 (3.5408)  loss_n_60: 2.6709 (4.2850)  loss_n_80: 2.2581 (3.6627)  loss_n_100: 2.3402 (3.5636)  triple_100: 0.0000 (0.0646)  triple_80: 0.0000 (0.0401)  triple_60: 0.0000 (0.0991)  triple_40: 0.0000 (0.0515)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1550/1724]  eta: 0:11:22  lr: 0.000080  loss: 9.9922 (15.2690)  loss_n_40: 2.3235 (3.5337)  loss_n_60: 2.6562 (4.2747)  loss_n_80: 2.2362 (3.6527)  loss_n_100: 2.2877 (3.5542)  triple_100: 0.0000 (0.0641)  triple_80: 0.0000 (0.0398)  triple_60: 0.0000 (0.0984)  triple_40: 0.0000 (0.0513)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1560/1724]  eta: 0:10:42  lr: 0.000080  loss: 8.7188 (15.2295)  loss_n_40: 2.1314 (3.5254)  loss_n_60: 2.4695 (4.2635)  loss_n_80: 2.1218 (3.6426)  loss_n_100: 2.0075 (3.5443)  triple_100: 0.0000 (0.0648)  triple_80: 0.0000 (0.0400)  triple_60: 0.0000 (0.0978)  triple_40: 0.0000 (0.0509)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1570/1724]  eta: 0:10:03  lr: 0.000080  loss: 8.3341 (15.1890)  loss_n_40: 2.0993 (3.5170)  loss_n_60: 2.4124 (4.2523)  loss_n_80: 2.0572 (3.6333)  loss_n_100: 1.9637 (3.5340)  triple_100: 0.0000 (0.0644)  triple_80: 0.0000 (0.0398)  triple_60: 0.0000 (0.0972)  triple_40: 0.0000 (0.0510)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1580/1724]  eta: 0:09:24  lr: 0.000080  loss: 8.1289 (15.1459)  loss_n_40: 2.0915 (3.5078)  loss_n_60: 2.3949 (4.2403)  loss_n_80: 2.0167 (3.6231)  loss_n_100: 1.7272 (3.5227)  triple_100: 0.0000 (0.0640)  triple_80: 0.0000 (0.0397)  triple_60: 0.0000 (0.0976)  triple_40: 0.0000 (0.0507)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1590/1724]  eta: 0:08:45  lr: 0.000080  loss: 8.0994 (15.1056)  loss_n_40: 2.0164 (3.4994)  loss_n_60: 2.3323 (4.2292)  loss_n_80: 2.0021 (3.6138)  loss_n_100: 1.7272 (3.5125)  triple_100: 0.0000 (0.0636)  triple_80: 0.0000 (0.0396)  triple_60: 0.0000 (0.0971)  triple_40: 0.0000 (0.0504)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1600/1724]  eta: 0:08:06  lr: 0.000080  loss: 8.0994 (15.0698)  loss_n_40: 2.0354 (3.4914)  loss_n_60: 2.3335 (4.2186)  loss_n_80: 1.9860 (3.6044)  loss_n_100: 1.7958 (3.5025)  triple_100: 0.0000 (0.0632)  triple_80: 0.0000 (0.0393)  triple_60: 0.0000 (0.0989)  triple_40: 0.0000 (0.0515)  time: 3.9180  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [1610/1724]  eta: 0:07:26  lr: 0.000080  loss: 9.3406 (15.0408)  loss_n_40: 2.3311 (3.4857)  loss_n_60: 2.6513 (4.2097)  loss_n_80: 2.2613 (3.5968)  loss_n_100: 2.1066 (3.4952)  triple_100: 0.0000 (0.0628)  triple_80: 0.0000 (0.0391)  triple_60: 0.0000 (0.0983)  triple_40: 0.0000 (0.0532)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1620/1724]  eta: 0:06:47  lr: 0.000080  loss: 9.4722 (15.0061)  loss_n_40: 2.4196 (3.4791)  loss_n_60: 2.6513 (4.2000)  loss_n_80: 2.2613 (3.5882)  loss_n_100: 2.2121 (3.4869)  triple_100: 0.0000 (0.0625)  triple_80: 0.0000 (0.0389)  triple_60: 0.0000 (0.0977)  triple_40: 0.0000 (0.0528)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1630/1724]  eta: 0:06:08  lr: 0.000080  loss: 9.6020 (14.9781)  loss_n_40: 2.3846 (3.4744)  loss_n_60: 2.7124 (4.1918)  loss_n_80: 2.2824 (3.5806)  loss_n_100: 2.2377 (3.4802)  triple_100: 0.0000 (0.0623)  triple_80: 0.0000 (0.0386)  triple_60: 0.0000 (0.0971)  triple_40: 0.0000 (0.0530)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1640/1724]  eta: 0:05:29  lr: 0.000080  loss: 9.6020 (14.9424)  loss_n_40: 2.3138 (3.4673)  loss_n_60: 2.6284 (4.1817)  loss_n_80: 2.2672 (3.5716)  loss_n_100: 2.1997 (3.4712)  triple_100: 0.0000 (0.0619)  triple_80: 0.0000 (0.0384)  triple_60: 0.0000 (0.0976)  triple_40: 0.0000 (0.0527)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1650/1724]  eta: 0:04:50  lr: 0.000080  loss: 9.0273 (14.9084)  loss_n_40: 2.2049 (3.4602)  loss_n_60: 2.4118 (4.1716)  loss_n_80: 2.1888 (3.5630)  loss_n_100: 2.0760 (3.4629)  triple_100: 0.0000 (0.0616)  triple_80: 0.0000 (0.0384)  triple_60: 0.0000 (0.0970)  triple_40: 0.0000 (0.0536)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1660/1724]  eta: 0:04:10  lr: 0.000080  loss: 7.9199 (14.8668)  loss_n_40: 2.0142 (3.4516)  loss_n_60: 2.2790 (4.1603)  loss_n_80: 1.8884 (3.5527)  loss_n_100: 1.7575 (3.4530)  triple_100: 0.0000 (0.0613)  triple_80: 0.0000 (0.0383)  triple_60: 0.0000 (0.0964)  triple_40: 0.0000 (0.0532)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1670/1724]  eta: 0:03:31  lr: 0.000080  loss: 7.6989 (14.8297)  loss_n_40: 1.9986 (3.4441)  loss_n_60: 2.2654 (4.1502)  loss_n_80: 1.8173 (3.5434)  loss_n_100: 1.7185 (3.4439)  triple_100: 0.0000 (0.0613)  triple_80: 0.0000 (0.0381)  triple_60: 0.0000 (0.0958)  triple_40: 0.0000 (0.0529)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1680/1724]  eta: 0:02:52  lr: 0.000080  loss: 8.2760 (14.7946)  loss_n_40: 2.0662 (3.4369)  loss_n_60: 2.3826 (4.1404)  loss_n_80: 1.9845 (3.5347)  loss_n_100: 1.9139 (3.4349)  triple_100: 0.0000 (0.0610)  triple_80: 0.0000 (0.0388)  triple_60: 0.0000 (0.0953)  triple_40: 0.0000 (0.0527)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1690/1724]  eta: 0:02:13  lr: 0.000080  loss: 8.3071 (14.7610)  loss_n_40: 2.0127 (3.4299)  loss_n_60: 2.4311 (4.1314)  loss_n_80: 1.9845 (3.5262)  loss_n_100: 1.9116 (3.4261)  triple_100: 0.0000 (0.0606)  triple_80: 0.0000 (0.0385)  triple_60: 0.0000 (0.0958)  triple_40: 0.0000 (0.0525)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1700/1724]  eta: 0:01:34  lr: 0.000080  loss: 10.6741 (14.7448)  loss_n_40: 2.0709 (3.4228)  loss_n_60: 2.5873 (4.1233)  loss_n_80: 2.2888 (3.5224)  loss_n_100: 2.3645 (3.4244)  triple_100: 0.0000 (0.0636)  triple_80: 0.0000 (0.0409)  triple_60: 0.0000 (0.0953)  triple_40: 0.0000 (0.0522)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1710/1724]  eta: 0:00:54  lr: 0.000080  loss: 11.1379 (14.7210)  loss_n_40: 2.3066 (3.4173)  loss_n_60: 2.8081 (4.1165)  loss_n_80: 2.7251 (3.5174)  loss_n_100: 2.7746 (3.4192)  triple_100: 0.0000 (0.0632)  triple_80: 0.0000 (0.0407)  triple_60: 0.0000 (0.0947)  triple_40: 0.0000 (0.0520)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:5]  [1720/1724]  eta: 0:00:15  lr: 0.000080  loss: 10.2598 (14.6987)  loss_n_40: 2.3917 (3.4124)  loss_n_60: 2.8546 (4.1101)  loss_n_80: 2.4933 (3.5112)  loss_n_100: 2.1963 (3.4125)  triple_100: 0.0000 (0.0628)  triple_80: 0.0000 (0.0414)  triple_60: 0.0000 (0.0955)  triple_40: 0.0000 (0.0528)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5]  [1723/1724]  eta: 0:00:03  lr: 0.000080  loss: 9.5335 (14.6880)  loss_n_40: 2.3225 (3.4100)  loss_n_60: 2.8369 (4.1074)  loss_n_80: 2.2954 (3.5088)  loss_n_100: 2.1407 (3.4098)  triple_100: 0.0000 (0.0627)  triple_80: 0.0000 (0.0413)  triple_60: 0.0000 (0.0954)  triple_40: 0.0000 (0.0527)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:5] Total time: 1:52:38 (3.9200 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 9.5335 (14.6880)  loss_n_40: 2.3225 (3.4100)  loss_n_60: 2.8369 (4.1074)  loss_n_80: 2.2954 (3.5088)  loss_n_100: 2.1407 (3.4098)  triple_100: 0.0000 (0.0627)  triple_80: 0.0000 (0.0413)  triple_60: 0.0000 (0.0954)  triple_40: 0.0000 (0.0527)\n",
      "Valid: [epoch:5]  [  0/845]  eta: 0:09:53  loss: 8.7167 (8.7167)  loss_n_40: 1.9437 (1.9437)  loss_n_60: 2.5184 (2.5184)  loss_n_80: 2.1748 (2.1748)  loss_n_100: 2.0797 (2.0797)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7026  data: 0.3678  max mem: 46473\n",
      "Valid: [epoch:5]  [ 10/845]  eta: 0:05:06  loss: 9.7896 (12.0249)  loss_n_40: 2.1768 (2.7347)  loss_n_60: 2.6719 (3.1180)  loss_n_80: 2.3593 (2.7864)  loss_n_100: 2.3097 (2.8160)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.1871)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.3827)  time: 0.3675  data: 0.0335  max mem: 46473\n",
      "Valid: [epoch:5]  [ 20/845]  eta: 0:04:50  loss: 9.7896 (11.4804)  loss_n_40: 2.1126 (2.5382)  loss_n_60: 2.6270 (2.9804)  loss_n_80: 2.3593 (2.7554)  loss_n_100: 2.3097 (2.9080)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0980)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.2005)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [ 30/845]  eta: 0:04:41  loss: 10.3117 (11.6556)  loss_n_40: 2.2269 (2.6040)  loss_n_60: 2.7564 (3.0321)  loss_n_80: 2.4648 (2.8086)  loss_n_100: 2.6126 (3.0086)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0664)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1358)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [ 40/845]  eta: 0:04:36  loss: 10.3117 (11.2372)  loss_n_40: 2.2051 (2.4846)  loss_n_60: 2.7564 (2.9394)  loss_n_80: 2.4648 (2.7114)  loss_n_100: 2.4352 (2.9002)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0502)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1515)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [ 50/845]  eta: 0:04:31  loss: 8.4518 (10.7963)  loss_n_40: 2.0241 (2.3936)  loss_n_60: 2.5449 (2.8685)  loss_n_80: 2.1052 (2.6199)  loss_n_100: 1.9076 (2.7522)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0403)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1218)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [ 60/845]  eta: 0:04:26  loss: 9.6717 (11.0600)  loss_n_40: 2.1161 (2.4609)  loss_n_60: 2.7126 (2.9243)  loss_n_80: 2.4440 (2.6701)  loss_n_100: 2.3909 (2.8050)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0576)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1422)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [ 70/845]  eta: 0:04:22  loss: 10.5800 (11.2135)  loss_n_40: 2.3110 (2.5092)  loss_n_60: 2.8501 (2.9599)  loss_n_80: 2.4885 (2.7093)  loss_n_100: 2.4550 (2.8553)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0575)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1222)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [ 80/845]  eta: 0:04:19  loss: 9.3704 (10.9760)  loss_n_40: 2.0236 (2.4580)  loss_n_60: 2.6343 (2.9208)  loss_n_80: 2.4411 (2.6574)  loss_n_100: 2.2968 (2.7823)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0504)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1071)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [ 90/845]  eta: 0:04:15  loss: 8.6842 (10.7894)  loss_n_40: 1.9982 (2.4125)  loss_n_60: 2.5058 (2.8837)  loss_n_80: 2.0947 (2.6168)  loss_n_100: 1.8732 (2.7270)  triple_100: 0.0000 (0.0091)  triple_80: 0.0000 (0.0449)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0953)  time: 0.3340  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:5]  [100/845]  eta: 0:04:11  loss: 8.5404 (10.8871)  loss_n_40: 1.9444 (2.4398)  loss_n_60: 2.4441 (2.9033)  loss_n_80: 2.0662 (2.6321)  loss_n_100: 1.9244 (2.7423)  triple_100: 0.0000 (0.0082)  triple_80: 0.0000 (0.0754)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0859)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [110/845]  eta: 0:04:07  loss: 8.9230 (10.7741)  loss_n_40: 2.0254 (2.4107)  loss_n_60: 2.6079 (2.8823)  loss_n_80: 2.2229 (2.6037)  loss_n_100: 2.1233 (2.7042)  triple_100: 0.0000 (0.0075)  triple_80: 0.0000 (0.0686)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0971)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [120/845]  eta: 0:04:04  loss: 9.2661 (10.7114)  loss_n_40: 2.0211 (2.4035)  loss_n_60: 2.5321 (2.8769)  loss_n_80: 2.2934 (2.5903)  loss_n_100: 2.2050 (2.6819)  triple_100: 0.0000 (0.0069)  triple_80: 0.0000 (0.0630)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0891)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [130/845]  eta: 0:04:00  loss: 9.4087 (10.6743)  loss_n_40: 2.0535 (2.3914)  loss_n_60: 2.5389 (2.8690)  loss_n_80: 2.3195 (2.5859)  loss_n_100: 2.4371 (2.6812)  triple_100: 0.0000 (0.0064)  triple_80: 0.0000 (0.0582)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0823)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [140/845]  eta: 0:03:57  loss: 9.4696 (10.5802)  loss_n_40: 2.0194 (2.3709)  loss_n_60: 2.5701 (2.8523)  loss_n_80: 2.3344 (2.5668)  loss_n_100: 2.4371 (2.6539)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0540)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0764)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [150/845]  eta: 0:03:53  loss: 9.0046 (10.6139)  loss_n_40: 1.9995 (2.3716)  loss_n_60: 2.5358 (2.8524)  loss_n_80: 2.3070 (2.5617)  loss_n_100: 2.2565 (2.6385)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0588)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1254)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [160/845]  eta: 0:03:50  loss: 9.0046 (10.5735)  loss_n_40: 2.0992 (2.3665)  loss_n_60: 2.6721 (2.8493)  loss_n_80: 2.3070 (2.5554)  loss_n_100: 2.2565 (2.6243)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0552)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1176)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [170/845]  eta: 0:03:46  loss: 8.5746 (10.5112)  loss_n_40: 2.0001 (2.3597)  loss_n_60: 2.5281 (2.8400)  loss_n_80: 2.1290 (2.5411)  loss_n_100: 1.9226 (2.6028)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0519)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1108)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [180/845]  eta: 0:03:43  loss: 8.3613 (10.4971)  loss_n_40: 1.9853 (2.3614)  loss_n_60: 2.4820 (2.8384)  loss_n_80: 2.0796 (2.5398)  loss_n_100: 1.8632 (2.5992)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0491)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1046)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [190/845]  eta: 0:03:40  loss: 8.4450 (10.4371)  loss_n_40: 1.9940 (2.3460)  loss_n_60: 2.4848 (2.8248)  loss_n_80: 2.1387 (2.5282)  loss_n_100: 1.9955 (2.5882)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0465)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0992)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [200/845]  eta: 0:03:36  loss: 8.5721 (10.3953)  loss_n_40: 1.9660 (2.3405)  loss_n_60: 2.4848 (2.8192)  loss_n_80: 2.1607 (2.5201)  loss_n_100: 2.0444 (2.5730)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0442)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0942)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [210/845]  eta: 0:03:33  loss: 8.5721 (10.4130)  loss_n_40: 1.9586 (2.3478)  loss_n_60: 2.5304 (2.8251)  loss_n_80: 2.1607 (2.5249)  loss_n_100: 2.0444 (2.5794)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0421)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0898)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [220/845]  eta: 0:03:29  loss: 8.4987 (10.3294)  loss_n_40: 1.9706 (2.3296)  loss_n_60: 2.5086 (2.8102)  loss_n_80: 2.0774 (2.5079)  loss_n_100: 1.9980 (2.5521)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0402)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0857)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [230/845]  eta: 0:03:26  loss: 8.7907 (10.3797)  loss_n_40: 1.9857 (2.3440)  loss_n_60: 2.5216 (2.8212)  loss_n_80: 2.1468 (2.5217)  loss_n_100: 1.9173 (2.5688)  triple_100: 0.0000 (0.0036)  triple_80: 0.0000 (0.0384)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0820)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [240/845]  eta: 0:03:23  loss: 8.9942 (10.3316)  loss_n_40: 2.0141 (2.3321)  loss_n_60: 2.5409 (2.8115)  loss_n_80: 2.2425 (2.5121)  loss_n_100: 2.2721 (2.5570)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0368)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0786)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [250/845]  eta: 0:03:19  loss: 8.5872 (10.3156)  loss_n_40: 1.9539 (2.3268)  loss_n_60: 2.4914 (2.8088)  loss_n_80: 2.1945 (2.5120)  loss_n_100: 2.0955 (2.5539)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0354)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0755)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [260/845]  eta: 0:03:16  loss: 8.6317 (10.2926)  loss_n_40: 1.9551 (2.3194)  loss_n_60: 2.4699 (2.8036)  loss_n_80: 2.1945 (2.5081)  loss_n_100: 2.0844 (2.5517)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0340)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0726)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [270/845]  eta: 0:03:12  loss: 8.5886 (10.2701)  loss_n_40: 1.9702 (2.3161)  loss_n_60: 2.4691 (2.8009)  loss_n_80: 2.1615 (2.5035)  loss_n_100: 2.0787 (2.5439)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0328)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0699)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [280/845]  eta: 0:03:09  loss: 8.5886 (10.3154)  loss_n_40: 1.9874 (2.3255)  loss_n_60: 2.5165 (2.8105)  loss_n_80: 2.1615 (2.5162)  loss_n_100: 2.0787 (2.5612)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0316)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0674)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [290/845]  eta: 0:03:06  loss: 10.2036 (10.3400)  loss_n_40: 2.2548 (2.3297)  loss_n_60: 2.8280 (2.8149)  loss_n_80: 2.5575 (2.5238)  loss_n_100: 2.5047 (2.5731)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0305)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0651)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [300/845]  eta: 0:03:02  loss: 9.2300 (10.3240)  loss_n_40: 2.0138 (2.3234)  loss_n_60: 2.6276 (2.8112)  loss_n_80: 2.3990 (2.5217)  loss_n_100: 2.3333 (2.5726)  triple_100: 0.0000 (0.0028)  triple_80: 0.0000 (0.0295)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0629)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [310/845]  eta: 0:02:59  loss: 8.6659 (10.3037)  loss_n_40: 1.9891 (2.3194)  loss_n_60: 2.5128 (2.8079)  loss_n_80: 2.2464 (2.5175)  loss_n_100: 2.0123 (2.5633)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0286)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0643)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [320/845]  eta: 0:02:56  loss: 8.4843 (10.2605)  loss_n_40: 1.9804 (2.3100)  loss_n_60: 2.4906 (2.8003)  loss_n_80: 2.1206 (2.5089)  loss_n_100: 1.9048 (2.5487)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0277)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0623)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [330/845]  eta: 0:02:52  loss: 8.5845 (10.2328)  loss_n_40: 1.9532 (2.3032)  loss_n_60: 2.4906 (2.7966)  loss_n_80: 2.2021 (2.5038)  loss_n_100: 2.0091 (2.5389)  triple_100: 0.0000 (0.0025)  triple_80: 0.0000 (0.0268)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0609)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [340/845]  eta: 0:02:49  loss: 8.7147 (10.2337)  loss_n_40: 1.9691 (2.3045)  loss_n_60: 2.5108 (2.7968)  loss_n_80: 2.1299 (2.5051)  loss_n_100: 1.9921 (2.5397)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0260)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0592)  time: 0.3343  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:5]  [350/845]  eta: 0:02:45  loss: 8.4010 (10.1871)  loss_n_40: 1.9625 (2.2955)  loss_n_60: 2.4497 (2.7878)  loss_n_80: 2.0878 (2.4947)  loss_n_100: 1.9134 (2.5239)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0575)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [360/845]  eta: 0:02:42  loss: 8.4245 (10.1522)  loss_n_40: 1.9421 (2.2870)  loss_n_60: 2.4346 (2.7806)  loss_n_80: 2.0770 (2.4876)  loss_n_100: 1.9134 (2.5143)  triple_100: 0.0000 (0.0023)  triple_80: 0.0000 (0.0246)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0559)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [370/845]  eta: 0:02:39  loss: 8.5434 (10.1669)  loss_n_40: 1.9655 (2.2911)  loss_n_60: 2.4851 (2.7845)  loss_n_80: 2.1274 (2.4913)  loss_n_100: 1.9862 (2.5196)  triple_100: 0.0000 (0.0022)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0544)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [380/845]  eta: 0:02:35  loss: 9.6552 (10.2458)  loss_n_40: 2.0983 (2.3108)  loss_n_60: 2.6359 (2.8005)  loss_n_80: 2.4151 (2.5077)  loss_n_100: 2.4122 (2.5448)  triple_100: 0.0000 (0.0022)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0537)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [390/845]  eta: 0:02:32  loss: 10.3876 (10.2757)  loss_n_40: 2.2449 (2.3191)  loss_n_60: 2.8768 (2.8088)  loss_n_80: 2.5751 (2.5150)  loss_n_100: 2.5674 (2.5528)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0255)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0524)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [400/845]  eta: 0:02:29  loss: 10.2543 (10.3330)  loss_n_40: 2.2336 (2.3367)  loss_n_60: 2.9444 (2.8210)  loss_n_80: 2.5448 (2.5257)  loss_n_100: 2.4710 (2.5648)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0318)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0511)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [410/845]  eta: 0:02:25  loss: 9.5470 (10.3518)  loss_n_40: 1.9739 (2.3405)  loss_n_60: 2.5685 (2.8246)  loss_n_80: 2.4237 (2.5312)  loss_n_100: 2.2539 (2.5726)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0310)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0498)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [420/845]  eta: 0:02:22  loss: 8.9164 (10.3710)  loss_n_40: 2.0409 (2.3441)  loss_n_60: 2.5685 (2.8282)  loss_n_80: 2.2206 (2.5367)  loss_n_100: 2.1671 (2.5812)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0302)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0486)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [430/845]  eta: 0:02:19  loss: 9.4829 (10.3603)  loss_n_40: 2.0529 (2.3387)  loss_n_60: 2.6327 (2.8246)  loss_n_80: 2.4387 (2.5364)  loss_n_100: 2.3381 (2.5817)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0295)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0475)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [440/845]  eta: 0:02:15  loss: 9.4829 (10.3486)  loss_n_40: 2.0332 (2.3333)  loss_n_60: 2.6250 (2.8210)  loss_n_80: 2.2973 (2.5315)  loss_n_100: 2.2723 (2.5750)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0289)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0571)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [450/845]  eta: 0:02:12  loss: 8.9301 (10.3619)  loss_n_40: 2.0246 (2.3382)  loss_n_60: 2.5517 (2.8250)  loss_n_80: 2.2595 (2.5341)  loss_n_100: 2.2337 (2.5783)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0282)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0562)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [460/845]  eta: 0:02:08  loss: 8.9301 (10.3936)  loss_n_40: 2.0246 (2.3455)  loss_n_60: 2.5804 (2.8307)  loss_n_80: 2.2595 (2.5413)  loss_n_100: 2.2491 (2.5894)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0276)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0574)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [470/845]  eta: 0:02:05  loss: 8.7034 (10.3957)  loss_n_40: 1.9987 (2.3500)  loss_n_60: 2.5804 (2.8335)  loss_n_80: 2.1454 (2.5406)  loss_n_100: 2.0777 (2.5867)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0270)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0561)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [480/845]  eta: 0:02:02  loss: 8.5825 (10.3858)  loss_n_40: 1.9835 (2.3489)  loss_n_60: 2.5195 (2.8317)  loss_n_80: 2.0829 (2.5368)  loss_n_100: 1.9326 (2.5808)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0265)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0594)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [490/845]  eta: 0:01:58  loss: 8.8286 (10.3959)  loss_n_40: 1.9815 (2.3541)  loss_n_60: 2.5133 (2.8354)  loss_n_80: 2.2229 (2.5385)  loss_n_100: 2.1039 (2.5809)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0272)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0582)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [500/845]  eta: 0:01:55  loss: 9.0203 (10.4044)  loss_n_40: 2.0015 (2.3560)  loss_n_60: 2.5681 (2.8374)  loss_n_80: 2.2826 (2.5404)  loss_n_100: 2.2264 (2.5830)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0289)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0570)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [510/845]  eta: 0:01:52  loss: 9.2214 (10.4031)  loss_n_40: 2.0239 (2.3531)  loss_n_60: 2.5836 (2.8357)  loss_n_80: 2.3561 (2.5401)  loss_n_100: 2.3186 (2.5853)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0283)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0559)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [520/845]  eta: 0:01:48  loss: 8.6669 (10.3879)  loss_n_40: 1.9714 (2.3503)  loss_n_60: 2.5101 (2.8328)  loss_n_80: 2.1998 (2.5373)  loss_n_100: 2.0427 (2.5804)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0548)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [530/845]  eta: 0:01:45  loss: 8.5998 (10.3769)  loss_n_40: 1.9714 (2.3488)  loss_n_60: 2.5125 (2.8315)  loss_n_80: 2.1268 (2.5343)  loss_n_100: 1.9958 (2.5749)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0273)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0557)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [540/845]  eta: 0:01:42  loss: 9.3540 (10.4404)  loss_n_40: 2.0761 (2.3652)  loss_n_60: 2.6149 (2.8445)  loss_n_80: 2.3418 (2.5459)  loss_n_100: 2.2618 (2.5898)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0359)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0547)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [550/845]  eta: 0:01:38  loss: 9.5195 (10.4454)  loss_n_40: 2.0761 (2.3645)  loss_n_60: 2.6531 (2.8452)  loss_n_80: 2.4201 (2.5482)  loss_n_100: 2.3130 (2.5943)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0353)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0537)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [560/845]  eta: 0:01:35  loss: 8.5861 (10.4371)  loss_n_40: 1.9771 (2.3636)  loss_n_60: 2.5221 (2.8439)  loss_n_80: 2.1592 (2.5449)  loss_n_100: 1.9557 (2.5887)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0391)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0527)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [570/845]  eta: 0:01:32  loss: 8.5903 (10.4579)  loss_n_40: 2.0414 (2.3701)  loss_n_60: 2.5116 (2.8489)  loss_n_80: 2.1592 (2.5493)  loss_n_100: 2.0583 (2.5934)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0402)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0518)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [580/845]  eta: 0:01:28  loss: 9.3268 (10.4699)  loss_n_40: 2.0574 (2.3729)  loss_n_60: 2.5801 (2.8503)  loss_n_80: 2.3552 (2.5529)  loss_n_100: 2.2668 (2.5993)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0396)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0509)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [590/845]  eta: 0:01:25  loss: 9.3268 (10.4945)  loss_n_40: 2.0574 (2.3793)  loss_n_60: 2.5302 (2.8547)  loss_n_80: 2.3296 (2.5579)  loss_n_100: 2.2842 (2.6078)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0389)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0500)  time: 0.3342  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:5]  [600/845]  eta: 0:01:22  loss: 9.1000 (10.4704)  loss_n_40: 1.9648 (2.3727)  loss_n_60: 2.5061 (2.8493)  loss_n_80: 2.3296 (2.5533)  loss_n_100: 2.2842 (2.6019)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0382)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0492)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [610/845]  eta: 0:01:18  loss: 9.2136 (10.4873)  loss_n_40: 1.9648 (2.3745)  loss_n_60: 2.5282 (2.8514)  loss_n_80: 2.3586 (2.5587)  loss_n_100: 2.2933 (2.6089)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0376)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0504)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [620/845]  eta: 0:01:15  loss: 10.0569 (10.4910)  loss_n_40: 2.1351 (2.3749)  loss_n_60: 2.6876 (2.8517)  loss_n_80: 2.4563 (2.5596)  loss_n_100: 2.3799 (2.6110)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0370)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0512)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [630/845]  eta: 0:01:11  loss: 10.5284 (10.5300)  loss_n_40: 2.2899 (2.3859)  loss_n_60: 2.8491 (2.8599)  loss_n_80: 2.4940 (2.5664)  loss_n_100: 2.5328 (2.6199)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0419)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0504)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [640/845]  eta: 0:01:08  loss: 10.7971 (10.5476)  loss_n_40: 2.3980 (2.3921)  loss_n_60: 2.9578 (2.8645)  loss_n_80: 2.5088 (2.5698)  loss_n_100: 2.6171 (2.6248)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0412)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0496)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [650/845]  eta: 0:01:05  loss: 8.3486 (10.5318)  loss_n_40: 2.0667 (2.3886)  loss_n_60: 2.5308 (2.8618)  loss_n_80: 2.1122 (2.5661)  loss_n_100: 1.9768 (2.6205)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0406)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0489)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [660/845]  eta: 0:01:01  loss: 8.5629 (10.5438)  loss_n_40: 2.0667 (2.3922)  loss_n_60: 2.5209 (2.8642)  loss_n_80: 2.0785 (2.5687)  loss_n_100: 2.0177 (2.6250)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0400)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0484)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [670/845]  eta: 0:00:58  loss: 8.5629 (10.5554)  loss_n_40: 2.0355 (2.3964)  loss_n_60: 2.4722 (2.8672)  loss_n_80: 2.1249 (2.5714)  loss_n_100: 2.0177 (2.6280)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0394)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0477)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [680/845]  eta: 0:00:55  loss: 8.5058 (10.5539)  loss_n_40: 1.9801 (2.3955)  loss_n_60: 2.4722 (2.8664)  loss_n_80: 2.1249 (2.5699)  loss_n_100: 1.9078 (2.6259)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0392)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0519)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [690/845]  eta: 0:00:51  loss: 8.4861 (10.5389)  loss_n_40: 1.9921 (2.3917)  loss_n_60: 2.4786 (2.8632)  loss_n_80: 2.1222 (2.5672)  loss_n_100: 1.8949 (2.6221)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0386)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0511)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [700/845]  eta: 0:00:48  loss: 9.2748 (10.5432)  loss_n_40: 2.0046 (2.3916)  loss_n_60: 2.4848 (2.8632)  loss_n_80: 2.2974 (2.5685)  loss_n_100: 2.3502 (2.6262)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0381)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0504)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [710/845]  eta: 0:00:45  loss: 8.5021 (10.5294)  loss_n_40: 1.9563 (2.3882)  loss_n_60: 2.5047 (2.8602)  loss_n_80: 2.1653 (2.5657)  loss_n_100: 1.9669 (2.6229)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0375)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0497)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [720/845]  eta: 0:00:41  loss: 8.5349 (10.5320)  loss_n_40: 1.9716 (2.3895)  loss_n_60: 2.5047 (2.8608)  loss_n_80: 2.1653 (2.5662)  loss_n_100: 1.9669 (2.6241)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0374)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0490)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [730/845]  eta: 0:00:38  loss: 9.0259 (10.5436)  loss_n_40: 2.0147 (2.3925)  loss_n_60: 2.5627 (2.8626)  loss_n_80: 2.2658 (2.5678)  loss_n_100: 2.2170 (2.6264)  triple_100: 0.0000 (0.0050)  triple_80: 0.0000 (0.0410)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0483)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [740/845]  eta: 0:00:35  loss: 9.3088 (10.5550)  loss_n_40: 2.0226 (2.3955)  loss_n_60: 2.5627 (2.8651)  loss_n_80: 2.3873 (2.5707)  loss_n_100: 2.3360 (2.6307)  triple_100: 0.0000 (0.0050)  triple_80: 0.0000 (0.0404)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0477)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [750/845]  eta: 0:00:31  loss: 9.5800 (10.5711)  loss_n_40: 2.1065 (2.3987)  loss_n_60: 2.5863 (2.8675)  loss_n_80: 2.4339 (2.5738)  loss_n_100: 2.3971 (2.6353)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0439)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0470)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [760/845]  eta: 0:00:28  loss: 8.9862 (10.5579)  loss_n_40: 1.9908 (2.3960)  loss_n_60: 2.5341 (2.8647)  loss_n_80: 2.3344 (2.5712)  loss_n_100: 2.2666 (2.6315)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0433)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0464)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [770/845]  eta: 0:00:25  loss: 8.8132 (10.5547)  loss_n_40: 1.9844 (2.3951)  loss_n_60: 2.5189 (2.8643)  loss_n_80: 2.1660 (2.5700)  loss_n_100: 2.1387 (2.6299)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0428)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0479)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [780/845]  eta: 0:00:21  loss: 8.8729 (10.5535)  loss_n_40: 2.0211 (2.3946)  loss_n_60: 2.5406 (2.8637)  loss_n_80: 2.1990 (2.5702)  loss_n_100: 2.1470 (2.6309)  triple_100: 0.0000 (0.0047)  triple_80: 0.0000 (0.0422)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0472)  time: 0.3353  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [790/845]  eta: 0:00:18  loss: 8.8729 (10.5590)  loss_n_40: 2.0278 (2.3957)  loss_n_60: 2.5187 (2.8644)  loss_n_80: 2.1719 (2.5720)  loss_n_100: 2.0621 (2.6339)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0417)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0466)  time: 0.3353  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [800/845]  eta: 0:00:15  loss: 8.7835 (10.5473)  loss_n_40: 1.9752 (2.3920)  loss_n_60: 2.4675 (2.8611)  loss_n_80: 2.2205 (2.5702)  loss_n_100: 2.1744 (2.6314)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0412)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0468)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [810/845]  eta: 0:00:11  loss: 9.2222 (10.5523)  loss_n_40: 1.9414 (2.3933)  loss_n_60: 2.5498 (2.8624)  loss_n_80: 2.4062 (2.5713)  loss_n_100: 2.2986 (2.6333)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0406)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0467)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [820/845]  eta: 0:00:08  loss: 9.7456 (10.5618)  loss_n_40: 2.0894 (2.3952)  loss_n_60: 2.7495 (2.8641)  loss_n_80: 2.4711 (2.5742)  loss_n_100: 2.3869 (2.6375)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0402)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0461)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [830/845]  eta: 0:00:05  loss: 9.0874 (10.5599)  loss_n_40: 1.9619 (2.3950)  loss_n_60: 2.4788 (2.8639)  loss_n_80: 2.4099 (2.5737)  loss_n_100: 2.2986 (2.6368)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0407)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0456)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5]  [840/845]  eta: 0:00:01  loss: 9.6911 (10.5586)  loss_n_40: 2.0912 (2.3931)  loss_n_60: 2.5646 (2.8632)  loss_n_80: 2.4290 (2.5737)  loss_n_100: 2.4185 (2.6390)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0402)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0450)  time: 0.3343  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:5]  [844/845]  eta: 0:00:00  loss: 10.4039 (10.5582)  loss_n_40: 2.2059 (2.3921)  loss_n_60: 2.8594 (2.8627)  loss_n_80: 2.4992 (2.5741)  loss_n_100: 2.5475 (2.6402)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0400)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0448)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:5] Total time: 0:04:42 (0.3348 s / it)\n",
      "Averaged stats: loss: 10.4039 (10.5582)  loss_n_40: 2.2059 (2.3921)  loss_n_60: 2.8594 (2.8627)  loss_n_80: 2.4992 (2.5741)  loss_n_100: 2.5475 (2.6402)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0400)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0448)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_5_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 2.640%\n",
      "Min loss_n_100: 2.640\n",
      "Best Epoch: 5.000\n",
      "Train: [epoch:6]  [   0/1724]  eta: 2:00:00  lr: 0.000100  loss: 8.7549 (8.7549)  loss_n_40: 2.0619 (2.0619)  loss_n_60: 2.5562 (2.5562)  loss_n_80: 2.0936 (2.0936)  loss_n_100: 2.0431 (2.0431)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1765  data: 0.4264  max mem: 46473\n",
      "Train: [epoch:6]  [  10/1724]  eta: 1:52:39  lr: 0.000100  loss: 10.5539 (11.2076)  loss_n_40: 2.1926 (2.4066)  loss_n_60: 2.6733 (2.8236)  loss_n_80: 2.6158 (2.6098)  loss_n_100: 3.1657 (3.0708)  triple_100: 0.0000 (0.0270)  triple_80: 0.0000 (0.0390)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.2307)  time: 3.9438  data: 0.0389  max mem: 46473\n",
      "Train: [epoch:6]  [  20/1724]  eta: 1:51:39  lr: 0.000100  loss: 11.3837 (11.0257)  loss_n_40: 2.4848 (2.4433)  loss_n_60: 2.8571 (2.8439)  loss_n_80: 2.6271 (2.5643)  loss_n_100: 3.0722 (2.9332)  triple_100: 0.0000 (0.0483)  triple_80: 0.0000 (0.0719)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.1209)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [  30/1724]  eta: 1:50:53  lr: 0.000100  loss: 10.2348 (10.7600)  loss_n_40: 2.3551 (2.4031)  loss_n_60: 2.8191 (2.8153)  loss_n_80: 2.3737 (2.5131)  loss_n_100: 2.5507 (2.7965)  triple_100: 0.0000 (0.0744)  triple_80: 0.0000 (0.0489)  triple_60: 0.0000 (0.0269)  triple_40: 0.0000 (0.0819)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [  40/1724]  eta: 1:50:10  lr: 0.000100  loss: 9.7945 (10.3626)  loss_n_40: 2.2094 (2.3438)  loss_n_60: 2.6269 (2.7478)  loss_n_80: 2.3499 (2.4284)  loss_n_100: 2.4053 (2.6536)  triple_100: 0.0000 (0.0562)  triple_80: 0.0000 (0.0370)  triple_60: 0.0000 (0.0203)  triple_40: 0.0000 (0.0755)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [  50/1724]  eta: 1:49:29  lr: 0.000100  loss: 8.3086 (9.9761)  loss_n_40: 2.0857 (2.2981)  loss_n_60: 2.3800 (2.6741)  loss_n_80: 1.9125 (2.3227)  loss_n_100: 1.9053 (2.4946)  triple_100: 0.0000 (0.0549)  triple_80: 0.0000 (0.0301)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0853)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [  60/1724]  eta: 1:48:48  lr: 0.000100  loss: 8.0019 (9.7491)  loss_n_40: 1.9468 (2.2764)  loss_n_60: 2.2500 (2.6214)  loss_n_80: 1.7893 (2.2736)  loss_n_100: 1.7183 (2.4105)  triple_100: 0.0000 (0.0493)  triple_80: 0.0000 (0.0294)  triple_60: 0.0000 (0.0172)  triple_40: 0.0000 (0.0713)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [  70/1724]  eta: 1:48:08  lr: 0.000100  loss: 9.1890 (9.6902)  loss_n_40: 2.0327 (2.2768)  loss_n_60: 2.2960 (2.6033)  loss_n_80: 2.0503 (2.2539)  loss_n_100: 2.0597 (2.3715)  triple_100: 0.0000 (0.0677)  triple_80: 0.0000 (0.0409)  triple_60: 0.0000 (0.0148)  triple_40: 0.0000 (0.0613)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [  80/1724]  eta: 1:47:27  lr: 0.000100  loss: 9.2340 (9.6154)  loss_n_40: 2.0647 (2.2704)  loss_n_60: 2.2960 (2.5836)  loss_n_80: 2.0503 (2.2365)  loss_n_100: 2.0597 (2.3335)  triple_100: 0.0000 (0.0687)  triple_80: 0.0000 (0.0359)  triple_60: 0.0000 (0.0333)  triple_40: 0.0000 (0.0537)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [  90/1724]  eta: 1:46:47  lr: 0.000100  loss: 8.6354 (9.5176)  loss_n_40: 2.0647 (2.2577)  loss_n_60: 2.2762 (2.5604)  loss_n_80: 1.9205 (2.2207)  loss_n_100: 1.9199 (2.2914)  triple_100: 0.0000 (0.0611)  triple_80: 0.0000 (0.0395)  triple_60: 0.0000 (0.0314)  triple_40: 0.0000 (0.0553)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 100/1724]  eta: 1:46:08  lr: 0.000100  loss: 7.8683 (9.3568)  loss_n_40: 1.9286 (2.2346)  loss_n_60: 2.2021 (2.5278)  loss_n_80: 1.8804 (2.1867)  loss_n_100: 1.7290 (2.2365)  triple_100: 0.0000 (0.0575)  triple_80: 0.0000 (0.0356)  triple_60: 0.0000 (0.0283)  triple_40: 0.0000 (0.0499)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 110/1724]  eta: 1:45:28  lr: 0.000100  loss: 7.8683 (9.2985)  loss_n_40: 2.0081 (2.2297)  loss_n_60: 2.2536 (2.5119)  loss_n_80: 1.8631 (2.1681)  loss_n_100: 1.7230 (2.2108)  triple_100: 0.0000 (0.0525)  triple_80: 0.0000 (0.0421)  triple_60: 0.0000 (0.0277)  triple_40: 0.0000 (0.0557)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 120/1724]  eta: 1:44:49  lr: 0.000100  loss: 7.4315 (9.1827)  loss_n_40: 1.8969 (2.2061)  loss_n_60: 2.1963 (2.4918)  loss_n_80: 1.8506 (2.1469)  loss_n_100: 1.6839 (2.1746)  triple_100: 0.0000 (0.0482)  triple_80: 0.0000 (0.0386)  triple_60: 0.0000 (0.0254)  triple_40: 0.0000 (0.0511)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 130/1724]  eta: 1:44:10  lr: 0.000100  loss: 7.3281 (9.0931)  loss_n_40: 1.8969 (2.1924)  loss_n_60: 2.1563 (2.4752)  loss_n_80: 1.7728 (2.1257)  loss_n_100: 1.5805 (2.1461)  triple_100: 0.0000 (0.0456)  triple_80: 0.0000 (0.0360)  triple_60: 0.0000 (0.0234)  triple_40: 0.0000 (0.0488)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 140/1724]  eta: 1:43:30  lr: 0.000100  loss: 7.2400 (9.0001)  loss_n_40: 1.8433 (2.1743)  loss_n_60: 2.1013 (2.4536)  loss_n_80: 1.7066 (2.0994)  loss_n_100: 1.5866 (2.1118)  triple_100: 0.0000 (0.0452)  triple_80: 0.0000 (0.0335)  triple_60: 0.0000 (0.0297)  triple_40: 0.0000 (0.0525)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 150/1724]  eta: 1:42:51  lr: 0.000100  loss: 7.3090 (8.9725)  loss_n_40: 1.8125 (2.1562)  loss_n_60: 2.0963 (2.4384)  loss_n_80: 1.9102 (2.1050)  loss_n_100: 1.6784 (2.1134)  triple_100: 0.0000 (0.0515)  triple_80: 0.0000 (0.0312)  triple_60: 0.0000 (0.0278)  triple_40: 0.0000 (0.0490)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 160/1724]  eta: 1:42:11  lr: 0.000100  loss: 7.7384 (8.9431)  loss_n_40: 1.9178 (2.1483)  loss_n_60: 2.1756 (2.4255)  loss_n_80: 1.9554 (2.1057)  loss_n_100: 1.8227 (2.1092)  triple_100: 0.0000 (0.0513)  triple_80: 0.0000 (0.0293)  triple_60: 0.0000 (0.0260)  triple_40: 0.0000 (0.0477)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 170/1724]  eta: 1:41:32  lr: 0.000100  loss: 7.3976 (8.8888)  loss_n_40: 1.8832 (2.1346)  loss_n_60: 2.1059 (2.4092)  loss_n_80: 1.7636 (2.0890)  loss_n_100: 1.6950 (2.0942)  triple_100: 0.0000 (0.0553)  triple_80: 0.0000 (0.0315)  triple_60: 0.0000 (0.0245)  triple_40: 0.0000 (0.0506)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 180/1724]  eta: 1:40:52  lr: 0.000100  loss: 7.4159 (8.8689)  loss_n_40: 1.9215 (2.1372)  loss_n_60: 2.1431 (2.4081)  loss_n_80: 1.7185 (2.0828)  loss_n_100: 1.7176 (2.0859)  triple_100: 0.0000 (0.0525)  triple_80: 0.0000 (0.0298)  triple_60: 0.0000 (0.0232)  triple_40: 0.0000 (0.0495)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 190/1724]  eta: 1:40:13  lr: 0.000100  loss: 8.3900 (8.8688)  loss_n_40: 2.0827 (2.1469)  loss_n_60: 2.3656 (2.4106)  loss_n_80: 1.9627 (2.0806)  loss_n_100: 1.9653 (2.0823)  triple_100: 0.0000 (0.0500)  triple_80: 0.0000 (0.0282)  triple_60: 0.0000 (0.0219)  triple_40: 0.0000 (0.0483)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 200/1724]  eta: 1:39:34  lr: 0.000100  loss: 8.6559 (8.8553)  loss_n_40: 2.0668 (2.1425)  loss_n_60: 2.3944 (2.4054)  loss_n_80: 1.9366 (2.0775)  loss_n_100: 1.9306 (2.0722)  triple_100: 0.0000 (0.0479)  triple_80: 0.0000 (0.0284)  triple_60: 0.0000 (0.0273)  triple_40: 0.0000 (0.0541)  time: 3.9196  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [ 210/1724]  eta: 1:38:54  lr: 0.000100  loss: 7.7402 (8.7992)  loss_n_40: 1.9393 (2.1292)  loss_n_60: 2.1809 (2.3931)  loss_n_80: 1.8771 (2.0696)  loss_n_100: 1.7240 (2.0563)  triple_100: 0.0000 (0.0456)  triple_80: 0.0000 (0.0275)  triple_60: 0.0000 (0.0260)  triple_40: 0.0000 (0.0521)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 220/1724]  eta: 1:38:15  lr: 0.000100  loss: 6.9633 (8.7131)  loss_n_40: 1.7287 (2.1106)  loss_n_60: 1.9993 (2.3726)  loss_n_80: 1.7278 (2.0505)  loss_n_100: 1.6097 (2.0338)  triple_100: 0.0000 (0.0435)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.0248)  triple_40: 0.0000 (0.0511)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 230/1724]  eta: 1:37:36  lr: 0.000100  loss: 6.5287 (8.6607)  loss_n_40: 1.6739 (2.0985)  loss_n_60: 1.8930 (2.3556)  loss_n_80: 1.5384 (2.0362)  loss_n_100: 1.3905 (2.0164)  triple_100: 0.0000 (0.0469)  triple_80: 0.0000 (0.0342)  triple_60: 0.0000 (0.0241)  triple_40: 0.0000 (0.0489)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 240/1724]  eta: 1:36:56  lr: 0.000100  loss: 7.0485 (8.6306)  loss_n_40: 1.7348 (2.0944)  loss_n_60: 1.9716 (2.3487)  loss_n_80: 1.6287 (2.0308)  loss_n_100: 1.5569 (2.0091)  triple_100: 0.0000 (0.0450)  triple_80: 0.0000 (0.0328)  triple_60: 0.0000 (0.0231)  triple_40: 0.0000 (0.0469)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 250/1724]  eta: 1:36:17  lr: 0.000100  loss: 7.6617 (8.6116)  loss_n_40: 1.8337 (2.0878)  loss_n_60: 2.1022 (2.3405)  loss_n_80: 1.7916 (2.0202)  loss_n_100: 1.7951 (1.9985)  triple_100: 0.0000 (0.0450)  triple_80: 0.0000 (0.0315)  triple_60: 0.0000 (0.0315)  triple_40: 0.0000 (0.0566)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 260/1724]  eta: 1:35:38  lr: 0.000100  loss: 7.2438 (8.5720)  loss_n_40: 1.7449 (2.0787)  loss_n_60: 2.0557 (2.3311)  loss_n_80: 1.6756 (2.0086)  loss_n_100: 1.5509 (1.9844)  triple_100: 0.0000 (0.0433)  triple_80: 0.0000 (0.0310)  triple_60: 0.0000 (0.0378)  triple_40: 0.0000 (0.0572)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 270/1724]  eta: 1:34:58  lr: 0.000100  loss: 8.2580 (8.5929)  loss_n_40: 1.8632 (2.0804)  loss_n_60: 2.1357 (2.3304)  loss_n_80: 1.8649 (2.0110)  loss_n_100: 1.8448 (1.9941)  triple_100: 0.0000 (0.0557)  triple_80: 0.0000 (0.0298)  triple_60: 0.0000 (0.0364)  triple_40: 0.0000 (0.0551)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 280/1724]  eta: 1:34:19  lr: 0.000100  loss: 8.5111 (8.5859)  loss_n_40: 1.9804 (2.0791)  loss_n_60: 2.1658 (2.3263)  loss_n_80: 1.9935 (2.0120)  loss_n_100: 2.1156 (1.9972)  triple_100: 0.0000 (0.0537)  triple_80: 0.0000 (0.0293)  triple_60: 0.0000 (0.0351)  triple_40: 0.0000 (0.0531)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 290/1724]  eta: 1:33:40  lr: 0.000100  loss: 7.8710 (8.5352)  loss_n_40: 1.8212 (2.0668)  loss_n_60: 2.0155 (2.3121)  loss_n_80: 1.9221 (2.0031)  loss_n_100: 1.8816 (1.9876)  triple_100: 0.0000 (0.0518)  triple_80: 0.0000 (0.0283)  triple_60: 0.0000 (0.0339)  triple_40: 0.0000 (0.0517)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 300/1724]  eta: 1:33:00  lr: 0.000100  loss: 6.8057 (8.4911)  loss_n_40: 1.7159 (2.0580)  loss_n_60: 1.9177 (2.3012)  loss_n_80: 1.6583 (1.9932)  loss_n_100: 1.5847 (1.9769)  triple_100: 0.0000 (0.0501)  triple_80: 0.0000 (0.0290)  triple_60: 0.0000 (0.0328)  triple_40: 0.0000 (0.0499)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 310/1724]  eta: 1:32:21  lr: 0.000100  loss: 6.9694 (8.4526)  loss_n_40: 1.6557 (2.0476)  loss_n_60: 1.8703 (2.2883)  loss_n_80: 1.6453 (1.9816)  loss_n_100: 1.6221 (1.9655)  triple_100: 0.0000 (0.0564)  triple_80: 0.0000 (0.0296)  triple_60: 0.0000 (0.0317)  triple_40: 0.0000 (0.0519)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 320/1724]  eta: 1:31:42  lr: 0.000100  loss: 6.7856 (8.4125)  loss_n_40: 1.5779 (2.0394)  loss_n_60: 1.8504 (2.2780)  loss_n_80: 1.6453 (1.9717)  loss_n_100: 1.6478 (1.9556)  triple_100: 0.0000 (0.0546)  triple_80: 0.0000 (0.0287)  triple_60: 0.0000 (0.0319)  triple_40: 0.0000 (0.0526)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 330/1724]  eta: 1:31:03  lr: 0.000100  loss: 6.9035 (8.3878)  loss_n_40: 1.7183 (2.0350)  loss_n_60: 1.8823 (2.2707)  loss_n_80: 1.6735 (1.9650)  loss_n_100: 1.6728 (1.9478)  triple_100: 0.0000 (0.0551)  triple_80: 0.0000 (0.0322)  triple_60: 0.0000 (0.0310)  triple_40: 0.0000 (0.0510)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 340/1724]  eta: 1:30:23  lr: 0.000100  loss: 7.1369 (8.3504)  loss_n_40: 1.8080 (2.0282)  loss_n_60: 1.9375 (2.2609)  loss_n_80: 1.6735 (1.9571)  loss_n_100: 1.6728 (1.9397)  triple_100: 0.0000 (0.0535)  triple_80: 0.0000 (0.0313)  triple_60: 0.0000 (0.0301)  triple_40: 0.0000 (0.0495)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 350/1724]  eta: 1:29:44  lr: 0.000100  loss: 7.3423 (8.3399)  loss_n_40: 1.8080 (2.0250)  loss_n_60: 2.0285 (2.2554)  loss_n_80: 1.7657 (1.9548)  loss_n_100: 1.7276 (1.9370)  triple_100: 0.0000 (0.0567)  triple_80: 0.0000 (0.0332)  triple_60: 0.0000 (0.0294)  triple_40: 0.0000 (0.0485)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 360/1724]  eta: 1:29:05  lr: 0.000100  loss: 6.9293 (8.2982)  loss_n_40: 1.7222 (2.0165)  loss_n_60: 1.9102 (2.2450)  loss_n_80: 1.7550 (1.9471)  loss_n_100: 1.6954 (1.9265)  triple_100: 0.0000 (0.0551)  triple_80: 0.0000 (0.0322)  triple_60: 0.0000 (0.0286)  triple_40: 0.0000 (0.0471)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 370/1724]  eta: 1:28:26  lr: 0.000100  loss: 6.6795 (8.2627)  loss_n_40: 1.5439 (2.0075)  loss_n_60: 1.8145 (2.2346)  loss_n_80: 1.6574 (1.9370)  loss_n_100: 1.4450 (1.9145)  triple_100: 0.0000 (0.0555)  triple_80: 0.0000 (0.0321)  triple_60: 0.0000 (0.0308)  triple_40: 0.0000 (0.0506)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 380/1724]  eta: 1:27:46  lr: 0.000100  loss: 8.0360 (8.2841)  loss_n_40: 1.9269 (2.0173)  loss_n_60: 2.1905 (2.2443)  loss_n_80: 1.8343 (1.9411)  loss_n_100: 1.7180 (1.9169)  triple_100: 0.0000 (0.0540)  triple_80: 0.0000 (0.0313)  triple_60: 0.0000 (0.0300)  triple_40: 0.0000 (0.0493)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 390/1724]  eta: 1:27:07  lr: 0.000100  loss: 8.1539 (8.2652)  loss_n_40: 2.0900 (2.0176)  loss_n_60: 2.3371 (2.2422)  loss_n_80: 1.8748 (1.9340)  loss_n_100: 1.7370 (1.9084)  triple_100: 0.0000 (0.0526)  triple_80: 0.0000 (0.0305)  triple_60: 0.0000 (0.0318)  triple_40: 0.0000 (0.0480)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 400/1724]  eta: 1:26:28  lr: 0.000100  loss: 6.4898 (8.2225)  loss_n_40: 1.7735 (2.0100)  loss_n_60: 1.9026 (2.2324)  loss_n_80: 1.4606 (1.9230)  loss_n_100: 1.3973 (1.8973)  triple_100: 0.0000 (0.0513)  triple_80: 0.0000 (0.0297)  triple_60: 0.0000 (0.0310)  triple_40: 0.0000 (0.0478)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 410/1724]  eta: 1:25:49  lr: 0.000100  loss: 6.4057 (8.1961)  loss_n_40: 1.6959 (2.0073)  loss_n_60: 1.8448 (2.2254)  loss_n_80: 1.4606 (1.9165)  loss_n_100: 1.3973 (1.8896)  triple_100: 0.0000 (0.0501)  triple_80: 0.0000 (0.0290)  triple_60: 0.0000 (0.0303)  triple_40: 0.0000 (0.0480)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 420/1724]  eta: 1:25:09  lr: 0.000100  loss: 6.2197 (8.1536)  loss_n_40: 1.6102 (1.9977)  loss_n_60: 1.7596 (2.2131)  loss_n_80: 1.5225 (1.9061)  loss_n_100: 1.3401 (1.8781)  triple_100: 0.0000 (0.0497)  triple_80: 0.0000 (0.0283)  triple_60: 0.0000 (0.0310)  triple_40: 0.0000 (0.0496)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 430/1724]  eta: 1:24:30  lr: 0.000100  loss: 6.5759 (8.1232)  loss_n_40: 1.5371 (1.9916)  loss_n_60: 1.7170 (2.2042)  loss_n_80: 1.5900 (1.8998)  loss_n_100: 1.3356 (1.8699)  triple_100: 0.0000 (0.0494)  triple_80: 0.0000 (0.0294)  triple_60: 0.0000 (0.0303)  triple_40: 0.0000 (0.0484)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 440/1724]  eta: 1:23:51  lr: 0.000100  loss: 6.4341 (8.0814)  loss_n_40: 1.4896 (1.9831)  loss_n_60: 1.5942 (2.1930)  loss_n_80: 1.4289 (1.8901)  loss_n_100: 1.2727 (1.8583)  triple_100: 0.0000 (0.0493)  triple_80: 0.0000 (0.0295)  triple_60: 0.0000 (0.0296)  triple_40: 0.0000 (0.0485)  time: 3.9171  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [ 450/1724]  eta: 1:23:12  lr: 0.000100  loss: 5.4148 (8.0291)  loss_n_40: 1.3771 (1.9720)  loss_n_60: 1.5871 (2.1808)  loss_n_80: 1.2918 (1.8784)  loss_n_100: 1.2005 (1.8444)  triple_100: 0.0000 (0.0482)  triple_80: 0.0000 (0.0288)  triple_60: 0.0000 (0.0290)  triple_40: 0.0000 (0.0475)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 460/1724]  eta: 1:22:33  lr: 0.000100  loss: 5.4148 (7.9838)  loss_n_40: 1.4171 (1.9640)  loss_n_60: 1.5880 (2.1704)  loss_n_80: 1.2818 (1.8679)  loss_n_100: 1.1675 (1.8314)  triple_100: 0.0000 (0.0472)  triple_80: 0.0000 (0.0282)  triple_60: 0.0000 (0.0283)  triple_40: 0.0000 (0.0464)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 470/1724]  eta: 1:21:53  lr: 0.000100  loss: 5.6408 (7.9465)  loss_n_40: 1.4288 (1.9548)  loss_n_60: 1.5748 (2.1593)  loss_n_80: 1.3588 (1.8581)  loss_n_100: 1.2857 (1.8204)  triple_100: 0.0000 (0.0493)  triple_80: 0.0000 (0.0284)  triple_60: 0.0000 (0.0293)  triple_40: 0.0000 (0.0468)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 480/1724]  eta: 1:21:14  lr: 0.000100  loss: 6.0003 (7.9196)  loss_n_40: 1.3947 (1.9474)  loss_n_60: 1.5822 (2.1507)  loss_n_80: 1.4584 (1.8538)  loss_n_100: 1.3887 (1.8167)  triple_100: 0.0000 (0.0486)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.0287)  triple_40: 0.0000 (0.0459)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 490/1724]  eta: 1:20:35  lr: 0.000100  loss: 6.4175 (7.9045)  loss_n_40: 1.5279 (1.9449)  loss_n_60: 1.6524 (2.1445)  loss_n_80: 1.6087 (1.8509)  loss_n_100: 1.6115 (1.8146)  triple_100: 0.0000 (0.0476)  triple_80: 0.0000 (0.0272)  triple_60: 0.0000 (0.0281)  triple_40: 0.0000 (0.0467)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 500/1724]  eta: 1:19:56  lr: 0.000100  loss: 5.2140 (7.8635)  loss_n_40: 1.3603 (1.9338)  loss_n_60: 1.4388 (2.1311)  loss_n_80: 1.3180 (1.8407)  loss_n_100: 1.1704 (1.8028)  triple_100: 0.0000 (0.0536)  triple_80: 0.0000 (0.0267)  triple_60: 0.0000 (0.0276)  triple_40: 0.0000 (0.0472)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 510/1724]  eta: 1:19:17  lr: 0.000100  loss: 5.2140 (7.8455)  loss_n_40: 1.3393 (1.9317)  loss_n_60: 1.4388 (2.1252)  loss_n_80: 1.3180 (1.8356)  loss_n_100: 1.1751 (1.7962)  triple_100: 0.0000 (0.0536)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.0289)  triple_40: 0.0000 (0.0480)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 520/1724]  eta: 1:18:37  lr: 0.000100  loss: 6.3079 (7.8204)  loss_n_40: 1.5430 (1.9267)  loss_n_60: 1.6503 (2.1172)  loss_n_80: 1.5342 (1.8308)  loss_n_100: 1.3891 (1.7904)  triple_100: 0.0000 (0.0529)  triple_80: 0.0000 (0.0257)  triple_60: 0.0000 (0.0285)  triple_40: 0.0000 (0.0482)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 530/1724]  eta: 1:17:58  lr: 0.000100  loss: 6.3079 (7.7907)  loss_n_40: 1.4866 (1.9190)  loss_n_60: 1.5979 (2.1071)  loss_n_80: 1.4798 (1.8232)  loss_n_100: 1.2956 (1.7808)  triple_100: 0.0000 (0.0556)  triple_80: 0.0000 (0.0284)  triple_60: 0.0000 (0.0289)  triple_40: 0.0000 (0.0478)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 540/1724]  eta: 1:17:19  lr: 0.000100  loss: 5.4242 (7.7677)  loss_n_40: 1.3978 (1.9135)  loss_n_60: 1.4708 (2.0986)  loss_n_80: 1.3268 (1.8162)  loss_n_100: 1.2710 (1.7749)  triple_100: 0.0000 (0.0583)  triple_80: 0.0000 (0.0310)  triple_60: 0.0000 (0.0283)  triple_40: 0.0000 (0.0469)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 550/1724]  eta: 1:16:40  lr: 0.000100  loss: 5.8245 (7.7437)  loss_n_40: 1.4621 (1.9089)  loss_n_60: 1.5395 (2.0928)  loss_n_80: 1.3721 (1.8111)  loss_n_100: 1.4508 (1.7692)  triple_100: 0.0000 (0.0574)  triple_80: 0.0000 (0.0304)  triple_60: 0.0000 (0.0278)  triple_40: 0.0000 (0.0460)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 560/1724]  eta: 1:16:00  lr: 0.000100  loss: 6.6369 (7.7201)  loss_n_40: 1.6167 (1.9033)  loss_n_60: 1.8304 (2.0866)  loss_n_80: 1.5525 (1.8067)  loss_n_100: 1.4920 (1.7643)  triple_100: 0.0000 (0.0563)  triple_80: 0.0000 (0.0299)  triple_60: 0.0000 (0.0278)  triple_40: 0.0000 (0.0452)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 570/1724]  eta: 1:15:21  lr: 0.000100  loss: 5.3652 (7.6822)  loss_n_40: 1.2993 (1.8939)  loss_n_60: 1.4949 (2.0763)  loss_n_80: 1.3234 (1.7990)  loss_n_100: 1.2899 (1.7559)  triple_100: 0.0000 (0.0553)  triple_80: 0.0000 (0.0294)  triple_60: 0.0000 (0.0273)  triple_40: 0.0000 (0.0452)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 580/1724]  eta: 1:14:42  lr: 0.000100  loss: 4.8979 (7.6536)  loss_n_40: 1.2503 (1.8875)  loss_n_60: 1.3654 (2.0682)  loss_n_80: 1.2277 (1.7938)  loss_n_100: 1.1380 (1.7494)  triple_100: 0.0000 (0.0544)  triple_80: 0.0000 (0.0290)  triple_60: 0.0000 (0.0268)  triple_40: 0.0000 (0.0444)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 590/1724]  eta: 1:14:03  lr: 0.000100  loss: 4.8288 (7.6118)  loss_n_40: 1.2356 (1.8777)  loss_n_60: 1.2893 (2.0572)  loss_n_80: 1.2047 (1.7847)  loss_n_100: 1.0937 (1.7396)  triple_100: 0.0000 (0.0535)  triple_80: 0.0000 (0.0285)  triple_60: 0.0000 (0.0264)  triple_40: 0.0000 (0.0442)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 600/1724]  eta: 1:13:24  lr: 0.000100  loss: 4.9988 (7.5952)  loss_n_40: 1.2356 (1.8707)  loss_n_60: 1.2731 (2.0486)  loss_n_80: 1.1906 (1.7776)  loss_n_100: 1.1152 (1.7320)  triple_100: 0.0000 (0.0547)  triple_80: 0.0000 (0.0281)  triple_60: 0.0000 (0.0380)  triple_40: 0.0000 (0.0455)  time: 3.9158  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 610/1724]  eta: 1:12:44  lr: 0.000100  loss: 6.3343 (7.5912)  loss_n_40: 1.4291 (1.8703)  loss_n_60: 1.6287 (2.0464)  loss_n_80: 1.3085 (1.7765)  loss_n_100: 1.2557 (1.7320)  triple_100: 0.0000 (0.0539)  triple_80: 0.0000 (0.0276)  triple_60: 0.0000 (0.0374)  triple_40: 0.0000 (0.0471)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 620/1724]  eta: 1:12:05  lr: 0.000100  loss: 5.6458 (7.5560)  loss_n_40: 1.4539 (1.8629)  loss_n_60: 1.4898 (2.0370)  loss_n_80: 1.3605 (1.7695)  loss_n_100: 1.1869 (1.7233)  triple_100: 0.0000 (0.0530)  triple_80: 0.0000 (0.0272)  triple_60: 0.0000 (0.0368)  triple_40: 0.0000 (0.0464)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 630/1724]  eta: 1:11:26  lr: 0.000100  loss: 5.3206 (7.5425)  loss_n_40: 1.4349 (1.8618)  loss_n_60: 1.4878 (2.0326)  loss_n_80: 1.2875 (1.7658)  loss_n_100: 1.1892 (1.7212)  triple_100: 0.0000 (0.0521)  triple_80: 0.0000 (0.0267)  triple_60: 0.0000 (0.0362)  triple_40: 0.0000 (0.0460)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 640/1724]  eta: 1:10:47  lr: 0.000100  loss: 7.2447 (7.5545)  loss_n_40: 2.0041 (1.8639)  loss_n_60: 1.9108 (2.0341)  loss_n_80: 1.5788 (1.7665)  loss_n_100: 1.5377 (1.7220)  triple_100: 0.0000 (0.0553)  triple_80: 0.0000 (0.0284)  triple_60: 0.0000 (0.0370)  triple_40: 0.0000 (0.0474)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 650/1724]  eta: 1:10:08  lr: 0.000100  loss: 7.5415 (7.5581)  loss_n_40: 2.0041 (1.8655)  loss_n_60: 2.0169 (2.0352)  loss_n_80: 1.7872 (1.7680)  loss_n_100: 1.7202 (1.7240)  triple_100: 0.0000 (0.0544)  triple_80: 0.0000 (0.0279)  triple_60: 0.0000 (0.0364)  triple_40: 0.0000 (0.0467)  time: 3.9153  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 660/1724]  eta: 1:09:28  lr: 0.000100  loss: 6.8287 (7.5437)  loss_n_40: 1.6919 (1.8626)  loss_n_60: 1.8611 (2.0312)  loss_n_80: 1.6024 (1.7643)  loss_n_100: 1.6219 (1.7210)  triple_100: 0.0000 (0.0536)  triple_80: 0.0000 (0.0282)  triple_60: 0.0000 (0.0359)  triple_40: 0.0000 (0.0470)  time: 3.9155  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 670/1724]  eta: 1:08:49  lr: 0.000100  loss: 6.2013 (7.5169)  loss_n_40: 1.4660 (1.8567)  loss_n_60: 1.6274 (2.0247)  loss_n_80: 1.4072 (1.7579)  loss_n_100: 1.3051 (1.7153)  triple_100: 0.0000 (0.0528)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.0353)  triple_40: 0.0000 (0.0463)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 680/1724]  eta: 1:08:10  lr: 0.000100  loss: 6.2013 (7.5115)  loss_n_40: 1.4660 (1.8574)  loss_n_60: 1.6616 (2.0232)  loss_n_80: 1.4716 (1.7561)  loss_n_100: 1.4548 (1.7141)  triple_100: 0.0000 (0.0522)  triple_80: 0.0000 (0.0275)  triple_60: 0.0000 (0.0354)  triple_40: 0.0000 (0.0457)  time: 3.9168  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [ 690/1724]  eta: 1:07:31  lr: 0.000100  loss: 6.4484 (7.4922)  loss_n_40: 1.7300 (1.8541)  loss_n_60: 1.7732 (2.0173)  loss_n_80: 1.5492 (1.7516)  loss_n_100: 1.4924 (1.7094)  triple_100: 0.0000 (0.0517)  triple_80: 0.0000 (0.0279)  triple_60: 0.0000 (0.0352)  triple_40: 0.0000 (0.0450)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 700/1724]  eta: 1:06:51  lr: 0.000100  loss: 5.7580 (7.4683)  loss_n_40: 1.3882 (1.8488)  loss_n_60: 1.6063 (2.0118)  loss_n_80: 1.3215 (1.7457)  loss_n_100: 1.3252 (1.7036)  triple_100: 0.0000 (0.0512)  triple_80: 0.0000 (0.0281)  triple_60: 0.0000 (0.0347)  triple_40: 0.0000 (0.0444)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 710/1724]  eta: 1:06:12  lr: 0.000100  loss: 5.6910 (7.4553)  loss_n_40: 1.4004 (1.8460)  loss_n_60: 1.6479 (2.0091)  loss_n_80: 1.3215 (1.7433)  loss_n_100: 1.2664 (1.7007)  triple_100: 0.0000 (0.0505)  triple_80: 0.0000 (0.0277)  triple_60: 0.0000 (0.0342)  triple_40: 0.0000 (0.0437)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 720/1724]  eta: 1:05:33  lr: 0.000100  loss: 5.6910 (7.4379)  loss_n_40: 1.3964 (1.8405)  loss_n_60: 1.6243 (2.0031)  loss_n_80: 1.3604 (1.7382)  loss_n_100: 1.2608 (1.6954)  triple_100: 0.0000 (0.0509)  triple_80: 0.0000 (0.0280)  triple_60: 0.0000 (0.0376)  triple_40: 0.0000 (0.0442)  time: 3.9179  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [ 730/1724]  eta: 1:04:54  lr: 0.000100  loss: 6.6313 (7.4634)  loss_n_40: 1.4778 (1.8418)  loss_n_60: 1.6747 (2.0065)  loss_n_80: 1.5765 (1.7431)  loss_n_100: 1.5048 (1.7014)  triple_100: 0.0000 (0.0585)  triple_80: 0.0000 (0.0297)  triple_60: 0.0000 (0.0377)  triple_40: 0.0000 (0.0447)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 740/1724]  eta: 1:04:15  lr: 0.000100  loss: 7.6820 (7.4676)  loss_n_40: 1.6664 (1.8436)  loss_n_60: 1.9974 (2.0091)  loss_n_80: 1.7166 (1.7445)  loss_n_100: 1.6363 (1.7020)  triple_100: 0.0000 (0.0577)  triple_80: 0.0000 (0.0293)  triple_60: 0.0000 (0.0372)  triple_40: 0.0000 (0.0443)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 750/1724]  eta: 1:03:36  lr: 0.000100  loss: 8.7765 (7.4949)  loss_n_40: 1.8048 (1.8437)  loss_n_60: 2.1761 (2.0120)  loss_n_80: 2.0013 (1.7520)  loss_n_100: 1.8084 (1.7124)  triple_100: 0.0000 (0.0591)  triple_80: 0.0000 (0.0293)  triple_60: 0.0000 (0.0388)  triple_40: 0.0000 (0.0476)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 760/1724]  eta: 1:02:56  lr: 0.000100  loss: 9.3330 (7.5185)  loss_n_40: 1.8555 (1.8438)  loss_n_60: 2.2697 (2.0159)  loss_n_80: 2.5043 (1.7606)  loss_n_100: 2.8322 (1.7253)  triple_100: 0.0000 (0.0586)  triple_80: 0.0000 (0.0289)  triple_60: 0.0000 (0.0383)  triple_40: 0.0000 (0.0470)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 770/1724]  eta: 1:02:17  lr: 0.000100  loss: 8.0295 (7.5170)  loss_n_40: 1.7129 (1.8416)  loss_n_60: 2.1444 (2.0158)  loss_n_80: 2.0952 (1.7617)  loss_n_100: 2.1290 (1.7272)  triple_100: 0.0000 (0.0578)  triple_80: 0.0000 (0.0285)  triple_60: 0.0000 (0.0378)  triple_40: 0.0000 (0.0464)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 780/1724]  eta: 1:01:38  lr: 0.000100  loss: 6.1110 (7.5026)  loss_n_40: 1.4164 (1.8379)  loss_n_60: 1.6691 (2.0122)  loss_n_80: 1.5356 (1.7587)  loss_n_100: 1.5001 (1.7241)  triple_100: 0.0000 (0.0571)  triple_80: 0.0000 (0.0282)  triple_60: 0.0000 (0.0387)  triple_40: 0.0000 (0.0458)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 790/1724]  eta: 1:00:59  lr: 0.000100  loss: 5.6741 (7.4830)  loss_n_40: 1.3278 (1.8329)  loss_n_60: 1.5519 (2.0071)  loss_n_80: 1.3182 (1.7540)  loss_n_100: 1.3760 (1.7201)  triple_100: 0.0000 (0.0570)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.0388)  triple_40: 0.0000 (0.0452)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 800/1724]  eta: 1:00:20  lr: 0.000100  loss: 5.3476 (7.4590)  loss_n_40: 1.2914 (1.8270)  loss_n_60: 1.4795 (2.0008)  loss_n_80: 1.2771 (1.7484)  loss_n_100: 1.3142 (1.7155)  triple_100: 0.0000 (0.0563)  triple_80: 0.0000 (0.0275)  triple_60: 0.0000 (0.0383)  triple_40: 0.0000 (0.0452)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 810/1724]  eta: 0:59:40  lr: 0.000100  loss: 5.1924 (7.4346)  loss_n_40: 1.2112 (1.8216)  loss_n_60: 1.4531 (1.9951)  loss_n_80: 1.2809 (1.7423)  loss_n_100: 1.2915 (1.7104)  triple_100: 0.0000 (0.0556)  triple_80: 0.0000 (0.0272)  triple_60: 0.0000 (0.0379)  triple_40: 0.0000 (0.0446)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 820/1724]  eta: 0:59:01  lr: 0.000100  loss: 5.1775 (7.4155)  loss_n_40: 1.1985 (1.8165)  loss_n_60: 1.4531 (1.9898)  loss_n_80: 1.2623 (1.7368)  loss_n_100: 1.2434 (1.7061)  triple_100: 0.0000 (0.0580)  triple_80: 0.0000 (0.0269)  triple_60: 0.0000 (0.0374)  triple_40: 0.0000 (0.0441)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 830/1724]  eta: 0:58:22  lr: 0.000100  loss: 5.8807 (7.3953)  loss_n_40: 1.2067 (1.8121)  loss_n_60: 1.4818 (1.9845)  loss_n_80: 1.2623 (1.7318)  loss_n_100: 1.2360 (1.7001)  triple_100: 0.0000 (0.0573)  triple_80: 0.0000 (0.0286)  triple_60: 0.0000 (0.0370)  triple_40: 0.0000 (0.0439)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 840/1724]  eta: 0:57:43  lr: 0.000100  loss: 6.4327 (7.4072)  loss_n_40: 1.3833 (1.8115)  loss_n_60: 1.7412 (1.9846)  loss_n_80: 1.4810 (1.7321)  loss_n_100: 1.3839 (1.7017)  triple_100: 0.0000 (0.0580)  triple_80: 0.0000 (0.0292)  triple_60: 0.0000 (0.0425)  triple_40: 0.0000 (0.0475)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 850/1724]  eta: 0:57:04  lr: 0.000100  loss: 6.6037 (7.3986)  loss_n_40: 1.3916 (1.8081)  loss_n_60: 1.7993 (1.9825)  loss_n_80: 1.5612 (1.7299)  loss_n_100: 1.6626 (1.7021)  triple_100: 0.0000 (0.0578)  triple_80: 0.0000 (0.0289)  triple_60: 0.0000 (0.0420)  triple_40: 0.0000 (0.0472)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 860/1724]  eta: 0:56:25  lr: 0.000100  loss: 5.6767 (7.3783)  loss_n_40: 1.2178 (1.8029)  loss_n_60: 1.5181 (1.9768)  loss_n_80: 1.3511 (1.7250)  loss_n_100: 1.4782 (1.6981)  triple_100: 0.0000 (0.0571)  triple_80: 0.0000 (0.0286)  triple_60: 0.0000 (0.0415)  triple_40: 0.0000 (0.0483)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 870/1724]  eta: 0:55:45  lr: 0.000100  loss: 4.7111 (7.3538)  loss_n_40: 1.1757 (1.7971)  loss_n_60: 1.2857 (1.9705)  loss_n_80: 1.1531 (1.7198)  loss_n_100: 1.1072 (1.6929)  triple_100: 0.0000 (0.0565)  triple_80: 0.0000 (0.0282)  triple_60: 0.0000 (0.0410)  triple_40: 0.0000 (0.0478)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 880/1724]  eta: 0:55:06  lr: 0.000100  loss: 4.6933 (7.3305)  loss_n_40: 1.1441 (1.7919)  loss_n_60: 1.2827 (1.9644)  loss_n_80: 1.1437 (1.7141)  loss_n_100: 1.1454 (1.6881)  triple_100: 0.0000 (0.0563)  triple_80: 0.0000 (0.0279)  triple_60: 0.0000 (0.0406)  triple_40: 0.0000 (0.0472)  time: 3.9170  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [ 890/1724]  eta: 0:54:27  lr: 0.000100  loss: 4.3830 (7.3031)  loss_n_40: 1.1038 (1.7856)  loss_n_60: 1.2057 (1.9568)  loss_n_80: 1.0185 (1.7063)  loss_n_100: 1.0581 (1.6809)  triple_100: 0.0000 (0.0575)  triple_80: 0.0000 (0.0279)  triple_60: 0.0000 (0.0411)  triple_40: 0.0000 (0.0470)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 900/1724]  eta: 0:53:48  lr: 0.000100  loss: 4.3748 (7.2788)  loss_n_40: 1.1266 (1.7811)  loss_n_60: 1.2728 (1.9514)  loss_n_80: 1.0280 (1.7004)  loss_n_100: 0.9620 (1.6744)  triple_100: 0.0000 (0.0568)  triple_80: 0.0000 (0.0276)  triple_60: 0.0000 (0.0406)  triple_40: 0.0000 (0.0465)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 910/1724]  eta: 0:53:09  lr: 0.000100  loss: 4.4712 (7.2575)  loss_n_40: 1.1849 (1.7766)  loss_n_60: 1.3241 (1.9460)  loss_n_80: 1.0796 (1.6952)  loss_n_100: 0.9634 (1.6684)  triple_100: 0.0000 (0.0562)  triple_80: 0.0000 (0.0273)  triple_60: 0.0000 (0.0408)  triple_40: 0.0000 (0.0470)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 920/1724]  eta: 0:52:29  lr: 0.000100  loss: 4.6337 (7.2345)  loss_n_40: 1.1823 (1.7708)  loss_n_60: 1.2672 (1.9397)  loss_n_80: 1.1220 (1.6897)  loss_n_100: 1.0928 (1.6646)  triple_100: 0.0000 (0.0558)  triple_80: 0.0000 (0.0270)  triple_60: 0.0000 (0.0404)  triple_40: 0.0000 (0.0465)  time: 3.9172  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [ 930/1724]  eta: 0:51:50  lr: 0.000100  loss: 4.6199 (7.2155)  loss_n_40: 1.1011 (1.7672)  loss_n_60: 1.2480 (1.9344)  loss_n_80: 1.0983 (1.6850)  loss_n_100: 1.1532 (1.6609)  triple_100: 0.0000 (0.0552)  triple_80: 0.0000 (0.0269)  triple_60: 0.0000 (0.0400)  triple_40: 0.0000 (0.0460)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 940/1724]  eta: 0:51:11  lr: 0.000100  loss: 4.4467 (7.1922)  loss_n_40: 1.1058 (1.7623)  loss_n_60: 1.1445 (1.9275)  loss_n_80: 1.0585 (1.6797)  loss_n_100: 1.1681 (1.6558)  triple_100: 0.0000 (0.0552)  triple_80: 0.0000 (0.0266)  triple_60: 0.0000 (0.0395)  triple_40: 0.0000 (0.0455)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 950/1724]  eta: 0:50:32  lr: 0.000100  loss: 4.4467 (7.1653)  loss_n_40: 1.0117 (1.7564)  loss_n_60: 1.0873 (1.9199)  loss_n_80: 0.9727 (1.6736)  loss_n_100: 0.9445 (1.6496)  triple_100: 0.0000 (0.0546)  triple_80: 0.0000 (0.0263)  triple_60: 0.0000 (0.0391)  triple_40: 0.0000 (0.0458)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 960/1724]  eta: 0:49:53  lr: 0.000100  loss: 4.5796 (7.1428)  loss_n_40: 1.1139 (1.7517)  loss_n_60: 1.2702 (1.9140)  loss_n_80: 1.0546 (1.6683)  loss_n_100: 0.9942 (1.6443)  triple_100: 0.0000 (0.0541)  triple_80: 0.0000 (0.0260)  triple_60: 0.0000 (0.0387)  triple_40: 0.0000 (0.0457)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 970/1724]  eta: 0:49:14  lr: 0.000100  loss: 4.7955 (7.1195)  loss_n_40: 1.1878 (1.7470)  loss_n_60: 1.2940 (1.9081)  loss_n_80: 1.1190 (1.6624)  loss_n_100: 1.0760 (1.6386)  triple_100: 0.0000 (0.0541)  triple_80: 0.0000 (0.0258)  triple_60: 0.0000 (0.0383)  triple_40: 0.0000 (0.0452)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 980/1724]  eta: 0:48:34  lr: 0.000100  loss: 4.0999 (7.0943)  loss_n_40: 1.0856 (1.7410)  loss_n_60: 1.1095 (1.9006)  loss_n_80: 0.9465 (1.6557)  loss_n_100: 0.9584 (1.6320)  triple_100: 0.0000 (0.0536)  triple_80: 0.0000 (0.0265)  triple_60: 0.0000 (0.0390)  triple_40: 0.0000 (0.0460)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [ 990/1724]  eta: 0:47:55  lr: 0.000100  loss: 4.6414 (7.0797)  loss_n_40: 1.2156 (1.7380)  loss_n_60: 1.2507 (1.8959)  loss_n_80: 1.1116 (1.6523)  loss_n_100: 1.1182 (1.6286)  triple_100: 0.0000 (0.0530)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.0396)  triple_40: 0.0000 (0.0461)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1000/1724]  eta: 0:47:16  lr: 0.000100  loss: 5.0247 (7.0611)  loss_n_40: 1.3603 (1.7348)  loss_n_60: 1.3523 (1.8909)  loss_n_80: 1.2363 (1.6480)  loss_n_100: 1.2160 (1.6240)  triple_100: 0.0000 (0.0525)  triple_80: 0.0000 (0.0259)  triple_60: 0.0000 (0.0394)  triple_40: 0.0000 (0.0457)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1010/1724]  eta: 0:46:37  lr: 0.000100  loss: 4.4681 (7.0402)  loss_n_40: 1.3548 (1.7312)  loss_n_60: 1.2572 (1.8850)  loss_n_80: 1.0852 (1.6431)  loss_n_100: 0.9878 (1.6188)  triple_100: 0.0000 (0.0520)  triple_80: 0.0000 (0.0257)  triple_60: 0.0000 (0.0390)  triple_40: 0.0000 (0.0455)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1020/1724]  eta: 0:45:58  lr: 0.000100  loss: 4.4186 (7.0238)  loss_n_40: 1.2148 (1.7286)  loss_n_60: 1.1861 (1.8804)  loss_n_80: 1.0209 (1.6393)  loss_n_100: 0.9829 (1.6147)  triple_100: 0.0000 (0.0516)  triple_80: 0.0000 (0.0254)  triple_60: 0.0000 (0.0386)  triple_40: 0.0000 (0.0451)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1030/1724]  eta: 0:45:19  lr: 0.000100  loss: 4.2019 (7.0069)  loss_n_40: 1.1560 (1.7260)  loss_n_60: 1.1644 (1.8754)  loss_n_80: 1.0209 (1.6356)  loss_n_100: 0.9415 (1.6108)  triple_100: 0.0000 (0.0511)  triple_80: 0.0000 (0.0252)  triple_60: 0.0000 (0.0382)  triple_40: 0.0000 (0.0446)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1040/1724]  eta: 0:44:39  lr: 0.000100  loss: 4.6210 (6.9866)  loss_n_40: 1.1560 (1.7220)  loss_n_60: 1.1655 (1.8693)  loss_n_80: 1.0236 (1.6309)  loss_n_100: 0.9415 (1.6055)  triple_100: 0.0000 (0.0510)  triple_80: 0.0000 (0.0256)  triple_60: 0.0000 (0.0378)  triple_40: 0.0000 (0.0444)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1050/1724]  eta: 0:44:00  lr: 0.000100  loss: 4.3482 (6.9633)  loss_n_40: 1.1101 (1.7168)  loss_n_60: 1.1655 (1.8633)  loss_n_80: 1.0041 (1.6253)  loss_n_100: 0.9165 (1.5996)  triple_100: 0.0000 (0.0506)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0377)  triple_40: 0.0000 (0.0446)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1060/1724]  eta: 0:43:21  lr: 0.000100  loss: 4.0177 (6.9411)  loss_n_40: 1.0429 (1.7122)  loss_n_60: 1.1419 (1.8574)  loss_n_80: 0.9629 (1.6204)  loss_n_100: 0.9088 (1.5943)  triple_100: 0.0000 (0.0501)  triple_80: 0.0000 (0.0251)  triple_60: 0.0000 (0.0374)  triple_40: 0.0000 (0.0442)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1070/1724]  eta: 0:42:42  lr: 0.000100  loss: 3.7724 (6.9166)  loss_n_40: 1.0165 (1.7072)  loss_n_60: 1.0319 (1.8507)  loss_n_80: 0.9273 (1.6148)  loss_n_100: 0.8709 (1.5882)  triple_100: 0.0000 (0.0497)  triple_80: 0.0000 (0.0249)  triple_60: 0.0000 (0.0370)  triple_40: 0.0000 (0.0440)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1080/1724]  eta: 0:42:03  lr: 0.000100  loss: 3.9514 (6.9002)  loss_n_40: 1.0364 (1.7041)  loss_n_60: 1.1097 (1.8460)  loss_n_80: 0.9379 (1.6111)  loss_n_100: 0.9102 (1.5838)  triple_100: 0.0000 (0.0499)  triple_80: 0.0000 (0.0246)  triple_60: 0.0000 (0.0367)  triple_40: 0.0000 (0.0439)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1090/1724]  eta: 0:41:23  lr: 0.000100  loss: 4.0716 (6.8753)  loss_n_40: 1.0982 (1.6984)  loss_n_60: 1.1097 (1.8394)  loss_n_80: 0.9592 (1.6055)  loss_n_100: 0.8458 (1.5774)  triple_100: 0.0000 (0.0495)  triple_80: 0.0000 (0.0244)  triple_60: 0.0000 (0.0372)  triple_40: 0.0000 (0.0435)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1100/1724]  eta: 0:40:44  lr: 0.000100  loss: 4.0868 (6.8572)  loss_n_40: 1.1029 (1.6960)  loss_n_60: 1.0952 (1.8349)  loss_n_80: 0.9592 (1.6007)  loss_n_100: 0.8691 (1.5722)  triple_100: 0.0000 (0.0492)  triple_80: 0.0000 (0.0242)  triple_60: 0.0000 (0.0369)  triple_40: 0.0000 (0.0431)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1110/1724]  eta: 0:40:05  lr: 0.000100  loss: 4.2305 (6.8353)  loss_n_40: 1.1289 (1.6920)  loss_n_60: 1.0863 (1.8290)  loss_n_80: 0.9491 (1.5956)  loss_n_100: 0.9103 (1.5665)  triple_100: 0.0000 (0.0487)  triple_80: 0.0000 (0.0240)  triple_60: 0.0000 (0.0366)  triple_40: 0.0000 (0.0428)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1120/1724]  eta: 0:39:26  lr: 0.000100  loss: 3.8161 (6.8107)  loss_n_40: 0.9976 (1.6868)  loss_n_60: 1.0101 (1.8224)  loss_n_80: 0.9205 (1.5901)  loss_n_100: 0.8879 (1.5606)  triple_100: 0.0000 (0.0483)  triple_80: 0.0000 (0.0238)  triple_60: 0.0000 (0.0362)  triple_40: 0.0000 (0.0425)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1130/1724]  eta: 0:38:47  lr: 0.000100  loss: 4.1510 (6.7908)  loss_n_40: 1.1254 (1.6834)  loss_n_60: 1.1088 (1.8171)  loss_n_80: 1.0043 (1.5853)  loss_n_100: 0.8980 (1.5552)  triple_100: 0.0000 (0.0479)  triple_80: 0.0000 (0.0236)  triple_60: 0.0000 (0.0359)  triple_40: 0.0000 (0.0425)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1140/1724]  eta: 0:38:08  lr: 0.000100  loss: 4.4731 (6.7732)  loss_n_40: 1.2856 (1.6810)  loss_n_60: 1.2698 (1.8126)  loss_n_80: 1.0377 (1.5806)  loss_n_100: 0.9098 (1.5501)  triple_100: 0.0000 (0.0475)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0359)  triple_40: 0.0000 (0.0422)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1150/1724]  eta: 0:37:28  lr: 0.000100  loss: 4.5492 (6.7589)  loss_n_40: 1.3033 (1.6791)  loss_n_60: 1.2425 (1.8086)  loss_n_80: 1.0386 (1.5772)  loss_n_100: 0.9423 (1.5464)  triple_100: 0.0000 (0.0471)  triple_80: 0.0000 (0.0231)  triple_60: 0.0000 (0.0356)  triple_40: 0.0000 (0.0419)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1160/1724]  eta: 0:36:49  lr: 0.000100  loss: 4.2871 (6.7392)  loss_n_40: 1.0747 (1.6750)  loss_n_60: 1.0714 (1.8029)  loss_n_80: 0.9475 (1.5725)  loss_n_100: 0.9558 (1.5414)  triple_100: 0.0000 (0.0467)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0353)  triple_40: 0.0000 (0.0423)  time: 3.9172  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [1170/1724]  eta: 0:36:10  lr: 0.000100  loss: 5.1870 (6.7519)  loss_n_40: 1.1907 (1.6737)  loss_n_60: 1.3683 (1.8017)  loss_n_80: 1.2408 (1.5747)  loss_n_100: 1.1599 (1.5442)  triple_100: 0.0000 (0.0477)  triple_80: 0.0000 (0.0247)  triple_60: 0.0000 (0.0417)  triple_40: 0.0000 (0.0434)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1180/1724]  eta: 0:35:31  lr: 0.000100  loss: 6.4114 (6.7498)  loss_n_40: 1.4723 (1.6731)  loss_n_60: 1.6276 (1.8007)  loss_n_80: 1.5683 (1.5745)  loss_n_100: 1.7481 (1.5453)  triple_100: 0.0000 (0.0473)  triple_80: 0.0000 (0.0245)  triple_60: 0.0000 (0.0413)  triple_40: 0.0000 (0.0430)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1190/1724]  eta: 0:34:52  lr: 0.000100  loss: 6.4114 (6.7553)  loss_n_40: 1.6331 (1.6742)  loss_n_60: 1.6931 (1.8004)  loss_n_80: 1.5679 (1.5751)  loss_n_100: 1.7040 (1.5472)  triple_100: 0.0000 (0.0472)  triple_80: 0.0000 (0.0244)  triple_60: 0.0000 (0.0424)  triple_40: 0.0000 (0.0443)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1200/1724]  eta: 0:34:12  lr: 0.000100  loss: 6.7110 (6.7529)  loss_n_40: 1.4087 (1.6718)  loss_n_60: 1.5455 (1.7975)  loss_n_80: 1.6613 (1.5755)  loss_n_100: 1.7040 (1.5478)  triple_100: 0.0000 (0.0478)  triple_80: 0.0000 (0.0249)  triple_60: 0.0000 (0.0436)  triple_40: 0.0000 (0.0440)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1210/1724]  eta: 0:33:33  lr: 0.000100  loss: 6.1369 (6.7818)  loss_n_40: 1.2643 (1.6693)  loss_n_60: 1.3564 (1.7935)  loss_n_80: 1.4205 (1.5745)  loss_n_100: 1.6359 (1.5496)  triple_100: 0.0000 (0.0647)  triple_80: 0.0000 (0.0374)  triple_60: 0.0000 (0.0453)  triple_40: 0.0000 (0.0474)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1220/1724]  eta: 0:32:54  lr: 0.000100  loss: 12.3133 (6.8503)  loss_n_40: 1.7284 (1.6811)  loss_n_60: 1.6458 (1.8096)  loss_n_80: 2.1232 (1.5931)  loss_n_100: 2.4214 (1.5697)  triple_100: 0.0000 (0.0676)  triple_80: 0.0000 (0.0372)  triple_60: 0.0000 (0.0450)  triple_40: 0.0000 (0.0470)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1230/1724]  eta: 0:32:15  lr: 0.000100  loss: 16.4270 (6.9429)  loss_n_40: 3.6171 (1.6997)  loss_n_60: 4.1752 (1.8311)  loss_n_80: 4.1338 (1.6151)  loss_n_100: 4.1431 (1.5925)  triple_100: 0.0000 (0.0690)  triple_80: 0.0000 (0.0409)  triple_60: 0.0000 (0.0446)  triple_40: 0.0000 (0.0499)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1240/1724]  eta: 0:31:36  lr: 0.000100  loss: 16.4540 (7.0142)  loss_n_40: 3.6171 (1.7136)  loss_n_60: 4.2042 (1.8491)  loss_n_80: 4.1795 (1.6357)  loss_n_100: 4.1027 (1.6117)  triple_100: 0.0000 (0.0692)  triple_80: 0.0000 (0.0406)  triple_60: 0.0000 (0.0449)  triple_40: 0.0000 (0.0495)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1250/1724]  eta: 0:30:57  lr: 0.000100  loss: 14.9297 (7.0689)  loss_n_40: 3.2086 (1.7238)  loss_n_60: 3.8508 (1.8617)  loss_n_80: 4.0133 (1.6532)  loss_n_100: 3.7779 (1.6273)  triple_100: 0.0000 (0.0686)  triple_80: 0.0000 (0.0403)  triple_60: 0.0000 (0.0445)  triple_40: 0.0000 (0.0496)  time: 3.9183  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [1260/1724]  eta: 0:30:17  lr: 0.000100  loss: 13.6608 (7.1271)  loss_n_40: 2.8431 (1.7319)  loss_n_60: 3.1999 (1.8713)  loss_n_80: 3.4949 (1.6682)  loss_n_100: 3.4687 (1.6415)  triple_100: 0.0000 (0.0717)  triple_80: 0.0000 (0.0446)  triple_60: 0.0000 (0.0481)  triple_40: 0.0000 (0.0498)  time: 3.9181  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [1270/1724]  eta: 0:29:38  lr: 0.000100  loss: 15.8501 (7.1982)  loss_n_40: 3.0649 (1.7443)  loss_n_60: 3.5628 (1.8896)  loss_n_80: 4.0737 (1.6889)  loss_n_100: 3.9301 (1.6612)  triple_100: 0.0000 (0.0711)  triple_80: 0.0000 (0.0457)  triple_60: 0.0000 (0.0479)  triple_40: 0.0000 (0.0494)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1280/1724]  eta: 0:28:59  lr: 0.000100  loss: 15.8501 (7.2651)  loss_n_40: 3.1994 (1.7551)  loss_n_60: 3.9489 (1.9041)  loss_n_80: 4.1218 (1.7068)  loss_n_100: 3.9229 (1.6768)  triple_100: 0.0000 (0.0706)  triple_80: 0.0000 (0.0476)  triple_60: 0.0000 (0.0551)  triple_40: 0.0000 (0.0490)  time: 3.9220  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [1290/1724]  eta: 0:28:20  lr: 0.000100  loss: 13.3407 (7.3035)  loss_n_40: 2.8818 (1.7619)  loss_n_60: 3.2522 (1.9109)  loss_n_80: 3.7563 (1.7200)  loss_n_100: 3.4314 (1.6892)  triple_100: 0.0000 (0.0700)  triple_80: 0.0000 (0.0473)  triple_60: 0.0000 (0.0556)  triple_40: 0.0000 (0.0487)  time: 3.9245  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [1300/1724]  eta: 0:27:41  lr: 0.000100  loss: 11.3011 (7.3307)  loss_n_40: 2.4721 (1.7661)  loss_n_60: 2.4377 (1.9141)  loss_n_80: 3.0615 (1.7297)  loss_n_100: 3.1485 (1.6998)  triple_100: 0.0000 (0.0695)  triple_80: 0.0000 (0.0477)  triple_60: 0.0000 (0.0551)  triple_40: 0.0000 (0.0488)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1310/1724]  eta: 0:27:02  lr: 0.000100  loss: 10.0022 (7.3464)  loss_n_40: 2.1940 (1.7695)  loss_n_60: 2.2079 (1.9158)  loss_n_80: 2.6742 (1.7351)  loss_n_100: 2.8464 (1.7066)  triple_100: 0.0000 (0.0689)  triple_80: 0.0000 (0.0473)  triple_60: 0.0000 (0.0547)  triple_40: 0.0000 (0.0484)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1320/1724]  eta: 0:26:22  lr: 0.000100  loss: 8.9204 (7.3549)  loss_n_40: 1.9756 (1.7705)  loss_n_60: 2.0263 (1.9159)  loss_n_80: 2.3274 (1.7388)  loss_n_100: 2.4600 (1.7120)  triple_100: 0.0000 (0.0684)  triple_80: 0.0000 (0.0469)  triple_60: 0.0000 (0.0543)  triple_40: 0.0000 (0.0480)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1330/1724]  eta: 0:25:43  lr: 0.000100  loss: 7.9781 (7.3584)  loss_n_40: 1.7557 (1.7699)  loss_n_60: 1.8096 (1.9149)  loss_n_80: 2.0974 (1.7410)  loss_n_100: 2.3233 (1.7161)  triple_100: 0.0000 (0.0680)  triple_80: 0.0000 (0.0466)  triple_60: 0.0000 (0.0542)  triple_40: 0.0000 (0.0477)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1340/1724]  eta: 0:25:04  lr: 0.000100  loss: 7.3828 (7.3562)  loss_n_40: 1.6079 (1.7686)  loss_n_60: 1.6880 (1.9127)  loss_n_80: 1.9223 (1.7415)  loss_n_100: 2.1474 (1.7185)  triple_100: 0.0000 (0.0675)  triple_80: 0.0000 (0.0462)  triple_60: 0.0000 (0.0538)  triple_40: 0.0000 (0.0473)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1350/1724]  eta: 0:24:25  lr: 0.000100  loss: 7.2434 (7.3846)  loss_n_40: 1.6430 (1.7706)  loss_n_60: 1.6768 (1.9153)  loss_n_80: 1.8223 (1.7479)  loss_n_100: 2.0284 (1.7258)  triple_100: 0.0000 (0.0685)  triple_80: 0.0000 (0.0508)  triple_60: 0.0000 (0.0577)  triple_40: 0.0000 (0.0480)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1360/1724]  eta: 0:23:46  lr: 0.000100  loss: 13.5711 (7.4374)  loss_n_40: 2.8776 (1.7803)  loss_n_60: 3.3896 (1.9281)  loss_n_80: 3.5517 (1.7635)  loss_n_100: 3.4167 (1.7404)  triple_100: 0.0000 (0.0680)  triple_80: 0.0000 (0.0504)  triple_60: 0.0000 (0.0574)  triple_40: 0.0000 (0.0493)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1370/1724]  eta: 0:23:07  lr: 0.000100  loss: 13.6238 (7.4785)  loss_n_40: 2.9883 (1.7876)  loss_n_60: 3.4218 (1.9379)  loss_n_80: 3.7447 (1.7772)  loss_n_100: 3.5336 (1.7524)  triple_100: 0.0000 (0.0675)  triple_80: 0.0000 (0.0501)  triple_60: 0.0000 (0.0570)  triple_40: 0.0000 (0.0489)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1380/1724]  eta: 0:22:27  lr: 0.000100  loss: 12.1579 (7.5090)  loss_n_40: 2.6831 (1.7933)  loss_n_60: 3.0439 (1.9447)  loss_n_80: 3.4243 (1.7873)  loss_n_100: 3.1762 (1.7613)  triple_100: 0.0000 (0.0670)  triple_80: 0.0000 (0.0500)  triple_60: 0.0000 (0.0566)  triple_40: 0.0000 (0.0488)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1390/1724]  eta: 0:21:48  lr: 0.000100  loss: 11.4017 (7.5338)  loss_n_40: 2.3828 (1.7963)  loss_n_60: 2.8384 (1.9506)  loss_n_80: 3.1693 (1.7968)  loss_n_100: 2.9878 (1.7692)  triple_100: 0.0000 (0.0665)  triple_80: 0.0000 (0.0497)  triple_60: 0.0000 (0.0562)  triple_40: 0.0000 (0.0484)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1400/1724]  eta: 0:21:09  lr: 0.000100  loss: 10.5743 (7.5541)  loss_n_40: 2.1475 (1.7991)  loss_n_60: 2.6237 (1.9550)  loss_n_80: 2.9784 (1.8045)  loss_n_100: 2.8544 (1.7762)  triple_100: 0.0000 (0.0660)  triple_80: 0.0000 (0.0493)  triple_60: 0.0000 (0.0558)  triple_40: 0.0000 (0.0481)  time: 3.9288  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [1410/1724]  eta: 0:20:30  lr: 0.000100  loss: 9.6671 (7.5674)  loss_n_40: 2.0041 (1.8003)  loss_n_60: 2.3753 (1.9576)  loss_n_80: 2.7049 (1.8104)  loss_n_100: 2.6405 (1.7815)  triple_100: 0.0000 (0.0656)  triple_80: 0.0000 (0.0490)  triple_60: 0.0000 (0.0554)  triple_40: 0.0000 (0.0477)  time: 3.9299  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1420/1724]  eta: 0:19:51  lr: 0.000100  loss: 9.3179 (7.5792)  loss_n_40: 1.9753 (1.8019)  loss_n_60: 2.2368 (1.9592)  loss_n_80: 2.5201 (1.8149)  loss_n_100: 2.5230 (1.7862)  triple_100: 0.0000 (0.0651)  triple_80: 0.0000 (0.0486)  triple_60: 0.0000 (0.0550)  triple_40: 0.0000 (0.0483)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1430/1724]  eta: 0:19:12  lr: 0.000100  loss: 9.1335 (7.5898)  loss_n_40: 1.9206 (1.8023)  loss_n_60: 2.1612 (1.9606)  loss_n_80: 2.4536 (1.8196)  loss_n_100: 2.5119 (1.7917)  triple_100: 0.0000 (0.0647)  triple_80: 0.0000 (0.0483)  triple_60: 0.0000 (0.0546)  triple_40: 0.0000 (0.0480)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1440/1724]  eta: 0:18:33  lr: 0.000100  loss: 8.6942 (7.5963)  loss_n_40: 1.8054 (1.8024)  loss_n_60: 2.0796 (1.9608)  loss_n_80: 2.3503 (1.8226)  loss_n_100: 2.5156 (1.7961)  triple_100: 0.0000 (0.0642)  triple_80: 0.0000 (0.0483)  triple_60: 0.0000 (0.0542)  triple_40: 0.0000 (0.0477)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1450/1724]  eta: 0:17:53  lr: 0.000100  loss: 8.1928 (7.5986)  loss_n_40: 1.7417 (1.8020)  loss_n_60: 1.9088 (1.9602)  loss_n_80: 2.1791 (1.8243)  loss_n_100: 2.3710 (1.7992)  triple_100: 0.0000 (0.0638)  triple_80: 0.0000 (0.0480)  triple_60: 0.0000 (0.0538)  triple_40: 0.0000 (0.0473)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1460/1724]  eta: 0:17:14  lr: 0.000100  loss: 7.3811 (7.5952)  loss_n_40: 1.6788 (1.8015)  loss_n_60: 1.8206 (1.9586)  loss_n_80: 1.8758 (1.8239)  loss_n_100: 2.0156 (1.7997)  triple_100: 0.0000 (0.0633)  triple_80: 0.0000 (0.0476)  triple_60: 0.0000 (0.0535)  triple_40: 0.0000 (0.0470)  time: 3.9283  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1470/1724]  eta: 0:16:35  lr: 0.000100  loss: 7.1468 (7.5918)  loss_n_40: 1.5268 (1.7994)  loss_n_60: 1.6660 (1.9562)  loss_n_80: 1.8010 (1.8243)  loss_n_100: 1.9590 (1.8019)  triple_100: 0.0000 (0.0629)  triple_80: 0.0000 (0.0473)  triple_60: 0.0000 (0.0531)  triple_40: 0.0000 (0.0467)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1480/1724]  eta: 0:15:56  lr: 0.000100  loss: 6.8773 (7.5847)  loss_n_40: 1.4319 (1.7971)  loss_n_60: 1.5855 (1.9533)  loss_n_80: 1.7867 (1.8235)  loss_n_100: 1.9977 (1.8023)  triple_100: 0.0000 (0.0625)  triple_80: 0.0000 (0.0470)  triple_60: 0.0000 (0.0527)  triple_40: 0.0000 (0.0464)  time: 3.9312  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [1490/1724]  eta: 0:15:17  lr: 0.000100  loss: 6.0099 (7.5733)  loss_n_40: 1.3038 (1.7936)  loss_n_60: 1.4031 (1.9491)  loss_n_80: 1.5738 (1.8217)  loss_n_100: 1.7668 (1.8017)  triple_100: 0.0000 (0.0621)  triple_80: 0.0000 (0.0467)  triple_60: 0.0000 (0.0524)  triple_40: 0.0000 (0.0461)  time: 3.9318  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [1500/1724]  eta: 0:14:37  lr: 0.000100  loss: 5.8290 (7.5623)  loss_n_40: 1.2262 (1.7900)  loss_n_60: 1.3152 (1.9448)  loss_n_80: 1.5330 (1.8197)  loss_n_100: 1.7284 (1.8009)  triple_100: 0.0000 (0.0623)  triple_80: 0.0000 (0.0464)  triple_60: 0.0000 (0.0525)  triple_40: 0.0000 (0.0458)  time: 3.9311  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1510/1724]  eta: 0:13:58  lr: 0.000100  loss: 5.8729 (7.5527)  loss_n_40: 1.2464 (1.7877)  loss_n_60: 1.3567 (1.9414)  loss_n_80: 1.5227 (1.8179)  loss_n_100: 1.6157 (1.7999)  triple_100: 0.0000 (0.0619)  triple_80: 0.0000 (0.0461)  triple_60: 0.0000 (0.0521)  triple_40: 0.0000 (0.0458)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1520/1724]  eta: 0:13:19  lr: 0.000100  loss: 5.7779 (7.5396)  loss_n_40: 1.2256 (1.7843)  loss_n_60: 1.2969 (1.9367)  loss_n_80: 1.4954 (1.8155)  loss_n_100: 1.6157 (1.7986)  triple_100: 0.0000 (0.0615)  triple_80: 0.0000 (0.0458)  triple_60: 0.0000 (0.0518)  triple_40: 0.0000 (0.0455)  time: 3.9307  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1530/1724]  eta: 0:12:40  lr: 0.000100  loss: 5.4819 (7.5260)  loss_n_40: 1.2174 (1.7809)  loss_n_60: 1.2319 (1.9324)  loss_n_80: 1.4609 (1.8129)  loss_n_100: 1.5831 (1.7967)  triple_100: 0.0000 (0.0611)  triple_80: 0.0000 (0.0455)  triple_60: 0.0000 (0.0515)  triple_40: 0.0000 (0.0452)  time: 3.9312  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1540/1724]  eta: 0:12:01  lr: 0.000100  loss: 5.1309 (7.5094)  loss_n_40: 1.1360 (1.7765)  loss_n_60: 1.1864 (1.9272)  loss_n_80: 1.3589 (1.8096)  loss_n_100: 1.4234 (1.7943)  triple_100: 0.0000 (0.0607)  triple_80: 0.0000 (0.0452)  triple_60: 0.0000 (0.0511)  triple_40: 0.0000 (0.0449)  time: 3.9312  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1550/1724]  eta: 0:11:22  lr: 0.000100  loss: 5.0775 (7.4959)  loss_n_40: 1.0966 (1.7725)  loss_n_60: 1.1450 (1.9226)  loss_n_80: 1.3342 (1.8068)  loss_n_100: 1.4544 (1.7924)  triple_100: 0.0000 (0.0603)  triple_80: 0.0000 (0.0449)  triple_60: 0.0000 (0.0508)  triple_40: 0.0000 (0.0456)  time: 3.9311  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1560/1724]  eta: 0:10:42  lr: 0.000100  loss: 5.0135 (7.4805)  loss_n_40: 1.0961 (1.7685)  loss_n_60: 1.1493 (1.9176)  loss_n_80: 1.3322 (1.8035)  loss_n_100: 1.4743 (1.7900)  triple_100: 0.0000 (0.0599)  triple_80: 0.0000 (0.0446)  triple_60: 0.0000 (0.0505)  triple_40: 0.0000 (0.0459)  time: 3.9314  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1570/1724]  eta: 0:10:03  lr: 0.000100  loss: 4.9583 (7.4647)  loss_n_40: 1.1084 (1.7647)  loss_n_60: 1.1211 (1.9128)  loss_n_80: 1.2891 (1.8002)  loss_n_100: 1.4034 (1.7874)  triple_100: 0.0000 (0.0595)  triple_80: 0.0000 (0.0443)  triple_60: 0.0000 (0.0501)  triple_40: 0.0000 (0.0456)  time: 3.9310  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1580/1724]  eta: 0:09:24  lr: 0.000100  loss: 4.9466 (7.4510)  loss_n_40: 1.1070 (1.7614)  loss_n_60: 1.1323 (1.9082)  loss_n_80: 1.2631 (1.7968)  loss_n_100: 1.3359 (1.7846)  triple_100: 0.0000 (0.0599)  triple_80: 0.0000 (0.0440)  triple_60: 0.0000 (0.0504)  triple_40: 0.0000 (0.0457)  time: 3.9303  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1590/1724]  eta: 0:08:45  lr: 0.000100  loss: 4.9466 (7.4353)  loss_n_40: 1.0770 (1.7576)  loss_n_60: 1.1323 (1.9034)  loss_n_80: 1.2478 (1.7935)  loss_n_100: 1.3359 (1.7820)  triple_100: 0.0000 (0.0595)  triple_80: 0.0000 (0.0438)  triple_60: 0.0000 (0.0501)  triple_40: 0.0000 (0.0454)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1600/1724]  eta: 0:08:06  lr: 0.000100  loss: 4.5694 (7.4163)  loss_n_40: 0.9719 (1.7528)  loss_n_60: 1.0592 (1.8978)  loss_n_80: 1.2252 (1.7894)  loss_n_100: 1.3144 (1.7787)  triple_100: 0.0000 (0.0591)  triple_80: 0.0000 (0.0435)  triple_60: 0.0000 (0.0498)  triple_40: 0.0000 (0.0452)  time: 3.9304  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1610/1724]  eta: 0:07:26  lr: 0.000100  loss: 4.3549 (7.3984)  loss_n_40: 0.9586 (1.7486)  loss_n_60: 0.9964 (1.8925)  loss_n_80: 1.1163 (1.7854)  loss_n_100: 1.2238 (1.7754)  triple_100: 0.0000 (0.0588)  triple_80: 0.0000 (0.0432)  triple_60: 0.0000 (0.0497)  triple_40: 0.0000 (0.0449)  time: 3.9305  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [1620/1724]  eta: 0:06:47  lr: 0.000100  loss: 4.5624 (7.3828)  loss_n_40: 1.0546 (1.7451)  loss_n_60: 1.0679 (1.8879)  loss_n_80: 1.1468 (1.7818)  loss_n_100: 1.2742 (1.7726)  triple_100: 0.0000 (0.0584)  triple_80: 0.0000 (0.0430)  triple_60: 0.0000 (0.0494)  triple_40: 0.0000 (0.0446)  time: 3.9309  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1630/1724]  eta: 0:06:08  lr: 0.000100  loss: 4.5768 (7.3647)  loss_n_40: 1.0322 (1.7407)  loss_n_60: 1.0783 (1.8828)  loss_n_80: 1.1241 (1.7776)  loss_n_100: 1.2742 (1.7694)  triple_100: 0.0000 (0.0581)  triple_80: 0.0000 (0.0427)  triple_60: 0.0000 (0.0491)  triple_40: 0.0000 (0.0443)  time: 3.9317  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1640/1724]  eta: 0:05:29  lr: 0.000100  loss: 4.3556 (7.3455)  loss_n_40: 0.9939 (1.7362)  loss_n_60: 1.0130 (1.8774)  loss_n_80: 1.0803 (1.7732)  loss_n_100: 1.2301 (1.7658)  triple_100: 0.0000 (0.0577)  triple_80: 0.0000 (0.0424)  triple_60: 0.0000 (0.0488)  triple_40: 0.0000 (0.0441)  time: 3.9320  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [1650/1724]  eta: 0:04:50  lr: 0.000100  loss: 4.2708 (7.3272)  loss_n_40: 0.9830 (1.7321)  loss_n_60: 1.0057 (1.8722)  loss_n_80: 1.0489 (1.7688)  loss_n_100: 1.2073 (1.7623)  triple_100: 0.0000 (0.0574)  triple_80: 0.0000 (0.0422)  triple_60: 0.0000 (0.0485)  triple_40: 0.0000 (0.0438)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1660/1724]  eta: 0:04:10  lr: 0.000100  loss: 4.2517 (7.3092)  loss_n_40: 0.9477 (1.7279)  loss_n_60: 1.0137 (1.8672)  loss_n_80: 1.0589 (1.7646)  loss_n_100: 1.2073 (1.7588)  triple_100: 0.0000 (0.0570)  triple_80: 0.0000 (0.0419)  triple_60: 0.0000 (0.0482)  triple_40: 0.0000 (0.0435)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1670/1724]  eta: 0:03:31  lr: 0.000100  loss: 4.1508 (7.2898)  loss_n_40: 0.9387 (1.7232)  loss_n_60: 0.9652 (1.8617)  loss_n_80: 1.0157 (1.7599)  loss_n_100: 1.1447 (1.7547)  triple_100: 0.0000 (0.0572)  triple_80: 0.0000 (0.0417)  triple_60: 0.0000 (0.0481)  triple_40: 0.0000 (0.0433)  time: 3.9301  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1680/1724]  eta: 0:02:52  lr: 0.000100  loss: 4.1534 (7.2757)  loss_n_40: 0.9622 (1.7195)  loss_n_60: 0.9610 (1.8572)  loss_n_80: 0.9859 (1.7563)  loss_n_100: 1.1391 (1.7519)  triple_100: 0.0000 (0.0572)  triple_80: 0.0000 (0.0419)  triple_60: 0.0000 (0.0478)  triple_40: 0.0000 (0.0438)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1690/1724]  eta: 0:02:13  lr: 0.000100  loss: 4.8055 (7.2617)  loss_n_40: 0.9942 (1.7156)  loss_n_60: 1.1564 (1.8530)  loss_n_80: 1.1641 (1.7529)  loss_n_100: 1.3404 (1.7498)  triple_100: 0.0000 (0.0574)  triple_80: 0.0000 (0.0417)  triple_60: 0.0000 (0.0478)  triple_40: 0.0000 (0.0435)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1700/1724]  eta: 0:01:34  lr: 0.000100  loss: 4.6080 (7.2455)  loss_n_40: 1.0172 (1.7119)  loss_n_60: 1.0913 (1.8484)  loss_n_80: 1.1545 (1.7490)  loss_n_100: 1.3332 (1.7467)  triple_100: 0.0000 (0.0571)  triple_80: 0.0000 (0.0414)  triple_60: 0.0000 (0.0475)  triple_40: 0.0000 (0.0433)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6]  [1710/1724]  eta: 0:00:54  lr: 0.000100  loss: 4.2948 (7.2259)  loss_n_40: 0.9870 (1.7073)  loss_n_60: 1.0180 (1.8431)  loss_n_80: 1.0342 (1.7444)  loss_n_100: 1.1539 (1.7429)  triple_100: 0.0000 (0.0568)  triple_80: 0.0000 (0.0412)  triple_60: 0.0000 (0.0473)  triple_40: 0.0000 (0.0430)  time: 3.9287  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [1720/1724]  eta: 0:00:15  lr: 0.000100  loss: 4.1335 (7.2088)  loss_n_40: 0.9432 (1.7037)  loss_n_60: 1.0019 (1.8384)  loss_n_80: 1.0040 (1.7402)  loss_n_100: 1.1026 (1.7394)  triple_100: 0.0000 (0.0564)  triple_80: 0.0000 (0.0409)  triple_60: 0.0000 (0.0470)  triple_40: 0.0000 (0.0428)  time: 3.9295  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:6]  [1723/1724]  eta: 0:00:03  lr: 0.000100  loss: 4.1335 (7.2039)  loss_n_40: 0.9624 (1.7025)  loss_n_60: 1.0038 (1.8370)  loss_n_80: 1.0379 (1.7390)  loss_n_100: 1.1026 (1.7385)  triple_100: 0.0000 (0.0563)  triple_80: 0.0000 (0.0409)  triple_60: 0.0000 (0.0469)  triple_40: 0.0000 (0.0427)  time: 3.9300  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:6] Total time: 1:52:39 (3.9211 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 4.1335 (7.2039)  loss_n_40: 0.9624 (1.7025)  loss_n_60: 1.0038 (1.8370)  loss_n_80: 1.0379 (1.7390)  loss_n_100: 1.1026 (1.7385)  triple_100: 0.0000 (0.0563)  triple_80: 0.0000 (0.0409)  triple_60: 0.0000 (0.0469)  triple_40: 0.0000 (0.0427)\n",
      "Valid: [epoch:6]  [  0/845]  eta: 0:10:50  loss: 3.2264 (3.2264)  loss_n_40: 0.7693 (0.7693)  loss_n_60: 0.7735 (0.7735)  loss_n_80: 0.7919 (0.7919)  loss_n_100: 0.8918 (0.8918)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7698  data: 0.4317  max mem: 46473\n",
      "Valid: [epoch:6]  [ 10/845]  eta: 0:05:12  loss: 4.0081 (3.9288)  loss_n_40: 0.7925 (0.9207)  loss_n_60: 0.9254 (0.9311)  loss_n_80: 1.0086 (0.9553)  loss_n_100: 1.1500 (1.1218)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3745  data: 0.0394  max mem: 46473\n",
      "Valid: [epoch:6]  [ 20/845]  eta: 0:04:53  loss: 3.7850 (4.1189)  loss_n_40: 0.7925 (1.0430)  loss_n_60: 0.8621 (0.9894)  loss_n_80: 0.9093 (0.9846)  loss_n_100: 1.1040 (1.1018)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [ 30/845]  eta: 0:04:44  loss: 3.5861 (4.0090)  loss_n_40: 0.7869 (0.9952)  loss_n_60: 0.8923 (0.9634)  loss_n_80: 0.8770 (0.9665)  loss_n_100: 1.0478 (1.0840)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [ 40/845]  eta: 0:04:38  loss: 3.7803 (3.9602)  loss_n_40: 0.7752 (0.9604)  loss_n_60: 0.9316 (0.9542)  loss_n_80: 0.9727 (0.9611)  loss_n_100: 1.0152 (1.0845)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [ 50/845]  eta: 0:04:32  loss: 3.9469 (4.0882)  loss_n_40: 0.7671 (1.0321)  loss_n_60: 0.9710 (0.9810)  loss_n_80: 0.9298 (0.9630)  loss_n_100: 1.0373 (1.0742)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0379)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [ 60/845]  eta: 0:04:28  loss: 3.3472 (3.9902)  loss_n_40: 0.7671 (0.9942)  loss_n_60: 0.8262 (0.9563)  loss_n_80: 0.8160 (0.9458)  loss_n_100: 0.9499 (1.0621)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0317)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [ 70/845]  eta: 0:04:24  loss: 3.1880 (3.9147)  loss_n_40: 0.7342 (0.9649)  loss_n_60: 0.7561 (0.9361)  loss_n_80: 0.8092 (0.9313)  loss_n_100: 0.9400 (1.0552)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0272)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [ 80/845]  eta: 0:04:20  loss: 3.3543 (3.8749)  loss_n_40: 0.7585 (0.9513)  loss_n_60: 0.7888 (0.9244)  loss_n_80: 0.8423 (0.9235)  loss_n_100: 0.9955 (1.0518)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0239)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [ 90/845]  eta: 0:04:16  loss: 3.5758 (3.9260)  loss_n_40: 0.7995 (0.9763)  loss_n_60: 0.8745 (0.9363)  loss_n_80: 0.8698 (0.9331)  loss_n_100: 1.0352 (1.0591)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0212)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [100/845]  eta: 0:04:12  loss: 3.7293 (3.8877)  loss_n_40: 0.7817 (0.9586)  loss_n_60: 0.8752 (0.9275)  loss_n_80: 0.9225 (0.9280)  loss_n_100: 1.0430 (1.0544)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0191)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [110/845]  eta: 0:04:09  loss: 3.3995 (3.9173)  loss_n_40: 0.7796 (0.9730)  loss_n_60: 0.8426 (0.9363)  loss_n_80: 0.8872 (0.9341)  loss_n_100: 1.0011 (1.0564)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0174)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [120/845]  eta: 0:04:05  loss: 3.9463 (3.9418)  loss_n_40: 0.7880 (0.9867)  loss_n_60: 0.9026 (0.9417)  loss_n_80: 0.9268 (0.9367)  loss_n_100: 1.0806 (1.0608)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0160)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [130/845]  eta: 0:04:01  loss: 3.4849 (3.9200)  loss_n_40: 0.7412 (0.9739)  loss_n_60: 0.8613 (0.9360)  loss_n_80: 0.8744 (0.9345)  loss_n_100: 1.0806 (1.0609)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0148)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [140/845]  eta: 0:03:58  loss: 3.5816 (3.9280)  loss_n_40: 0.7721 (0.9717)  loss_n_60: 0.8227 (0.9373)  loss_n_80: 0.8791 (0.9382)  loss_n_100: 1.1258 (1.0670)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0137)  time: 0.3350  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:6]  [150/845]  eta: 0:03:54  loss: 4.1119 (3.9397)  loss_n_40: 0.8806 (0.9768)  loss_n_60: 0.9130 (0.9399)  loss_n_80: 0.9572 (0.9396)  loss_n_100: 1.1258 (1.0706)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0128)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [160/845]  eta: 0:03:51  loss: 3.7045 (3.9457)  loss_n_40: 0.7907 (0.9834)  loss_n_60: 0.9130 (0.9424)  loss_n_80: 0.9447 (0.9395)  loss_n_100: 1.0250 (1.0684)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0120)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [170/845]  eta: 0:03:47  loss: 3.7045 (3.9781)  loss_n_40: 0.7907 (0.9994)  loss_n_60: 0.8491 (0.9519)  loss_n_80: 0.9067 (0.9440)  loss_n_100: 1.0250 (1.0714)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0113)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [180/845]  eta: 0:03:44  loss: 3.5762 (3.9781)  loss_n_40: 0.8034 (0.9996)  loss_n_60: 0.8491 (0.9524)  loss_n_80: 0.8974 (0.9447)  loss_n_100: 1.0262 (1.0708)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0107)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [190/845]  eta: 0:03:40  loss: 3.4562 (3.9881)  loss_n_40: 0.8067 (1.0051)  loss_n_60: 0.8666 (0.9550)  loss_n_80: 0.8835 (0.9450)  loss_n_100: 0.9752 (1.0678)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0153)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [200/845]  eta: 0:03:37  loss: 3.6938 (3.9881)  loss_n_40: 0.8169 (1.0034)  loss_n_60: 0.8841 (0.9533)  loss_n_80: 0.9161 (0.9451)  loss_n_100: 0.9954 (1.0717)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0145)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [210/845]  eta: 0:03:33  loss: 3.6767 (3.9947)  loss_n_40: 0.8129 (1.0079)  loss_n_60: 0.9412 (0.9562)  loss_n_80: 0.8880 (0.9453)  loss_n_100: 1.0819 (1.0715)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0138)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [220/845]  eta: 0:03:30  loss: 3.5626 (3.9785)  loss_n_40: 0.7764 (0.9987)  loss_n_60: 0.8596 (0.9520)  loss_n_80: 0.8804 (0.9435)  loss_n_100: 1.0160 (1.0711)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0132)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [230/845]  eta: 0:03:27  loss: 3.5712 (3.9718)  loss_n_40: 0.7846 (0.9946)  loss_n_60: 0.8596 (0.9494)  loss_n_80: 0.9244 (0.9425)  loss_n_100: 1.0160 (1.0727)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0126)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [240/845]  eta: 0:03:23  loss: 3.9237 (3.9685)  loss_n_40: 0.8245 (0.9916)  loss_n_60: 0.9261 (0.9472)  loss_n_80: 0.9454 (0.9423)  loss_n_100: 1.1516 (1.0752)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0121)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [250/845]  eta: 0:03:20  loss: 3.7976 (3.9661)  loss_n_40: 0.8354 (0.9938)  loss_n_60: 0.8950 (0.9467)  loss_n_80: 0.9645 (0.9413)  loss_n_100: 1.0483 (1.0726)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0116)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [260/845]  eta: 0:03:16  loss: 3.7976 (3.9714)  loss_n_40: 0.7714 (0.9956)  loss_n_60: 0.9509 (0.9486)  loss_n_80: 0.9704 (0.9427)  loss_n_100: 1.0422 (1.0734)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0112)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [270/845]  eta: 0:03:13  loss: 3.9684 (3.9721)  loss_n_40: 0.8570 (0.9923)  loss_n_60: 0.9605 (0.9486)  loss_n_80: 1.0162 (0.9440)  loss_n_100: 1.1382 (1.0764)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0108)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [280/845]  eta: 0:03:10  loss: 4.0805 (3.9747)  loss_n_40: 0.8570 (0.9895)  loss_n_60: 0.9617 (0.9497)  loss_n_80: 1.0213 (0.9457)  loss_n_100: 1.0498 (1.0794)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0104)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [290/845]  eta: 0:03:06  loss: 3.6161 (3.9668)  loss_n_40: 0.8031 (0.9848)  loss_n_60: 0.8720 (0.9474)  loss_n_80: 0.9313 (0.9448)  loss_n_100: 1.0661 (1.0798)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0100)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [300/845]  eta: 0:03:03  loss: 3.8579 (3.9764)  loss_n_40: 0.8034 (0.9882)  loss_n_60: 0.8806 (0.9501)  loss_n_80: 0.9568 (0.9473)  loss_n_100: 1.0699 (1.0812)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0097)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [310/845]  eta: 0:02:59  loss: 4.1681 (3.9779)  loss_n_40: 0.8702 (0.9858)  loss_n_60: 0.9609 (0.9503)  loss_n_80: 1.0247 (0.9484)  loss_n_100: 1.1370 (1.0840)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0094)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [320/845]  eta: 0:02:56  loss: 3.7929 (3.9693)  loss_n_40: 0.8364 (0.9820)  loss_n_60: 0.9393 (0.9482)  loss_n_80: 0.9393 (0.9470)  loss_n_100: 1.1141 (1.0831)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0091)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [330/845]  eta: 0:02:53  loss: 3.8309 (3.9706)  loss_n_40: 0.8067 (0.9797)  loss_n_60: 0.9393 (0.9485)  loss_n_80: 0.9217 (0.9485)  loss_n_100: 1.0966 (1.0851)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0088)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [340/845]  eta: 0:02:49  loss: 3.9765 (3.9946)  loss_n_40: 0.8047 (0.9874)  loss_n_60: 0.9600 (0.9540)  loss_n_80: 0.9584 (0.9502)  loss_n_100: 1.1216 (1.0858)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0172)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [350/845]  eta: 0:02:46  loss: 4.0160 (4.0050)  loss_n_40: 0.8295 (0.9930)  loss_n_60: 0.9499 (0.9569)  loss_n_80: 0.9999 (0.9518)  loss_n_100: 1.1216 (1.0866)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0167)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [360/845]  eta: 0:02:42  loss: 3.9228 (4.0114)  loss_n_40: 0.8295 (0.9950)  loss_n_60: 0.9241 (0.9590)  loss_n_80: 0.9872 (0.9537)  loss_n_100: 1.0212 (1.0874)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0162)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [370/845]  eta: 0:02:39  loss: 3.8925 (4.0184)  loss_n_40: 0.8038 (0.9979)  loss_n_60: 0.9172 (0.9613)  loss_n_80: 0.9804 (0.9546)  loss_n_100: 1.0405 (1.0888)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0158)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [380/845]  eta: 0:02:36  loss: 4.1390 (4.0221)  loss_n_40: 0.8555 (0.9968)  loss_n_60: 0.9559 (0.9617)  loss_n_80: 0.9972 (0.9564)  loss_n_100: 1.2175 (1.0919)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0154)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [390/845]  eta: 0:02:32  loss: 4.1851 (4.0341)  loss_n_40: 0.8555 (0.9998)  loss_n_60: 0.9812 (0.9654)  loss_n_80: 1.0256 (0.9597)  loss_n_100: 1.2339 (1.0943)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0150)  time: 0.3347  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:6]  [400/845]  eta: 0:02:29  loss: 4.0321 (4.0332)  loss_n_40: 0.8032 (1.0011)  loss_n_60: 0.9966 (0.9648)  loss_n_80: 0.9914 (0.9593)  loss_n_100: 1.0633 (1.0934)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0146)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [410/845]  eta: 0:02:26  loss: 3.5513 (4.0317)  loss_n_40: 0.8007 (1.0000)  loss_n_60: 0.8462 (0.9640)  loss_n_80: 0.9071 (0.9592)  loss_n_100: 1.0380 (1.0942)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0142)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:6]  [420/845]  eta: 0:02:22  loss: 3.5180 (4.0243)  loss_n_40: 0.7569 (0.9964)  loss_n_60: 0.8462 (0.9620)  loss_n_80: 0.9071 (0.9579)  loss_n_100: 1.0253 (1.0941)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0139)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [430/845]  eta: 0:02:19  loss: 3.4168 (4.0208)  loss_n_40: 0.7772 (0.9962)  loss_n_60: 0.8341 (0.9615)  loss_n_80: 0.8657 (0.9569)  loss_n_100: 0.9937 (1.0926)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0136)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [440/845]  eta: 0:02:15  loss: 3.4494 (4.0170)  loss_n_40: 0.7974 (0.9952)  loss_n_60: 0.8451 (0.9603)  loss_n_80: 0.8657 (0.9564)  loss_n_100: 0.9937 (1.0918)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0133)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [450/845]  eta: 0:02:12  loss: 3.8445 (4.0214)  loss_n_40: 0.8342 (0.9969)  loss_n_60: 0.8683 (0.9616)  loss_n_80: 0.9215 (0.9572)  loss_n_100: 1.0674 (1.0928)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0130)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [460/845]  eta: 0:02:09  loss: 4.2941 (4.0341)  loss_n_40: 0.8436 (0.9997)  loss_n_60: 1.0152 (0.9643)  loss_n_80: 1.0468 (0.9602)  loss_n_100: 1.2206 (1.0972)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0127)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [470/845]  eta: 0:02:05  loss: 4.2034 (4.0259)  loss_n_40: 0.8055 (0.9981)  loss_n_60: 0.9931 (0.9627)  loss_n_80: 1.0059 (0.9580)  loss_n_100: 1.1151 (1.0947)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0124)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [480/845]  eta: 0:02:02  loss: 3.7063 (4.0364)  loss_n_40: 0.7901 (1.0028)  loss_n_60: 0.8719 (0.9657)  loss_n_80: 0.9406 (0.9600)  loss_n_100: 1.0546 (1.0958)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0122)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [490/845]  eta: 0:01:59  loss: 4.1775 (4.0384)  loss_n_40: 1.0180 (1.0029)  loss_n_60: 0.9871 (0.9662)  loss_n_80: 1.0233 (0.9609)  loss_n_100: 1.1586 (1.0964)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0119)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [500/845]  eta: 0:01:55  loss: 4.0623 (4.0368)  loss_n_40: 0.8323 (1.0006)  loss_n_60: 0.9573 (0.9659)  loss_n_80: 1.0233 (0.9613)  loss_n_100: 1.1227 (1.0972)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0117)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [510/845]  eta: 0:01:52  loss: 3.8763 (4.0326)  loss_n_40: 0.7853 (0.9981)  loss_n_60: 0.9005 (0.9646)  loss_n_80: 0.9808 (0.9606)  loss_n_100: 1.0826 (1.0979)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0115)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [520/845]  eta: 0:01:49  loss: 3.4373 (4.0319)  loss_n_40: 0.7900 (0.9980)  loss_n_60: 0.8664 (0.9644)  loss_n_80: 0.8561 (0.9607)  loss_n_100: 1.0149 (1.0975)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0112)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [530/845]  eta: 0:01:45  loss: 4.2422 (4.0520)  loss_n_40: 0.8285 (1.0056)  loss_n_60: 1.0084 (0.9705)  loss_n_80: 1.0302 (0.9641)  loss_n_100: 1.1732 (1.1007)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0110)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [540/845]  eta: 0:01:42  loss: 3.9109 (4.0483)  loss_n_40: 0.8125 (1.0046)  loss_n_60: 0.9783 (0.9699)  loss_n_80: 1.0014 (0.9636)  loss_n_100: 1.1483 (1.0994)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0108)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [550/845]  eta: 0:01:38  loss: 3.4474 (4.0407)  loss_n_40: 0.7628 (1.0015)  loss_n_60: 0.8188 (0.9681)  loss_n_80: 0.8526 (0.9627)  loss_n_100: 0.9781 (1.0978)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0106)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [560/845]  eta: 0:01:35  loss: 3.3867 (4.0363)  loss_n_40: 0.7923 (1.0003)  loss_n_60: 0.8085 (0.9669)  loss_n_80: 0.8390 (0.9619)  loss_n_100: 1.0010 (1.0968)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0104)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [570/845]  eta: 0:01:32  loss: 3.5077 (4.0456)  loss_n_40: 0.8216 (1.0052)  loss_n_60: 0.8607 (0.9697)  loss_n_80: 0.8937 (0.9634)  loss_n_100: 1.0207 (1.0970)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0102)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [580/845]  eta: 0:01:28  loss: 3.5806 (4.0394)  loss_n_40: 0.8216 (1.0030)  loss_n_60: 0.8631 (0.9684)  loss_n_80: 0.8937 (0.9619)  loss_n_100: 1.0471 (1.0960)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0101)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [590/845]  eta: 0:01:25  loss: 3.7494 (4.0389)  loss_n_40: 0.8080 (1.0015)  loss_n_60: 0.9058 (0.9683)  loss_n_80: 0.9163 (0.9624)  loss_n_100: 1.0228 (1.0967)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0099)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [600/845]  eta: 0:01:22  loss: 3.8069 (4.0371)  loss_n_40: 0.8336 (1.0018)  loss_n_60: 0.9411 (0.9680)  loss_n_80: 0.9615 (0.9617)  loss_n_100: 1.0310 (1.0959)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0097)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [610/845]  eta: 0:01:18  loss: 3.3188 (4.0316)  loss_n_40: 0.8014 (0.9996)  loss_n_60: 0.8339 (0.9665)  loss_n_80: 0.8411 (0.9606)  loss_n_100: 0.9737 (1.0953)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0096)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [620/845]  eta: 0:01:15  loss: 3.6274 (4.0301)  loss_n_40: 0.7747 (0.9990)  loss_n_60: 0.8692 (0.9664)  loss_n_80: 0.8815 (0.9602)  loss_n_100: 1.0286 (1.0951)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0094)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [630/845]  eta: 0:01:12  loss: 3.8272 (4.0340)  loss_n_40: 0.8167 (0.9997)  loss_n_60: 0.9628 (0.9683)  loss_n_80: 0.9317 (0.9615)  loss_n_100: 1.0295 (1.0953)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0093)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [640/845]  eta: 0:01:08  loss: 3.8181 (4.0292)  loss_n_40: 0.8130 (0.9973)  loss_n_60: 0.9189 (0.9672)  loss_n_80: 0.9160 (0.9608)  loss_n_100: 1.0295 (1.0948)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0091)  time: 0.3350  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:6]  [650/845]  eta: 0:01:05  loss: 3.4485 (4.0237)  loss_n_40: 0.7794 (0.9945)  loss_n_60: 0.8208 (0.9657)  loss_n_80: 0.8538 (0.9601)  loss_n_100: 1.0382 (1.0945)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0090)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [660/845]  eta: 0:01:02  loss: 3.6076 (4.0241)  loss_n_40: 0.7830 (0.9931)  loss_n_60: 0.8966 (0.9657)  loss_n_80: 0.8941 (0.9605)  loss_n_100: 1.0394 (1.0959)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0089)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [670/845]  eta: 0:00:58  loss: 3.7245 (4.0228)  loss_n_40: 0.8194 (0.9934)  loss_n_60: 0.8981 (0.9660)  loss_n_80: 0.9221 (0.9602)  loss_n_100: 1.0647 (1.0945)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0087)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [680/845]  eta: 0:00:55  loss: 3.4786 (4.0210)  loss_n_40: 0.7880 (0.9934)  loss_n_60: 0.8637 (0.9659)  loss_n_80: 0.8694 (0.9599)  loss_n_100: 0.9523 (1.0933)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0086)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [690/845]  eta: 0:00:51  loss: 3.5036 (4.0205)  loss_n_40: 0.7882 (0.9933)  loss_n_60: 0.8699 (0.9656)  loss_n_80: 0.9171 (0.9598)  loss_n_100: 1.0389 (1.0934)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0085)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [700/845]  eta: 0:00:48  loss: 3.4957 (4.0197)  loss_n_40: 0.7854 (0.9931)  loss_n_60: 0.8626 (0.9655)  loss_n_80: 0.8792 (0.9598)  loss_n_100: 1.0363 (1.0930)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0083)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [710/845]  eta: 0:00:45  loss: 3.4279 (4.0188)  loss_n_40: 0.7624 (0.9930)  loss_n_60: 0.8253 (0.9650)  loss_n_80: 0.8370 (0.9597)  loss_n_100: 1.0130 (1.0928)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0082)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [720/845]  eta: 0:00:41  loss: 3.4598 (4.0241)  loss_n_40: 0.7761 (0.9965)  loss_n_60: 0.8196 (0.9660)  loss_n_80: 0.8819 (0.9596)  loss_n_100: 0.9761 (1.0916)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0104)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [730/845]  eta: 0:00:38  loss: 3.5491 (4.0221)  loss_n_40: 0.7993 (0.9961)  loss_n_60: 0.8677 (0.9653)  loss_n_80: 0.8982 (0.9589)  loss_n_100: 1.0556 (1.0916)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0103)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [740/845]  eta: 0:00:35  loss: 3.7045 (4.0201)  loss_n_40: 0.8729 (0.9947)  loss_n_60: 0.8832 (0.9648)  loss_n_80: 0.9002 (0.9586)  loss_n_100: 1.0880 (1.0919)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0101)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [750/845]  eta: 0:00:31  loss: 3.4578 (4.0150)  loss_n_40: 0.7941 (0.9930)  loss_n_60: 0.8086 (0.9636)  loss_n_80: 0.8596 (0.9574)  loss_n_100: 0.9882 (1.0910)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0100)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [760/845]  eta: 0:00:28  loss: 3.4798 (4.0124)  loss_n_40: 0.7677 (0.9919)  loss_n_60: 0.8041 (0.9631)  loss_n_80: 0.8596 (0.9571)  loss_n_100: 0.9654 (1.0906)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0099)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [770/845]  eta: 0:00:25  loss: 3.6678 (4.0096)  loss_n_40: 0.8064 (0.9908)  loss_n_60: 0.8740 (0.9623)  loss_n_80: 0.9515 (0.9566)  loss_n_100: 1.0219 (1.0902)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0098)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [780/845]  eta: 0:00:21  loss: 3.6599 (4.0075)  loss_n_40: 0.8381 (0.9897)  loss_n_60: 0.8415 (0.9616)  loss_n_80: 0.8817 (0.9564)  loss_n_100: 1.0511 (1.0902)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0096)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [790/845]  eta: 0:00:18  loss: 3.5744 (4.0040)  loss_n_40: 0.7743 (0.9876)  loss_n_60: 0.8357 (0.9606)  loss_n_80: 0.8953 (0.9561)  loss_n_100: 1.0888 (1.0902)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0095)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [800/845]  eta: 0:00:15  loss: 4.0237 (4.0103)  loss_n_40: 0.7813 (0.9888)  loss_n_60: 0.9568 (0.9619)  loss_n_80: 1.0263 (0.9577)  loss_n_100: 1.1969 (1.0924)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0094)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [810/845]  eta: 0:00:11  loss: 3.9158 (4.0051)  loss_n_40: 0.7730 (0.9868)  loss_n_60: 0.9281 (0.9608)  loss_n_80: 0.9737 (0.9568)  loss_n_100: 1.1735 (1.0914)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0093)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [820/845]  eta: 0:00:08  loss: 3.4772 (4.0063)  loss_n_40: 0.7693 (0.9882)  loss_n_60: 0.8878 (0.9612)  loss_n_80: 0.8433 (0.9569)  loss_n_100: 0.9746 (1.0908)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0092)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [830/845]  eta: 0:00:05  loss: 3.4898 (4.0014)  loss_n_40: 0.7775 (0.9861)  loss_n_60: 0.8455 (0.9598)  loss_n_80: 0.8684 (0.9561)  loss_n_100: 0.9991 (1.0903)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0090)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [840/845]  eta: 0:00:01  loss: 4.0226 (4.0144)  loss_n_40: 0.8556 (0.9918)  loss_n_60: 0.9692 (0.9640)  loss_n_80: 0.9776 (0.9583)  loss_n_100: 1.1386 (1.0913)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0089)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6]  [844/845]  eta: 0:00:00  loss: 4.0226 (4.0127)  loss_n_40: 0.8413 (0.9908)  loss_n_60: 0.9692 (0.9637)  loss_n_80: 0.9776 (0.9581)  loss_n_100: 1.0834 (1.0913)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0089)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:6] Total time: 0:04:43 (0.3354 s / it)\n",
      "Averaged stats: loss: 4.0226 (4.0127)  loss_n_40: 0.8413 (0.9908)  loss_n_60: 0.9692 (0.9637)  loss_n_80: 0.9776 (0.9581)  loss_n_100: 1.0834 (1.0913)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0089)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_6_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 1.091%\n",
      "Min loss_n_100: 1.091\n",
      "Best Epoch: 6.000\n",
      "Train: [epoch:7]  [   0/1724]  eta: 1:59:51  lr: 0.000120  loss: 4.6795 (4.6795)  loss_n_40: 1.2074 (1.2074)  loss_n_60: 1.1646 (1.1646)  loss_n_80: 1.0717 (1.0717)  loss_n_100: 1.2359 (1.2359)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1714  data: 0.4133  max mem: 46473\n",
      "Train: [epoch:7]  [  10/1724]  eta: 1:52:45  lr: 0.000120  loss: 3.8423 (3.8334)  loss_n_40: 0.8877 (0.9267)  loss_n_60: 0.9224 (0.9179)  loss_n_80: 0.8998 (0.9305)  loss_n_100: 1.0496 (1.0582)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9474  data: 0.0377  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [  20/1724]  eta: 1:51:47  lr: 0.000120  loss: 3.6357 (3.7143)  loss_n_40: 0.8348 (0.8715)  loss_n_60: 0.8730 (0.8951)  loss_n_80: 0.8794 (0.9131)  loss_n_100: 1.0134 (1.0346)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [  30/1724]  eta: 1:51:01  lr: 0.000120  loss: 3.7141 (3.7844)  loss_n_40: 0.8287 (0.9119)  loss_n_60: 0.8953 (0.9101)  loss_n_80: 0.9042 (0.9288)  loss_n_100: 1.0154 (1.0336)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [  40/1724]  eta: 1:50:18  lr: 0.000120  loss: 3.8738 (3.8946)  loss_n_40: 0.9394 (0.9600)  loss_n_60: 0.9135 (0.9318)  loss_n_80: 0.9395 (0.9422)  loss_n_100: 1.0154 (1.0374)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0029)  triple_60: 0.0000 (0.0019)  triple_40: 0.0000 (0.0183)  time: 3.9235  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [  50/1724]  eta: 1:49:36  lr: 0.000120  loss: 4.5550 (4.2020)  loss_n_40: 0.9780 (0.9883)  loss_n_60: 1.0276 (0.9771)  loss_n_80: 1.0683 (1.0366)  loss_n_100: 1.1514 (1.1291)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0024)  triple_60: 0.0000 (0.0122)  triple_40: 0.0000 (0.0516)  time: 3.9226  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [  60/1724]  eta: 1:48:56  lr: 0.000120  loss: 5.4763 (4.4291)  loss_n_40: 1.1556 (1.0409)  loss_n_60: 1.2466 (1.0254)  loss_n_80: 1.4009 (1.1003)  loss_n_100: 1.5513 (1.2031)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0020)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0431)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [  70/1724]  eta: 1:48:16  lr: 0.000120  loss: 5.2101 (4.4876)  loss_n_40: 1.1735 (1.0544)  loss_n_60: 1.1900 (1.0393)  loss_n_80: 1.3154 (1.1209)  loss_n_100: 1.4884 (1.2220)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0017)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0370)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [  80/1724]  eta: 1:47:36  lr: 0.000120  loss: 4.6674 (4.4925)  loss_n_40: 1.0785 (1.0613)  loss_n_60: 1.1204 (1.0458)  loss_n_80: 1.1586 (1.1206)  loss_n_100: 1.2377 (1.2201)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0015)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0325)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [  90/1724]  eta: 1:46:56  lr: 0.000120  loss: 4.2313 (4.4372)  loss_n_40: 0.9962 (1.0514)  loss_n_60: 1.0119 (1.0364)  loss_n_80: 1.0097 (1.1039)  loss_n_100: 1.1566 (1.2057)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0013)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0289)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 100/1724]  eta: 1:46:16  lr: 0.000120  loss: 3.9484 (4.3845)  loss_n_40: 0.9110 (1.0420)  loss_n_60: 0.9477 (1.0253)  loss_n_80: 0.9741 (1.0903)  loss_n_100: 1.0736 (1.1910)  triple_100: 0.0000 (0.0025)  triple_80: 0.0000 (0.0012)  triple_60: 0.0000 (0.0062)  triple_40: 0.0000 (0.0260)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 110/1724]  eta: 1:45:37  lr: 0.000120  loss: 3.8230 (4.3296)  loss_n_40: 0.8429 (1.0299)  loss_n_60: 0.8918 (1.0126)  loss_n_80: 0.9414 (1.0760)  loss_n_100: 1.0633 (1.1785)  triple_100: 0.0000 (0.0022)  triple_80: 0.0000 (0.0011)  triple_60: 0.0000 (0.0056)  triple_40: 0.0000 (0.0237)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 120/1724]  eta: 1:44:57  lr: 0.000120  loss: 4.1729 (4.4448)  loss_n_40: 0.9535 (1.0403)  loss_n_60: 0.9590 (1.0271)  loss_n_80: 1.0226 (1.0831)  loss_n_100: 1.1039 (1.1836)  triple_100: 0.0000 (0.0219)  triple_80: 0.0000 (0.0198)  triple_60: 0.0000 (0.0472)  triple_40: 0.0000 (0.0217)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 130/1724]  eta: 1:44:18  lr: 0.000120  loss: 4.5946 (4.4600)  loss_n_40: 1.1097 (1.0540)  loss_n_60: 1.1068 (1.0312)  loss_n_80: 1.1380 (1.0850)  loss_n_100: 1.2645 (1.1876)  triple_100: 0.0000 (0.0202)  triple_80: 0.0000 (0.0183)  triple_60: 0.0000 (0.0436)  triple_40: 0.0000 (0.0201)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 140/1724]  eta: 1:43:39  lr: 0.000120  loss: 4.4245 (4.4519)  loss_n_40: 1.1097 (1.0622)  loss_n_60: 1.0347 (1.0287)  loss_n_80: 1.0360 (1.0815)  loss_n_100: 1.1727 (1.1845)  triple_100: 0.0000 (0.0188)  triple_80: 0.0000 (0.0170)  triple_60: 0.0000 (0.0405)  triple_40: 0.0000 (0.0186)  time: 3.9252  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [ 150/1724]  eta: 1:42:59  lr: 0.000120  loss: 3.9920 (4.4333)  loss_n_40: 1.0728 (1.0661)  loss_n_60: 0.9341 (1.0246)  loss_n_80: 0.9645 (1.0759)  loss_n_100: 1.0942 (1.1780)  triple_100: 0.0000 (0.0176)  triple_80: 0.0000 (0.0159)  triple_60: 0.0000 (0.0379)  triple_40: 0.0000 (0.0174)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 160/1724]  eta: 1:42:20  lr: 0.000120  loss: 3.8743 (4.3848)  loss_n_40: 0.9797 (1.0574)  loss_n_60: 0.8750 (1.0131)  loss_n_80: 0.9115 (1.0635)  loss_n_100: 1.0251 (1.1676)  triple_100: 0.0000 (0.0165)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0355)  triple_40: 0.0000 (0.0163)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 170/1724]  eta: 1:41:40  lr: 0.000120  loss: 3.6668 (4.3455)  loss_n_40: 0.9352 (1.0518)  loss_n_60: 0.8364 (1.0035)  loss_n_80: 0.8564 (1.0533)  loss_n_100: 1.0058 (1.1585)  triple_100: 0.0000 (0.0155)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0334)  triple_40: 0.0000 (0.0154)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 180/1724]  eta: 1:41:01  lr: 0.000120  loss: 3.6564 (4.3087)  loss_n_40: 0.9544 (1.0460)  loss_n_60: 0.8381 (0.9961)  loss_n_80: 0.8511 (1.0442)  loss_n_100: 0.9719 (1.1484)  triple_100: 0.0000 (0.0147)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0316)  triple_40: 0.0000 (0.0145)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 190/1724]  eta: 1:40:22  lr: 0.000120  loss: 3.4958 (4.2735)  loss_n_40: 0.8827 (1.0385)  loss_n_60: 0.8163 (0.9872)  loss_n_80: 0.8647 (1.0349)  loss_n_100: 0.9574 (1.1381)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0126)  triple_60: 0.0000 (0.0299)  triple_40: 0.0000 (0.0184)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 200/1724]  eta: 1:39:42  lr: 0.000120  loss: 3.4678 (4.2505)  loss_n_40: 0.8732 (1.0334)  loss_n_60: 0.8163 (0.9826)  loss_n_80: 0.8647 (1.0291)  loss_n_100: 0.9440 (1.1313)  triple_100: 0.0000 (0.0159)  triple_80: 0.0000 (0.0119)  triple_60: 0.0000 (0.0289)  triple_40: 0.0000 (0.0175)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 210/1724]  eta: 1:39:03  lr: 0.000120  loss: 4.7326 (4.7076)  loss_n_40: 1.0204 (1.0703)  loss_n_60: 1.0688 (1.0372)  loss_n_80: 1.0725 (1.1015)  loss_n_100: 1.1817 (1.2067)  triple_100: 0.0000 (0.1006)  triple_80: 0.0000 (0.0779)  triple_60: 0.0000 (0.0359)  triple_40: 0.0000 (0.0775)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 220/1724]  eta: 1:38:24  lr: 0.000120  loss: 20.8551 (5.5246)  loss_n_40: 4.0229 (1.2429)  loss_n_60: 4.3733 (1.2278)  loss_n_80: 4.6990 (1.3000)  loss_n_100: 4.8368 (1.3976)  triple_100: 0.0000 (0.1094)  triple_80: 0.0000 (0.1318)  triple_60: 0.0000 (0.0411)  triple_40: 0.0000 (0.0740)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 230/1724]  eta: 1:37:44  lr: 0.000120  loss: 22.3654 (6.2662)  loss_n_40: 5.2248 (1.4239)  loss_n_60: 5.5982 (1.4244)  loss_n_80: 5.6742 (1.4952)  loss_n_100: 5.5274 (1.5818)  triple_100: 0.0000 (0.1046)  triple_80: 0.0000 (0.1261)  triple_60: 0.0000 (0.0393)  triple_40: 0.0000 (0.0708)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 240/1724]  eta: 1:37:05  lr: 0.000120  loss: 21.9776 (6.8770)  loss_n_40: 5.2524 (1.5720)  loss_n_60: 5.6767 (1.5888)  loss_n_80: 5.6446 (1.6556)  loss_n_100: 5.4039 (1.7316)  triple_100: 0.0000 (0.1003)  triple_80: 0.0000 (0.1209)  triple_60: 0.0000 (0.0392)  triple_40: 0.0000 (0.0686)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 250/1724]  eta: 1:36:25  lr: 0.000120  loss: 20.0077 (7.3553)  loss_n_40: 4.6335 (1.6880)  loss_n_60: 4.9131 (1.7122)  loss_n_80: 5.2275 (1.7861)  loss_n_100: 5.0538 (1.8531)  triple_100: 0.0000 (0.0963)  triple_80: 0.0000 (0.1161)  triple_60: 0.0000 (0.0376)  triple_40: 0.0000 (0.0658)  time: 3.9217  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [ 260/1724]  eta: 1:35:46  lr: 0.000120  loss: 18.1037 (7.7478)  loss_n_40: 4.2093 (1.7758)  loss_n_60: 4.3638 (1.8070)  loss_n_80: 4.7287 (1.8942)  loss_n_100: 4.6653 (1.9590)  triple_100: 0.0000 (0.0926)  triple_80: 0.0000 (0.1165)  triple_60: 0.0000 (0.0394)  triple_40: 0.0000 (0.0633)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 270/1724]  eta: 1:35:06  lr: 0.000120  loss: 16.4064 (8.0163)  loss_n_40: 3.6722 (1.8345)  loss_n_60: 3.9318 (1.8732)  loss_n_80: 4.4024 (1.9712)  loss_n_100: 4.4128 (2.0369)  triple_100: 0.0000 (0.0892)  triple_80: 0.0000 (0.1124)  triple_60: 0.0000 (0.0380)  triple_40: 0.0000 (0.0610)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 280/1724]  eta: 1:34:27  lr: 0.000120  loss: 13.2995 (8.1720)  loss_n_40: 3.0206 (1.8678)  loss_n_60: 3.1219 (1.9073)  loss_n_80: 3.5745 (2.0201)  loss_n_100: 3.6923 (2.0846)  triple_100: 0.0000 (0.0860)  triple_80: 0.0000 (0.1084)  triple_60: 0.0000 (0.0366)  triple_40: 0.0000 (0.0610)  time: 3.9238  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [ 290/1724]  eta: 1:33:48  lr: 0.000120  loss: 12.5262 (8.4199)  loss_n_40: 2.6825 (1.8920)  loss_n_60: 2.8033 (1.9390)  loss_n_80: 3.2444 (2.0592)  loss_n_100: 3.3770 (2.1249)  triple_100: 0.0000 (0.1031)  triple_80: 0.0000 (0.1157)  triple_60: 0.0000 (0.0369)  triple_40: 0.0000 (0.1490)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 300/1724]  eta: 1:33:08  lr: 0.000120  loss: 14.1900 (8.6169)  loss_n_40: 2.8034 (1.9272)  loss_n_60: 3.1355 (1.9917)  loss_n_80: 3.3198 (2.1161)  loss_n_100: 3.3823 (2.1722)  triple_100: 0.0000 (0.0997)  triple_80: 0.0000 (0.1127)  triple_60: 0.0000 (0.0529)  triple_40: 0.0000 (0.1444)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 310/1724]  eta: 1:32:29  lr: 0.000120  loss: 14.6610 (8.8617)  loss_n_40: 2.9535 (1.9621)  loss_n_60: 3.2291 (2.0295)  loss_n_80: 3.9781 (2.1847)  loss_n_100: 3.8112 (2.2439)  triple_100: 0.0000 (0.1143)  triple_80: 0.0000 (0.1159)  triple_60: 0.0000 (0.0547)  triple_40: 0.0000 (0.1566)  time: 3.9238  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [ 320/1724]  eta: 1:31:50  lr: 0.000120  loss: 16.0757 (9.1188)  loss_n_40: 2.8623 (1.9877)  loss_n_60: 3.2291 (2.0736)  loss_n_80: 4.2241 (2.2488)  loss_n_100: 4.4144 (2.3110)  triple_100: 0.0000 (0.1107)  triple_80: 0.0000 (0.1350)  triple_60: 0.0000 (0.0626)  triple_40: 0.0000 (0.1894)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 330/1724]  eta: 1:31:10  lr: 0.000120  loss: 14.4929 (9.2809)  loss_n_40: 2.7198 (2.0105)  loss_n_60: 3.4528 (2.1145)  loss_n_80: 3.9994 (2.2982)  loss_n_100: 4.1537 (2.3648)  triple_100: 0.0000 (0.1176)  triple_80: 0.0000 (0.1309)  triple_60: 0.0000 (0.0607)  triple_40: 0.0000 (0.1837)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 340/1724]  eta: 1:30:31  lr: 0.000120  loss: 13.8585 (9.3994)  loss_n_40: 2.6411 (2.0278)  loss_n_60: 3.2301 (2.1399)  loss_n_80: 3.8316 (2.3391)  loss_n_100: 3.9516 (2.4059)  triple_100: 0.0000 (0.1216)  triple_80: 0.0000 (0.1278)  triple_60: 0.0000 (0.0589)  triple_40: 0.0000 (0.1783)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 350/1724]  eta: 1:29:52  lr: 0.000120  loss: 13.4628 (9.5129)  loss_n_40: 2.5836 (2.0473)  loss_n_60: 3.0243 (2.1667)  loss_n_80: 3.6478 (2.3741)  loss_n_100: 3.6368 (2.4365)  triple_100: 0.0000 (0.1261)  triple_80: 0.0000 (0.1242)  triple_60: 0.0000 (0.0648)  triple_40: 0.0000 (0.1732)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 360/1724]  eta: 1:29:12  lr: 0.000120  loss: 14.2944 (9.7059)  loss_n_40: 2.9427 (2.0873)  loss_n_60: 3.2570 (2.2066)  loss_n_80: 3.7780 (2.4188)  loss_n_100: 3.6902 (2.4774)  triple_100: 0.0000 (0.1226)  triple_80: 0.0000 (0.1207)  triple_60: 0.0000 (0.0630)  triple_40: 0.0000 (0.2096)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 370/1724]  eta: 1:28:33  lr: 0.000120  loss: 16.9826 (9.9111)  loss_n_40: 3.7833 (2.1375)  loss_n_60: 4.0526 (2.2642)  loss_n_80: 4.1995 (2.4717)  loss_n_100: 4.0936 (2.5256)  triple_100: 0.0000 (0.1193)  triple_80: 0.0000 (0.1175)  triple_60: 0.0000 (0.0613)  triple_40: 0.0000 (0.2140)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 380/1724]  eta: 1:27:54  lr: 0.000120  loss: 16.7363 (10.0655)  loss_n_40: 3.8562 (2.1748)  loss_n_60: 4.3147 (2.3138)  loss_n_80: 4.1976 (2.5116)  loss_n_100: 4.1701 (2.5652)  triple_100: 0.0000 (0.1162)  triple_80: 0.0000 (0.1144)  triple_60: 0.0000 (0.0597)  triple_40: 0.0000 (0.2098)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 390/1724]  eta: 1:27:14  lr: 0.000120  loss: 15.0802 (10.1801)  loss_n_40: 3.3094 (2.2010)  loss_n_60: 3.9231 (2.3486)  loss_n_80: 3.8591 (2.5431)  loss_n_100: 3.8950 (2.5960)  triple_100: 0.0000 (0.1133)  triple_80: 0.0000 (0.1115)  triple_60: 0.0000 (0.0582)  triple_40: 0.0000 (0.2083)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 400/1724]  eta: 1:26:35  lr: 0.000120  loss: 13.8580 (10.2653)  loss_n_40: 3.1176 (2.2229)  loss_n_60: 3.5734 (2.3780)  loss_n_80: 3.5517 (2.5678)  loss_n_100: 3.5560 (2.6176)  triple_100: 0.0000 (0.1104)  triple_80: 0.0000 (0.1087)  triple_60: 0.0000 (0.0567)  triple_40: 0.0000 (0.2031)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 410/1724]  eta: 1:25:56  lr: 0.000120  loss: 12.9114 (10.3214)  loss_n_40: 2.9043 (2.2371)  loss_n_60: 3.3589 (2.3992)  loss_n_80: 3.4576 (2.5862)  loss_n_100: 3.3324 (2.6316)  triple_100: 0.0000 (0.1078)  triple_80: 0.0000 (0.1061)  triple_60: 0.0000 (0.0553)  triple_40: 0.0000 (0.1982)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 420/1724]  eta: 1:25:17  lr: 0.000120  loss: 12.0398 (10.3547)  loss_n_40: 2.7784 (2.2479)  loss_n_60: 3.1074 (2.4114)  loss_n_80: 3.1767 (2.5982)  loss_n_100: 2.9842 (2.6384)  triple_100: 0.0000 (0.1052)  triple_80: 0.0000 (0.1035)  triple_60: 0.0000 (0.0540)  triple_40: 0.0000 (0.1961)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 430/1724]  eta: 1:24:37  lr: 0.000120  loss: 11.1979 (10.3648)  loss_n_40: 2.6119 (2.2541)  loss_n_60: 2.8131 (2.4168)  loss_n_80: 3.0003 (2.6046)  loss_n_100: 2.8507 (2.6411)  triple_100: 0.0000 (0.1028)  triple_80: 0.0000 (0.1011)  triple_60: 0.0000 (0.0528)  triple_40: 0.0000 (0.1915)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 440/1724]  eta: 1:23:58  lr: 0.000120  loss: 10.8308 (10.3829)  loss_n_40: 2.5156 (2.2627)  loss_n_60: 2.6427 (2.4229)  loss_n_80: 2.8621 (2.6125)  loss_n_100: 2.7658 (2.6463)  triple_100: 0.0000 (0.1004)  triple_80: 0.0000 (0.0988)  triple_60: 0.0000 (0.0516)  triple_40: 0.0000 (0.1876)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 450/1724]  eta: 1:23:19  lr: 0.000120  loss: 10.6562 (10.3848)  loss_n_40: 2.4911 (2.2676)  loss_n_60: 2.6100 (2.4247)  loss_n_80: 2.8041 (2.6159)  loss_n_100: 2.7295 (2.6480)  triple_100: 0.0000 (0.0982)  triple_80: 0.0000 (0.0967)  triple_60: 0.0000 (0.0504)  triple_40: 0.0000 (0.1834)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 460/1724]  eta: 1:22:39  lr: 0.000120  loss: 9.6858 (10.3636)  loss_n_40: 2.3048 (2.2675)  loss_n_60: 2.3078 (2.4212)  loss_n_80: 2.5720 (2.6124)  loss_n_100: 2.5684 (2.6430)  triple_100: 0.0000 (0.0961)  triple_80: 0.0000 (0.0946)  triple_60: 0.0000 (0.0493)  triple_40: 0.0000 (0.1795)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 470/1724]  eta: 1:22:00  lr: 0.000120  loss: 9.4014 (10.3513)  loss_n_40: 2.2157 (2.2687)  loss_n_60: 2.2191 (2.4194)  loss_n_80: 2.4378 (2.6112)  loss_n_100: 2.4741 (2.6416)  triple_100: 0.0000 (0.0940)  triple_80: 0.0000 (0.0925)  triple_60: 0.0000 (0.0483)  triple_40: 0.0000 (0.1757)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 480/1724]  eta: 1:21:21  lr: 0.000120  loss: 9.4014 (10.3386)  loss_n_40: 2.3021 (2.2684)  loss_n_60: 2.2191 (2.4165)  loss_n_80: 2.4685 (2.6101)  loss_n_100: 2.4741 (2.6385)  triple_100: 0.0000 (0.0921)  triple_80: 0.0000 (0.0906)  triple_60: 0.0000 (0.0473)  triple_40: 0.0000 (0.1751)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 490/1724]  eta: 1:20:42  lr: 0.000120  loss: 9.3828 (10.3248)  loss_n_40: 2.2982 (2.2688)  loss_n_60: 2.1852 (2.4133)  loss_n_80: 2.4741 (2.6072)  loss_n_100: 2.3905 (2.6353)  triple_100: 0.0000 (0.0902)  triple_80: 0.0000 (0.0921)  triple_60: 0.0000 (0.0463)  triple_40: 0.0000 (0.1716)  time: 3.9235  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [ 500/1724]  eta: 1:20:02  lr: 0.000120  loss: 9.3823 (10.3025)  loss_n_40: 2.2675 (2.2677)  loss_n_60: 2.1717 (2.4083)  loss_n_80: 2.3936 (2.6022)  loss_n_100: 2.4170 (2.6300)  triple_100: 0.0000 (0.0884)  triple_80: 0.0000 (0.0913)  triple_60: 0.0000 (0.0454)  triple_40: 0.0000 (0.1692)  time: 3.9243  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [ 510/1724]  eta: 1:19:23  lr: 0.000120  loss: 8.9568 (10.2709)  loss_n_40: 2.0950 (2.2640)  loss_n_60: 2.0620 (2.4015)  loss_n_80: 2.3219 (2.5957)  loss_n_100: 2.3439 (2.6232)  triple_100: 0.0000 (0.0867)  triple_80: 0.0000 (0.0896)  triple_60: 0.0000 (0.0445)  triple_40: 0.0000 (0.1659)  time: 3.9244  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [ 520/1724]  eta: 1:18:44  lr: 0.000120  loss: 8.8344 (10.2483)  loss_n_40: 2.0494 (2.2610)  loss_n_60: 2.0466 (2.3971)  loss_n_80: 2.3130 (2.5918)  loss_n_100: 2.3439 (2.6192)  triple_100: 0.0000 (0.0850)  triple_80: 0.0000 (0.0878)  triple_60: 0.0000 (0.0436)  triple_40: 0.0000 (0.1627)  time: 3.9243  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 530/1724]  eta: 1:18:05  lr: 0.000120  loss: 8.8269 (10.2152)  loss_n_40: 2.0765 (2.2579)  loss_n_60: 2.0773 (2.3899)  loss_n_80: 2.3073 (2.5843)  loss_n_100: 2.3799 (2.6110)  triple_100: 0.0000 (0.0834)  triple_80: 0.0000 (0.0862)  triple_60: 0.0000 (0.0428)  triple_40: 0.0000 (0.1596)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 540/1724]  eta: 1:17:26  lr: 0.000120  loss: 8.4839 (10.1861)  loss_n_40: 2.0156 (2.2532)  loss_n_60: 1.9896 (2.3831)  loss_n_80: 2.2696 (2.5790)  loss_n_100: 2.2919 (2.6056)  triple_100: 0.0000 (0.0819)  triple_80: 0.0000 (0.0846)  triple_60: 0.0000 (0.0420)  triple_40: 0.0000 (0.1567)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 550/1724]  eta: 1:16:46  lr: 0.000120  loss: 8.6837 (10.1745)  loss_n_40: 1.9960 (2.2503)  loss_n_60: 2.0096 (2.3784)  loss_n_80: 2.3752 (2.5768)  loss_n_100: 2.3145 (2.6012)  triple_100: 0.0000 (0.0804)  triple_80: 0.0000 (0.0898)  triple_60: 0.0000 (0.0438)  triple_40: 0.0000 (0.1538)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 560/1724]  eta: 1:16:07  lr: 0.000120  loss: 8.6684 (10.1456)  loss_n_40: 2.0551 (2.2464)  loss_n_60: 2.0072 (2.3715)  loss_n_80: 2.3509 (2.5720)  loss_n_100: 2.2894 (2.5944)  triple_100: 0.0000 (0.0789)  triple_80: 0.0000 (0.0882)  triple_60: 0.0000 (0.0431)  triple_40: 0.0000 (0.1511)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 570/1724]  eta: 1:15:28  lr: 0.000120  loss: 8.2487 (10.1182)  loss_n_40: 2.0409 (2.2433)  loss_n_60: 1.9452 (2.3643)  loss_n_80: 2.2477 (2.5674)  loss_n_100: 2.1427 (2.5883)  triple_100: 0.0000 (0.0776)  triple_80: 0.0000 (0.0867)  triple_60: 0.0000 (0.0423)  triple_40: 0.0000 (0.1484)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 580/1724]  eta: 1:14:49  lr: 0.000120  loss: 8.2487 (10.0957)  loss_n_40: 1.9555 (2.2382)  loss_n_60: 1.8525 (2.3553)  loss_n_80: 2.1796 (2.5605)  loss_n_100: 2.1025 (2.5806)  triple_100: 0.0000 (0.0805)  triple_80: 0.0000 (0.0852)  triple_60: 0.0000 (0.0430)  triple_40: 0.0000 (0.1524)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 590/1724]  eta: 1:14:09  lr: 0.000120  loss: 8.4288 (10.0761)  loss_n_40: 1.9756 (2.2361)  loss_n_60: 1.9140 (2.3500)  loss_n_80: 2.2523 (2.5582)  loss_n_100: 2.1675 (2.5767)  triple_100: 0.0000 (0.0791)  triple_80: 0.0000 (0.0837)  triple_60: 0.0000 (0.0423)  triple_40: 0.0000 (0.1499)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 600/1724]  eta: 1:13:30  lr: 0.000120  loss: 8.6079 (10.0571)  loss_n_40: 2.0901 (2.2339)  loss_n_60: 2.0095 (2.3450)  loss_n_80: 2.3023 (2.5559)  loss_n_100: 2.2655 (2.5732)  triple_100: 0.0000 (0.0778)  triple_80: 0.0000 (0.0823)  triple_60: 0.0000 (0.0416)  triple_40: 0.0000 (0.1474)  time: 3.9243  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 610/1724]  eta: 1:12:51  lr: 0.000120  loss: 8.3813 (10.0264)  loss_n_40: 2.0023 (2.2294)  loss_n_60: 1.9366 (2.3370)  loss_n_80: 2.2841 (2.5501)  loss_n_100: 2.1902 (2.5666)  triple_100: 0.0000 (0.0765)  triple_80: 0.0000 (0.0810)  triple_60: 0.0000 (0.0409)  triple_40: 0.0000 (0.1449)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 620/1724]  eta: 1:12:12  lr: 0.000120  loss: 8.0052 (9.9946)  loss_n_40: 1.9191 (2.2247)  loss_n_60: 1.8062 (2.3288)  loss_n_80: 2.1243 (2.5431)  loss_n_100: 2.1323 (2.5599)  triple_100: 0.0000 (0.0753)  triple_80: 0.0000 (0.0797)  triple_60: 0.0000 (0.0403)  triple_40: 0.0000 (0.1428)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 630/1724]  eta: 1:11:33  lr: 0.000120  loss: 7.8734 (9.9584)  loss_n_40: 1.9171 (2.2198)  loss_n_60: 1.7836 (2.3199)  loss_n_80: 2.0555 (2.5350)  loss_n_100: 2.0981 (2.5511)  triple_100: 0.0000 (0.0741)  triple_80: 0.0000 (0.0784)  triple_60: 0.0000 (0.0396)  triple_40: 0.0000 (0.1405)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 640/1724]  eta: 1:10:53  lr: 0.000120  loss: 7.7336 (9.9268)  loss_n_40: 1.8602 (2.2155)  loss_n_60: 1.7697 (2.3119)  loss_n_80: 2.0433 (2.5276)  loss_n_100: 1.9819 (2.5435)  triple_100: 0.0000 (0.0729)  triple_80: 0.0000 (0.0781)  triple_60: 0.0000 (0.0390)  triple_40: 0.0000 (0.1383)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 650/1724]  eta: 1:10:14  lr: 0.000120  loss: 7.6147 (9.8915)  loss_n_40: 1.8186 (2.2099)  loss_n_60: 1.7073 (2.3032)  loss_n_80: 1.9686 (2.5194)  loss_n_100: 1.9952 (2.5353)  triple_100: 0.0000 (0.0718)  triple_80: 0.0000 (0.0772)  triple_60: 0.0000 (0.0384)  triple_40: 0.0000 (0.1362)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 660/1724]  eta: 1:09:35  lr: 0.000120  loss: 7.4251 (9.8549)  loss_n_40: 1.8030 (2.2051)  loss_n_60: 1.6789 (2.2944)  loss_n_80: 1.9212 (2.5103)  loss_n_100: 1.9457 (2.5252)  triple_100: 0.0000 (0.0707)  triple_80: 0.0000 (0.0768)  triple_60: 0.0000 (0.0382)  triple_40: 0.0000 (0.1341)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 670/1724]  eta: 1:08:56  lr: 0.000120  loss: 7.2282 (9.8174)  loss_n_40: 1.8298 (2.1996)  loss_n_60: 1.6151 (2.2845)  loss_n_80: 1.8931 (2.5010)  loss_n_100: 1.8146 (2.5155)  triple_100: 0.0000 (0.0697)  triple_80: 0.0000 (0.0756)  triple_60: 0.0000 (0.0376)  triple_40: 0.0000 (0.1337)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 680/1724]  eta: 1:08:16  lr: 0.000120  loss: 7.2229 (9.7821)  loss_n_40: 1.8298 (2.1948)  loss_n_60: 1.6255 (2.2760)  loss_n_80: 1.8558 (2.4924)  loss_n_100: 1.8287 (2.5069)  triple_100: 0.0000 (0.0687)  triple_80: 0.0000 (0.0745)  triple_60: 0.0000 (0.0371)  triple_40: 0.0000 (0.1318)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 690/1724]  eta: 1:07:37  lr: 0.000120  loss: 7.0067 (9.7409)  loss_n_40: 1.7980 (2.1887)  loss_n_60: 1.6166 (2.2662)  loss_n_80: 1.8156 (2.4825)  loss_n_100: 1.8450 (2.4961)  triple_100: 0.0000 (0.0677)  triple_80: 0.0000 (0.0734)  triple_60: 0.0000 (0.0365)  triple_40: 0.0000 (0.1299)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 700/1724]  eta: 1:06:58  lr: 0.000120  loss: 7.0067 (9.7033)  loss_n_40: 1.7895 (2.1836)  loss_n_60: 1.6166 (2.2572)  loss_n_80: 1.8156 (2.4727)  loss_n_100: 1.8279 (2.4858)  triple_100: 0.0000 (0.0667)  triple_80: 0.0000 (0.0724)  triple_60: 0.0000 (0.0360)  triple_40: 0.0000 (0.1288)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 710/1724]  eta: 1:06:19  lr: 0.000120  loss: 7.2712 (9.6685)  loss_n_40: 1.8013 (2.1785)  loss_n_60: 1.6281 (2.2486)  loss_n_80: 1.8327 (2.4638)  loss_n_100: 1.8296 (2.4771)  triple_100: 0.0000 (0.0658)  triple_80: 0.0000 (0.0714)  triple_60: 0.0000 (0.0355)  triple_40: 0.0000 (0.1278)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 720/1724]  eta: 1:05:39  lr: 0.000120  loss: 6.8647 (9.6293)  loss_n_40: 1.7692 (2.1719)  loss_n_60: 1.5910 (2.2392)  loss_n_80: 1.8010 (2.4546)  loss_n_100: 1.7433 (2.4673)  triple_100: 0.0000 (0.0649)  triple_80: 0.0000 (0.0704)  triple_60: 0.0000 (0.0350)  triple_40: 0.0000 (0.1260)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 730/1724]  eta: 1:05:00  lr: 0.000120  loss: 6.8193 (9.5914)  loss_n_40: 1.6949 (2.1657)  loss_n_60: 1.5187 (2.2297)  loss_n_80: 1.7943 (2.4452)  loss_n_100: 1.7298 (2.4574)  triple_100: 0.0000 (0.0640)  triple_80: 0.0000 (0.0694)  triple_60: 0.0000 (0.0356)  triple_40: 0.0000 (0.1243)  time: 3.9229  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [ 740/1724]  eta: 1:04:21  lr: 0.000120  loss: 6.7858 (9.5506)  loss_n_40: 1.6949 (2.1591)  loss_n_60: 1.4981 (2.2198)  loss_n_80: 1.6853 (2.4351)  loss_n_100: 1.6885 (2.4473)  triple_100: 0.0000 (0.0631)  triple_80: 0.0000 (0.0685)  triple_60: 0.0000 (0.0351)  triple_40: 0.0000 (0.1226)  time: 3.9237  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [ 750/1724]  eta: 1:03:42  lr: 0.000120  loss: 6.6948 (9.5138)  loss_n_40: 1.7495 (2.1535)  loss_n_60: 1.5371 (2.2108)  loss_n_80: 1.6571 (2.4253)  loss_n_100: 1.6577 (2.4368)  triple_100: 0.0000 (0.0623)  triple_80: 0.0000 (0.0690)  triple_60: 0.0000 (0.0347)  triple_40: 0.0000 (0.1215)  time: 3.9237  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [ 760/1724]  eta: 1:03:02  lr: 0.000120  loss: 6.8897 (9.4810)  loss_n_40: 1.7720 (2.1488)  loss_n_60: 1.5672 (2.2030)  loss_n_80: 1.7285 (2.4173)  loss_n_100: 1.6577 (2.4283)  triple_100: 0.0000 (0.0614)  triple_80: 0.0000 (0.0681)  triple_60: 0.0000 (0.0342)  triple_40: 0.0000 (0.1199)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 770/1724]  eta: 1:02:23  lr: 0.000120  loss: 6.5893 (9.4427)  loss_n_40: 1.7539 (2.1430)  loss_n_60: 1.5075 (2.1941)  loss_n_80: 1.6791 (2.4074)  loss_n_100: 1.6272 (2.4182)  triple_100: 0.0000 (0.0606)  triple_80: 0.0000 (0.0672)  triple_60: 0.0000 (0.0338)  triple_40: 0.0000 (0.1184)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 780/1724]  eta: 1:01:44  lr: 0.000120  loss: 6.5842 (9.4137)  loss_n_40: 1.7202 (2.1388)  loss_n_60: 1.5075 (2.1870)  loss_n_80: 1.6757 (2.4003)  loss_n_100: 1.6272 (2.4109)  triple_100: 0.0000 (0.0599)  triple_80: 0.0000 (0.0664)  triple_60: 0.0000 (0.0333)  triple_40: 0.0000 (0.1172)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 790/1724]  eta: 1:01:05  lr: 0.000120  loss: 6.8454 (9.3808)  loss_n_40: 1.7202 (2.1337)  loss_n_60: 1.5385 (2.1788)  loss_n_80: 1.7503 (2.3923)  loss_n_100: 1.7630 (2.4027)  triple_100: 0.0000 (0.0591)  triple_80: 0.0000 (0.0655)  triple_60: 0.0000 (0.0329)  triple_40: 0.0000 (0.1157)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 800/1724]  eta: 1:00:25  lr: 0.000120  loss: 6.5510 (9.3447)  loss_n_40: 1.6679 (2.1282)  loss_n_60: 1.4745 (2.1702)  loss_n_80: 1.6685 (2.3832)  loss_n_100: 1.6472 (2.3932)  triple_100: 0.0000 (0.0584)  triple_80: 0.0000 (0.0647)  triple_60: 0.0000 (0.0325)  triple_40: 0.0000 (0.1143)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 810/1724]  eta: 0:59:46  lr: 0.000120  loss: 6.2880 (9.3081)  loss_n_40: 1.6084 (2.1219)  loss_n_60: 1.4138 (2.1614)  loss_n_80: 1.6217 (2.3738)  loss_n_100: 1.6219 (2.3836)  triple_100: 0.0000 (0.0577)  triple_80: 0.0000 (0.0639)  triple_60: 0.0000 (0.0321)  triple_40: 0.0000 (0.1139)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 820/1724]  eta: 0:59:07  lr: 0.000120  loss: 6.3750 (9.2809)  loss_n_40: 1.6084 (2.1170)  loss_n_60: 1.4726 (2.1539)  loss_n_80: 1.6217 (2.3663)  loss_n_100: 1.6108 (2.3759)  triple_100: 0.0000 (0.0570)  triple_80: 0.0000 (0.0659)  triple_60: 0.0000 (0.0317)  triple_40: 0.0000 (0.1132)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 830/1724]  eta: 0:58:28  lr: 0.000120  loss: 6.9845 (9.2604)  loss_n_40: 1.7948 (2.1148)  loss_n_60: 1.5724 (2.1489)  loss_n_80: 1.7976 (2.3615)  loss_n_100: 1.7377 (2.3705)  triple_100: 0.0000 (0.0563)  triple_80: 0.0000 (0.0651)  triple_60: 0.0000 (0.0313)  triple_40: 0.0000 (0.1119)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 840/1724]  eta: 0:57:48  lr: 0.000120  loss: 6.9845 (9.2278)  loss_n_40: 1.7980 (2.1103)  loss_n_60: 1.6056 (2.1408)  loss_n_80: 1.8116 (2.3534)  loss_n_100: 1.7111 (2.3611)  triple_100: 0.0000 (0.0556)  triple_80: 0.0000 (0.0644)  triple_60: 0.0000 (0.0310)  triple_40: 0.0000 (0.1113)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 850/1724]  eta: 0:57:09  lr: 0.000120  loss: 6.4854 (9.1965)  loss_n_40: 1.6624 (2.1050)  loss_n_60: 1.4631 (2.1332)  loss_n_80: 1.7014 (2.3457)  loss_n_100: 1.6168 (2.3529)  triple_100: 0.0000 (0.0549)  triple_80: 0.0000 (0.0636)  triple_60: 0.0000 (0.0306)  triple_40: 0.0000 (0.1105)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 860/1724]  eta: 0:56:30  lr: 0.000120  loss: 6.9039 (9.1781)  loss_n_40: 1.6521 (2.1007)  loss_n_60: 1.5240 (2.1267)  loss_n_80: 1.7588 (2.3392)  loss_n_100: 1.7090 (2.3465)  triple_100: 0.0000 (0.0543)  triple_80: 0.0000 (0.0662)  triple_60: 0.0000 (0.0302)  triple_40: 0.0000 (0.1143)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 870/1724]  eta: 0:55:51  lr: 0.000120  loss: 6.7100 (9.1516)  loss_n_40: 1.6465 (2.0956)  loss_n_60: 1.5357 (2.1208)  loss_n_80: 1.7588 (2.3331)  loss_n_100: 1.7229 (2.3400)  triple_100: 0.0000 (0.0537)  triple_80: 0.0000 (0.0655)  triple_60: 0.0000 (0.0299)  triple_40: 0.0000 (0.1130)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 880/1724]  eta: 0:55:11  lr: 0.000120  loss: 6.7000 (9.1254)  loss_n_40: 1.6630 (2.0910)  loss_n_60: 1.5749 (2.1153)  loss_n_80: 1.7582 (2.3271)  loss_n_100: 1.7023 (2.3330)  triple_100: 0.0000 (0.0531)  triple_80: 0.0000 (0.0647)  triple_60: 0.0000 (0.0296)  triple_40: 0.0000 (0.1117)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 890/1724]  eta: 0:54:32  lr: 0.000120  loss: 6.7000 (9.0963)  loss_n_40: 1.6571 (2.0859)  loss_n_60: 1.5749 (2.1091)  loss_n_80: 1.7335 (2.3203)  loss_n_100: 1.6575 (2.3248)  triple_100: 0.0000 (0.0525)  triple_80: 0.0000 (0.0640)  triple_60: 0.0000 (0.0292)  triple_40: 0.0000 (0.1104)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 900/1724]  eta: 0:53:53  lr: 0.000120  loss: 6.2292 (9.0638)  loss_n_40: 1.5760 (2.0801)  loss_n_60: 1.4838 (2.1018)  loss_n_80: 1.6574 (2.3124)  loss_n_100: 1.5442 (2.3163)  triple_100: 0.0000 (0.0519)  triple_80: 0.0000 (0.0633)  triple_60: 0.0000 (0.0289)  triple_40: 0.0000 (0.1092)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 910/1724]  eta: 0:53:14  lr: 0.000120  loss: 6.1505 (9.0342)  loss_n_40: 1.5323 (2.0750)  loss_n_60: 1.4629 (2.0952)  loss_n_80: 1.6247 (2.3050)  loss_n_100: 1.5270 (2.3085)  triple_100: 0.0000 (0.0513)  triple_80: 0.0000 (0.0626)  triple_60: 0.0000 (0.0286)  triple_40: 0.0000 (0.1080)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 920/1724]  eta: 0:52:35  lr: 0.000120  loss: 6.2300 (9.0036)  loss_n_40: 1.5308 (2.0683)  loss_n_60: 1.4440 (2.0875)  loss_n_80: 1.5872 (2.2969)  loss_n_100: 1.5446 (2.3000)  triple_100: 0.0000 (0.0508)  triple_80: 0.0000 (0.0641)  triple_60: 0.0000 (0.0291)  triple_40: 0.0000 (0.1068)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 930/1724]  eta: 0:51:55  lr: 0.000120  loss: 6.2300 (8.9749)  loss_n_40: 1.5402 (2.0634)  loss_n_60: 1.4440 (2.0808)  loss_n_80: 1.5857 (2.2888)  loss_n_100: 1.5446 (2.2917)  triple_100: 0.0000 (0.0502)  triple_80: 0.0000 (0.0635)  triple_60: 0.0000 (0.0309)  triple_40: 0.0000 (0.1057)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 940/1724]  eta: 0:51:16  lr: 0.000120  loss: 6.1688 (8.9465)  loss_n_40: 1.5220 (2.0577)  loss_n_60: 1.4580 (2.0742)  loss_n_80: 1.5962 (2.2817)  loss_n_100: 1.5916 (2.2847)  triple_100: 0.0000 (0.0497)  triple_80: 0.0000 (0.0632)  triple_60: 0.0000 (0.0306)  triple_40: 0.0000 (0.1047)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 950/1724]  eta: 0:50:37  lr: 0.000120  loss: 6.1354 (8.9165)  loss_n_40: 1.4714 (2.0514)  loss_n_60: 1.3942 (2.0672)  loss_n_80: 1.5879 (2.2740)  loss_n_100: 1.5916 (2.2774)  triple_100: 0.0000 (0.0492)  triple_80: 0.0000 (0.0626)  triple_60: 0.0000 (0.0303)  triple_40: 0.0000 (0.1046)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 960/1724]  eta: 0:49:58  lr: 0.000120  loss: 6.0769 (8.8856)  loss_n_40: 1.4420 (2.0453)  loss_n_60: 1.3864 (2.0600)  loss_n_80: 1.5264 (2.2659)  loss_n_100: 1.5565 (2.2694)  triple_100: 0.0000 (0.0487)  triple_80: 0.0000 (0.0622)  triple_60: 0.0000 (0.0299)  triple_40: 0.0000 (0.1042)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 970/1724]  eta: 0:49:18  lr: 0.000120  loss: 5.8791 (8.8557)  loss_n_40: 1.4153 (2.0394)  loss_n_60: 1.3547 (2.0532)  loss_n_80: 1.5281 (2.2586)  loss_n_100: 1.5271 (2.2621)  triple_100: 0.0000 (0.0482)  triple_80: 0.0000 (0.0615)  triple_60: 0.0000 (0.0296)  triple_40: 0.0000 (0.1031)  time: 3.9244  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [ 980/1724]  eta: 0:48:39  lr: 0.000120  loss: 5.7735 (8.8223)  loss_n_40: 1.4096 (2.0330)  loss_n_60: 1.3547 (2.0457)  loss_n_80: 1.5073 (2.2502)  loss_n_100: 1.5166 (2.2534)  triple_100: 0.0000 (0.0477)  triple_80: 0.0000 (0.0609)  triple_60: 0.0000 (0.0293)  triple_40: 0.0000 (0.1020)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [ 990/1724]  eta: 0:48:00  lr: 0.000120  loss: 5.6016 (8.7892)  loss_n_40: 1.4061 (2.0266)  loss_n_60: 1.3077 (2.0380)  loss_n_80: 1.4415 (2.2418)  loss_n_100: 1.3909 (2.2449)  triple_100: 0.0000 (0.0472)  triple_80: 0.0000 (0.0603)  triple_60: 0.0000 (0.0295)  triple_40: 0.0000 (0.1010)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1000/1724]  eta: 0:47:21  lr: 0.000120  loss: 5.3252 (8.7547)  loss_n_40: 1.3235 (2.0194)  loss_n_60: 1.2606 (2.0299)  loss_n_80: 1.3893 (2.2334)  loss_n_100: 1.3695 (2.2363)  triple_100: 0.0000 (0.0467)  triple_80: 0.0000 (0.0597)  triple_60: 0.0000 (0.0292)  triple_40: 0.0000 (0.1000)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1010/1724]  eta: 0:46:41  lr: 0.000120  loss: 5.3131 (8.7206)  loss_n_40: 1.3168 (2.0124)  loss_n_60: 1.2273 (2.0221)  loss_n_80: 1.3893 (2.2250)  loss_n_100: 1.3886 (2.2278)  triple_100: 0.0000 (0.0463)  triple_80: 0.0000 (0.0591)  triple_60: 0.0000 (0.0289)  triple_40: 0.0000 (0.0990)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1020/1724]  eta: 0:46:02  lr: 0.000120  loss: 5.0336 (8.6839)  loss_n_40: 1.2572 (2.0049)  loss_n_60: 1.1723 (2.0136)  loss_n_80: 1.3065 (2.2158)  loss_n_100: 1.2803 (2.2185)  triple_100: 0.0000 (0.0458)  triple_80: 0.0000 (0.0585)  triple_60: 0.0000 (0.0286)  triple_40: 0.0000 (0.0981)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1030/1724]  eta: 0:45:23  lr: 0.000120  loss: 5.0336 (8.6529)  loss_n_40: 1.2414 (1.9989)  loss_n_60: 1.1354 (2.0068)  loss_n_80: 1.3065 (2.2077)  loss_n_100: 1.3054 (2.2106)  triple_100: 0.0000 (0.0454)  triple_80: 0.0000 (0.0580)  triple_60: 0.0000 (0.0284)  triple_40: 0.0000 (0.0973)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1040/1724]  eta: 0:44:44  lr: 0.000120  loss: 5.2506 (8.6230)  loss_n_40: 1.3452 (1.9924)  loss_n_60: 1.2559 (1.9994)  loss_n_80: 1.3551 (2.1996)  loss_n_100: 1.3604 (2.2024)  triple_100: 0.0000 (0.0449)  triple_80: 0.0000 (0.0574)  triple_60: 0.0000 (0.0301)  triple_40: 0.0000 (0.0968)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1050/1724]  eta: 0:44:04  lr: 0.000120  loss: 5.3913 (8.5954)  loss_n_40: 1.3509 (1.9872)  loss_n_60: 1.2724 (1.9932)  loss_n_80: 1.3808 (2.1922)  loss_n_100: 1.3669 (2.1948)  triple_100: 0.0000 (0.0445)  triple_80: 0.0000 (0.0578)  triple_60: 0.0000 (0.0298)  triple_40: 0.0000 (0.0959)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1060/1724]  eta: 0:43:25  lr: 0.000120  loss: 5.3790 (8.5666)  loss_n_40: 1.4274 (1.9818)  loss_n_60: 1.2900 (1.9868)  loss_n_80: 1.3904 (2.1848)  loss_n_100: 1.3739 (2.1874)  triple_100: 0.0000 (0.0441)  triple_80: 0.0000 (0.0572)  triple_60: 0.0000 (0.0295)  triple_40: 0.0000 (0.0949)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1070/1724]  eta: 0:42:46  lr: 0.000120  loss: 5.3572 (8.5364)  loss_n_40: 1.3359 (1.9759)  loss_n_60: 1.2733 (1.9801)  loss_n_80: 1.3627 (2.1770)  loss_n_100: 1.3791 (2.1798)  triple_100: 0.0000 (0.0437)  triple_80: 0.0000 (0.0567)  triple_60: 0.0000 (0.0292)  triple_40: 0.0000 (0.0941)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1080/1724]  eta: 0:42:07  lr: 0.000120  loss: 5.1747 (8.5048)  loss_n_40: 1.2622 (1.9691)  loss_n_60: 1.2099 (1.9729)  loss_n_80: 1.3410 (2.1691)  loss_n_100: 1.3781 (2.1722)  triple_100: 0.0000 (0.0433)  triple_80: 0.0000 (0.0562)  triple_60: 0.0000 (0.0290)  triple_40: 0.0000 (0.0932)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1090/1724]  eta: 0:41:27  lr: 0.000120  loss: 5.1266 (8.4764)  loss_n_40: 1.2355 (1.9626)  loss_n_60: 1.1775 (1.9656)  loss_n_80: 1.3211 (2.1612)  loss_n_100: 1.3576 (2.1647)  triple_100: 0.0000 (0.0442)  triple_80: 0.0000 (0.0561)  triple_60: 0.0000 (0.0287)  triple_40: 0.0000 (0.0933)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1100/1724]  eta: 0:40:48  lr: 0.000120  loss: 5.6951 (8.4524)  loss_n_40: 1.3516 (1.9577)  loss_n_60: 1.3085 (1.9603)  loss_n_80: 1.4258 (2.1552)  loss_n_100: 1.4465 (2.1586)  triple_100: 0.0000 (0.0438)  triple_80: 0.0000 (0.0558)  triple_60: 0.0000 (0.0284)  triple_40: 0.0000 (0.0925)  time: 3.9214  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1110/1724]  eta: 0:40:09  lr: 0.000120  loss: 5.3723 (8.4224)  loss_n_40: 1.3394 (1.9513)  loss_n_60: 1.2927 (1.9532)  loss_n_80: 1.4053 (2.1478)  loss_n_100: 1.4393 (2.1516)  triple_100: 0.0000 (0.0434)  triple_80: 0.0000 (0.0553)  triple_60: 0.0000 (0.0282)  triple_40: 0.0000 (0.0916)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1120/1724]  eta: 0:39:30  lr: 0.000120  loss: 4.9266 (8.3899)  loss_n_40: 1.2184 (1.9448)  loss_n_60: 1.1207 (1.9457)  loss_n_80: 1.2533 (2.1395)  loss_n_100: 1.2878 (2.1433)  triple_100: 0.0000 (0.0430)  triple_80: 0.0000 (0.0548)  triple_60: 0.0000 (0.0279)  triple_40: 0.0000 (0.0908)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1130/1724]  eta: 0:38:50  lr: 0.000120  loss: 4.5365 (8.3549)  loss_n_40: 1.1026 (1.9370)  loss_n_60: 1.0321 (1.9375)  loss_n_80: 1.1746 (2.1309)  loss_n_100: 1.2217 (2.1349)  triple_100: 0.0000 (0.0427)  triple_80: 0.0000 (0.0543)  triple_60: 0.0000 (0.0277)  triple_40: 0.0000 (0.0900)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1140/1724]  eta: 0:38:11  lr: 0.000120  loss: 4.3471 (8.3194)  loss_n_40: 1.0294 (1.9291)  loss_n_60: 1.0123 (1.9291)  loss_n_80: 1.1127 (2.1219)  loss_n_100: 1.1858 (2.1264)  triple_100: 0.0000 (0.0423)  triple_80: 0.0000 (0.0539)  triple_60: 0.0000 (0.0274)  triple_40: 0.0000 (0.0892)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1150/1724]  eta: 0:37:32  lr: 0.000120  loss: 4.0170 (8.2822)  loss_n_40: 0.9836 (1.9210)  loss_n_60: 0.9135 (1.9204)  loss_n_80: 1.0195 (2.1124)  loss_n_100: 1.1101 (2.1174)  triple_100: 0.0000 (0.0419)  triple_80: 0.0000 (0.0534)  triple_60: 0.0000 (0.0272)  triple_40: 0.0000 (0.0884)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1160/1724]  eta: 0:36:53  lr: 0.000120  loss: 4.0422 (8.2622)  loss_n_40: 0.9576 (1.9154)  loss_n_60: 0.9347 (1.9149)  loss_n_80: 1.0282 (2.1068)  loss_n_100: 1.1117 (2.1119)  triple_100: 0.0000 (0.0434)  triple_80: 0.0000 (0.0537)  triple_60: 0.0000 (0.0281)  triple_40: 0.0000 (0.0882)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1170/1724]  eta: 0:36:13  lr: 0.000120  loss: 9.1809 (8.2858)  loss_n_40: 1.7388 (1.9175)  loss_n_60: 2.0817 (1.9198)  loss_n_80: 2.5571 (2.1155)  loss_n_100: 2.4358 (2.1202)  triple_100: 0.0000 (0.0430)  triple_80: 0.0000 (0.0545)  triple_60: 0.0000 (0.0278)  triple_40: 0.0000 (0.0874)  time: 3.9245  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1180/1724]  eta: 0:35:34  lr: 0.000120  loss: 10.2175 (8.2997)  loss_n_40: 2.0493 (1.9186)  loss_n_60: 2.2556 (1.9218)  loss_n_80: 2.9732 (2.1221)  loss_n_100: 2.9228 (2.1262)  triple_100: 0.0000 (0.0426)  triple_80: 0.0000 (0.0540)  triple_60: 0.0000 (0.0276)  triple_40: 0.0000 (0.0867)  time: 3.9250  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1190/1724]  eta: 0:34:55  lr: 0.000120  loss: 8.6574 (8.2973)  loss_n_40: 1.9771 (1.9185)  loss_n_60: 1.8386 (1.9201)  loss_n_80: 2.4481 (2.1229)  loss_n_100: 2.3691 (2.1265)  triple_100: 0.0000 (0.0426)  triple_80: 0.0000 (0.0536)  triple_60: 0.0000 (0.0274)  triple_40: 0.0000 (0.0859)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1200/1724]  eta: 0:34:16  lr: 0.000120  loss: 7.5290 (8.2879)  loss_n_40: 1.7406 (1.9159)  loss_n_60: 1.6457 (1.9174)  loss_n_80: 2.0432 (2.1217)  loss_n_100: 2.0315 (2.1252)  triple_100: 0.0000 (0.0422)  triple_80: 0.0000 (0.0531)  triple_60: 0.0000 (0.0271)  triple_40: 0.0000 (0.0852)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1210/1724]  eta: 0:33:37  lr: 0.000120  loss: 6.8012 (8.2774)  loss_n_40: 1.4967 (1.9123)  loss_n_60: 1.6003 (1.9147)  loss_n_80: 1.8655 (2.1189)  loss_n_100: 1.9361 (2.1228)  triple_100: 0.0000 (0.0419)  triple_80: 0.0000 (0.0527)  triple_60: 0.0000 (0.0297)  triple_40: 0.0000 (0.0845)  time: 3.9249  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [1220/1724]  eta: 0:32:57  lr: 0.000120  loss: 6.4468 (8.2583)  loss_n_40: 1.3550 (1.9079)  loss_n_60: 1.4915 (1.9104)  loss_n_80: 1.6782 (2.1143)  loss_n_100: 1.6657 (2.1187)  triple_100: 0.0000 (0.0415)  triple_80: 0.0000 (0.0523)  triple_60: 0.0000 (0.0294)  triple_40: 0.0000 (0.0838)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1230/1724]  eta: 0:32:18  lr: 0.000120  loss: 5.7345 (8.2376)  loss_n_40: 1.2399 (1.9025)  loss_n_60: 1.2893 (1.9054)  loss_n_80: 1.4731 (2.1089)  loss_n_100: 1.5437 (2.1139)  triple_100: 0.0000 (0.0412)  triple_80: 0.0000 (0.0518)  triple_60: 0.0000 (0.0292)  triple_40: 0.0000 (0.0847)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1240/1724]  eta: 0:31:39  lr: 0.000120  loss: 5.3250 (8.2116)  loss_n_40: 1.1418 (1.8965)  loss_n_60: 1.2340 (1.8993)  loss_n_80: 1.3860 (2.1027)  loss_n_100: 1.4543 (2.1079)  triple_100: 0.0000 (0.0408)  triple_80: 0.0000 (0.0514)  triple_60: 0.0000 (0.0289)  triple_40: 0.0000 (0.0840)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1250/1724]  eta: 0:31:00  lr: 0.000120  loss: 4.8012 (8.1841)  loss_n_40: 1.1001 (1.8898)  loss_n_60: 1.0817 (1.8929)  loss_n_80: 1.3286 (2.0964)  loss_n_100: 1.2966 (2.1014)  triple_100: 0.0000 (0.0405)  triple_80: 0.0000 (0.0510)  triple_60: 0.0000 (0.0288)  triple_40: 0.0000 (0.0833)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1260/1724]  eta: 0:30:20  lr: 0.000120  loss: 5.0614 (8.1632)  loss_n_40: 1.2332 (1.8861)  loss_n_60: 1.1085 (1.8876)  loss_n_80: 1.3488 (2.0910)  loss_n_100: 1.3212 (2.0961)  triple_100: 0.0000 (0.0402)  triple_80: 0.0000 (0.0506)  triple_60: 0.0000 (0.0289)  triple_40: 0.0000 (0.0827)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1270/1724]  eta: 0:29:41  lr: 0.000120  loss: 5.0844 (8.1372)  loss_n_40: 1.3193 (1.8806)  loss_n_60: 1.1532 (1.8816)  loss_n_80: 1.3258 (2.0842)  loss_n_100: 1.3017 (2.0897)  triple_100: 0.0000 (0.0399)  triple_80: 0.0000 (0.0502)  triple_60: 0.0000 (0.0287)  triple_40: 0.0000 (0.0822)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1280/1724]  eta: 0:29:02  lr: 0.000120  loss: 4.7964 (8.1119)  loss_n_40: 1.0863 (1.8750)  loss_n_60: 1.0888 (1.8754)  loss_n_80: 1.2443 (2.0776)  loss_n_100: 1.2699 (2.0832)  triple_100: 0.0000 (0.0396)  triple_80: 0.0000 (0.0505)  triple_60: 0.0000 (0.0285)  triple_40: 0.0000 (0.0822)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1290/1724]  eta: 0:28:23  lr: 0.000120  loss: 4.7964 (8.0887)  loss_n_40: 1.1761 (1.8694)  loss_n_60: 1.0845 (1.8701)  loss_n_80: 1.2443 (2.0717)  loss_n_100: 1.2657 (2.0781)  triple_100: 0.0000 (0.0393)  triple_80: 0.0000 (0.0503)  triple_60: 0.0000 (0.0282)  triple_40: 0.0000 (0.0816)  time: 3.9241  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1300/1724]  eta: 0:27:43  lr: 0.000120  loss: 6.4117 (8.1033)  loss_n_40: 1.3327 (1.8686)  loss_n_60: 1.4718 (1.8709)  loss_n_80: 1.7833 (2.0735)  loss_n_100: 1.9240 (2.0811)  triple_100: 0.0000 (0.0403)  triple_80: 0.0000 (0.0528)  triple_60: 0.0000 (0.0350)  triple_40: 0.0000 (0.0809)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1310/1724]  eta: 0:27:04  lr: 0.000120  loss: 10.1325 (8.1203)  loss_n_40: 2.0321 (1.8726)  loss_n_60: 2.2731 (1.8759)  loss_n_80: 2.5570 (2.0785)  loss_n_100: 2.6244 (2.0859)  triple_100: 0.0000 (0.0400)  triple_80: 0.0000 (0.0524)  triple_60: 0.0000 (0.0348)  triple_40: 0.0000 (0.0803)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1320/1724]  eta: 0:26:25  lr: 0.000120  loss: 10.1325 (8.1300)  loss_n_40: 2.2041 (1.8736)  loss_n_60: 2.4183 (1.8786)  loss_n_80: 2.5732 (2.0809)  loss_n_100: 2.5929 (2.0875)  triple_100: 0.0000 (0.0397)  triple_80: 0.0000 (0.0542)  triple_60: 0.0000 (0.0359)  triple_40: 0.0000 (0.0797)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1330/1724]  eta: 0:25:46  lr: 0.000120  loss: 8.8453 (8.1327)  loss_n_40: 1.9287 (1.8740)  loss_n_60: 2.2132 (1.8807)  loss_n_80: 2.2873 (2.0821)  loss_n_100: 2.3048 (2.0880)  triple_100: 0.0000 (0.0394)  triple_80: 0.0000 (0.0538)  triple_60: 0.0000 (0.0356)  triple_40: 0.0000 (0.0791)  time: 3.9220  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1340/1724]  eta: 0:25:06  lr: 0.000120  loss: 8.2062 (8.1289)  loss_n_40: 1.8299 (1.8729)  loss_n_60: 2.1386 (1.8812)  loss_n_80: 2.1680 (2.0813)  loss_n_100: 2.1121 (2.0872)  triple_100: 0.0000 (0.0391)  triple_80: 0.0000 (0.0534)  triple_60: 0.0000 (0.0353)  triple_40: 0.0000 (0.0785)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1350/1724]  eta: 0:24:27  lr: 0.000120  loss: 7.1673 (8.1201)  loss_n_40: 1.6733 (1.8715)  loss_n_60: 1.8482 (1.8805)  loss_n_80: 1.8789 (2.0792)  loss_n_100: 1.6998 (2.0842)  triple_100: 0.0000 (0.0388)  triple_80: 0.0000 (0.0530)  triple_60: 0.0000 (0.0351)  triple_40: 0.0000 (0.0779)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1360/1724]  eta: 0:23:48  lr: 0.000120  loss: 6.5518 (8.1061)  loss_n_40: 1.5292 (1.8681)  loss_n_60: 1.6810 (1.8781)  loss_n_80: 1.6985 (2.0757)  loss_n_100: 1.6266 (2.0807)  triple_100: 0.0000 (0.0385)  triple_80: 0.0000 (0.0528)  triple_60: 0.0000 (0.0348)  triple_40: 0.0000 (0.0774)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1370/1724]  eta: 0:23:09  lr: 0.000120  loss: 5.8856 (8.0884)  loss_n_40: 1.3351 (1.8641)  loss_n_60: 1.4774 (1.8746)  loss_n_80: 1.4862 (2.0711)  loss_n_100: 1.4747 (2.0765)  triple_100: 0.0000 (0.0382)  triple_80: 0.0000 (0.0524)  triple_60: 0.0000 (0.0346)  triple_40: 0.0000 (0.0768)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1380/1724]  eta: 0:22:29  lr: 0.000120  loss: 5.3671 (8.0674)  loss_n_40: 1.2536 (1.8598)  loss_n_60: 1.3006 (1.8701)  loss_n_80: 1.3169 (2.0654)  loss_n_100: 1.4686 (2.0716)  triple_100: 0.0000 (0.0380)  triple_80: 0.0000 (0.0520)  triple_60: 0.0000 (0.0343)  triple_40: 0.0000 (0.0763)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1390/1724]  eta: 0:21:50  lr: 0.000120  loss: 4.9876 (8.0442)  loss_n_40: 1.1487 (1.8546)  loss_n_60: 1.1729 (1.8652)  loss_n_80: 1.2291 (2.0592)  loss_n_100: 1.3666 (2.0661)  triple_100: 0.0000 (0.0377)  triple_80: 0.0000 (0.0516)  triple_60: 0.0000 (0.0341)  triple_40: 0.0000 (0.0757)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1400/1724]  eta: 0:21:11  lr: 0.000120  loss: 4.8285 (8.0261)  loss_n_40: 1.1104 (1.8500)  loss_n_60: 1.1684 (1.8608)  loss_n_80: 1.1909 (2.0542)  loss_n_100: 1.3627 (2.0618)  triple_100: 0.0000 (0.0386)  triple_80: 0.0000 (0.0516)  triple_60: 0.0000 (0.0338)  triple_40: 0.0000 (0.0752)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1410/1724]  eta: 0:20:32  lr: 0.000120  loss: 5.9454 (8.0181)  loss_n_40: 1.3727 (1.8476)  loss_n_60: 1.4908 (1.8591)  loss_n_80: 1.5904 (2.0528)  loss_n_100: 1.5949 (2.0607)  triple_100: 0.0000 (0.0383)  triple_80: 0.0000 (0.0513)  triple_60: 0.0000 (0.0336)  triple_40: 0.0000 (0.0747)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1420/1724]  eta: 0:19:52  lr: 0.000120  loss: 6.4423 (8.0051)  loss_n_40: 1.4302 (1.8440)  loss_n_60: 1.5097 (1.8565)  loss_n_80: 1.6421 (2.0496)  loss_n_100: 1.7207 (2.0578)  triple_100: 0.0000 (0.0380)  triple_80: 0.0000 (0.0509)  triple_60: 0.0000 (0.0339)  triple_40: 0.0000 (0.0743)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1430/1724]  eta: 0:19:13  lr: 0.000120  loss: 6.1361 (7.9896)  loss_n_40: 1.2499 (1.8405)  loss_n_60: 1.4449 (1.8535)  loss_n_80: 1.5036 (2.0456)  loss_n_100: 1.5853 (2.0543)  triple_100: 0.0000 (0.0378)  triple_80: 0.0000 (0.0506)  triple_60: 0.0000 (0.0336)  triple_40: 0.0000 (0.0738)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1440/1724]  eta: 0:18:34  lr: 0.000120  loss: 5.3630 (7.9704)  loss_n_40: 1.1493 (1.8356)  loss_n_60: 1.3042 (1.8495)  loss_n_80: 1.3763 (2.0408)  loss_n_100: 1.4579 (2.0502)  triple_100: 0.0000 (0.0375)  triple_80: 0.0000 (0.0502)  triple_60: 0.0000 (0.0334)  triple_40: 0.0000 (0.0733)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1450/1724]  eta: 0:17:55  lr: 0.000120  loss: 5.5484 (7.9573)  loss_n_40: 1.1263 (1.8316)  loss_n_60: 1.3583 (1.8468)  loss_n_80: 1.4476 (2.0377)  loss_n_100: 1.5134 (2.0476)  triple_100: 0.0000 (0.0376)  triple_80: 0.0000 (0.0501)  triple_60: 0.0000 (0.0332)  triple_40: 0.0000 (0.0728)  time: 3.9247  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [1460/1724]  eta: 0:17:15  lr: 0.000120  loss: 5.9353 (7.9413)  loss_n_40: 1.2367 (1.8281)  loss_n_60: 1.4262 (1.8436)  loss_n_80: 1.5299 (2.0337)  loss_n_100: 1.5134 (2.0436)  triple_100: 0.0000 (0.0373)  triple_80: 0.0000 (0.0498)  triple_60: 0.0000 (0.0329)  triple_40: 0.0000 (0.0723)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1470/1724]  eta: 0:16:36  lr: 0.000120  loss: 5.1822 (7.9220)  loss_n_40: 1.1662 (1.8235)  loss_n_60: 1.2501 (1.8395)  loss_n_80: 1.3504 (2.0289)  loss_n_100: 1.3835 (2.0390)  triple_100: 0.0000 (0.0371)  triple_80: 0.0000 (0.0494)  triple_60: 0.0000 (0.0327)  triple_40: 0.0000 (0.0718)  time: 3.9241  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1480/1724]  eta: 0:15:57  lr: 0.000120  loss: 4.8611 (7.9013)  loss_n_40: 1.0101 (1.8181)  loss_n_60: 1.1853 (1.8351)  loss_n_80: 1.3144 (2.0239)  loss_n_100: 1.3618 (2.0343)  triple_100: 0.0000 (0.0368)  triple_80: 0.0000 (0.0492)  triple_60: 0.0000 (0.0326)  triple_40: 0.0000 (0.0713)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1490/1724]  eta: 0:15:18  lr: 0.000120  loss: 4.8582 (7.8806)  loss_n_40: 1.0131 (1.8129)  loss_n_60: 1.1853 (1.8306)  loss_n_80: 1.3068 (2.0190)  loss_n_100: 1.3335 (2.0296)  triple_100: 0.0000 (0.0366)  triple_80: 0.0000 (0.0489)  triple_60: 0.0000 (0.0323)  triple_40: 0.0000 (0.0708)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1500/1724]  eta: 0:14:38  lr: 0.000120  loss: 4.8233 (7.8626)  loss_n_40: 1.0153 (1.8084)  loss_n_60: 1.1846 (1.8268)  loss_n_80: 1.3055 (2.0144)  loss_n_100: 1.3335 (2.0251)  triple_100: 0.0000 (0.0363)  triple_80: 0.0000 (0.0488)  triple_60: 0.0000 (0.0323)  triple_40: 0.0000 (0.0704)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1510/1724]  eta: 0:13:59  lr: 0.000120  loss: 4.8233 (7.8442)  loss_n_40: 0.9694 (1.8035)  loss_n_60: 1.1637 (1.8225)  loss_n_80: 1.2971 (2.0097)  loss_n_100: 1.3465 (2.0208)  triple_100: 0.0000 (0.0367)  triple_80: 0.0000 (0.0489)  triple_60: 0.0000 (0.0321)  triple_40: 0.0000 (0.0699)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1520/1724]  eta: 0:13:20  lr: 0.000120  loss: 4.8781 (7.8252)  loss_n_40: 0.9903 (1.7991)  loss_n_60: 1.1378 (1.8185)  loss_n_80: 1.3208 (2.0049)  loss_n_100: 1.3465 (2.0162)  triple_100: 0.0000 (0.0365)  triple_80: 0.0000 (0.0486)  triple_60: 0.0000 (0.0319)  triple_40: 0.0000 (0.0694)  time: 3.9236  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1530/1724]  eta: 0:12:41  lr: 0.000120  loss: 4.5141 (7.8044)  loss_n_40: 0.9462 (1.7935)  loss_n_60: 1.1123 (1.8140)  loss_n_80: 1.1967 (1.9994)  loss_n_100: 1.2495 (2.0111)  triple_100: 0.0000 (0.0368)  triple_80: 0.0000 (0.0486)  triple_60: 0.0000 (0.0320)  triple_40: 0.0000 (0.0690)  time: 3.9243  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1540/1724]  eta: 0:12:02  lr: 0.000120  loss: 4.3911 (7.7844)  loss_n_40: 0.9817 (1.7890)  loss_n_60: 1.1123 (1.8100)  loss_n_80: 1.1157 (1.9943)  loss_n_100: 1.2144 (2.0060)  triple_100: 0.0000 (0.0365)  triple_80: 0.0000 (0.0483)  triple_60: 0.0000 (0.0318)  triple_40: 0.0000 (0.0685)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1550/1724]  eta: 0:11:22  lr: 0.000120  loss: 4.3714 (7.7622)  loss_n_40: 0.9975 (1.7839)  loss_n_60: 1.1425 (1.8054)  loss_n_80: 1.1079 (1.9885)  loss_n_100: 1.1775 (2.0005)  triple_100: 0.0000 (0.0363)  triple_80: 0.0000 (0.0480)  triple_60: 0.0000 (0.0316)  triple_40: 0.0000 (0.0681)  time: 3.9242  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1560/1724]  eta: 0:10:43  lr: 0.000120  loss: 4.1242 (7.7398)  loss_n_40: 0.8956 (1.7785)  loss_n_60: 1.0520 (1.8007)  loss_n_80: 1.0516 (1.9829)  loss_n_100: 1.1231 (1.9949)  triple_100: 0.0000 (0.0361)  triple_80: 0.0000 (0.0477)  triple_60: 0.0000 (0.0314)  triple_40: 0.0000 (0.0677)  time: 3.9253  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1570/1724]  eta: 0:10:04  lr: 0.000120  loss: 3.9763 (7.7156)  loss_n_40: 0.8548 (1.7730)  loss_n_60: 1.0040 (1.7956)  loss_n_80: 1.0155 (1.9768)  loss_n_100: 1.0515 (1.9886)  triple_100: 0.0000 (0.0358)  triple_80: 0.0000 (0.0474)  triple_60: 0.0000 (0.0312)  triple_40: 0.0000 (0.0672)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1580/1724]  eta: 0:09:25  lr: 0.000120  loss: 3.8140 (7.6913)  loss_n_40: 0.8144 (1.7671)  loss_n_60: 0.9466 (1.7903)  loss_n_80: 1.0052 (1.9707)  loss_n_100: 1.0488 (1.9828)  triple_100: 0.0000 (0.0356)  triple_80: 0.0000 (0.0471)  triple_60: 0.0000 (0.0310)  triple_40: 0.0000 (0.0668)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1590/1724]  eta: 0:08:45  lr: 0.000120  loss: 4.5154 (7.7368)  loss_n_40: 0.8423 (1.7705)  loss_n_60: 1.0153 (1.7937)  loss_n_80: 1.1034 (1.9745)  loss_n_100: 1.1418 (1.9856)  triple_100: 0.0000 (0.0394)  triple_80: 0.0000 (0.0689)  triple_60: 0.0000 (0.0367)  triple_40: 0.0000 (0.0675)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1600/1724]  eta: 0:08:06  lr: 0.000120  loss: 14.2672 (7.7767)  loss_n_40: 3.5441 (1.7828)  loss_n_60: 3.2862 (1.8041)  loss_n_80: 3.3036 (1.9841)  loss_n_100: 3.0531 (1.9930)  triple_100: 0.0000 (0.0392)  triple_80: 0.0000 (0.0700)  triple_60: 0.0000 (0.0364)  triple_40: 0.0000 (0.0671)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1610/1724]  eta: 0:07:27  lr: 0.000120  loss: 13.8088 (7.8125)  loss_n_40: 3.6953 (1.7943)  loss_n_60: 3.3389 (1.8133)  loss_n_80: 3.4771 (1.9928)  loss_n_100: 3.2060 (2.0003)  triple_100: 0.0000 (0.0389)  triple_80: 0.0000 (0.0695)  triple_60: 0.0000 (0.0362)  triple_40: 0.0000 (0.0671)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1620/1724]  eta: 0:06:48  lr: 0.000120  loss: 12.5648 (7.8382)  loss_n_40: 3.2611 (1.8017)  loss_n_60: 3.1320 (1.8205)  loss_n_80: 3.2070 (1.9994)  loss_n_100: 3.0497 (2.0058)  triple_100: 0.0000 (0.0387)  triple_80: 0.0000 (0.0691)  triple_60: 0.0000 (0.0360)  triple_40: 0.0000 (0.0671)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1630/1724]  eta: 0:06:08  lr: 0.000120  loss: 10.9657 (7.8556)  loss_n_40: 2.7057 (1.8063)  loss_n_60: 2.6957 (1.8256)  loss_n_80: 2.8988 (2.0046)  loss_n_100: 2.7587 (2.0096)  triple_100: 0.0000 (0.0384)  triple_80: 0.0000 (0.0687)  triple_60: 0.0000 (0.0358)  triple_40: 0.0000 (0.0666)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1640/1724]  eta: 0:05:29  lr: 0.000120  loss: 10.7229 (7.8698)  loss_n_40: 2.4245 (1.8096)  loss_n_60: 2.6247 (1.8299)  loss_n_80: 2.8607 (2.0092)  loss_n_100: 2.6053 (2.0129)  triple_100: 0.0000 (0.0382)  triple_80: 0.0000 (0.0683)  triple_60: 0.0000 (0.0355)  triple_40: 0.0000 (0.0662)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1650/1724]  eta: 0:04:50  lr: 0.000120  loss: 9.7921 (7.8812)  loss_n_40: 2.3120 (1.8122)  loss_n_60: 2.4801 (1.8333)  loss_n_80: 2.7034 (2.0131)  loss_n_100: 2.3800 (2.0153)  triple_100: 0.0000 (0.0380)  triple_80: 0.0000 (0.0681)  triple_60: 0.0000 (0.0353)  triple_40: 0.0000 (0.0658)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1660/1724]  eta: 0:04:11  lr: 0.000120  loss: 10.2151 (7.8959)  loss_n_40: 2.3708 (1.8157)  loss_n_60: 2.4854 (1.8374)  loss_n_80: 2.7034 (2.0179)  loss_n_100: 2.5123 (2.0190)  triple_100: 0.0000 (0.0377)  triple_80: 0.0000 (0.0677)  triple_60: 0.0000 (0.0351)  triple_40: 0.0000 (0.0654)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1670/1724]  eta: 0:03:31  lr: 0.000120  loss: 10.2345 (7.9066)  loss_n_40: 2.3390 (1.8179)  loss_n_60: 2.4288 (1.8402)  loss_n_80: 2.7862 (2.0218)  loss_n_100: 2.5936 (2.0219)  triple_100: 0.0000 (0.0375)  triple_80: 0.0000 (0.0673)  triple_60: 0.0000 (0.0349)  triple_40: 0.0000 (0.0650)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1680/1724]  eta: 0:02:52  lr: 0.000120  loss: 9.6061 (7.9176)  loss_n_40: 2.1655 (1.8204)  loss_n_60: 2.2274 (1.8430)  loss_n_80: 2.5837 (2.0254)  loss_n_100: 2.4640 (2.0249)  triple_100: 0.0000 (0.0373)  triple_80: 0.0000 (0.0672)  triple_60: 0.0000 (0.0347)  triple_40: 0.0000 (0.0647)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1690/1724]  eta: 0:02:13  lr: 0.000120  loss: 9.2318 (7.9245)  loss_n_40: 2.1018 (1.8220)  loss_n_60: 2.1999 (1.8449)  loss_n_80: 2.4870 (2.0278)  loss_n_100: 2.4229 (2.0271)  triple_100: 0.0000 (0.0371)  triple_80: 0.0000 (0.0668)  triple_60: 0.0000 (0.0345)  triple_40: 0.0000 (0.0643)  time: 3.9243  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [1700/1724]  eta: 0:01:34  lr: 0.000120  loss: 8.6510 (7.9299)  loss_n_40: 2.0240 (1.8235)  loss_n_60: 2.0714 (1.8464)  loss_n_80: 2.2982 (2.0297)  loss_n_100: 2.3377 (2.0287)  triple_100: 0.0000 (0.0369)  triple_80: 0.0000 (0.0665)  triple_60: 0.0000 (0.0343)  triple_40: 0.0000 (0.0639)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:7]  [1710/1724]  eta: 0:00:54  lr: 0.000120  loss: 8.6205 (7.9349)  loss_n_40: 2.0240 (1.8250)  loss_n_60: 2.0191 (1.8479)  loss_n_80: 2.2982 (2.0316)  loss_n_100: 2.2256 (2.0301)  triple_100: 0.0000 (0.0366)  triple_80: 0.0000 (0.0661)  triple_60: 0.0000 (0.0341)  triple_40: 0.0000 (0.0635)  time: 3.9244  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1720/1724]  eta: 0:00:15  lr: 0.000120  loss: 8.5247 (7.9398)  loss_n_40: 1.9927 (1.8264)  loss_n_60: 2.0636 (1.8495)  loss_n_80: 2.3242 (2.0334)  loss_n_100: 2.2256 (2.0313)  triple_100: 0.0000 (0.0364)  triple_80: 0.0000 (0.0657)  triple_60: 0.0000 (0.0339)  triple_40: 0.0000 (0.0632)  time: 3.9247  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7]  [1723/1724]  eta: 0:00:03  lr: 0.000120  loss: 8.4081 (7.9414)  loss_n_40: 1.9808 (1.8267)  loss_n_60: 2.0191 (1.8501)  loss_n_80: 2.2784 (2.0341)  loss_n_100: 2.2016 (2.0317)  triple_100: 0.0000 (0.0364)  triple_80: 0.0000 (0.0656)  triple_60: 0.0000 (0.0338)  triple_40: 0.0000 (0.0631)  time: 3.9246  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:7] Total time: 1:52:45 (3.9242 s / it)\n",
      "Averaged stats: lr: 0.000120  loss: 8.4081 (7.9414)  loss_n_40: 1.9808 (1.8267)  loss_n_60: 2.0191 (1.8501)  loss_n_80: 2.2784 (2.0341)  loss_n_100: 2.2016 (2.0317)  triple_100: 0.0000 (0.0364)  triple_80: 0.0000 (0.0656)  triple_60: 0.0000 (0.0338)  triple_40: 0.0000 (0.0631)\n",
      "Valid: [epoch:7]  [  0/845]  eta: 0:11:11  loss: 9.2058 (9.2058)  loss_n_40: 2.1161 (2.1161)  loss_n_60: 2.1553 (2.1553)  loss_n_80: 2.5099 (2.5099)  loss_n_100: 2.4245 (2.4245)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7941  data: 0.4608  max mem: 46473\n",
      "Valid: [epoch:7]  [ 10/845]  eta: 0:05:14  loss: 8.0530 (8.6926)  loss_n_40: 1.9587 (2.0282)  loss_n_60: 1.8970 (2.0545)  loss_n_80: 2.1709 (2.3440)  loss_n_100: 2.0906 (2.2659)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3764  data: 0.0420  max mem: 46473\n",
      "Valid: [epoch:7]  [ 20/845]  eta: 0:04:54  loss: 7.9947 (8.5959)  loss_n_40: 1.9169 (1.9882)  loss_n_60: 1.8598 (2.0494)  loss_n_80: 2.1546 (2.3225)  loss_n_100: 2.0880 (2.2357)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [ 30/845]  eta: 0:04:44  loss: 7.8512 (8.6978)  loss_n_40: 1.8621 (1.9973)  loss_n_60: 1.8415 (2.0816)  loss_n_80: 2.1968 (2.3524)  loss_n_100: 2.0891 (2.2666)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [ 40/845]  eta: 0:04:38  loss: 7.5887 (8.3643)  loss_n_40: 1.8996 (1.9608)  loss_n_60: 1.8033 (2.0052)  loss_n_80: 2.0875 (2.2530)  loss_n_100: 2.0372 (2.1453)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [ 50/845]  eta: 0:04:33  loss: 7.6465 (8.3825)  loss_n_40: 1.8990 (1.9586)  loss_n_60: 1.8033 (2.0108)  loss_n_80: 2.0858 (2.2566)  loss_n_100: 2.0254 (2.1565)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:7]  [ 60/845]  eta: 0:04:28  loss: 7.9242 (8.3879)  loss_n_40: 1.7722 (1.9501)  loss_n_60: 1.8561 (2.0103)  loss_n_80: 2.1483 (2.2593)  loss_n_100: 2.0503 (2.1682)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [ 70/845]  eta: 0:04:24  loss: 8.0722 (8.4202)  loss_n_40: 1.9047 (1.9563)  loss_n_60: 1.8789 (2.0176)  loss_n_80: 2.1543 (2.2665)  loss_n_100: 2.1522 (2.1799)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [ 80/845]  eta: 0:04:20  loss: 7.7578 (8.3531)  loss_n_40: 1.8643 (1.9513)  loss_n_60: 1.8286 (2.0042)  loss_n_80: 2.0790 (2.2471)  loss_n_100: 2.0542 (2.1505)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [ 90/845]  eta: 0:04:16  loss: 7.5644 (8.3660)  loss_n_40: 1.8259 (1.9506)  loss_n_60: 1.8236 (2.0101)  loss_n_80: 2.0697 (2.2513)  loss_n_100: 2.0144 (2.1539)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [100/845]  eta: 0:04:12  loss: 7.7183 (8.3627)  loss_n_40: 1.8259 (1.9510)  loss_n_60: 1.8701 (2.0095)  loss_n_80: 2.1071 (2.2503)  loss_n_100: 2.0683 (2.1519)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [110/845]  eta: 0:04:08  loss: 7.8992 (8.4185)  loss_n_40: 1.9132 (1.9624)  loss_n_60: 1.9162 (2.0246)  loss_n_80: 2.1338 (2.2652)  loss_n_100: 2.0920 (2.1663)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [120/845]  eta: 0:04:05  loss: 8.2593 (8.3961)  loss_n_40: 1.9663 (1.9619)  loss_n_60: 1.9162 (2.0211)  loss_n_80: 2.1787 (2.2561)  loss_n_100: 2.1800 (2.1570)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [130/845]  eta: 0:04:01  loss: 7.3904 (8.3720)  loss_n_40: 1.7286 (1.9565)  loss_n_60: 1.7913 (2.0187)  loss_n_80: 2.0402 (2.2494)  loss_n_100: 1.9487 (2.1474)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:7]  [140/845]  eta: 0:03:58  loss: 7.6362 (8.3564)  loss_n_40: 1.8530 (1.9539)  loss_n_60: 1.8144 (2.0161)  loss_n_80: 2.0402 (2.2444)  loss_n_100: 1.9672 (2.1420)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [150/845]  eta: 0:03:54  loss: 8.0103 (8.3849)  loss_n_40: 1.9371 (1.9570)  loss_n_60: 1.8873 (2.0240)  loss_n_80: 2.1168 (2.2528)  loss_n_100: 2.0781 (2.1511)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [160/845]  eta: 0:03:51  loss: 7.7859 (8.3303)  loss_n_40: 1.8193 (1.9438)  loss_n_60: 1.9203 (2.0130)  loss_n_80: 2.0924 (2.2373)  loss_n_100: 2.0365 (2.1362)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [170/845]  eta: 0:03:47  loss: 7.5347 (8.2802)  loss_n_40: 1.7172 (1.9326)  loss_n_60: 1.7849 (1.9994)  loss_n_80: 2.0197 (2.2242)  loss_n_100: 1.9490 (2.1241)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3360  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:7]  [180/845]  eta: 0:03:44  loss: 7.5252 (8.2835)  loss_n_40: 1.7756 (1.9329)  loss_n_60: 1.8259 (2.0052)  loss_n_80: 2.0397 (2.2223)  loss_n_100: 1.9474 (2.1230)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3361  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [190/845]  eta: 0:03:40  loss: 9.2606 (8.3394)  loss_n_40: 2.0921 (1.9444)  loss_n_60: 2.1897 (2.0184)  loss_n_80: 2.4906 (2.2372)  loss_n_100: 2.3436 (2.1394)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:7]  [200/845]  eta: 0:03:37  loss: 7.8886 (8.3225)  loss_n_40: 1.9306 (1.9403)  loss_n_60: 1.9369 (2.0154)  loss_n_80: 2.1406 (2.2335)  loss_n_100: 2.0849 (2.1333)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [210/845]  eta: 0:03:33  loss: 7.7588 (8.2899)  loss_n_40: 1.8249 (1.9346)  loss_n_60: 1.8753 (2.0086)  loss_n_80: 2.0629 (2.2231)  loss_n_100: 2.0319 (2.1236)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [220/845]  eta: 0:03:30  loss: 7.4522 (8.2777)  loss_n_40: 1.8690 (1.9357)  loss_n_60: 1.8113 (2.0053)  loss_n_80: 2.0629 (2.2179)  loss_n_100: 1.9587 (2.1187)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [230/845]  eta: 0:03:27  loss: 7.3140 (8.2456)  loss_n_40: 1.7449 (1.9285)  loss_n_60: 1.8198 (1.9998)  loss_n_80: 1.9381 (2.2081)  loss_n_100: 1.9230 (2.1091)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [240/845]  eta: 0:03:23  loss: 7.8350 (8.2534)  loss_n_40: 1.8377 (1.9316)  loss_n_60: 1.8495 (2.0001)  loss_n_80: 2.0840 (2.2097)  loss_n_100: 2.0873 (2.1120)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [250/845]  eta: 0:03:20  loss: 7.8350 (8.2370)  loss_n_40: 1.8787 (1.9295)  loss_n_60: 1.8281 (1.9951)  loss_n_80: 2.0840 (2.2047)  loss_n_100: 2.0873 (2.1077)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [260/845]  eta: 0:03:16  loss: 7.6000 (8.2238)  loss_n_40: 1.8300 (1.9264)  loss_n_60: 1.8445 (1.9932)  loss_n_80: 2.0663 (2.2010)  loss_n_100: 1.9955 (2.1033)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [270/845]  eta: 0:03:13  loss: 7.6620 (8.2232)  loss_n_40: 1.7793 (1.9255)  loss_n_60: 1.8445 (1.9930)  loss_n_80: 2.1005 (2.2006)  loss_n_100: 2.0608 (2.1040)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [280/845]  eta: 0:03:09  loss: 7.8511 (8.2448)  loss_n_40: 1.8469 (1.9286)  loss_n_60: 1.9460 (1.9973)  loss_n_80: 2.1242 (2.2071)  loss_n_100: 2.1184 (2.1119)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [290/845]  eta: 0:03:06  loss: 8.7966 (8.2551)  loss_n_40: 2.0219 (1.9296)  loss_n_60: 2.0976 (1.9991)  loss_n_80: 2.3644 (2.2103)  loss_n_100: 2.2306 (2.1161)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [300/845]  eta: 0:03:03  loss: 7.9743 (8.2563)  loss_n_40: 1.8827 (1.9286)  loss_n_60: 1.8749 (1.9989)  loss_n_80: 2.1297 (2.2121)  loss_n_100: 2.1092 (2.1167)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [310/845]  eta: 0:02:59  loss: 7.3037 (8.2332)  loss_n_40: 1.6710 (1.9257)  loss_n_60: 1.7260 (1.9928)  loss_n_80: 2.0515 (2.2062)  loss_n_100: 1.9242 (2.1085)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [320/845]  eta: 0:02:56  loss: 7.1724 (8.2244)  loss_n_40: 1.8118 (1.9259)  loss_n_60: 1.7372 (1.9905)  loss_n_80: 2.0250 (2.2032)  loss_n_100: 1.8507 (2.1048)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [330/845]  eta: 0:02:53  loss: 7.4182 (8.2068)  loss_n_40: 1.8118 (1.9234)  loss_n_60: 1.7372 (1.9858)  loss_n_80: 2.0464 (2.1981)  loss_n_100: 1.9592 (2.0994)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [340/845]  eta: 0:02:49  loss: 7.4683 (8.2077)  loss_n_40: 1.9068 (1.9249)  loss_n_60: 1.7869 (1.9858)  loss_n_80: 2.0535 (2.1980)  loss_n_100: 1.9751 (2.0989)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [350/845]  eta: 0:02:46  loss: 7.5711 (8.1822)  loss_n_40: 1.7868 (1.9207)  loss_n_60: 1.8050 (1.9794)  loss_n_80: 2.0726 (2.1918)  loss_n_100: 1.9751 (2.0904)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [360/845]  eta: 0:02:42  loss: 7.3563 (8.1901)  loss_n_40: 1.7371 (1.9224)  loss_n_60: 1.7643 (1.9805)  loss_n_80: 2.0364 (2.1938)  loss_n_100: 1.9256 (2.0934)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [370/845]  eta: 0:02:39  loss: 7.4457 (8.1713)  loss_n_40: 1.7374 (1.9187)  loss_n_60: 1.7989 (1.9763)  loss_n_80: 2.0219 (2.1880)  loss_n_100: 1.9471 (2.0883)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [380/845]  eta: 0:02:36  loss: 7.4457 (8.1703)  loss_n_40: 1.7208 (1.9177)  loss_n_60: 1.7989 (1.9760)  loss_n_80: 2.0219 (2.1881)  loss_n_100: 1.9970 (2.0885)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [390/845]  eta: 0:02:32  loss: 7.5285 (8.1633)  loss_n_40: 1.7618 (1.9152)  loss_n_60: 1.7968 (1.9744)  loss_n_80: 2.0346 (2.1868)  loss_n_100: 1.9970 (2.0870)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [400/845]  eta: 0:02:29  loss: 7.7286 (8.1733)  loss_n_40: 1.7817 (1.9163)  loss_n_60: 1.8230 (1.9769)  loss_n_80: 2.1096 (2.1897)  loss_n_100: 2.0381 (2.0905)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [410/845]  eta: 0:02:26  loss: 7.7286 (8.1667)  loss_n_40: 1.7849 (1.9153)  loss_n_60: 1.8230 (1.9755)  loss_n_80: 2.1376 (2.1881)  loss_n_100: 2.0921 (2.0879)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [420/845]  eta: 0:02:22  loss: 7.8925 (8.1681)  loss_n_40: 1.7849 (1.9151)  loss_n_60: 1.8251 (1.9756)  loss_n_80: 2.1025 (2.1882)  loss_n_100: 2.0858 (2.0892)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [430/845]  eta: 0:02:19  loss: 7.7063 (8.1623)  loss_n_40: 1.8304 (1.9148)  loss_n_60: 1.8023 (1.9732)  loss_n_80: 2.0783 (2.1868)  loss_n_100: 2.0623 (2.0877)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [440/845]  eta: 0:02:15  loss: 7.5839 (8.1746)  loss_n_40: 1.8304 (1.9168)  loss_n_60: 1.7790 (1.9759)  loss_n_80: 2.0372 (2.1903)  loss_n_100: 2.0364 (2.0916)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:7]  [450/845]  eta: 0:02:12  loss: 7.7347 (8.1640)  loss_n_40: 1.8001 (1.9145)  loss_n_60: 1.8179 (1.9733)  loss_n_80: 2.0887 (2.1871)  loss_n_100: 2.0593 (2.0891)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [460/845]  eta: 0:02:09  loss: 7.6896 (8.1643)  loss_n_40: 1.7708 (1.9136)  loss_n_60: 1.7895 (1.9733)  loss_n_80: 2.0656 (2.1876)  loss_n_100: 2.0386 (2.0898)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [470/845]  eta: 0:02:05  loss: 7.7030 (8.1603)  loss_n_40: 1.7446 (1.9125)  loss_n_60: 1.7961 (1.9727)  loss_n_80: 2.0452 (2.1867)  loss_n_100: 2.0562 (2.0885)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [480/845]  eta: 0:02:02  loss: 7.7030 (8.1711)  loss_n_40: 1.7934 (1.9144)  loss_n_60: 1.8898 (1.9752)  loss_n_80: 2.0464 (2.1896)  loss_n_100: 2.1176 (2.0919)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [490/845]  eta: 0:01:59  loss: 7.6737 (8.1714)  loss_n_40: 1.8125 (1.9145)  loss_n_60: 1.8613 (1.9756)  loss_n_80: 2.0753 (2.1899)  loss_n_100: 1.9992 (2.0914)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [500/845]  eta: 0:01:55  loss: 7.7029 (8.1675)  loss_n_40: 1.8285 (1.9157)  loss_n_60: 1.8383 (1.9744)  loss_n_80: 2.0753 (2.1881)  loss_n_100: 2.0547 (2.0892)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [510/845]  eta: 0:01:52  loss: 7.7029 (8.1720)  loss_n_40: 1.8285 (1.9161)  loss_n_60: 1.8121 (1.9748)  loss_n_80: 2.0737 (2.1895)  loss_n_100: 2.0547 (2.0916)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [520/845]  eta: 0:01:49  loss: 7.6885 (8.1682)  loss_n_40: 1.7706 (1.9155)  loss_n_60: 1.8160 (1.9739)  loss_n_80: 2.0737 (2.1879)  loss_n_100: 2.0743 (2.0908)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [530/845]  eta: 0:01:45  loss: 7.6360 (8.1653)  loss_n_40: 1.7439 (1.9141)  loss_n_60: 1.8160 (1.9728)  loss_n_80: 2.0633 (2.1879)  loss_n_100: 2.0642 (2.0905)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [540/845]  eta: 0:01:42  loss: 7.5933 (8.1685)  loss_n_40: 1.7439 (1.9142)  loss_n_60: 1.7924 (1.9734)  loss_n_80: 2.0663 (2.1889)  loss_n_100: 2.0436 (2.0920)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [550/845]  eta: 0:01:38  loss: 7.6332 (8.1597)  loss_n_40: 1.7658 (1.9119)  loss_n_60: 1.7948 (1.9722)  loss_n_80: 2.0663 (2.1865)  loss_n_100: 2.0246 (2.0891)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [560/845]  eta: 0:01:35  loss: 7.3205 (8.1351)  loss_n_40: 1.6865 (1.9064)  loss_n_60: 1.7308 (1.9664)  loss_n_80: 1.9877 (2.1802)  loss_n_100: 1.8999 (2.0821)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [570/845]  eta: 0:01:32  loss: 7.3265 (8.1392)  loss_n_40: 1.6229 (1.9067)  loss_n_60: 1.7177 (1.9682)  loss_n_80: 2.0372 (2.1815)  loss_n_100: 1.9117 (2.0827)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [580/845]  eta: 0:01:28  loss: 7.9319 (8.1396)  loss_n_40: 1.8078 (1.9071)  loss_n_60: 1.8986 (1.9684)  loss_n_80: 2.1271 (2.1815)  loss_n_100: 2.0829 (2.0826)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [590/845]  eta: 0:01:25  loss: 7.9319 (8.1465)  loss_n_40: 1.8129 (1.9079)  loss_n_60: 1.9512 (1.9706)  loss_n_80: 2.1448 (2.1832)  loss_n_100: 2.0829 (2.0848)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [600/845]  eta: 0:01:22  loss: 7.7249 (8.1519)  loss_n_40: 1.8129 (1.9087)  loss_n_60: 1.8681 (1.9718)  loss_n_80: 2.1075 (2.1852)  loss_n_100: 2.0568 (2.0862)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [610/845]  eta: 0:01:18  loss: 7.7006 (8.1489)  loss_n_40: 1.8089 (1.9089)  loss_n_60: 1.8196 (1.9711)  loss_n_80: 2.0695 (2.1841)  loss_n_100: 2.0325 (2.0847)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [620/845]  eta: 0:01:15  loss: 7.7017 (8.1484)  loss_n_40: 1.7583 (1.9077)  loss_n_60: 1.7891 (1.9711)  loss_n_80: 2.0671 (2.1841)  loss_n_100: 2.0481 (2.0855)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [630/845]  eta: 0:01:12  loss: 7.6402 (8.1363)  loss_n_40: 1.7583 (1.9069)  loss_n_60: 1.7891 (1.9672)  loss_n_80: 2.0398 (2.1804)  loss_n_100: 2.0177 (2.0817)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [640/845]  eta: 0:01:08  loss: 7.5299 (8.1347)  loss_n_40: 1.8670 (1.9066)  loss_n_60: 1.8037 (1.9659)  loss_n_80: 2.0729 (2.1801)  loss_n_100: 2.0031 (2.0820)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [650/845]  eta: 0:01:05  loss: 7.8754 (8.1357)  loss_n_40: 1.8809 (1.9066)  loss_n_60: 1.8482 (1.9668)  loss_n_80: 2.1053 (2.1800)  loss_n_100: 2.1060 (2.0823)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [660/845]  eta: 0:01:02  loss: 7.7504 (8.1419)  loss_n_40: 1.8358 (1.9078)  loss_n_60: 1.9264 (1.9682)  loss_n_80: 2.0806 (2.1819)  loss_n_100: 2.0213 (2.0840)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [670/845]  eta: 0:00:58  loss: 7.7504 (8.1451)  loss_n_40: 1.8358 (1.9085)  loss_n_60: 1.9287 (1.9695)  loss_n_80: 2.1132 (2.1832)  loss_n_100: 2.0213 (2.0839)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [680/845]  eta: 0:00:55  loss: 7.8055 (8.1474)  loss_n_40: 1.8737 (1.9086)  loss_n_60: 1.8520 (1.9702)  loss_n_80: 2.1094 (2.1841)  loss_n_100: 2.0582 (2.0844)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [690/845]  eta: 0:00:51  loss: 9.0069 (8.1655)  loss_n_40: 2.1641 (1.9122)  loss_n_60: 2.0818 (1.9746)  loss_n_80: 2.4123 (2.1891)  loss_n_100: 2.3222 (2.0896)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:7]  [700/845]  eta: 0:00:48  loss: 9.3525 (8.1712)  loss_n_40: 2.1907 (1.9135)  loss_n_60: 2.2089 (1.9766)  loss_n_80: 2.5503 (2.1900)  loss_n_100: 2.4450 (2.0911)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [710/845]  eta: 0:00:45  loss: 9.2299 (8.1817)  loss_n_40: 2.1919 (1.9175)  loss_n_60: 2.2089 (1.9789)  loss_n_80: 2.4690 (2.1919)  loss_n_100: 2.3944 (2.0934)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [720/845]  eta: 0:00:41  loss: 9.5899 (8.1895)  loss_n_40: 2.2318 (1.9190)  loss_n_60: 2.3010 (1.9813)  loss_n_80: 2.5393 (2.1943)  loss_n_100: 2.4370 (2.0949)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [730/845]  eta: 0:00:38  loss: 7.7008 (8.1896)  loss_n_40: 1.8192 (1.9184)  loss_n_60: 1.8142 (1.9812)  loss_n_80: 2.1400 (2.1947)  loss_n_100: 2.0193 (2.0951)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [740/845]  eta: 0:00:35  loss: 7.5750 (8.1928)  loss_n_40: 1.7390 (1.9193)  loss_n_60: 1.8142 (1.9822)  loss_n_80: 2.0613 (2.1952)  loss_n_100: 1.9590 (2.0961)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [750/845]  eta: 0:00:31  loss: 7.6525 (8.1821)  loss_n_40: 1.7517 (1.9172)  loss_n_60: 1.8277 (1.9798)  loss_n_80: 2.0411 (2.1923)  loss_n_100: 1.9577 (2.0928)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [760/845]  eta: 0:00:28  loss: 7.7826 (8.1883)  loss_n_40: 1.8414 (1.9197)  loss_n_60: 1.8592 (1.9812)  loss_n_80: 2.0866 (2.1934)  loss_n_100: 2.0585 (2.0940)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [770/845]  eta: 0:00:25  loss: 7.8754 (8.1858)  loss_n_40: 1.9898 (1.9208)  loss_n_60: 1.8343 (1.9807)  loss_n_80: 2.0866 (2.1923)  loss_n_100: 2.0784 (2.0920)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [780/845]  eta: 0:00:21  loss: 7.6068 (8.1896)  loss_n_40: 1.9783 (1.9211)  loss_n_60: 1.8399 (1.9820)  loss_n_80: 2.0738 (2.1935)  loss_n_100: 1.9508 (2.0929)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [790/845]  eta: 0:00:18  loss: 7.9094 (8.1906)  loss_n_40: 1.8913 (1.9220)  loss_n_60: 1.8573 (1.9819)  loss_n_80: 2.1185 (2.1938)  loss_n_100: 2.1124 (2.0929)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [800/845]  eta: 0:00:15  loss: 7.9094 (8.1913)  loss_n_40: 1.9054 (1.9219)  loss_n_60: 1.8750 (1.9824)  loss_n_80: 2.1185 (2.1936)  loss_n_100: 2.1124 (2.0934)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [810/845]  eta: 0:00:11  loss: 7.8013 (8.1903)  loss_n_40: 1.8905 (1.9216)  loss_n_60: 1.8796 (1.9823)  loss_n_80: 2.0720 (2.1931)  loss_n_100: 2.1028 (2.0933)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [820/845]  eta: 0:00:08  loss: 7.6890 (8.1871)  loss_n_40: 1.7230 (1.9206)  loss_n_60: 1.8054 (1.9819)  loss_n_80: 2.0823 (2.1924)  loss_n_100: 2.0416 (2.0922)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [830/845]  eta: 0:00:05  loss: 7.7398 (8.1918)  loss_n_40: 1.7559 (1.9213)  loss_n_60: 1.8478 (1.9832)  loss_n_80: 2.1358 (2.1936)  loss_n_100: 2.0480 (2.0938)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [840/845]  eta: 0:00:01  loss: 7.6606 (8.1922)  loss_n_40: 1.7869 (1.9217)  loss_n_60: 1.9072 (1.9832)  loss_n_80: 2.0504 (2.1935)  loss_n_100: 2.0678 (2.0939)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7]  [844/845]  eta: 0:00:00  loss: 7.6606 (8.1978)  loss_n_40: 1.7869 (1.9225)  loss_n_60: 1.9072 (1.9845)  loss_n_80: 2.0504 (2.1952)  loss_n_100: 2.0678 (2.0956)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:7] Total time: 0:04:43 (0.3353 s / it)\n",
      "Averaged stats: loss: 7.6606 (8.1978)  loss_n_40: 1.7869 (1.9225)  loss_n_60: 1.9072 (1.9845)  loss_n_80: 2.0504 (2.1952)  loss_n_100: 2.0678 (2.0956)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_7_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 2.096%\n",
      "Min loss_n_100: 1.091\n",
      "Best Epoch: 6.000\n",
      "Train: [epoch:8]  [   0/1724]  eta: 2:00:45  lr: 0.000140  loss: 8.4393 (8.4393)  loss_n_40: 1.9149 (1.9149)  loss_n_60: 2.0581 (2.0581)  loss_n_80: 2.2583 (2.2583)  loss_n_100: 2.2081 (2.2081)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.2029  data: 0.4465  max mem: 46473\n",
      "Train: [epoch:8]  [  10/1724]  eta: 1:52:50  lr: 0.000140  loss: 8.0083 (8.1100)  loss_n_40: 1.9149 (1.8751)  loss_n_60: 1.9108 (1.9203)  loss_n_80: 2.1565 (2.1289)  loss_n_100: 2.0193 (2.0329)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.1015)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0513)  time: 3.9501  data: 0.0407  max mem: 46473\n",
      "Train: [epoch:8]  [  20/1724]  eta: 1:51:49  lr: 0.000140  loss: 7.7556 (7.9431)  loss_n_40: 1.8234 (1.8443)  loss_n_60: 1.9105 (1.9176)  loss_n_80: 2.0932 (2.1026)  loss_n_100: 2.0100 (1.9987)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0532)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0269)  time: 3.9242  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [  30/1724]  eta: 1:51:02  lr: 0.000140  loss: 7.6297 (7.9030)  loss_n_40: 1.8038 (1.8388)  loss_n_60: 1.9100 (1.9187)  loss_n_80: 2.0831 (2.1009)  loss_n_100: 1.9363 (1.9904)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0360)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0182)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [  40/1724]  eta: 1:50:19  lr: 0.000140  loss: 7.5516 (7.8103)  loss_n_40: 1.7689 (1.8095)  loss_n_60: 1.9002 (1.9132)  loss_n_80: 2.0344 (2.0791)  loss_n_100: 1.9039 (1.9674)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0272)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0138)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [  50/1724]  eta: 1:49:37  lr: 0.000140  loss: 7.3604 (7.7069)  loss_n_40: 1.7230 (1.7961)  loss_n_60: 1.8380 (1.8886)  loss_n_80: 1.9801 (2.0513)  loss_n_100: 1.8498 (1.9380)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0219)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0111)  time: 3.9237  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [  60/1724]  eta: 1:48:57  lr: 0.000140  loss: 7.0563 (7.6323)  loss_n_40: 1.7054 (1.7830)  loss_n_60: 1.7363 (1.8668)  loss_n_80: 1.8905 (2.0317)  loss_n_100: 1.7684 (1.9232)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0183)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0092)  time: 3.9243  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [  70/1724]  eta: 1:48:17  lr: 0.000140  loss: 6.8226 (7.5244)  loss_n_40: 1.6832 (1.7664)  loss_n_60: 1.6919 (1.8438)  loss_n_80: 1.8201 (1.9987)  loss_n_100: 1.7218 (1.8917)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0079)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [  80/1724]  eta: 1:47:36  lr: 0.000140  loss: 6.6872 (7.4122)  loss_n_40: 1.5874 (1.7468)  loss_n_60: 1.6366 (1.8193)  loss_n_80: 1.7582 (1.9665)  loss_n_100: 1.6483 (1.8588)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0070)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [  90/1724]  eta: 1:46:57  lr: 0.000140  loss: 6.7725 (7.3406)  loss_n_40: 1.6103 (1.7320)  loss_n_60: 1.6963 (1.8019)  loss_n_80: 1.7884 (1.9460)  loss_n_100: 1.7035 (1.8424)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0123)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0062)  time: 3.9235  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [ 100/1724]  eta: 1:46:17  lr: 0.000140  loss: 6.9448 (7.2912)  loss_n_40: 1.6441 (1.7254)  loss_n_60: 1.6985 (1.7864)  loss_n_80: 1.8290 (1.9316)  loss_n_100: 1.7803 (1.8311)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0111)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0056)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 110/1724]  eta: 1:45:37  lr: 0.000140  loss: 6.8385 (7.1903)  loss_n_40: 1.6210 (1.7123)  loss_n_60: 1.5892 (1.7579)  loss_n_80: 1.7724 (1.8995)  loss_n_100: 1.6339 (1.8003)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0101)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0102)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 120/1724]  eta: 1:44:57  lr: 0.000140  loss: 6.3950 (7.1453)  loss_n_40: 1.6003 (1.7100)  loss_n_60: 1.5205 (1.7466)  loss_n_80: 1.6604 (1.8850)  loss_n_100: 1.6038 (1.7851)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0092)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0093)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 130/1724]  eta: 1:44:18  lr: 0.000140  loss: 6.3487 (7.0881)  loss_n_40: 1.6819 (1.7075)  loss_n_60: 1.5381 (1.7340)  loss_n_80: 1.6149 (1.8657)  loss_n_100: 1.4885 (1.7636)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0085)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0086)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 140/1724]  eta: 1:43:38  lr: 0.000140  loss: 6.1877 (7.0184)  loss_n_40: 1.5804 (1.6970)  loss_n_60: 1.4788 (1.7168)  loss_n_80: 1.5912 (1.8454)  loss_n_100: 1.4434 (1.7433)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0079)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0080)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 150/1724]  eta: 1:42:59  lr: 0.000140  loss: 6.3017 (6.9881)  loss_n_40: 1.5560 (1.6891)  loss_n_60: 1.5329 (1.7088)  loss_n_80: 1.6436 (1.8323)  loss_n_100: 1.5310 (1.7300)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0064)  triple_40: 0.0000 (0.0075)  time: 3.9256  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [ 160/1724]  eta: 1:42:20  lr: 0.000140  loss: 6.3672 (6.9443)  loss_n_40: 1.5560 (1.6808)  loss_n_60: 1.5272 (1.6950)  loss_n_80: 1.6493 (1.8174)  loss_n_100: 1.5449 (1.7157)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0142)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 170/1724]  eta: 1:41:40  lr: 0.000140  loss: 6.2526 (6.9003)  loss_n_40: 1.5176 (1.6723)  loss_n_60: 1.4628 (1.6827)  loss_n_80: 1.6124 (1.8041)  loss_n_100: 1.5391 (1.7079)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0134)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 180/1724]  eta: 1:41:01  lr: 0.000140  loss: 6.0895 (6.8503)  loss_n_40: 1.4851 (1.6594)  loss_n_60: 1.4954 (1.6712)  loss_n_80: 1.5836 (1.7904)  loss_n_100: 1.5391 (1.6980)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0123)  triple_60: 0.0000 (0.0065)  triple_40: 0.0000 (0.0127)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 190/1724]  eta: 1:40:21  lr: 0.000140  loss: 5.8463 (6.7937)  loss_n_40: 1.4328 (1.6463)  loss_n_60: 1.4458 (1.6578)  loss_n_80: 1.4755 (1.7741)  loss_n_100: 1.4834 (1.6857)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0116)  triple_60: 0.0000 (0.0062)  triple_40: 0.0000 (0.0120)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 200/1724]  eta: 1:39:42  lr: 0.000140  loss: 5.6251 (6.7257)  loss_n_40: 1.3891 (1.6326)  loss_n_60: 1.3855 (1.6423)  loss_n_80: 1.4454 (1.7542)  loss_n_100: 1.4299 (1.6682)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0111)  triple_60: 0.0000 (0.0059)  triple_40: 0.0000 (0.0114)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 210/1724]  eta: 1:39:02  lr: 0.000140  loss: 5.3073 (6.6544)  loss_n_40: 1.3250 (1.6177)  loss_n_60: 1.3350 (1.6255)  loss_n_80: 1.3460 (1.7339)  loss_n_100: 1.3192 (1.6503)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0056)  triple_40: 0.0000 (0.0109)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 220/1724]  eta: 1:38:23  lr: 0.000140  loss: 5.0696 (6.5970)  loss_n_40: 1.2485 (1.5993)  loss_n_60: 1.2066 (1.6041)  loss_n_80: 1.2681 (1.7108)  loss_n_100: 1.2570 (1.6310)  triple_100: 0.0000 (0.0061)  triple_80: 0.0000 (0.0192)  triple_60: 0.0000 (0.0161)  triple_40: 0.0000 (0.0104)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 230/1724]  eta: 1:37:44  lr: 0.000140  loss: 4.6542 (6.5198)  loss_n_40: 1.2202 (1.5824)  loss_n_60: 1.1230 (1.5845)  loss_n_80: 1.1723 (1.6874)  loss_n_100: 1.2367 (1.6159)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0184)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0099)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 240/1724]  eta: 1:37:05  lr: 0.000140  loss: 4.5620 (6.4294)  loss_n_40: 1.1709 (1.5617)  loss_n_60: 1.0894 (1.5611)  loss_n_80: 1.0843 (1.6606)  loss_n_100: 1.1928 (1.5943)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0176)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0095)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 250/1724]  eta: 1:36:25  lr: 0.000140  loss: 4.2929 (6.3499)  loss_n_40: 1.1103 (1.5450)  loss_n_60: 1.0626 (1.5418)  loss_n_80: 1.0596 (1.6381)  loss_n_100: 1.0688 (1.5754)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0169)  triple_60: 0.0000 (0.0181)  triple_40: 0.0000 (0.0092)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 260/1724]  eta: 1:35:46  lr: 0.000140  loss: 4.2654 (6.2651)  loss_n_40: 1.0237 (1.5243)  loss_n_60: 1.0041 (1.5199)  loss_n_80: 1.0761 (1.6155)  loss_n_100: 1.1263 (1.5578)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0174)  triple_40: 0.0000 (0.0088)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 270/1724]  eta: 1:35:07  lr: 0.000140  loss: 4.0337 (6.1780)  loss_n_40: 0.9692 (1.5034)  loss_n_60: 0.9386 (1.4985)  loss_n_80: 0.9768 (1.5914)  loss_n_100: 1.0675 (1.5388)  triple_100: 0.0000 (0.0050)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0085)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 280/1724]  eta: 1:34:28  lr: 0.000140  loss: 3.6714 (6.0889)  loss_n_40: 0.8973 (1.4816)  loss_n_60: 0.9092 (1.4762)  loss_n_80: 0.9106 (1.5670)  loss_n_100: 1.0110 (1.5198)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0082)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 290/1724]  eta: 1:33:48  lr: 0.000140  loss: 3.5472 (5.9996)  loss_n_40: 0.8524 (1.4604)  loss_n_60: 0.8469 (1.4533)  loss_n_80: 0.8698 (1.5421)  loss_n_100: 0.9737 (1.5011)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0146)  triple_60: 0.0000 (0.0156)  triple_40: 0.0000 (0.0079)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 300/1724]  eta: 1:33:09  lr: 0.000140  loss: 3.3629 (5.9095)  loss_n_40: 0.8196 (1.4395)  loss_n_60: 0.7742 (1.4307)  loss_n_80: 0.8076 (1.5177)  loss_n_100: 0.9144 (1.4802)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0076)  time: 3.9249  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [ 310/1724]  eta: 1:32:30  lr: 0.000140  loss: 3.3935 (5.8326)  loss_n_40: 0.8196 (1.4212)  loss_n_60: 0.7989 (1.4122)  loss_n_80: 0.8149 (1.4963)  loss_n_100: 0.8911 (1.4629)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0146)  triple_40: 0.0000 (0.0074)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 320/1724]  eta: 1:31:51  lr: 0.000140  loss: 3.4206 (5.7702)  loss_n_40: 0.8744 (1.4060)  loss_n_60: 0.8417 (1.3953)  loss_n_80: 0.8282 (1.4764)  loss_n_100: 0.9117 (1.4465)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0120)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 330/1724]  eta: 1:31:11  lr: 0.000140  loss: 3.5267 (5.7070)  loss_n_40: 0.8569 (1.3877)  loss_n_60: 0.8524 (1.3793)  loss_n_80: 0.8733 (1.4595)  loss_n_100: 0.9619 (1.4338)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0146)  triple_40: 0.0000 (0.0128)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 340/1724]  eta: 1:30:32  lr: 0.000140  loss: 3.5187 (5.6402)  loss_n_40: 0.8107 (1.3707)  loss_n_60: 0.8465 (1.3631)  loss_n_80: 0.8838 (1.4413)  loss_n_100: 0.9630 (1.4196)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0124)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 350/1724]  eta: 1:29:53  lr: 0.000140  loss: 3.2982 (5.5753)  loss_n_40: 0.8002 (1.3551)  loss_n_60: 0.8171 (1.3472)  loss_n_80: 0.8019 (1.4234)  loss_n_100: 0.9264 (1.4054)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0121)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 360/1724]  eta: 1:29:13  lr: 0.000140  loss: 3.2672 (5.5108)  loss_n_40: 0.7666 (1.3401)  loss_n_60: 0.7817 (1.3322)  loss_n_80: 0.7886 (1.4059)  loss_n_100: 0.8413 (1.3897)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0134)  triple_40: 0.0000 (0.0118)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 370/1724]  eta: 1:28:34  lr: 0.000140  loss: 3.1415 (5.4451)  loss_n_40: 0.7443 (1.3240)  loss_n_60: 0.7756 (1.3162)  loss_n_80: 0.7645 (1.3883)  loss_n_100: 0.8088 (1.3749)  triple_100: 0.0000 (0.0036)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0130)  triple_40: 0.0000 (0.0114)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 380/1724]  eta: 1:27:55  lr: 0.000140  loss: 3.4297 (5.3961)  loss_n_40: 0.7327 (1.3093)  loss_n_60: 0.7756 (1.3028)  loss_n_80: 0.8359 (1.3747)  loss_n_100: 0.9198 (1.3648)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0127)  triple_40: 0.0000 (0.0148)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 390/1724]  eta: 1:27:16  lr: 0.000140  loss: 3.4810 (5.3484)  loss_n_40: 0.7327 (1.2966)  loss_n_60: 0.8056 (1.2911)  loss_n_80: 0.8978 (1.3620)  loss_n_100: 1.0116 (1.3552)  triple_100: 0.0000 (0.0034)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0124)  triple_40: 0.0000 (0.0145)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 400/1724]  eta: 1:26:36  lr: 0.000140  loss: 3.3277 (5.2990)  loss_n_40: 0.7363 (1.2846)  loss_n_60: 0.8068 (1.2799)  loss_n_80: 0.8376 (1.3486)  loss_n_100: 0.9180 (1.3434)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0121)  triple_40: 0.0000 (0.0141)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 410/1724]  eta: 1:25:57  lr: 0.000140  loss: 3.1377 (5.2433)  loss_n_40: 0.7355 (1.2712)  loss_n_60: 0.7633 (1.2668)  loss_n_80: 0.7600 (1.3338)  loss_n_100: 0.8139 (1.3301)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0127)  triple_60: 0.0000 (0.0118)  triple_40: 0.0000 (0.0137)  time: 3.9253  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [ 420/1724]  eta: 1:25:18  lr: 0.000140  loss: 3.1377 (5.2335)  loss_n_40: 0.7420 (1.2650)  loss_n_60: 0.7633 (1.2619)  loss_n_80: 0.7600 (1.3295)  loss_n_100: 0.8731 (1.3286)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0148)  triple_40: 0.0000 (0.0134)  time: 3.9251  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [ 430/1724]  eta: 1:24:39  lr: 0.000140  loss: 4.7164 (5.2248)  loss_n_40: 1.0152 (1.2610)  loss_n_60: 1.0802 (1.2586)  loss_n_80: 1.1652 (1.3276)  loss_n_100: 1.2446 (1.3303)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0144)  triple_40: 0.0000 (0.0131)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 440/1724]  eta: 1:23:59  lr: 0.000140  loss: 4.5296 (5.1961)  loss_n_40: 1.0102 (1.2538)  loss_n_60: 1.0163 (1.2519)  loss_n_80: 1.0917 (1.3195)  loss_n_100: 1.2286 (1.3247)  triple_100: 0.0000 (0.0047)  triple_80: 0.0000 (0.0146)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0128)  time: 3.9251  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [ 450/1724]  eta: 1:23:20  lr: 0.000140  loss: 3.6503 (5.1582)  loss_n_40: 0.8125 (1.2438)  loss_n_60: 0.9110 (1.2431)  loss_n_80: 0.8741 (1.3094)  loss_n_100: 0.9820 (1.3167)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0125)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 460/1724]  eta: 1:22:41  lr: 0.000140  loss: 3.2635 (5.1184)  loss_n_40: 0.7714 (1.2344)  loss_n_60: 0.7969 (1.2335)  loss_n_80: 0.7999 (1.2983)  loss_n_100: 0.9399 (1.3080)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0135)  triple_40: 0.0000 (0.0123)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 470/1724]  eta: 1:22:02  lr: 0.000140  loss: 3.0706 (5.0737)  loss_n_40: 0.7342 (1.2244)  loss_n_60: 0.7437 (1.2227)  loss_n_80: 0.7477 (1.2863)  loss_n_100: 0.8538 (1.2970)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0132)  triple_40: 0.0000 (0.0120)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 480/1724]  eta: 1:21:22  lr: 0.000140  loss: 2.8932 (5.0276)  loss_n_40: 0.6435 (1.2127)  loss_n_60: 0.6963 (1.2114)  loss_n_80: 0.7043 (1.2744)  loss_n_100: 0.7665 (1.2867)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0129)  triple_40: 0.0000 (0.0117)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 490/1724]  eta: 1:20:43  lr: 0.000140  loss: 2.8396 (4.9863)  loss_n_40: 0.6276 (1.2020)  loss_n_60: 0.6695 (1.2010)  loss_n_80: 0.7077 (1.2636)  loss_n_100: 0.7665 (1.2773)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0127)  triple_40: 0.0000 (0.0123)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 500/1724]  eta: 1:20:04  lr: 0.000140  loss: 2.6710 (4.9441)  loss_n_40: 0.6276 (1.1915)  loss_n_60: 0.6308 (1.1900)  loss_n_80: 0.6954 (1.2523)  loss_n_100: 0.7612 (1.2669)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0129)  triple_40: 0.0000 (0.0121)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 510/1724]  eta: 1:19:25  lr: 0.000140  loss: 2.6710 (4.9075)  loss_n_40: 0.6276 (1.1840)  loss_n_60: 0.6471 (1.1809)  loss_n_80: 0.6920 (1.2422)  loss_n_100: 0.7617 (1.2573)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0127)  triple_40: 0.0000 (0.0124)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 520/1724]  eta: 1:18:45  lr: 0.000140  loss: 2.8193 (4.8690)  loss_n_40: 0.6603 (1.1740)  loss_n_60: 0.6916 (1.1713)  loss_n_80: 0.7138 (1.2325)  loss_n_100: 0.7728 (1.2489)  triple_100: 0.0000 (0.0040)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0124)  triple_40: 0.0000 (0.0121)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 530/1724]  eta: 1:18:06  lr: 0.000140  loss: 2.8114 (4.8311)  loss_n_40: 0.6547 (1.1653)  loss_n_60: 0.6566 (1.1617)  loss_n_80: 0.7049 (1.2228)  loss_n_100: 0.7790 (1.2398)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0122)  triple_40: 0.0000 (0.0119)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 540/1724]  eta: 1:17:27  lr: 0.000140  loss: 2.7744 (4.7967)  loss_n_40: 0.6465 (1.1566)  loss_n_60: 0.6498 (1.1531)  loss_n_80: 0.7140 (1.2141)  loss_n_100: 0.7670 (1.2319)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0117)  time: 3.9259  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [ 550/1724]  eta: 1:16:48  lr: 0.000140  loss: 2.6719 (4.7586)  loss_n_40: 0.6286 (1.1475)  loss_n_60: 0.6427 (1.1436)  loss_n_80: 0.6705 (1.2043)  loss_n_100: 0.7413 (1.2231)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0117)  triple_40: 0.0000 (0.0115)  time: 3.9265  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [ 560/1724]  eta: 1:16:08  lr: 0.000140  loss: 2.6428 (4.7214)  loss_n_40: 0.6346 (1.1390)  loss_n_60: 0.6224 (1.1342)  loss_n_80: 0.6581 (1.1946)  loss_n_100: 0.7413 (1.2141)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0115)  triple_40: 0.0000 (0.0113)  time: 3.9266  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [ 570/1724]  eta: 1:15:29  lr: 0.000140  loss: 2.6294 (4.6842)  loss_n_40: 0.6052 (1.1301)  loss_n_60: 0.6083 (1.1249)  loss_n_80: 0.6581 (1.1848)  loss_n_100: 0.7418 (1.2052)  triple_100: 0.0000 (0.0036)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0113)  triple_40: 0.0000 (0.0111)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 580/1724]  eta: 1:14:50  lr: 0.000140  loss: 2.5473 (4.6477)  loss_n_40: 0.6004 (1.1212)  loss_n_60: 0.5912 (1.1157)  loss_n_80: 0.6174 (1.1754)  loss_n_100: 0.7131 (1.1967)  triple_100: 0.0000 (0.0036)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0109)  time: 3.9271  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 590/1724]  eta: 1:14:11  lr: 0.000140  loss: 2.5342 (4.6111)  loss_n_40: 0.6099 (1.1125)  loss_n_60: 0.5865 (1.1066)  loss_n_80: 0.6201 (1.1659)  loss_n_100: 0.7005 (1.1881)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0107)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 600/1724]  eta: 1:13:32  lr: 0.000140  loss: 2.4773 (4.5789)  loss_n_40: 0.6036 (1.1057)  loss_n_60: 0.5819 (1.0987)  loss_n_80: 0.6193 (1.1574)  loss_n_100: 0.7005 (1.1798)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0126)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0105)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 610/1724]  eta: 1:12:52  lr: 0.000140  loss: 2.4815 (4.5501)  loss_n_40: 0.6073 (1.0990)  loss_n_60: 0.5960 (1.0909)  loss_n_80: 0.6280 (1.1490)  loss_n_100: 0.6589 (1.1716)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0112)  triple_40: 0.0000 (0.0103)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 620/1724]  eta: 1:12:13  lr: 0.000140  loss: 2.6544 (4.5208)  loss_n_40: 0.6338 (1.0924)  loss_n_60: 0.6348 (1.0838)  loss_n_80: 0.6418 (1.1416)  loss_n_100: 0.6589 (1.1641)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0102)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 630/1724]  eta: 1:11:34  lr: 0.000140  loss: 2.7570 (4.5070)  loss_n_40: 0.6669 (1.0859)  loss_n_60: 0.6476 (1.0778)  loss_n_80: 0.7089 (1.1362)  loss_n_100: 0.7597 (1.1594)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0161)  triple_60: 0.0000 (0.0145)  triple_40: 0.0000 (0.0127)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 640/1724]  eta: 1:10:55  lr: 0.000140  loss: 6.0150 (4.5757)  loss_n_40: 0.9852 (1.0919)  loss_n_60: 0.9844 (1.0876)  loss_n_80: 1.1838 (1.1494)  loss_n_100: 1.3456 (1.1741)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0316)  triple_60: 0.0000 (0.0242)  triple_40: 0.0000 (0.0125)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 650/1724]  eta: 1:10:15  lr: 0.000140  loss: 6.8020 (4.6016)  loss_n_40: 1.4462 (1.0973)  loss_n_60: 1.5539 (1.0944)  loss_n_80: 1.8279 (1.1567)  loss_n_100: 1.7974 (1.1816)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0312)  triple_60: 0.0000 (0.0238)  triple_40: 0.0000 (0.0123)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 660/1724]  eta: 1:09:36  lr: 0.000140  loss: 5.8417 (4.6146)  loss_n_40: 1.3951 (1.1013)  loss_n_60: 1.3740 (1.0973)  loss_n_80: 1.4402 (1.1600)  loss_n_100: 1.4970 (1.1855)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0307)  triple_60: 0.0000 (0.0234)  triple_40: 0.0000 (0.0122)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 670/1724]  eta: 1:08:57  lr: 0.000140  loss: 5.1438 (4.6199)  loss_n_40: 1.3060 (1.1048)  loss_n_60: 1.2026 (1.0979)  loss_n_80: 1.2995 (1.1610)  loss_n_100: 1.3314 (1.1867)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0302)  triple_60: 0.0000 (0.0231)  triple_40: 0.0000 (0.0120)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 680/1724]  eta: 1:08:18  lr: 0.000140  loss: 4.6872 (4.6188)  loss_n_40: 1.2374 (1.1055)  loss_n_60: 1.1110 (1.0976)  loss_n_80: 1.1693 (1.1606)  loss_n_100: 1.2092 (1.1867)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0298)  triple_60: 0.0000 (0.0227)  triple_40: 0.0000 (0.0118)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 690/1724]  eta: 1:07:38  lr: 0.000140  loss: 4.2738 (4.6130)  loss_n_40: 1.0305 (1.1043)  loss_n_60: 0.9850 (1.0957)  loss_n_80: 1.0257 (1.1583)  loss_n_100: 1.1456 (1.1859)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0294)  triple_60: 0.0000 (0.0224)  triple_40: 0.0000 (0.0129)  time: 3.9243  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 700/1724]  eta: 1:06:59  lr: 0.000140  loss: 3.9413 (4.6053)  loss_n_40: 0.9661 (1.1030)  loss_n_60: 0.9167 (1.0938)  loss_n_80: 0.9863 (1.1562)  loss_n_100: 1.0941 (1.1846)  triple_100: 0.0000 (0.0040)  triple_80: 0.0000 (0.0289)  triple_60: 0.0000 (0.0221)  triple_40: 0.0000 (0.0127)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 710/1724]  eta: 1:06:20  lr: 0.000140  loss: 3.6098 (4.5880)  loss_n_40: 0.8901 (1.0993)  loss_n_60: 0.8430 (1.0898)  loss_n_80: 0.8991 (1.1514)  loss_n_100: 0.9932 (1.1808)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0285)  triple_60: 0.0000 (0.0218)  triple_40: 0.0000 (0.0125)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 720/1724]  eta: 1:05:41  lr: 0.000140  loss: 3.4087 (4.5724)  loss_n_40: 0.7984 (1.0959)  loss_n_60: 0.8001 (1.0863)  loss_n_80: 0.8322 (1.1472)  loss_n_100: 0.9078 (1.1771)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0281)  triple_60: 0.0000 (0.0215)  triple_40: 0.0000 (0.0123)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 730/1724]  eta: 1:05:01  lr: 0.000140  loss: 3.3488 (4.5555)  loss_n_40: 0.7984 (1.0925)  loss_n_60: 0.8131 (1.0825)  loss_n_80: 0.8322 (1.1429)  loss_n_100: 0.8943 (1.1728)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.0212)  triple_40: 0.0000 (0.0122)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 740/1724]  eta: 1:04:22  lr: 0.000140  loss: 3.0135 (4.5364)  loss_n_40: 0.7441 (1.0883)  loss_n_60: 0.7534 (1.0780)  loss_n_80: 0.7586 (1.1378)  loss_n_100: 0.8196 (1.1682)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0274)  triple_60: 0.0000 (0.0209)  triple_40: 0.0000 (0.0120)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 750/1724]  eta: 1:03:43  lr: 0.000140  loss: 2.9934 (4.5159)  loss_n_40: 0.6968 (1.0838)  loss_n_60: 0.7186 (1.0730)  loss_n_80: 0.7225 (1.1325)  loss_n_100: 0.7920 (1.1634)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0270)  triple_60: 0.0000 (0.0206)  triple_40: 0.0000 (0.0118)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 760/1724]  eta: 1:03:03  lr: 0.000140  loss: 2.7888 (4.4937)  loss_n_40: 0.6450 (1.0784)  loss_n_60: 0.6748 (1.0676)  loss_n_80: 0.7091 (1.1269)  loss_n_100: 0.8033 (1.1584)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0267)  triple_60: 0.0000 (0.0203)  triple_40: 0.0000 (0.0117)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 770/1724]  eta: 1:02:24  lr: 0.000140  loss: 3.0984 (4.4956)  loss_n_40: 0.6751 (1.0768)  loss_n_60: 0.6981 (1.0667)  loss_n_80: 0.7221 (1.1271)  loss_n_100: 0.8410 (1.1605)  triple_100: 0.0000 (0.0065)  triple_80: 0.0000 (0.0263)  triple_60: 0.0000 (0.0201)  triple_40: 0.0000 (0.0115)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 780/1724]  eta: 1:01:45  lr: 0.000140  loss: 4.7603 (4.5031)  loss_n_40: 1.1083 (1.0781)  loss_n_60: 1.0791 (1.0678)  loss_n_80: 1.2297 (1.1290)  loss_n_100: 1.3349 (1.1630)  triple_100: 0.0000 (0.0064)  triple_80: 0.0000 (0.0260)  triple_60: 0.0000 (0.0209)  triple_40: 0.0000 (0.0120)  time: 3.9238  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [ 790/1724]  eta: 1:01:06  lr: 0.000140  loss: 4.1982 (4.4969)  loss_n_40: 1.0241 (1.0766)  loss_n_60: 0.9853 (1.0661)  loss_n_80: 1.0626 (1.1272)  loss_n_100: 1.1478 (1.1625)  triple_100: 0.0000 (0.0063)  triple_80: 0.0000 (0.0257)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0118)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 800/1724]  eta: 1:00:26  lr: 0.000140  loss: 3.8192 (4.4861)  loss_n_40: 0.8677 (1.0741)  loss_n_60: 0.9064 (1.0633)  loss_n_80: 0.9647 (1.1245)  loss_n_100: 1.0587 (1.1605)  triple_100: 0.0000 (0.0062)  triple_80: 0.0000 (0.0254)  triple_60: 0.0000 (0.0204)  triple_40: 0.0000 (0.0117)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 810/1724]  eta: 0:59:47  lr: 0.000140  loss: 3.3089 (4.4712)  loss_n_40: 0.8270 (1.0714)  loss_n_60: 0.7668 (1.0596)  loss_n_80: 0.8239 (1.1203)  loss_n_100: 0.9449 (1.1571)  triple_100: 0.0000 (0.0062)  triple_80: 0.0000 (0.0250)  triple_60: 0.0000 (0.0202)  triple_40: 0.0000 (0.0115)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 820/1724]  eta: 0:59:08  lr: 0.000140  loss: 3.1424 (4.4538)  loss_n_40: 0.8254 (1.0677)  loss_n_60: 0.7241 (1.0553)  loss_n_80: 0.7407 (1.1154)  loss_n_100: 0.8277 (1.1532)  triple_100: 0.0000 (0.0061)  triple_80: 0.0000 (0.0247)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0114)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 830/1724]  eta: 0:58:29  lr: 0.000140  loss: 2.7840 (4.4315)  loss_n_40: 0.6291 (1.0621)  loss_n_60: 0.6343 (1.0497)  loss_n_80: 0.6874 (1.1097)  loss_n_100: 0.7921 (1.1486)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0244)  triple_60: 0.0000 (0.0197)  triple_40: 0.0000 (0.0113)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 840/1724]  eta: 0:57:49  lr: 0.000140  loss: 2.6452 (4.4138)  loss_n_40: 0.6107 (1.0584)  loss_n_60: 0.5907 (1.0453)  loss_n_80: 0.6416 (1.1052)  loss_n_100: 0.7687 (1.1442)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0241)  triple_60: 0.0000 (0.0194)  triple_40: 0.0000 (0.0111)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 850/1724]  eta: 0:57:10  lr: 0.000140  loss: 2.6955 (4.3941)  loss_n_40: 0.6107 (1.0534)  loss_n_60: 0.6153 (1.0405)  loss_n_80: 0.6960 (1.1003)  loss_n_100: 0.7604 (1.1400)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0192)  triple_40: 0.0000 (0.0110)  time: 3.9250  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [ 860/1724]  eta: 0:56:31  lr: 0.000140  loss: 2.5258 (4.3710)  loss_n_40: 0.5549 (1.0478)  loss_n_60: 0.5891 (1.0349)  loss_n_80: 0.6251 (1.0942)  loss_n_100: 0.7243 (1.1345)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0190)  triple_40: 0.0000 (0.0109)  time: 3.9255  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [ 870/1724]  eta: 0:55:52  lr: 0.000140  loss: 2.3735 (4.3510)  loss_n_40: 0.5524 (1.0431)  loss_n_60: 0.5444 (1.0300)  loss_n_80: 0.5806 (1.0890)  loss_n_100: 0.6947 (1.1300)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0236)  triple_60: 0.0000 (0.0188)  triple_40: 0.0000 (0.0108)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 880/1724]  eta: 0:55:12  lr: 0.000140  loss: 2.4072 (4.3306)  loss_n_40: 0.5610 (1.0379)  loss_n_60: 0.5431 (1.0250)  loss_n_80: 0.6018 (1.0838)  loss_n_100: 0.7189 (1.1256)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0186)  triple_40: 0.0000 (0.0108)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 890/1724]  eta: 0:54:33  lr: 0.000140  loss: 2.8021 (4.3181)  loss_n_40: 0.6197 (1.0342)  loss_n_60: 0.6675 (1.0218)  loss_n_80: 0.6826 (1.0802)  loss_n_100: 0.7947 (1.1228)  triple_100: 0.0000 (0.0066)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0183)  triple_40: 0.0000 (0.0107)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 900/1724]  eta: 0:53:54  lr: 0.000140  loss: 3.1296 (4.3047)  loss_n_40: 0.6640 (1.0305)  loss_n_60: 0.7412 (1.0186)  loss_n_80: 0.7668 (1.0770)  loss_n_100: 0.8617 (1.1200)  triple_100: 0.0000 (0.0065)  triple_80: 0.0000 (0.0232)  triple_60: 0.0000 (0.0181)  triple_40: 0.0000 (0.0106)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 910/1724]  eta: 0:53:15  lr: 0.000140  loss: 2.8907 (4.2879)  loss_n_40: 0.6196 (1.0261)  loss_n_60: 0.7087 (1.0149)  loss_n_80: 0.7414 (1.0729)  loss_n_100: 0.7912 (1.1162)  triple_100: 0.0000 (0.0064)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0179)  triple_40: 0.0000 (0.0105)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 920/1724]  eta: 0:52:35  lr: 0.000140  loss: 2.7021 (4.2693)  loss_n_40: 0.5936 (1.0216)  loss_n_60: 0.6557 (1.0105)  loss_n_80: 0.6638 (1.0680)  loss_n_100: 0.7122 (1.1115)  triple_100: 0.0000 (0.0063)  triple_80: 0.0000 (0.0232)  triple_60: 0.0000 (0.0177)  triple_40: 0.0000 (0.0103)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 930/1724]  eta: 0:51:56  lr: 0.000140  loss: 2.5041 (4.2536)  loss_n_40: 0.5707 (1.0172)  loss_n_60: 0.5882 (1.0067)  loss_n_80: 0.6054 (1.0636)  loss_n_100: 0.6990 (1.1076)  triple_100: 0.0000 (0.0063)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0102)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 940/1724]  eta: 0:51:17  lr: 0.000140  loss: 2.4883 (4.2352)  loss_n_40: 0.5503 (1.0122)  loss_n_60: 0.5939 (1.0024)  loss_n_80: 0.6232 (1.0591)  loss_n_100: 0.7472 (1.1034)  triple_100: 0.0000 (0.0062)  triple_80: 0.0000 (0.0229)  triple_60: 0.0000 (0.0187)  triple_40: 0.0000 (0.0101)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 950/1724]  eta: 0:50:38  lr: 0.000140  loss: 2.4817 (4.2167)  loss_n_40: 0.5254 (1.0078)  loss_n_60: 0.5697 (0.9980)  loss_n_80: 0.6232 (1.0545)  loss_n_100: 0.6966 (1.0989)  triple_100: 0.0000 (0.0061)  triple_80: 0.0000 (0.0227)  triple_60: 0.0000 (0.0185)  triple_40: 0.0000 (0.0100)  time: 3.9297  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 960/1724]  eta: 0:49:58  lr: 0.000140  loss: 2.3725 (4.1992)  loss_n_40: 0.5580 (1.0036)  loss_n_60: 0.6027 (0.9940)  loss_n_80: 0.5954 (1.0500)  loss_n_100: 0.6773 (1.0948)  triple_100: 0.0000 (0.0061)  triple_80: 0.0000 (0.0224)  triple_60: 0.0000 (0.0184)  triple_40: 0.0000 (0.0099)  time: 3.9302  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 970/1724]  eta: 0:49:19  lr: 0.000140  loss: 2.3558 (4.1801)  loss_n_40: 0.5223 (0.9988)  loss_n_60: 0.5717 (0.9895)  loss_n_80: 0.5911 (1.0451)  loss_n_100: 0.6773 (1.0903)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0222)  triple_60: 0.0000 (0.0182)  triple_40: 0.0000 (0.0100)  time: 3.9303  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 980/1724]  eta: 0:48:40  lr: 0.000140  loss: 2.3029 (4.1634)  loss_n_40: 0.4915 (0.9945)  loss_n_60: 0.5387 (0.9853)  loss_n_80: 0.5776 (1.0406)  loss_n_100: 0.6681 (1.0861)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0228)  triple_60: 0.0000 (0.0180)  triple_40: 0.0000 (0.0099)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [ 990/1724]  eta: 0:48:01  lr: 0.000140  loss: 2.4624 (4.1474)  loss_n_40: 0.5267 (0.9908)  loss_n_60: 0.5867 (0.9815)  loss_n_80: 0.6119 (1.0367)  loss_n_100: 0.6821 (1.0823)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0226)  triple_60: 0.0000 (0.0178)  triple_40: 0.0000 (0.0098)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1000/1724]  eta: 0:47:22  lr: 0.000140  loss: 2.4624 (4.1306)  loss_n_40: 0.5573 (0.9871)  loss_n_60: 0.5941 (0.9776)  loss_n_80: 0.6219 (1.0323)  loss_n_100: 0.6742 (1.0781)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0224)  triple_60: 0.0000 (0.0176)  triple_40: 0.0000 (0.0097)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1010/1724]  eta: 0:46:42  lr: 0.000140  loss: 2.2966 (4.1119)  loss_n_40: 0.5387 (0.9826)  loss_n_60: 0.5422 (0.9730)  loss_n_80: 0.5551 (1.0274)  loss_n_100: 0.6273 (1.0735)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0222)  triple_60: 0.0000 (0.0178)  triple_40: 0.0000 (0.0096)  time: 3.9269  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [1020/1724]  eta: 0:46:03  lr: 0.000140  loss: 2.1853 (4.0938)  loss_n_40: 0.5052 (0.9788)  loss_n_60: 0.5078 (0.9689)  loss_n_80: 0.5296 (1.0227)  loss_n_100: 0.5764 (1.0686)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0219)  triple_60: 0.0000 (0.0176)  triple_40: 0.0000 (0.0095)  time: 3.9278  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [1030/1724]  eta: 0:45:24  lr: 0.000140  loss: 2.0032 (4.0739)  loss_n_40: 0.4640 (0.9741)  loss_n_60: 0.4820 (0.9642)  loss_n_80: 0.4994 (1.0176)  loss_n_100: 0.5666 (1.0638)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0217)  triple_60: 0.0000 (0.0174)  triple_40: 0.0000 (0.0094)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1040/1724]  eta: 0:44:45  lr: 0.000140  loss: 1.9236 (4.0541)  loss_n_40: 0.4522 (0.9693)  loss_n_60: 0.4500 (0.9594)  loss_n_80: 0.4909 (1.0126)  loss_n_100: 0.5518 (1.0589)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0215)  triple_60: 0.0000 (0.0173)  triple_40: 0.0000 (0.0094)  time: 3.9277  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1050/1724]  eta: 0:44:05  lr: 0.000140  loss: 1.9236 (4.0345)  loss_n_40: 0.4605 (0.9647)  loss_n_60: 0.4587 (0.9547)  loss_n_80: 0.4803 (1.0077)  loss_n_100: 0.5480 (1.0541)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0213)  triple_60: 0.0000 (0.0171)  triple_40: 0.0000 (0.0093)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1060/1724]  eta: 0:43:26  lr: 0.000140  loss: 2.2145 (4.0355)  loss_n_40: 0.5096 (0.9629)  loss_n_60: 0.5153 (0.9540)  loss_n_80: 0.5493 (1.0073)  loss_n_100: 0.6017 (1.0541)  triple_100: 0.0000 (0.0069)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0178)  triple_40: 0.0000 (0.0092)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1070/1724]  eta: 0:42:47  lr: 0.000140  loss: 3.8541 (4.0345)  loss_n_40: 0.8589 (0.9628)  loss_n_60: 0.9206 (0.9540)  loss_n_80: 0.9388 (1.0071)  loss_n_100: 0.9845 (1.0540)  triple_100: 0.0000 (0.0069)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0176)  triple_40: 0.0000 (0.0091)  time: 3.9273  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [1080/1724]  eta: 0:42:08  lr: 0.000140  loss: 3.4307 (4.0276)  loss_n_40: 0.8741 (0.9615)  loss_n_60: 0.8512 (0.9522)  loss_n_80: 0.8501 (1.0052)  loss_n_100: 0.9601 (1.0526)  triple_100: 0.0000 (0.0068)  triple_80: 0.0000 (0.0228)  triple_60: 0.0000 (0.0174)  triple_40: 0.0000 (0.0090)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1090/1724]  eta: 0:41:28  lr: 0.000140  loss: 3.0528 (4.0174)  loss_n_40: 0.7347 (0.9598)  loss_n_60: 0.6931 (0.9499)  loss_n_80: 0.7023 (1.0021)  loss_n_100: 0.7878 (1.0499)  triple_100: 0.0000 (0.0068)  triple_80: 0.0000 (0.0226)  triple_60: 0.0000 (0.0173)  triple_40: 0.0000 (0.0089)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1100/1724]  eta: 0:40:49  lr: 0.000140  loss: 2.6077 (4.0032)  loss_n_40: 0.5990 (0.9563)  loss_n_60: 0.6288 (0.9465)  loss_n_80: 0.6181 (0.9985)  loss_n_100: 0.7163 (1.0468)  triple_100: 0.0000 (0.0067)  triple_80: 0.0000 (0.0224)  triple_60: 0.0000 (0.0171)  triple_40: 0.0000 (0.0088)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1110/1724]  eta: 0:40:10  lr: 0.000140  loss: 2.3646 (3.9889)  loss_n_40: 0.5679 (0.9529)  loss_n_60: 0.5663 (0.9431)  loss_n_80: 0.5922 (0.9949)  loss_n_100: 0.6610 (1.0434)  triple_100: 0.0000 (0.0066)  triple_80: 0.0000 (0.0222)  triple_60: 0.0000 (0.0170)  triple_40: 0.0000 (0.0088)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1120/1724]  eta: 0:39:31  lr: 0.000140  loss: 2.3584 (3.9731)  loss_n_40: 0.5429 (0.9491)  loss_n_60: 0.5481 (0.9394)  loss_n_80: 0.5781 (0.9909)  loss_n_100: 0.6402 (1.0396)  triple_100: 0.0000 (0.0066)  triple_80: 0.0000 (0.0220)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0087)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1130/1724]  eta: 0:38:51  lr: 0.000140  loss: 2.3373 (3.9595)  loss_n_40: 0.5389 (0.9463)  loss_n_60: 0.5481 (0.9362)  loss_n_80: 0.5599 (0.9873)  loss_n_100: 0.6233 (1.0360)  triple_100: 0.0000 (0.0065)  triple_80: 0.0000 (0.0219)  triple_60: 0.0000 (0.0167)  triple_40: 0.0000 (0.0086)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1140/1724]  eta: 0:38:12  lr: 0.000140  loss: 2.2351 (3.9435)  loss_n_40: 0.5163 (0.9426)  loss_n_60: 0.5326 (0.9325)  loss_n_80: 0.5327 (0.9831)  loss_n_100: 0.6013 (1.0321)  triple_100: 0.0000 (0.0065)  triple_80: 0.0000 (0.0217)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0085)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1150/1724]  eta: 0:37:33  lr: 0.000140  loss: 2.1997 (3.9300)  loss_n_40: 0.4983 (0.9396)  loss_n_60: 0.5075 (0.9293)  loss_n_80: 0.5239 (0.9795)  loss_n_100: 0.5965 (1.0286)  triple_100: 0.0000 (0.0067)  triple_80: 0.0000 (0.0215)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0085)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1160/1724]  eta: 0:36:54  lr: 0.000140  loss: 2.5682 (3.9348)  loss_n_40: 0.5877 (0.9373)  loss_n_60: 0.5622 (0.9271)  loss_n_80: 0.6076 (0.9773)  loss_n_100: 0.6483 (1.0266)  triple_100: 0.0000 (0.0115)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0182)  triple_40: 0.0000 (0.0133)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1170/1724]  eta: 0:36:14  lr: 0.000140  loss: 5.7471 (3.9600)  loss_n_40: 0.9170 (0.9420)  loss_n_60: 0.9762 (0.9309)  loss_n_80: 1.0190 (0.9823)  loss_n_100: 1.0424 (1.0318)  triple_100: 0.0000 (0.0151)  triple_80: 0.0000 (0.0266)  triple_60: 0.0000 (0.0181)  triple_40: 0.0000 (0.0132)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1180/1724]  eta: 0:35:35  lr: 0.000140  loss: 5.8681 (3.9748)  loss_n_40: 1.3826 (0.9444)  loss_n_60: 1.3580 (0.9346)  loss_n_80: 1.4329 (0.9868)  loss_n_100: 1.5522 (1.0368)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0264)  triple_60: 0.0000 (0.0179)  triple_40: 0.0000 (0.0131)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1190/1724]  eta: 0:34:56  lr: 0.000140  loss: 5.1103 (3.9830)  loss_n_40: 1.1035 (0.9457)  loss_n_60: 1.2210 (0.9367)  loss_n_80: 1.3302 (0.9891)  loss_n_100: 1.4579 (1.0398)  triple_100: 0.0000 (0.0148)  triple_80: 0.0000 (0.0261)  triple_60: 0.0000 (0.0178)  triple_40: 0.0000 (0.0130)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1200/1724]  eta: 0:34:17  lr: 0.000140  loss: 4.6415 (3.9869)  loss_n_40: 1.0227 (0.9461)  loss_n_60: 1.0985 (0.9375)  loss_n_80: 1.1571 (0.9901)  loss_n_100: 1.3169 (1.0420)  triple_100: 0.0000 (0.0147)  triple_80: 0.0000 (0.0259)  triple_60: 0.0000 (0.0176)  triple_40: 0.0000 (0.0129)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1210/1724]  eta: 0:33:37  lr: 0.000140  loss: 3.9998 (3.9892)  loss_n_40: 0.8967 (0.9458)  loss_n_60: 0.9199 (0.9377)  loss_n_80: 1.0200 (0.9906)  loss_n_100: 1.2231 (1.0437)  triple_100: 0.0000 (0.0153)  triple_80: 0.0000 (0.0257)  triple_60: 0.0000 (0.0175)  triple_40: 0.0000 (0.0128)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1220/1724]  eta: 0:32:58  lr: 0.000140  loss: 3.9187 (3.9892)  loss_n_40: 0.8356 (0.9446)  loss_n_60: 0.9007 (0.9377)  loss_n_80: 0.9587 (0.9908)  loss_n_100: 1.2005 (1.0453)  triple_100: 0.0000 (0.0152)  triple_80: 0.0000 (0.0255)  triple_60: 0.0000 (0.0174)  triple_40: 0.0000 (0.0127)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1230/1724]  eta: 0:32:19  lr: 0.000140  loss: 3.5942 (3.9839)  loss_n_40: 0.7803 (0.9431)  loss_n_60: 0.8324 (0.9366)  loss_n_80: 0.8748 (0.9894)  loss_n_100: 1.1009 (1.0446)  triple_100: 0.0000 (0.0151)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0172)  triple_40: 0.0000 (0.0127)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1240/1724]  eta: 0:31:40  lr: 0.000140  loss: 3.2360 (3.9787)  loss_n_40: 0.7456 (0.9421)  loss_n_60: 0.7853 (0.9356)  loss_n_80: 0.7597 (0.9879)  loss_n_100: 0.8642 (1.0435)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0251)  triple_60: 0.0000 (0.0171)  triple_40: 0.0000 (0.0126)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1250/1724]  eta: 0:31:00  lr: 0.000140  loss: 3.0668 (3.9720)  loss_n_40: 0.6475 (0.9404)  loss_n_60: 0.7539 (0.9342)  loss_n_80: 0.7358 (0.9860)  loss_n_100: 0.8787 (1.0423)  triple_100: 0.0000 (0.0148)  triple_80: 0.0000 (0.0249)  triple_60: 0.0000 (0.0169)  triple_40: 0.0000 (0.0125)  time: 3.9264  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [1260/1724]  eta: 0:30:21  lr: 0.000140  loss: 2.9421 (3.9618)  loss_n_40: 0.6137 (0.9378)  loss_n_60: 0.7221 (0.9319)  loss_n_80: 0.7227 (0.9833)  loss_n_100: 0.8337 (1.0402)  triple_100: 0.0000 (0.0147)  triple_80: 0.0000 (0.0247)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0124)  time: 3.9264  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [1270/1724]  eta: 0:29:42  lr: 0.000140  loss: 2.5801 (3.9510)  loss_n_40: 0.5842 (0.9351)  loss_n_60: 0.6320 (0.9295)  loss_n_80: 0.6170 (0.9805)  loss_n_100: 0.7492 (1.0378)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0245)  triple_60: 0.0000 (0.0167)  triple_40: 0.0000 (0.0123)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1280/1724]  eta: 0:29:03  lr: 0.000140  loss: 2.5165 (3.9399)  loss_n_40: 0.5719 (0.9327)  loss_n_60: 0.5923 (0.9269)  loss_n_80: 0.6079 (0.9776)  loss_n_100: 0.7237 (1.0352)  triple_100: 0.0000 (0.0145)  triple_80: 0.0000 (0.0243)  triple_60: 0.0000 (0.0166)  triple_40: 0.0000 (0.0122)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1290/1724]  eta: 0:28:23  lr: 0.000140  loss: 2.4556 (3.9290)  loss_n_40: 0.5333 (0.9299)  loss_n_60: 0.5923 (0.9244)  loss_n_80: 0.5816 (0.9748)  loss_n_100: 0.6904 (1.0328)  triple_100: 0.0000 (0.0144)  triple_80: 0.0000 (0.0241)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0121)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1300/1724]  eta: 0:27:44  lr: 0.000140  loss: 2.3529 (3.9171)  loss_n_40: 0.5095 (0.9267)  loss_n_60: 0.5800 (0.9215)  loss_n_80: 0.5759 (0.9718)  loss_n_100: 0.6821 (1.0302)  triple_100: 0.0000 (0.0143)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0125)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1310/1724]  eta: 0:27:05  lr: 0.000140  loss: 2.2603 (3.9046)  loss_n_40: 0.5068 (0.9238)  loss_n_60: 0.5344 (0.9187)  loss_n_80: 0.5420 (0.9685)  loss_n_100: 0.6527 (1.0272)  triple_100: 0.0000 (0.0142)  triple_80: 0.0000 (0.0238)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0124)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1320/1724]  eta: 0:26:25  lr: 0.000140  loss: 2.2603 (3.8928)  loss_n_40: 0.4827 (0.9206)  loss_n_60: 0.5567 (0.9158)  loss_n_80: 0.5425 (0.9654)  loss_n_100: 0.6328 (1.0243)  triple_100: 0.0000 (0.0140)  triple_80: 0.0000 (0.0236)  triple_60: 0.0000 (0.0160)  triple_40: 0.0000 (0.0131)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1330/1724]  eta: 0:25:46  lr: 0.000140  loss: 2.2250 (3.8797)  loss_n_40: 0.4698 (0.9172)  loss_n_60: 0.5146 (0.9127)  loss_n_80: 0.5628 (0.9622)  loss_n_100: 0.6328 (1.0213)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0159)  triple_40: 0.0000 (0.0130)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1340/1724]  eta: 0:25:07  lr: 0.000140  loss: 2.2946 (3.9003)  loss_n_40: 0.5206 (0.9188)  loss_n_60: 0.5419 (0.9146)  loss_n_80: 0.5959 (0.9648)  loss_n_100: 0.6839 (1.0244)  triple_100: 0.0000 (0.0182)  triple_80: 0.0000 (0.0281)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0149)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1350/1724]  eta: 0:24:28  lr: 0.000140  loss: 7.3714 (3.9289)  loss_n_40: 1.2933 (0.9225)  loss_n_60: 1.6413 (0.9210)  loss_n_80: 2.0066 (0.9742)  loss_n_100: 2.0249 (1.0326)  triple_100: 0.0000 (0.0195)  triple_80: 0.0000 (0.0279)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0148)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1360/1724]  eta: 0:23:48  lr: 0.000140  loss: 6.8746 (3.9457)  loss_n_40: 1.3743 (0.9249)  loss_n_60: 1.6413 (0.9248)  loss_n_80: 2.0566 (0.9805)  loss_n_100: 1.9022 (1.0376)  triple_100: 0.0000 (0.0193)  triple_80: 0.0000 (0.0277)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0147)  time: 3.9271  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [1370/1724]  eta: 0:23:09  lr: 0.000140  loss: 5.1656 (3.9527)  loss_n_40: 0.9664 (0.9250)  loss_n_60: 1.2214 (0.9265)  loss_n_80: 1.5168 (0.9836)  loss_n_100: 1.4831 (1.0402)  triple_100: 0.0000 (0.0192)  triple_80: 0.0000 (0.0275)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0146)  time: 3.9279  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [1380/1724]  eta: 0:22:30  lr: 0.000140  loss: 4.5930 (3.9616)  loss_n_40: 0.9348 (0.9256)  loss_n_60: 1.0638 (0.9272)  loss_n_80: 1.2703 (0.9852)  loss_n_100: 1.2871 (1.0413)  triple_100: 0.0000 (0.0204)  triple_80: 0.0000 (0.0296)  triple_60: 0.0000 (0.0178)  triple_40: 0.0000 (0.0145)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1390/1724]  eta: 0:21:51  lr: 0.000140  loss: 4.6889 (3.9681)  loss_n_40: 1.1565 (0.9276)  loss_n_60: 1.0671 (0.9286)  loss_n_80: 1.2328 (0.9871)  loss_n_100: 1.2205 (1.0431)  triple_100: 0.0000 (0.0202)  triple_80: 0.0000 (0.0294)  triple_60: 0.0000 (0.0177)  triple_40: 0.0000 (0.0144)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1400/1724]  eta: 0:21:11  lr: 0.000140  loss: 4.2891 (3.9679)  loss_n_40: 1.0937 (0.9274)  loss_n_60: 0.9889 (0.9284)  loss_n_80: 1.0561 (0.9871)  loss_n_100: 1.2145 (1.0440)  triple_100: 0.0000 (0.0201)  triple_80: 0.0000 (0.0292)  triple_60: 0.0000 (0.0175)  triple_40: 0.0000 (0.0143)  time: 3.9287  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1410/1724]  eta: 0:20:32  lr: 0.000140  loss: 3.5410 (3.9630)  loss_n_40: 0.7909 (0.9262)  loss_n_60: 0.7894 (0.9273)  loss_n_80: 0.8849 (0.9858)  loss_n_100: 1.0282 (1.0431)  triple_100: 0.0000 (0.0199)  triple_80: 0.0000 (0.0290)  triple_60: 0.0000 (0.0174)  triple_40: 0.0000 (0.0142)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1420/1724]  eta: 0:19:53  lr: 0.000140  loss: 3.1101 (3.9572)  loss_n_40: 0.6786 (0.9245)  loss_n_60: 0.7422 (0.9260)  loss_n_80: 0.7868 (0.9845)  loss_n_100: 0.9294 (1.0423)  triple_100: 0.0000 (0.0198)  triple_80: 0.0000 (0.0288)  triple_60: 0.0000 (0.0173)  triple_40: 0.0000 (0.0141)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1430/1724]  eta: 0:19:14  lr: 0.000140  loss: 2.9986 (3.9502)  loss_n_40: 0.6726 (0.9229)  loss_n_60: 0.7059 (0.9245)  loss_n_80: 0.7727 (0.9828)  loss_n_100: 0.8504 (1.0407)  triple_100: 0.0000 (0.0196)  triple_80: 0.0000 (0.0286)  triple_60: 0.0000 (0.0172)  triple_40: 0.0000 (0.0140)  time: 3.9292  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1440/1724]  eta: 0:18:34  lr: 0.000140  loss: 2.6121 (3.9403)  loss_n_40: 0.5836 (0.9206)  loss_n_60: 0.6256 (0.9222)  loss_n_80: 0.6565 (0.9803)  loss_n_100: 0.7195 (1.0384)  triple_100: 0.0000 (0.0195)  triple_80: 0.0000 (0.0284)  triple_60: 0.0000 (0.0171)  triple_40: 0.0000 (0.0139)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1450/1724]  eta: 0:17:55  lr: 0.000140  loss: 2.4005 (3.9303)  loss_n_40: 0.5442 (0.9183)  loss_n_60: 0.5780 (0.9199)  loss_n_80: 0.6038 (0.9779)  loss_n_100: 0.6598 (1.0358)  triple_100: 0.0000 (0.0194)  triple_80: 0.0000 (0.0282)  triple_60: 0.0000 (0.0169)  triple_40: 0.0000 (0.0138)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1460/1724]  eta: 0:17:16  lr: 0.000140  loss: 2.3164 (3.9194)  loss_n_40: 0.4933 (0.9158)  loss_n_60: 0.5626 (0.9175)  loss_n_80: 0.5795 (0.9752)  loss_n_100: 0.6352 (1.0331)  triple_100: 0.0000 (0.0192)  triple_80: 0.0000 (0.0280)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0137)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1470/1724]  eta: 0:16:37  lr: 0.000140  loss: 2.4889 (3.9135)  loss_n_40: 0.5896 (0.9144)  loss_n_60: 0.5693 (0.9157)  loss_n_80: 0.6193 (0.9735)  loss_n_100: 0.6771 (1.0315)  triple_100: 0.0000 (0.0194)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0144)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1480/1724]  eta: 0:15:57  lr: 0.000140  loss: 3.3314 (3.9117)  loss_n_40: 0.7760 (0.9140)  loss_n_60: 0.7682 (0.9150)  loss_n_80: 0.7566 (0.9726)  loss_n_100: 0.8324 (1.0305)  triple_100: 0.0000 (0.0192)  triple_80: 0.0000 (0.0286)  triple_60: 0.0000 (0.0167)  triple_40: 0.0000 (0.0152)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1490/1724]  eta: 0:15:18  lr: 0.000140  loss: 3.2928 (3.9067)  loss_n_40: 0.7760 (0.9127)  loss_n_60: 0.8003 (0.9141)  loss_n_80: 0.7568 (0.9711)  loss_n_100: 0.8362 (1.0294)  triple_100: 0.0000 (0.0191)  triple_80: 0.0000 (0.0284)  triple_60: 0.0000 (0.0166)  triple_40: 0.0000 (0.0154)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1500/1724]  eta: 0:14:39  lr: 0.000140  loss: 2.7282 (3.8981)  loss_n_40: 0.6200 (0.9106)  loss_n_60: 0.6904 (0.9123)  loss_n_80: 0.6840 (0.9691)  loss_n_100: 0.7596 (1.0272)  triple_100: 0.0000 (0.0190)  triple_80: 0.0000 (0.0282)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0153)  time: 3.9286  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [1510/1724]  eta: 0:14:00  lr: 0.000140  loss: 2.4172 (3.8886)  loss_n_40: 0.5393 (0.9084)  loss_n_60: 0.5987 (0.9102)  loss_n_80: 0.6321 (0.9668)  loss_n_100: 0.6570 (1.0249)  triple_100: 0.0000 (0.0188)  triple_80: 0.0000 (0.0280)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0152)  time: 3.9291  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1520/1724]  eta: 0:13:20  lr: 0.000140  loss: 2.3528 (3.8791)  loss_n_40: 0.5477 (0.9061)  loss_n_60: 0.5960 (0.9081)  loss_n_80: 0.6037 (0.9646)  loss_n_100: 0.6490 (1.0225)  triple_100: 0.0000 (0.0187)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0151)  time: 3.9307  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1530/1724]  eta: 0:12:41  lr: 0.000140  loss: 2.3551 (3.8714)  loss_n_40: 0.5285 (0.9044)  loss_n_60: 0.5872 (0.9061)  loss_n_80: 0.6129 (0.9623)  loss_n_100: 0.6658 (1.0203)  triple_100: 0.0000 (0.0190)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0150)  time: 3.9309  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1540/1724]  eta: 0:12:02  lr: 0.000140  loss: 3.0260 (3.8675)  loss_n_40: 0.6902 (0.9031)  loss_n_60: 0.6592 (0.9048)  loss_n_80: 0.6650 (0.9613)  loss_n_100: 0.7474 (1.0195)  triple_100: 0.0000 (0.0196)  triple_80: 0.0000 (0.0279)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0149)  time: 3.9303  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1550/1724]  eta: 0:11:23  lr: 0.000140  loss: 3.1160 (3.8715)  loss_n_40: 0.6963 (0.9021)  loss_n_60: 0.6891 (0.9038)  loss_n_80: 0.7797 (0.9603)  loss_n_100: 0.8757 (1.0187)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0297)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0148)  time: 3.9309  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1560/1724]  eta: 0:10:43  lr: 0.000140  loss: 4.6513 (3.8949)  loss_n_40: 0.9470 (0.9042)  loss_n_60: 0.9810 (0.9081)  loss_n_80: 1.0746 (0.9666)  loss_n_100: 1.1130 (1.0263)  triple_100: 0.0000 (0.0265)  triple_80: 0.0000 (0.0318)  triple_60: 0.0000 (0.0167)  triple_40: 0.0000 (0.0147)  time: 3.9307  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1570/1724]  eta: 0:10:04  lr: 0.000140  loss: 7.5846 (3.9173)  loss_n_40: 1.4608 (0.9080)  loss_n_60: 1.6841 (0.9133)  loss_n_80: 2.1156 (0.9731)  loss_n_100: 2.2901 (1.0337)  triple_100: 0.0000 (0.0264)  triple_80: 0.0000 (0.0316)  triple_60: 0.0000 (0.0166)  triple_40: 0.0000 (0.0146)  time: 3.9300  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1580/1724]  eta: 0:09:25  lr: 0.000140  loss: 6.4111 (3.9301)  loss_n_40: 1.3834 (0.9106)  loss_n_60: 1.5085 (0.9164)  loss_n_80: 1.6760 (0.9767)  loss_n_100: 1.8845 (1.0379)  triple_100: 0.0000 (0.0262)  triple_80: 0.0000 (0.0314)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0145)  time: 3.9314  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1590/1724]  eta: 0:08:46  lr: 0.000140  loss: 5.3520 (3.9364)  loss_n_40: 1.2335 (0.9122)  loss_n_60: 1.2851 (0.9183)  loss_n_80: 1.3112 (0.9782)  loss_n_100: 1.4504 (1.0398)  triple_100: 0.0000 (0.0260)  triple_80: 0.0000 (0.0312)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0144)  time: 3.9310  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1600/1724]  eta: 0:08:06  lr: 0.000140  loss: 4.5225 (3.9382)  loss_n_40: 1.1142 (0.9129)  loss_n_60: 1.0879 (0.9188)  loss_n_80: 1.0867 (0.9784)  loss_n_100: 1.2675 (1.0406)  triple_100: 0.0000 (0.0259)  triple_80: 0.0000 (0.0310)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0143)  time: 3.9295  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [1610/1724]  eta: 0:07:27  lr: 0.000140  loss: 3.9244 (3.9373)  loss_n_40: 0.9889 (0.9131)  loss_n_60: 0.9373 (0.9187)  loss_n_80: 0.9490 (0.9781)  loss_n_100: 1.0600 (1.0405)  triple_100: 0.0000 (0.0257)  triple_80: 0.0000 (0.0308)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0142)  time: 3.9294  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [1620/1724]  eta: 0:06:48  lr: 0.000140  loss: 3.7632 (3.9369)  loss_n_40: 0.9392 (0.9131)  loss_n_60: 0.8822 (0.9188)  loss_n_80: 0.8883 (0.9779)  loss_n_100: 1.0526 (1.0407)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0306)  triple_60: 0.0000 (0.0161)  triple_40: 0.0000 (0.0141)  time: 3.9285  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1630/1724]  eta: 0:06:09  lr: 0.000140  loss: 3.5090 (3.9331)  loss_n_40: 0.8280 (0.9123)  loss_n_60: 0.8822 (0.9181)  loss_n_80: 0.8170 (0.9767)  loss_n_100: 1.0064 (1.0402)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0304)  triple_60: 0.0000 (0.0160)  triple_40: 0.0000 (0.0140)  time: 3.9280  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1640/1724]  eta: 0:05:29  lr: 0.000140  loss: 3.3714 (3.9303)  loss_n_40: 0.7978 (0.9119)  loss_n_60: 0.8090 (0.9176)  loss_n_80: 0.7982 (0.9758)  loss_n_100: 0.9759 (1.0397)  triple_100: 0.0000 (0.0252)  triple_80: 0.0000 (0.0303)  triple_60: 0.0000 (0.0159)  triple_40: 0.0000 (0.0140)  time: 3.9278  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1650/1724]  eta: 0:04:50  lr: 0.000140  loss: 3.3337 (3.9254)  loss_n_40: 0.7861 (0.9108)  loss_n_60: 0.7815 (0.9166)  loss_n_80: 0.7801 (0.9744)  loss_n_100: 0.8993 (1.0387)  triple_100: 0.0000 (0.0251)  triple_80: 0.0000 (0.0301)  triple_60: 0.0000 (0.0158)  triple_40: 0.0000 (0.0139)  time: 3.9274  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1660/1724]  eta: 0:04:11  lr: 0.000140  loss: 2.8945 (3.9187)  loss_n_40: 0.6700 (0.9095)  loss_n_60: 0.6940 (0.9150)  loss_n_80: 0.6941 (0.9725)  loss_n_100: 0.8223 (1.0373)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0299)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0138)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1670/1724]  eta: 0:03:32  lr: 0.000140  loss: 2.7571 (3.9117)  loss_n_40: 0.6435 (0.9079)  loss_n_60: 0.6334 (0.9135)  loss_n_80: 0.6597 (0.9706)  loss_n_100: 0.7985 (1.0359)  triple_100: 0.0000 (0.0248)  triple_80: 0.0000 (0.0297)  triple_60: 0.0000 (0.0156)  triple_40: 0.0000 (0.0137)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1680/1724]  eta: 0:02:52  lr: 0.000140  loss: 2.6603 (3.9041)  loss_n_40: 0.6289 (0.9063)  loss_n_60: 0.6467 (0.9119)  loss_n_80: 0.6354 (0.9686)  loss_n_100: 0.7504 (1.0341)  triple_100: 0.0000 (0.0246)  triple_80: 0.0000 (0.0295)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0136)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1690/1724]  eta: 0:02:13  lr: 0.000140  loss: 2.6655 (3.8983)  loss_n_40: 0.6500 (0.9051)  loss_n_60: 0.6467 (0.9105)  loss_n_80: 0.6354 (0.9670)  loss_n_100: 0.7553 (1.0328)  triple_100: 0.0000 (0.0245)  triple_80: 0.0000 (0.0294)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0135)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1700/1724]  eta: 0:01:34  lr: 0.000140  loss: 2.5156 (3.8900)  loss_n_40: 0.5814 (0.9029)  loss_n_60: 0.5933 (0.9086)  loss_n_80: 0.6244 (0.9648)  loss_n_100: 0.7542 (1.0309)  triple_100: 0.0000 (0.0243)  triple_80: 0.0000 (0.0292)  triple_60: 0.0000 (0.0156)  triple_40: 0.0000 (0.0137)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:8]  [1710/1724]  eta: 0:00:54  lr: 0.000140  loss: 2.3434 (3.8813)  loss_n_40: 0.5171 (0.9007)  loss_n_60: 0.5555 (0.9065)  loss_n_80: 0.5589 (0.9626)  loss_n_100: 0.7044 (1.0291)  triple_100: 0.0000 (0.0242)  triple_80: 0.0000 (0.0290)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0136)  time: 3.9264  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [1720/1724]  eta: 0:00:15  lr: 0.000140  loss: 2.4561 (3.8737)  loss_n_40: 0.5459 (0.8991)  loss_n_60: 0.5603 (0.9048)  loss_n_80: 0.5855 (0.9606)  loss_n_100: 0.7124 (1.0274)  triple_100: 0.0000 (0.0241)  triple_80: 0.0000 (0.0289)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0136)  time: 3.9255  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8]  [1723/1724]  eta: 0:00:03  lr: 0.000140  loss: 2.3475 (3.8718)  loss_n_40: 0.5809 (0.8988)  loss_n_60: 0.5495 (0.9043)  loss_n_80: 0.5855 (0.9600)  loss_n_100: 0.7044 (1.0268)  triple_100: 0.0000 (0.0240)  triple_80: 0.0000 (0.0289)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0135)  time: 3.9254  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:8] Total time: 1:52:49 (3.9265 s / it)\n",
      "Averaged stats: lr: 0.000140  loss: 2.3475 (3.8718)  loss_n_40: 0.5809 (0.8988)  loss_n_60: 0.5495 (0.9043)  loss_n_80: 0.5855 (0.9600)  loss_n_100: 0.7044 (1.0268)  triple_100: 0.0000 (0.0240)  triple_80: 0.0000 (0.0289)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0135)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:8]  [  0/845]  eta: 0:10:14  loss: 2.0041 (2.0041)  loss_n_40: 0.4220 (0.4220)  loss_n_60: 0.4603 (0.4603)  loss_n_80: 0.5028 (0.5028)  loss_n_100: 0.6190 (0.6190)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7268  data: 0.3886  max mem: 46473\n",
      "Valid: [epoch:8]  [ 10/845]  eta: 0:05:08  loss: 2.3646 (2.4965)  loss_n_40: 0.5257 (0.6447)  loss_n_60: 0.4876 (0.5543)  loss_n_80: 0.5229 (0.5899)  loss_n_100: 0.6932 (0.7075)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3698  data: 0.0354  max mem: 46473\n",
      "Valid: [epoch:8]  [ 20/845]  eta: 0:04:50  loss: 2.3260 (2.5080)  loss_n_40: 0.5012 (0.6122)  loss_n_60: 0.4876 (0.5679)  loss_n_80: 0.5229 (0.6110)  loss_n_100: 0.6932 (0.7170)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [ 30/845]  eta: 0:04:42  loss: 2.1103 (2.4523)  loss_n_40: 0.4646 (0.5784)  loss_n_60: 0.4697 (0.5616)  loss_n_80: 0.5148 (0.6019)  loss_n_100: 0.6332 (0.7105)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [ 40/845]  eta: 0:04:36  loss: 1.8773 (2.3516)  loss_n_40: 0.3961 (0.5379)  loss_n_60: 0.4534 (0.5421)  loss_n_80: 0.4700 (0.5768)  loss_n_100: 0.5897 (0.6948)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [ 50/845]  eta: 0:04:31  loss: 1.8773 (2.3466)  loss_n_40: 0.3961 (0.5533)  loss_n_60: 0.4476 (0.5402)  loss_n_80: 0.4700 (0.5692)  loss_n_100: 0.5791 (0.6840)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [ 60/845]  eta: 0:04:27  loss: 2.1871 (2.4015)  loss_n_40: 0.4176 (0.5740)  loss_n_60: 0.4970 (0.5521)  loss_n_80: 0.5385 (0.5802)  loss_n_100: 0.7011 (0.6952)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [ 70/845]  eta: 0:04:23  loss: 2.3153 (2.3787)  loss_n_40: 0.4371 (0.5613)  loss_n_60: 0.5186 (0.5502)  loss_n_80: 0.5421 (0.5734)  loss_n_100: 0.7125 (0.6938)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [ 80/845]  eta: 0:04:19  loss: 2.1817 (2.3754)  loss_n_40: 0.4384 (0.5635)  loss_n_60: 0.4957 (0.5454)  loss_n_80: 0.5230 (0.5692)  loss_n_100: 0.6709 (0.6972)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [ 90/845]  eta: 0:04:15  loss: 2.2097 (2.3754)  loss_n_40: 0.4735 (0.5588)  loss_n_60: 0.4885 (0.5470)  loss_n_80: 0.5459 (0.5699)  loss_n_100: 0.6956 (0.6997)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [100/845]  eta: 0:04:12  loss: 2.2097 (2.3469)  loss_n_40: 0.4593 (0.5469)  loss_n_60: 0.4885 (0.5409)  loss_n_80: 0.5268 (0.5643)  loss_n_100: 0.6824 (0.6948)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [110/845]  eta: 0:04:08  loss: 2.2126 (2.3486)  loss_n_40: 0.4398 (0.5500)  loss_n_60: 0.4919 (0.5389)  loss_n_80: 0.5346 (0.5637)  loss_n_100: 0.6669 (0.6960)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [120/845]  eta: 0:04:04  loss: 2.2402 (2.3533)  loss_n_40: 0.4686 (0.5493)  loss_n_60: 0.5018 (0.5421)  loss_n_80: 0.5502 (0.5638)  loss_n_100: 0.6824 (0.6981)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [130/845]  eta: 0:04:01  loss: 2.1251 (2.3489)  loss_n_40: 0.4282 (0.5456)  loss_n_60: 0.5033 (0.5458)  loss_n_80: 0.5073 (0.5634)  loss_n_100: 0.6990 (0.6941)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [140/845]  eta: 0:03:57  loss: 1.9228 (2.3451)  loss_n_40: 0.4273 (0.5436)  loss_n_60: 0.5136 (0.5461)  loss_n_80: 0.4690 (0.5618)  loss_n_100: 0.5960 (0.6937)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [150/845]  eta: 0:03:54  loss: 2.2215 (2.3425)  loss_n_40: 0.4519 (0.5441)  loss_n_60: 0.5259 (0.5448)  loss_n_80: 0.5300 (0.5610)  loss_n_100: 0.6186 (0.6927)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [160/845]  eta: 0:03:50  loss: 2.2326 (2.3519)  loss_n_40: 0.4800 (0.5450)  loss_n_60: 0.5140 (0.5472)  loss_n_80: 0.5517 (0.5653)  loss_n_100: 0.6864 (0.6944)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [170/845]  eta: 0:03:47  loss: 2.2280 (2.3469)  loss_n_40: 0.4576 (0.5457)  loss_n_60: 0.4808 (0.5451)  loss_n_80: 0.4844 (0.5629)  loss_n_100: 0.6777 (0.6932)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [180/845]  eta: 0:03:43  loss: 2.2280 (2.3404)  loss_n_40: 0.4506 (0.5427)  loss_n_60: 0.4808 (0.5432)  loss_n_80: 0.5286 (0.5614)  loss_n_100: 0.6837 (0.6930)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [190/845]  eta: 0:03:40  loss: 2.2547 (2.3516)  loss_n_40: 0.4425 (0.5423)  loss_n_60: 0.4881 (0.5469)  loss_n_80: 0.5302 (0.5650)  loss_n_100: 0.7365 (0.6974)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [200/845]  eta: 0:03:37  loss: 2.2178 (2.3592)  loss_n_40: 0.4589 (0.5467)  loss_n_60: 0.5201 (0.5502)  loss_n_80: 0.5554 (0.5664)  loss_n_100: 0.7021 (0.6959)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [210/845]  eta: 0:03:33  loss: 2.2178 (2.3693)  loss_n_40: 0.4595 (0.5505)  loss_n_60: 0.5201 (0.5529)  loss_n_80: 0.5614 (0.5683)  loss_n_100: 0.7091 (0.6977)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [220/845]  eta: 0:03:30  loss: 2.2918 (2.3837)  loss_n_40: 0.4962 (0.5604)  loss_n_60: 0.5384 (0.5547)  loss_n_80: 0.5695 (0.5704)  loss_n_100: 0.7174 (0.6982)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [230/845]  eta: 0:03:26  loss: 2.1859 (2.3756)  loss_n_40: 0.4596 (0.5561)  loss_n_60: 0.4677 (0.5529)  loss_n_80: 0.5140 (0.5687)  loss_n_100: 0.6832 (0.6979)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [240/845]  eta: 0:03:23  loss: 2.0624 (2.3887)  loss_n_40: 0.4383 (0.5618)  loss_n_60: 0.4754 (0.5569)  loss_n_80: 0.4984 (0.5722)  loss_n_100: 0.6774 (0.6978)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:8]  [250/845]  eta: 0:03:20  loss: 2.2009 (2.3889)  loss_n_40: 0.4581 (0.5606)  loss_n_60: 0.5126 (0.5577)  loss_n_80: 0.5314 (0.5726)  loss_n_100: 0.6829 (0.6980)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3353  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [260/845]  eta: 0:03:16  loss: 2.1805 (2.3855)  loss_n_40: 0.4581 (0.5581)  loss_n_60: 0.5064 (0.5568)  loss_n_80: 0.5242 (0.5723)  loss_n_100: 0.6491 (0.6983)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3359  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [270/845]  eta: 0:03:13  loss: 2.2603 (2.3912)  loss_n_40: 0.4576 (0.5599)  loss_n_60: 0.5075 (0.5580)  loss_n_80: 0.5052 (0.5738)  loss_n_100: 0.7081 (0.6995)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3357  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [280/845]  eta: 0:03:09  loss: 2.2603 (2.3879)  loss_n_40: 0.4683 (0.5573)  loss_n_60: 0.4872 (0.5566)  loss_n_80: 0.5242 (0.5731)  loss_n_100: 0.7081 (0.7009)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3352  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [290/845]  eta: 0:03:06  loss: 1.9263 (2.3767)  loss_n_40: 0.4421 (0.5536)  loss_n_60: 0.4517 (0.5544)  loss_n_80: 0.4520 (0.5701)  loss_n_100: 0.6062 (0.6985)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3352  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [300/845]  eta: 0:03:03  loss: 2.2348 (2.3864)  loss_n_40: 0.4610 (0.5578)  loss_n_60: 0.4813 (0.5570)  loss_n_80: 0.5353 (0.5715)  loss_n_100: 0.6855 (0.7001)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [310/845]  eta: 0:02:59  loss: 2.2519 (2.3830)  loss_n_40: 0.4620 (0.5566)  loss_n_60: 0.5307 (0.5558)  loss_n_80: 0.5581 (0.5709)  loss_n_100: 0.6948 (0.6996)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [320/845]  eta: 0:02:56  loss: 2.2109 (2.3872)  loss_n_40: 0.4639 (0.5606)  loss_n_60: 0.5230 (0.5565)  loss_n_80: 0.5447 (0.5706)  loss_n_100: 0.6638 (0.6994)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [330/845]  eta: 0:02:53  loss: 2.1549 (2.3818)  loss_n_40: 0.4572 (0.5601)  loss_n_60: 0.4708 (0.5549)  loss_n_80: 0.4882 (0.5692)  loss_n_100: 0.6444 (0.6976)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [340/845]  eta: 0:02:49  loss: 2.0771 (2.3757)  loss_n_40: 0.4315 (0.5590)  loss_n_60: 0.4708 (0.5538)  loss_n_80: 0.4698 (0.5675)  loss_n_100: 0.5666 (0.6954)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [350/845]  eta: 0:02:46  loss: 2.0771 (2.4101)  loss_n_40: 0.4545 (0.5616)  loss_n_60: 0.4792 (0.5554)  loss_n_80: 0.4865 (0.5695)  loss_n_100: 0.5869 (0.6953)  triple_100: 0.0000 (0.0098)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0042)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [360/845]  eta: 0:02:42  loss: 1.9989 (2.4033)  loss_n_40: 0.4210 (0.5600)  loss_n_60: 0.4724 (0.5541)  loss_n_80: 0.4687 (0.5680)  loss_n_100: 0.5869 (0.6935)  triple_100: 0.0000 (0.0095)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0041)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [370/845]  eta: 0:02:39  loss: 2.0117 (2.3994)  loss_n_40: 0.4194 (0.5578)  loss_n_60: 0.4877 (0.5534)  loss_n_80: 0.4687 (0.5673)  loss_n_100: 0.6016 (0.6940)  triple_100: 0.0000 (0.0093)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0040)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [380/845]  eta: 0:02:36  loss: 2.3285 (2.3999)  loss_n_40: 0.4667 (0.5574)  loss_n_60: 0.5347 (0.5538)  loss_n_80: 0.5468 (0.5674)  loss_n_100: 0.6835 (0.6952)  triple_100: 0.0000 (0.0090)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0039)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [390/845]  eta: 0:02:32  loss: 2.2663 (2.3925)  loss_n_40: 0.4638 (0.5547)  loss_n_60: 0.5229 (0.5524)  loss_n_80: 0.5388 (0.5659)  loss_n_100: 0.6835 (0.6941)  triple_100: 0.0000 (0.0088)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0038)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [400/845]  eta: 0:02:29  loss: 2.2464 (2.3933)  loss_n_40: 0.4612 (0.5550)  loss_n_60: 0.5037 (0.5528)  loss_n_80: 0.5499 (0.5662)  loss_n_100: 0.7232 (0.6945)  triple_100: 0.0000 (0.0086)  triple_80: 0.0000 (0.0125)  triple_60: 0.0000 (0.0037)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [410/845]  eta: 0:02:26  loss: 2.2379 (2.3987)  loss_n_40: 0.4335 (0.5573)  loss_n_60: 0.5099 (0.5539)  loss_n_80: 0.5645 (0.5678)  loss_n_100: 0.6757 (0.6954)  triple_100: 0.0000 (0.0084)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0036)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [420/845]  eta: 0:02:22  loss: 2.1621 (2.3957)  loss_n_40: 0.4160 (0.5551)  loss_n_60: 0.5099 (0.5536)  loss_n_80: 0.5176 (0.5674)  loss_n_100: 0.6480 (0.6960)  triple_100: 0.0000 (0.0082)  triple_80: 0.0000 (0.0119)  triple_60: 0.0000 (0.0035)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [430/845]  eta: 0:02:19  loss: 2.0012 (2.3966)  loss_n_40: 0.4237 (0.5567)  loss_n_60: 0.4700 (0.5542)  loss_n_80: 0.4905 (0.5668)  loss_n_100: 0.6459 (0.6950)  triple_100: 0.0000 (0.0080)  triple_80: 0.0000 (0.0124)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [440/845]  eta: 0:02:15  loss: 2.1273 (2.3952)  loss_n_40: 0.4399 (0.5563)  loss_n_60: 0.4740 (0.5539)  loss_n_80: 0.4905 (0.5666)  loss_n_100: 0.6415 (0.6951)  triple_100: 0.0000 (0.0078)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [450/845]  eta: 0:02:12  loss: 2.0504 (2.3872)  loss_n_40: 0.4399 (0.5538)  loss_n_60: 0.4882 (0.5519)  loss_n_80: 0.4935 (0.5648)  loss_n_100: 0.6271 (0.6939)  triple_100: 0.0000 (0.0076)  triple_80: 0.0000 (0.0119)  triple_60: 0.0000 (0.0033)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [460/845]  eta: 0:02:09  loss: 1.9855 (2.3812)  loss_n_40: 0.4005 (0.5514)  loss_n_60: 0.4493 (0.5505)  loss_n_80: 0.4740 (0.5636)  loss_n_100: 0.6083 (0.6933)  triple_100: 0.0000 (0.0075)  triple_80: 0.0000 (0.0116)  triple_60: 0.0000 (0.0032)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [470/845]  eta: 0:02:05  loss: 2.0567 (2.3844)  loss_n_40: 0.4524 (0.5531)  loss_n_60: 0.5000 (0.5517)  loss_n_80: 0.4885 (0.5644)  loss_n_100: 0.6275 (0.6933)  triple_100: 0.0000 (0.0073)  triple_80: 0.0000 (0.0114)  triple_60: 0.0000 (0.0032)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [480/845]  eta: 0:02:02  loss: 1.9956 (2.3789)  loss_n_40: 0.4177 (0.5528)  loss_n_60: 0.4476 (0.5503)  loss_n_80: 0.4602 (0.5631)  loss_n_100: 0.5780 (0.6913)  triple_100: 0.0000 (0.0072)  triple_80: 0.0000 (0.0111)  triple_60: 0.0000 (0.0031)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [490/845]  eta: 0:01:59  loss: 2.2115 (2.3859)  loss_n_40: 0.4667 (0.5546)  loss_n_60: 0.4721 (0.5521)  loss_n_80: 0.5363 (0.5650)  loss_n_100: 0.6916 (0.6933)  triple_100: 0.0000 (0.0070)  triple_80: 0.0000 (0.0109)  triple_60: 0.0000 (0.0030)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:8]  [500/845]  eta: 0:01:55  loss: 2.2115 (2.3823)  loss_n_40: 0.4667 (0.5541)  loss_n_60: 0.5002 (0.5513)  loss_n_80: 0.5363 (0.5641)  loss_n_100: 0.6997 (0.6922)  triple_100: 0.0000 (0.0069)  triple_80: 0.0000 (0.0107)  triple_60: 0.0000 (0.0030)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [510/845]  eta: 0:01:52  loss: 2.0247 (2.3796)  loss_n_40: 0.4338 (0.5528)  loss_n_60: 0.4786 (0.5506)  loss_n_80: 0.4816 (0.5637)  loss_n_100: 0.6251 (0.6924)  triple_100: 0.0000 (0.0067)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0029)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [520/845]  eta: 0:01:49  loss: 2.2435 (2.3774)  loss_n_40: 0.4588 (0.5518)  loss_n_60: 0.5062 (0.5502)  loss_n_80: 0.5348 (0.5631)  loss_n_100: 0.7051 (0.6926)  triple_100: 0.0000 (0.0066)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [530/845]  eta: 0:01:45  loss: 2.2602 (2.3815)  loss_n_40: 0.4784 (0.5534)  loss_n_60: 0.5062 (0.5512)  loss_n_80: 0.5254 (0.5639)  loss_n_100: 0.6729 (0.6936)  triple_100: 0.0000 (0.0065)  triple_80: 0.0000 (0.0101)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [540/845]  eta: 0:01:42  loss: 2.0662 (2.3775)  loss_n_40: 0.4624 (0.5532)  loss_n_60: 0.4755 (0.5500)  loss_n_80: 0.5051 (0.5628)  loss_n_100: 0.6481 (0.6925)  triple_100: 0.0000 (0.0064)  triple_80: 0.0000 (0.0099)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [550/845]  eta: 0:01:38  loss: 2.0662 (2.3745)  loss_n_40: 0.4392 (0.5521)  loss_n_60: 0.4755 (0.5499)  loss_n_80: 0.4953 (0.5623)  loss_n_100: 0.5948 (0.6916)  triple_100: 0.0000 (0.0063)  triple_80: 0.0000 (0.0097)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [560/845]  eta: 0:01:35  loss: 2.2742 (2.3815)  loss_n_40: 0.4626 (0.5536)  loss_n_60: 0.5415 (0.5516)  loss_n_80: 0.5679 (0.5644)  loss_n_100: 0.7393 (0.6936)  triple_100: 0.0000 (0.0061)  triple_80: 0.0000 (0.0096)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [570/845]  eta: 0:01:32  loss: 2.2516 (2.3750)  loss_n_40: 0.4575 (0.5512)  loss_n_60: 0.5086 (0.5502)  loss_n_80: 0.5662 (0.5630)  loss_n_100: 0.7391 (0.6926)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [580/845]  eta: 0:01:28  loss: 1.8829 (2.3709)  loss_n_40: 0.4078 (0.5501)  loss_n_60: 0.4549 (0.5496)  loss_n_80: 0.4610 (0.5621)  loss_n_100: 0.5658 (0.6915)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0092)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [590/845]  eta: 0:01:25  loss: 1.8787 (2.3673)  loss_n_40: 0.4085 (0.5492)  loss_n_60: 0.4549 (0.5490)  loss_n_80: 0.4569 (0.5615)  loss_n_100: 0.5614 (0.6902)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0091)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [600/845]  eta: 0:01:22  loss: 1.8904 (2.3707)  loss_n_40: 0.4214 (0.5501)  loss_n_60: 0.4787 (0.5500)  loss_n_80: 0.4716 (0.5626)  loss_n_100: 0.5823 (0.6908)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0089)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [610/845]  eta: 0:01:18  loss: 2.2189 (2.3689)  loss_n_40: 0.4413 (0.5491)  loss_n_60: 0.4906 (0.5494)  loss_n_80: 0.5623 (0.5626)  loss_n_100: 0.6778 (0.6910)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0088)  triple_60: 0.0000 (0.0024)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [620/845]  eta: 0:01:15  loss: 2.2764 (2.3719)  loss_n_40: 0.4413 (0.5500)  loss_n_60: 0.5043 (0.5506)  loss_n_80: 0.5310 (0.5632)  loss_n_100: 0.6778 (0.6915)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0086)  triple_60: 0.0000 (0.0024)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [630/845]  eta: 0:01:12  loss: 2.0730 (2.3655)  loss_n_40: 0.4059 (0.5474)  loss_n_60: 0.4839 (0.5492)  loss_n_80: 0.4990 (0.5619)  loss_n_100: 0.6436 (0.6907)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0085)  triple_60: 0.0000 (0.0024)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [640/845]  eta: 0:01:08  loss: 1.9175 (2.3642)  loss_n_40: 0.3867 (0.5484)  loss_n_60: 0.4596 (0.5489)  loss_n_80: 0.4680 (0.5616)  loss_n_100: 0.5914 (0.6893)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0084)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [650/845]  eta: 0:01:05  loss: 1.9175 (2.3637)  loss_n_40: 0.4080 (0.5488)  loss_n_60: 0.4881 (0.5491)  loss_n_80: 0.4713 (0.5615)  loss_n_100: 0.5557 (0.6885)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0082)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [660/845]  eta: 0:01:02  loss: 2.2684 (2.3732)  loss_n_40: 0.4834 (0.5501)  loss_n_60: 0.4881 (0.5503)  loss_n_80: 0.5488 (0.5630)  loss_n_100: 0.6745 (0.6897)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [670/845]  eta: 0:00:58  loss: 2.2186 (2.3718)  loss_n_40: 0.4831 (0.5494)  loss_n_60: 0.4837 (0.5501)  loss_n_80: 0.5397 (0.5626)  loss_n_100: 0.7068 (0.6899)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0120)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [680/845]  eta: 0:00:55  loss: 2.0925 (2.3737)  loss_n_40: 0.4523 (0.5513)  loss_n_60: 0.4994 (0.5504)  loss_n_80: 0.4781 (0.5630)  loss_n_100: 0.6794 (0.6894)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0118)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [690/845]  eta: 0:00:51  loss: 2.3020 (2.3767)  loss_n_40: 0.4671 (0.5518)  loss_n_60: 0.5314 (0.5511)  loss_n_80: 0.5613 (0.5637)  loss_n_100: 0.7204 (0.6908)  triple_100: 0.0000 (0.0050)  triple_80: 0.0000 (0.0117)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [700/845]  eta: 0:00:48  loss: 2.3659 (2.3773)  loss_n_40: 0.4671 (0.5518)  loss_n_60: 0.4882 (0.5514)  loss_n_80: 0.5534 (0.5642)  loss_n_100: 0.7202 (0.6909)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0115)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [710/845]  eta: 0:00:45  loss: 2.2209 (2.3771)  loss_n_40: 0.4384 (0.5519)  loss_n_60: 0.4730 (0.5513)  loss_n_80: 0.5351 (0.5645)  loss_n_100: 0.6796 (0.6907)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [720/845]  eta: 0:00:41  loss: 2.2362 (2.3792)  loss_n_40: 0.4486 (0.5518)  loss_n_60: 0.4760 (0.5511)  loss_n_80: 0.5119 (0.5643)  loss_n_100: 0.6796 (0.6908)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [730/845]  eta: 0:00:38  loss: 2.2820 (2.3803)  loss_n_40: 0.4357 (0.5519)  loss_n_60: 0.5326 (0.5517)  loss_n_80: 0.5170 (0.5646)  loss_n_100: 0.6927 (0.6913)  triple_100: 0.0000 (0.0047)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [740/845]  eta: 0:00:35  loss: 2.1475 (2.3780)  loss_n_40: 0.4263 (0.5514)  loss_n_60: 0.5213 (0.5511)  loss_n_80: 0.5163 (0.5641)  loss_n_100: 0.6480 (0.6908)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0024)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:8]  [750/845]  eta: 0:00:31  loss: 2.2536 (2.3789)  loss_n_40: 0.4512 (0.5513)  loss_n_60: 0.4932 (0.5514)  loss_n_80: 0.4958 (0.5645)  loss_n_100: 0.6719 (0.6914)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0024)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [760/845]  eta: 0:00:28  loss: 2.2798 (2.3787)  loss_n_40: 0.4977 (0.5513)  loss_n_60: 0.4988 (0.5514)  loss_n_80: 0.5445 (0.5646)  loss_n_100: 0.6719 (0.6913)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0024)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [770/845]  eta: 0:00:25  loss: 2.2681 (2.3804)  loss_n_40: 0.4777 (0.5524)  loss_n_60: 0.4988 (0.5518)  loss_n_80: 0.5395 (0.5649)  loss_n_100: 0.6719 (0.6915)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [780/845]  eta: 0:00:21  loss: 2.1951 (2.3831)  loss_n_40: 0.4663 (0.5535)  loss_n_60: 0.5075 (0.5524)  loss_n_80: 0.5395 (0.5658)  loss_n_100: 0.6836 (0.6919)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:8]  [790/845]  eta: 0:00:18  loss: 2.0195 (2.3797)  loss_n_40: 0.4409 (0.5524)  loss_n_60: 0.4926 (0.5518)  loss_n_80: 0.4883 (0.5650)  loss_n_100: 0.6505 (0.6913)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0126)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [800/845]  eta: 0:00:15  loss: 1.9680 (2.3789)  loss_n_40: 0.4100 (0.5523)  loss_n_60: 0.4532 (0.5518)  loss_n_80: 0.4837 (0.5646)  loss_n_100: 0.6061 (0.6912)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0125)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [810/845]  eta: 0:00:11  loss: 2.2190 (2.3809)  loss_n_40: 0.4505 (0.5536)  loss_n_60: 0.5244 (0.5525)  loss_n_80: 0.5276 (0.5651)  loss_n_100: 0.6864 (0.6910)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0123)  triple_60: 0.0000 (0.0022)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [820/845]  eta: 0:00:08  loss: 2.1980 (2.3798)  loss_n_40: 0.4819 (0.5531)  loss_n_60: 0.5197 (0.5524)  loss_n_80: 0.5083 (0.5648)  loss_n_100: 0.6426 (0.6909)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0022)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [830/845]  eta: 0:00:05  loss: 2.2676 (2.3829)  loss_n_40: 0.4991 (0.5542)  loss_n_60: 0.5108 (0.5531)  loss_n_80: 0.5386 (0.5655)  loss_n_100: 0.6550 (0.6917)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0120)  triple_60: 0.0000 (0.0022)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [840/845]  eta: 0:00:01  loss: 2.2853 (2.3809)  loss_n_40: 0.4998 (0.5534)  loss_n_60: 0.5203 (0.5528)  loss_n_80: 0.5386 (0.5650)  loss_n_100: 0.6550 (0.6916)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0119)  triple_60: 0.0000 (0.0022)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8]  [844/845]  eta: 0:00:00  loss: 2.2469 (2.3805)  loss_n_40: 0.5065 (0.5533)  loss_n_60: 0.5108 (0.5527)  loss_n_80: 0.5242 (0.5650)  loss_n_100: 0.6401 (0.6915)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0118)  triple_60: 0.0000 (0.0021)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:8] Total time: 0:04:43 (0.3355 s / it)\n",
      "Averaged stats: loss: 2.2469 (2.3805)  loss_n_40: 0.5065 (0.5533)  loss_n_60: 0.5108 (0.5527)  loss_n_80: 0.5242 (0.5650)  loss_n_100: 0.6401 (0.6915)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0118)  triple_60: 0.0000 (0.0021)  triple_40: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_8_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 0.691%\n",
      "Min loss_n_100: 0.691\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:9]  [   0/1724]  eta: 2:02:09  lr: 0.000160  loss: 2.5458 (2.5458)  loss_n_40: 0.5980 (0.5980)  loss_n_60: 0.6174 (0.6174)  loss_n_80: 0.6282 (0.6282)  loss_n_100: 0.7021 (0.7021)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.2515  data: 0.4981  max mem: 46473\n",
      "Train: [epoch:9]  [  10/1724]  eta: 1:53:01  lr: 0.000160  loss: 2.9863 (2.8528)  loss_n_40: 0.7236 (0.7033)  loss_n_60: 0.6595 (0.6474)  loss_n_80: 0.6837 (0.6685)  loss_n_100: 0.7416 (0.7642)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0694)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9564  data: 0.0454  max mem: 46473\n",
      "Train: [epoch:9]  [  20/1724]  eta: 1:51:57  lr: 0.000160  loss: 2.6272 (2.7358)  loss_n_40: 0.6815 (0.6879)  loss_n_60: 0.5999 (0.6253)  loss_n_80: 0.6147 (0.6403)  loss_n_100: 0.7246 (0.7460)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0363)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [  30/1724]  eta: 1:51:09  lr: 0.000160  loss: 2.4584 (2.6129)  loss_n_40: 0.6442 (0.6758)  loss_n_60: 0.5606 (0.5926)  loss_n_80: 0.5574 (0.6098)  loss_n_100: 0.6802 (0.7100)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0246)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [  40/1724]  eta: 1:50:25  lr: 0.000160  loss: 2.3698 (2.5648)  loss_n_40: 0.6075 (0.6570)  loss_n_60: 0.5145 (0.5851)  loss_n_80: 0.5427 (0.6009)  loss_n_100: 0.6311 (0.7033)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0186)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [  50/1724]  eta: 1:49:43  lr: 0.000160  loss: 2.3095 (2.5071)  loss_n_40: 0.5694 (0.6401)  loss_n_60: 0.5088 (0.5680)  loss_n_80: 0.5751 (0.5931)  loss_n_100: 0.6417 (0.6910)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [  60/1724]  eta: 1:49:01  lr: 0.000160  loss: 2.1929 (2.4536)  loss_n_40: 0.5494 (0.6284)  loss_n_60: 0.4872 (0.5568)  loss_n_80: 0.5140 (0.5811)  loss_n_100: 0.5936 (0.6749)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0125)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [  70/1724]  eta: 1:48:20  lr: 0.000160  loss: 2.0272 (2.4011)  loss_n_40: 0.5067 (0.6111)  loss_n_60: 0.4525 (0.5455)  loss_n_80: 0.4851 (0.5702)  loss_n_100: 0.5686 (0.6635)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [  80/1724]  eta: 1:47:40  lr: 0.000160  loss: 2.5284 (2.5186)  loss_n_40: 0.5175 (0.6249)  loss_n_60: 0.5110 (0.5739)  loss_n_80: 0.5910 (0.5923)  loss_n_100: 0.6866 (0.6953)  triple_100: 0.0000 (0.0218)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0009)  triple_40: 0.0000 (0.0000)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [  90/1724]  eta: 1:47:00  lr: 0.000160  loss: 3.9503 (2.7191)  loss_n_40: 0.9473 (0.6701)  loss_n_60: 0.9931 (0.6325)  loss_n_80: 0.8927 (0.6414)  loss_n_100: 1.0511 (0.7461)  triple_100: 0.0000 (0.0194)  triple_80: 0.0000 (0.0084)  triple_60: 0.0000 (0.0008)  triple_40: 0.0000 (0.0003)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 100/1724]  eta: 1:46:20  lr: 0.000160  loss: 4.1695 (2.8475)  loss_n_40: 1.0128 (0.7030)  loss_n_60: 1.0177 (0.6619)  loss_n_80: 0.9911 (0.6732)  loss_n_100: 1.1131 (0.7761)  triple_100: 0.0000 (0.0175)  triple_80: 0.0000 (0.0076)  triple_60: 0.0000 (0.0007)  triple_40: 0.0000 (0.0075)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 110/1724]  eta: 1:45:41  lr: 0.000160  loss: 3.1168 (2.8585)  loss_n_40: 0.8050 (0.7060)  loss_n_60: 0.7358 (0.6652)  loss_n_80: 0.7731 (0.6779)  loss_n_100: 0.8403 (0.7790)  triple_100: 0.0000 (0.0159)  triple_80: 0.0000 (0.0069)  triple_60: 0.0000 (0.0007)  triple_40: 0.0000 (0.0068)  time: 3.9255  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [ 120/1724]  eta: 1:45:01  lr: 0.000160  loss: 2.9689 (2.8579)  loss_n_40: 0.7079 (0.7045)  loss_n_60: 0.6895 (0.6650)  loss_n_80: 0.7352 (0.6801)  loss_n_100: 0.8089 (0.7805)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0063)  triple_60: 0.0000 (0.0006)  triple_40: 0.0000 (0.0063)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 130/1724]  eta: 1:44:21  lr: 0.000160  loss: 2.3335 (2.8167)  loss_n_40: 0.5727 (0.6955)  loss_n_60: 0.5259 (0.6552)  loss_n_80: 0.5791 (0.6710)  loss_n_100: 0.6663 (0.7694)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0058)  triple_60: 0.0000 (0.0006)  triple_40: 0.0000 (0.0058)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 140/1724]  eta: 1:43:41  lr: 0.000160  loss: 2.2026 (2.7714)  loss_n_40: 0.5357 (0.6831)  loss_n_60: 0.4966 (0.6436)  loss_n_80: 0.5482 (0.6619)  loss_n_100: 0.6180 (0.7590)  triple_100: 0.0000 (0.0125)  triple_80: 0.0000 (0.0054)  triple_60: 0.0000 (0.0005)  triple_40: 0.0000 (0.0054)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 150/1724]  eta: 1:43:02  lr: 0.000160  loss: 2.1594 (2.7221)  loss_n_40: 0.5244 (0.6723)  loss_n_60: 0.4928 (0.6323)  loss_n_80: 0.5116 (0.6501)  loss_n_100: 0.5603 (0.7443)  triple_100: 0.0000 (0.0117)  triple_80: 0.0000 (0.0054)  triple_60: 0.0000 (0.0005)  triple_40: 0.0000 (0.0055)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 160/1724]  eta: 1:42:22  lr: 0.000160  loss: 2.1571 (2.6971)  loss_n_40: 0.5138 (0.6655)  loss_n_60: 0.5019 (0.6270)  loss_n_80: 0.5167 (0.6451)  loss_n_100: 0.5570 (0.7378)  triple_100: 0.0000 (0.0110)  triple_80: 0.0000 (0.0050)  triple_60: 0.0000 (0.0005)  triple_40: 0.0000 (0.0051)  time: 3.9243  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 170/1724]  eta: 1:41:43  lr: 0.000160  loss: 2.2445 (2.7000)  loss_n_40: 0.5552 (0.6628)  loss_n_60: 0.5197 (0.6230)  loss_n_80: 0.5504 (0.6408)  loss_n_100: 0.6078 (0.7303)  triple_100: 0.0000 (0.0187)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0064)  triple_40: 0.0000 (0.0048)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 180/1724]  eta: 1:41:03  lr: 0.000160  loss: 2.7122 (2.7793)  loss_n_40: 0.6463 (0.6748)  loss_n_60: 0.6582 (0.6363)  loss_n_80: 0.7161 (0.6605)  loss_n_100: 0.7222 (0.7503)  triple_100: 0.0000 (0.0319)  triple_80: 0.0000 (0.0126)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0048)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 190/1724]  eta: 1:40:23  lr: 0.000160  loss: 4.0275 (2.8406)  loss_n_40: 0.8733 (0.6870)  loss_n_60: 0.8936 (0.6495)  loss_n_80: 1.0188 (0.6797)  loss_n_100: 1.1233 (0.7699)  triple_100: 0.0000 (0.0302)  triple_80: 0.0000 (0.0119)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0046)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 200/1724]  eta: 1:39:44  lr: 0.000160  loss: 3.5027 (2.8637)  loss_n_40: 0.8286 (0.6934)  loss_n_60: 0.8271 (0.6554)  loss_n_80: 0.9308 (0.6877)  loss_n_100: 1.0072 (0.7754)  triple_100: 0.0000 (0.0287)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0043)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 210/1724]  eta: 1:39:05  lr: 0.000160  loss: 3.0190 (2.8559)  loss_n_40: 0.6996 (0.6916)  loss_n_60: 0.6903 (0.6540)  loss_n_80: 0.7615 (0.6881)  loss_n_100: 0.8185 (0.7729)  triple_100: 0.0000 (0.0274)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0041)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 220/1724]  eta: 1:38:25  lr: 0.000160  loss: 2.5729 (2.8415)  loss_n_40: 0.6286 (0.6875)  loss_n_60: 0.6011 (0.6518)  loss_n_80: 0.6663 (0.6867)  loss_n_100: 0.6863 (0.7685)  triple_100: 0.0000 (0.0261)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0039)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 230/1724]  eta: 1:37:46  lr: 0.000160  loss: 2.3498 (2.8160)  loss_n_40: 0.5470 (0.6820)  loss_n_60: 0.5763 (0.6458)  loss_n_80: 0.6061 (0.6816)  loss_n_100: 0.6393 (0.7616)  triple_100: 0.0000 (0.0250)  triple_80: 0.0000 (0.0098)  triple_60: 0.0000 (0.0064)  triple_40: 0.0000 (0.0038)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 240/1724]  eta: 1:37:06  lr: 0.000160  loss: 1.9081 (2.7839)  loss_n_40: 0.4695 (0.6760)  loss_n_60: 0.4476 (0.6389)  loss_n_80: 0.4978 (0.6742)  loss_n_100: 0.5305 (0.7516)  triple_100: 0.0000 (0.0239)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0061)  triple_40: 0.0000 (0.0036)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 250/1724]  eta: 1:36:27  lr: 0.000160  loss: 1.9661 (2.7532)  loss_n_40: 0.4695 (0.6682)  loss_n_60: 0.4598 (0.6322)  loss_n_80: 0.5072 (0.6680)  loss_n_100: 0.5357 (0.7435)  triple_100: 0.0000 (0.0230)  triple_80: 0.0000 (0.0091)  triple_60: 0.0000 (0.0059)  triple_40: 0.0000 (0.0035)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 260/1724]  eta: 1:35:47  lr: 0.000160  loss: 1.9661 (2.7202)  loss_n_40: 0.4233 (0.6589)  loss_n_60: 0.4588 (0.6249)  loss_n_80: 0.5064 (0.6611)  loss_n_100: 0.5405 (0.7354)  triple_100: 0.0000 (0.0221)  triple_80: 0.0000 (0.0087)  triple_60: 0.0000 (0.0057)  triple_40: 0.0000 (0.0033)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 270/1724]  eta: 1:35:08  lr: 0.000160  loss: 1.8871 (2.6909)  loss_n_40: 0.4224 (0.6519)  loss_n_60: 0.4364 (0.6185)  loss_n_80: 0.4843 (0.6552)  loss_n_100: 0.5002 (0.7269)  triple_100: 0.0000 (0.0213)  triple_80: 0.0000 (0.0084)  triple_60: 0.0000 (0.0055)  triple_40: 0.0000 (0.0032)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 280/1724]  eta: 1:34:29  lr: 0.000160  loss: 1.8142 (2.6674)  loss_n_40: 0.4266 (0.6463)  loss_n_60: 0.4271 (0.6134)  loss_n_80: 0.4721 (0.6505)  loss_n_100: 0.4986 (0.7202)  triple_100: 0.0000 (0.0205)  triple_80: 0.0000 (0.0081)  triple_60: 0.0000 (0.0053)  triple_40: 0.0000 (0.0031)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 290/1724]  eta: 1:33:50  lr: 0.000160  loss: 1.8534 (2.6424)  loss_n_40: 0.4235 (0.6402)  loss_n_60: 0.4398 (0.6082)  loss_n_80: 0.4721 (0.6451)  loss_n_100: 0.5008 (0.7132)  triple_100: 0.0000 (0.0198)  triple_80: 0.0000 (0.0078)  triple_60: 0.0000 (0.0051)  triple_40: 0.0000 (0.0030)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 300/1724]  eta: 1:33:10  lr: 0.000160  loss: 1.9302 (2.6236)  loss_n_40: 0.4399 (0.6355)  loss_n_60: 0.4666 (0.6040)  loss_n_80: 0.4984 (0.6412)  loss_n_100: 0.5202 (0.7084)  triple_100: 0.0000 (0.0192)  triple_80: 0.0000 (0.0076)  triple_60: 0.0000 (0.0049)  triple_40: 0.0000 (0.0029)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 310/1724]  eta: 1:32:31  lr: 0.000160  loss: 1.9153 (2.6036)  loss_n_40: 0.4720 (0.6315)  loss_n_60: 0.4666 (0.5998)  loss_n_80: 0.4969 (0.6365)  loss_n_100: 0.5334 (0.7025)  triple_100: 0.0000 (0.0186)  triple_80: 0.0000 (0.0073)  triple_60: 0.0000 (0.0048)  triple_40: 0.0000 (0.0028)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 320/1724]  eta: 1:31:52  lr: 0.000160  loss: 2.0260 (2.5918)  loss_n_40: 0.4663 (0.6274)  loss_n_60: 0.4674 (0.5963)  loss_n_80: 0.5290 (0.6339)  loss_n_100: 0.5365 (0.6996)  triple_100: 0.0000 (0.0180)  triple_80: 0.0000 (0.0088)  triple_60: 0.0000 (0.0046)  triple_40: 0.0000 (0.0032)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 330/1724]  eta: 1:31:13  lr: 0.000160  loss: 2.1976 (2.5834)  loss_n_40: 0.5196 (0.6254)  loss_n_60: 0.5001 (0.5940)  loss_n_80: 0.5634 (0.6325)  loss_n_100: 0.6173 (0.6980)  triple_100: 0.0000 (0.0174)  triple_80: 0.0000 (0.0085)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0031)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 340/1724]  eta: 1:30:33  lr: 0.000160  loss: 2.1248 (2.5673)  loss_n_40: 0.5196 (0.6223)  loss_n_60: 0.4942 (0.5903)  loss_n_80: 0.5323 (0.6288)  loss_n_100: 0.5788 (0.6932)  triple_100: 0.0000 (0.0169)  triple_80: 0.0000 (0.0083)  triple_60: 0.0000 (0.0043)  triple_40: 0.0000 (0.0030)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 350/1724]  eta: 1:29:54  lr: 0.000160  loss: 2.0167 (2.5522)  loss_n_40: 0.5111 (0.6191)  loss_n_60: 0.4529 (0.5870)  loss_n_80: 0.4801 (0.6256)  loss_n_100: 0.5264 (0.6889)  triple_100: 0.0000 (0.0164)  triple_80: 0.0000 (0.0081)  triple_60: 0.0000 (0.0042)  triple_40: 0.0000 (0.0030)  time: 3.9249  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [ 360/1724]  eta: 1:29:15  lr: 0.000160  loss: 1.8003 (2.5323)  loss_n_40: 0.4607 (0.6143)  loss_n_60: 0.4279 (0.5828)  loss_n_80: 0.4570 (0.6210)  loss_n_100: 0.4834 (0.6834)  triple_100: 0.0000 (0.0160)  triple_80: 0.0000 (0.0078)  triple_60: 0.0000 (0.0041)  triple_40: 0.0000 (0.0029)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 370/1724]  eta: 1:28:35  lr: 0.000160  loss: 1.7590 (2.5164)  loss_n_40: 0.4303 (0.6106)  loss_n_60: 0.4158 (0.5792)  loss_n_80: 0.4409 (0.6175)  loss_n_100: 0.4845 (0.6792)  triple_100: 0.0000 (0.0156)  triple_80: 0.0000 (0.0076)  triple_60: 0.0000 (0.0040)  triple_40: 0.0000 (0.0028)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 380/1724]  eta: 1:27:56  lr: 0.000160  loss: 1.7452 (2.4959)  loss_n_40: 0.4224 (0.6053)  loss_n_60: 0.4026 (0.5747)  loss_n_80: 0.4437 (0.6129)  loss_n_100: 0.4917 (0.6738)  triple_100: 0.0000 (0.0151)  triple_80: 0.0000 (0.0074)  triple_60: 0.0000 (0.0039)  triple_40: 0.0000 (0.0027)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 390/1724]  eta: 1:27:17  lr: 0.000160  loss: 1.7452 (2.4825)  loss_n_40: 0.4110 (0.6032)  loss_n_60: 0.4026 (0.5718)  loss_n_80: 0.4479 (0.6096)  loss_n_100: 0.4766 (0.6694)  triple_100: 0.0000 (0.0148)  triple_80: 0.0000 (0.0072)  triple_60: 0.0000 (0.0038)  triple_40: 0.0000 (0.0027)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 400/1724]  eta: 1:26:38  lr: 0.000160  loss: 1.6549 (2.4610)  loss_n_40: 0.3699 (0.5979)  loss_n_60: 0.3937 (0.5669)  loss_n_80: 0.4261 (0.6047)  loss_n_100: 0.4492 (0.6638)  triple_100: 0.0000 (0.0144)  triple_80: 0.0000 (0.0070)  triple_60: 0.0000 (0.0037)  triple_40: 0.0000 (0.0026)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 410/1724]  eta: 1:25:58  lr: 0.000160  loss: 1.6089 (2.4415)  loss_n_40: 0.3754 (0.5931)  loss_n_60: 0.3673 (0.5625)  loss_n_80: 0.4118 (0.6001)  loss_n_100: 0.4359 (0.6585)  triple_100: 0.0000 (0.0140)  triple_80: 0.0000 (0.0069)  triple_60: 0.0000 (0.0036)  triple_40: 0.0000 (0.0028)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 420/1724]  eta: 1:25:19  lr: 0.000160  loss: 1.6566 (2.4254)  loss_n_40: 0.3892 (0.5896)  loss_n_60: 0.3856 (0.5587)  loss_n_80: 0.4202 (0.5960)  loss_n_100: 0.4359 (0.6536)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0067)  triple_60: 0.0000 (0.0035)  triple_40: 0.0000 (0.0028)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 430/1724]  eta: 1:24:40  lr: 0.000160  loss: 1.7252 (2.4094)  loss_n_40: 0.4193 (0.5852)  loss_n_60: 0.4080 (0.5551)  loss_n_80: 0.4397 (0.5926)  loss_n_100: 0.4682 (0.6495)  triple_100: 0.0000 (0.0142)  triple_80: 0.0000 (0.0066)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0027)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 440/1724]  eta: 1:24:00  lr: 0.000160  loss: 1.7545 (2.3947)  loss_n_40: 0.4171 (0.5818)  loss_n_60: 0.4140 (0.5520)  loss_n_80: 0.4397 (0.5892)  loss_n_100: 0.4499 (0.6453)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0064)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0027)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 450/1724]  eta: 1:23:21  lr: 0.000160  loss: 1.6593 (2.3825)  loss_n_40: 0.4015 (0.5789)  loss_n_60: 0.3953 (0.5491)  loss_n_80: 0.4266 (0.5865)  loss_n_100: 0.4477 (0.6417)  triple_100: 0.0000 (0.0136)  triple_80: 0.0000 (0.0067)  triple_60: 0.0000 (0.0033)  triple_40: 0.0000 (0.0026)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 460/1724]  eta: 1:22:42  lr: 0.000160  loss: 1.9196 (2.3990)  loss_n_40: 0.4492 (0.5777)  loss_n_60: 0.4663 (0.5488)  loss_n_80: 0.4943 (0.5867)  loss_n_100: 0.5167 (0.6411)  triple_100: 0.0000 (0.0133)  triple_80: 0.0000 (0.0213)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0030)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 470/1724]  eta: 1:22:02  lr: 0.000160  loss: 2.3020 (2.4058)  loss_n_40: 0.4926 (0.5777)  loss_n_60: 0.5429 (0.5499)  loss_n_80: 0.5959 (0.5884)  loss_n_100: 0.6690 (0.6424)  triple_100: 0.0000 (0.0168)  triple_80: 0.0000 (0.0209)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0029)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 480/1724]  eta: 1:21:23  lr: 0.000160  loss: 2.3870 (2.4111)  loss_n_40: 0.5493 (0.5794)  loss_n_60: 0.5936 (0.5522)  loss_n_80: 0.6506 (0.5903)  loss_n_100: 0.6829 (0.6429)  triple_100: 0.0000 (0.0164)  triple_80: 0.0000 (0.0205)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0029)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 490/1724]  eta: 1:20:44  lr: 0.000160  loss: 2.1583 (2.4031)  loss_n_40: 0.5154 (0.5770)  loss_n_60: 0.5230 (0.5505)  loss_n_80: 0.5687 (0.5890)  loss_n_100: 0.6095 (0.6412)  triple_100: 0.0000 (0.0161)  triple_80: 0.0000 (0.0200)  triple_60: 0.0000 (0.0065)  triple_40: 0.0000 (0.0028)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 500/1724]  eta: 1:20:04  lr: 0.000160  loss: 1.9665 (2.3962)  loss_n_40: 0.4423 (0.5755)  loss_n_60: 0.4469 (0.5492)  loss_n_80: 0.5087 (0.5876)  loss_n_100: 0.5300 (0.6393)  triple_100: 0.0000 (0.0158)  triple_80: 0.0000 (0.0196)  triple_60: 0.0000 (0.0064)  triple_40: 0.0000 (0.0028)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 510/1724]  eta: 1:19:25  lr: 0.000160  loss: 1.7851 (2.3856)  loss_n_40: 0.4027 (0.5726)  loss_n_60: 0.4162 (0.5471)  loss_n_80: 0.4636 (0.5855)  loss_n_100: 0.5064 (0.6368)  triple_100: 0.0000 (0.0155)  triple_80: 0.0000 (0.0193)  triple_60: 0.0000 (0.0063)  triple_40: 0.0000 (0.0027)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 520/1724]  eta: 1:18:46  lr: 0.000160  loss: 1.6013 (2.3713)  loss_n_40: 0.3878 (0.5692)  loss_n_60: 0.3784 (0.5439)  loss_n_80: 0.4072 (0.5823)  loss_n_100: 0.4514 (0.6331)  triple_100: 0.0000 (0.0152)  triple_80: 0.0000 (0.0189)  triple_60: 0.0000 (0.0061)  triple_40: 0.0000 (0.0026)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 530/1724]  eta: 1:18:06  lr: 0.000160  loss: 1.4924 (2.3568)  loss_n_40: 0.3528 (0.5659)  loss_n_60: 0.3570 (0.5407)  loss_n_80: 0.3996 (0.5790)  loss_n_100: 0.4118 (0.6291)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0185)  triple_60: 0.0000 (0.0060)  triple_40: 0.0000 (0.0026)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 540/1724]  eta: 1:17:27  lr: 0.000160  loss: 1.6331 (2.3490)  loss_n_40: 0.3869 (0.5648)  loss_n_60: 0.3802 (0.5393)  loss_n_80: 0.4199 (0.5772)  loss_n_100: 0.4350 (0.6264)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0182)  triple_60: 0.0000 (0.0059)  triple_40: 0.0000 (0.0025)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 550/1724]  eta: 1:16:48  lr: 0.000160  loss: 2.0477 (2.3543)  loss_n_40: 0.4586 (0.5635)  loss_n_60: 0.4785 (0.5390)  loss_n_80: 0.4883 (0.5774)  loss_n_100: 0.4802 (0.6259)  triple_100: 0.0000 (0.0179)  triple_80: 0.0000 (0.0186)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0040)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 560/1724]  eta: 1:16:08  lr: 0.000160  loss: 4.0501 (2.3950)  loss_n_40: 0.7334 (0.5704)  loss_n_60: 0.8365 (0.5485)  loss_n_80: 0.9566 (0.5889)  loss_n_100: 0.9825 (0.6388)  triple_100: 0.0000 (0.0176)  triple_80: 0.0000 (0.0189)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0039)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 570/1724]  eta: 1:15:29  lr: 0.000160  loss: 4.0501 (2.4205)  loss_n_40: 0.8617 (0.5747)  loss_n_60: 0.9814 (0.5555)  loss_n_80: 1.0743 (0.5961)  loss_n_100: 1.1742 (0.6466)  triple_100: 0.0000 (0.0173)  triple_80: 0.0000 (0.0186)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0038)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 580/1724]  eta: 1:14:50  lr: 0.000160  loss: 3.5208 (2.4332)  loss_n_40: 0.7236 (0.5767)  loss_n_60: 0.8548 (0.5594)  loss_n_80: 0.8547 (0.5992)  loss_n_100: 0.9682 (0.6512)  triple_100: 0.0000 (0.0170)  triple_80: 0.0000 (0.0182)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0038)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 590/1724]  eta: 1:14:11  lr: 0.000160  loss: 2.8294 (2.4373)  loss_n_40: 0.5990 (0.5771)  loss_n_60: 0.6573 (0.5604)  loss_n_80: 0.7094 (0.6004)  loss_n_100: 0.8412 (0.6535)  triple_100: 0.0000 (0.0167)  triple_80: 0.0000 (0.0179)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0037)  time: 3.9230  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [ 600/1724]  eta: 1:13:31  lr: 0.000160  loss: 2.5496 (2.4360)  loss_n_40: 0.5599 (0.5760)  loss_n_60: 0.5746 (0.5600)  loss_n_80: 0.6691 (0.6004)  loss_n_100: 0.7614 (0.6544)  triple_100: 0.0000 (0.0164)  triple_80: 0.0000 (0.0176)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0037)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 610/1724]  eta: 1:12:52  lr: 0.000160  loss: 2.1554 (2.4334)  loss_n_40: 0.4924 (0.5752)  loss_n_60: 0.4880 (0.5594)  loss_n_80: 0.5560 (0.5999)  loss_n_100: 0.6370 (0.6545)  triple_100: 0.0000 (0.0161)  triple_80: 0.0000 (0.0174)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0036)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 620/1724]  eta: 1:12:13  lr: 0.000160  loss: 2.0731 (2.4288)  loss_n_40: 0.4712 (0.5742)  loss_n_60: 0.4723 (0.5583)  loss_n_80: 0.5125 (0.5987)  loss_n_100: 0.6155 (0.6539)  triple_100: 0.0000 (0.0159)  triple_80: 0.0000 (0.0171)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0035)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 630/1724]  eta: 1:11:34  lr: 0.000160  loss: 1.8604 (2.4186)  loss_n_40: 0.4145 (0.5717)  loss_n_60: 0.4154 (0.5561)  loss_n_80: 0.4586 (0.5966)  loss_n_100: 0.5293 (0.6512)  triple_100: 0.0000 (0.0156)  triple_80: 0.0000 (0.0168)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0035)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 640/1724]  eta: 1:10:54  lr: 0.000160  loss: 1.7617 (2.4109)  loss_n_40: 0.4163 (0.5699)  loss_n_60: 0.4005 (0.5545)  loss_n_80: 0.4606 (0.5951)  loss_n_100: 0.4826 (0.6490)  triple_100: 0.0000 (0.0154)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0034)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 650/1724]  eta: 1:10:15  lr: 0.000160  loss: 1.9311 (2.4039)  loss_n_40: 0.4339 (0.5683)  loss_n_60: 0.4535 (0.5531)  loss_n_80: 0.4882 (0.5934)  loss_n_100: 0.5176 (0.6473)  triple_100: 0.0000 (0.0152)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0034)  time: 3.9264  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 660/1724]  eta: 1:09:36  lr: 0.000160  loss: 1.8770 (2.3958)  loss_n_40: 0.4172 (0.5663)  loss_n_60: 0.4404 (0.5515)  loss_n_80: 0.4882 (0.5916)  loss_n_100: 0.5176 (0.6453)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0160)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0033)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 670/1724]  eta: 1:08:57  lr: 0.000160  loss: 1.7655 (2.3871)  loss_n_40: 0.4069 (0.5640)  loss_n_60: 0.4184 (0.5498)  loss_n_80: 0.4527 (0.5896)  loss_n_100: 0.5075 (0.6432)  triple_100: 0.0000 (0.0147)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0033)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 680/1724]  eta: 1:08:17  lr: 0.000160  loss: 1.7130 (2.3789)  loss_n_40: 0.3935 (0.5623)  loss_n_60: 0.4182 (0.5479)  loss_n_80: 0.4365 (0.5874)  loss_n_100: 0.4693 (0.6404)  triple_100: 0.0000 (0.0145)  triple_80: 0.0000 (0.0160)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0032)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 690/1724]  eta: 1:07:38  lr: 0.000160  loss: 1.7011 (2.3712)  loss_n_40: 0.3897 (0.5608)  loss_n_60: 0.3942 (0.5463)  loss_n_80: 0.4241 (0.5854)  loss_n_100: 0.4508 (0.6383)  triple_100: 0.0000 (0.0143)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0032)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 700/1724]  eta: 1:06:59  lr: 0.000160  loss: 1.6492 (2.3603)  loss_n_40: 0.3807 (0.5582)  loss_n_60: 0.3795 (0.5440)  loss_n_80: 0.4178 (0.5829)  loss_n_100: 0.4508 (0.6355)  triple_100: 0.0000 (0.0141)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0031)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 710/1724]  eta: 1:06:20  lr: 0.000160  loss: 1.6492 (2.3516)  loss_n_40: 0.3807 (0.5562)  loss_n_60: 0.3795 (0.5421)  loss_n_80: 0.4178 (0.5809)  loss_n_100: 0.4335 (0.6332)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0154)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0031)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 720/1724]  eta: 1:05:40  lr: 0.000160  loss: 1.7103 (2.3423)  loss_n_40: 0.3757 (0.5538)  loss_n_60: 0.4072 (0.5401)  loss_n_80: 0.4334 (0.5788)  loss_n_100: 0.4811 (0.6309)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0030)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 730/1724]  eta: 1:05:01  lr: 0.000160  loss: 1.6462 (2.3324)  loss_n_40: 0.3669 (0.5516)  loss_n_60: 0.3891 (0.5379)  loss_n_80: 0.4299 (0.5765)  loss_n_100: 0.4450 (0.6283)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0030)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 740/1724]  eta: 1:04:22  lr: 0.000160  loss: 1.6244 (2.3254)  loss_n_40: 0.3839 (0.5497)  loss_n_60: 0.3891 (0.5362)  loss_n_80: 0.3980 (0.5744)  loss_n_100: 0.4389 (0.6260)  triple_100: 0.0000 (0.0143)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0030)  time: 3.9260  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [ 750/1724]  eta: 1:03:43  lr: 0.000160  loss: 2.8012 (2.3407)  loss_n_40: 0.5260 (0.5519)  loss_n_60: 0.4841 (0.5399)  loss_n_80: 0.5725 (0.5792)  loss_n_100: 0.6457 (0.6309)  triple_100: 0.0000 (0.0141)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0029)  time: 3.9242  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [ 760/1724]  eta: 1:03:03  lr: 0.000160  loss: 3.0978 (2.3469)  loss_n_40: 0.6578 (0.5525)  loss_n_60: 0.7504 (0.5417)  loss_n_80: 0.8426 (0.5814)  loss_n_100: 0.8841 (0.6329)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0066)  triple_40: 0.0000 (0.0029)  time: 3.9214  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 770/1724]  eta: 1:02:24  lr: 0.000160  loss: 2.5867 (2.3478)  loss_n_40: 0.5642 (0.5525)  loss_n_60: 0.6221 (0.5426)  loss_n_80: 0.6594 (0.5819)  loss_n_100: 0.6830 (0.6329)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0066)  triple_40: 0.0000 (0.0029)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 780/1724]  eta: 1:01:45  lr: 0.000160  loss: 2.2079 (2.3451)  loss_n_40: 0.4946 (0.5516)  loss_n_60: 0.5500 (0.5423)  loss_n_80: 0.5727 (0.5815)  loss_n_100: 0.6122 (0.6325)  triple_100: 0.0000 (0.0136)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0065)  triple_40: 0.0000 (0.0028)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 790/1724]  eta: 1:01:05  lr: 0.000160  loss: 2.0427 (2.3414)  loss_n_40: 0.4638 (0.5507)  loss_n_60: 0.4932 (0.5417)  loss_n_80: 0.5094 (0.5807)  loss_n_100: 0.5668 (0.6315)  triple_100: 0.0000 (0.0134)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0064)  triple_40: 0.0000 (0.0028)  time: 3.9214  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 800/1724]  eta: 1:00:26  lr: 0.000160  loss: 1.9687 (2.3372)  loss_n_40: 0.4359 (0.5497)  loss_n_60: 0.4780 (0.5410)  loss_n_80: 0.4937 (0.5798)  loss_n_100: 0.5482 (0.6303)  triple_100: 0.0000 (0.0132)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0063)  triple_40: 0.0000 (0.0027)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 810/1724]  eta: 0:59:47  lr: 0.000160  loss: 1.7467 (2.3302)  loss_n_40: 0.3833 (0.5481)  loss_n_60: 0.4239 (0.5396)  loss_n_80: 0.4521 (0.5782)  loss_n_100: 0.5123 (0.6284)  triple_100: 0.0000 (0.0131)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0062)  triple_40: 0.0000 (0.0027)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 820/1724]  eta: 0:59:08  lr: 0.000160  loss: 1.6219 (2.3209)  loss_n_40: 0.3642 (0.5457)  loss_n_60: 0.3842 (0.5376)  loss_n_80: 0.4060 (0.5760)  loss_n_100: 0.4538 (0.6260)  triple_100: 0.0000 (0.0129)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0062)  triple_40: 0.0000 (0.0027)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 830/1724]  eta: 0:58:28  lr: 0.000160  loss: 1.6219 (2.3139)  loss_n_40: 0.3774 (0.5441)  loss_n_60: 0.3842 (0.5360)  loss_n_80: 0.4151 (0.5745)  loss_n_100: 0.4541 (0.6242)  triple_100: 0.0000 (0.0128)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0061)  triple_40: 0.0000 (0.0026)  time: 3.9230  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [ 840/1724]  eta: 0:57:49  lr: 0.000160  loss: 1.6961 (2.3070)  loss_n_40: 0.3810 (0.5426)  loss_n_60: 0.4151 (0.5346)  loss_n_80: 0.4271 (0.5729)  loss_n_100: 0.4564 (0.6223)  triple_100: 0.0000 (0.0126)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0060)  triple_40: 0.0000 (0.0026)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 850/1724]  eta: 0:57:10  lr: 0.000160  loss: 1.6532 (2.2981)  loss_n_40: 0.3788 (0.5405)  loss_n_60: 0.4029 (0.5326)  loss_n_80: 0.4119 (0.5707)  loss_n_100: 0.4503 (0.6201)  triple_100: 0.0000 (0.0125)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0059)  triple_40: 0.0000 (0.0026)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 860/1724]  eta: 0:56:31  lr: 0.000160  loss: 1.5390 (2.2903)  loss_n_40: 0.3457 (0.5389)  loss_n_60: 0.3653 (0.5309)  loss_n_80: 0.3870 (0.5687)  loss_n_100: 0.4336 (0.6180)  triple_100: 0.0000 (0.0123)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0059)  triple_40: 0.0000 (0.0026)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 870/1724]  eta: 0:55:51  lr: 0.000160  loss: 1.5664 (2.2851)  loss_n_40: 0.3510 (0.5379)  loss_n_60: 0.3627 (0.5298)  loss_n_80: 0.4025 (0.5674)  loss_n_100: 0.4371 (0.6164)  triple_100: 0.0000 (0.0122)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0058)  triple_40: 0.0000 (0.0025)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 880/1724]  eta: 0:55:12  lr: 0.000160  loss: 1.5876 (2.2793)  loss_n_40: 0.3492 (0.5362)  loss_n_60: 0.3627 (0.5285)  loss_n_80: 0.4123 (0.5662)  loss_n_100: 0.4654 (0.6151)  triple_100: 0.0000 (0.0120)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0057)  triple_40: 0.0000 (0.0025)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 890/1724]  eta: 0:54:33  lr: 0.000160  loss: 1.5535 (2.2714)  loss_n_40: 0.3440 (0.5342)  loss_n_60: 0.3532 (0.5268)  loss_n_80: 0.4060 (0.5644)  loss_n_100: 0.4367 (0.6131)  triple_100: 0.0000 (0.0119)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0057)  triple_40: 0.0000 (0.0025)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 900/1724]  eta: 0:53:54  lr: 0.000160  loss: 2.0637 (2.3018)  loss_n_40: 0.4128 (0.5362)  loss_n_60: 0.4746 (0.5299)  loss_n_80: 0.4947 (0.5689)  loss_n_100: 0.5302 (0.6183)  triple_100: 0.0000 (0.0180)  triple_80: 0.0000 (0.0168)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0043)  time: 3.9258  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [ 910/1724]  eta: 0:53:14  lr: 0.000160  loss: 4.0598 (2.3191)  loss_n_40: 0.7936 (0.5388)  loss_n_60: 0.9075 (0.5341)  loss_n_80: 1.0644 (0.5740)  loss_n_100: 1.1313 (0.6243)  triple_100: 0.0000 (0.0178)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0092)  triple_40: 0.0000 (0.0043)  time: 3.9259  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [ 920/1724]  eta: 0:52:35  lr: 0.000160  loss: 3.6348 (2.3274)  loss_n_40: 0.7194 (0.5403)  loss_n_60: 0.7919 (0.5360)  loss_n_80: 0.9385 (0.5767)  loss_n_100: 1.0211 (0.6271)  triple_100: 0.0000 (0.0176)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0042)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 930/1724]  eta: 0:51:56  lr: 0.000160  loss: 2.8402 (2.3322)  loss_n_40: 0.6420 (0.5416)  loss_n_60: 0.6427 (0.5370)  loss_n_80: 0.7640 (0.5785)  loss_n_100: 0.7730 (0.6282)  triple_100: 0.0000 (0.0174)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0042)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 940/1724]  eta: 0:51:17  lr: 0.000160  loss: 2.5967 (2.3326)  loss_n_40: 0.5656 (0.5414)  loss_n_60: 0.5852 (0.5372)  loss_n_80: 0.6684 (0.5790)  loss_n_100: 0.6890 (0.6286)  triple_100: 0.0000 (0.0173)  triple_80: 0.0000 (0.0161)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0041)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 950/1724]  eta: 0:50:37  lr: 0.000160  loss: 2.2862 (2.3314)  loss_n_40: 0.5228 (0.5413)  loss_n_60: 0.5380 (0.5372)  loss_n_80: 0.6008 (0.5790)  loss_n_100: 0.6106 (0.6280)  triple_100: 0.0000 (0.0171)  triple_80: 0.0000 (0.0160)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0041)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 960/1724]  eta: 0:49:58  lr: 0.000160  loss: 2.2384 (2.3312)  loss_n_40: 0.5485 (0.5415)  loss_n_60: 0.5380 (0.5375)  loss_n_80: 0.5992 (0.5792)  loss_n_100: 0.5613 (0.6276)  triple_100: 0.0000 (0.0169)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0040)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 970/1724]  eta: 0:49:19  lr: 0.000160  loss: 2.1793 (2.3297)  loss_n_40: 0.4728 (0.5410)  loss_n_60: 0.4908 (0.5373)  loss_n_80: 0.5754 (0.5792)  loss_n_100: 0.5447 (0.6273)  triple_100: 0.0000 (0.0167)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0040)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [ 980/1724]  eta: 0:48:40  lr: 0.000160  loss: 1.9508 (2.3259)  loss_n_40: 0.4448 (0.5399)  loss_n_60: 0.4785 (0.5367)  loss_n_80: 0.5083 (0.5785)  loss_n_100: 0.5306 (0.6263)  triple_100: 0.0000 (0.0166)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0040)  time: 3.9247  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [ 990/1724]  eta: 0:48:00  lr: 0.000160  loss: 1.8223 (2.3206)  loss_n_40: 0.4155 (0.5387)  loss_n_60: 0.4274 (0.5356)  loss_n_80: 0.4832 (0.5774)  loss_n_100: 0.4874 (0.6249)  triple_100: 0.0000 (0.0164)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0039)  time: 3.9245  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1000/1724]  eta: 0:47:21  lr: 0.000160  loss: 1.7455 (2.3161)  loss_n_40: 0.4125 (0.5379)  loss_n_60: 0.4242 (0.5347)  loss_n_80: 0.4583 (0.5764)  loss_n_100: 0.4781 (0.6235)  triple_100: 0.0000 (0.0162)  triple_80: 0.0000 (0.0152)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0039)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1010/1724]  eta: 0:46:42  lr: 0.000160  loss: 1.8303 (2.3116)  loss_n_40: 0.4210 (0.5369)  loss_n_60: 0.4298 (0.5337)  loss_n_80: 0.4766 (0.5755)  loss_n_100: 0.4987 (0.6224)  triple_100: 0.0000 (0.0161)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0038)  time: 3.9252  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1020/1724]  eta: 0:46:03  lr: 0.000160  loss: 1.7489 (2.3054)  loss_n_40: 0.3824 (0.5354)  loss_n_60: 0.4050 (0.5324)  loss_n_80: 0.4436 (0.5742)  loss_n_100: 0.4681 (0.6207)  triple_100: 0.0000 (0.0159)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0038)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1030/1724]  eta: 0:45:23  lr: 0.000160  loss: 1.6360 (2.3008)  loss_n_40: 0.3693 (0.5344)  loss_n_60: 0.3935 (0.5315)  loss_n_80: 0.4417 (0.5733)  loss_n_100: 0.4455 (0.6194)  triple_100: 0.0000 (0.0158)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0038)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1040/1724]  eta: 0:44:44  lr: 0.000160  loss: 1.7658 (2.2955)  loss_n_40: 0.4136 (0.5332)  loss_n_60: 0.4133 (0.5304)  loss_n_80: 0.4469 (0.5720)  loss_n_100: 0.4521 (0.6177)  triple_100: 0.0000 (0.0156)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0037)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1050/1724]  eta: 0:44:05  lr: 0.000160  loss: 1.7658 (2.2916)  loss_n_40: 0.4283 (0.5327)  loss_n_60: 0.4326 (0.5296)  loss_n_80: 0.4378 (0.5711)  loss_n_100: 0.4343 (0.6164)  triple_100: 0.0000 (0.0155)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0037)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1060/1724]  eta: 0:43:26  lr: 0.000160  loss: 1.7352 (2.2872)  loss_n_40: 0.4392 (0.5323)  loss_n_60: 0.4326 (0.5289)  loss_n_80: 0.4323 (0.5699)  loss_n_100: 0.4139 (0.6147)  triple_100: 0.0000 (0.0153)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0037)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1070/1724]  eta: 0:42:46  lr: 0.000160  loss: 1.5850 (2.2819)  loss_n_40: 0.3598 (0.5310)  loss_n_60: 0.3775 (0.5277)  loss_n_80: 0.4243 (0.5689)  loss_n_100: 0.4335 (0.6133)  triple_100: 0.0000 (0.0152)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0036)  time: 3.9247  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [1080/1724]  eta: 0:42:07  lr: 0.000160  loss: 1.6023 (2.2762)  loss_n_40: 0.3763 (0.5298)  loss_n_60: 0.3821 (0.5264)  loss_n_80: 0.4246 (0.5676)  loss_n_100: 0.4651 (0.6117)  triple_100: 0.0000 (0.0150)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0036)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1090/1724]  eta: 0:41:28  lr: 0.000160  loss: 1.7056 (2.2718)  loss_n_40: 0.3916 (0.5292)  loss_n_60: 0.3906 (0.5255)  loss_n_80: 0.4354 (0.5667)  loss_n_100: 0.4468 (0.6102)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0036)  time: 3.9260  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1100/1724]  eta: 0:40:49  lr: 0.000160  loss: 1.6734 (2.2658)  loss_n_40: 0.3903 (0.5281)  loss_n_60: 0.3906 (0.5242)  loss_n_80: 0.4303 (0.5653)  loss_n_100: 0.4242 (0.6084)  triple_100: 0.0000 (0.0147)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0035)  time: 3.9258  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1110/1724]  eta: 0:40:09  lr: 0.000160  loss: 1.5960 (2.2596)  loss_n_40: 0.3780 (0.5267)  loss_n_60: 0.3782 (0.5228)  loss_n_80: 0.3986 (0.5638)  loss_n_100: 0.4105 (0.6067)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0035)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1120/1724]  eta: 0:39:30  lr: 0.000160  loss: 1.4308 (2.2523)  loss_n_40: 0.3620 (0.5252)  loss_n_60: 0.3341 (0.5211)  loss_n_80: 0.3664 (0.5620)  loss_n_100: 0.3950 (0.6048)  triple_100: 0.0000 (0.0145)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0035)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1130/1724]  eta: 0:38:51  lr: 0.000160  loss: 1.5149 (2.2475)  loss_n_40: 0.3614 (0.5242)  loss_n_60: 0.3643 (0.5201)  loss_n_80: 0.3764 (0.5609)  loss_n_100: 0.4121 (0.6035)  triple_100: 0.0000 (0.0144)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0034)  time: 3.9257  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1140/1724]  eta: 0:38:12  lr: 0.000160  loss: 1.6906 (2.2434)  loss_n_40: 0.3908 (0.5232)  loss_n_60: 0.3948 (0.5192)  loss_n_80: 0.4236 (0.5600)  loss_n_100: 0.4572 (0.6025)  triple_100: 0.0000 (0.0142)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0034)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1150/1724]  eta: 0:37:32  lr: 0.000160  loss: 1.7389 (2.2391)  loss_n_40: 0.4072 (0.5223)  loss_n_60: 0.4116 (0.5183)  loss_n_80: 0.4506 (0.5590)  loss_n_100: 0.4547 (0.6014)  triple_100: 0.0000 (0.0141)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0034)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1160/1724]  eta: 0:36:53  lr: 0.000160  loss: 1.6354 (2.2346)  loss_n_40: 0.4108 (0.5217)  loss_n_60: 0.3858 (0.5173)  loss_n_80: 0.4127 (0.5577)  loss_n_100: 0.4390 (0.6001)  triple_100: 0.0000 (0.0140)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0033)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1170/1724]  eta: 0:36:14  lr: 0.000160  loss: 1.6297 (2.2302)  loss_n_40: 0.4053 (0.5209)  loss_n_60: 0.3790 (0.5162)  loss_n_80: 0.3916 (0.5565)  loss_n_100: 0.4281 (0.5989)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0033)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1180/1724]  eta: 0:35:35  lr: 0.000160  loss: 1.6531 (2.2265)  loss_n_40: 0.3934 (0.5203)  loss_n_60: 0.3790 (0.5153)  loss_n_80: 0.3980 (0.5556)  loss_n_100: 0.4386 (0.5979)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0033)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1190/1724]  eta: 0:34:55  lr: 0.000160  loss: 1.6983 (2.2235)  loss_n_40: 0.4224 (0.5199)  loss_n_60: 0.3999 (0.5144)  loss_n_80: 0.4308 (0.5547)  loss_n_100: 0.4577 (0.5968)  triple_100: 0.0000 (0.0136)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0033)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1200/1724]  eta: 0:34:16  lr: 0.000160  loss: 1.6366 (2.2183)  loss_n_40: 0.3999 (0.5190)  loss_n_60: 0.3785 (0.5132)  loss_n_80: 0.3938 (0.5533)  loss_n_100: 0.4242 (0.5952)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0032)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1210/1724]  eta: 0:33:37  lr: 0.000160  loss: 1.5819 (2.2138)  loss_n_40: 0.3956 (0.5183)  loss_n_60: 0.3744 (0.5122)  loss_n_80: 0.3914 (0.5522)  loss_n_100: 0.4185 (0.5940)  triple_100: 0.0000 (0.0134)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0032)  time: 3.9249  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1220/1724]  eta: 0:32:58  lr: 0.000160  loss: 1.5994 (2.2101)  loss_n_40: 0.3912 (0.5176)  loss_n_60: 0.3838 (0.5114)  loss_n_80: 0.3977 (0.5511)  loss_n_100: 0.4349 (0.5927)  triple_100: 0.0000 (0.0133)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0036)  time: 3.9249  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1230/1724]  eta: 0:32:18  lr: 0.000160  loss: 1.9470 (2.2086)  loss_n_40: 0.4840 (0.5178)  loss_n_60: 0.4469 (0.5110)  loss_n_80: 0.4809 (0.5507)  loss_n_100: 0.4787 (0.5922)  triple_100: 0.0000 (0.0132)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0035)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1240/1724]  eta: 0:31:39  lr: 0.000160  loss: 1.9333 (2.2065)  loss_n_40: 0.4687 (0.5176)  loss_n_60: 0.4548 (0.5106)  loss_n_80: 0.4844 (0.5501)  loss_n_100: 0.5080 (0.5915)  triple_100: 0.0000 (0.0131)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0035)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1250/1724]  eta: 0:31:00  lr: 0.000160  loss: 1.8251 (2.2030)  loss_n_40: 0.4511 (0.5170)  loss_n_60: 0.4393 (0.5099)  loss_n_80: 0.4541 (0.5493)  loss_n_100: 0.4747 (0.5904)  triple_100: 0.0000 (0.0130)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0035)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1260/1724]  eta: 0:30:21  lr: 0.000160  loss: 1.7417 (2.2000)  loss_n_40: 0.4261 (0.5164)  loss_n_60: 0.4126 (0.5093)  loss_n_80: 0.4419 (0.5483)  loss_n_100: 0.4747 (0.5894)  triple_100: 0.0000 (0.0129)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0036)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1270/1724]  eta: 0:29:41  lr: 0.000160  loss: 1.9102 (2.1996)  loss_n_40: 0.4697 (0.5163)  loss_n_60: 0.4256 (0.5091)  loss_n_80: 0.4701 (0.5481)  loss_n_100: 0.5050 (0.5891)  triple_100: 0.0000 (0.0128)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0036)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1280/1724]  eta: 0:29:02  lr: 0.000160  loss: 2.1266 (2.1994)  loss_n_40: 0.5088 (0.5166)  loss_n_60: 0.4983 (0.5092)  loss_n_80: 0.5088 (0.5480)  loss_n_100: 0.5596 (0.5890)  triple_100: 0.0000 (0.0127)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0036)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1290/1724]  eta: 0:28:23  lr: 0.000160  loss: 2.1497 (2.1991)  loss_n_40: 0.4950 (0.5166)  loss_n_60: 0.5093 (0.5094)  loss_n_80: 0.5296 (0.5479)  loss_n_100: 0.5763 (0.5889)  triple_100: 0.0000 (0.0126)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0036)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1300/1724]  eta: 0:27:44  lr: 0.000160  loss: 1.8821 (2.1955)  loss_n_40: 0.4406 (0.5159)  loss_n_60: 0.4606 (0.5087)  loss_n_80: 0.4533 (0.5469)  loss_n_100: 0.4932 (0.5879)  triple_100: 0.0000 (0.0125)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0035)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1310/1724]  eta: 0:27:04  lr: 0.000160  loss: 1.7887 (2.1939)  loss_n_40: 0.4280 (0.5154)  loss_n_60: 0.4274 (0.5084)  loss_n_80: 0.4420 (0.5465)  loss_n_100: 0.4850 (0.5877)  triple_100: 0.0000 (0.0125)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0035)  time: 3.9267  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [1320/1724]  eta: 0:26:25  lr: 0.000160  loss: 1.8007 (2.1907)  loss_n_40: 0.4326 (0.5147)  loss_n_60: 0.4299 (0.5077)  loss_n_80: 0.4506 (0.5457)  loss_n_100: 0.5015 (0.5870)  triple_100: 0.0000 (0.0124)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0035)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1330/1724]  eta: 0:25:46  lr: 0.000160  loss: 1.7014 (2.1879)  loss_n_40: 0.4047 (0.5140)  loss_n_60: 0.3852 (0.5069)  loss_n_80: 0.4253 (0.5448)  loss_n_100: 0.4621 (0.5861)  triple_100: 0.0000 (0.0123)  triple_80: 0.0000 (0.0127)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0038)  time: 3.9288  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1340/1724]  eta: 0:25:07  lr: 0.000160  loss: 1.6754 (2.1834)  loss_n_40: 0.3751 (0.5129)  loss_n_60: 0.3637 (0.5059)  loss_n_80: 0.4179 (0.5437)  loss_n_100: 0.4381 (0.5851)  triple_100: 0.0000 (0.0123)  triple_80: 0.0000 (0.0126)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0038)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1350/1724]  eta: 0:24:27  lr: 0.000160  loss: 1.6876 (2.1803)  loss_n_40: 0.3944 (0.5123)  loss_n_60: 0.3828 (0.5053)  loss_n_80: 0.4179 (0.5428)  loss_n_100: 0.4850 (0.5844)  triple_100: 0.0000 (0.0122)  triple_80: 0.0000 (0.0125)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0038)  time: 3.9286  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1360/1724]  eta: 0:23:48  lr: 0.000160  loss: 1.5445 (2.1755)  loss_n_40: 0.3856 (0.5112)  loss_n_60: 0.3545 (0.5042)  loss_n_80: 0.3900 (0.5416)  loss_n_100: 0.4325 (0.5832)  triple_100: 0.0000 (0.0121)  triple_80: 0.0000 (0.0125)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0037)  time: 3.9300  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1370/1724]  eta: 0:23:09  lr: 0.000160  loss: 1.4659 (2.1705)  loss_n_40: 0.3398 (0.5101)  loss_n_60: 0.3405 (0.5031)  loss_n_80: 0.3708 (0.5404)  loss_n_100: 0.4066 (0.5819)  triple_100: 0.0000 (0.0120)  triple_80: 0.0000 (0.0124)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0037)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1380/1724]  eta: 0:22:30  lr: 0.000160  loss: 1.4327 (2.1660)  loss_n_40: 0.3367 (0.5090)  loss_n_60: 0.3393 (0.5021)  loss_n_80: 0.3553 (0.5392)  loss_n_100: 0.3913 (0.5806)  triple_100: 0.0000 (0.0122)  triple_80: 0.0000 (0.0123)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0037)  time: 3.9269  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1390/1724]  eta: 0:21:51  lr: 0.000160  loss: 1.7205 (2.1656)  loss_n_40: 0.3979 (0.5085)  loss_n_60: 0.4054 (0.5017)  loss_n_80: 0.4265 (0.5389)  loss_n_100: 0.4836 (0.5803)  triple_100: 0.0000 (0.0122)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0037)  time: 3.9260  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1400/1724]  eta: 0:21:11  lr: 0.000160  loss: 2.2281 (2.1705)  loss_n_40: 0.4888 (0.5099)  loss_n_60: 0.5074 (0.5026)  loss_n_80: 0.5448 (0.5399)  loss_n_100: 0.6419 (0.5815)  triple_100: 0.0000 (0.0128)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0036)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1410/1724]  eta: 0:20:32  lr: 0.000160  loss: 2.9556 (2.1768)  loss_n_40: 0.6646 (0.5114)  loss_n_60: 0.6735 (0.5040)  loss_n_80: 0.7234 (0.5412)  loss_n_100: 0.7762 (0.5831)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0036)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1420/1724]  eta: 0:19:53  lr: 0.000160  loss: 2.9223 (2.1808)  loss_n_40: 0.6620 (0.5123)  loss_n_60: 0.6735 (0.5050)  loss_n_80: 0.7268 (0.5422)  loss_n_100: 0.7957 (0.5843)  triple_100: 0.0000 (0.0134)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0036)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1430/1724]  eta: 0:19:14  lr: 0.000160  loss: 2.8386 (2.1947)  loss_n_40: 0.6587 (0.5143)  loss_n_60: 0.6359 (0.5065)  loss_n_80: 0.7370 (0.5439)  loss_n_100: 0.7983 (0.5863)  triple_100: 0.0000 (0.0172)  triple_80: 0.0000 (0.0152)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0036)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1440/1724]  eta: 0:18:34  lr: 0.000160  loss: 3.4499 (2.2052)  loss_n_40: 0.7531 (0.5166)  loss_n_60: 0.7569 (0.5085)  loss_n_80: 0.8691 (0.5467)  loss_n_100: 0.9778 (0.5898)  triple_100: 0.0000 (0.0171)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0035)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1450/1724]  eta: 0:17:55  lr: 0.000160  loss: 4.3429 (2.2577)  loss_n_40: 0.9875 (0.5232)  loss_n_60: 0.8862 (0.5158)  loss_n_80: 1.0919 (0.5557)  loss_n_100: 1.2660 (0.5986)  triple_100: 0.0000 (0.0269)  triple_80: 0.0000 (0.0240)  triple_60: 0.0000 (0.0099)  triple_40: 0.0000 (0.0035)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1460/1724]  eta: 0:17:16  lr: 0.000160  loss: 9.6565 (2.3144)  loss_n_40: 2.1083 (0.5365)  loss_n_60: 2.2982 (0.5308)  loss_n_80: 2.5006 (0.5709)  loss_n_100: 2.3620 (0.6120)  triple_100: 0.0000 (0.0267)  triple_80: 0.0000 (0.0242)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0035)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1470/1724]  eta: 0:16:37  lr: 0.000160  loss: 11.1040 (2.3895)  loss_n_40: 2.5014 (0.5501)  loss_n_60: 2.7755 (0.5469)  loss_n_80: 2.8619 (0.5870)  loss_n_100: 2.5421 (0.6268)  triple_100: 0.0000 (0.0286)  triple_80: 0.0000 (0.0250)  triple_60: 0.0000 (0.0187)  triple_40: 0.0000 (0.0063)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1480/1724]  eta: 0:15:57  lr: 0.000160  loss: 13.3615 (2.4750)  loss_n_40: 2.7758 (0.5684)  loss_n_60: 3.1684 (0.5674)  loss_n_80: 3.0262 (0.6060)  loss_n_100: 3.0180 (0.6451)  triple_100: 0.0000 (0.0284)  triple_80: 0.0000 (0.0250)  triple_60: 0.0000 (0.0201)  triple_40: 0.0000 (0.0147)  time: 3.9273  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1490/1724]  eta: 0:15:18  lr: 0.000160  loss: 13.8645 (2.5487)  loss_n_40: 3.1270 (0.5847)  loss_n_60: 3.5172 (0.5875)  loss_n_80: 3.4001 (0.6251)  loss_n_100: 3.2889 (0.6631)  triple_100: 0.0000 (0.0282)  triple_80: 0.0000 (0.0248)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0146)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1500/1724]  eta: 0:14:39  lr: 0.000160  loss: 12.2519 (2.6106)  loss_n_40: 2.8056 (0.5989)  loss_n_60: 3.3056 (0.6048)  loss_n_80: 3.1865 (0.6408)  loss_n_100: 3.0887 (0.6782)  triple_100: 0.0000 (0.0280)  triple_80: 0.0000 (0.0246)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0145)  time: 3.9276  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1510/1724]  eta: 0:14:00  lr: 0.000160  loss: 11.3037 (2.6688)  loss_n_40: 2.5642 (0.6111)  loss_n_60: 3.0925 (0.6204)  loss_n_80: 2.9253 (0.6561)  loss_n_100: 2.8336 (0.6930)  triple_100: 0.0000 (0.0278)  triple_80: 0.0000 (0.0245)  triple_60: 0.0000 (0.0205)  triple_40: 0.0000 (0.0153)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1520/1724]  eta: 0:13:20  lr: 0.000160  loss: 10.8594 (2.7217)  loss_n_40: 2.1794 (0.6211)  loss_n_60: 2.8777 (0.6354)  loss_n_80: 2.9161 (0.6707)  loss_n_100: 2.7686 (0.7064)  triple_100: 0.0000 (0.0277)  triple_80: 0.0000 (0.0243)  triple_60: 0.0000 (0.0204)  triple_40: 0.0000 (0.0157)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1530/1724]  eta: 0:12:41  lr: 0.000160  loss: 10.5735 (2.7713)  loss_n_40: 2.0441 (0.6296)  loss_n_60: 2.8612 (0.6497)  loss_n_80: 2.8873 (0.6850)  loss_n_100: 2.7498 (0.7195)  triple_100: 0.0000 (0.0275)  triple_80: 0.0000 (0.0242)  triple_60: 0.0000 (0.0203)  triple_40: 0.0000 (0.0156)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1540/1724]  eta: 0:12:02  lr: 0.000160  loss: 9.7350 (2.8125)  loss_n_40: 1.8326 (0.6368)  loss_n_60: 2.5699 (0.6611)  loss_n_80: 2.7640 (0.6971)  loss_n_100: 2.5598 (0.7305)  triple_100: 0.0000 (0.0273)  triple_80: 0.0000 (0.0240)  triple_60: 0.0000 (0.0201)  triple_40: 0.0000 (0.0155)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1550/1724]  eta: 0:11:22  lr: 0.000160  loss: 8.6069 (2.8484)  loss_n_40: 1.6531 (0.6430)  loss_n_60: 2.2492 (0.6709)  loss_n_80: 2.4204 (0.7075)  loss_n_100: 2.2970 (0.7405)  triple_100: 0.0000 (0.0271)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0154)  time: 3.9246  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [1560/1724]  eta: 0:10:43  lr: 0.000160  loss: 8.2784 (2.8826)  loss_n_40: 1.5564 (0.6491)  loss_n_60: 2.1275 (0.6798)  loss_n_80: 2.3162 (0.7174)  loss_n_100: 2.2940 (0.7504)  triple_100: 0.0000 (0.0270)  triple_80: 0.0000 (0.0237)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0153)  time: 3.9248  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1570/1724]  eta: 0:10:04  lr: 0.000160  loss: 8.3118 (2.9177)  loss_n_40: 1.5304 (0.6546)  loss_n_60: 2.0484 (0.6885)  loss_n_80: 2.3192 (0.7278)  loss_n_100: 2.3594 (0.7615)  triple_100: 0.0000 (0.0268)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0198)  triple_40: 0.0000 (0.0152)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1580/1724]  eta: 0:09:25  lr: 0.000160  loss: 8.0971 (2.9469)  loss_n_40: 1.4742 (0.6596)  loss_n_60: 1.9055 (0.6953)  loss_n_80: 2.2153 (0.7359)  loss_n_100: 2.2865 (0.7707)  triple_100: 0.0000 (0.0266)  triple_80: 0.0000 (0.0234)  triple_60: 0.0000 (0.0203)  triple_40: 0.0000 (0.0151)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1590/1724]  eta: 0:08:45  lr: 0.000160  loss: 7.5852 (2.9775)  loss_n_40: 1.4584 (0.6647)  loss_n_60: 1.8192 (0.7025)  loss_n_80: 2.0257 (0.7448)  loss_n_100: 2.2614 (0.7806)  triple_100: 0.0000 (0.0264)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0202)  triple_40: 0.0000 (0.0150)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1600/1724]  eta: 0:08:06  lr: 0.000160  loss: 7.3691 (3.0045)  loss_n_40: 1.4344 (0.6694)  loss_n_60: 1.7676 (0.7091)  loss_n_80: 1.9873 (0.7526)  loss_n_100: 2.1706 (0.7891)  triple_100: 0.0000 (0.0263)  triple_80: 0.0000 (0.0231)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0149)  time: 3.9239  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1610/1724]  eta: 0:07:27  lr: 0.000160  loss: 7.0345 (3.0289)  loss_n_40: 1.3774 (0.6737)  loss_n_60: 1.6496 (0.7149)  loss_n_80: 1.9281 (0.7597)  loss_n_100: 2.0427 (0.7967)  triple_100: 0.0000 (0.0261)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0148)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1620/1724]  eta: 0:06:48  lr: 0.000160  loss: 6.8178 (3.0503)  loss_n_40: 1.3327 (0.6777)  loss_n_60: 1.5850 (0.7199)  loss_n_80: 1.8528 (0.7657)  loss_n_100: 1.9943 (0.8035)  triple_100: 0.0000 (0.0260)  triple_80: 0.0000 (0.0229)  triple_60: 0.0000 (0.0198)  triple_40: 0.0000 (0.0148)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1630/1724]  eta: 0:06:08  lr: 0.000160  loss: 6.2281 (3.0695)  loss_n_40: 1.2947 (0.6816)  loss_n_60: 1.5073 (0.7246)  loss_n_80: 1.6659 (0.7710)  loss_n_100: 1.7625 (0.8091)  triple_100: 0.0000 (0.0258)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0197)  triple_40: 0.0000 (0.0147)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1640/1724]  eta: 0:05:29  lr: 0.000160  loss: 6.0008 (3.0866)  loss_n_40: 1.2774 (0.6850)  loss_n_60: 1.4574 (0.7287)  loss_n_80: 1.6149 (0.7757)  loss_n_100: 1.7548 (0.8146)  triple_100: 0.0000 (0.0256)  triple_80: 0.0000 (0.0229)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0146)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1650/1724]  eta: 0:04:50  lr: 0.000160  loss: 5.6149 (3.1010)  loss_n_40: 1.2004 (0.6881)  loss_n_60: 1.3284 (0.7323)  loss_n_80: 1.4589 (0.7796)  loss_n_100: 1.5825 (0.8189)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0227)  triple_60: 0.0000 (0.0194)  triple_40: 0.0000 (0.0145)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1660/1724]  eta: 0:04:11  lr: 0.000160  loss: 5.1248 (3.1121)  loss_n_40: 1.1488 (0.6903)  loss_n_60: 1.2483 (0.7351)  loss_n_80: 1.2709 (0.7827)  loss_n_100: 1.4079 (0.8223)  triple_100: 0.0000 (0.0253)  triple_80: 0.0000 (0.0226)  triple_60: 0.0000 (0.0193)  triple_40: 0.0000 (0.0144)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1670/1724]  eta: 0:03:31  lr: 0.000160  loss: 4.7466 (3.1230)  loss_n_40: 1.0304 (0.6927)  loss_n_60: 1.1382 (0.7378)  loss_n_80: 1.2517 (0.7858)  loss_n_100: 1.3362 (0.8256)  triple_100: 0.0000 (0.0252)  triple_80: 0.0000 (0.0224)  triple_60: 0.0000 (0.0192)  triple_40: 0.0000 (0.0143)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1680/1724]  eta: 0:02:52  lr: 0.000160  loss: 4.6758 (3.1331)  loss_n_40: 1.0197 (0.6947)  loss_n_60: 1.1382 (0.7403)  loss_n_80: 1.2119 (0.7886)  loss_n_100: 1.3362 (0.8288)  triple_100: 0.0000 (0.0250)  triple_80: 0.0000 (0.0223)  triple_60: 0.0000 (0.0191)  triple_40: 0.0000 (0.0142)  time: 3.9262  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1690/1724]  eta: 0:02:13  lr: 0.000160  loss: 4.6081 (3.1426)  loss_n_40: 0.9737 (0.6966)  loss_n_60: 1.1051 (0.7425)  loss_n_80: 1.2116 (0.7912)  loss_n_100: 1.3200 (0.8318)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0222)  triple_60: 0.0000 (0.0192)  triple_40: 0.0000 (0.0142)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1700/1724]  eta: 0:01:34  lr: 0.000160  loss: 5.3859 (3.1591)  loss_n_40: 1.2379 (0.7007)  loss_n_60: 1.2660 (0.7462)  loss_n_80: 1.4038 (0.7955)  loss_n_100: 1.5395 (0.8367)  triple_100: 0.0000 (0.0247)  triple_80: 0.0000 (0.0220)  triple_60: 0.0000 (0.0191)  triple_40: 0.0000 (0.0141)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:9]  [1710/1724]  eta: 0:00:54  lr: 0.000160  loss: 5.7067 (3.1740)  loss_n_40: 1.2976 (0.7043)  loss_n_60: 1.3033 (0.7492)  loss_n_80: 1.4038 (0.7988)  loss_n_100: 1.5982 (0.8408)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0219)  triple_60: 0.0000 (0.0190)  triple_40: 0.0000 (0.0146)  time: 3.9250  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1720/1724]  eta: 0:00:15  lr: 0.000160  loss: 5.6060 (3.1882)  loss_n_40: 1.2808 (0.7081)  loss_n_60: 1.2415 (0.7524)  loss_n_80: 1.3592 (0.8022)  loss_n_100: 1.4840 (0.8451)  triple_100: 0.0000 (0.0253)  triple_80: 0.0000 (0.0218)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0145)  time: 3.9247  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9]  [1723/1724]  eta: 0:00:03  lr: 0.000160  loss: 5.5584 (3.1924)  loss_n_40: 1.2840 (0.7092)  loss_n_60: 1.2415 (0.7533)  loss_n_80: 1.3614 (0.8033)  loss_n_100: 1.5273 (0.8464)  triple_100: 0.0000 (0.0252)  triple_80: 0.0000 (0.0218)  triple_60: 0.0000 (0.0188)  triple_40: 0.0000 (0.0145)  time: 3.9245  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:9] Total time: 1:52:47 (3.9254 s / it)\n",
      "Averaged stats: lr: 0.000160  loss: 5.5584 (3.1924)  loss_n_40: 1.2840 (0.7092)  loss_n_60: 1.2415 (0.7533)  loss_n_80: 1.3614 (0.8033)  loss_n_100: 1.5273 (0.8464)  triple_100: 0.0000 (0.0252)  triple_80: 0.0000 (0.0218)  triple_60: 0.0000 (0.0188)  triple_40: 0.0000 (0.0145)\n",
      "Valid: [epoch:9]  [  0/845]  eta: 0:10:43  loss: 5.1483 (5.1483)  loss_n_40: 1.2601 (1.2601)  loss_n_60: 1.0683 (1.0683)  loss_n_80: 1.2122 (1.2122)  loss_n_100: 1.6077 (1.6077)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7617  data: 0.4253  max mem: 46473\n",
      "Valid: [epoch:9]  [ 10/845]  eta: 0:05:11  loss: 4.6536 (4.7342)  loss_n_40: 1.2329 (1.2166)  loss_n_60: 1.0683 (1.0663)  loss_n_80: 1.1951 (1.1366)  loss_n_100: 1.3661 (1.3147)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3736  data: 0.0388  max mem: 46473\n",
      "Valid: [epoch:9]  [ 20/845]  eta: 0:04:52  loss: 4.7359 (4.9639)  loss_n_40: 1.1974 (1.2679)  loss_n_60: 1.0691 (1.1491)  loss_n_80: 1.1951 (1.1932)  loss_n_100: 1.3661 (1.3536)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:9]  [ 30/845]  eta: 0:04:43  loss: 5.1882 (5.0291)  loss_n_40: 1.1974 (1.2566)  loss_n_60: 1.2255 (1.1696)  loss_n_80: 1.2401 (1.2173)  loss_n_100: 1.4310 (1.3856)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:9]  [ 40/845]  eta: 0:04:37  loss: 5.3083 (5.0949)  loss_n_40: 1.1625 (1.2497)  loss_n_60: 1.2255 (1.1945)  loss_n_80: 1.2832 (1.2382)  loss_n_100: 1.4379 (1.4125)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:9]  [ 50/845]  eta: 0:04:32  loss: 5.1377 (5.1072)  loss_n_40: 1.2233 (1.2435)  loss_n_60: 1.2676 (1.2000)  loss_n_80: 1.3017 (1.2414)  loss_n_100: 1.4133 (1.4223)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [ 60/845]  eta: 0:04:28  loss: 4.5871 (4.9995)  loss_n_40: 1.1742 (1.2218)  loss_n_60: 0.9859 (1.1619)  loss_n_80: 1.0594 (1.2087)  loss_n_100: 1.3927 (1.4071)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [ 70/845]  eta: 0:04:24  loss: 4.5180 (5.0539)  loss_n_40: 1.1742 (1.2275)  loss_n_60: 0.9859 (1.1725)  loss_n_80: 1.0875 (1.2301)  loss_n_100: 1.3412 (1.4238)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [ 80/845]  eta: 0:04:20  loss: 5.1887 (5.0245)  loss_n_40: 1.2359 (1.2259)  loss_n_60: 1.1499 (1.1581)  loss_n_80: 1.2605 (1.2231)  loss_n_100: 1.3788 (1.4174)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [ 90/845]  eta: 0:04:16  loss: 5.1887 (5.0640)  loss_n_40: 1.1892 (1.2278)  loss_n_60: 1.1236 (1.1661)  loss_n_80: 1.2605 (1.2347)  loss_n_100: 1.4736 (1.4354)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [100/845]  eta: 0:04:12  loss: 5.2825 (5.1011)  loss_n_40: 1.1892 (1.2234)  loss_n_60: 1.1506 (1.1783)  loss_n_80: 1.3564 (1.2443)  loss_n_100: 1.5902 (1.4552)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3352  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [110/845]  eta: 0:04:08  loss: 5.0215 (5.0906)  loss_n_40: 1.1903 (1.2216)  loss_n_60: 1.1241 (1.1764)  loss_n_80: 1.2147 (1.2407)  loss_n_100: 1.5796 (1.4518)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [120/845]  eta: 0:04:05  loss: 5.0407 (5.0986)  loss_n_40: 1.2410 (1.2257)  loss_n_60: 1.1101 (1.1764)  loss_n_80: 1.2504 (1.2450)  loss_n_100: 1.4069 (1.4514)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [130/845]  eta: 0:04:01  loss: 5.1492 (5.1093)  loss_n_40: 1.2635 (1.2277)  loss_n_60: 1.1101 (1.1730)  loss_n_80: 1.3162 (1.2439)  loss_n_100: 1.4096 (1.4480)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0166)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [140/845]  eta: 0:03:58  loss: 5.1620 (5.1258)  loss_n_40: 1.2455 (1.2347)  loss_n_60: 1.1501 (1.1747)  loss_n_80: 1.2550 (1.2469)  loss_n_100: 1.3997 (1.4542)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0154)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [150/845]  eta: 0:03:54  loss: 5.2289 (5.1421)  loss_n_40: 1.2614 (1.2411)  loss_n_60: 1.1814 (1.1757)  loss_n_80: 1.3095 (1.2531)  loss_n_100: 1.4499 (1.4579)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0144)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [160/845]  eta: 0:03:51  loss: 5.2052 (5.1374)  loss_n_40: 1.2376 (1.2432)  loss_n_60: 1.0992 (1.1720)  loss_n_80: 1.2504 (1.2503)  loss_n_100: 1.4543 (1.4583)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0135)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [170/845]  eta: 0:03:47  loss: 5.0634 (5.1240)  loss_n_40: 1.1957 (1.2351)  loss_n_60: 1.0700 (1.1710)  loss_n_80: 1.1718 (1.2468)  loss_n_100: 1.4543 (1.4584)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0127)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [180/845]  eta: 0:03:44  loss: 5.0634 (5.1330)  loss_n_40: 1.2054 (1.2385)  loss_n_60: 1.1827 (1.1757)  loss_n_80: 1.2351 (1.2477)  loss_n_100: 1.4027 (1.4590)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0120)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [190/845]  eta: 0:03:40  loss: 5.0969 (5.1349)  loss_n_40: 1.3067 (1.2390)  loss_n_60: 1.1704 (1.1778)  loss_n_80: 1.2465 (1.2482)  loss_n_100: 1.4155 (1.4585)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0114)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [200/845]  eta: 0:03:37  loss: 4.9126 (5.1319)  loss_n_40: 1.1681 (1.2361)  loss_n_60: 1.1040 (1.1754)  loss_n_80: 1.2465 (1.2472)  loss_n_100: 1.4392 (1.4624)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0108)  time: 0.3348  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:9]  [210/845]  eta: 0:03:33  loss: 5.2078 (5.1420)  loss_n_40: 1.1995 (1.2380)  loss_n_60: 1.1742 (1.1804)  loss_n_80: 1.2799 (1.2510)  loss_n_100: 1.4608 (1.4623)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0103)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [220/845]  eta: 0:03:30  loss: 5.3358 (5.1579)  loss_n_40: 1.2659 (1.2473)  loss_n_60: 1.2161 (1.1865)  loss_n_80: 1.3349 (1.2539)  loss_n_100: 1.3676 (1.4604)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0098)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [230/845]  eta: 0:03:27  loss: 5.0910 (5.1479)  loss_n_40: 1.1996 (1.2454)  loss_n_60: 1.1754 (1.1823)  loss_n_80: 1.2323 (1.2513)  loss_n_100: 1.3786 (1.4595)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0094)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [240/845]  eta: 0:03:23  loss: 4.8659 (5.1373)  loss_n_40: 1.1615 (1.2456)  loss_n_60: 1.0244 (1.1788)  loss_n_80: 1.1959 (1.2491)  loss_n_100: 1.3824 (1.4547)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0090)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [250/845]  eta: 0:03:20  loss: 4.7900 (5.1274)  loss_n_40: 1.0919 (1.2416)  loss_n_60: 1.0194 (1.1758)  loss_n_80: 1.1959 (1.2485)  loss_n_100: 1.4379 (1.4528)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0086)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [260/845]  eta: 0:03:16  loss: 5.0865 (5.1363)  loss_n_40: 1.2081 (1.2460)  loss_n_60: 1.0923 (1.1789)  loss_n_80: 1.2614 (1.2512)  loss_n_100: 1.4379 (1.4518)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0083)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [270/845]  eta: 0:03:13  loss: 5.2450 (5.1313)  loss_n_40: 1.2497 (1.2446)  loss_n_60: 1.1989 (1.1774)  loss_n_80: 1.2475 (1.2502)  loss_n_100: 1.3774 (1.4511)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0080)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [280/845]  eta: 0:03:10  loss: 5.2608 (5.1378)  loss_n_40: 1.1629 (1.2436)  loss_n_60: 1.1989 (1.1812)  loss_n_80: 1.2477 (1.2515)  loss_n_100: 1.4094 (1.4537)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0077)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [290/845]  eta: 0:03:06  loss: 5.2608 (5.1458)  loss_n_40: 1.2306 (1.2463)  loss_n_60: 1.2163 (1.1835)  loss_n_80: 1.2978 (1.2521)  loss_n_100: 1.5388 (1.4565)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0075)  time: 0.3349  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:9]  [300/845]  eta: 0:03:03  loss: 5.3425 (5.1587)  loss_n_40: 1.2306 (1.2474)  loss_n_60: 1.3050 (1.1893)  loss_n_80: 1.3265 (1.2556)  loss_n_100: 1.5411 (1.4593)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0072)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [310/845]  eta: 0:02:59  loss: 5.3647 (5.1558)  loss_n_40: 1.2592 (1.2473)  loss_n_60: 1.2591 (1.1883)  loss_n_80: 1.3187 (1.2544)  loss_n_100: 1.5234 (1.4588)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0070)  time: 0.3350  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:9]  [320/845]  eta: 0:02:56  loss: 5.2768 (5.1556)  loss_n_40: 1.2592 (1.2490)  loss_n_60: 1.1105 (1.1872)  loss_n_80: 1.2357 (1.2533)  loss_n_100: 1.4193 (1.4594)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0068)  time: 0.3351  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:9]  [330/845]  eta: 0:02:53  loss: 5.2840 (5.1581)  loss_n_40: 1.2242 (1.2470)  loss_n_60: 1.1105 (1.1875)  loss_n_80: 1.2701 (1.2543)  loss_n_100: 1.5500 (1.4626)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0066)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [340/845]  eta: 0:02:49  loss: 5.1105 (5.1605)  loss_n_40: 1.2009 (1.2457)  loss_n_60: 1.1240 (1.1881)  loss_n_80: 1.2445 (1.2551)  loss_n_100: 1.5951 (1.4652)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0064)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [350/845]  eta: 0:02:46  loss: 5.1105 (5.1677)  loss_n_40: 1.2274 (1.2478)  loss_n_60: 1.1465 (1.1904)  loss_n_80: 1.2380 (1.2567)  loss_n_100: 1.4448 (1.4666)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0062)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [360/845]  eta: 0:02:42  loss: 4.9842 (5.1659)  loss_n_40: 1.1654 (1.2492)  loss_n_60: 1.1458 (1.1909)  loss_n_80: 1.2278 (1.2558)  loss_n_100: 1.3909 (1.4640)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0060)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [370/845]  eta: 0:02:39  loss: 4.9394 (5.1695)  loss_n_40: 1.2141 (1.2504)  loss_n_60: 1.1195 (1.1916)  loss_n_80: 1.2610 (1.2567)  loss_n_100: 1.3597 (1.4649)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0058)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [380/845]  eta: 0:02:36  loss: 4.8980 (5.1615)  loss_n_40: 1.2141 (1.2478)  loss_n_60: 1.2203 (1.1905)  loss_n_80: 1.1982 (1.2547)  loss_n_100: 1.4024 (1.4628)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0057)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [390/845]  eta: 0:02:32  loss: 4.9535 (5.1636)  loss_n_40: 1.1642 (1.2509)  loss_n_60: 1.1696 (1.1917)  loss_n_80: 1.2057 (1.2546)  loss_n_100: 1.4206 (1.4608)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0055)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [400/845]  eta: 0:02:29  loss: 5.0918 (5.1760)  loss_n_40: 1.3160 (1.2537)  loss_n_60: 1.1985 (1.1940)  loss_n_80: 1.2719 (1.2564)  loss_n_100: 1.4206 (1.4595)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0024)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0100)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [410/845]  eta: 0:02:26  loss: 5.0646 (5.1760)  loss_n_40: 1.2934 (1.2566)  loss_n_60: 1.1985 (1.1927)  loss_n_80: 1.2343 (1.2561)  loss_n_100: 1.3610 (1.4586)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0023)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0097)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [420/845]  eta: 0:02:22  loss: 5.3612 (5.1857)  loss_n_40: 1.2745 (1.2596)  loss_n_60: 1.1228 (1.1949)  loss_n_80: 1.3054 (1.2588)  loss_n_100: 1.4754 (1.4606)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0023)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0095)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [430/845]  eta: 0:02:19  loss: 5.0830 (5.1756)  loss_n_40: 1.1879 (1.2571)  loss_n_60: 1.1228 (1.1917)  loss_n_80: 1.3054 (1.2575)  loss_n_100: 1.4754 (1.4579)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0022)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0093)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [440/845]  eta: 0:02:15  loss: 4.8251 (5.1819)  loss_n_40: 1.1796 (1.2588)  loss_n_60: 1.1184 (1.1940)  loss_n_80: 1.2332 (1.2596)  loss_n_100: 1.3962 (1.4583)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0022)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0091)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [450/845]  eta: 0:02:12  loss: 5.2872 (5.1862)  loss_n_40: 1.2467 (1.2599)  loss_n_60: 1.1989 (1.1948)  loss_n_80: 1.3129 (1.2606)  loss_n_100: 1.3780 (1.4599)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0021)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0089)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [460/845]  eta: 0:02:09  loss: 4.8358 (5.1793)  loss_n_40: 1.1677 (1.2570)  loss_n_60: 1.0863 (1.1929)  loss_n_80: 1.1860 (1.2589)  loss_n_100: 1.4007 (1.4599)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0021)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0087)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [470/845]  eta: 0:02:05  loss: 5.0524 (5.1848)  loss_n_40: 1.1677 (1.2595)  loss_n_60: 1.0863 (1.1952)  loss_n_80: 1.1860 (1.2601)  loss_n_100: 1.4007 (1.4594)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0020)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0085)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [480/845]  eta: 0:02:02  loss: 5.4243 (5.1925)  loss_n_40: 1.3348 (1.2653)  loss_n_60: 1.1509 (1.1972)  loss_n_80: 1.3538 (1.2612)  loss_n_100: 1.4308 (1.4585)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0020)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0083)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [490/845]  eta: 0:01:59  loss: 5.2571 (5.1974)  loss_n_40: 1.2999 (1.2649)  loss_n_60: 1.1417 (1.1983)  loss_n_80: 1.2759 (1.2603)  loss_n_100: 1.4308 (1.4583)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0073)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0081)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [500/845]  eta: 0:01:55  loss: 5.0072 (5.1954)  loss_n_40: 1.1818 (1.2640)  loss_n_60: 1.1865 (1.1989)  loss_n_80: 1.2252 (1.2605)  loss_n_100: 1.4339 (1.4569)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0072)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0080)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [510/845]  eta: 0:01:52  loss: 5.0560 (5.1957)  loss_n_40: 1.1893 (1.2634)  loss_n_60: 1.1986 (1.1991)  loss_n_80: 1.2428 (1.2610)  loss_n_100: 1.4381 (1.4574)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0070)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0078)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [520/845]  eta: 0:01:49  loss: 5.0435 (5.1908)  loss_n_40: 1.1893 (1.2620)  loss_n_60: 1.0931 (1.1976)  loss_n_80: 1.2252 (1.2597)  loss_n_100: 1.4211 (1.4569)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0069)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0077)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [530/845]  eta: 0:01:45  loss: 4.7526 (5.1865)  loss_n_40: 1.1469 (1.2617)  loss_n_60: 1.0079 (1.1961)  loss_n_80: 1.1992 (1.2579)  loss_n_100: 1.4197 (1.4565)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0068)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0075)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [540/845]  eta: 0:01:42  loss: 4.7526 (5.1830)  loss_n_40: 1.1502 (1.2607)  loss_n_60: 0.9909 (1.1941)  loss_n_80: 1.1386 (1.2572)  loss_n_100: 1.4277 (1.4570)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0066)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0074)  time: 0.3349  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:9]  [550/845]  eta: 0:01:38  loss: 4.8616 (5.1831)  loss_n_40: 1.1494 (1.2593)  loss_n_60: 1.0573 (1.1950)  loss_n_80: 1.1756 (1.2573)  loss_n_100: 1.5470 (1.4578)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0065)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0073)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [560/845]  eta: 0:01:35  loss: 5.2339 (5.1838)  loss_n_40: 1.2126 (1.2597)  loss_n_60: 1.1885 (1.1953)  loss_n_80: 1.3152 (1.2578)  loss_n_100: 1.5626 (1.4574)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0064)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0071)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [570/845]  eta: 0:01:32  loss: 5.2339 (5.1832)  loss_n_40: 1.2388 (1.2594)  loss_n_60: 1.1019 (1.1945)  loss_n_80: 1.2431 (1.2576)  loss_n_100: 1.4944 (1.4584)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0063)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0070)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [580/845]  eta: 0:01:28  loss: 5.2787 (5.1856)  loss_n_40: 1.1943 (1.2590)  loss_n_60: 1.1741 (1.1951)  loss_n_80: 1.2298 (1.2584)  loss_n_100: 1.5151 (1.4599)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0062)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0069)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [590/845]  eta: 0:01:25  loss: 5.3972 (5.1881)  loss_n_40: 1.2095 (1.2589)  loss_n_60: 1.2442 (1.1961)  loss_n_80: 1.3893 (1.2597)  loss_n_100: 1.5746 (1.4606)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0061)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0068)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [600/845]  eta: 0:01:22  loss: 5.3131 (5.1852)  loss_n_40: 1.1885 (1.2581)  loss_n_60: 1.1966 (1.1952)  loss_n_80: 1.3432 (1.2591)  loss_n_100: 1.4033 (1.4601)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0060)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0067)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [610/845]  eta: 0:01:18  loss: 5.1249 (5.1847)  loss_n_40: 1.1634 (1.2572)  loss_n_60: 1.0845 (1.1951)  loss_n_80: 1.3098 (1.2590)  loss_n_100: 1.4187 (1.4610)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0059)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0065)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [620/845]  eta: 0:01:15  loss: 4.6645 (5.1816)  loss_n_40: 1.1681 (1.2563)  loss_n_60: 1.0280 (1.1939)  loss_n_80: 1.2198 (1.2580)  loss_n_100: 1.4780 (1.4612)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0058)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0064)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [630/845]  eta: 0:01:12  loss: 4.6427 (5.1860)  loss_n_40: 1.1943 (1.2591)  loss_n_60: 0.9753 (1.1941)  loss_n_80: 1.1250 (1.2584)  loss_n_100: 1.4896 (1.4624)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0057)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0063)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [640/845]  eta: 0:01:08  loss: 5.1351 (5.1891)  loss_n_40: 1.2142 (1.2594)  loss_n_60: 1.1755 (1.1951)  loss_n_80: 1.2564 (1.2590)  loss_n_100: 1.5462 (1.4637)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0056)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0062)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [650/845]  eta: 0:01:05  loss: 5.0925 (5.1868)  loss_n_40: 1.2142 (1.2588)  loss_n_60: 1.1888 (1.1946)  loss_n_80: 1.2692 (1.2594)  loss_n_100: 1.4420 (1.4623)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0055)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0061)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [660/845]  eta: 0:01:02  loss: 5.0197 (5.1880)  loss_n_40: 1.2166 (1.2593)  loss_n_60: 1.1701 (1.1953)  loss_n_80: 1.2826 (1.2597)  loss_n_100: 1.3348 (1.4622)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0054)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0060)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [670/845]  eta: 0:00:58  loss: 5.5189 (5.1889)  loss_n_40: 1.1943 (1.2580)  loss_n_60: 1.2708 (1.1960)  loss_n_80: 1.2592 (1.2603)  loss_n_100: 1.5467 (1.4633)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0054)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0060)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [680/845]  eta: 0:00:55  loss: 5.1219 (5.1916)  loss_n_40: 1.2009 (1.2606)  loss_n_60: 1.2327 (1.1964)  loss_n_80: 1.2433 (1.2607)  loss_n_100: 1.4771 (1.4628)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0053)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0059)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [690/845]  eta: 0:00:51  loss: 5.2270 (5.1971)  loss_n_40: 1.2458 (1.2619)  loss_n_60: 1.1348 (1.1980)  loss_n_80: 1.3119 (1.2616)  loss_n_100: 1.5067 (1.4647)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0052)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0058)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [700/845]  eta: 0:00:48  loss: 5.2270 (5.1928)  loss_n_40: 1.1926 (1.2611)  loss_n_60: 1.1348 (1.1965)  loss_n_80: 1.2455 (1.2608)  loss_n_100: 1.5105 (1.4635)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0051)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0057)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [710/845]  eta: 0:00:45  loss: 4.9812 (5.1924)  loss_n_40: 1.1926 (1.2616)  loss_n_60: 1.0921 (1.1965)  loss_n_80: 1.2189 (1.2609)  loss_n_100: 1.4212 (1.4628)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0050)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0056)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [720/845]  eta: 0:00:41  loss: 4.8645 (5.1865)  loss_n_40: 1.1762 (1.2610)  loss_n_60: 1.0921 (1.1951)  loss_n_80: 1.2584 (1.2605)  loss_n_100: 1.2824 (1.4593)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0050)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0055)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [730/845]  eta: 0:00:38  loss: 4.8181 (5.1860)  loss_n_40: 1.2538 (1.2638)  loss_n_60: 1.1176 (1.1949)  loss_n_80: 1.2073 (1.2600)  loss_n_100: 1.1623 (1.4569)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0049)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0055)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [740/845]  eta: 0:00:35  loss: 4.7057 (5.1796)  loss_n_40: 1.2210 (1.2632)  loss_n_60: 1.0612 (1.1926)  loss_n_80: 1.1426 (1.2584)  loss_n_100: 1.2756 (1.4551)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0048)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0054)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [750/845]  eta: 0:00:31  loss: 5.0010 (5.1807)  loss_n_40: 1.1778 (1.2625)  loss_n_60: 1.1064 (1.1930)  loss_n_80: 1.2194 (1.2588)  loss_n_100: 1.3998 (1.4564)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0048)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0053)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [760/845]  eta: 0:00:28  loss: 5.0546 (5.1757)  loss_n_40: 1.1778 (1.2616)  loss_n_60: 1.1229 (1.1917)  loss_n_80: 1.2426 (1.2584)  loss_n_100: 1.4403 (1.4540)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0047)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0053)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [770/845]  eta: 0:00:25  loss: 4.4465 (5.1714)  loss_n_40: 1.1374 (1.2619)  loss_n_60: 0.9292 (1.1901)  loss_n_80: 1.1365 (1.2568)  loss_n_100: 1.3653 (1.4528)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0047)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0052)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [780/845]  eta: 0:00:21  loss: 4.9614 (5.1736)  loss_n_40: 1.2155 (1.2625)  loss_n_60: 1.1045 (1.1905)  loss_n_80: 1.1469 (1.2576)  loss_n_100: 1.3984 (1.4533)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0046)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0051)  time: 0.3353  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:9]  [790/845]  eta: 0:00:18  loss: 5.1798 (5.1734)  loss_n_40: 1.1915 (1.2617)  loss_n_60: 1.2327 (1.1911)  loss_n_80: 1.2912 (1.2578)  loss_n_100: 1.4108 (1.4532)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0045)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0051)  time: 0.3353  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:9]  [800/845]  eta: 0:00:15  loss: 4.9180 (5.1720)  loss_n_40: 1.1370 (1.2619)  loss_n_60: 1.1217 (1.1909)  loss_n_80: 1.2444 (1.2569)  loss_n_100: 1.4187 (1.4529)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0045)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0050)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [810/845]  eta: 0:00:11  loss: 4.8524 (5.1704)  loss_n_40: 1.1437 (1.2614)  loss_n_60: 1.0618 (1.1907)  loss_n_80: 1.2359 (1.2568)  loss_n_100: 1.4379 (1.4522)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0044)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0049)  time: 0.3348  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:9]  [820/845]  eta: 0:00:08  loss: 4.8556 (5.1680)  loss_n_40: 1.2033 (1.2609)  loss_n_60: 1.0402 (1.1896)  loss_n_80: 1.2187 (1.2562)  loss_n_100: 1.4421 (1.4521)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0044)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0049)  time: 0.3350  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:9]  [830/845]  eta: 0:00:05  loss: 4.8713 (5.1643)  loss_n_40: 1.1491 (1.2604)  loss_n_60: 1.0586 (1.1891)  loss_n_80: 1.1938 (1.2551)  loss_n_100: 1.3937 (1.4506)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0043)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0048)  time: 0.3351  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:9]  [840/845]  eta: 0:00:01  loss: 5.1510 (5.1808)  loss_n_40: 1.3161 (1.2630)  loss_n_60: 1.2121 (1.1909)  loss_n_80: 1.2582 (1.2560)  loss_n_100: 1.3787 (1.4517)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0072)  triple_60: 0.0000 (0.0018)  triple_40: 0.0000 (0.0048)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9]  [844/845]  eta: 0:00:00  loss: 5.1433 (5.1790)  loss_n_40: 1.3161 (1.2628)  loss_n_60: 1.1390 (1.1903)  loss_n_80: 1.1935 (1.2556)  loss_n_100: 1.3787 (1.4513)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0072)  triple_60: 0.0000 (0.0018)  triple_40: 0.0000 (0.0047)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:9] Total time: 0:04:43 (0.3355 s / it)\n",
      "Averaged stats: loss: 5.1433 (5.1790)  loss_n_40: 1.3161 (1.2628)  loss_n_60: 1.1390 (1.1903)  loss_n_80: 1.1935 (1.2556)  loss_n_100: 1.3787 (1.4513)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0072)  triple_60: 0.0000 (0.0018)  triple_40: 0.0000 (0.0047)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_9_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 1.451%\n",
      "Min loss_n_100: 0.691\n",
      "Best Epoch: 8.000\n",
      "Train: [epoch:10]  [   0/1724]  eta: 2:00:32  lr: 0.000180  loss: 5.3948 (5.3948)  loss_n_40: 1.2625 (1.2625)  loss_n_60: 1.2403 (1.2403)  loss_n_80: 1.3305 (1.3305)  loss_n_100: 1.5614 (1.5614)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1952  data: 0.4361  max mem: 46473\n",
      "Train: [epoch:10]  [  10/1724]  eta: 1:52:48  lr: 0.000180  loss: 4.7808 (4.7526)  loss_n_40: 1.1741 (1.1945)  loss_n_60: 1.0501 (1.0904)  loss_n_80: 1.1762 (1.1659)  loss_n_100: 1.2884 (1.3018)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9490  data: 0.0398  max mem: 46473\n",
      "Train: [epoch:10]  [  20/1724]  eta: 1:51:48  lr: 0.000180  loss: 4.5072 (4.5160)  loss_n_40: 1.1155 (1.1557)  loss_n_60: 1.0350 (1.0349)  loss_n_80: 1.0964 (1.0993)  loss_n_100: 1.1972 (1.2156)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [  30/1724]  eta: 1:51:02  lr: 0.000180  loss: 4.0213 (4.3253)  loss_n_40: 1.0574 (1.1191)  loss_n_60: 0.9531 (0.9958)  loss_n_80: 0.9507 (1.0474)  loss_n_100: 1.0663 (1.1559)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0071)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [  40/1724]  eta: 1:50:20  lr: 0.000180  loss: 3.7494 (4.1591)  loss_n_40: 0.9579 (1.0679)  loss_n_60: 0.8705 (0.9582)  loss_n_80: 0.9039 (1.0116)  loss_n_100: 0.9922 (1.1160)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0054)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [  50/1724]  eta: 1:49:38  lr: 0.000180  loss: 3.4148 (4.0650)  loss_n_40: 0.8910 (1.0385)  loss_n_60: 0.8040 (0.9326)  loss_n_80: 0.8598 (0.9891)  loss_n_100: 0.9710 (1.0891)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0104)  triple_60: 0.0000 (0.0017)  triple_40: 0.0000 (0.0035)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [  60/1724]  eta: 1:48:57  lr: 0.000180  loss: 3.5350 (3.9955)  loss_n_40: 0.9050 (1.0141)  loss_n_60: 0.8040 (0.9126)  loss_n_80: 0.8588 (0.9787)  loss_n_100: 0.9828 (1.0771)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0087)  triple_60: 0.0000 (0.0014)  triple_40: 0.0000 (0.0029)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [  70/1724]  eta: 1:48:17  lr: 0.000180  loss: 3.5350 (3.9263)  loss_n_40: 0.8951 (1.0003)  loss_n_60: 0.7774 (0.8950)  loss_n_80: 0.8727 (0.9645)  loss_n_100: 0.9626 (1.0553)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0075)  triple_60: 0.0000 (0.0012)  triple_40: 0.0000 (0.0025)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [  80/1724]  eta: 1:47:37  lr: 0.000180  loss: 3.3278 (3.8554)  loss_n_40: 0.8261 (0.9807)  loss_n_60: 0.7303 (0.8813)  loss_n_80: 0.8314 (0.9484)  loss_n_100: 0.8869 (1.0352)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0066)  triple_60: 0.0000 (0.0010)  triple_40: 0.0000 (0.0022)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [  90/1724]  eta: 1:46:57  lr: 0.000180  loss: 3.0535 (3.7550)  loss_n_40: 0.7198 (0.9511)  loss_n_60: 0.6968 (0.8585)  loss_n_80: 0.7617 (0.9250)  loss_n_100: 0.8338 (1.0111)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0065)  triple_60: 0.0000 (0.0009)  triple_40: 0.0000 (0.0020)  time: 3.9254  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 100/1724]  eta: 1:46:18  lr: 0.000180  loss: 2.9332 (3.6830)  loss_n_40: 0.7111 (0.9342)  loss_n_60: 0.6535 (0.8418)  loss_n_80: 0.7176 (0.9066)  loss_n_100: 0.7955 (0.9919)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0059)  triple_60: 0.0000 (0.0008)  triple_40: 0.0000 (0.0018)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 110/1724]  eta: 1:45:39  lr: 0.000180  loss: 2.7419 (3.6099)  loss_n_40: 0.6545 (0.9132)  loss_n_60: 0.6312 (0.8258)  loss_n_80: 0.7012 (0.8892)  loss_n_100: 0.7713 (0.9740)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0053)  triple_60: 0.0000 (0.0008)  triple_40: 0.0000 (0.0017)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 120/1724]  eta: 1:44:59  lr: 0.000180  loss: 2.7000 (3.5274)  loss_n_40: 0.6097 (0.8884)  loss_n_60: 0.6200 (0.8082)  loss_n_80: 0.6718 (0.8691)  loss_n_100: 0.7425 (0.9546)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0049)  triple_60: 0.0000 (0.0007)  triple_40: 0.0000 (0.0015)  time: 3.9273  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 130/1724]  eta: 1:44:20  lr: 0.000180  loss: 2.5942 (3.4689)  loss_n_40: 0.6229 (0.8700)  loss_n_60: 0.6183 (0.7952)  loss_n_80: 0.6290 (0.8553)  loss_n_100: 0.7316 (0.9404)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0045)  triple_60: 0.0000 (0.0006)  triple_40: 0.0000 (0.0027)  time: 3.9243  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 140/1724]  eta: 1:43:40  lr: 0.000180  loss: 2.8062 (3.4276)  loss_n_40: 0.6611 (0.8546)  loss_n_60: 0.6262 (0.7860)  loss_n_80: 0.6961 (0.8452)  loss_n_100: 0.7203 (0.9288)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0051)  triple_60: 0.0000 (0.0036)  triple_40: 0.0000 (0.0043)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 150/1724]  eta: 1:43:01  lr: 0.000180  loss: 3.5906 (3.5725)  loss_n_40: 0.7746 (0.8746)  loss_n_60: 0.7680 (0.8094)  loss_n_80: 0.9284 (0.8829)  loss_n_100: 1.0343 (0.9705)  triple_100: 0.0000 (0.0067)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0125)  triple_40: 0.0000 (0.0065)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 160/1724]  eta: 1:42:21  lr: 0.000180  loss: 5.7939 (3.7294)  loss_n_40: 1.1904 (0.8957)  loss_n_60: 1.2761 (0.8432)  loss_n_80: 1.5368 (0.9289)  loss_n_100: 1.6481 (1.0239)  triple_100: 0.0000 (0.0063)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0117)  triple_40: 0.0000 (0.0061)  time: 3.9261  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [ 170/1724]  eta: 1:41:42  lr: 0.000180  loss: 5.5294 (3.8132)  loss_n_40: 1.1273 (0.9065)  loss_n_60: 1.2750 (0.8610)  loss_n_80: 1.4434 (0.9527)  loss_n_100: 1.6106 (1.0517)  triple_100: 0.0000 (0.0118)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0057)  time: 3.9281  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 180/1724]  eta: 1:41:03  lr: 0.000180  loss: 4.8561 (3.8749)  loss_n_40: 1.0567 (0.9127)  loss_n_60: 1.1154 (0.8736)  loss_n_80: 1.2936 (0.9728)  loss_n_100: 1.4923 (1.0762)  triple_100: 0.0000 (0.0111)  triple_80: 0.0000 (0.0121)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0058)  time: 3.9298  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 190/1724]  eta: 1:40:24  lr: 0.000180  loss: 4.7176 (3.9137)  loss_n_40: 0.9788 (0.9157)  loss_n_60: 1.0487 (0.8817)  loss_n_80: 1.2827 (0.9863)  loss_n_100: 1.3989 (1.0912)  triple_100: 0.0000 (0.0105)  triple_80: 0.0000 (0.0115)  triple_60: 0.0000 (0.0099)  triple_40: 0.0000 (0.0069)  time: 3.9284  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 200/1724]  eta: 1:39:44  lr: 0.000180  loss: 4.5707 (3.9617)  loss_n_40: 0.9486 (0.9160)  loss_n_60: 1.0303 (0.8870)  loss_n_80: 1.2064 (0.9946)  loss_n_100: 1.3162 (1.0993)  triple_100: 0.0000 (0.0160)  triple_80: 0.0000 (0.0291)  triple_60: 0.0000 (0.0115)  triple_40: 0.0000 (0.0081)  time: 3.9261  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 210/1724]  eta: 1:39:05  lr: 0.000180  loss: 4.5707 (4.0083)  loss_n_40: 0.9386 (0.9179)  loss_n_60: 0.9984 (0.8947)  loss_n_80: 1.2099 (1.0062)  loss_n_100: 1.2921 (1.1122)  triple_100: 0.0000 (0.0153)  triple_80: 0.0000 (0.0435)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0077)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 220/1724]  eta: 1:38:25  lr: 0.000180  loss: 4.3296 (4.0162)  loss_n_40: 0.9386 (0.9159)  loss_n_60: 0.9984 (0.8980)  loss_n_80: 1.1430 (1.0109)  loss_n_100: 1.2494 (1.1175)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0415)  triple_60: 0.0000 (0.0105)  triple_40: 0.0000 (0.0073)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 230/1724]  eta: 1:37:46  lr: 0.000180  loss: 4.0967 (4.0241)  loss_n_40: 0.8286 (0.9119)  loss_n_60: 0.9409 (0.9025)  loss_n_80: 1.1122 (1.0171)  loss_n_100: 1.2065 (1.1220)  triple_100: 0.0000 (0.0140)  triple_80: 0.0000 (0.0397)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0070)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 240/1724]  eta: 1:37:07  lr: 0.000180  loss: 3.7986 (4.0178)  loss_n_40: 0.7684 (0.9043)  loss_n_60: 0.8592 (0.8991)  loss_n_80: 1.0328 (1.0159)  loss_n_100: 1.1126 (1.1190)  triple_100: 0.0000 (0.0134)  triple_80: 0.0000 (0.0443)  triple_60: 0.0000 (0.0139)  triple_40: 0.0000 (0.0078)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 250/1724]  eta: 1:36:27  lr: 0.000180  loss: 4.6462 (4.0648)  loss_n_40: 0.8094 (0.9062)  loss_n_60: 0.9299 (0.9099)  loss_n_80: 1.0638 (1.0329)  loss_n_100: 1.1502 (1.1392)  triple_100: 0.0000 (0.0132)  triple_80: 0.0000 (0.0425)  triple_60: 0.0000 (0.0134)  triple_40: 0.0000 (0.0075)  time: 3.9262  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 260/1724]  eta: 1:35:48  lr: 0.000180  loss: 4.9748 (4.1126)  loss_n_40: 0.8802 (0.9091)  loss_n_60: 1.1317 (0.9211)  loss_n_80: 1.3743 (1.0478)  loss_n_100: 1.6202 (1.1591)  triple_100: 0.0000 (0.0127)  triple_80: 0.0000 (0.0409)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0072)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 270/1724]  eta: 1:35:09  lr: 0.000180  loss: 4.5259 (4.1161)  loss_n_40: 0.7688 (0.9026)  loss_n_60: 1.0513 (0.9230)  loss_n_80: 1.2095 (1.0505)  loss_n_100: 1.4437 (1.1660)  triple_100: 0.0000 (0.0122)  triple_80: 0.0000 (0.0394)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0069)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 280/1724]  eta: 1:34:29  lr: 0.000180  loss: 3.8844 (4.0949)  loss_n_40: 0.7047 (0.8947)  loss_n_60: 0.8807 (0.9184)  loss_n_80: 1.0483 (1.0457)  loss_n_100: 1.2237 (1.1642)  triple_100: 0.0000 (0.0118)  triple_80: 0.0000 (0.0380)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0067)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 290/1724]  eta: 1:33:50  lr: 0.000180  loss: 3.3667 (4.1191)  loss_n_40: 0.6713 (0.8887)  loss_n_60: 0.7862 (0.9158)  loss_n_80: 0.8730 (1.0419)  loss_n_100: 1.0350 (1.1615)  triple_100: 0.0000 (0.0337)  triple_80: 0.0000 (0.0479)  triple_60: 0.0000 (0.0231)  triple_40: 0.0000 (0.0064)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 300/1724]  eta: 1:33:10  lr: 0.000180  loss: 7.2139 (4.3156)  loss_n_40: 0.9015 (0.9115)  loss_n_60: 1.0864 (0.9538)  loss_n_80: 1.1853 (1.0826)  loss_n_100: 1.4524 (1.2003)  triple_100: 0.0000 (0.0778)  triple_80: 0.0000 (0.0610)  triple_60: 0.0000 (0.0223)  triple_40: 0.0000 (0.0062)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 310/1724]  eta: 1:32:31  lr: 0.000180  loss: 10.9919 (4.6212)  loss_n_40: 2.0435 (0.9559)  loss_n_60: 2.4803 (1.0115)  loss_n_80: 2.5635 (1.1426)  loss_n_100: 2.6568 (1.2613)  triple_100: 0.0000 (0.0976)  triple_80: 0.0000 (0.0817)  triple_60: 0.0000 (0.0225)  triple_40: 0.0000 (0.0480)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 320/1724]  eta: 1:31:52  lr: 0.000180  loss: 11.5822 (4.8572)  loss_n_40: 2.3430 (0.9973)  loss_n_60: 2.7194 (1.0621)  loss_n_80: 2.9942 (1.2012)  loss_n_100: 3.0664 (1.3194)  triple_100: 0.0000 (0.1022)  triple_80: 0.0000 (0.1066)  triple_60: 0.0000 (0.0218)  triple_40: 0.0000 (0.0465)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 330/1724]  eta: 1:31:13  lr: 0.000180  loss: 10.7798 (5.0200)  loss_n_40: 2.2275 (1.0329)  loss_n_60: 2.6044 (1.1069)  loss_n_80: 2.9362 (1.2494)  loss_n_100: 2.9148 (1.3621)  triple_100: 0.0000 (0.0992)  triple_80: 0.0000 (0.1034)  triple_60: 0.0000 (0.0212)  triple_40: 0.0000 (0.0451)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 340/1724]  eta: 1:30:33  lr: 0.000180  loss: 10.2568 (5.1616)  loss_n_40: 2.1158 (1.0620)  loss_n_60: 2.5398 (1.1465)  loss_n_80: 2.8096 (1.2912)  loss_n_100: 2.7696 (1.4011)  triple_100: 0.0000 (0.0962)  triple_80: 0.0000 (0.1003)  triple_60: 0.0000 (0.0205)  triple_40: 0.0000 (0.0438)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 350/1724]  eta: 1:29:54  lr: 0.000180  loss: 9.6277 (5.2779)  loss_n_40: 1.9111 (1.0839)  loss_n_60: 2.3759 (1.1807)  loss_n_80: 2.5818 (1.3246)  loss_n_100: 2.6769 (1.4352)  triple_100: 0.0000 (0.0935)  triple_80: 0.0000 (0.0975)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0425)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 360/1724]  eta: 1:29:14  lr: 0.000180  loss: 9.3408 (5.3962)  loss_n_40: 1.8596 (1.1064)  loss_n_60: 2.4161 (1.2159)  loss_n_80: 2.4668 (1.3567)  loss_n_100: 2.7172 (1.4708)  triple_100: 0.0000 (0.0909)  triple_80: 0.0000 (0.0948)  triple_60: 0.0000 (0.0194)  triple_40: 0.0000 (0.0413)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 370/1724]  eta: 1:28:35  lr: 0.000180  loss: 9.1254 (5.4770)  loss_n_40: 1.7712 (1.1227)  loss_n_60: 2.3471 (1.2390)  loss_n_80: 2.4010 (1.3772)  loss_n_100: 2.6322 (1.4938)  triple_100: 0.0000 (0.0903)  triple_80: 0.0000 (0.0922)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0430)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 380/1724]  eta: 1:27:55  lr: 0.000180  loss: 8.4117 (5.5621)  loss_n_40: 1.7116 (1.1383)  loss_n_60: 2.1264 (1.2641)  loss_n_80: 2.2083 (1.4007)  loss_n_100: 2.4741 (1.5209)  triple_100: 0.0000 (0.0879)  triple_80: 0.0000 (0.0898)  triple_60: 0.0000 (0.0184)  triple_40: 0.0000 (0.0419)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 390/1724]  eta: 1:27:16  lr: 0.000180  loss: 8.4689 (5.6451)  loss_n_40: 1.6835 (1.1525)  loss_n_60: 2.1540 (1.2891)  loss_n_80: 2.2251 (1.4242)  loss_n_100: 2.4776 (1.5475)  triple_100: 0.0000 (0.0857)  triple_80: 0.0000 (0.0875)  triple_60: 0.0000 (0.0179)  triple_40: 0.0000 (0.0408)  time: 3.9229  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 400/1724]  eta: 1:26:37  lr: 0.000180  loss: 8.2862 (5.7051)  loss_n_40: 1.5843 (1.1625)  loss_n_60: 2.1163 (1.3073)  loss_n_80: 2.1486 (1.4409)  loss_n_100: 2.4303 (1.5672)  triple_100: 0.0000 (0.0835)  triple_80: 0.0000 (0.0865)  triple_60: 0.0000 (0.0175)  triple_40: 0.0000 (0.0398)  time: 3.9240  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [ 410/1724]  eta: 1:25:58  lr: 0.000180  loss: 7.8055 (5.7564)  loss_n_40: 1.4980 (1.1710)  loss_n_60: 1.9618 (1.3226)  loss_n_80: 2.1007 (1.4553)  loss_n_100: 2.3710 (1.5842)  triple_100: 0.0000 (0.0817)  triple_80: 0.0000 (0.0857)  triple_60: 0.0000 (0.0170)  triple_40: 0.0000 (0.0388)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 420/1724]  eta: 1:25:18  lr: 0.000180  loss: 7.6225 (5.7942)  loss_n_40: 1.3804 (1.1746)  loss_n_60: 1.8760 (1.3334)  loss_n_80: 2.0242 (1.4681)  loss_n_100: 2.3419 (1.6002)  triple_100: 0.0000 (0.0798)  triple_80: 0.0000 (0.0837)  triple_60: 0.0000 (0.0166)  triple_40: 0.0000 (0.0379)  time: 3.9243  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 430/1724]  eta: 1:24:39  lr: 0.000180  loss: 7.5075 (5.8366)  loss_n_40: 1.3602 (1.1782)  loss_n_60: 1.7903 (1.3434)  loss_n_80: 2.0242 (1.4810)  loss_n_100: 2.2820 (1.6164)  triple_100: 0.0000 (0.0789)  triple_80: 0.0000 (0.0852)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0370)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 440/1724]  eta: 1:24:00  lr: 0.000180  loss: 7.1127 (5.8587)  loss_n_40: 1.3192 (1.1804)  loss_n_60: 1.6511 (1.3488)  loss_n_80: 1.9602 (1.4898)  loss_n_100: 2.2226 (1.6272)  triple_100: 0.0000 (0.0772)  triple_80: 0.0000 (0.0833)  triple_60: 0.0000 (0.0159)  triple_40: 0.0000 (0.0362)  time: 3.9238  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 450/1724]  eta: 1:23:20  lr: 0.000180  loss: 6.4923 (5.8661)  loss_n_40: 1.2487 (1.1819)  loss_n_60: 1.5196 (1.3496)  loss_n_80: 1.7194 (1.4935)  loss_n_100: 1.9923 (1.6332)  triple_100: 0.0000 (0.0754)  triple_80: 0.0000 (0.0814)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0354)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 460/1724]  eta: 1:22:41  lr: 0.000180  loss: 6.3971 (5.8867)  loss_n_40: 1.2076 (1.1845)  loss_n_60: 1.4012 (1.3510)  loss_n_80: 1.6188 (1.4958)  loss_n_100: 1.8960 (1.6378)  triple_100: 0.0000 (0.0835)  triple_80: 0.0000 (0.0833)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0356)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 470/1724]  eta: 1:22:02  lr: 0.000180  loss: 6.1618 (5.8904)  loss_n_40: 1.1912 (1.1844)  loss_n_60: 1.3746 (1.3521)  loss_n_80: 1.6148 (1.4983)  loss_n_100: 1.8935 (1.6427)  triple_100: 0.0000 (0.0818)  triple_80: 0.0000 (0.0815)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0348)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 480/1724]  eta: 1:21:23  lr: 0.000180  loss: 5.8270 (5.8877)  loss_n_40: 1.1703 (1.1838)  loss_n_60: 1.3355 (1.3508)  loss_n_80: 1.5245 (1.4972)  loss_n_100: 1.8072 (1.6437)  triple_100: 0.0000 (0.0837)  triple_80: 0.0000 (0.0798)  triple_60: 0.0000 (0.0146)  triple_40: 0.0000 (0.0341)  time: 3.9253  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 490/1724]  eta: 1:20:43  lr: 0.000180  loss: 5.1167 (5.8657)  loss_n_40: 1.0310 (1.1796)  loss_n_60: 1.1802 (1.3463)  loss_n_80: 1.3098 (1.4919)  loss_n_100: 1.5125 (1.6401)  triple_100: 0.0000 (0.0820)  triple_80: 0.0000 (0.0782)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0334)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 500/1724]  eta: 1:20:04  lr: 0.000180  loss: 4.5756 (5.8398)  loss_n_40: 0.9774 (1.1747)  loss_n_60: 1.0857 (1.3408)  loss_n_80: 1.2023 (1.4854)  loss_n_100: 1.4167 (1.6346)  triple_100: 0.0000 (0.0809)  triple_80: 0.0000 (0.0766)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0327)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 510/1724]  eta: 1:19:25  lr: 0.000180  loss: 4.2275 (5.8056)  loss_n_40: 0.8463 (1.1691)  loss_n_60: 0.9984 (1.3340)  loss_n_80: 1.0853 (1.4765)  loss_n_100: 1.2560 (1.6258)  triple_100: 0.0000 (0.0794)  triple_80: 0.0000 (0.0751)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0321)  time: 3.9279  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 520/1724]  eta: 1:18:46  lr: 0.000180  loss: 4.1371 (5.7794)  loss_n_40: 0.8166 (1.1630)  loss_n_60: 0.9446 (1.3264)  loss_n_80: 1.0308 (1.4680)  loss_n_100: 1.1729 (1.6175)  triple_100: 0.0000 (0.0784)  triple_80: 0.0000 (0.0745)  triple_60: 0.0000 (0.0179)  triple_40: 0.0000 (0.0336)  time: 3.9294  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 530/1724]  eta: 1:18:07  lr: 0.000180  loss: 4.4341 (5.7621)  loss_n_40: 0.8565 (1.1588)  loss_n_60: 1.0212 (1.3222)  loss_n_80: 1.1580 (1.4636)  loss_n_100: 1.3223 (1.6137)  triple_100: 0.0000 (0.0770)  triple_80: 0.0000 (0.0732)  triple_60: 0.0000 (0.0175)  triple_40: 0.0000 (0.0362)  time: 3.9301  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 540/1724]  eta: 1:17:28  lr: 0.000180  loss: 4.3251 (5.7308)  loss_n_40: 0.8546 (1.1530)  loss_n_60: 1.0130 (1.3151)  loss_n_80: 1.1149 (1.4558)  loss_n_100: 1.3211 (1.6068)  triple_100: 0.0000 (0.0755)  triple_80: 0.0000 (0.0719)  triple_60: 0.0000 (0.0172)  triple_40: 0.0000 (0.0355)  time: 3.9297  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 550/1724]  eta: 1:16:48  lr: 0.000180  loss: 3.8665 (5.6951)  loss_n_40: 0.7960 (1.1474)  loss_n_60: 0.8891 (1.3066)  loss_n_80: 0.9866 (1.4456)  loss_n_100: 1.1725 (1.5969)  triple_100: 0.0000 (0.0763)  triple_80: 0.0000 (0.0706)  triple_60: 0.0000 (0.0169)  triple_40: 0.0000 (0.0349)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 560/1724]  eta: 1:16:09  lr: 0.000180  loss: 3.6251 (5.6588)  loss_n_40: 0.7971 (1.1435)  loss_n_60: 0.8397 (1.2987)  loss_n_80: 0.8996 (1.4359)  loss_n_100: 1.0158 (1.5856)  triple_100: 0.0000 (0.0750)  triple_80: 0.0000 (0.0693)  triple_60: 0.0000 (0.0166)  triple_40: 0.0000 (0.0342)  time: 3.9288  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 570/1724]  eta: 1:15:30  lr: 0.000180  loss: 3.4671 (5.6204)  loss_n_40: 0.8037 (1.1377)  loss_n_60: 0.8310 (1.2902)  loss_n_80: 0.8473 (1.4263)  loss_n_100: 0.9589 (1.5745)  triple_100: 0.0000 (0.0737)  triple_80: 0.0000 (0.0681)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0336)  time: 3.9289  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 580/1724]  eta: 1:14:51  lr: 0.000180  loss: 3.2969 (5.5769)  loss_n_40: 0.7574 (1.1307)  loss_n_60: 0.7698 (1.2804)  loss_n_80: 0.8415 (1.4153)  loss_n_100: 0.8921 (1.5621)  triple_100: 0.0000 (0.0724)  triple_80: 0.0000 (0.0670)  triple_60: 0.0000 (0.0160)  triple_40: 0.0000 (0.0331)  time: 3.9295  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 590/1724]  eta: 1:14:12  lr: 0.000180  loss: 3.0142 (5.5326)  loss_n_40: 0.6926 (1.1234)  loss_n_60: 0.6875 (1.2705)  loss_n_80: 0.7391 (1.4040)  loss_n_100: 0.8180 (1.5494)  triple_100: 0.0000 (0.0712)  triple_80: 0.0000 (0.0658)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0325)  time: 3.9313  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 600/1724]  eta: 1:13:32  lr: 0.000180  loss: 2.7927 (5.4869)  loss_n_40: 0.6280 (1.1153)  loss_n_60: 0.6486 (1.2602)  loss_n_80: 0.6981 (1.3926)  loss_n_100: 0.8069 (1.5367)  triple_100: 0.0000 (0.0700)  triple_80: 0.0000 (0.0647)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0320)  time: 3.9328  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 610/1724]  eta: 1:12:53  lr: 0.000180  loss: 2.9545 (5.4551)  loss_n_40: 0.6854 (1.1098)  loss_n_60: 0.7101 (1.2527)  loss_n_80: 0.7489 (1.3840)  loss_n_100: 0.8069 (1.5278)  triple_100: 0.0000 (0.0688)  triple_80: 0.0000 (0.0642)  triple_60: 0.0000 (0.0153)  triple_40: 0.0000 (0.0325)  time: 3.9322  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 620/1724]  eta: 1:12:14  lr: 0.000180  loss: 3.7770 (5.4311)  loss_n_40: 0.7597 (1.1061)  loss_n_60: 0.8827 (1.2476)  loss_n_80: 0.9598 (1.3779)  loss_n_100: 1.0873 (1.5213)  triple_100: 0.0000 (0.0677)  triple_80: 0.0000 (0.0631)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0320)  time: 3.9318  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 630/1724]  eta: 1:11:35  lr: 0.000180  loss: 3.5184 (5.3991)  loss_n_40: 0.7597 (1.1005)  loss_n_60: 0.8365 (1.2405)  loss_n_80: 0.9349 (1.3697)  loss_n_100: 1.0234 (1.5122)  triple_100: 0.0000 (0.0667)  triple_80: 0.0000 (0.0627)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0314)  time: 3.9341  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 640/1724]  eta: 1:10:56  lr: 0.000180  loss: 3.1188 (5.3610)  loss_n_40: 0.6806 (1.0937)  loss_n_60: 0.7405 (1.2321)  loss_n_80: 0.7881 (1.3599)  loss_n_100: 0.8698 (1.5018)  triple_100: 0.0000 (0.0656)  triple_80: 0.0000 (0.0617)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0310)  time: 3.9357  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [ 650/1724]  eta: 1:10:17  lr: 0.000180  loss: 2.8354 (5.3214)  loss_n_40: 0.6228 (1.0867)  loss_n_60: 0.6455 (1.2232)  loss_n_80: 0.7030 (1.3497)  loss_n_100: 0.8168 (1.4910)  triple_100: 0.0000 (0.0646)  triple_80: 0.0000 (0.0609)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0305)  time: 3.9344  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 660/1724]  eta: 1:09:38  lr: 0.000180  loss: 2.6593 (5.2862)  loss_n_40: 0.5993 (1.0812)  loss_n_60: 0.6195 (1.2152)  loss_n_80: 0.6762 (1.3400)  loss_n_100: 0.7587 (1.4801)  triple_100: 0.0000 (0.0636)  triple_80: 0.0000 (0.0613)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0300)  time: 3.9341  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 670/1724]  eta: 1:08:58  lr: 0.000180  loss: 2.8008 (5.2507)  loss_n_40: 0.5883 (1.0739)  loss_n_60: 0.6520 (1.2069)  loss_n_80: 0.6904 (1.3307)  loss_n_100: 0.7781 (1.4705)  triple_100: 0.0000 (0.0627)  triple_80: 0.0000 (0.0617)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0296)  time: 3.9335  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 680/1724]  eta: 1:08:19  lr: 0.000180  loss: 2.8008 (5.2187)  loss_n_40: 0.5556 (1.0673)  loss_n_60: 0.6520 (1.1991)  loss_n_80: 0.7237 (1.3220)  loss_n_100: 0.8566 (1.4613)  triple_100: 0.0000 (0.0618)  triple_80: 0.0000 (0.0622)  triple_60: 0.0000 (0.0159)  triple_40: 0.0000 (0.0291)  time: 3.9326  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 690/1724]  eta: 1:07:40  lr: 0.000180  loss: 2.9765 (5.1872)  loss_n_40: 0.6463 (1.0614)  loss_n_60: 0.6929 (1.1922)  loss_n_80: 0.7610 (1.3143)  loss_n_100: 0.8602 (1.4527)  triple_100: 0.0000 (0.0609)  triple_80: 0.0000 (0.0613)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0287)  time: 3.9324  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 700/1724]  eta: 1:07:01  lr: 0.000180  loss: 2.8497 (5.1519)  loss_n_40: 0.6353 (1.0548)  loss_n_60: 0.6877 (1.1842)  loss_n_80: 0.7366 (1.3053)  loss_n_100: 0.8344 (1.4433)  triple_100: 0.0000 (0.0601)  triple_80: 0.0000 (0.0605)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0283)  time: 3.9322  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 710/1724]  eta: 1:06:22  lr: 0.000180  loss: 2.5397 (5.1135)  loss_n_40: 0.5603 (1.0483)  loss_n_60: 0.5930 (1.1756)  loss_n_80: 0.6111 (1.2951)  loss_n_100: 0.7119 (1.4325)  triple_100: 0.0000 (0.0592)  triple_80: 0.0000 (0.0596)  triple_60: 0.0000 (0.0153)  triple_40: 0.0000 (0.0279)  time: 3.9314  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 720/1724]  eta: 1:05:42  lr: 0.000180  loss: 2.3109 (5.0748)  loss_n_40: 0.5435 (1.0416)  loss_n_60: 0.5424 (1.1670)  loss_n_80: 0.5699 (1.2849)  loss_n_100: 0.6490 (1.4216)  triple_100: 0.0000 (0.0584)  triple_80: 0.0000 (0.0588)  triple_60: 0.0000 (0.0150)  triple_40: 0.0000 (0.0275)  time: 3.9282  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 730/1724]  eta: 1:05:03  lr: 0.000180  loss: 2.1993 (5.0476)  loss_n_40: 0.5435 (1.0349)  loss_n_60: 0.5381 (1.1594)  loss_n_80: 0.5400 (1.2763)  loss_n_100: 0.6345 (1.4130)  triple_100: 0.0000 (0.0583)  triple_80: 0.0000 (0.0594)  triple_60: 0.0000 (0.0161)  triple_40: 0.0000 (0.0302)  time: 3.9255  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 740/1724]  eta: 1:04:24  lr: 0.000180  loss: 4.2186 (5.0426)  loss_n_40: 0.7088 (1.0321)  loss_n_60: 0.9660 (1.1585)  loss_n_80: 1.1476 (1.2763)  loss_n_100: 1.2230 (1.4129)  triple_100: 0.0000 (0.0575)  triple_80: 0.0000 (0.0596)  triple_60: 0.0000 (0.0159)  triple_40: 0.0000 (0.0298)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 750/1724]  eta: 1:03:45  lr: 0.000180  loss: 4.4124 (5.0304)  loss_n_40: 0.8223 (1.0301)  loss_n_60: 1.0322 (1.1562)  loss_n_80: 1.1856 (1.2738)  loss_n_100: 1.2429 (1.4097)  triple_100: 0.0000 (0.0568)  triple_80: 0.0000 (0.0588)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0294)  time: 3.9249  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 760/1724]  eta: 1:03:05  lr: 0.000180  loss: 3.8009 (5.0127)  loss_n_40: 0.7979 (1.0270)  loss_n_60: 0.9166 (1.1526)  loss_n_80: 0.9923 (1.2694)  loss_n_100: 1.1022 (1.4051)  triple_100: 0.0000 (0.0560)  triple_80: 0.0000 (0.0581)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0290)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 770/1724]  eta: 1:02:26  lr: 0.000180  loss: 3.3847 (4.9886)  loss_n_40: 0.6993 (1.0223)  loss_n_60: 0.7831 (1.1473)  loss_n_80: 0.8525 (1.2633)  loss_n_100: 0.9738 (1.3993)  triple_100: 0.0000 (0.0553)  triple_80: 0.0000 (0.0573)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0287)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 780/1724]  eta: 1:01:47  lr: 0.000180  loss: 3.3847 (4.9764)  loss_n_40: 0.7074 (1.0200)  loss_n_60: 0.7725 (1.1435)  loss_n_80: 0.8617 (1.2590)  loss_n_100: 0.9738 (1.3948)  triple_100: 0.0000 (0.0546)  triple_80: 0.0000 (0.0605)  triple_60: 0.0000 (0.0156)  triple_40: 0.0000 (0.0283)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 790/1724]  eta: 1:01:07  lr: 0.000180  loss: 3.9303 (4.9636)  loss_n_40: 0.8817 (1.0181)  loss_n_60: 0.8955 (1.1407)  loss_n_80: 0.9533 (1.2556)  loss_n_100: 1.1201 (1.3922)  triple_100: 0.0000 (0.0539)  triple_80: 0.0000 (0.0598)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0279)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 800/1724]  eta: 1:00:28  lr: 0.000180  loss: 3.5878 (4.9413)  loss_n_40: 0.7633 (1.0140)  loss_n_60: 0.8402 (1.1358)  loss_n_80: 0.8759 (1.2497)  loss_n_100: 1.0429 (1.3866)  triple_100: 0.0000 (0.0532)  triple_80: 0.0000 (0.0590)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0277)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 810/1724]  eta: 0:59:49  lr: 0.000180  loss: 3.3051 (4.9426)  loss_n_40: 0.7134 (1.0127)  loss_n_60: 0.7523 (1.1340)  loss_n_80: 0.8261 (1.2480)  loss_n_100: 1.0135 (1.3867)  triple_100: 0.0000 (0.0561)  triple_80: 0.0000 (0.0608)  triple_60: 0.0000 (0.0166)  triple_40: 0.0000 (0.0276)  time: 3.9242  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 820/1724]  eta: 0:59:09  lr: 0.000180  loss: 5.0135 (4.9476)  loss_n_40: 0.9754 (1.0133)  loss_n_60: 1.1617 (1.1354)  loss_n_80: 1.2714 (1.2503)  loss_n_100: 1.4083 (1.3886)  triple_100: 0.0000 (0.0555)  triple_80: 0.0000 (0.0601)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0276)  time: 3.9254  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 830/1724]  eta: 0:58:30  lr: 0.000180  loss: 5.1340 (4.9500)  loss_n_40: 1.0938 (1.0157)  loss_n_60: 1.2383 (1.1366)  loss_n_80: 1.3023 (1.2514)  loss_n_100: 1.3699 (1.3884)  triple_100: 0.0000 (0.0548)  triple_80: 0.0000 (0.0594)  triple_60: 0.0000 (0.0166)  triple_40: 0.0000 (0.0273)  time: 3.9250  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [ 840/1724]  eta: 0:57:51  lr: 0.000180  loss: 4.6529 (4.9448)  loss_n_40: 1.1288 (1.0165)  loss_n_60: 1.1650 (1.1366)  loss_n_80: 1.1912 (1.2504)  loss_n_100: 1.1868 (1.3852)  triple_100: 0.0000 (0.0541)  triple_80: 0.0000 (0.0586)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0269)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 850/1724]  eta: 0:57:12  lr: 0.000180  loss: 4.0653 (4.9288)  loss_n_40: 0.8789 (1.0143)  loss_n_60: 1.0275 (1.1334)  loss_n_80: 1.0815 (1.2469)  loss_n_100: 1.0577 (1.3798)  triple_100: 0.0000 (0.0535)  triple_80: 0.0000 (0.0580)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0266)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 860/1724]  eta: 0:56:32  lr: 0.000180  loss: 3.4766 (4.9107)  loss_n_40: 0.7958 (1.0123)  loss_n_60: 0.8237 (1.1296)  loss_n_80: 0.9193 (1.2428)  loss_n_100: 0.8390 (1.3735)  triple_100: 0.0000 (0.0529)  triple_80: 0.0000 (0.0573)  triple_60: 0.0000 (0.0160)  triple_40: 0.0000 (0.0263)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 870/1724]  eta: 0:55:53  lr: 0.000180  loss: 3.1241 (4.8885)  loss_n_40: 0.7223 (1.0087)  loss_n_60: 0.7528 (1.1247)  loss_n_80: 0.8706 (1.2377)  loss_n_100: 0.7874 (1.3667)  triple_100: 0.0000 (0.0523)  triple_80: 0.0000 (0.0566)  triple_60: 0.0000 (0.0159)  triple_40: 0.0000 (0.0260)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 880/1724]  eta: 0:55:14  lr: 0.000180  loss: 3.0229 (4.8682)  loss_n_40: 0.7102 (1.0066)  loss_n_60: 0.6950 (1.1207)  loss_n_80: 0.7529 (1.2325)  loss_n_100: 0.7142 (1.3593)  triple_100: 0.0000 (0.0517)  triple_80: 0.0000 (0.0560)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0257)  time: 3.9236  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [ 890/1724]  eta: 0:54:34  lr: 0.000180  loss: 2.7994 (4.8441)  loss_n_40: 0.6749 (1.0030)  loss_n_60: 0.6950 (1.1154)  loss_n_80: 0.7311 (1.2266)  loss_n_100: 0.6941 (1.3517)  triple_100: 0.0000 (0.0511)  triple_80: 0.0000 (0.0554)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0254)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 900/1724]  eta: 0:53:55  lr: 0.000180  loss: 2.4810 (4.8179)  loss_n_40: 0.5691 (0.9984)  loss_n_60: 0.5637 (1.1093)  loss_n_80: 0.6639 (1.2201)  loss_n_100: 0.6759 (1.3442)  triple_100: 0.0000 (0.0505)  triple_80: 0.0000 (0.0547)  triple_60: 0.0000 (0.0153)  triple_40: 0.0000 (0.0253)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 910/1724]  eta: 0:53:16  lr: 0.000180  loss: 2.5635 (4.7966)  loss_n_40: 0.5498 (0.9942)  loss_n_60: 0.5703 (1.1043)  loss_n_80: 0.6662 (1.2150)  loss_n_100: 0.7159 (1.3382)  triple_100: 0.0000 (0.0504)  triple_80: 0.0000 (0.0543)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0250)  time: 3.9271  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 920/1724]  eta: 0:52:37  lr: 0.000180  loss: 2.8338 (4.7765)  loss_n_40: 0.6548 (0.9910)  loss_n_60: 0.6771 (1.0999)  loss_n_80: 0.7514 (1.2101)  loss_n_100: 0.7969 (1.3322)  triple_100: 0.0000 (0.0499)  triple_80: 0.0000 (0.0537)  triple_60: 0.0000 (0.0150)  triple_40: 0.0000 (0.0247)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 930/1724]  eta: 0:51:57  lr: 0.000180  loss: 2.8099 (4.7537)  loss_n_40: 0.6613 (0.9874)  loss_n_60: 0.6706 (1.0951)  loss_n_80: 0.6939 (1.2043)  loss_n_100: 0.7043 (1.3251)  triple_100: 0.0000 (0.0494)  triple_80: 0.0000 (0.0531)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0245)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 940/1724]  eta: 0:51:18  lr: 0.000180  loss: 2.5901 (4.7374)  loss_n_40: 0.5709 (0.9834)  loss_n_60: 0.5961 (1.0900)  loss_n_80: 0.6733 (1.1991)  loss_n_100: 0.6726 (1.3188)  triple_100: 0.0000 (0.0504)  triple_80: 0.0000 (0.0542)  triple_60: 0.0000 (0.0173)  triple_40: 0.0000 (0.0242)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 950/1724]  eta: 0:50:39  lr: 0.000180  loss: 3.0395 (4.7216)  loss_n_40: 0.6166 (0.9802)  loss_n_60: 0.6669 (1.0865)  loss_n_80: 0.7582 (1.1956)  loss_n_100: 0.8232 (1.3148)  triple_100: 0.0000 (0.0499)  triple_80: 0.0000 (0.0536)  triple_60: 0.0000 (0.0171)  triple_40: 0.0000 (0.0240)  time: 3.9250  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 960/1724]  eta: 0:49:59  lr: 0.000180  loss: 3.1148 (4.7036)  loss_n_40: 0.6448 (0.9772)  loss_n_60: 0.7273 (1.0825)  loss_n_80: 0.8455 (1.1914)  loss_n_100: 0.8863 (1.3095)  triple_100: 0.0000 (0.0494)  triple_80: 0.0000 (0.0530)  triple_60: 0.0000 (0.0169)  triple_40: 0.0000 (0.0237)  time: 3.9254  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 970/1724]  eta: 0:49:20  lr: 0.000180  loss: 3.0243 (4.6863)  loss_n_40: 0.6727 (0.9748)  loss_n_60: 0.7036 (1.0787)  loss_n_80: 0.7939 (1.1872)  loss_n_100: 0.7747 (1.3039)  triple_100: 0.0000 (0.0489)  triple_80: 0.0000 (0.0525)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0236)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 980/1724]  eta: 0:48:41  lr: 0.000180  loss: 2.6330 (4.6634)  loss_n_40: 0.6008 (0.9702)  loss_n_60: 0.6085 (1.0733)  loss_n_80: 0.6844 (1.1813)  loss_n_100: 0.7304 (1.2976)  triple_100: 0.0000 (0.0487)  triple_80: 0.0000 (0.0522)  triple_60: 0.0000 (0.0166)  triple_40: 0.0000 (0.0234)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [ 990/1724]  eta: 0:48:02  lr: 0.000180  loss: 2.6027 (4.6465)  loss_n_40: 0.5779 (0.9676)  loss_n_60: 0.5813 (1.0694)  loss_n_80: 0.6783 (1.1772)  loss_n_100: 0.7434 (1.2927)  triple_100: 0.0000 (0.0482)  triple_80: 0.0000 (0.0517)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0231)  time: 3.9263  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1000/1724]  eta: 0:47:22  lr: 0.000180  loss: 2.6422 (4.6251)  loss_n_40: 0.6004 (0.9639)  loss_n_60: 0.5900 (1.0644)  loss_n_80: 0.7151 (1.1721)  loss_n_100: 0.7460 (1.2866)  triple_100: 0.0000 (0.0477)  triple_80: 0.0000 (0.0512)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0229)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1010/1724]  eta: 0:46:43  lr: 0.000180  loss: 2.3485 (4.6024)  loss_n_40: 0.5602 (0.9601)  loss_n_60: 0.5292 (1.0592)  loss_n_80: 0.6156 (1.1665)  loss_n_100: 0.6374 (1.2798)  triple_100: 0.0000 (0.0473)  triple_80: 0.0000 (0.0507)  triple_60: 0.0000 (0.0161)  triple_40: 0.0000 (0.0227)  time: 3.9268  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1020/1724]  eta: 0:46:04  lr: 0.000180  loss: 2.2876 (4.5793)  loss_n_40: 0.5198 (0.9556)  loss_n_60: 0.5084 (1.0538)  loss_n_80: 0.6085 (1.1609)  loss_n_100: 0.5951 (1.2734)  triple_100: 0.0000 (0.0468)  triple_80: 0.0000 (0.0503)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0225)  time: 3.9266  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1030/1724]  eta: 0:45:25  lr: 0.000180  loss: 2.2424 (4.5567)  loss_n_40: 0.5150 (0.9513)  loss_n_60: 0.5169 (1.0486)  loss_n_80: 0.5955 (1.1553)  loss_n_100: 0.6172 (1.2670)  triple_100: 0.0000 (0.0464)  triple_80: 0.0000 (0.0498)  triple_60: 0.0000 (0.0160)  triple_40: 0.0000 (0.0222)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1040/1724]  eta: 0:44:45  lr: 0.000180  loss: 2.1797 (4.5339)  loss_n_40: 0.4936 (0.9469)  loss_n_60: 0.5102 (1.0433)  loss_n_80: 0.5600 (1.1496)  loss_n_100: 0.5958 (1.2606)  triple_100: 0.0000 (0.0460)  triple_80: 0.0000 (0.0493)  triple_60: 0.0000 (0.0158)  triple_40: 0.0000 (0.0223)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1050/1724]  eta: 0:44:06  lr: 0.000180  loss: 2.2275 (4.5126)  loss_n_40: 0.5026 (0.9437)  loss_n_60: 0.5305 (1.0386)  loss_n_80: 0.5556 (1.1441)  loss_n_100: 0.5735 (1.2541)  triple_100: 0.0000 (0.0456)  triple_80: 0.0000 (0.0488)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0221)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1060/1724]  eta: 0:43:27  lr: 0.000180  loss: 2.1649 (4.4886)  loss_n_40: 0.4719 (0.9391)  loss_n_60: 0.5220 (1.0330)  loss_n_80: 0.5132 (1.1380)  loss_n_100: 0.5488 (1.2474)  triple_100: 0.0000 (0.0453)  triple_80: 0.0000 (0.0484)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0219)  time: 3.9251  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1070/1724]  eta: 0:42:47  lr: 0.000180  loss: 1.9079 (4.4666)  loss_n_40: 0.4070 (0.9353)  loss_n_60: 0.4381 (1.0280)  loss_n_80: 0.4956 (1.1324)  loss_n_100: 0.5527 (1.2411)  triple_100: 0.0000 (0.0448)  triple_80: 0.0000 (0.0479)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0217)  time: 3.9251  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1080/1724]  eta: 0:42:08  lr: 0.000180  loss: 1.9279 (4.4435)  loss_n_40: 0.4470 (0.9312)  loss_n_60: 0.4437 (1.0228)  loss_n_80: 0.4971 (1.1265)  loss_n_100: 0.5474 (1.2343)  triple_100: 0.0000 (0.0444)  triple_80: 0.0000 (0.0475)  triple_60: 0.0000 (0.0153)  triple_40: 0.0000 (0.0215)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1090/1724]  eta: 0:41:29  lr: 0.000180  loss: 1.7460 (4.4204)  loss_n_40: 0.3884 (0.9265)  loss_n_60: 0.3899 (1.0174)  loss_n_80: 0.4585 (1.1208)  loss_n_100: 0.4999 (1.2279)  triple_100: 0.0000 (0.0440)  triple_80: 0.0000 (0.0474)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0213)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1100/1724]  eta: 0:40:50  lr: 0.000180  loss: 1.8881 (4.4078)  loss_n_40: 0.4484 (0.9235)  loss_n_60: 0.4218 (1.0136)  loss_n_80: 0.5117 (1.1167)  loss_n_100: 0.5276 (1.2233)  triple_100: 0.0000 (0.0451)  triple_80: 0.0000 (0.0479)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0219)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1110/1724]  eta: 0:40:10  lr: 0.000180  loss: 3.5971 (4.4198)  loss_n_40: 0.7765 (0.9242)  loss_n_60: 0.8307 (1.0142)  loss_n_80: 0.9386 (1.1168)  loss_n_100: 0.9297 (1.2227)  triple_100: 0.0000 (0.0451)  triple_80: 0.0000 (0.0548)  triple_60: 0.0000 (0.0202)  triple_40: 0.0000 (0.0218)  time: 3.9257  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1120/1724]  eta: 0:39:31  lr: 0.000180  loss: 4.1784 (4.4194)  loss_n_40: 0.9712 (0.9244)  loss_n_60: 1.0089 (1.0138)  loss_n_80: 1.1069 (1.1166)  loss_n_100: 1.1287 (1.2218)  triple_100: 0.0000 (0.0451)  triple_80: 0.0000 (0.0561)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0216)  time: 3.9247  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [1130/1724]  eta: 0:38:52  lr: 0.000180  loss: 3.6948 (4.4110)  loss_n_40: 0.8774 (0.9234)  loss_n_60: 0.8580 (1.0121)  loss_n_80: 1.0012 (1.1147)  loss_n_100: 1.0201 (1.2193)  triple_100: 0.0000 (0.0447)  triple_80: 0.0000 (0.0556)  triple_60: 0.0000 (0.0198)  triple_40: 0.0000 (0.0214)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1140/1724]  eta: 0:38:13  lr: 0.000180  loss: 3.4653 (4.4018)  loss_n_40: 0.7623 (0.9222)  loss_n_60: 0.7966 (1.0101)  loss_n_80: 0.9140 (1.1125)  loss_n_100: 0.9051 (1.2167)  triple_100: 0.0000 (0.0443)  triple_80: 0.0000 (0.0551)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0212)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1150/1724]  eta: 0:37:33  lr: 0.000180  loss: 2.9194 (4.3885)  loss_n_40: 0.6324 (0.9196)  loss_n_60: 0.6829 (1.0070)  loss_n_80: 0.7813 (1.1093)  loss_n_100: 0.8440 (1.2134)  triple_100: 0.0000 (0.0439)  triple_80: 0.0000 (0.0546)  triple_60: 0.0000 (0.0195)  triple_40: 0.0000 (0.0210)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1160/1724]  eta: 0:36:54  lr: 0.000180  loss: 2.7812 (4.3731)  loss_n_40: 0.6101 (0.9168)  loss_n_60: 0.6514 (1.0036)  loss_n_80: 0.7169 (1.1056)  loss_n_100: 0.8017 (1.2092)  triple_100: 0.0000 (0.0436)  triple_80: 0.0000 (0.0542)  triple_60: 0.0000 (0.0193)  triple_40: 0.0000 (0.0208)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1170/1724]  eta: 0:36:15  lr: 0.000180  loss: 2.6038 (4.3579)  loss_n_40: 0.5805 (0.9145)  loss_n_60: 0.6209 (1.0003)  loss_n_80: 0.6704 (1.1018)  loss_n_100: 0.7034 (1.2047)  triple_100: 0.0000 (0.0432)  triple_80: 0.0000 (0.0537)  triple_60: 0.0000 (0.0192)  triple_40: 0.0000 (0.0207)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1180/1724]  eta: 0:35:35  lr: 0.000180  loss: 2.3211 (4.3398)  loss_n_40: 0.5227 (0.9108)  loss_n_60: 0.5144 (0.9960)  loss_n_80: 0.6029 (1.0972)  loss_n_100: 0.6239 (1.1997)  triple_100: 0.0000 (0.0428)  triple_80: 0.0000 (0.0537)  triple_60: 0.0000 (0.0190)  triple_40: 0.0000 (0.0205)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1190/1724]  eta: 0:34:56  lr: 0.000180  loss: 2.3119 (4.3289)  loss_n_40: 0.5125 (0.9085)  loss_n_60: 0.5367 (0.9932)  loss_n_80: 0.5943 (1.0939)  loss_n_100: 0.6499 (1.1961)  triple_100: 0.0000 (0.0432)  triple_80: 0.0000 (0.0542)  triple_60: 0.0000 (0.0193)  triple_40: 0.0000 (0.0206)  time: 3.9259  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1200/1724]  eta: 0:34:17  lr: 0.000180  loss: 2.8731 (4.3176)  loss_n_40: 0.6006 (0.9064)  loss_n_60: 0.6509 (0.9904)  loss_n_80: 0.7057 (1.0913)  loss_n_100: 0.7743 (1.1934)  triple_100: 0.0000 (0.0428)  triple_80: 0.0000 (0.0537)  triple_60: 0.0000 (0.0191)  triple_40: 0.0000 (0.0204)  time: 3.9265  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1210/1724]  eta: 0:33:38  lr: 0.000180  loss: 2.9330 (4.3074)  loss_n_40: 0.6006 (0.9038)  loss_n_60: 0.6512 (0.9876)  loss_n_80: 0.7483 (1.0886)  loss_n_100: 0.8430 (1.1907)  triple_100: 0.0000 (0.0442)  triple_80: 0.0000 (0.0533)  triple_60: 0.0000 (0.0190)  triple_40: 0.0000 (0.0202)  time: 3.9258  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1220/1724]  eta: 0:32:58  lr: 0.000180  loss: 3.0831 (4.3038)  loss_n_40: 0.6852 (0.9043)  loss_n_60: 0.6723 (0.9863)  loss_n_80: 0.8068 (1.0877)  loss_n_100: 0.8862 (1.1891)  triple_100: 0.0000 (0.0438)  triple_80: 0.0000 (0.0533)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0203)  time: 3.9256  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1230/1724]  eta: 0:32:19  lr: 0.000180  loss: 4.3034 (4.3092)  loss_n_40: 0.9295 (0.9050)  loss_n_60: 0.9328 (0.9870)  loss_n_80: 1.0862 (1.0893)  loss_n_100: 1.1537 (1.1905)  triple_100: 0.0000 (0.0440)  triple_80: 0.0000 (0.0529)  triple_60: 0.0000 (0.0194)  triple_40: 0.0000 (0.0212)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1240/1724]  eta: 0:31:40  lr: 0.000180  loss: 4.3736 (4.3079)  loss_n_40: 0.9295 (0.9046)  loss_n_60: 0.9875 (0.9868)  loss_n_80: 1.1745 (1.0892)  loss_n_100: 1.2158 (1.1908)  triple_100: 0.0000 (0.0438)  triple_80: 0.0000 (0.0525)  triple_60: 0.0000 (0.0193)  triple_40: 0.0000 (0.0210)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1250/1724]  eta: 0:31:01  lr: 0.000180  loss: 4.0074 (4.3073)  loss_n_40: 0.7950 (0.9038)  loss_n_60: 0.9282 (0.9864)  loss_n_80: 1.0384 (1.0892)  loss_n_100: 1.1481 (1.1910)  triple_100: 0.0000 (0.0444)  triple_80: 0.0000 (0.0521)  triple_60: 0.0000 (0.0192)  triple_40: 0.0000 (0.0213)  time: 3.9260  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1260/1724]  eta: 0:30:21  lr: 0.000180  loss: 3.7468 (4.3020)  loss_n_40: 0.7950 (0.9032)  loss_n_60: 0.9422 (0.9856)  loss_n_80: 0.9508 (1.0878)  loss_n_100: 1.0143 (1.1895)  triple_100: 0.0000 (0.0440)  triple_80: 0.0000 (0.0516)  triple_60: 0.0000 (0.0191)  triple_40: 0.0000 (0.0211)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1270/1724]  eta: 0:29:42  lr: 0.000180  loss: 3.5109 (4.2951)  loss_n_40: 0.7818 (0.9022)  loss_n_60: 0.8354 (0.9842)  loss_n_80: 0.9072 (1.0862)  loss_n_100: 0.9501 (1.1878)  triple_100: 0.0000 (0.0437)  triple_80: 0.0000 (0.0512)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0209)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1280/1724]  eta: 0:29:03  lr: 0.000180  loss: 3.1878 (4.2850)  loss_n_40: 0.6612 (0.9006)  loss_n_60: 0.7604 (0.9821)  loss_n_80: 0.7944 (1.0836)  loss_n_100: 0.9205 (1.1849)  triple_100: 0.0000 (0.0433)  triple_80: 0.0000 (0.0508)  triple_60: 0.0000 (0.0188)  triple_40: 0.0000 (0.0208)  time: 3.9246  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1290/1724]  eta: 0:28:24  lr: 0.000180  loss: 3.0593 (4.2748)  loss_n_40: 0.6442 (0.8988)  loss_n_60: 0.6811 (0.9798)  loss_n_80: 0.7247 (1.0809)  loss_n_100: 0.7716 (1.1820)  triple_100: 0.0000 (0.0435)  triple_80: 0.0000 (0.0506)  triple_60: 0.0000 (0.0186)  triple_40: 0.0000 (0.0206)  time: 3.9237  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1300/1724]  eta: 0:27:44  lr: 0.000180  loss: 3.1238 (4.2663)  loss_n_40: 0.6645 (0.8972)  loss_n_60: 0.7299 (0.9782)  loss_n_80: 0.7874 (1.0789)  loss_n_100: 0.8055 (1.1797)  triple_100: 0.0000 (0.0431)  triple_80: 0.0000 (0.0502)  triple_60: 0.0000 (0.0185)  triple_40: 0.0000 (0.0204)  time: 3.9251  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1310/1724]  eta: 0:27:05  lr: 0.000180  loss: 2.9924 (4.2564)  loss_n_40: 0.6564 (0.8955)  loss_n_60: 0.7086 (0.9762)  loss_n_80: 0.7772 (1.0765)  loss_n_100: 0.8248 (1.1770)  triple_100: 0.0000 (0.0428)  triple_80: 0.0000 (0.0499)  triple_60: 0.0000 (0.0183)  triple_40: 0.0000 (0.0203)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1320/1724]  eta: 0:26:26  lr: 0.000180  loss: 2.7136 (4.2436)  loss_n_40: 0.5814 (0.8932)  loss_n_60: 0.6577 (0.9735)  loss_n_80: 0.7144 (1.0733)  loss_n_100: 0.7508 (1.1734)  triple_100: 0.0000 (0.0425)  triple_80: 0.0000 (0.0495)  triple_60: 0.0000 (0.0182)  triple_40: 0.0000 (0.0201)  time: 3.9275  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1330/1724]  eta: 0:25:47  lr: 0.000180  loss: 2.4239 (4.2291)  loss_n_40: 0.5294 (0.8904)  loss_n_60: 0.5879 (0.9703)  loss_n_80: 0.6193 (1.0696)  loss_n_100: 0.6963 (1.1694)  triple_100: 0.0000 (0.0422)  triple_80: 0.0000 (0.0491)  triple_60: 0.0000 (0.0181)  triple_40: 0.0000 (0.0200)  time: 3.9272  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1340/1724]  eta: 0:25:07  lr: 0.000180  loss: 2.3248 (4.2161)  loss_n_40: 0.4768 (0.8876)  loss_n_60: 0.5713 (0.9674)  loss_n_80: 0.6044 (1.0663)  loss_n_100: 0.6608 (1.1658)  triple_100: 0.0000 (0.0423)  triple_80: 0.0000 (0.0488)  triple_60: 0.0000 (0.0181)  triple_40: 0.0000 (0.0198)  time: 3.9270  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1350/1724]  eta: 0:24:28  lr: 0.000180  loss: 2.3248 (4.2025)  loss_n_40: 0.5134 (0.8853)  loss_n_60: 0.5713 (0.9645)  loss_n_80: 0.5860 (1.0627)  loss_n_100: 0.6385 (1.1617)  triple_100: 0.0000 (0.0420)  triple_80: 0.0000 (0.0485)  triple_60: 0.0000 (0.0180)  triple_40: 0.0000 (0.0197)  time: 3.9267  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1360/1724]  eta: 0:23:49  lr: 0.000180  loss: 2.2424 (4.1889)  loss_n_40: 0.5256 (0.8829)  loss_n_60: 0.5456 (0.9615)  loss_n_80: 0.5734 (1.0592)  loss_n_100: 0.6074 (1.1578)  triple_100: 0.0000 (0.0419)  triple_80: 0.0000 (0.0481)  triple_60: 0.0000 (0.0179)  triple_40: 0.0000 (0.0195)  time: 3.9261  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [1370/1724]  eta: 0:23:09  lr: 0.000180  loss: 2.2308 (4.1751)  loss_n_40: 0.5138 (0.8806)  loss_n_60: 0.5428 (0.9585)  loss_n_80: 0.5789 (1.0557)  loss_n_100: 0.6146 (1.1538)  triple_100: 0.0000 (0.0416)  triple_80: 0.0000 (0.0478)  triple_60: 0.0000 (0.0177)  triple_40: 0.0000 (0.0194)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1380/1724]  eta: 0:22:30  lr: 0.000180  loss: 2.1738 (4.1627)  loss_n_40: 0.4920 (0.8783)  loss_n_60: 0.5170 (0.9556)  loss_n_80: 0.5585 (1.0521)  loss_n_100: 0.5929 (1.1498)  triple_100: 0.0000 (0.0419)  triple_80: 0.0000 (0.0479)  triple_60: 0.0000 (0.0179)  triple_40: 0.0000 (0.0193)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1390/1724]  eta: 0:21:51  lr: 0.000180  loss: 2.9355 (4.1614)  loss_n_40: 0.5326 (0.8769)  loss_n_60: 0.6581 (0.9550)  loss_n_80: 0.6446 (1.0518)  loss_n_100: 0.7013 (1.1495)  triple_100: 0.0000 (0.0428)  triple_80: 0.0000 (0.0485)  triple_60: 0.0000 (0.0178)  triple_40: 0.0000 (0.0191)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1400/1724]  eta: 0:21:12  lr: 0.000180  loss: 4.6831 (4.2289)  loss_n_40: 0.9030 (0.8781)  loss_n_60: 1.0890 (0.9573)  loss_n_80: 1.2714 (1.0551)  loss_n_100: 1.3819 (1.1538)  triple_100: 0.0000 (0.0756)  triple_80: 0.0000 (0.0676)  triple_60: 0.0000 (0.0224)  triple_40: 0.0000 (0.0190)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1410/1724]  eta: 0:20:32  lr: 0.000180  loss: 7.1239 (4.2692)  loss_n_40: 1.2857 (0.8822)  loss_n_60: 1.5537 (0.9624)  loss_n_80: 1.8556 (1.0615)  loss_n_100: 2.0516 (1.1612)  triple_100: 0.0000 (0.0842)  triple_80: 0.0000 (0.0756)  triple_60: 0.0000 (0.0234)  triple_40: 0.0000 (0.0188)  time: 3.9231  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1420/1724]  eta: 0:19:53  lr: 0.000180  loss: 7.9364 (4.3030)  loss_n_40: 1.5357 (0.8875)  loss_n_60: 1.6936 (0.9701)  loss_n_80: 2.0433 (1.0703)  loss_n_100: 2.2542 (1.1710)  triple_100: 0.0000 (0.0871)  triple_80: 0.0000 (0.0750)  triple_60: 0.0000 (0.0232)  triple_40: 0.0000 (0.0187)  time: 3.9238  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1430/1724]  eta: 0:19:14  lr: 0.000180  loss: 8.8168 (4.3340)  loss_n_40: 1.6437 (0.8930)  loss_n_60: 2.1675 (0.9787)  loss_n_80: 2.3989 (1.0796)  loss_n_100: 2.4719 (1.1800)  triple_100: 0.0000 (0.0865)  triple_80: 0.0000 (0.0745)  triple_60: 0.0000 (0.0230)  triple_40: 0.0000 (0.0186)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1440/1724]  eta: 0:18:35  lr: 0.000180  loss: 8.3901 (4.3596)  loss_n_40: 1.5634 (0.8975)  loss_n_60: 2.0772 (0.9856)  loss_n_80: 2.3290 (1.0873)  loss_n_100: 2.3977 (1.1881)  triple_100: 0.0000 (0.0859)  triple_80: 0.0000 (0.0740)  triple_60: 0.0000 (0.0229)  triple_40: 0.0000 (0.0185)  time: 3.9221  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1450/1724]  eta: 0:17:55  lr: 0.000180  loss: 7.7009 (4.3807)  loss_n_40: 1.4029 (0.9007)  loss_n_60: 1.8862 (0.9908)  loss_n_80: 2.1554 (1.0940)  loss_n_100: 2.3857 (1.1954)  triple_100: 0.0000 (0.0853)  triple_80: 0.0000 (0.0735)  triple_60: 0.0000 (0.0227)  triple_40: 0.0000 (0.0183)  time: 3.9229  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1460/1724]  eta: 0:17:16  lr: 0.000180  loss: 6.9081 (4.3966)  loss_n_40: 1.2368 (0.9023)  loss_n_60: 1.6145 (0.9944)  loss_n_80: 1.9624 (1.0998)  loss_n_100: 2.1746 (1.2016)  triple_100: 0.0000 (0.0847)  triple_80: 0.0000 (0.0730)  triple_60: 0.0000 (0.0226)  triple_40: 0.0000 (0.0182)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1470/1724]  eta: 0:16:37  lr: 0.000180  loss: 5.9661 (4.4048)  loss_n_40: 1.0690 (0.9034)  loss_n_60: 1.3309 (0.9962)  loss_n_80: 1.6457 (1.1030)  loss_n_100: 1.8581 (1.2052)  triple_100: 0.0000 (0.0841)  triple_80: 0.0000 (0.0725)  triple_60: 0.0000 (0.0224)  triple_40: 0.0000 (0.0181)  time: 3.9219  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1480/1724]  eta: 0:15:57  lr: 0.000180  loss: 4.9376 (4.4083)  loss_n_40: 1.0086 (0.9041)  loss_n_60: 1.1521 (0.9971)  loss_n_80: 1.3819 (1.1047)  loss_n_100: 1.4768 (1.2067)  triple_100: 0.0000 (0.0836)  triple_80: 0.0000 (0.0720)  triple_60: 0.0000 (0.0222)  triple_40: 0.0000 (0.0180)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1490/1724]  eta: 0:15:18  lr: 0.000180  loss: 4.6965 (4.4100)  loss_n_40: 0.9799 (0.9050)  loss_n_60: 1.1083 (0.9977)  loss_n_80: 1.2406 (1.1055)  loss_n_100: 1.3176 (1.2072)  triple_100: 0.0000 (0.0830)  triple_80: 0.0000 (0.0715)  triple_60: 0.0000 (0.0221)  triple_40: 0.0000 (0.0180)  time: 3.9219  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1500/1724]  eta: 0:14:39  lr: 0.000180  loss: 4.4231 (4.4076)  loss_n_40: 0.9696 (0.9051)  loss_n_60: 1.0307 (0.9975)  loss_n_80: 1.1747 (1.1052)  loss_n_100: 1.1679 (1.2065)  triple_100: 0.0000 (0.0824)  triple_80: 0.0000 (0.0710)  triple_60: 0.0000 (0.0220)  triple_40: 0.0000 (0.0178)  time: 3.9223  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1510/1724]  eta: 0:14:00  lr: 0.000180  loss: 3.9591 (4.4049)  loss_n_40: 0.8999 (0.9053)  loss_n_60: 0.9569 (0.9973)  loss_n_80: 1.0347 (1.1046)  loss_n_100: 1.0578 (1.2057)  triple_100: 0.0000 (0.0819)  triple_80: 0.0000 (0.0706)  triple_60: 0.0000 (0.0218)  triple_40: 0.0000 (0.0177)  time: 3.9221  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1520/1724]  eta: 0:13:20  lr: 0.000180  loss: 3.6144 (4.3991)  loss_n_40: 0.7866 (0.9045)  loss_n_60: 0.8931 (0.9964)  loss_n_80: 0.9406 (1.1034)  loss_n_100: 1.0218 (1.2041)  triple_100: 0.0000 (0.0814)  triple_80: 0.0000 (0.0701)  triple_60: 0.0000 (0.0217)  triple_40: 0.0000 (0.0176)  time: 3.9226  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1530/1724]  eta: 0:12:41  lr: 0.000180  loss: 3.4660 (4.3931)  loss_n_40: 0.7770 (0.9038)  loss_n_60: 0.8345 (0.9954)  loss_n_80: 0.9050 (1.1021)  loss_n_100: 0.9250 (1.2024)  triple_100: 0.0000 (0.0808)  triple_80: 0.0000 (0.0696)  triple_60: 0.0000 (0.0215)  triple_40: 0.0000 (0.0175)  time: 3.9234  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1540/1724]  eta: 0:12:02  lr: 0.000180  loss: 3.2423 (4.3858)  loss_n_40: 0.6995 (0.9030)  loss_n_60: 0.7995 (0.9941)  loss_n_80: 0.8353 (1.1004)  loss_n_100: 0.8619 (1.2002)  triple_100: 0.0000 (0.0803)  triple_80: 0.0000 (0.0692)  triple_60: 0.0000 (0.0214)  triple_40: 0.0000 (0.0174)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1550/1724]  eta: 0:11:23  lr: 0.000180  loss: 3.0249 (4.3772)  loss_n_40: 0.6905 (0.9019)  loss_n_60: 0.7275 (0.9924)  loss_n_80: 0.7817 (1.0982)  loss_n_100: 0.8196 (1.1977)  triple_100: 0.0000 (0.0798)  triple_80: 0.0000 (0.0687)  triple_60: 0.0000 (0.0212)  triple_40: 0.0000 (0.0173)  time: 3.9227  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1560/1724]  eta: 0:10:43  lr: 0.000180  loss: 2.9013 (4.3675)  loss_n_40: 0.6571 (0.9006)  loss_n_60: 0.6889 (0.9904)  loss_n_80: 0.7540 (1.0959)  loss_n_100: 0.7810 (1.1949)  triple_100: 0.0000 (0.0793)  triple_80: 0.0000 (0.0683)  triple_60: 0.0000 (0.0211)  triple_40: 0.0000 (0.0172)  time: 3.9217  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1570/1724]  eta: 0:10:04  lr: 0.000180  loss: 2.8714 (4.3573)  loss_n_40: 0.6598 (0.8993)  loss_n_60: 0.6385 (0.9882)  loss_n_80: 0.6997 (1.0933)  loss_n_100: 0.7384 (1.1918)  triple_100: 0.0000 (0.0788)  triple_80: 0.0000 (0.0679)  triple_60: 0.0000 (0.0210)  triple_40: 0.0000 (0.0171)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1580/1724]  eta: 0:09:25  lr: 0.000180  loss: 2.6831 (4.3464)  loss_n_40: 0.6264 (0.8975)  loss_n_60: 0.6357 (0.9860)  loss_n_80: 0.6933 (1.0907)  loss_n_100: 0.6920 (1.1887)  triple_100: 0.0000 (0.0783)  triple_80: 0.0000 (0.0674)  triple_60: 0.0000 (0.0208)  triple_40: 0.0000 (0.0169)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1590/1724]  eta: 0:08:46  lr: 0.000180  loss: 2.5537 (4.3355)  loss_n_40: 0.5879 (0.8960)  loss_n_60: 0.6308 (0.9838)  loss_n_80: 0.6619 (1.0878)  loss_n_100: 0.6671 (1.1854)  triple_100: 0.0000 (0.0778)  triple_80: 0.0000 (0.0670)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0169)  time: 3.9214  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1600/1724]  eta: 0:08:06  lr: 0.000180  loss: 2.5728 (4.3242)  loss_n_40: 0.5654 (0.8942)  loss_n_60: 0.6278 (0.9815)  loss_n_80: 0.6369 (1.0851)  loss_n_100: 0.6645 (1.1822)  triple_100: 0.0000 (0.0773)  triple_80: 0.0000 (0.0666)  triple_60: 0.0000 (0.0206)  triple_40: 0.0000 (0.0168)  time: 3.9220  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [1610/1724]  eta: 0:07:27  lr: 0.000180  loss: 2.3649 (4.3122)  loss_n_40: 0.5454 (0.8923)  loss_n_60: 0.5659 (0.9789)  loss_n_80: 0.6033 (1.0821)  loss_n_100: 0.6509 (1.1788)  triple_100: 0.0000 (0.0768)  triple_80: 0.0000 (0.0662)  triple_60: 0.0000 (0.0205)  triple_40: 0.0000 (0.0167)  time: 3.9222  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1620/1724]  eta: 0:06:48  lr: 0.000180  loss: 2.3040 (4.2995)  loss_n_40: 0.5109 (0.8904)  loss_n_60: 0.5455 (0.9762)  loss_n_80: 0.5702 (1.0789)  loss_n_100: 0.5866 (1.1750)  triple_100: 0.0000 (0.0763)  triple_80: 0.0000 (0.0658)  triple_60: 0.0000 (0.0203)  triple_40: 0.0000 (0.0166)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1630/1724]  eta: 0:06:09  lr: 0.000180  loss: 2.2154 (4.2890)  loss_n_40: 0.5298 (0.8886)  loss_n_60: 0.5376 (0.9739)  loss_n_80: 0.5602 (1.0761)  loss_n_100: 0.5805 (1.1718)  triple_100: 0.0000 (0.0759)  triple_80: 0.0000 (0.0654)  triple_60: 0.0000 (0.0202)  triple_40: 0.0000 (0.0171)  time: 3.9226  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1640/1724]  eta: 0:05:29  lr: 0.000180  loss: 3.0015 (4.2949)  loss_n_40: 0.6418 (0.8876)  loss_n_60: 0.6777 (0.9737)  loss_n_80: 0.7322 (1.0769)  loss_n_100: 0.7585 (1.1733)  triple_100: 0.0000 (0.0757)  triple_80: 0.0000 (0.0668)  triple_60: 0.0000 (0.0227)  triple_40: 0.0000 (0.0182)  time: 3.9228  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1650/1724]  eta: 0:04:50  lr: 0.000180  loss: 5.3499 (4.3008)  loss_n_40: 0.8490 (0.8880)  loss_n_60: 1.1015 (0.9751)  loss_n_80: 1.3988 (1.0792)  loss_n_100: 1.6306 (1.1763)  triple_100: 0.0000 (0.0752)  triple_80: 0.0000 (0.0664)  triple_60: 0.0000 (0.0226)  triple_40: 0.0000 (0.0181)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1660/1724]  eta: 0:04:11  lr: 0.000180  loss: 4.9435 (4.3012)  loss_n_40: 0.8490 (0.8874)  loss_n_60: 1.0593 (0.9751)  loss_n_80: 1.3138 (1.0798)  loss_n_100: 1.5346 (1.1777)  triple_100: 0.0000 (0.0748)  triple_80: 0.0000 (0.0660)  triple_60: 0.0000 (0.0224)  triple_40: 0.0000 (0.0180)  time: 3.9219  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1670/1724]  eta: 0:03:31  lr: 0.000180  loss: 4.0510 (4.2993)  loss_n_40: 0.7079 (0.8864)  loss_n_60: 0.8994 (0.9746)  loss_n_80: 1.0989 (1.0799)  loss_n_100: 1.3331 (1.1784)  triple_100: 0.0000 (0.0743)  triple_80: 0.0000 (0.0656)  triple_60: 0.0000 (0.0223)  triple_40: 0.0000 (0.0179)  time: 3.9221  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1680/1724]  eta: 0:02:52  lr: 0.000180  loss: 3.7000 (4.2939)  loss_n_40: 0.6512 (0.8851)  loss_n_60: 0.8182 (0.9734)  loss_n_80: 1.0170 (1.0789)  loss_n_100: 1.2101 (1.1775)  triple_100: 0.0000 (0.0739)  triple_80: 0.0000 (0.0652)  triple_60: 0.0000 (0.0222)  triple_40: 0.0000 (0.0178)  time: 3.9229  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1690/1724]  eta: 0:02:13  lr: 0.000180  loss: 3.2006 (4.2860)  loss_n_40: 0.6272 (0.8839)  loss_n_60: 0.7266 (0.9718)  loss_n_80: 0.8123 (1.0769)  loss_n_100: 0.8896 (1.1754)  triple_100: 0.0000 (0.0735)  triple_80: 0.0000 (0.0648)  triple_60: 0.0000 (0.0220)  triple_40: 0.0000 (0.0177)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1700/1724]  eta: 0:01:34  lr: 0.000180  loss: 2.7960 (4.2770)  loss_n_40: 0.5572 (0.8825)  loss_n_60: 0.6694 (0.9701)  loss_n_80: 0.7037 (1.0746)  loss_n_100: 0.7621 (1.1728)  triple_100: 0.0000 (0.0730)  triple_80: 0.0000 (0.0644)  triple_60: 0.0000 (0.0219)  triple_40: 0.0000 (0.0176)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:10]  [1710/1724]  eta: 0:00:54  lr: 0.000180  loss: 2.5899 (4.2678)  loss_n_40: 0.5951 (0.8817)  loss_n_60: 0.6338 (0.9682)  loss_n_80: 0.6363 (1.0722)  loss_n_100: 0.6832 (1.1698)  triple_100: 0.0000 (0.0726)  triple_80: 0.0000 (0.0641)  triple_60: 0.0000 (0.0218)  triple_40: 0.0000 (0.0175)  time: 3.9233  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1720/1724]  eta: 0:00:15  lr: 0.000180  loss: 2.4846 (4.2564)  loss_n_40: 0.5643 (0.8797)  loss_n_60: 0.5927 (0.9658)  loss_n_80: 0.6325 (1.0694)  loss_n_100: 0.6527 (1.1666)  triple_100: 0.0000 (0.0722)  triple_80: 0.0000 (0.0637)  triple_60: 0.0000 (0.0216)  triple_40: 0.0000 (0.0174)  time: 3.9230  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10]  [1723/1724]  eta: 0:00:03  lr: 0.000180  loss: 2.3662 (4.2525)  loss_n_40: 0.5197 (0.8789)  loss_n_60: 0.5453 (0.9649)  loss_n_80: 0.6182 (1.0684)  loss_n_100: 0.6164 (1.1656)  triple_100: 0.0000 (0.0721)  triple_80: 0.0000 (0.0636)  triple_60: 0.0000 (0.0216)  triple_40: 0.0000 (0.0174)  time: 3.9232  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:10] Total time: 1:52:48 (3.9258 s / it)\n",
      "Averaged stats: lr: 0.000180  loss: 2.3662 (4.2525)  loss_n_40: 0.5197 (0.8789)  loss_n_60: 0.5453 (0.9649)  loss_n_80: 0.6182 (1.0684)  loss_n_100: 0.6164 (1.1656)  triple_100: 0.0000 (0.0721)  triple_80: 0.0000 (0.0636)  triple_60: 0.0000 (0.0216)  triple_40: 0.0000 (0.0174)\n",
      "Valid: [epoch:10]  [  0/845]  eta: 0:09:43  loss: 2.2333 (2.2333)  loss_n_40: 0.3968 (0.3968)  loss_n_60: 0.5548 (0.5548)  loss_n_80: 0.6448 (0.6448)  loss_n_100: 0.6369 (0.6369)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.6906  data: 0.3528  max mem: 46473\n",
      "Valid: [epoch:10]  [ 10/845]  eta: 0:05:05  loss: 2.2301 (2.1442)  loss_n_40: 0.4685 (0.4768)  loss_n_60: 0.5033 (0.5038)  loss_n_80: 0.5928 (0.5557)  loss_n_100: 0.6205 (0.6079)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3664  data: 0.0322  max mem: 46473\n",
      "Valid: [epoch:10]  [ 20/845]  eta: 0:04:49  loss: 2.1627 (2.1396)  loss_n_40: 0.4381 (0.4820)  loss_n_60: 0.4693 (0.4988)  loss_n_80: 0.5770 (0.5525)  loss_n_100: 0.5705 (0.6063)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [ 30/845]  eta: 0:04:41  loss: 2.0405 (2.1562)  loss_n_40: 0.4381 (0.5121)  loss_n_60: 0.4500 (0.5011)  loss_n_80: 0.5231 (0.5502)  loss_n_100: 0.5524 (0.5875)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0053)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [ 40/845]  eta: 0:04:36  loss: 2.1563 (2.2006)  loss_n_40: 0.4923 (0.5301)  loss_n_60: 0.4795 (0.5116)  loss_n_80: 0.5670 (0.5598)  loss_n_100: 0.5576 (0.5900)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0091)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [ 50/845]  eta: 0:04:31  loss: 2.1000 (2.1514)  loss_n_40: 0.4791 (0.5131)  loss_n_60: 0.4598 (0.4993)  loss_n_80: 0.5670 (0.5514)  loss_n_100: 0.5386 (0.5802)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0073)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [ 60/845]  eta: 0:04:27  loss: 1.8726 (2.1282)  loss_n_40: 0.4139 (0.5020)  loss_n_60: 0.4373 (0.4984)  loss_n_80: 0.4823 (0.5452)  loss_n_100: 0.5386 (0.5764)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0061)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [ 70/845]  eta: 0:04:22  loss: 2.2718 (2.1785)  loss_n_40: 0.4752 (0.5199)  loss_n_60: 0.5375 (0.5093)  loss_n_80: 0.5300 (0.5553)  loss_n_100: 0.6404 (0.5888)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0053)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [ 80/845]  eta: 0:04:19  loss: 2.2718 (2.1719)  loss_n_40: 0.4752 (0.5263)  loss_n_60: 0.5295 (0.5107)  loss_n_80: 0.5300 (0.5496)  loss_n_100: 0.6256 (0.5807)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0046)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [ 90/845]  eta: 0:04:15  loss: 1.8704 (2.1753)  loss_n_40: 0.4088 (0.5350)  loss_n_60: 0.4249 (0.5132)  loss_n_80: 0.4668 (0.5462)  loss_n_100: 0.4902 (0.5768)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0041)  time: 0.3347  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:10]  [100/845]  eta: 0:04:11  loss: 1.9529 (2.1683)  loss_n_40: 0.4516 (0.5334)  loss_n_60: 0.4178 (0.5096)  loss_n_80: 0.5247 (0.5448)  loss_n_100: 0.5064 (0.5722)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0084)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [110/845]  eta: 0:04:08  loss: 2.0992 (2.1748)  loss_n_40: 0.4500 (0.5420)  loss_n_60: 0.4542 (0.5115)  loss_n_80: 0.5491 (0.5434)  loss_n_100: 0.5104 (0.5702)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0076)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [120/845]  eta: 0:04:04  loss: 1.9771 (2.1529)  loss_n_40: 0.4187 (0.5317)  loss_n_60: 0.4264 (0.5072)  loss_n_80: 0.5134 (0.5389)  loss_n_100: 0.5418 (0.5682)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0070)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [130/845]  eta: 0:04:01  loss: 1.5483 (2.1138)  loss_n_40: 0.3559 (0.5184)  loss_n_60: 0.3811 (0.4983)  loss_n_80: 0.4007 (0.5296)  loss_n_100: 0.4566 (0.5610)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0064)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [140/845]  eta: 0:03:57  loss: 1.6710 (2.1138)  loss_n_40: 0.3632 (0.5253)  loss_n_60: 0.3908 (0.4980)  loss_n_80: 0.4281 (0.5276)  loss_n_100: 0.4750 (0.5570)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0060)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [150/845]  eta: 0:03:54  loss: 1.9131 (2.1084)  loss_n_40: 0.4481 (0.5207)  loss_n_60: 0.4235 (0.4976)  loss_n_80: 0.5181 (0.5266)  loss_n_100: 0.5075 (0.5580)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0056)  time: 0.3352  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [160/845]  eta: 0:03:50  loss: 1.8416 (2.0967)  loss_n_40: 0.4342 (0.5142)  loss_n_60: 0.4207 (0.4958)  loss_n_80: 0.4948 (0.5243)  loss_n_100: 0.5299 (0.5572)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0052)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [170/845]  eta: 0:03:47  loss: 2.0292 (2.1562)  loss_n_40: 0.4344 (0.5252)  loss_n_60: 0.4416 (0.4989)  loss_n_80: 0.5523 (0.5289)  loss_n_100: 0.5320 (0.5583)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0450)  time: 0.3348  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [180/845]  eta: 0:03:43  loss: 2.1235 (2.1508)  loss_n_40: 0.4888 (0.5218)  loss_n_60: 0.4562 (0.4978)  loss_n_80: 0.5562 (0.5297)  loss_n_100: 0.5374 (0.5591)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0425)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [190/845]  eta: 0:03:40  loss: 1.9521 (2.1517)  loss_n_40: 0.4680 (0.5202)  loss_n_60: 0.4198 (0.4986)  loss_n_80: 0.5398 (0.5311)  loss_n_100: 0.5285 (0.5615)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0403)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [200/845]  eta: 0:03:36  loss: 2.1470 (2.1571)  loss_n_40: 0.4612 (0.5226)  loss_n_60: 0.4578 (0.4993)  loss_n_80: 0.5722 (0.5330)  loss_n_100: 0.5241 (0.5640)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0383)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [210/845]  eta: 0:03:33  loss: 2.1848 (2.1532)  loss_n_40: 0.4612 (0.5198)  loss_n_60: 0.5022 (0.4996)  loss_n_80: 0.5599 (0.5332)  loss_n_100: 0.5804 (0.5641)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0364)  time: 0.3347  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [220/845]  eta: 0:03:30  loss: 2.1143 (2.1742)  loss_n_40: 0.4433 (0.5323)  loss_n_60: 0.4710 (0.5049)  loss_n_80: 0.5597 (0.5370)  loss_n_100: 0.5646 (0.5651)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0348)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [230/845]  eta: 0:03:26  loss: 2.1143 (2.1928)  loss_n_40: 0.4892 (0.5381)  loss_n_60: 0.4559 (0.5065)  loss_n_80: 0.5597 (0.5378)  loss_n_100: 0.5538 (0.5648)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0456)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [240/845]  eta: 0:03:23  loss: 2.1694 (2.1880)  loss_n_40: 0.4624 (0.5352)  loss_n_60: 0.4973 (0.5055)  loss_n_80: 0.5617 (0.5382)  loss_n_100: 0.5911 (0.5653)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0437)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [250/845]  eta: 0:03:19  loss: 1.9305 (2.1984)  loss_n_40: 0.4322 (0.5338)  loss_n_60: 0.4528 (0.5048)  loss_n_80: 0.5559 (0.5392)  loss_n_100: 0.5714 (0.5669)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0537)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [260/845]  eta: 0:03:16  loss: 1.9305 (2.2041)  loss_n_40: 0.4509 (0.5364)  loss_n_60: 0.4541 (0.5065)  loss_n_80: 0.5559 (0.5410)  loss_n_100: 0.5476 (0.5685)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0516)  time: 0.3350  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [270/845]  eta: 0:03:13  loss: 2.0265 (2.2225)  loss_n_40: 0.4509 (0.5368)  loss_n_60: 0.4541 (0.5067)  loss_n_80: 0.5227 (0.5410)  loss_n_100: 0.5394 (0.5685)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0055)  triple_40: 0.0000 (0.0620)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [280/845]  eta: 0:03:09  loss: 1.8788 (2.2197)  loss_n_40: 0.4459 (0.5408)  loss_n_60: 0.4095 (0.5064)  loss_n_80: 0.4977 (0.5399)  loss_n_100: 0.4584 (0.5655)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0053)  triple_40: 0.0000 (0.0598)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [290/845]  eta: 0:03:06  loss: 2.2932 (2.2434)  loss_n_40: 0.5342 (0.5469)  loss_n_60: 0.5029 (0.5098)  loss_n_80: 0.5705 (0.5415)  loss_n_100: 0.5790 (0.5671)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0051)  triple_40: 0.0000 (0.0709)  time: 0.3348  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [300/845]  eta: 0:03:03  loss: 2.3749 (2.2395)  loss_n_40: 0.4933 (0.5442)  loss_n_60: 0.5091 (0.5097)  loss_n_80: 0.5705 (0.5418)  loss_n_100: 0.6178 (0.5683)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0049)  triple_40: 0.0000 (0.0686)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [310/845]  eta: 0:02:59  loss: 2.0959 (2.2423)  loss_n_40: 0.4521 (0.5431)  loss_n_60: 0.4740 (0.5102)  loss_n_80: 0.5667 (0.5428)  loss_n_100: 0.6103 (0.5701)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0048)  triple_40: 0.0000 (0.0695)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [320/845]  eta: 0:02:56  loss: 2.3861 (2.2478)  loss_n_40: 0.4543 (0.5424)  loss_n_60: 0.5625 (0.5110)  loss_n_80: 0.5919 (0.5442)  loss_n_100: 0.6366 (0.5716)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0046)  triple_40: 0.0000 (0.0722)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [330/845]  eta: 0:02:52  loss: 2.3036 (2.2432)  loss_n_40: 0.4766 (0.5429)  loss_n_60: 0.5328 (0.5107)  loss_n_80: 0.5727 (0.5432)  loss_n_100: 0.5168 (0.5702)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0700)  time: 0.3346  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [340/845]  eta: 0:02:49  loss: 2.0483 (2.2546)  loss_n_40: 0.4582 (0.5442)  loss_n_60: 0.4505 (0.5116)  loss_n_80: 0.5241 (0.5432)  loss_n_100: 0.4982 (0.5708)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0043)  triple_40: 0.0000 (0.0788)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:10]  [350/845]  eta: 0:02:46  loss: 2.0810 (2.2557)  loss_n_40: 0.4117 (0.5416)  loss_n_60: 0.4903 (0.5114)  loss_n_80: 0.5241 (0.5423)  loss_n_100: 0.5806 (0.5708)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0058)  triple_40: 0.0000 (0.0821)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [360/845]  eta: 0:02:42  loss: 1.9113 (2.2576)  loss_n_40: 0.4037 (0.5450)  loss_n_60: 0.4381 (0.5130)  loss_n_80: 0.5278 (0.5429)  loss_n_100: 0.5123 (0.5696)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0056)  triple_40: 0.0000 (0.0799)  time: 0.3351  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [370/845]  eta: 0:02:39  loss: 1.9113 (2.2480)  loss_n_40: 0.4106 (0.5412)  loss_n_60: 0.4029 (0.5110)  loss_n_80: 0.5315 (0.5421)  loss_n_100: 0.5123 (0.5689)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0055)  triple_40: 0.0000 (0.0777)  time: 0.3350  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [380/845]  eta: 0:02:36  loss: 1.9726 (2.2542)  loss_n_40: 0.4148 (0.5405)  loss_n_60: 0.4465 (0.5124)  loss_n_80: 0.5839 (0.5440)  loss_n_100: 0.5777 (0.5716)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0054)  triple_40: 0.0000 (0.0788)  time: 0.3350  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [390/845]  eta: 0:02:32  loss: 2.3262 (2.2516)  loss_n_40: 0.4790 (0.5388)  loss_n_60: 0.5342 (0.5123)  loss_n_80: 0.6189 (0.5446)  loss_n_100: 0.6492 (0.5724)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0052)  triple_40: 0.0000 (0.0768)  time: 0.3350  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [400/845]  eta: 0:02:29  loss: 2.2592 (2.2521)  loss_n_40: 0.4840 (0.5381)  loss_n_60: 0.4981 (0.5129)  loss_n_80: 0.6162 (0.5457)  loss_n_100: 0.6492 (0.5739)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0051)  triple_40: 0.0000 (0.0749)  time: 0.3352  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [410/845]  eta: 0:02:25  loss: 2.2493 (2.2464)  loss_n_40: 0.4952 (0.5365)  loss_n_60: 0.5108 (0.5119)  loss_n_80: 0.5994 (0.5451)  loss_n_100: 0.6418 (0.5735)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0050)  triple_40: 0.0000 (0.0731)  time: 0.3354  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [420/845]  eta: 0:02:22  loss: 2.1450 (2.2559)  loss_n_40: 0.4968 (0.5400)  loss_n_60: 0.5108 (0.5135)  loss_n_80: 0.5923 (0.5479)  loss_n_100: 0.6018 (0.5749)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0048)  triple_40: 0.0000 (0.0733)  time: 0.3350  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [430/845]  eta: 0:02:19  loss: 2.3100 (2.2602)  loss_n_40: 0.5170 (0.5408)  loss_n_60: 0.5494 (0.5156)  loss_n_80: 0.6479 (0.5497)  loss_n_100: 0.6181 (0.5764)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0047)  triple_40: 0.0000 (0.0716)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [440/845]  eta: 0:02:15  loss: 2.0485 (2.2527)  loss_n_40: 0.4808 (0.5387)  loss_n_60: 0.4753 (0.5140)  loss_n_80: 0.5618 (0.5487)  loss_n_100: 0.5703 (0.5753)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0046)  triple_40: 0.0000 (0.0700)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [450/845]  eta: 0:02:12  loss: 1.9106 (2.2577)  loss_n_40: 0.4808 (0.5422)  loss_n_60: 0.4467 (0.5153)  loss_n_80: 0.4920 (0.5492)  loss_n_100: 0.4952 (0.5753)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0698)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [460/845]  eta: 0:02:09  loss: 2.1140 (2.2502)  loss_n_40: 0.4391 (0.5399)  loss_n_60: 0.4556 (0.5140)  loss_n_80: 0.5678 (0.5479)  loss_n_100: 0.5300 (0.5744)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0683)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [470/845]  eta: 0:02:05  loss: 1.9661 (2.2485)  loss_n_40: 0.4300 (0.5397)  loss_n_60: 0.4366 (0.5144)  loss_n_80: 0.5611 (0.5477)  loss_n_100: 0.5300 (0.5743)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0043)  triple_40: 0.0000 (0.0669)  time: 0.3348  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [480/845]  eta: 0:02:02  loss: 1.8915 (2.2415)  loss_n_40: 0.4059 (0.5374)  loss_n_60: 0.4366 (0.5129)  loss_n_80: 0.5271 (0.5470)  loss_n_100: 0.5027 (0.5734)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0042)  triple_40: 0.0000 (0.0655)  time: 0.3352  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [490/845]  eta: 0:01:59  loss: 1.8915 (2.2397)  loss_n_40: 0.4435 (0.5361)  loss_n_60: 0.4488 (0.5132)  loss_n_80: 0.5271 (0.5470)  loss_n_100: 0.5351 (0.5739)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0042)  triple_40: 0.0000 (0.0641)  time: 0.3351  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [500/845]  eta: 0:01:55  loss: 1.8424 (2.2374)  loss_n_40: 0.4435 (0.5348)  loss_n_60: 0.4383 (0.5131)  loss_n_80: 0.4761 (0.5467)  loss_n_100: 0.5197 (0.5743)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0043)  triple_40: 0.0000 (0.0631)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [510/845]  eta: 0:01:52  loss: 1.8872 (2.2358)  loss_n_40: 0.4491 (0.5360)  loss_n_60: 0.4134 (0.5129)  loss_n_80: 0.4972 (0.5459)  loss_n_100: 0.5138 (0.5739)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0042)  triple_40: 0.0000 (0.0618)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [520/845]  eta: 0:01:49  loss: 1.6979 (2.2261)  loss_n_40: 0.3735 (0.5332)  loss_n_60: 0.4127 (0.5112)  loss_n_80: 0.4167 (0.5438)  loss_n_100: 0.4838 (0.5720)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0041)  triple_40: 0.0000 (0.0607)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [530/845]  eta: 0:01:45  loss: 1.6979 (2.2245)  loss_n_40: 0.3735 (0.5331)  loss_n_60: 0.4216 (0.5113)  loss_n_80: 0.4167 (0.5437)  loss_n_100: 0.4883 (0.5717)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0041)  triple_40: 0.0000 (0.0595)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [540/845]  eta: 0:01:42  loss: 1.7919 (2.2191)  loss_n_40: 0.4081 (0.5311)  loss_n_60: 0.4188 (0.5100)  loss_n_80: 0.4677 (0.5431)  loss_n_100: 0.5087 (0.5713)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0040)  triple_40: 0.0000 (0.0584)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [550/845]  eta: 0:01:38  loss: 1.9123 (2.2195)  loss_n_40: 0.4294 (0.5316)  loss_n_60: 0.4233 (0.5105)  loss_n_80: 0.5045 (0.5435)  loss_n_100: 0.5087 (0.5716)  triple_100: 0.0000 (0.0010)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0039)  triple_40: 0.0000 (0.0574)  time: 0.3350  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [560/845]  eta: 0:01:35  loss: 1.9096 (2.2166)  loss_n_40: 0.4294 (0.5317)  loss_n_60: 0.4481 (0.5098)  loss_n_80: 0.5092 (0.5428)  loss_n_100: 0.5392 (0.5711)  triple_100: 0.0000 (0.0010)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0038)  triple_40: 0.0000 (0.0563)  time: 0.3347  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [570/845]  eta: 0:01:32  loss: 1.9005 (2.2139)  loss_n_40: 0.3997 (0.5303)  loss_n_60: 0.4169 (0.5095)  loss_n_80: 0.5031 (0.5425)  loss_n_100: 0.5339 (0.5715)  triple_100: 0.0000 (0.0010)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0038)  triple_40: 0.0000 (0.0553)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [580/845]  eta: 0:01:28  loss: 2.1206 (2.2125)  loss_n_40: 0.4494 (0.5299)  loss_n_60: 0.5027 (0.5094)  loss_n_80: 0.5434 (0.5425)  loss_n_100: 0.5825 (0.5716)  triple_100: 0.0000 (0.0010)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0037)  triple_40: 0.0000 (0.0544)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [590/845]  eta: 0:01:25  loss: 2.1857 (2.2215)  loss_n_40: 0.5148 (0.5320)  loss_n_60: 0.5052 (0.5100)  loss_n_80: 0.5620 (0.5428)  loss_n_100: 0.5446 (0.5713)  triple_100: 0.0000 (0.0010)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0037)  triple_40: 0.0000 (0.0607)  time: 0.3346  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:10]  [600/845]  eta: 0:01:22  loss: 2.1118 (2.2192)  loss_n_40: 0.4412 (0.5307)  loss_n_60: 0.4728 (0.5094)  loss_n_80: 0.5611 (0.5429)  loss_n_100: 0.5851 (0.5719)  triple_100: 0.0000 (0.0010)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0036)  triple_40: 0.0000 (0.0597)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [610/845]  eta: 0:01:18  loss: 2.1107 (2.2209)  loss_n_40: 0.4412 (0.5308)  loss_n_60: 0.4883 (0.5100)  loss_n_80: 0.5679 (0.5438)  loss_n_100: 0.6145 (0.5732)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0035)  triple_40: 0.0000 (0.0587)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [620/845]  eta: 0:01:15  loss: 2.2183 (2.2206)  loss_n_40: 0.4998 (0.5302)  loss_n_60: 0.5257 (0.5105)  loss_n_80: 0.5737 (0.5438)  loss_n_100: 0.6229 (0.5736)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0035)  triple_40: 0.0000 (0.0580)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [630/845]  eta: 0:01:12  loss: 2.3104 (2.2207)  loss_n_40: 0.4631 (0.5298)  loss_n_60: 0.5722 (0.5111)  loss_n_80: 0.5473 (0.5439)  loss_n_100: 0.6372 (0.5744)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0571)  time: 0.3351  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [640/845]  eta: 0:01:08  loss: 2.2244 (2.2192)  loss_n_40: 0.4631 (0.5290)  loss_n_60: 0.5441 (0.5114)  loss_n_80: 0.5473 (0.5438)  loss_n_100: 0.6170 (0.5744)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0562)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [650/845]  eta: 0:01:05  loss: 2.2029 (2.2247)  loss_n_40: 0.4530 (0.5313)  loss_n_60: 0.4929 (0.5128)  loss_n_80: 0.5545 (0.5446)  loss_n_100: 0.5703 (0.5751)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0033)  triple_40: 0.0000 (0.0567)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [660/845]  eta: 0:01:02  loss: 2.2418 (2.2273)  loss_n_40: 0.4562 (0.5321)  loss_n_60: 0.5647 (0.5135)  loss_n_80: 0.5911 (0.5446)  loss_n_100: 0.5704 (0.5750)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0033)  triple_40: 0.0000 (0.0579)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [670/845]  eta: 0:00:58  loss: 2.4294 (2.2311)  loss_n_40: 0.4919 (0.5336)  loss_n_60: 0.5490 (0.5146)  loss_n_80: 0.5911 (0.5458)  loss_n_100: 0.5826 (0.5760)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0032)  triple_40: 0.0000 (0.0570)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [680/845]  eta: 0:00:55  loss: 2.0860 (2.2295)  loss_n_40: 0.4894 (0.5339)  loss_n_60: 0.4509 (0.5142)  loss_n_80: 0.5690 (0.5457)  loss_n_100: 0.5539 (0.5754)  triple_100: 0.0000 (0.0008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0032)  triple_40: 0.0000 (0.0562)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [690/845]  eta: 0:00:51  loss: 2.1120 (2.2279)  loss_n_40: 0.4603 (0.5328)  loss_n_60: 0.4650 (0.5142)  loss_n_80: 0.5667 (0.5458)  loss_n_100: 0.5539 (0.5758)  triple_100: 0.0000 (0.0008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0031)  triple_40: 0.0000 (0.0554)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [700/845]  eta: 0:00:48  loss: 2.1773 (2.2256)  loss_n_40: 0.4470 (0.5317)  loss_n_60: 0.5029 (0.5137)  loss_n_80: 0.5391 (0.5457)  loss_n_100: 0.5860 (0.5759)  triple_100: 0.0000 (0.0008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0031)  triple_40: 0.0000 (0.0546)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [710/845]  eta: 0:00:45  loss: 2.1164 (2.2378)  loss_n_40: 0.5052 (0.5333)  loss_n_60: 0.4744 (0.5142)  loss_n_80: 0.5517 (0.5461)  loss_n_100: 0.5470 (0.5757)  triple_100: 0.0000 (0.0008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0030)  triple_40: 0.0000 (0.0647)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [720/845]  eta: 0:00:41  loss: 2.1164 (2.2363)  loss_n_40: 0.4679 (0.5334)  loss_n_60: 0.4744 (0.5142)  loss_n_80: 0.5517 (0.5457)  loss_n_100: 0.5360 (0.5755)  triple_100: 0.0000 (0.0008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0030)  triple_40: 0.0000 (0.0638)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [730/845]  eta: 0:00:38  loss: 2.0345 (2.2359)  loss_n_40: 0.4649 (0.5329)  loss_n_60: 0.4839 (0.5143)  loss_n_80: 0.5408 (0.5462)  loss_n_100: 0.5613 (0.5759)  triple_100: 0.0000 (0.0008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0030)  triple_40: 0.0000 (0.0629)  time: 0.3351  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [740/845]  eta: 0:00:35  loss: 2.3017 (2.2396)  loss_n_40: 0.4662 (0.5326)  loss_n_60: 0.4989 (0.5142)  loss_n_80: 0.5681 (0.5458)  loss_n_100: 0.5930 (0.5757)  triple_100: 0.0000 (0.0008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0029)  triple_40: 0.0000 (0.0675)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [750/845]  eta: 0:00:31  loss: 1.9649 (2.2375)  loss_n_40: 0.3980 (0.5318)  loss_n_60: 0.4407 (0.5140)  loss_n_80: 0.5044 (0.5457)  loss_n_100: 0.5772 (0.5755)  triple_100: 0.0000 (0.0008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0029)  triple_40: 0.0000 (0.0668)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [760/845]  eta: 0:00:28  loss: 2.0491 (2.2375)  loss_n_40: 0.4349 (0.5319)  loss_n_60: 0.4478 (0.5143)  loss_n_80: 0.5554 (0.5461)  loss_n_100: 0.5993 (0.5758)  triple_100: 0.0000 (0.0008)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0659)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [770/845]  eta: 0:00:25  loss: 2.2602 (2.2416)  loss_n_40: 0.4733 (0.5327)  loss_n_60: 0.5230 (0.5151)  loss_n_80: 0.6038 (0.5469)  loss_n_100: 0.6253 (0.5766)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0668)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [780/845]  eta: 0:00:21  loss: 2.3128 (2.2448)  loss_n_40: 0.4966 (0.5336)  loss_n_60: 0.5099 (0.5154)  loss_n_80: 0.5901 (0.5470)  loss_n_100: 0.5912 (0.5765)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0688)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [790/845]  eta: 0:00:18  loss: 2.1651 (2.2446)  loss_n_40: 0.4966 (0.5351)  loss_n_60: 0.4874 (0.5159)  loss_n_80: 0.5310 (0.5465)  loss_n_100: 0.5088 (0.5756)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0680)  time: 0.3350  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [800/845]  eta: 0:00:15  loss: 2.2818 (2.2448)  loss_n_40: 0.4471 (0.5361)  loss_n_60: 0.5313 (0.5162)  loss_n_80: 0.4963 (0.5463)  loss_n_100: 0.4864 (0.5752)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0675)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [810/845]  eta: 0:00:11  loss: 1.8755 (2.2438)  loss_n_40: 0.4471 (0.5364)  loss_n_60: 0.4477 (0.5165)  loss_n_80: 0.4963 (0.5459)  loss_n_100: 0.5074 (0.5749)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0666)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:10]  [820/845]  eta: 0:00:08  loss: 1.8192 (2.2397)  loss_n_40: 0.3839 (0.5353)  loss_n_60: 0.3982 (0.5157)  loss_n_80: 0.4612 (0.5451)  loss_n_100: 0.5058 (0.5745)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0658)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [830/845]  eta: 0:00:05  loss: 1.8574 (2.2386)  loss_n_40: 0.3839 (0.5353)  loss_n_60: 0.3974 (0.5153)  loss_n_80: 0.4897 (0.5450)  loss_n_100: 0.4830 (0.5740)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0656)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10]  [840/845]  eta: 0:00:01  loss: 1.9532 (2.2394)  loss_n_40: 0.4208 (0.5352)  loss_n_60: 0.4267 (0.5155)  loss_n_80: 0.5811 (0.5454)  loss_n_100: 0.5488 (0.5746)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0655)  time: 0.3349  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:10]  [844/845]  eta: 0:00:00  loss: 2.3563 (2.2398)  loss_n_40: 0.4736 (0.5350)  loss_n_60: 0.5482 (0.5155)  loss_n_80: 0.6202 (0.5459)  loss_n_100: 0.5663 (0.5751)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0652)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:10] Total time: 0:04:43 (0.3354 s / it)\n",
      "Averaged stats: loss: 2.3563 (2.2398)  loss_n_40: 0.4736 (0.5350)  loss_n_60: 0.5482 (0.5155)  loss_n_80: 0.6202 (0.5459)  loss_n_100: 0.5663 (0.5751)  triple_100: 0.0000 (0.0007)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0652)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_10_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 0.575%\n",
      "Min loss_n_100: 0.575\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:11]  [   0/1724]  eta: 2:00:20  lr: 0.000200  loss: 2.2509 (2.2509)  loss_n_40: 0.5138 (0.5138)  loss_n_60: 0.5726 (0.5726)  loss_n_80: 0.5736 (0.5736)  loss_n_100: 0.5908 (0.5908)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1884  data: 0.4145  max mem: 46473\n",
      "Train: [epoch:11]  [  10/1724]  eta: 1:52:46  lr: 0.000200  loss: 2.1681 (2.1364)  loss_n_40: 0.5105 (0.5456)  loss_n_60: 0.5233 (0.5201)  loss_n_80: 0.5417 (0.5198)  loss_n_100: 0.5556 (0.5509)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9478  data: 0.0379  max mem: 46473\n",
      "Train: [epoch:11]  [  20/1724]  eta: 1:51:48  lr: 0.000200  loss: 2.3285 (2.4837)  loss_n_40: 0.5081 (0.5446)  loss_n_60: 0.5491 (0.5717)  loss_n_80: 0.5785 (0.6214)  loss_n_100: 0.6370 (0.6962)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0128)  triple_40: 0.0000 (0.0370)  time: 3.9242  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [  30/1724]  eta: 1:51:01  lr: 0.000200  loss: 2.7107 (2.5642)  loss_n_40: 0.5242 (0.5516)  loss_n_60: 0.6188 (0.5956)  loss_n_80: 0.7218 (0.6541)  loss_n_100: 0.8167 (0.7292)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0251)  time: 3.9244  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [  40/1724]  eta: 1:50:19  lr: 0.000200  loss: 2.5016 (2.4922)  loss_n_40: 0.5088 (0.5359)  loss_n_60: 0.5628 (0.5799)  loss_n_80: 0.6278 (0.6397)  loss_n_100: 0.7073 (0.7112)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0065)  triple_40: 0.0000 (0.0189)  time: 3.9240  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [  50/1724]  eta: 1:49:37  lr: 0.000200  loss: 2.2998 (2.4609)  loss_n_40: 0.5088 (0.5441)  loss_n_60: 0.5440 (0.5726)  loss_n_80: 0.5705 (0.6262)  loss_n_100: 0.6034 (0.6865)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0053)  triple_40: 0.0000 (0.0263)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [  60/1724]  eta: 1:48:56  lr: 0.000200  loss: 2.0684 (2.4150)  loss_n_40: 0.4753 (0.5315)  loss_n_60: 0.5123 (0.5595)  loss_n_80: 0.5271 (0.6097)  loss_n_100: 0.5473 (0.6671)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0406)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [  70/1724]  eta: 1:48:15  lr: 0.000200  loss: 1.9774 (2.3638)  loss_n_40: 0.4383 (0.5209)  loss_n_60: 0.4688 (0.5492)  loss_n_80: 0.5151 (0.5988)  loss_n_100: 0.5436 (0.6543)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0057)  triple_40: 0.0000 (0.0349)  time: 3.9231  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [  80/1724]  eta: 1:47:35  lr: 0.000200  loss: 2.0694 (2.3337)  loss_n_40: 0.4333 (0.5180)  loss_n_60: 0.4841 (0.5443)  loss_n_80: 0.5282 (0.5914)  loss_n_100: 0.5543 (0.6444)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0050)  triple_40: 0.0000 (0.0306)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [  90/1724]  eta: 1:46:54  lr: 0.000200  loss: 2.0411 (2.2914)  loss_n_40: 0.4450 (0.5108)  loss_n_60: 0.4797 (0.5347)  loss_n_80: 0.5194 (0.5814)  loss_n_100: 0.5424 (0.6328)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0272)  time: 3.9202  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 100/1724]  eta: 1:46:14  lr: 0.000200  loss: 1.9173 (2.2586)  loss_n_40: 0.4371 (0.5040)  loss_n_60: 0.4494 (0.5250)  loss_n_80: 0.4902 (0.5705)  loss_n_100: 0.5303 (0.6194)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0040)  triple_40: 0.0000 (0.0319)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 110/1724]  eta: 1:45:34  lr: 0.000200  loss: 1.9173 (2.2454)  loss_n_40: 0.4344 (0.4991)  loss_n_60: 0.4546 (0.5227)  loss_n_80: 0.4907 (0.5682)  loss_n_100: 0.5419 (0.6193)  triple_100: 0.0000 (0.0034)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0037)  triple_40: 0.0000 (0.0290)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 120/1724]  eta: 1:44:54  lr: 0.000200  loss: 2.1432 (2.2338)  loss_n_40: 0.4413 (0.4999)  loss_n_60: 0.5069 (0.5214)  loss_n_80: 0.5602 (0.5654)  loss_n_100: 0.5941 (0.6140)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0266)  time: 3.9207  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 130/1724]  eta: 1:44:15  lr: 0.000200  loss: 2.1432 (2.2180)  loss_n_40: 0.5061 (0.5004)  loss_n_60: 0.5088 (0.5187)  loss_n_80: 0.5149 (0.5609)  loss_n_100: 0.5322 (0.6074)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0031)  triple_40: 0.0000 (0.0246)  time: 3.9201  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 140/1724]  eta: 1:43:35  lr: 0.000200  loss: 1.9229 (2.2156)  loss_n_40: 0.4306 (0.4980)  loss_n_60: 0.4486 (0.5133)  loss_n_80: 0.4815 (0.5548)  loss_n_100: 0.5166 (0.5991)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0071)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0299)  time: 3.9199  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 150/1724]  eta: 1:42:55  lr: 0.000200  loss: 2.7705 (2.3086)  loss_n_40: 0.5117 (0.5056)  loss_n_60: 0.5910 (0.5261)  loss_n_80: 0.6210 (0.5770)  loss_n_100: 0.6216 (0.6245)  triple_100: 0.0000 (0.0144)  triple_80: 0.0000 (0.0112)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0340)  time: 3.9198  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 160/1724]  eta: 1:42:16  lr: 0.000200  loss: 3.4478 (2.3767)  loss_n_40: 0.6773 (0.5208)  loss_n_60: 0.7594 (0.5413)  loss_n_80: 0.8918 (0.5980)  loss_n_100: 0.9721 (0.6459)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0319)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 170/1724]  eta: 1:41:36  lr: 0.000200  loss: 3.3681 (2.4402)  loss_n_40: 0.7557 (0.5359)  loss_n_60: 0.7594 (0.5564)  loss_n_80: 0.8792 (0.6155)  loss_n_100: 0.9371 (0.6624)  triple_100: 0.0000 (0.0154)  triple_80: 0.0000 (0.0099)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0300)  time: 3.9212  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 180/1724]  eta: 1:40:57  lr: 0.000200  loss: 3.0681 (2.4701)  loss_n_40: 0.6153 (0.5416)  loss_n_60: 0.6867 (0.5627)  loss_n_80: 0.8204 (0.6259)  loss_n_100: 0.8566 (0.6738)  triple_100: 0.0000 (0.0145)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0139)  triple_40: 0.0000 (0.0284)  time: 3.9213  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 190/1724]  eta: 1:40:17  lr: 0.000200  loss: 2.6905 (2.4654)  loss_n_40: 0.5531 (0.5418)  loss_n_60: 0.6082 (0.5624)  loss_n_80: 0.7115 (0.6259)  loss_n_100: 0.7380 (0.6726)  triple_100: 0.0000 (0.0138)  triple_80: 0.0000 (0.0089)  triple_60: 0.0000 (0.0132)  triple_40: 0.0000 (0.0269)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 200/1724]  eta: 1:39:38  lr: 0.000200  loss: 2.2900 (2.4547)  loss_n_40: 0.5135 (0.5409)  loss_n_60: 0.5413 (0.5606)  loss_n_80: 0.6181 (0.6245)  loss_n_100: 0.6081 (0.6691)  triple_100: 0.0000 (0.0131)  triple_80: 0.0000 (0.0084)  triple_60: 0.0000 (0.0125)  triple_40: 0.0000 (0.0256)  time: 3.9198  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [ 210/1724]  eta: 1:38:58  lr: 0.000200  loss: 2.2994 (2.4494)  loss_n_40: 0.5249 (0.5407)  loss_n_60: 0.5573 (0.5602)  loss_n_80: 0.5998 (0.6238)  loss_n_100: 0.6100 (0.6677)  triple_100: 0.0000 (0.0125)  triple_80: 0.0000 (0.0080)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0246)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 220/1724]  eta: 1:38:19  lr: 0.000200  loss: 2.2389 (2.4305)  loss_n_40: 0.4745 (0.5373)  loss_n_60: 0.5186 (0.5568)  loss_n_80: 0.5791 (0.6195)  loss_n_100: 0.5903 (0.6625)  triple_100: 0.0000 (0.0119)  triple_80: 0.0000 (0.0077)  triple_60: 0.0000 (0.0114)  triple_40: 0.0000 (0.0235)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 230/1724]  eta: 1:37:40  lr: 0.000200  loss: 1.9902 (2.4174)  loss_n_40: 0.4446 (0.5354)  loss_n_60: 0.4797 (0.5544)  loss_n_80: 0.5251 (0.6168)  loss_n_100: 0.5636 (0.6587)  triple_100: 0.0000 (0.0114)  triple_80: 0.0000 (0.0073)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0225)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 240/1724]  eta: 1:37:00  lr: 0.000200  loss: 1.9634 (2.3953)  loss_n_40: 0.4270 (0.5316)  loss_n_60: 0.4578 (0.5496)  loss_n_80: 0.5229 (0.6115)  loss_n_100: 0.5439 (0.6527)  triple_100: 0.0000 (0.0109)  triple_80: 0.0000 (0.0070)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0215)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 250/1724]  eta: 1:36:21  lr: 0.000200  loss: 1.8360 (2.3775)  loss_n_40: 0.4048 (0.5281)  loss_n_60: 0.4437 (0.5466)  loss_n_80: 0.5001 (0.6072)  loss_n_100: 0.5062 (0.6476)  triple_100: 0.0000 (0.0105)  triple_80: 0.0000 (0.0067)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0207)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 260/1724]  eta: 1:35:42  lr: 0.000200  loss: 1.8293 (2.3586)  loss_n_40: 0.4413 (0.5260)  loss_n_60: 0.4363 (0.5422)  loss_n_80: 0.4750 (0.6023)  loss_n_100: 0.5037 (0.6421)  triple_100: 0.0000 (0.0101)  triple_80: 0.0000 (0.0065)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0199)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 270/1724]  eta: 1:35:02  lr: 0.000200  loss: 1.6733 (2.3266)  loss_n_40: 0.3783 (0.5191)  loss_n_60: 0.3882 (0.5351)  loss_n_80: 0.4112 (0.5943)  loss_n_100: 0.4491 (0.6337)  triple_100: 0.0000 (0.0097)  triple_80: 0.0000 (0.0062)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0191)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 280/1724]  eta: 1:34:23  lr: 0.000200  loss: 1.5360 (2.3130)  loss_n_40: 0.3472 (0.5147)  loss_n_60: 0.3593 (0.5315)  loss_n_80: 0.4026 (0.5904)  loss_n_100: 0.4519 (0.6301)  triple_100: 0.0000 (0.0115)  triple_80: 0.0000 (0.0061)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0198)  time: 3.9205  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 290/1724]  eta: 1:33:44  lr: 0.000200  loss: 2.1841 (2.3142)  loss_n_40: 0.4221 (0.5141)  loss_n_60: 0.5074 (0.5320)  loss_n_80: 0.5747 (0.5920)  loss_n_100: 0.5970 (0.6315)  triple_100: 0.0000 (0.0111)  triple_80: 0.0000 (0.0059)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0191)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 300/1724]  eta: 1:33:04  lr: 0.000200  loss: 2.3904 (2.3321)  loss_n_40: 0.4935 (0.5149)  loss_n_60: 0.5390 (0.5332)  loss_n_80: 0.6419 (0.5934)  loss_n_100: 0.6658 (0.6337)  triple_100: 0.0000 (0.0164)  triple_80: 0.0000 (0.0102)  triple_60: 0.0000 (0.0118)  triple_40: 0.0000 (0.0186)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 310/1724]  eta: 1:32:25  lr: 0.000200  loss: 2.4082 (2.3362)  loss_n_40: 0.5062 (0.5154)  loss_n_60: 0.5532 (0.5347)  loss_n_80: 0.6187 (0.5952)  loss_n_100: 0.6693 (0.6358)  triple_100: 0.0000 (0.0159)  triple_80: 0.0000 (0.0098)  triple_60: 0.0000 (0.0114)  triple_40: 0.0000 (0.0180)  time: 3.9215  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 320/1724]  eta: 1:31:46  lr: 0.000200  loss: 2.1924 (2.3312)  loss_n_40: 0.4898 (0.5150)  loss_n_60: 0.5260 (0.5336)  loss_n_80: 0.5867 (0.5934)  loss_n_100: 0.6137 (0.6334)  triple_100: 0.0000 (0.0154)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0198)  time: 3.9210  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 330/1724]  eta: 1:31:07  lr: 0.000200  loss: 2.1154 (2.3238)  loss_n_40: 0.4858 (0.5149)  loss_n_60: 0.4996 (0.5325)  loss_n_80: 0.5339 (0.5914)  loss_n_100: 0.5564 (0.6308)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0093)  triple_60: 0.0000 (0.0107)  triple_40: 0.0000 (0.0192)  time: 3.9217  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 340/1724]  eta: 1:30:28  lr: 0.000200  loss: 2.0627 (2.3137)  loss_n_40: 0.4978 (0.5143)  loss_n_60: 0.4729 (0.5310)  loss_n_80: 0.5019 (0.5887)  loss_n_100: 0.5244 (0.6272)  triple_100: 0.0000 (0.0145)  triple_80: 0.0000 (0.0090)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0186)  time: 3.9225  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 350/1724]  eta: 1:29:48  lr: 0.000200  loss: 1.9263 (2.3020)  loss_n_40: 0.4978 (0.5138)  loss_n_60: 0.4606 (0.5287)  loss_n_80: 0.4769 (0.5854)  loss_n_100: 0.4939 (0.6232)  triple_100: 0.0000 (0.0141)  triple_80: 0.0000 (0.0087)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0181)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 360/1724]  eta: 1:29:09  lr: 0.000200  loss: 1.8743 (2.2906)  loss_n_40: 0.4487 (0.5124)  loss_n_60: 0.4642 (0.5263)  loss_n_80: 0.4792 (0.5823)  loss_n_100: 0.4800 (0.6197)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0085)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0180)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 370/1724]  eta: 1:28:30  lr: 0.000200  loss: 1.8743 (2.2804)  loss_n_40: 0.4513 (0.5121)  loss_n_60: 0.4486 (0.5242)  loss_n_80: 0.4792 (0.5793)  loss_n_100: 0.4800 (0.6161)  triple_100: 0.0000 (0.0133)  triple_80: 0.0000 (0.0083)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0175)  time: 3.9220  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 380/1724]  eta: 1:27:51  lr: 0.000200  loss: 1.7867 (2.2676)  loss_n_40: 0.4320 (0.5106)  loss_n_60: 0.4232 (0.5215)  loss_n_80: 0.4388 (0.5754)  loss_n_100: 0.4611 (0.6119)  triple_100: 0.0000 (0.0130)  triple_80: 0.0000 (0.0080)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0179)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 390/1724]  eta: 1:27:12  lr: 0.000200  loss: 1.7050 (2.2528)  loss_n_40: 0.4014 (0.5079)  loss_n_60: 0.3940 (0.5182)  loss_n_80: 0.4196 (0.5716)  loss_n_100: 0.4611 (0.6081)  triple_100: 0.0000 (0.0127)  triple_80: 0.0000 (0.0078)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0175)  time: 3.9232  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 400/1724]  eta: 1:26:32  lr: 0.000200  loss: 1.7367 (2.2447)  loss_n_40: 0.4052 (0.5077)  loss_n_60: 0.4019 (0.5168)  loss_n_80: 0.4461 (0.5693)  loss_n_100: 0.4718 (0.6051)  triple_100: 0.0000 (0.0123)  triple_80: 0.0000 (0.0076)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0170)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 410/1724]  eta: 1:25:53  lr: 0.000200  loss: 1.7732 (2.2329)  loss_n_40: 0.4184 (0.5064)  loss_n_60: 0.4168 (0.5144)  loss_n_80: 0.4541 (0.5660)  loss_n_100: 0.4634 (0.6015)  triple_100: 0.0000 (0.0120)  triple_80: 0.0000 (0.0075)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0166)  time: 3.9229  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 420/1724]  eta: 1:25:14  lr: 0.000200  loss: 1.7295 (2.2263)  loss_n_40: 0.4204 (0.5073)  loss_n_60: 0.3997 (0.5128)  loss_n_80: 0.4407 (0.5634)  loss_n_100: 0.4518 (0.5982)  triple_100: 0.0000 (0.0118)  triple_80: 0.0000 (0.0073)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0171)  time: 3.9234  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 430/1724]  eta: 1:24:35  lr: 0.000200  loss: 1.8496 (2.2218)  loss_n_40: 0.4775 (0.5063)  loss_n_60: 0.4193 (0.5114)  loss_n_80: 0.4822 (0.5621)  loss_n_100: 0.4793 (0.5968)  triple_100: 0.0000 (0.0115)  triple_80: 0.0000 (0.0071)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0167)  time: 3.9236  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 440/1724]  eta: 1:23:56  lr: 0.000200  loss: 1.8262 (2.2118)  loss_n_40: 0.4136 (0.5040)  loss_n_60: 0.4278 (0.5092)  loss_n_80: 0.4611 (0.5598)  loss_n_100: 0.4986 (0.5946)  triple_100: 0.0000 (0.0112)  triple_80: 0.0000 (0.0069)  triple_60: 0.0000 (0.0097)  triple_40: 0.0000 (0.0163)  time: 3.9228  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [ 450/1724]  eta: 1:23:16  lr: 0.000200  loss: 1.6565 (2.2009)  loss_n_40: 0.3996 (0.5026)  loss_n_60: 0.3867 (0.5068)  loss_n_80: 0.4320 (0.5570)  loss_n_100: 0.4564 (0.5913)  triple_100: 0.0000 (0.0110)  triple_80: 0.0000 (0.0068)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0160)  time: 3.9218  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 460/1724]  eta: 1:22:37  lr: 0.000200  loss: 1.8015 (2.2044)  loss_n_40: 0.3962 (0.5008)  loss_n_60: 0.4130 (0.5059)  loss_n_80: 0.4703 (0.5568)  loss_n_100: 0.4935 (0.5917)  triple_100: 0.0000 (0.0165)  triple_80: 0.0000 (0.0074)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0160)  time: 3.9223  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 470/1724]  eta: 1:21:58  lr: 0.000200  loss: 2.0340 (2.2020)  loss_n_40: 0.4319 (0.5005)  loss_n_60: 0.4709 (0.5056)  loss_n_80: 0.5202 (0.5564)  loss_n_100: 0.5859 (0.5915)  triple_100: 0.0000 (0.0162)  triple_80: 0.0000 (0.0072)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0157)  time: 3.9222  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 480/1724]  eta: 1:21:19  lr: 0.000200  loss: 2.0236 (2.1975)  loss_n_40: 0.4329 (0.4993)  loss_n_60: 0.4709 (0.5047)  loss_n_80: 0.5238 (0.5557)  loss_n_100: 0.5687 (0.5907)  triple_100: 0.0000 (0.0158)  triple_80: 0.0000 (0.0071)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0153)  time: 3.9231  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 490/1724]  eta: 1:20:40  lr: 0.000200  loss: 1.9576 (2.1931)  loss_n_40: 0.4259 (0.4989)  loss_n_60: 0.4588 (0.5037)  loss_n_80: 0.5149 (0.5545)  loss_n_100: 0.5558 (0.5897)  triple_100: 0.0000 (0.0155)  triple_80: 0.0000 (0.0069)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0150)  time: 3.9241  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 500/1724]  eta: 1:20:00  lr: 0.000200  loss: 1.9187 (2.1896)  loss_n_40: 0.4577 (0.4992)  loss_n_60: 0.4427 (0.5031)  loss_n_80: 0.4860 (0.5530)  loss_n_100: 0.5182 (0.5880)  triple_100: 0.0000 (0.0152)  triple_80: 0.0000 (0.0068)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0157)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 510/1724]  eta: 1:19:21  lr: 0.000200  loss: 1.8961 (2.1826)  loss_n_40: 0.4446 (0.4976)  loss_n_60: 0.4331 (0.5014)  loss_n_80: 0.4788 (0.5516)  loss_n_100: 0.5097 (0.5867)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0066)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0154)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 520/1724]  eta: 1:18:42  lr: 0.000200  loss: 1.8174 (2.1753)  loss_n_40: 0.4108 (0.4966)  loss_n_60: 0.4093 (0.4996)  loss_n_80: 0.4769 (0.5500)  loss_n_100: 0.5073 (0.5847)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0065)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0151)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 530/1724]  eta: 1:18:03  lr: 0.000200  loss: 1.7376 (2.1652)  loss_n_40: 0.3843 (0.4943)  loss_n_60: 0.3801 (0.4971)  loss_n_80: 0.4537 (0.5479)  loss_n_100: 0.4644 (0.5822)  triple_100: 0.0000 (0.0144)  triple_80: 0.0000 (0.0064)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0148)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 540/1724]  eta: 1:17:23  lr: 0.000200  loss: 1.6096 (2.1566)  loss_n_40: 0.3860 (0.4936)  loss_n_60: 0.3636 (0.4951)  loss_n_80: 0.4160 (0.5455)  loss_n_100: 0.4378 (0.5796)  triple_100: 0.0000 (0.0141)  triple_80: 0.0000 (0.0063)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0146)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 550/1724]  eta: 1:16:44  lr: 0.000200  loss: 1.5810 (2.1473)  loss_n_40: 0.3870 (0.4921)  loss_n_60: 0.3607 (0.4927)  loss_n_80: 0.4052 (0.5428)  loss_n_100: 0.4278 (0.5767)  triple_100: 0.0000 (0.0138)  triple_80: 0.0000 (0.0062)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0151)  time: 3.9225  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 560/1724]  eta: 1:16:05  lr: 0.000200  loss: 2.1238 (2.1577)  loss_n_40: 0.4445 (0.4928)  loss_n_60: 0.4810 (0.4947)  loss_n_80: 0.4848 (0.5449)  loss_n_100: 0.4879 (0.5794)  triple_100: 0.0000 (0.0161)  triple_80: 0.0000 (0.0062)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0149)  time: 3.9221  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 570/1724]  eta: 1:15:26  lr: 0.000200  loss: 2.4801 (2.1628)  loss_n_40: 0.5005 (0.4938)  loss_n_60: 0.5961 (0.4959)  loss_n_80: 0.6164 (0.5466)  loss_n_100: 0.6803 (0.5814)  triple_100: 0.0000 (0.0158)  triple_80: 0.0000 (0.0061)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0146)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 580/1724]  eta: 1:14:47  lr: 0.000200  loss: 2.1762 (2.1617)  loss_n_40: 0.5087 (0.4938)  loss_n_60: 0.4955 (0.4956)  loss_n_80: 0.5631 (0.5462)  loss_n_100: 0.6025 (0.5813)  triple_100: 0.0000 (0.0156)  triple_80: 0.0000 (0.0060)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0147)  time: 3.9235  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 590/1724]  eta: 1:14:07  lr: 0.000200  loss: 1.9995 (2.1592)  loss_n_40: 0.4587 (0.4939)  loss_n_60: 0.4477 (0.4951)  loss_n_80: 0.5072 (0.5456)  loss_n_100: 0.5514 (0.5805)  triple_100: 0.0000 (0.0153)  triple_80: 0.0000 (0.0059)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0145)  time: 3.9234  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 600/1724]  eta: 1:13:28  lr: 0.000200  loss: 1.8684 (2.1546)  loss_n_40: 0.4525 (0.4935)  loss_n_60: 0.4274 (0.4943)  loss_n_80: 0.4919 (0.5445)  loss_n_100: 0.5132 (0.5792)  triple_100: 0.0000 (0.0150)  triple_80: 0.0000 (0.0058)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0142)  time: 3.9225  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 610/1724]  eta: 1:12:49  lr: 0.000200  loss: 1.8180 (2.1493)  loss_n_40: 0.4197 (0.4927)  loss_n_60: 0.4189 (0.4931)  loss_n_80: 0.4643 (0.5432)  loss_n_100: 0.4837 (0.5778)  triple_100: 0.0000 (0.0148)  triple_80: 0.0000 (0.0057)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0140)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 620/1724]  eta: 1:12:10  lr: 0.000200  loss: 1.7052 (2.1425)  loss_n_40: 0.4007 (0.4915)  loss_n_60: 0.4006 (0.4916)  loss_n_80: 0.4572 (0.5414)  loss_n_100: 0.4813 (0.5760)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0056)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0138)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 630/1724]  eta: 1:11:31  lr: 0.000200  loss: 1.6951 (2.1374)  loss_n_40: 0.4379 (0.4907)  loss_n_60: 0.3944 (0.4905)  loss_n_80: 0.4283 (0.5401)  loss_n_100: 0.4662 (0.5748)  triple_100: 0.0000 (0.0144)  triple_80: 0.0000 (0.0055)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0136)  time: 3.9211  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 640/1724]  eta: 1:10:51  lr: 0.000200  loss: 1.6729 (2.1309)  loss_n_40: 0.4065 (0.4892)  loss_n_60: 0.3944 (0.4890)  loss_n_80: 0.4218 (0.5385)  loss_n_100: 0.4571 (0.5734)  triple_100: 0.0000 (0.0141)  triple_80: 0.0000 (0.0054)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0134)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 650/1724]  eta: 1:10:12  lr: 0.000200  loss: 1.5937 (2.1224)  loss_n_40: 0.3745 (0.4875)  loss_n_60: 0.3695 (0.4872)  loss_n_80: 0.4109 (0.5365)  loss_n_100: 0.4507 (0.5712)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0053)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0131)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 660/1724]  eta: 1:09:33  lr: 0.000200  loss: 1.6107 (2.1191)  loss_n_40: 0.3827 (0.4862)  loss_n_60: 0.3695 (0.4858)  loss_n_80: 0.4016 (0.5351)  loss_n_100: 0.4405 (0.5700)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0053)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0146)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 670/1724]  eta: 1:08:54  lr: 0.000200  loss: 2.5339 (2.1585)  loss_n_40: 0.5558 (0.4924)  loss_n_60: 0.5262 (0.4914)  loss_n_80: 0.5854 (0.5418)  loss_n_100: 0.6514 (0.5769)  triple_100: 0.0000 (0.0246)  triple_80: 0.0000 (0.0080)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0151)  time: 3.9218  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 680/1724]  eta: 1:08:14  lr: 0.000200  loss: 4.1538 (2.1898)  loss_n_40: 0.8939 (0.4998)  loss_n_60: 0.8989 (0.4977)  loss_n_80: 1.0988 (0.5508)  loss_n_100: 1.1854 (0.5863)  triple_100: 0.0000 (0.0242)  triple_80: 0.0000 (0.0079)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0149)  time: 3.9212  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [ 690/1724]  eta: 1:07:35  lr: 0.000200  loss: 3.7846 (2.2061)  loss_n_40: 0.8268 (0.5033)  loss_n_60: 0.8216 (0.5012)  loss_n_80: 1.0105 (0.5556)  loss_n_100: 1.0782 (0.5915)  triple_100: 0.0000 (0.0239)  triple_80: 0.0000 (0.0078)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0146)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 700/1724]  eta: 1:06:56  lr: 0.000200  loss: 2.9988 (2.2100)  loss_n_40: 0.6111 (0.5041)  loss_n_60: 0.6448 (0.5023)  loss_n_80: 0.8255 (0.5571)  loss_n_100: 0.7293 (0.5929)  triple_100: 0.0000 (0.0235)  triple_80: 0.0000 (0.0076)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0144)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 710/1724]  eta: 1:06:17  lr: 0.000200  loss: 2.3688 (2.2115)  loss_n_40: 0.4903 (0.5045)  loss_n_60: 0.5200 (0.5027)  loss_n_80: 0.6394 (0.5576)  loss_n_100: 0.6597 (0.5934)  triple_100: 0.0000 (0.0232)  triple_80: 0.0000 (0.0075)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0146)  time: 3.9232  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 720/1724]  eta: 1:05:38  lr: 0.000200  loss: 2.2200 (2.2102)  loss_n_40: 0.4398 (0.5038)  loss_n_60: 0.4746 (0.5024)  loss_n_80: 0.5588 (0.5577)  loss_n_100: 0.6155 (0.5937)  triple_100: 0.0000 (0.0229)  triple_80: 0.0000 (0.0074)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0144)  time: 3.9243  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 730/1724]  eta: 1:04:58  lr: 0.000200  loss: 2.2200 (2.2157)  loss_n_40: 0.4606 (0.5043)  loss_n_60: 0.5090 (0.5028)  loss_n_80: 0.5588 (0.5584)  loss_n_100: 0.6122 (0.5946)  triple_100: 0.0000 (0.0233)  triple_80: 0.0000 (0.0091)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0143)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 740/1724]  eta: 1:04:19  lr: 0.000200  loss: 2.8411 (2.2308)  loss_n_40: 0.5418 (0.5048)  loss_n_60: 0.6337 (0.5057)  loss_n_80: 0.7530 (0.5634)  loss_n_100: 0.8033 (0.6019)  triple_100: 0.0000 (0.0230)  triple_80: 0.0000 (0.0090)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0141)  time: 3.9239  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 750/1724]  eta: 1:03:40  lr: 0.000200  loss: 3.1003 (2.2403)  loss_n_40: 0.5533 (0.5057)  loss_n_60: 0.6640 (0.5076)  loss_n_80: 0.8585 (0.5664)  loss_n_100: 1.0695 (0.6065)  triple_100: 0.0000 (0.0226)  triple_80: 0.0000 (0.0089)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0139)  time: 3.9248  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 760/1724]  eta: 1:03:01  lr: 0.000200  loss: 2.6108 (2.2435)  loss_n_40: 0.5185 (0.5066)  loss_n_60: 0.5665 (0.5082)  loss_n_80: 0.6905 (0.5673)  loss_n_100: 0.8261 (0.6080)  triple_100: 0.0000 (0.0224)  triple_80: 0.0000 (0.0088)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0138)  time: 3.9245  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 770/1724]  eta: 1:02:22  lr: 0.000200  loss: 2.0547 (2.2397)  loss_n_40: 0.4679 (0.5062)  loss_n_60: 0.4690 (0.5072)  loss_n_80: 0.5187 (0.5661)  loss_n_100: 0.6012 (0.6074)  triple_100: 0.0000 (0.0221)  triple_80: 0.0000 (0.0086)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0136)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 780/1724]  eta: 1:01:42  lr: 0.000200  loss: 1.8215 (2.2350)  loss_n_40: 0.4100 (0.5054)  loss_n_60: 0.4044 (0.5061)  loss_n_80: 0.4574 (0.5648)  loss_n_100: 0.5346 (0.6065)  triple_100: 0.0000 (0.0218)  triple_80: 0.0000 (0.0085)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0134)  time: 3.9244  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 790/1724]  eta: 1:01:03  lr: 0.000200  loss: 1.6766 (2.2288)  loss_n_40: 0.3870 (0.5046)  loss_n_60: 0.3680 (0.5048)  loss_n_80: 0.4203 (0.5631)  loss_n_100: 0.4990 (0.6049)  triple_100: 0.0000 (0.0215)  triple_80: 0.0000 (0.0084)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0132)  time: 3.9243  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 800/1724]  eta: 1:00:24  lr: 0.000200  loss: 1.5954 (2.2234)  loss_n_40: 0.3805 (0.5034)  loss_n_60: 0.3680 (0.5034)  loss_n_80: 0.3966 (0.5617)  loss_n_100: 0.4774 (0.6039)  triple_100: 0.0000 (0.0212)  triple_80: 0.0000 (0.0083)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0132)  time: 3.9237  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 810/1724]  eta: 0:59:45  lr: 0.000200  loss: 1.6179 (2.2164)  loss_n_40: 0.3548 (0.5021)  loss_n_60: 0.3629 (0.5017)  loss_n_80: 0.4150 (0.5597)  loss_n_100: 0.4839 (0.6025)  triple_100: 0.0000 (0.0210)  triple_80: 0.0000 (0.0082)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0130)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 820/1724]  eta: 0:59:05  lr: 0.000200  loss: 1.6179 (2.2103)  loss_n_40: 0.3548 (0.5014)  loss_n_60: 0.3629 (0.5003)  loss_n_80: 0.4162 (0.5579)  loss_n_100: 0.4839 (0.6010)  triple_100: 0.0000 (0.0207)  triple_80: 0.0000 (0.0081)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0128)  time: 3.9239  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 830/1724]  eta: 0:58:26  lr: 0.000200  loss: 1.5954 (2.2020)  loss_n_40: 0.3639 (0.4999)  loss_n_60: 0.3588 (0.4984)  loss_n_80: 0.4097 (0.5557)  loss_n_100: 0.4446 (0.5989)  triple_100: 0.0000 (0.0205)  triple_80: 0.0000 (0.0080)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0127)  time: 3.9238  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 840/1724]  eta: 0:57:47  lr: 0.000200  loss: 1.5237 (2.1957)  loss_n_40: 0.3502 (0.4989)  loss_n_60: 0.3408 (0.4970)  loss_n_80: 0.3628 (0.5540)  loss_n_100: 0.4408 (0.5973)  triple_100: 0.0000 (0.0202)  triple_80: 0.0000 (0.0079)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0125)  time: 3.9234  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 850/1724]  eta: 0:57:08  lr: 0.000200  loss: 1.7672 (2.1907)  loss_n_40: 0.3903 (0.4982)  loss_n_60: 0.3830 (0.4958)  loss_n_80: 0.4166 (0.5524)  loss_n_100: 0.4563 (0.5959)  triple_100: 0.0000 (0.0200)  triple_80: 0.0000 (0.0082)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0124)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 860/1724]  eta: 0:56:29  lr: 0.000200  loss: 1.7279 (2.1837)  loss_n_40: 0.3875 (0.4967)  loss_n_60: 0.3827 (0.4942)  loss_n_80: 0.4166 (0.5506)  loss_n_100: 0.4650 (0.5942)  triple_100: 0.0000 (0.0198)  triple_80: 0.0000 (0.0081)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0122)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 870/1724]  eta: 0:55:49  lr: 0.000200  loss: 1.5527 (2.1766)  loss_n_40: 0.3686 (0.4953)  loss_n_60: 0.3551 (0.4925)  loss_n_80: 0.3882 (0.5488)  loss_n_100: 0.4405 (0.5926)  triple_100: 0.0000 (0.0195)  triple_80: 0.0000 (0.0080)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0121)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 880/1724]  eta: 0:55:10  lr: 0.000200  loss: 1.5237 (2.1681)  loss_n_40: 0.3471 (0.4937)  loss_n_60: 0.3385 (0.4906)  loss_n_80: 0.3759 (0.5466)  loss_n_100: 0.4321 (0.5905)  triple_100: 0.0000 (0.0193)  triple_80: 0.0000 (0.0079)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0120)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 890/1724]  eta: 0:54:31  lr: 0.000200  loss: 1.4873 (2.1614)  loss_n_40: 0.3218 (0.4928)  loss_n_60: 0.3372 (0.4891)  loss_n_80: 0.3684 (0.5447)  loss_n_100: 0.3971 (0.5885)  triple_100: 0.0000 (0.0191)  triple_80: 0.0000 (0.0078)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0118)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 900/1724]  eta: 0:53:52  lr: 0.000200  loss: 1.6806 (2.1588)  loss_n_40: 0.3957 (0.4921)  loss_n_60: 0.3907 (0.4882)  loss_n_80: 0.3915 (0.5438)  loss_n_100: 0.4422 (0.5877)  triple_100: 0.0000 (0.0189)  triple_80: 0.0000 (0.0081)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0121)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 910/1724]  eta: 0:53:12  lr: 0.000200  loss: 2.0004 (2.1578)  loss_n_40: 0.4830 (0.4922)  loss_n_60: 0.4475 (0.4880)  loss_n_80: 0.4958 (0.5435)  loss_n_100: 0.5608 (0.5875)  triple_100: 0.0000 (0.0187)  triple_80: 0.0000 (0.0080)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0119)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 920/1724]  eta: 0:52:33  lr: 0.000200  loss: 1.8876 (2.1543)  loss_n_40: 0.4788 (0.4919)  loss_n_60: 0.4361 (0.4874)  loss_n_80: 0.4781 (0.5425)  loss_n_100: 0.5122 (0.5865)  triple_100: 0.0000 (0.0185)  triple_80: 0.0000 (0.0079)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0118)  time: 3.9236  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [ 930/1724]  eta: 0:51:54  lr: 0.000200  loss: 1.6466 (2.1486)  loss_n_40: 0.3970 (0.4909)  loss_n_60: 0.3740 (0.4861)  loss_n_80: 0.4229 (0.5410)  loss_n_100: 0.4713 (0.5851)  triple_100: 0.0000 (0.0183)  triple_80: 0.0000 (0.0078)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0117)  time: 3.9232  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 940/1724]  eta: 0:51:15  lr: 0.000200  loss: 1.5197 (2.1423)  loss_n_40: 0.3358 (0.4897)  loss_n_60: 0.3480 (0.4847)  loss_n_80: 0.3677 (0.5393)  loss_n_100: 0.4232 (0.5835)  triple_100: 0.0000 (0.0181)  triple_80: 0.0000 (0.0077)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0115)  time: 3.9224  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [ 950/1724]  eta: 0:50:36  lr: 0.000200  loss: 1.4533 (2.1347)  loss_n_40: 0.3259 (0.4881)  loss_n_60: 0.3254 (0.4829)  loss_n_80: 0.3677 (0.5373)  loss_n_100: 0.4232 (0.5816)  triple_100: 0.0000 (0.0180)  triple_80: 0.0000 (0.0077)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0114)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 960/1724]  eta: 0:49:56  lr: 0.000200  loss: 1.4533 (2.1317)  loss_n_40: 0.3215 (0.4866)  loss_n_60: 0.3209 (0.4813)  loss_n_80: 0.3551 (0.5354)  loss_n_100: 0.4042 (0.5799)  triple_100: 0.0000 (0.0191)  triple_80: 0.0000 (0.0089)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0121)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 970/1724]  eta: 0:49:17  lr: 0.000200  loss: 1.7195 (2.1374)  loss_n_40: 0.3883 (0.4870)  loss_n_60: 0.3783 (0.4821)  loss_n_80: 0.4362 (0.5366)  loss_n_100: 0.4523 (0.5813)  triple_100: 0.0000 (0.0203)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0120)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 980/1724]  eta: 0:48:38  lr: 0.000200  loss: 2.6503 (2.1421)  loss_n_40: 0.5492 (0.4876)  loss_n_60: 0.5876 (0.4832)  loss_n_80: 0.6909 (0.5382)  loss_n_100: 0.7782 (0.5833)  triple_100: 0.0000 (0.0201)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0119)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [ 990/1724]  eta: 0:47:59  lr: 0.000200  loss: 2.5333 (2.1457)  loss_n_40: 0.5349 (0.4887)  loss_n_60: 0.5583 (0.4839)  loss_n_80: 0.6611 (0.5392)  loss_n_100: 0.7441 (0.5845)  triple_100: 0.0000 (0.0199)  triple_80: 0.0000 (0.0093)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0118)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1000/1724]  eta: 0:47:19  lr: 0.000200  loss: 2.2456 (2.1463)  loss_n_40: 0.5266 (0.4890)  loss_n_60: 0.5151 (0.4841)  loss_n_80: 0.5653 (0.5394)  loss_n_100: 0.6632 (0.5851)  triple_100: 0.0000 (0.0197)  triple_80: 0.0000 (0.0093)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0116)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1010/1724]  eta: 0:46:40  lr: 0.000200  loss: 2.0411 (2.1448)  loss_n_40: 0.4557 (0.4893)  loss_n_60: 0.4544 (0.4838)  loss_n_80: 0.5094 (0.5388)  loss_n_100: 0.5726 (0.5845)  triple_100: 0.0000 (0.0195)  triple_80: 0.0000 (0.0092)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0115)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1020/1724]  eta: 0:46:01  lr: 0.000200  loss: 1.7716 (2.1415)  loss_n_40: 0.4033 (0.4887)  loss_n_60: 0.3972 (0.4831)  loss_n_80: 0.4544 (0.5379)  loss_n_100: 0.5126 (0.5839)  triple_100: 0.0000 (0.0193)  triple_80: 0.0000 (0.0091)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0114)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1030/1724]  eta: 0:45:22  lr: 0.000200  loss: 1.7315 (2.1376)  loss_n_40: 0.3954 (0.4881)  loss_n_60: 0.3888 (0.4823)  loss_n_80: 0.4294 (0.5368)  loss_n_100: 0.5014 (0.5829)  triple_100: 0.0000 (0.0191)  triple_80: 0.0000 (0.0090)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0113)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1040/1724]  eta: 0:44:42  lr: 0.000200  loss: 1.6562 (2.1329)  loss_n_40: 0.3807 (0.4873)  loss_n_60: 0.3700 (0.4813)  loss_n_80: 0.4088 (0.5356)  loss_n_100: 0.4585 (0.5817)  triple_100: 0.0000 (0.0189)  triple_80: 0.0000 (0.0089)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0112)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1050/1724]  eta: 0:44:03  lr: 0.000200  loss: 1.5114 (2.1285)  loss_n_40: 0.3629 (0.4870)  loss_n_60: 0.3510 (0.4803)  loss_n_80: 0.3808 (0.5342)  loss_n_100: 0.4442 (0.5804)  triple_100: 0.0000 (0.0188)  triple_80: 0.0000 (0.0088)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0113)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1060/1724]  eta: 0:43:24  lr: 0.000200  loss: 1.6347 (2.1247)  loss_n_40: 0.3716 (0.4864)  loss_n_60: 0.3713 (0.4795)  loss_n_80: 0.4000 (0.5332)  loss_n_100: 0.4503 (0.5794)  triple_100: 0.0000 (0.0186)  triple_80: 0.0000 (0.0087)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0112)  time: 3.9190  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1070/1724]  eta: 0:42:45  lr: 0.000200  loss: 1.6491 (2.1212)  loss_n_40: 0.4009 (0.4860)  loss_n_60: 0.3774 (0.4787)  loss_n_80: 0.4230 (0.5322)  loss_n_100: 0.4756 (0.5785)  triple_100: 0.0000 (0.0184)  triple_80: 0.0000 (0.0087)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0111)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1080/1724]  eta: 0:42:05  lr: 0.000200  loss: 1.7096 (2.1202)  loss_n_40: 0.4362 (0.4859)  loss_n_60: 0.3978 (0.4784)  loss_n_80: 0.4263 (0.5317)  loss_n_100: 0.4937 (0.5780)  triple_100: 0.0000 (0.0182)  triple_80: 0.0000 (0.0086)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0118)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1090/1724]  eta: 0:41:26  lr: 0.000200  loss: 1.7750 (2.1166)  loss_n_40: 0.4066 (0.4855)  loss_n_60: 0.3959 (0.4776)  loss_n_80: 0.4287 (0.5307)  loss_n_100: 0.4804 (0.5771)  triple_100: 0.0000 (0.0181)  triple_80: 0.0000 (0.0085)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0117)  time: 3.9204  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1100/1724]  eta: 0:40:47  lr: 0.000200  loss: 1.6919 (2.1129)  loss_n_40: 0.3932 (0.4849)  loss_n_60: 0.3888 (0.4768)  loss_n_80: 0.4228 (0.5297)  loss_n_100: 0.4740 (0.5762)  triple_100: 0.0000 (0.0179)  triple_80: 0.0000 (0.0084)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0116)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1110/1724]  eta: 0:40:08  lr: 0.000200  loss: 1.6556 (2.1085)  loss_n_40: 0.3823 (0.4842)  loss_n_60: 0.3695 (0.4758)  loss_n_80: 0.4169 (0.5285)  loss_n_100: 0.4657 (0.5750)  triple_100: 0.0000 (0.0178)  triple_80: 0.0000 (0.0083)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0115)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1120/1724]  eta: 0:39:28  lr: 0.000200  loss: 1.5704 (2.1091)  loss_n_40: 0.3660 (0.4835)  loss_n_60: 0.3563 (0.4747)  loss_n_80: 0.3844 (0.5271)  loss_n_100: 0.4161 (0.5736)  triple_100: 0.0000 (0.0176)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0141)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1130/1724]  eta: 0:38:49  lr: 0.000200  loss: 1.9161 (2.1301)  loss_n_40: 0.5622 (0.4851)  loss_n_60: 0.4092 (0.4775)  loss_n_80: 0.4601 (0.5310)  loss_n_100: 0.5190 (0.5787)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0140)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1140/1724]  eta: 0:38:10  lr: 0.000200  loss: 3.8060 (2.1418)  loss_n_40: 0.6537 (0.4868)  loss_n_60: 0.7977 (0.4802)  loss_n_80: 0.9918 (0.5344)  loss_n_100: 1.1613 (0.5833)  triple_100: 0.0000 (0.0252)  triple_80: 0.0000 (0.0093)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0139)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1150/1724]  eta: 0:37:31  lr: 0.000200  loss: 2.9540 (2.1476)  loss_n_40: 0.5818 (0.4876)  loss_n_60: 0.6958 (0.4816)  loss_n_80: 0.7814 (0.5361)  loss_n_100: 0.9152 (0.5856)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0092)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0138)  time: 3.9212  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1160/1724]  eta: 0:36:52  lr: 0.000200  loss: 2.7248 (2.1517)  loss_n_40: 0.5495 (0.4885)  loss_n_60: 0.6268 (0.4828)  loss_n_80: 0.6899 (0.5372)  loss_n_100: 0.7877 (0.5870)  triple_100: 0.0000 (0.0247)  triple_80: 0.0000 (0.0092)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0137)  time: 3.9212  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [1170/1724]  eta: 0:36:12  lr: 0.000200  loss: 2.5732 (2.1544)  loss_n_40: 0.5495 (0.4893)  loss_n_60: 0.5965 (0.4833)  loss_n_80: 0.6523 (0.5377)  loss_n_100: 0.7033 (0.5876)  triple_100: 0.0000 (0.0245)  triple_80: 0.0000 (0.0091)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0135)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1180/1724]  eta: 0:35:33  lr: 0.000200  loss: 2.8206 (2.1728)  loss_n_40: 0.6490 (0.4913)  loss_n_60: 0.6325 (0.4870)  loss_n_80: 0.7051 (0.5423)  loss_n_100: 0.7937 (0.5931)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0099)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0140)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1190/1724]  eta: 0:34:54  lr: 0.000200  loss: 4.8423 (2.1993)  loss_n_40: 0.9440 (0.4964)  loss_n_60: 1.1398 (0.4934)  loss_n_80: 1.2313 (0.5492)  loss_n_100: 1.4232 (0.6008)  triple_100: 0.0000 (0.0252)  triple_80: 0.0000 (0.0098)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0148)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1200/1724]  eta: 0:34:15  lr: 0.000200  loss: 4.9304 (2.2225)  loss_n_40: 1.0507 (0.5016)  loss_n_60: 1.1675 (0.4990)  loss_n_80: 1.2749 (0.5550)  loss_n_100: 1.4424 (0.6074)  triple_100: 0.0000 (0.0250)  triple_80: 0.0000 (0.0097)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0147)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1210/1724]  eta: 0:33:35  lr: 0.000200  loss: 4.5849 (2.2406)  loss_n_40: 0.9853 (0.5056)  loss_n_60: 1.0546 (0.5033)  loss_n_80: 1.1514 (0.5597)  loss_n_100: 1.2941 (0.6130)  triple_100: 0.0000 (0.0248)  triple_80: 0.0000 (0.0096)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0145)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1220/1724]  eta: 0:32:56  lr: 0.000200  loss: 3.9993 (2.2537)  loss_n_40: 0.9160 (0.5088)  loss_n_60: 0.9466 (0.5065)  loss_n_80: 1.0190 (0.5631)  loss_n_100: 1.1569 (0.6168)  triple_100: 0.0000 (0.0246)  triple_80: 0.0000 (0.0096)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0144)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1230/1724]  eta: 0:32:17  lr: 0.000200  loss: 3.7163 (2.2658)  loss_n_40: 0.8757 (0.5121)  loss_n_60: 0.8737 (0.5096)  loss_n_80: 0.9378 (0.5660)  loss_n_100: 1.0401 (0.6198)  triple_100: 0.0000 (0.0244)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0099)  triple_40: 0.0000 (0.0146)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1240/1724]  eta: 0:31:38  lr: 0.000200  loss: 3.4590 (2.2760)  loss_n_40: 0.8381 (0.5149)  loss_n_60: 0.8195 (0.5124)  loss_n_80: 0.8845 (0.5685)  loss_n_100: 0.9518 (0.6223)  triple_100: 0.0000 (0.0242)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0145)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1250/1724]  eta: 0:30:58  lr: 0.000200  loss: 3.1506 (2.2810)  loss_n_40: 0.7284 (0.5163)  loss_n_60: 0.7261 (0.5137)  loss_n_80: 0.7754 (0.5697)  loss_n_100: 0.8459 (0.6237)  triple_100: 0.0000 (0.0241)  triple_80: 0.0000 (0.0093)  triple_60: 0.0000 (0.0097)  triple_40: 0.0000 (0.0144)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1260/1724]  eta: 0:30:19  lr: 0.000200  loss: 2.7211 (2.2973)  loss_n_40: 0.6491 (0.5177)  loss_n_60: 0.6474 (0.5152)  loss_n_80: 0.6997 (0.5713)  loss_n_100: 0.7743 (0.6255)  triple_100: 0.0000 (0.0283)  triple_80: 0.0000 (0.0127)  triple_60: 0.0000 (0.0103)  triple_40: 0.0000 (0.0163)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1270/1724]  eta: 0:29:40  lr: 0.000200  loss: 5.5742 (2.3366)  loss_n_40: 0.9175 (0.5226)  loss_n_60: 1.1227 (0.5218)  loss_n_80: 1.2309 (0.5797)  loss_n_100: 1.2809 (0.6357)  triple_100: 0.0000 (0.0374)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0161)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1280/1724]  eta: 0:29:01  lr: 0.000200  loss: 6.2735 (2.3669)  loss_n_40: 1.1813 (0.5284)  loss_n_60: 1.3703 (0.5286)  loss_n_80: 1.6200 (0.5881)  loss_n_100: 1.8638 (0.6457)  triple_100: 0.0000 (0.0372)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0160)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1290/1724]  eta: 0:28:22  lr: 0.000200  loss: 5.7592 (2.3957)  loss_n_40: 1.1827 (0.5336)  loss_n_60: 1.2929 (0.5341)  loss_n_80: 1.5593 (0.5948)  loss_n_100: 1.7814 (0.6538)  triple_100: 0.0000 (0.0369)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0124)  triple_40: 0.0000 (0.0166)  time: 3.9206  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1300/1724]  eta: 0:27:42  lr: 0.000200  loss: 6.7292 (2.4421)  loss_n_40: 1.2291 (0.5409)  loss_n_60: 1.5100 (0.5447)  loss_n_80: 1.6025 (0.6080)  loss_n_100: 1.8198 (0.6681)  triple_100: 0.0000 (0.0382)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0123)  triple_40: 0.0000 (0.0165)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1310/1724]  eta: 0:27:03  lr: 0.000200  loss: 7.5843 (2.4823)  loss_n_40: 1.2845 (0.5457)  loss_n_60: 1.6634 (0.5536)  loss_n_80: 2.0758 (0.6197)  loss_n_100: 2.4226 (0.6818)  triple_100: 0.0000 (0.0396)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0122)  triple_40: 0.0000 (0.0164)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1320/1724]  eta: 0:26:24  lr: 0.000200  loss: 7.0059 (2.5153)  loss_n_40: 1.1681 (0.5507)  loss_n_60: 1.5388 (0.5613)  loss_n_80: 1.9270 (0.6294)  loss_n_100: 2.2595 (0.6931)  triple_100: 0.0000 (0.0393)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0121)  triple_40: 0.0000 (0.0162)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1330/1724]  eta: 0:25:45  lr: 0.000200  loss: 6.5536 (2.5456)  loss_n_40: 1.1620 (0.5550)  loss_n_60: 1.4840 (0.5685)  loss_n_80: 1.8113 (0.6382)  loss_n_100: 2.1134 (0.7034)  triple_100: 0.0000 (0.0392)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0161)  time: 3.9213  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1340/1724]  eta: 0:25:05  lr: 0.000200  loss: 5.9554 (2.5705)  loss_n_40: 1.0175 (0.5585)  loss_n_60: 1.3961 (0.5737)  loss_n_80: 1.5994 (0.6441)  loss_n_100: 1.7457 (0.7103)  triple_100: 0.0000 (0.0423)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0160)  time: 3.9226  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1350/1724]  eta: 0:24:26  lr: 0.000200  loss: 6.1545 (2.6094)  loss_n_40: 1.0376 (0.5623)  loss_n_60: 1.3765 (0.5810)  loss_n_80: 1.5994 (0.6541)  loss_n_100: 1.7894 (0.7216)  triple_100: 0.0000 (0.0476)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0163)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1360/1724]  eta: 0:23:47  lr: 0.000200  loss: 7.6324 (2.6488)  loss_n_40: 1.0695 (0.5664)  loss_n_60: 1.7748 (0.5907)  loss_n_80: 2.2271 (0.6671)  loss_n_100: 2.4904 (0.7349)  triple_100: 0.0000 (0.0472)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0118)  triple_40: 0.0000 (0.0161)  time: 3.9207  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1370/1724]  eta: 0:23:08  lr: 0.000200  loss: 7.9525 (2.6889)  loss_n_40: 1.1917 (0.5713)  loss_n_60: 1.8642 (0.5999)  loss_n_80: 2.3886 (0.6803)  loss_n_100: 2.5423 (0.7483)  triple_100: 0.0000 (0.0469)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0117)  triple_40: 0.0000 (0.0160)  time: 3.9204  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1380/1724]  eta: 0:22:29  lr: 0.000200  loss: 7.2413 (2.7164)  loss_n_40: 1.1863 (0.5742)  loss_n_60: 1.5561 (0.6056)  loss_n_80: 2.3325 (0.6900)  loss_n_100: 2.3615 (0.7583)  triple_100: 0.0000 (0.0466)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0117)  triple_40: 0.0000 (0.0159)  time: 3.9218  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1390/1724]  eta: 0:21:49  lr: 0.000200  loss: 6.4230 (2.7535)  loss_n_40: 0.9911 (0.5778)  loss_n_60: 1.4157 (0.6122)  loss_n_80: 1.8810 (0.6994)  loss_n_100: 1.9991 (0.7681)  triple_100: 0.0000 (0.0462)  triple_80: 0.0000 (0.0161)  triple_60: 0.0000 (0.0146)  triple_40: 0.0000 (0.0189)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1400/1724]  eta: 0:21:10  lr: 0.000200  loss: 8.3751 (2.8027)  loss_n_40: 1.1826 (0.5827)  loss_n_60: 1.9343 (0.6239)  loss_n_80: 2.3703 (0.7136)  loss_n_100: 2.5769 (0.7826)  triple_100: 0.0000 (0.0485)  triple_80: 0.0000 (0.0181)  triple_60: 0.0000 (0.0145)  triple_40: 0.0000 (0.0188)  time: 3.9176  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [1410/1724]  eta: 0:20:31  lr: 0.000200  loss: 8.3732 (2.8387)  loss_n_40: 1.1878 (0.5868)  loss_n_60: 1.8762 (0.6323)  loss_n_80: 2.5062 (0.7257)  loss_n_100: 2.5769 (0.7946)  triple_100: 0.0000 (0.0482)  triple_80: 0.0000 (0.0180)  triple_60: 0.0000 (0.0144)  triple_40: 0.0000 (0.0186)  time: 3.9183  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1420/1724]  eta: 0:19:52  lr: 0.000200  loss: 7.8960 (2.8750)  loss_n_40: 1.1258 (0.5911)  loss_n_60: 1.8014 (0.6400)  loss_n_80: 2.4689 (0.7378)  loss_n_100: 2.5016 (0.8076)  triple_100: 0.0000 (0.0478)  triple_80: 0.0000 (0.0179)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0185)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1430/1724]  eta: 0:19:12  lr: 0.000200  loss: 7.0898 (2.8997)  loss_n_40: 1.0975 (0.5941)  loss_n_60: 1.5222 (0.6454)  loss_n_80: 2.1621 (0.7460)  loss_n_100: 2.2488 (0.8163)  triple_100: 0.0000 (0.0475)  triple_80: 0.0000 (0.0178)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0184)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1440/1724]  eta: 0:18:33  lr: 0.000200  loss: 5.9242 (2.9187)  loss_n_40: 1.0438 (0.5976)  loss_n_60: 1.3408 (0.6498)  loss_n_80: 1.6579 (0.7518)  loss_n_100: 1.8220 (0.8223)  triple_100: 0.0000 (0.0472)  triple_80: 0.0000 (0.0176)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0183)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1450/1724]  eta: 0:17:54  lr: 0.000200  loss: 5.4458 (2.9359)  loss_n_40: 0.9589 (0.6008)  loss_n_60: 1.2057 (0.6537)  loss_n_80: 1.5462 (0.7571)  loss_n_100: 1.6749 (0.8278)  triple_100: 0.0000 (0.0469)  triple_80: 0.0000 (0.0175)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0181)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1460/1724]  eta: 0:17:15  lr: 0.000200  loss: 4.8430 (2.9462)  loss_n_40: 0.9092 (0.6024)  loss_n_60: 1.0565 (0.6558)  loss_n_80: 1.3971 (0.7606)  loss_n_100: 1.4736 (0.8316)  triple_100: 0.0000 (0.0465)  triple_80: 0.0000 (0.0174)  triple_60: 0.0000 (0.0139)  triple_40: 0.0000 (0.0180)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1470/1724]  eta: 0:16:36  lr: 0.000200  loss: 4.2960 (2.9554)  loss_n_40: 0.8227 (0.6042)  loss_n_60: 0.9311 (0.6579)  loss_n_80: 1.1672 (0.7633)  loss_n_100: 1.3359 (0.8348)  triple_100: 0.0000 (0.0462)  triple_80: 0.0000 (0.0173)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0179)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1480/1724]  eta: 0:15:56  lr: 0.000200  loss: 4.0821 (2.9626)  loss_n_40: 0.7627 (0.6054)  loss_n_60: 0.9085 (0.6595)  loss_n_80: 1.0908 (0.7655)  loss_n_100: 1.2529 (0.8377)  triple_100: 0.0000 (0.0459)  triple_80: 0.0000 (0.0172)  triple_60: 0.0000 (0.0137)  triple_40: 0.0000 (0.0178)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1490/1724]  eta: 0:15:17  lr: 0.000200  loss: 3.8930 (2.9679)  loss_n_40: 0.7538 (0.6066)  loss_n_60: 0.8828 (0.6607)  loss_n_80: 1.0293 (0.7669)  loss_n_100: 1.1694 (0.8395)  triple_100: 0.0000 (0.0458)  triple_80: 0.0000 (0.0170)  triple_60: 0.0000 (0.0136)  triple_40: 0.0000 (0.0176)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1500/1724]  eta: 0:14:38  lr: 0.000200  loss: 3.5070 (2.9715)  loss_n_40: 0.6420 (0.6069)  loss_n_60: 0.7785 (0.6615)  loss_n_80: 0.9271 (0.7680)  loss_n_100: 1.1286 (0.8416)  triple_100: 0.0000 (0.0455)  triple_80: 0.0000 (0.0169)  triple_60: 0.0000 (0.0135)  triple_40: 0.0000 (0.0175)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1510/1724]  eta: 0:13:59  lr: 0.000200  loss: 3.4329 (2.9759)  loss_n_40: 0.6106 (0.6080)  loss_n_60: 0.7475 (0.6626)  loss_n_80: 0.9180 (0.7691)  loss_n_100: 1.1286 (0.8434)  triple_100: 0.0000 (0.0452)  triple_80: 0.0000 (0.0168)  triple_60: 0.0000 (0.0134)  triple_40: 0.0000 (0.0174)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1520/1724]  eta: 0:13:20  lr: 0.000200  loss: 3.3160 (2.9777)  loss_n_40: 0.6549 (0.6083)  loss_n_60: 0.7324 (0.6630)  loss_n_80: 0.8703 (0.7696)  loss_n_100: 1.0262 (0.8445)  triple_100: 0.0000 (0.0449)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0134)  triple_40: 0.0000 (0.0173)  time: 3.9208  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1530/1724]  eta: 0:12:40  lr: 0.000200  loss: 3.0132 (2.9768)  loss_n_40: 0.5889 (0.6081)  loss_n_60: 0.6653 (0.6628)  loss_n_80: 0.8035 (0.7694)  loss_n_100: 0.9737 (0.8449)  triple_100: 0.0000 (0.0446)  triple_80: 0.0000 (0.0166)  triple_60: 0.0000 (0.0133)  triple_40: 0.0000 (0.0172)  time: 3.9212  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1540/1724]  eta: 0:12:01  lr: 0.000200  loss: 2.6855 (2.9752)  loss_n_40: 0.5633 (0.6081)  loss_n_60: 0.6017 (0.6626)  loss_n_80: 0.6952 (0.7689)  loss_n_100: 0.8125 (0.8446)  triple_100: 0.0000 (0.0443)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0132)  triple_40: 0.0000 (0.0171)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1550/1724]  eta: 0:11:22  lr: 0.000200  loss: 2.7552 (2.9749)  loss_n_40: 0.5721 (0.6082)  loss_n_60: 0.5993 (0.6624)  loss_n_80: 0.6952 (0.7686)  loss_n_100: 0.8125 (0.8445)  triple_100: 0.0000 (0.0445)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0132)  triple_40: 0.0000 (0.0170)  time: 3.9233  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1560/1724]  eta: 0:10:43  lr: 0.000200  loss: 2.6105 (2.9720)  loss_n_40: 0.5341 (0.6078)  loss_n_60: 0.5891 (0.6620)  loss_n_80: 0.6659 (0.7678)  loss_n_100: 0.7655 (0.8438)  triple_100: 0.0000 (0.0442)  triple_80: 0.0000 (0.0164)  triple_60: 0.0000 (0.0131)  triple_40: 0.0000 (0.0169)  time: 3.9225  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1570/1724]  eta: 0:10:03  lr: 0.000200  loss: 2.4734 (2.9687)  loss_n_40: 0.4882 (0.6073)  loss_n_60: 0.5693 (0.6615)  loss_n_80: 0.6476 (0.7670)  loss_n_100: 0.7263 (0.8429)  triple_100: 0.0000 (0.0439)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0131)  triple_40: 0.0000 (0.0168)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1580/1724]  eta: 0:09:24  lr: 0.000200  loss: 2.5677 (2.9917)  loss_n_40: 0.5322 (0.6090)  loss_n_60: 0.6373 (0.6642)  loss_n_80: 0.6999 (0.7700)  loss_n_100: 0.7580 (0.8475)  triple_100: 0.0000 (0.0494)  triple_80: 0.0000 (0.0207)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0168)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1590/1724]  eta: 0:08:45  lr: 0.000200  loss: 5.1945 (3.0056)  loss_n_40: 1.0062 (0.6118)  loss_n_60: 1.1660 (0.6676)  loss_n_80: 1.3227 (0.7737)  loss_n_100: 1.6134 (0.8521)  triple_100: 0.0000 (0.0491)  triple_80: 0.0000 (0.0206)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0167)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1600/1724]  eta: 0:08:06  lr: 0.000200  loss: 4.8427 (3.0168)  loss_n_40: 1.0168 (0.6146)  loss_n_60: 1.1217 (0.6699)  loss_n_80: 1.2244 (0.7762)  loss_n_100: 1.3602 (0.8548)  triple_100: 0.0000 (0.0488)  triple_80: 0.0000 (0.0207)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0166)  time: 3.9213  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1610/1724]  eta: 0:07:27  lr: 0.000200  loss: 4.1946 (3.0215)  loss_n_40: 0.8491 (0.6159)  loss_n_60: 0.9393 (0.6710)  loss_n_80: 1.0810 (0.7774)  loss_n_100: 1.2052 (0.8564)  triple_100: 0.0000 (0.0485)  triple_80: 0.0000 (0.0206)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0165)  time: 3.9215  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1620/1724]  eta: 0:06:47  lr: 0.000200  loss: 3.6644 (3.0249)  loss_n_40: 0.7486 (0.6167)  loss_n_60: 0.7984 (0.6717)  loss_n_80: 0.9433 (0.7782)  loss_n_100: 1.0371 (0.8573)  triple_100: 0.0000 (0.0482)  triple_80: 0.0000 (0.0205)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0172)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1630/1724]  eta: 0:06:08  lr: 0.000200  loss: 3.2337 (3.0271)  loss_n_40: 0.6768 (0.6171)  loss_n_60: 0.7330 (0.6720)  loss_n_80: 0.8393 (0.7785)  loss_n_100: 0.9251 (0.8576)  triple_100: 0.0000 (0.0482)  triple_80: 0.0000 (0.0203)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0171)  time: 3.9213  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1640/1724]  eta: 0:05:29  lr: 0.000200  loss: 3.0563 (3.0270)  loss_n_40: 0.6360 (0.6174)  loss_n_60: 0.6916 (0.6720)  loss_n_80: 0.8034 (0.7785)  loss_n_100: 0.8922 (0.8577)  triple_100: 0.0000 (0.0479)  triple_80: 0.0000 (0.0203)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0169)  time: 3.9210  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [1650/1724]  eta: 0:04:50  lr: 0.000200  loss: 2.8707 (3.0257)  loss_n_40: 0.5490 (0.6171)  loss_n_60: 0.6529 (0.6720)  loss_n_80: 0.7571 (0.7783)  loss_n_100: 0.8454 (0.8576)  triple_100: 0.0000 (0.0476)  triple_80: 0.0000 (0.0201)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0168)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1660/1724]  eta: 0:04:10  lr: 0.000200  loss: 2.6040 (3.0230)  loss_n_40: 0.5149 (0.6165)  loss_n_60: 0.6259 (0.6715)  loss_n_80: 0.6903 (0.7774)  loss_n_100: 0.7770 (0.8568)  triple_100: 0.0000 (0.0474)  triple_80: 0.0000 (0.0201)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0167)  time: 3.9218  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1670/1724]  eta: 0:03:31  lr: 0.000200  loss: 2.3679 (3.0201)  loss_n_40: 0.4926 (0.6163)  loss_n_60: 0.5561 (0.6711)  loss_n_80: 0.6080 (0.7765)  loss_n_100: 0.6970 (0.8559)  triple_100: 0.0000 (0.0471)  triple_80: 0.0000 (0.0200)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0166)  time: 3.9225  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1680/1724]  eta: 0:02:52  lr: 0.000200  loss: 2.3414 (3.0171)  loss_n_40: 0.4872 (0.6161)  loss_n_60: 0.5522 (0.6708)  loss_n_80: 0.5985 (0.7756)  loss_n_100: 0.6754 (0.8549)  triple_100: 0.0000 (0.0469)  triple_80: 0.0000 (0.0200)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0165)  time: 3.9225  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1690/1724]  eta: 0:02:13  lr: 0.000200  loss: 2.2811 (3.0131)  loss_n_40: 0.4583 (0.6152)  loss_n_60: 0.5422 (0.6700)  loss_n_80: 0.5847 (0.7743)  loss_n_100: 0.6533 (0.8537)  triple_100: 0.0000 (0.0468)  triple_80: 0.0000 (0.0201)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0164)  time: 3.9235  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1700/1724]  eta: 0:01:34  lr: 0.000200  loss: 2.1834 (3.0101)  loss_n_40: 0.4500 (0.6150)  loss_n_60: 0.5302 (0.6696)  loss_n_80: 0.5237 (0.7732)  loss_n_100: 0.6183 (0.8526)  triple_100: 0.0000 (0.0469)  triple_80: 0.0000 (0.0199)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0164)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:11]  [1710/1724]  eta: 0:00:54  lr: 0.000200  loss: 2.3674 (3.0070)  loss_n_40: 0.4923 (0.6145)  loss_n_60: 0.6027 (0.6693)  loss_n_80: 0.6076 (0.7725)  loss_n_100: 0.6730 (0.8517)  triple_100: 0.0000 (0.0466)  triple_80: 0.0000 (0.0198)  triple_60: 0.0000 (0.0163)  triple_40: 0.0000 (0.0163)  time: 3.9224  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1720/1724]  eta: 0:00:15  lr: 0.000200  loss: 2.3674 (3.0044)  loss_n_40: 0.4853 (0.6139)  loss_n_60: 0.6036 (0.6689)  loss_n_80: 0.6134 (0.7716)  loss_n_100: 0.7096 (0.8509)  triple_100: 0.0000 (0.0466)  triple_80: 0.0000 (0.0199)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0162)  time: 3.9225  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11]  [1723/1724]  eta: 0:00:03  lr: 0.000200  loss: 2.3674 (3.0031)  loss_n_40: 0.4625 (0.6136)  loss_n_60: 0.5965 (0.6687)  loss_n_80: 0.6134 (0.7713)  loss_n_100: 0.7096 (0.8507)  triple_100: 0.0000 (0.0465)  triple_80: 0.0000 (0.0199)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0161)  time: 3.9218  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:11] Total time: 1:52:41 (3.9218 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 2.3674 (3.0031)  loss_n_40: 0.4625 (0.6136)  loss_n_60: 0.5965 (0.6687)  loss_n_80: 0.6134 (0.7713)  loss_n_100: 0.7096 (0.8507)  triple_100: 0.0000 (0.0465)  triple_80: 0.0000 (0.0199)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0161)\n",
      "Valid: [epoch:11]  [  0/845]  eta: 0:10:54  loss: 2.8619 (2.8619)  loss_n_40: 0.5343 (0.5343)  loss_n_60: 0.7113 (0.7113)  loss_n_80: 0.7726 (0.7726)  loss_n_100: 0.8436 (0.8436)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7749  data: 0.4395  max mem: 46473\n",
      "Valid: [epoch:11]  [ 10/845]  eta: 0:05:12  loss: 2.6889 (2.6334)  loss_n_40: 0.4717 (0.4956)  loss_n_60: 0.6981 (0.6723)  loss_n_80: 0.7239 (0.7112)  loss_n_100: 0.7477 (0.7543)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3740  data: 0.0401  max mem: 46473\n",
      "Valid: [epoch:11]  [ 20/845]  eta: 0:04:52  loss: 2.4751 (2.6060)  loss_n_40: 0.4431 (0.5098)  loss_n_60: 0.6776 (0.6470)  loss_n_80: 0.6680 (0.6997)  loss_n_100: 0.7176 (0.7495)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [ 30/845]  eta: 0:04:44  loss: 2.3688 (2.5968)  loss_n_40: 0.4431 (0.5257)  loss_n_60: 0.5684 (0.6318)  loss_n_80: 0.6281 (0.6946)  loss_n_100: 0.7003 (0.7447)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [ 40/845]  eta: 0:04:37  loss: 2.2986 (2.5352)  loss_n_40: 0.4182 (0.5039)  loss_n_60: 0.5717 (0.6192)  loss_n_80: 0.6201 (0.6799)  loss_n_100: 0.6918 (0.7322)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:11]  [ 50/845]  eta: 0:04:32  loss: 2.3009 (2.5737)  loss_n_40: 0.4569 (0.5238)  loss_n_60: 0.5904 (0.6243)  loss_n_80: 0.6359 (0.6873)  loss_n_100: 0.6751 (0.7382)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:11]  [ 60/845]  eta: 0:04:28  loss: 2.4865 (2.5675)  loss_n_40: 0.4639 (0.5123)  loss_n_60: 0.6190 (0.6266)  loss_n_80: 0.6856 (0.6886)  loss_n_100: 0.7362 (0.7401)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [ 70/845]  eta: 0:04:23  loss: 2.4865 (2.5464)  loss_n_40: 0.4374 (0.5050)  loss_n_60: 0.6151 (0.6261)  loss_n_80: 0.6746 (0.6827)  loss_n_100: 0.7362 (0.7325)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [ 80/845]  eta: 0:04:20  loss: 2.3008 (2.5249)  loss_n_40: 0.4386 (0.5012)  loss_n_60: 0.5942 (0.6229)  loss_n_80: 0.6505 (0.6760)  loss_n_100: 0.6558 (0.7248)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [ 90/845]  eta: 0:04:16  loss: 2.2188 (2.4930)  loss_n_40: 0.3986 (0.4950)  loss_n_60: 0.5649 (0.6184)  loss_n_80: 0.6106 (0.6643)  loss_n_100: 0.6372 (0.7153)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:11]  [100/845]  eta: 0:04:12  loss: 2.2697 (2.5051)  loss_n_40: 0.4331 (0.5119)  loss_n_60: 0.5657 (0.6161)  loss_n_80: 0.5938 (0.6619)  loss_n_100: 0.6531 (0.7152)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [110/845]  eta: 0:04:08  loss: 2.2965 (2.5034)  loss_n_40: 0.4609 (0.5191)  loss_n_60: 0.5690 (0.6155)  loss_n_80: 0.5996 (0.6578)  loss_n_100: 0.6552 (0.7110)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [120/845]  eta: 0:04:05  loss: 2.2789 (2.4966)  loss_n_40: 0.4247 (0.5156)  loss_n_60: 0.5809 (0.6138)  loss_n_80: 0.6050 (0.6567)  loss_n_100: 0.6657 (0.7104)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [130/845]  eta: 0:04:01  loss: 2.3742 (2.5156)  loss_n_40: 0.4375 (0.5138)  loss_n_60: 0.6034 (0.6154)  loss_n_80: 0.6270 (0.6650)  loss_n_100: 0.6912 (0.7214)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:11]  [140/845]  eta: 0:03:58  loss: 2.5198 (2.5209)  loss_n_40: 0.4535 (0.5158)  loss_n_60: 0.6044 (0.6150)  loss_n_80: 0.6886 (0.6657)  loss_n_100: 0.7779 (0.7243)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:11]  [150/845]  eta: 0:03:54  loss: 2.2300 (2.4985)  loss_n_40: 0.4280 (0.5109)  loss_n_60: 0.5809 (0.6118)  loss_n_80: 0.6304 (0.6592)  loss_n_100: 0.6897 (0.7166)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [160/845]  eta: 0:03:51  loss: 2.3533 (2.5169)  loss_n_40: 0.4220 (0.5143)  loss_n_60: 0.6016 (0.6167)  loss_n_80: 0.6332 (0.6633)  loss_n_100: 0.7201 (0.7227)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [170/845]  eta: 0:03:47  loss: 2.6084 (2.5211)  loss_n_40: 0.4614 (0.5136)  loss_n_60: 0.6328 (0.6173)  loss_n_80: 0.6885 (0.6654)  loss_n_100: 0.7613 (0.7248)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [180/845]  eta: 0:03:44  loss: 2.3565 (2.5093)  loss_n_40: 0.4142 (0.5091)  loss_n_60: 0.6328 (0.6167)  loss_n_80: 0.6504 (0.6623)  loss_n_100: 0.6491 (0.7212)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [190/845]  eta: 0:03:40  loss: 2.2851 (2.5134)  loss_n_40: 0.4142 (0.5084)  loss_n_60: 0.5862 (0.6166)  loss_n_80: 0.6435 (0.6653)  loss_n_100: 0.6796 (0.7231)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [200/845]  eta: 0:03:37  loss: 2.3107 (2.5119)  loss_n_40: 0.4727 (0.5071)  loss_n_60: 0.6175 (0.6174)  loss_n_80: 0.6347 (0.6646)  loss_n_100: 0.6796 (0.7228)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [210/845]  eta: 0:03:33  loss: 2.3544 (2.5140)  loss_n_40: 0.4727 (0.5061)  loss_n_60: 0.6275 (0.6171)  loss_n_80: 0.6347 (0.6654)  loss_n_100: 0.7088 (0.7254)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [220/845]  eta: 0:03:30  loss: 2.5540 (2.5250)  loss_n_40: 0.4598 (0.5106)  loss_n_60: 0.6391 (0.6185)  loss_n_80: 0.6963 (0.6679)  loss_n_100: 0.7152 (0.7279)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [230/845]  eta: 0:03:26  loss: 2.5162 (2.5250)  loss_n_40: 0.4489 (0.5110)  loss_n_60: 0.6143 (0.6184)  loss_n_80: 0.6612 (0.6676)  loss_n_100: 0.7397 (0.7281)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [240/845]  eta: 0:03:23  loss: 2.3303 (2.5160)  loss_n_40: 0.3939 (0.5065)  loss_n_60: 0.5905 (0.6167)  loss_n_80: 0.6256 (0.6651)  loss_n_100: 0.6833 (0.7276)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [250/845]  eta: 0:03:20  loss: 2.3045 (2.5153)  loss_n_40: 0.4076 (0.5056)  loss_n_60: 0.5889 (0.6176)  loss_n_80: 0.5866 (0.6646)  loss_n_100: 0.6676 (0.7276)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [260/845]  eta: 0:03:16  loss: 2.4714 (2.5173)  loss_n_40: 0.4498 (0.5045)  loss_n_60: 0.6298 (0.6179)  loss_n_80: 0.6695 (0.6659)  loss_n_100: 0.7350 (0.7290)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [270/845]  eta: 0:03:13  loss: 2.4255 (2.5162)  loss_n_40: 0.4591 (0.5025)  loss_n_60: 0.6210 (0.6181)  loss_n_80: 0.6496 (0.6659)  loss_n_100: 0.7265 (0.7298)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [280/845]  eta: 0:03:09  loss: 2.2876 (2.5058)  loss_n_40: 0.4224 (0.4993)  loss_n_60: 0.5723 (0.6164)  loss_n_80: 0.6094 (0.6633)  loss_n_100: 0.6650 (0.7268)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [290/845]  eta: 0:03:06  loss: 2.2876 (2.5095)  loss_n_40: 0.4224 (0.5024)  loss_n_60: 0.5614 (0.6161)  loss_n_80: 0.5890 (0.6631)  loss_n_100: 0.6590 (0.7279)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [300/845]  eta: 0:03:03  loss: 2.4384 (2.5185)  loss_n_40: 0.4749 (0.5095)  loss_n_60: 0.5762 (0.6161)  loss_n_80: 0.6707 (0.6640)  loss_n_100: 0.6919 (0.7289)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [310/845]  eta: 0:02:59  loss: 2.3368 (2.5139)  loss_n_40: 0.4361 (0.5073)  loss_n_60: 0.5752 (0.6155)  loss_n_80: 0.6149 (0.6634)  loss_n_100: 0.6731 (0.7277)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [320/845]  eta: 0:02:56  loss: 2.3015 (2.5117)  loss_n_40: 0.4225 (0.5061)  loss_n_60: 0.5869 (0.6147)  loss_n_80: 0.6330 (0.6636)  loss_n_100: 0.6660 (0.7273)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [330/845]  eta: 0:02:52  loss: 2.3015 (2.5117)  loss_n_40: 0.4363 (0.5049)  loss_n_60: 0.5697 (0.6147)  loss_n_80: 0.6330 (0.6638)  loss_n_100: 0.6693 (0.7282)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [340/845]  eta: 0:02:49  loss: 2.4022 (2.5117)  loss_n_40: 0.4638 (0.5044)  loss_n_60: 0.6126 (0.6151)  loss_n_80: 0.6462 (0.6640)  loss_n_100: 0.7322 (0.7282)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [350/845]  eta: 0:02:46  loss: 2.4140 (2.5153)  loss_n_40: 0.4638 (0.5066)  loss_n_60: 0.6212 (0.6153)  loss_n_80: 0.6462 (0.6641)  loss_n_100: 0.7371 (0.7293)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [360/845]  eta: 0:02:42  loss: 2.4649 (2.5142)  loss_n_40: 0.4588 (0.5052)  loss_n_60: 0.5889 (0.6144)  loss_n_80: 0.6452 (0.6642)  loss_n_100: 0.7442 (0.7304)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [370/845]  eta: 0:02:39  loss: 2.3825 (2.5128)  loss_n_40: 0.4397 (0.5059)  loss_n_60: 0.5828 (0.6139)  loss_n_80: 0.6313 (0.6633)  loss_n_100: 0.7018 (0.7296)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [380/845]  eta: 0:02:36  loss: 2.3627 (2.5165)  loss_n_40: 0.4526 (0.5086)  loss_n_60: 0.6036 (0.6147)  loss_n_80: 0.6118 (0.6638)  loss_n_100: 0.6546 (0.7293)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:11]  [390/845]  eta: 0:02:32  loss: 2.3098 (2.5159)  loss_n_40: 0.4588 (0.5107)  loss_n_60: 0.6036 (0.6140)  loss_n_80: 0.6217 (0.6628)  loss_n_100: 0.6622 (0.7283)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [400/845]  eta: 0:02:29  loss: 2.4489 (2.5135)  loss_n_40: 0.4753 (0.5099)  loss_n_60: 0.5977 (0.6132)  loss_n_80: 0.6439 (0.6622)  loss_n_100: 0.6979 (0.7282)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [410/845]  eta: 0:02:25  loss: 2.3938 (2.5106)  loss_n_40: 0.4621 (0.5090)  loss_n_60: 0.5977 (0.6126)  loss_n_80: 0.6439 (0.6616)  loss_n_100: 0.6979 (0.7273)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [420/845]  eta: 0:02:22  loss: 2.2531 (2.5080)  loss_n_40: 0.4439 (0.5080)  loss_n_60: 0.5891 (0.6126)  loss_n_80: 0.5855 (0.6611)  loss_n_100: 0.6397 (0.7262)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [430/845]  eta: 0:02:19  loss: 2.2387 (2.5082)  loss_n_40: 0.4136 (0.5065)  loss_n_60: 0.5699 (0.6126)  loss_n_80: 0.6235 (0.6619)  loss_n_100: 0.6610 (0.7270)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [440/845]  eta: 0:02:15  loss: 2.4916 (2.5096)  loss_n_40: 0.4406 (0.5061)  loss_n_60: 0.5997 (0.6132)  loss_n_80: 0.6751 (0.6624)  loss_n_100: 0.7723 (0.7278)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [450/845]  eta: 0:02:12  loss: 2.4660 (2.5043)  loss_n_40: 0.4406 (0.5060)  loss_n_60: 0.6034 (0.6120)  loss_n_80: 0.6407 (0.6605)  loss_n_100: 0.7256 (0.7256)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [460/845]  eta: 0:02:09  loss: 2.2673 (2.5014)  loss_n_40: 0.4121 (0.5050)  loss_n_60: 0.5718 (0.6116)  loss_n_80: 0.6159 (0.6598)  loss_n_100: 0.6409 (0.7248)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [470/845]  eta: 0:02:05  loss: 2.3904 (2.5050)  loss_n_40: 0.4312 (0.5047)  loss_n_60: 0.5926 (0.6119)  loss_n_80: 0.6584 (0.6617)  loss_n_100: 0.7487 (0.7266)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [480/845]  eta: 0:02:02  loss: 2.5628 (2.5044)  loss_n_40: 0.4265 (0.5033)  loss_n_60: 0.6167 (0.6122)  loss_n_80: 0.6646 (0.6619)  loss_n_100: 0.7535 (0.7269)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [490/845]  eta: 0:01:59  loss: 2.5104 (2.5069)  loss_n_40: 0.4271 (0.5039)  loss_n_60: 0.6123 (0.6127)  loss_n_80: 0.6831 (0.6624)  loss_n_100: 0.7826 (0.7278)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [500/845]  eta: 0:01:55  loss: 2.4993 (2.5103)  loss_n_40: 0.4273 (0.5040)  loss_n_60: 0.5977 (0.6132)  loss_n_80: 0.6434 (0.6638)  loss_n_100: 0.7390 (0.7291)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [510/845]  eta: 0:01:52  loss: 2.3347 (2.5102)  loss_n_40: 0.4289 (0.5038)  loss_n_60: 0.6009 (0.6135)  loss_n_80: 0.6434 (0.6640)  loss_n_100: 0.7040 (0.7288)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [520/845]  eta: 0:01:49  loss: 2.4109 (2.5128)  loss_n_40: 0.4511 (0.5036)  loss_n_60: 0.6068 (0.6138)  loss_n_80: 0.6556 (0.6653)  loss_n_100: 0.7121 (0.7300)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [530/845]  eta: 0:01:45  loss: 2.3921 (2.5095)  loss_n_40: 0.4609 (0.5024)  loss_n_60: 0.6068 (0.6135)  loss_n_80: 0.6459 (0.6644)  loss_n_100: 0.7121 (0.7291)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [540/845]  eta: 0:01:42  loss: 2.3919 (2.5090)  loss_n_40: 0.4567 (0.5028)  loss_n_60: 0.6171 (0.6133)  loss_n_80: 0.6300 (0.6643)  loss_n_100: 0.6971 (0.7286)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [550/845]  eta: 0:01:38  loss: 2.4615 (2.5130)  loss_n_40: 0.4567 (0.5058)  loss_n_60: 0.6085 (0.6134)  loss_n_80: 0.6583 (0.6648)  loss_n_100: 0.7073 (0.7288)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [560/845]  eta: 0:01:35  loss: 2.3273 (2.5094)  loss_n_40: 0.4535 (0.5052)  loss_n_60: 0.5936 (0.6128)  loss_n_80: 0.6217 (0.6636)  loss_n_100: 0.6745 (0.7276)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [570/845]  eta: 0:01:32  loss: 2.3002 (2.5067)  loss_n_40: 0.4420 (0.5046)  loss_n_60: 0.5936 (0.6128)  loss_n_80: 0.6060 (0.6626)  loss_n_100: 0.6807 (0.7266)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3351  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:11]  [580/845]  eta: 0:01:28  loss: 2.4483 (2.5058)  loss_n_40: 0.4490 (0.5036)  loss_n_60: 0.5917 (0.6124)  loss_n_80: 0.6010 (0.6627)  loss_n_100: 0.6862 (0.7270)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:11]  [590/845]  eta: 0:01:25  loss: 2.2284 (2.5016)  loss_n_40: 0.4023 (0.5020)  loss_n_60: 0.5621 (0.6115)  loss_n_80: 0.5978 (0.6618)  loss_n_100: 0.6862 (0.7263)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:11]  [600/845]  eta: 0:01:22  loss: 2.2797 (2.5011)  loss_n_40: 0.4007 (0.5030)  loss_n_60: 0.5563 (0.6110)  loss_n_80: 0.6100 (0.6611)  loss_n_100: 0.6897 (0.7259)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:11]  [610/845]  eta: 0:01:18  loss: 2.2799 (2.4998)  loss_n_40: 0.4265 (0.5037)  loss_n_60: 0.5683 (0.6108)  loss_n_80: 0.6100 (0.6604)  loss_n_100: 0.6817 (0.7247)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [620/845]  eta: 0:01:15  loss: 2.2799 (2.4997)  loss_n_40: 0.4230 (0.5051)  loss_n_60: 0.5890 (0.6109)  loss_n_80: 0.5801 (0.6598)  loss_n_100: 0.6220 (0.7239)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [630/845]  eta: 0:01:12  loss: 2.4630 (2.5000)  loss_n_40: 0.4623 (0.5048)  loss_n_60: 0.6013 (0.6112)  loss_n_80: 0.6481 (0.6598)  loss_n_100: 0.6641 (0.7241)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:11]  [640/845]  eta: 0:01:08  loss: 2.3314 (2.4989)  loss_n_40: 0.4228 (0.5038)  loss_n_60: 0.5936 (0.6114)  loss_n_80: 0.6420 (0.6598)  loss_n_100: 0.7156 (0.7238)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [650/845]  eta: 0:01:05  loss: 2.2979 (2.4960)  loss_n_40: 0.4122 (0.5026)  loss_n_60: 0.5919 (0.6110)  loss_n_80: 0.6306 (0.6590)  loss_n_100: 0.6879 (0.7234)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [660/845]  eta: 0:01:02  loss: 2.5899 (2.4993)  loss_n_40: 0.4769 (0.5039)  loss_n_60: 0.6082 (0.6110)  loss_n_80: 0.6833 (0.6599)  loss_n_100: 0.7244 (0.7244)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [670/845]  eta: 0:00:58  loss: 2.6616 (2.5035)  loss_n_40: 0.4947 (0.5049)  loss_n_60: 0.6163 (0.6114)  loss_n_80: 0.7079 (0.6611)  loss_n_100: 0.7831 (0.7261)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [680/845]  eta: 0:00:55  loss: 2.5160 (2.5072)  loss_n_40: 0.5011 (0.5063)  loss_n_60: 0.6319 (0.6126)  loss_n_80: 0.6545 (0.6615)  loss_n_100: 0.7345 (0.7267)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3350  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [690/845]  eta: 0:00:51  loss: 2.3560 (2.5074)  loss_n_40: 0.4576 (0.5067)  loss_n_60: 0.6319 (0.6125)  loss_n_80: 0.6419 (0.6616)  loss_n_100: 0.7125 (0.7265)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [700/845]  eta: 0:00:48  loss: 2.4815 (2.5073)  loss_n_40: 0.4275 (0.5059)  loss_n_60: 0.5784 (0.6127)  loss_n_80: 0.6688 (0.6619)  loss_n_100: 0.7228 (0.7268)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [710/845]  eta: 0:00:45  loss: 2.3592 (2.5078)  loss_n_40: 0.4302 (0.5064)  loss_n_60: 0.5808 (0.6125)  loss_n_80: 0.6506 (0.6620)  loss_n_100: 0.6929 (0.7269)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0001)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [720/845]  eta: 0:00:41  loss: 2.2407 (2.5111)  loss_n_40: 0.4336 (0.5074)  loss_n_60: 0.5750 (0.6132)  loss_n_80: 0.5975 (0.6629)  loss_n_100: 0.6839 (0.7276)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [730/845]  eta: 0:00:38  loss: 2.3266 (2.5125)  loss_n_40: 0.4323 (0.5085)  loss_n_60: 0.6060 (0.6137)  loss_n_80: 0.6160 (0.6630)  loss_n_100: 0.6624 (0.7271)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [740/845]  eta: 0:00:35  loss: 2.3834 (2.5108)  loss_n_40: 0.4242 (0.5077)  loss_n_60: 0.5852 (0.6132)  loss_n_80: 0.6422 (0.6628)  loss_n_100: 0.6624 (0.7270)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [750/845]  eta: 0:00:31  loss: 2.3056 (2.5066)  loss_n_40: 0.4105 (0.5063)  loss_n_60: 0.5321 (0.6124)  loss_n_80: 0.6285 (0.6619)  loss_n_100: 0.6770 (0.7259)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [760/845]  eta: 0:00:28  loss: 2.3582 (2.5076)  loss_n_40: 0.4289 (0.5064)  loss_n_60: 0.5783 (0.6125)  loss_n_80: 0.6285 (0.6624)  loss_n_100: 0.7024 (0.7263)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [770/845]  eta: 0:00:25  loss: 2.5955 (2.5082)  loss_n_40: 0.4660 (0.5059)  loss_n_60: 0.6196 (0.6127)  loss_n_80: 0.6937 (0.6628)  loss_n_100: 0.7364 (0.7267)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [780/845]  eta: 0:00:21  loss: 2.8396 (2.5146)  loss_n_40: 0.5502 (0.5072)  loss_n_60: 0.6715 (0.6137)  loss_n_80: 0.7469 (0.6649)  loss_n_100: 0.8254 (0.7287)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [790/845]  eta: 0:00:18  loss: 2.8635 (2.5156)  loss_n_40: 0.5480 (0.5069)  loss_n_60: 0.6854 (0.6141)  loss_n_80: 0.7469 (0.6654)  loss_n_100: 0.7927 (0.7292)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [800/845]  eta: 0:00:15  loss: 2.6400 (2.5198)  loss_n_40: 0.4594 (0.5102)  loss_n_60: 0.6415 (0.6144)  loss_n_80: 0.6867 (0.6657)  loss_n_100: 0.7514 (0.7294)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [810/845]  eta: 0:00:11  loss: 2.5136 (2.5193)  loss_n_40: 0.4195 (0.5106)  loss_n_60: 0.6182 (0.6140)  loss_n_80: 0.6332 (0.6655)  loss_n_100: 0.7071 (0.7292)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [820/845]  eta: 0:00:08  loss: 2.3566 (2.5211)  loss_n_40: 0.4252 (0.5118)  loss_n_60: 0.5839 (0.6147)  loss_n_80: 0.6297 (0.6654)  loss_n_100: 0.6758 (0.7291)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [830/845]  eta: 0:00:05  loss: 2.3410 (2.5203)  loss_n_40: 0.4128 (0.5122)  loss_n_60: 0.5969 (0.6147)  loss_n_80: 0.6208 (0.6650)  loss_n_100: 0.6430 (0.7284)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [840/845]  eta: 0:00:01  loss: 2.3076 (2.5189)  loss_n_40: 0.4128 (0.5114)  loss_n_60: 0.6021 (0.6145)  loss_n_80: 0.6208 (0.6648)  loss_n_100: 0.6430 (0.7282)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11]  [844/845]  eta: 0:00:00  loss: 2.3076 (2.5181)  loss_n_40: 0.4128 (0.5111)  loss_n_60: 0.6021 (0.6144)  loss_n_80: 0.6214 (0.6646)  loss_n_100: 0.6700 (0.7280)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:11] Total time: 0:04:43 (0.3353 s / it)\n",
      "Averaged stats: loss: 2.3076 (2.5181)  loss_n_40: 0.4128 (0.5111)  loss_n_60: 0.6021 (0.6144)  loss_n_80: 0.6214 (0.6646)  loss_n_100: 0.6700 (0.7280)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_11_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 0.728%\n",
      "Min loss_n_100: 0.575\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:12]  [   0/1724]  eta: 1:59:32  lr: 0.000200  loss: 2.7220 (2.7220)  loss_n_40: 0.4621 (0.4621)  loss_n_60: 0.6906 (0.6906)  loss_n_80: 0.7587 (0.7587)  loss_n_100: 0.8105 (0.8105)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1607  data: 0.4016  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [  10/1724]  eta: 1:52:36  lr: 0.000200  loss: 2.1824 (2.3529)  loss_n_40: 0.4639 (0.4906)  loss_n_60: 0.5608 (0.5821)  loss_n_80: 0.5631 (0.6134)  loss_n_100: 0.6187 (0.6668)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9421  data: 0.0367  max mem: 46473\n",
      "Train: [epoch:12]  [  20/1724]  eta: 1:51:41  lr: 0.000200  loss: 2.1536 (2.2850)  loss_n_40: 0.4639 (0.4921)  loss_n_60: 0.5418 (0.5668)  loss_n_80: 0.5591 (0.5820)  loss_n_100: 0.5973 (0.6442)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9213  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [  30/1724]  eta: 1:50:55  lr: 0.000200  loss: 2.0554 (2.2016)  loss_n_40: 0.4391 (0.4856)  loss_n_60: 0.5112 (0.5429)  loss_n_80: 0.5017 (0.5560)  loss_n_100: 0.5765 (0.6171)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [  40/1724]  eta: 1:50:13  lr: 0.000200  loss: 1.9698 (2.1532)  loss_n_40: 0.4202 (0.4742)  loss_n_60: 0.4780 (0.5292)  loss_n_80: 0.5017 (0.5455)  loss_n_100: 0.5689 (0.6043)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9215  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [  50/1724]  eta: 1:49:32  lr: 0.000200  loss: 2.2003 (2.3595)  loss_n_40: 0.4553 (0.4878)  loss_n_60: 0.5496 (0.5547)  loss_n_80: 0.5660 (0.5729)  loss_n_100: 0.6145 (0.6343)  triple_100: 0.0000 (0.0115)  triple_80: 0.0000 (0.0367)  triple_60: 0.0000 (0.0466)  triple_40: 0.0000 (0.0149)  time: 3.9213  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [  60/1724]  eta: 1:48:51  lr: 0.000200  loss: 2.9525 (2.5298)  loss_n_40: 0.6142 (0.5260)  loss_n_60: 0.7034 (0.5840)  loss_n_80: 0.7322 (0.6108)  loss_n_100: 0.8131 (0.6770)  triple_100: 0.0000 (0.0096)  triple_80: 0.0000 (0.0434)  triple_60: 0.0000 (0.0665)  triple_40: 0.0000 (0.0124)  time: 3.9212  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [  70/1724]  eta: 1:48:11  lr: 0.000200  loss: 2.8621 (2.5683)  loss_n_40: 0.6142 (0.5396)  loss_n_60: 0.6533 (0.5930)  loss_n_80: 0.7322 (0.6262)  loss_n_100: 0.8405 (0.6961)  triple_100: 0.0000 (0.0083)  triple_80: 0.0000 (0.0373)  triple_60: 0.0000 (0.0572)  triple_40: 0.0000 (0.0107)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [  80/1724]  eta: 1:47:31  lr: 0.000200  loss: 2.7148 (2.5913)  loss_n_40: 0.5750 (0.5528)  loss_n_60: 0.6143 (0.6012)  loss_n_80: 0.6855 (0.6342)  loss_n_100: 0.7727 (0.7037)  triple_100: 0.0000 (0.0073)  triple_80: 0.0000 (0.0327)  triple_60: 0.0000 (0.0501)  triple_40: 0.0000 (0.0094)  time: 3.9212  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [  90/1724]  eta: 1:46:51  lr: 0.000200  loss: 2.4315 (2.5596)  loss_n_40: 0.5105 (0.5473)  loss_n_60: 0.5665 (0.5980)  loss_n_80: 0.6423 (0.6291)  loss_n_100: 0.6983 (0.6968)  triple_100: 0.0000 (0.0065)  triple_80: 0.0000 (0.0291)  triple_60: 0.0000 (0.0446)  triple_40: 0.0000 (0.0083)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 100/1724]  eta: 1:46:11  lr: 0.000200  loss: 2.3034 (2.5369)  loss_n_40: 0.4907 (0.5458)  loss_n_60: 0.5646 (0.5952)  loss_n_80: 0.5758 (0.6239)  loss_n_100: 0.6548 (0.6924)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.0402)  triple_40: 0.0000 (0.0075)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 110/1724]  eta: 1:45:32  lr: 0.000200  loss: 2.3034 (2.5095)  loss_n_40: 0.4993 (0.5480)  loss_n_60: 0.5517 (0.5919)  loss_n_80: 0.5480 (0.6156)  loss_n_100: 0.6101 (0.6814)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0238)  triple_60: 0.0000 (0.0366)  triple_40: 0.0000 (0.0068)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 120/1724]  eta: 1:44:52  lr: 0.000200  loss: 1.9691 (2.4603)  loss_n_40: 0.4476 (0.5381)  loss_n_60: 0.4871 (0.5822)  loss_n_80: 0.4967 (0.6041)  loss_n_100: 0.5443 (0.6693)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0219)  triple_60: 0.0000 (0.0335)  triple_40: 0.0000 (0.0063)  time: 3.9221  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 130/1724]  eta: 1:44:13  lr: 0.000200  loss: 1.8356 (2.4134)  loss_n_40: 0.3963 (0.5289)  loss_n_60: 0.4641 (0.5729)  loss_n_80: 0.4662 (0.5929)  loss_n_100: 0.5083 (0.6572)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0202)  triple_60: 0.0000 (0.0310)  triple_40: 0.0000 (0.0058)  time: 3.9226  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 140/1724]  eta: 1:43:34  lr: 0.000200  loss: 1.7959 (2.3968)  loss_n_40: 0.3892 (0.5227)  loss_n_60: 0.4492 (0.5653)  loss_n_80: 0.4399 (0.5843)  loss_n_100: 0.5034 (0.6480)  triple_100: 0.0000 (0.0093)  triple_80: 0.0000 (0.0224)  triple_60: 0.0000 (0.0305)  triple_40: 0.0000 (0.0143)  time: 3.9227  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 150/1724]  eta: 1:42:54  lr: 0.000200  loss: 1.9885 (2.3915)  loss_n_40: 0.4209 (0.5203)  loss_n_60: 0.4867 (0.5655)  loss_n_80: 0.5001 (0.5844)  loss_n_100: 0.5395 (0.6474)  triple_100: 0.0000 (0.0087)  triple_80: 0.0000 (0.0210)  triple_60: 0.0000 (0.0310)  triple_40: 0.0000 (0.0134)  time: 3.9222  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 160/1724]  eta: 1:42:15  lr: 0.000200  loss: 2.4341 (2.4070)  loss_n_40: 0.5259 (0.5229)  loss_n_60: 0.6027 (0.5704)  loss_n_80: 0.5980 (0.5897)  loss_n_100: 0.6594 (0.6542)  triple_100: 0.0000 (0.0085)  triple_80: 0.0000 (0.0197)  triple_60: 0.0000 (0.0291)  triple_40: 0.0000 (0.0125)  time: 3.9218  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 170/1724]  eta: 1:41:36  lr: 0.000200  loss: 2.4901 (2.4157)  loss_n_40: 0.5451 (0.5222)  loss_n_60: 0.6114 (0.5712)  loss_n_80: 0.6386 (0.5919)  loss_n_100: 0.7043 (0.6557)  triple_100: 0.0000 (0.0105)  triple_80: 0.0000 (0.0241)  triple_60: 0.0000 (0.0282)  triple_40: 0.0000 (0.0118)  time: 3.9218  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 180/1724]  eta: 1:40:56  lr: 0.000200  loss: 2.3585 (2.4092)  loss_n_40: 0.5102 (0.5226)  loss_n_60: 0.5539 (0.5703)  loss_n_80: 0.6147 (0.5917)  loss_n_100: 0.6398 (0.6542)  triple_100: 0.0000 (0.0099)  triple_80: 0.0000 (0.0228)  triple_60: 0.0000 (0.0266)  triple_40: 0.0000 (0.0111)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 190/1724]  eta: 1:40:17  lr: 0.000200  loss: 2.1389 (2.3900)  loss_n_40: 0.4427 (0.5187)  loss_n_60: 0.5215 (0.5667)  loss_n_80: 0.5406 (0.5878)  loss_n_100: 0.5909 (0.6500)  triple_100: 0.0000 (0.0094)  triple_80: 0.0000 (0.0216)  triple_60: 0.0000 (0.0252)  triple_40: 0.0000 (0.0106)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 200/1724]  eta: 1:39:38  lr: 0.000200  loss: 2.0555 (2.3876)  loss_n_40: 0.4522 (0.5189)  loss_n_60: 0.5097 (0.5667)  loss_n_80: 0.5170 (0.5862)  loss_n_100: 0.5833 (0.6479)  triple_100: 0.0000 (0.0105)  triple_80: 0.0000 (0.0218)  triple_60: 0.0000 (0.0255)  triple_40: 0.0000 (0.0100)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 210/1724]  eta: 1:38:59  lr: 0.000200  loss: 1.9190 (2.3672)  loss_n_40: 0.4428 (0.5162)  loss_n_60: 0.4970 (0.5632)  loss_n_80: 0.4753 (0.5809)  loss_n_100: 0.5379 (0.6423)  triple_100: 0.0000 (0.0100)  triple_80: 0.0000 (0.0208)  triple_60: 0.0000 (0.0243)  triple_40: 0.0000 (0.0096)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 220/1724]  eta: 1:38:19  lr: 0.000200  loss: 1.9395 (2.3548)  loss_n_40: 0.4272 (0.5145)  loss_n_60: 0.4970 (0.5607)  loss_n_80: 0.4753 (0.5767)  loss_n_100: 0.5330 (0.6376)  triple_100: 0.0000 (0.0096)  triple_80: 0.0000 (0.0198)  triple_60: 0.0000 (0.0239)  triple_40: 0.0000 (0.0119)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 230/1724]  eta: 1:37:40  lr: 0.000200  loss: 2.0107 (2.3387)  loss_n_40: 0.4257 (0.5104)  loss_n_60: 0.5034 (0.5571)  loss_n_80: 0.4862 (0.5727)  loss_n_100: 0.5483 (0.6337)  triple_100: 0.0000 (0.0092)  triple_80: 0.0000 (0.0196)  triple_60: 0.0000 (0.0230)  triple_40: 0.0000 (0.0131)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 240/1724]  eta: 1:37:01  lr: 0.000200  loss: 1.9493 (2.3256)  loss_n_40: 0.4041 (0.5070)  loss_n_60: 0.4701 (0.5540)  loss_n_80: 0.5019 (0.5708)  loss_n_100: 0.5535 (0.6316)  triple_100: 0.0000 (0.0088)  triple_80: 0.0000 (0.0188)  triple_60: 0.0000 (0.0220)  triple_40: 0.0000 (0.0125)  time: 3.9221  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [ 250/1724]  eta: 1:36:22  lr: 0.000200  loss: 1.8719 (2.3051)  loss_n_40: 0.3815 (0.5023)  loss_n_60: 0.4473 (0.5492)  loss_n_80: 0.4918 (0.5668)  loss_n_100: 0.5412 (0.6271)  triple_100: 0.0000 (0.0084)  triple_80: 0.0000 (0.0180)  triple_60: 0.0000 (0.0211)  triple_40: 0.0000 (0.0120)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 260/1724]  eta: 1:35:42  lr: 0.000200  loss: 1.8722 (2.2998)  loss_n_40: 0.3588 (0.5000)  loss_n_60: 0.4437 (0.5474)  loss_n_80: 0.4955 (0.5653)  loss_n_100: 0.5423 (0.6253)  triple_100: 0.0000 (0.0093)  triple_80: 0.0000 (0.0187)  triple_60: 0.0000 (0.0222)  triple_40: 0.0000 (0.0116)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 270/1724]  eta: 1:35:03  lr: 0.000200  loss: 1.8976 (2.2824)  loss_n_40: 0.3921 (0.4975)  loss_n_60: 0.4646 (0.5439)  loss_n_80: 0.4955 (0.5609)  loss_n_100: 0.5359 (0.6205)  triple_100: 0.0000 (0.0090)  triple_80: 0.0000 (0.0181)  triple_60: 0.0000 (0.0214)  triple_40: 0.0000 (0.0111)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 280/1724]  eta: 1:34:24  lr: 0.000200  loss: 1.7518 (2.2645)  loss_n_40: 0.3921 (0.4939)  loss_n_60: 0.4322 (0.5401)  loss_n_80: 0.4250 (0.5568)  loss_n_100: 0.4838 (0.6162)  triple_100: 0.0000 (0.0087)  triple_80: 0.0000 (0.0174)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0107)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 290/1724]  eta: 1:33:45  lr: 0.000200  loss: 1.7837 (2.2895)  loss_n_40: 0.4070 (0.4943)  loss_n_60: 0.4409 (0.5390)  loss_n_80: 0.4416 (0.5556)  loss_n_100: 0.5073 (0.6151)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0218)  triple_60: 0.0000 (0.0260)  triple_40: 0.0000 (0.0228)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 300/1724]  eta: 1:33:05  lr: 0.000200  loss: 2.4951 (2.3010)  loss_n_40: 0.5849 (0.4990)  loss_n_60: 0.5626 (0.5412)  loss_n_80: 0.5971 (0.5586)  loss_n_100: 0.6821 (0.6195)  triple_100: 0.0000 (0.0144)  triple_80: 0.0000 (0.0211)  triple_60: 0.0000 (0.0252)  triple_40: 0.0000 (0.0220)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 310/1724]  eta: 1:32:26  lr: 0.000200  loss: 2.5015 (2.3054)  loss_n_40: 0.5849 (0.5013)  loss_n_60: 0.5742 (0.5420)  loss_n_80: 0.6183 (0.5599)  loss_n_100: 0.7086 (0.6217)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0204)  triple_60: 0.0000 (0.0243)  triple_40: 0.0000 (0.0218)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 320/1724]  eta: 1:31:47  lr: 0.000200  loss: 2.3377 (2.3076)  loss_n_40: 0.5357 (0.5037)  loss_n_60: 0.5439 (0.5421)  loss_n_80: 0.5849 (0.5605)  loss_n_100: 0.6673 (0.6233)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0198)  triple_60: 0.0000 (0.0236)  triple_40: 0.0000 (0.0211)  time: 3.9211  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 330/1724]  eta: 1:31:08  lr: 0.000200  loss: 2.2498 (2.3020)  loss_n_40: 0.5268 (0.5040)  loss_n_60: 0.5181 (0.5406)  loss_n_80: 0.5513 (0.5591)  loss_n_100: 0.6546 (0.6227)  triple_100: 0.0000 (0.0131)  triple_80: 0.0000 (0.0192)  triple_60: 0.0000 (0.0229)  triple_40: 0.0000 (0.0205)  time: 3.9227  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 340/1724]  eta: 1:30:28  lr: 0.000200  loss: 2.1061 (2.2938)  loss_n_40: 0.5046 (0.5043)  loss_n_60: 0.4738 (0.5386)  loss_n_80: 0.4951 (0.5568)  loss_n_100: 0.5780 (0.6207)  triple_100: 0.0000 (0.0127)  triple_80: 0.0000 (0.0186)  triple_60: 0.0000 (0.0222)  triple_40: 0.0000 (0.0199)  time: 3.9237  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 350/1724]  eta: 1:29:49  lr: 0.000200  loss: 1.9729 (2.2871)  loss_n_40: 0.4328 (0.5039)  loss_n_60: 0.4560 (0.5372)  loss_n_80: 0.4891 (0.5552)  loss_n_100: 0.5737 (0.6195)  triple_100: 0.0000 (0.0123)  triple_80: 0.0000 (0.0181)  triple_60: 0.0000 (0.0216)  triple_40: 0.0000 (0.0193)  time: 3.9226  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 360/1724]  eta: 1:29:10  lr: 0.000200  loss: 1.9245 (2.2767)  loss_n_40: 0.4328 (0.5023)  loss_n_60: 0.4611 (0.5351)  loss_n_80: 0.4884 (0.5528)  loss_n_100: 0.5453 (0.6171)  triple_100: 0.0000 (0.0120)  triple_80: 0.0000 (0.0176)  triple_60: 0.0000 (0.0210)  triple_40: 0.0000 (0.0188)  time: 3.9228  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 370/1724]  eta: 1:28:31  lr: 0.000200  loss: 1.8968 (2.2659)  loss_n_40: 0.4296 (0.5007)  loss_n_60: 0.4611 (0.5328)  loss_n_80: 0.4547 (0.5504)  loss_n_100: 0.5210 (0.6145)  triple_100: 0.0000 (0.0117)  triple_80: 0.0000 (0.0171)  triple_60: 0.0000 (0.0204)  triple_40: 0.0000 (0.0183)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 380/1724]  eta: 1:27:52  lr: 0.000200  loss: 1.7714 (2.2532)  loss_n_40: 0.3877 (0.4993)  loss_n_60: 0.4120 (0.5300)  loss_n_80: 0.4319 (0.5472)  loss_n_100: 0.4772 (0.6110)  triple_100: 0.0000 (0.0114)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0178)  time: 3.9240  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 390/1724]  eta: 1:27:12  lr: 0.000200  loss: 1.7223 (2.2396)  loss_n_40: 0.3828 (0.4967)  loss_n_60: 0.4055 (0.5271)  loss_n_80: 0.4276 (0.5441)  loss_n_100: 0.4723 (0.6077)  triple_100: 0.0000 (0.0111)  triple_80: 0.0000 (0.0162)  triple_60: 0.0000 (0.0194)  triple_40: 0.0000 (0.0173)  time: 3.9233  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 400/1724]  eta: 1:26:33  lr: 0.000200  loss: 1.7377 (2.2265)  loss_n_40: 0.3927 (0.4946)  loss_n_60: 0.4119 (0.5242)  loss_n_80: 0.4276 (0.5411)  loss_n_100: 0.4804 (0.6043)  triple_100: 0.0000 (0.0108)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0169)  time: 3.9225  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 410/1724]  eta: 1:25:54  lr: 0.000200  loss: 1.7543 (2.2158)  loss_n_40: 0.3927 (0.4928)  loss_n_60: 0.4119 (0.5216)  loss_n_80: 0.4125 (0.5383)  loss_n_100: 0.4755 (0.6011)  triple_100: 0.0000 (0.0105)  triple_80: 0.0000 (0.0154)  triple_60: 0.0000 (0.0184)  triple_40: 0.0000 (0.0176)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 420/1724]  eta: 1:25:15  lr: 0.000200  loss: 1.6507 (2.2039)  loss_n_40: 0.3852 (0.4908)  loss_n_60: 0.4044 (0.5189)  loss_n_80: 0.4074 (0.5356)  loss_n_100: 0.4611 (0.5981)  triple_100: 0.0000 (0.0103)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0180)  triple_40: 0.0000 (0.0172)  time: 3.9232  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 430/1724]  eta: 1:24:36  lr: 0.000200  loss: 1.6507 (2.1935)  loss_n_40: 0.4019 (0.4892)  loss_n_60: 0.4044 (0.5166)  loss_n_80: 0.4044 (0.5332)  loss_n_100: 0.4506 (0.5954)  triple_100: 0.0000 (0.0101)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0176)  triple_40: 0.0000 (0.0168)  time: 3.9233  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 440/1724]  eta: 1:23:56  lr: 0.000200  loss: 1.6143 (2.1806)  loss_n_40: 0.3855 (0.4871)  loss_n_60: 0.3768 (0.5137)  loss_n_80: 0.3978 (0.5302)  loss_n_100: 0.4225 (0.5919)  triple_100: 0.0000 (0.0098)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0172)  triple_40: 0.0000 (0.0164)  time: 3.9238  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 450/1724]  eta: 1:23:17  lr: 0.000200  loss: 1.5152 (2.1723)  loss_n_40: 0.3346 (0.4848)  loss_n_60: 0.3634 (0.5109)  loss_n_80: 0.3821 (0.5276)  loss_n_100: 0.4214 (0.5888)  triple_100: 0.0000 (0.0096)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0198)  time: 3.9246  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 460/1724]  eta: 1:22:38  lr: 0.000200  loss: 1.5257 (2.1640)  loss_n_40: 0.3564 (0.4833)  loss_n_60: 0.3634 (0.5092)  loss_n_80: 0.3851 (0.5259)  loss_n_100: 0.4366 (0.5867)  triple_100: 0.0000 (0.0094)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0194)  time: 3.9252  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 470/1724]  eta: 1:21:59  lr: 0.000200  loss: 1.6795 (2.1523)  loss_n_40: 0.3604 (0.4812)  loss_n_60: 0.4148 (0.5065)  loss_n_80: 0.4251 (0.5232)  loss_n_100: 0.4583 (0.5835)  triple_100: 0.0000 (0.0092)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0161)  triple_40: 0.0000 (0.0191)  time: 3.9258  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 480/1724]  eta: 1:21:20  lr: 0.000200  loss: 1.6433 (2.1413)  loss_n_40: 0.3571 (0.4789)  loss_n_60: 0.3901 (0.5041)  loss_n_80: 0.4032 (0.5208)  loss_n_100: 0.4565 (0.5809)  triple_100: 0.0000 (0.0090)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0187)  time: 3.9251  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [ 490/1724]  eta: 1:20:40  lr: 0.000200  loss: 1.5980 (2.1383)  loss_n_40: 0.3648 (0.4773)  loss_n_60: 0.3809 (0.5018)  loss_n_80: 0.4013 (0.5187)  loss_n_100: 0.4560 (0.5787)  triple_100: 0.0000 (0.0112)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0187)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 500/1724]  eta: 1:20:01  lr: 0.000200  loss: 1.8891 (2.1502)  loss_n_40: 0.4035 (0.4763)  loss_n_60: 0.4320 (0.5018)  loss_n_80: 0.4725 (0.5200)  loss_n_100: 0.5601 (0.5811)  triple_100: 0.0000 (0.0160)  triple_80: 0.0000 (0.0181)  triple_60: 0.0000 (0.0185)  triple_40: 0.0000 (0.0184)  time: 3.9247  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 510/1724]  eta: 1:19:22  lr: 0.000200  loss: 2.8246 (2.1801)  loss_n_40: 0.4877 (0.4792)  loss_n_60: 0.5579 (0.5068)  loss_n_80: 0.7032 (0.5272)  loss_n_100: 0.8204 (0.5890)  triple_100: 0.0000 (0.0172)  triple_80: 0.0000 (0.0200)  triple_60: 0.0000 (0.0216)  triple_40: 0.0000 (0.0191)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 520/1724]  eta: 1:18:43  lr: 0.000200  loss: 3.1220 (2.1951)  loss_n_40: 0.5911 (0.4816)  loss_n_60: 0.7372 (0.5111)  loss_n_80: 0.7695 (0.5316)  loss_n_100: 0.8694 (0.5941)  triple_100: 0.0000 (0.0169)  triple_80: 0.0000 (0.0197)  triple_60: 0.0000 (0.0214)  triple_40: 0.0000 (0.0187)  time: 3.9218  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 530/1724]  eta: 1:18:04  lr: 0.000200  loss: 2.8006 (2.2047)  loss_n_40: 0.5828 (0.4847)  loss_n_60: 0.6650 (0.5131)  loss_n_80: 0.7039 (0.5335)  loss_n_100: 0.7909 (0.5963)  triple_100: 0.0000 (0.0166)  triple_80: 0.0000 (0.0213)  triple_60: 0.0000 (0.0210)  triple_40: 0.0000 (0.0184)  time: 3.9219  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 540/1724]  eta: 1:17:24  lr: 0.000200  loss: 2.3909 (2.2058)  loss_n_40: 0.5092 (0.4854)  loss_n_60: 0.5716 (0.5134)  loss_n_80: 0.5696 (0.5339)  loss_n_100: 0.6777 (0.5970)  triple_100: 0.0000 (0.0163)  triple_80: 0.0000 (0.0213)  triple_60: 0.0000 (0.0206)  triple_40: 0.0000 (0.0180)  time: 3.9224  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 550/1724]  eta: 1:16:45  lr: 0.000200  loss: 1.9996 (2.2009)  loss_n_40: 0.4431 (0.4844)  loss_n_60: 0.4792 (0.5125)  loss_n_80: 0.5065 (0.5329)  loss_n_100: 0.5708 (0.5959)  triple_100: 0.0000 (0.0163)  triple_80: 0.0000 (0.0210)  triple_60: 0.0000 (0.0202)  triple_40: 0.0000 (0.0177)  time: 3.9217  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 560/1724]  eta: 1:16:06  lr: 0.000200  loss: 1.9081 (2.1957)  loss_n_40: 0.4302 (0.4835)  loss_n_60: 0.4639 (0.5115)  loss_n_80: 0.4801 (0.5319)  loss_n_100: 0.5368 (0.5948)  triple_100: 0.0000 (0.0160)  triple_80: 0.0000 (0.0207)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0174)  time: 3.9218  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 570/1724]  eta: 1:15:27  lr: 0.000200  loss: 1.8110 (2.1893)  loss_n_40: 0.3937 (0.4825)  loss_n_60: 0.4291 (0.5102)  loss_n_80: 0.4544 (0.5305)  loss_n_100: 0.5286 (0.5934)  triple_100: 0.0000 (0.0157)  triple_80: 0.0000 (0.0203)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0171)  time: 3.9225  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 580/1724]  eta: 1:14:47  lr: 0.000200  loss: 1.7962 (2.1855)  loss_n_40: 0.4081 (0.4827)  loss_n_60: 0.4291 (0.5093)  loss_n_80: 0.4467 (0.5296)  loss_n_100: 0.5095 (0.5924)  triple_100: 0.0000 (0.0154)  triple_80: 0.0000 (0.0200)  triple_60: 0.0000 (0.0193)  triple_40: 0.0000 (0.0168)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 590/1724]  eta: 1:14:08  lr: 0.000200  loss: 1.7962 (2.1803)  loss_n_40: 0.4092 (0.4815)  loss_n_60: 0.4399 (0.5083)  loss_n_80: 0.4529 (0.5284)  loss_n_100: 0.5015 (0.5911)  triple_100: 0.0000 (0.0159)  triple_80: 0.0000 (0.0198)  triple_60: 0.0000 (0.0190)  triple_40: 0.0000 (0.0165)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 600/1724]  eta: 1:13:29  lr: 0.000200  loss: 1.9359 (2.1797)  loss_n_40: 0.4092 (0.4808)  loss_n_60: 0.4499 (0.5076)  loss_n_80: 0.4753 (0.5277)  loss_n_100: 0.5256 (0.5903)  triple_100: 0.0000 (0.0156)  triple_80: 0.0000 (0.0194)  triple_60: 0.0000 (0.0221)  triple_40: 0.0000 (0.0162)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 610/1724]  eta: 1:12:50  lr: 0.000200  loss: 2.0158 (2.1774)  loss_n_40: 0.4076 (0.4798)  loss_n_60: 0.4838 (0.5073)  loss_n_80: 0.5130 (0.5277)  loss_n_100: 0.5764 (0.5904)  triple_100: 0.0000 (0.0153)  triple_80: 0.0000 (0.0191)  triple_60: 0.0000 (0.0217)  triple_40: 0.0000 (0.0159)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 620/1724]  eta: 1:12:10  lr: 0.000200  loss: 2.0122 (2.1722)  loss_n_40: 0.4054 (0.4789)  loss_n_60: 0.4505 (0.5062)  loss_n_80: 0.5130 (0.5268)  loss_n_100: 0.5732 (0.5894)  triple_100: 0.0000 (0.0151)  triple_80: 0.0000 (0.0188)  triple_60: 0.0000 (0.0214)  triple_40: 0.0000 (0.0157)  time: 3.9235  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 630/1724]  eta: 1:11:31  lr: 0.000200  loss: 1.7144 (2.1664)  loss_n_40: 0.3789 (0.4772)  loss_n_60: 0.4155 (0.5048)  loss_n_80: 0.4297 (0.5255)  loss_n_100: 0.4943 (0.5880)  triple_100: 0.0000 (0.0148)  triple_80: 0.0000 (0.0185)  triple_60: 0.0000 (0.0217)  triple_40: 0.0000 (0.0158)  time: 3.9231  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 640/1724]  eta: 1:10:52  lr: 0.000200  loss: 1.7381 (2.1613)  loss_n_40: 0.3859 (0.4764)  loss_n_60: 0.4214 (0.5037)  loss_n_80: 0.4297 (0.5245)  loss_n_100: 0.4976 (0.5869)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0182)  triple_60: 0.0000 (0.0213)  triple_40: 0.0000 (0.0156)  time: 3.9221  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 650/1724]  eta: 1:10:13  lr: 0.000200  loss: 1.7323 (2.1521)  loss_n_40: 0.3859 (0.4745)  loss_n_60: 0.3964 (0.5017)  loss_n_80: 0.4420 (0.5226)  loss_n_100: 0.4976 (0.5846)  triple_100: 0.0000 (0.0144)  triple_80: 0.0000 (0.0180)  triple_60: 0.0000 (0.0210)  triple_40: 0.0000 (0.0154)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 660/1724]  eta: 1:09:33  lr: 0.000200  loss: 1.8449 (2.1612)  loss_n_40: 0.3959 (0.4752)  loss_n_60: 0.4108 (0.5020)  loss_n_80: 0.4541 (0.5229)  loss_n_100: 0.5261 (0.5852)  triple_100: 0.0000 (0.0151)  triple_80: 0.0000 (0.0194)  triple_60: 0.0000 (0.0222)  triple_40: 0.0000 (0.0191)  time: 3.9221  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 670/1724]  eta: 1:08:54  lr: 0.000200  loss: 2.3662 (2.1688)  loss_n_40: 0.5170 (0.4772)  loss_n_60: 0.5427 (0.5034)  loss_n_80: 0.5847 (0.5249)  loss_n_100: 0.6449 (0.5879)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0191)  triple_60: 0.0000 (0.0219)  triple_40: 0.0000 (0.0195)  time: 3.9227  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 680/1724]  eta: 1:08:15  lr: 0.000200  loss: 2.6685 (2.1766)  loss_n_40: 0.5406 (0.4785)  loss_n_60: 0.5698 (0.5044)  loss_n_80: 0.6568 (0.5270)  loss_n_100: 0.8124 (0.5921)  triple_100: 0.0000 (0.0149)  triple_80: 0.0000 (0.0188)  triple_60: 0.0000 (0.0216)  triple_40: 0.0000 (0.0193)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 690/1724]  eta: 1:07:36  lr: 0.000200  loss: 2.4909 (2.1785)  loss_n_40: 0.5209 (0.4788)  loss_n_60: 0.5250 (0.5044)  loss_n_80: 0.6315 (0.5277)  loss_n_100: 0.7983 (0.5942)  triple_100: 0.0000 (0.0147)  triple_80: 0.0000 (0.0185)  triple_60: 0.0000 (0.0213)  triple_40: 0.0000 (0.0190)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 700/1724]  eta: 1:06:56  lr: 0.000200  loss: 2.2784 (2.1793)  loss_n_40: 0.4862 (0.4788)  loss_n_60: 0.4864 (0.5042)  loss_n_80: 0.5934 (0.5284)  loss_n_100: 0.7067 (0.5955)  triple_100: 0.0000 (0.0145)  triple_80: 0.0000 (0.0183)  triple_60: 0.0000 (0.0210)  triple_40: 0.0000 (0.0187)  time: 3.9232  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 710/1724]  eta: 1:06:17  lr: 0.000200  loss: 2.1880 (2.1777)  loss_n_40: 0.4713 (0.4786)  loss_n_60: 0.4768 (0.5037)  loss_n_80: 0.5698 (0.5284)  loss_n_100: 0.6560 (0.5956)  triple_100: 0.0000 (0.0143)  triple_80: 0.0000 (0.0180)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0184)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 720/1724]  eta: 1:05:38  lr: 0.000200  loss: 1.8971 (2.1730)  loss_n_40: 0.4385 (0.4779)  loss_n_60: 0.4349 (0.5027)  loss_n_80: 0.4729 (0.5275)  loss_n_100: 0.5325 (0.5944)  triple_100: 0.0000 (0.0141)  triple_80: 0.0000 (0.0177)  triple_60: 0.0000 (0.0204)  triple_40: 0.0000 (0.0182)  time: 3.9224  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [ 730/1724]  eta: 1:04:59  lr: 0.000200  loss: 1.8682 (2.1704)  loss_n_40: 0.4041 (0.4773)  loss_n_60: 0.4297 (0.5019)  loss_n_80: 0.4633 (0.5268)  loss_n_100: 0.5184 (0.5937)  triple_100: 0.0000 (0.0142)  triple_80: 0.0000 (0.0177)  triple_60: 0.0000 (0.0209)  triple_40: 0.0000 (0.0179)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 740/1724]  eta: 1:04:20  lr: 0.000200  loss: 1.9113 (2.1671)  loss_n_40: 0.4226 (0.4771)  loss_n_60: 0.4260 (0.5009)  loss_n_80: 0.4637 (0.5261)  loss_n_100: 0.5408 (0.5932)  triple_100: 0.0000 (0.0140)  triple_80: 0.0000 (0.0175)  triple_60: 0.0000 (0.0206)  triple_40: 0.0000 (0.0177)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 750/1724]  eta: 1:03:40  lr: 0.000200  loss: 1.8704 (2.1626)  loss_n_40: 0.4241 (0.4766)  loss_n_60: 0.4179 (0.4998)  loss_n_80: 0.4567 (0.5251)  loss_n_100: 0.5381 (0.5922)  triple_100: 0.0000 (0.0138)  triple_80: 0.0000 (0.0172)  triple_60: 0.0000 (0.0203)  triple_40: 0.0000 (0.0175)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 760/1724]  eta: 1:03:01  lr: 0.000200  loss: 1.7704 (2.1571)  loss_n_40: 0.4000 (0.4756)  loss_n_60: 0.4054 (0.4985)  loss_n_80: 0.4414 (0.5240)  loss_n_100: 0.5125 (0.5910)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0170)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0172)  time: 3.9211  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 770/1724]  eta: 1:02:22  lr: 0.000200  loss: 1.7647 (2.1512)  loss_n_40: 0.3913 (0.4745)  loss_n_60: 0.4005 (0.4973)  loss_n_80: 0.4414 (0.5227)  loss_n_100: 0.5073 (0.5896)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0168)  triple_60: 0.0000 (0.0198)  triple_40: 0.0000 (0.0170)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 780/1724]  eta: 1:01:43  lr: 0.000200  loss: 1.7579 (2.1464)  loss_n_40: 0.3831 (0.4743)  loss_n_60: 0.4005 (0.4962)  loss_n_80: 0.4445 (0.5215)  loss_n_100: 0.4903 (0.5882)  triple_100: 0.0000 (0.0133)  triple_80: 0.0000 (0.0166)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0168)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 790/1724]  eta: 1:01:03  lr: 0.000200  loss: 1.6552 (2.1410)  loss_n_40: 0.3950 (0.4736)  loss_n_60: 0.3883 (0.4949)  loss_n_80: 0.4100 (0.5202)  loss_n_100: 0.4612 (0.5868)  triple_100: 0.0000 (0.0131)  triple_80: 0.0000 (0.0164)  triple_60: 0.0000 (0.0193)  triple_40: 0.0000 (0.0166)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 800/1724]  eta: 1:00:24  lr: 0.000200  loss: 1.6512 (2.1397)  loss_n_40: 0.3849 (0.4731)  loss_n_60: 0.3824 (0.4936)  loss_n_80: 0.3961 (0.5187)  loss_n_100: 0.4612 (0.5854)  triple_100: 0.0000 (0.0130)  triple_80: 0.0000 (0.0168)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0191)  time: 3.9209  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 810/1724]  eta: 0:59:45  lr: 0.000200  loss: 2.1741 (2.1619)  loss_n_40: 0.5395 (0.4747)  loss_n_60: 0.4757 (0.4960)  loss_n_80: 0.5123 (0.5220)  loss_n_100: 0.5285 (0.5894)  triple_100: 0.0000 (0.0208)  triple_80: 0.0000 (0.0186)  triple_60: 0.0000 (0.0216)  triple_40: 0.0000 (0.0189)  time: 3.9216  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 820/1724]  eta: 0:59:06  lr: 0.000200  loss: 3.5937 (2.1821)  loss_n_40: 0.6808 (0.4786)  loss_n_60: 0.7802 (0.5009)  loss_n_80: 0.8935 (0.5279)  loss_n_100: 1.0353 (0.5957)  triple_100: 0.0000 (0.0206)  triple_80: 0.0000 (0.0184)  triple_60: 0.0000 (0.0213)  triple_40: 0.0000 (0.0187)  time: 3.9227  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 830/1724]  eta: 0:58:26  lr: 0.000200  loss: 3.5113 (2.1959)  loss_n_40: 0.7527 (0.4816)  loss_n_60: 0.7986 (0.5041)  loss_n_80: 0.9043 (0.5319)  loss_n_100: 1.0231 (0.6004)  triple_100: 0.0000 (0.0203)  triple_80: 0.0000 (0.0181)  triple_60: 0.0000 (0.0211)  triple_40: 0.0000 (0.0184)  time: 3.9217  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 840/1724]  eta: 0:57:47  lr: 0.000200  loss: 3.0049 (2.2033)  loss_n_40: 0.5607 (0.4823)  loss_n_60: 0.6612 (0.5054)  loss_n_80: 0.7732 (0.5341)  loss_n_100: 0.9308 (0.6036)  triple_100: 0.0000 (0.0201)  triple_80: 0.0000 (0.0180)  triple_60: 0.0000 (0.0210)  triple_40: 0.0000 (0.0188)  time: 3.9220  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 850/1724]  eta: 0:57:08  lr: 0.000200  loss: 2.8919 (2.2253)  loss_n_40: 0.5008 (0.4846)  loss_n_60: 0.6501 (0.5084)  loss_n_80: 0.7680 (0.5385)  loss_n_100: 0.9045 (0.6088)  triple_100: 0.0000 (0.0233)  triple_80: 0.0000 (0.0210)  triple_60: 0.0000 (0.0208)  triple_40: 0.0000 (0.0198)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 860/1724]  eta: 0:56:29  lr: 0.000200  loss: 4.3073 (2.2536)  loss_n_40: 0.8170 (0.4896)  loss_n_60: 0.9472 (0.5146)  loss_n_80: 1.1354 (0.5466)  loss_n_100: 1.2452 (0.6185)  triple_100: 0.0000 (0.0234)  triple_80: 0.0000 (0.0208)  triple_60: 0.0000 (0.0206)  triple_40: 0.0000 (0.0196)  time: 3.9223  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [ 870/1724]  eta: 0:55:49  lr: 0.000200  loss: 4.2639 (2.2732)  loss_n_40: 0.8271 (0.4928)  loss_n_60: 0.9927 (0.5192)  loss_n_80: 1.1405 (0.5526)  loss_n_100: 1.2862 (0.6253)  triple_100: 0.0000 (0.0231)  triple_80: 0.0000 (0.0205)  triple_60: 0.0000 (0.0204)  triple_40: 0.0000 (0.0194)  time: 3.9214  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 880/1724]  eta: 0:55:10  lr: 0.000200  loss: 3.4643 (2.2847)  loss_n_40: 0.7264 (0.4954)  loss_n_60: 0.7864 (0.5218)  loss_n_80: 0.9304 (0.5560)  loss_n_100: 1.0407 (0.6291)  triple_100: 0.0000 (0.0228)  triple_80: 0.0000 (0.0203)  triple_60: 0.0000 (0.0201)  triple_40: 0.0000 (0.0192)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 890/1724]  eta: 0:54:31  lr: 0.000200  loss: 2.9593 (2.2887)  loss_n_40: 0.5925 (0.4961)  loss_n_60: 0.6608 (0.5227)  loss_n_80: 0.7869 (0.5575)  loss_n_100: 0.8972 (0.6309)  triple_100: 0.0000 (0.0226)  triple_80: 0.0000 (0.0201)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0189)  time: 3.9230  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 900/1724]  eta: 0:53:52  lr: 0.000200  loss: 2.4603 (2.2906)  loss_n_40: 0.4645 (0.4961)  loss_n_60: 0.5594 (0.5230)  loss_n_80: 0.6300 (0.5582)  loss_n_100: 0.6968 (0.6316)  triple_100: 0.0000 (0.0224)  triple_80: 0.0000 (0.0203)  triple_60: 0.0000 (0.0203)  triple_40: 0.0000 (0.0187)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 910/1724]  eta: 0:53:13  lr: 0.000200  loss: 2.3209 (2.2917)  loss_n_40: 0.4753 (0.4961)  loss_n_60: 0.5352 (0.5234)  loss_n_80: 0.5958 (0.5588)  loss_n_100: 0.6865 (0.6324)  triple_100: 0.0000 (0.0222)  triple_80: 0.0000 (0.0201)  triple_60: 0.0000 (0.0201)  triple_40: 0.0000 (0.0185)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 920/1724]  eta: 0:52:33  lr: 0.000200  loss: 2.3078 (2.2914)  loss_n_40: 0.4780 (0.4967)  loss_n_60: 0.5352 (0.5236)  loss_n_80: 0.5895 (0.5589)  loss_n_100: 0.6318 (0.6320)  triple_100: 0.0000 (0.0220)  triple_80: 0.0000 (0.0199)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0183)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 930/1724]  eta: 0:51:54  lr: 0.000200  loss: 2.1228 (2.3025)  loss_n_40: 0.4668 (0.4968)  loss_n_60: 0.5012 (0.5239)  loss_n_80: 0.5348 (0.5594)  loss_n_100: 0.5854 (0.6325)  triple_100: 0.0000 (0.0259)  triple_80: 0.0000 (0.0228)  triple_60: 0.0000 (0.0230)  triple_40: 0.0000 (0.0183)  time: 3.9229  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 940/1724]  eta: 0:51:15  lr: 0.000200  loss: 4.2280 (2.3803)  loss_n_40: 0.7720 (0.5038)  loss_n_60: 0.8948 (0.5339)  loss_n_80: 0.9761 (0.5726)  loss_n_100: 1.1877 (0.6470)  triple_100: 0.0000 (0.0492)  triple_80: 0.0000 (0.0309)  triple_60: 0.0000 (0.0239)  triple_40: 0.0000 (0.0190)  time: 3.9221  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 950/1724]  eta: 0:50:36  lr: 0.000200  loss: 7.6055 (2.4319)  loss_n_40: 1.2953 (0.5136)  loss_n_60: 1.6070 (0.5462)  loss_n_80: 1.9195 (0.5873)  loss_n_100: 1.9992 (0.6623)  triple_100: 0.0000 (0.0487)  triple_80: 0.0000 (0.0306)  triple_60: 0.0000 (0.0243)  triple_40: 0.0000 (0.0188)  time: 3.9214  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 960/1724]  eta: 0:49:56  lr: 0.000200  loss: 6.4730 (2.4696)  loss_n_40: 1.3004 (0.5216)  loss_n_60: 1.4389 (0.5551)  loss_n_80: 1.7137 (0.5982)  loss_n_100: 1.8523 (0.6736)  triple_100: 0.0000 (0.0482)  triple_80: 0.0000 (0.0303)  triple_60: 0.0000 (0.0241)  triple_40: 0.0000 (0.0186)  time: 3.9211  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [ 970/1724]  eta: 0:49:17  lr: 0.000200  loss: 5.2878 (2.4934)  loss_n_40: 1.0908 (0.5263)  loss_n_60: 1.1603 (0.5602)  loss_n_80: 1.4772 (0.6054)  loss_n_100: 1.6267 (0.6815)  triple_100: 0.0000 (0.0477)  triple_80: 0.0000 (0.0300)  triple_60: 0.0000 (0.0238)  triple_40: 0.0000 (0.0184)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 980/1724]  eta: 0:48:38  lr: 0.000200  loss: 4.5908 (2.5121)  loss_n_40: 0.9187 (0.5302)  loss_n_60: 1.0121 (0.5641)  loss_n_80: 1.2127 (0.6111)  loss_n_100: 1.3658 (0.6880)  triple_100: 0.0000 (0.0472)  triple_80: 0.0000 (0.0297)  triple_60: 0.0000 (0.0236)  triple_40: 0.0000 (0.0182)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [ 990/1724]  eta: 0:47:59  lr: 0.000200  loss: 3.9713 (2.5227)  loss_n_40: 0.7774 (0.5325)  loss_n_60: 0.8373 (0.5660)  loss_n_80: 1.0490 (0.6147)  loss_n_100: 1.1628 (0.6920)  triple_100: 0.0000 (0.0467)  triple_80: 0.0000 (0.0294)  triple_60: 0.0000 (0.0233)  triple_40: 0.0000 (0.0180)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1000/1724]  eta: 0:47:19  lr: 0.000200  loss: 3.4000 (2.5318)  loss_n_40: 0.6705 (0.5342)  loss_n_60: 0.6937 (0.5678)  loss_n_80: 0.9506 (0.6181)  loss_n_100: 1.0841 (0.6954)  triple_100: 0.0000 (0.0463)  triple_80: 0.0000 (0.0291)  triple_60: 0.0000 (0.0231)  triple_40: 0.0000 (0.0179)  time: 3.9155  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1010/1724]  eta: 0:46:40  lr: 0.000200  loss: 3.1553 (2.5360)  loss_n_40: 0.6078 (0.5349)  loss_n_60: 0.6706 (0.5685)  loss_n_80: 0.8287 (0.6200)  loss_n_100: 0.9085 (0.6974)  triple_100: 0.0000 (0.0458)  triple_80: 0.0000 (0.0288)  triple_60: 0.0000 (0.0229)  triple_40: 0.0000 (0.0177)  time: 3.9153  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1020/1724]  eta: 0:46:01  lr: 0.000200  loss: 2.8501 (2.5392)  loss_n_40: 0.5508 (0.5354)  loss_n_60: 0.6119 (0.5690)  loss_n_80: 0.7943 (0.6217)  loss_n_100: 0.8779 (0.6990)  triple_100: 0.0000 (0.0454)  triple_80: 0.0000 (0.0285)  triple_60: 0.0000 (0.0226)  triple_40: 0.0000 (0.0175)  time: 3.9147  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1030/1724]  eta: 0:45:21  lr: 0.000200  loss: 2.7565 (2.5422)  loss_n_40: 0.5955 (0.5364)  loss_n_60: 0.6044 (0.5695)  loss_n_80: 0.7522 (0.6231)  loss_n_100: 0.8227 (0.7003)  triple_100: 0.0000 (0.0449)  triple_80: 0.0000 (0.0282)  triple_60: 0.0000 (0.0224)  triple_40: 0.0000 (0.0173)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1040/1724]  eta: 0:44:42  lr: 0.000200  loss: 2.5235 (2.5397)  loss_n_40: 0.5227 (0.5358)  loss_n_60: 0.5452 (0.5691)  loss_n_80: 0.6872 (0.6230)  loss_n_100: 0.7478 (0.6999)  triple_100: 0.0000 (0.0445)  triple_80: 0.0000 (0.0280)  triple_60: 0.0000 (0.0222)  triple_40: 0.0000 (0.0172)  time: 3.9154  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1050/1724]  eta: 0:44:03  lr: 0.000200  loss: 2.2319 (2.5369)  loss_n_40: 0.4494 (0.5355)  loss_n_60: 0.5327 (0.5687)  loss_n_80: 0.6097 (0.6226)  loss_n_100: 0.6514 (0.6993)  triple_100: 0.0000 (0.0441)  triple_80: 0.0000 (0.0277)  triple_60: 0.0000 (0.0220)  triple_40: 0.0000 (0.0170)  time: 3.9150  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1060/1724]  eta: 0:43:24  lr: 0.000200  loss: 2.0777 (2.5319)  loss_n_40: 0.4362 (0.5345)  loss_n_60: 0.5060 (0.5679)  loss_n_80: 0.5485 (0.6218)  loss_n_100: 0.6002 (0.6981)  triple_100: 0.0000 (0.0436)  triple_80: 0.0000 (0.0274)  triple_60: 0.0000 (0.0218)  triple_40: 0.0000 (0.0169)  time: 3.9150  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1070/1724]  eta: 0:42:44  lr: 0.000200  loss: 2.0201 (2.5292)  loss_n_40: 0.4190 (0.5338)  loss_n_60: 0.4752 (0.5673)  loss_n_80: 0.5275 (0.6212)  loss_n_100: 0.5688 (0.6971)  triple_100: 0.0000 (0.0432)  triple_80: 0.0000 (0.0274)  triple_60: 0.0000 (0.0221)  triple_40: 0.0000 (0.0171)  time: 3.9145  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1080/1724]  eta: 0:42:05  lr: 0.000200  loss: 2.2593 (2.5286)  loss_n_40: 0.4624 (0.5337)  loss_n_60: 0.5229 (0.5674)  loss_n_80: 0.6110 (0.6215)  loss_n_100: 0.6596 (0.6971)  triple_100: 0.0000 (0.0428)  triple_80: 0.0000 (0.0272)  triple_60: 0.0000 (0.0219)  triple_40: 0.0000 (0.0169)  time: 3.9142  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1090/1724]  eta: 0:41:26  lr: 0.000200  loss: 2.2114 (2.5236)  loss_n_40: 0.4203 (0.5327)  loss_n_60: 0.4902 (0.5665)  loss_n_80: 0.5716 (0.6207)  loss_n_100: 0.6337 (0.6960)  triple_100: 0.0000 (0.0424)  triple_80: 0.0000 (0.0269)  triple_60: 0.0000 (0.0217)  triple_40: 0.0000 (0.0168)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1100/1724]  eta: 0:40:47  lr: 0.000200  loss: 2.0409 (2.5204)  loss_n_40: 0.4444 (0.5322)  loss_n_60: 0.4861 (0.5659)  loss_n_80: 0.5355 (0.6202)  loss_n_100: 0.5727 (0.6952)  triple_100: 0.0000 (0.0421)  triple_80: 0.0000 (0.0267)  triple_60: 0.0000 (0.0215)  triple_40: 0.0000 (0.0166)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1110/1724]  eta: 0:40:07  lr: 0.000200  loss: 1.9827 (2.5149)  loss_n_40: 0.4327 (0.5315)  loss_n_60: 0.4694 (0.5649)  loss_n_80: 0.5265 (0.6190)  loss_n_100: 0.5603 (0.6936)  triple_100: 0.0000 (0.0417)  triple_80: 0.0000 (0.0264)  triple_60: 0.0000 (0.0213)  triple_40: 0.0000 (0.0165)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1120/1724]  eta: 0:39:28  lr: 0.000200  loss: 1.9084 (2.5089)  loss_n_40: 0.3868 (0.5301)  loss_n_60: 0.4460 (0.5637)  loss_n_80: 0.4931 (0.6179)  loss_n_100: 0.5303 (0.6922)  triple_100: 0.0000 (0.0413)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.0211)  triple_40: 0.0000 (0.0163)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1130/1724]  eta: 0:38:49  lr: 0.000200  loss: 1.9114 (2.5037)  loss_n_40: 0.3852 (0.5293)  loss_n_60: 0.4499 (0.5628)  loss_n_80: 0.4947 (0.6169)  loss_n_100: 0.5393 (0.6908)  triple_100: 0.0000 (0.0409)  triple_80: 0.0000 (0.0260)  triple_60: 0.0000 (0.0209)  triple_40: 0.0000 (0.0162)  time: 3.9154  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1140/1724]  eta: 0:38:10  lr: 0.000200  loss: 1.8701 (2.4979)  loss_n_40: 0.3930 (0.5284)  loss_n_60: 0.4539 (0.5618)  loss_n_80: 0.4707 (0.6156)  loss_n_100: 0.4865 (0.6891)  triple_100: 0.0000 (0.0406)  triple_80: 0.0000 (0.0257)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0160)  time: 3.9148  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1150/1724]  eta: 0:37:30  lr: 0.000200  loss: 1.7555 (2.4930)  loss_n_40: 0.3667 (0.5271)  loss_n_60: 0.4047 (0.5605)  loss_n_80: 0.4510 (0.6142)  loss_n_100: 0.4847 (0.6874)  triple_100: 0.0000 (0.0407)  triple_80: 0.0000 (0.0259)  triple_60: 0.0000 (0.0210)  triple_40: 0.0000 (0.0163)  time: 3.9157  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1160/1724]  eta: 0:36:51  lr: 0.000200  loss: 2.3306 (2.4929)  loss_n_40: 0.4149 (0.5269)  loss_n_60: 0.4758 (0.5605)  loss_n_80: 0.5225 (0.6146)  loss_n_100: 0.5759 (0.6877)  triple_100: 0.0000 (0.0403)  triple_80: 0.0000 (0.0257)  triple_60: 0.0000 (0.0211)  triple_40: 0.0000 (0.0161)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1170/1724]  eta: 0:36:12  lr: 0.000200  loss: 2.4801 (2.4949)  loss_n_40: 0.5206 (0.5274)  loss_n_60: 0.5582 (0.5610)  loss_n_80: 0.6825 (0.6156)  loss_n_100: 0.7137 (0.6885)  triple_100: 0.0000 (0.0400)  triple_80: 0.0000 (0.0255)  triple_60: 0.0000 (0.0209)  triple_40: 0.0000 (0.0160)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1180/1724]  eta: 0:35:33  lr: 0.000200  loss: 2.4055 (2.4936)  loss_n_40: 0.5155 (0.5272)  loss_n_60: 0.5534 (0.5609)  loss_n_80: 0.6320 (0.6156)  loss_n_100: 0.6911 (0.6884)  triple_100: 0.0000 (0.0397)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0159)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1190/1724]  eta: 0:34:53  lr: 0.000200  loss: 2.2090 (2.4903)  loss_n_40: 0.4557 (0.5264)  loss_n_60: 0.5115 (0.5603)  loss_n_80: 0.5917 (0.6152)  loss_n_100: 0.6605 (0.6877)  triple_100: 0.0000 (0.0393)  triple_80: 0.0000 (0.0251)  triple_60: 0.0000 (0.0206)  triple_40: 0.0000 (0.0157)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1200/1724]  eta: 0:34:14  lr: 0.000200  loss: 1.9168 (2.4848)  loss_n_40: 0.3837 (0.5255)  loss_n_60: 0.4495 (0.5592)  loss_n_80: 0.5167 (0.6140)  loss_n_100: 0.5522 (0.6862)  triple_100: 0.0000 (0.0390)  triple_80: 0.0000 (0.0249)  triple_60: 0.0000 (0.0204)  triple_40: 0.0000 (0.0156)  time: 3.9178  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [1210/1724]  eta: 0:33:35  lr: 0.000200  loss: 1.8181 (2.4796)  loss_n_40: 0.3699 (0.5247)  loss_n_60: 0.4111 (0.5582)  loss_n_80: 0.4797 (0.6129)  loss_n_100: 0.5194 (0.6848)  triple_100: 0.0000 (0.0387)  triple_80: 0.0000 (0.0247)  triple_60: 0.0000 (0.0202)  triple_40: 0.0000 (0.0155)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1220/1724]  eta: 0:32:56  lr: 0.000200  loss: 1.7115 (2.4726)  loss_n_40: 0.3594 (0.5233)  loss_n_60: 0.4091 (0.5568)  loss_n_80: 0.4384 (0.6114)  loss_n_100: 0.4650 (0.6829)  triple_100: 0.0000 (0.0384)  triple_80: 0.0000 (0.0245)  triple_60: 0.0000 (0.0201)  triple_40: 0.0000 (0.0153)  time: 3.9180  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1230/1724]  eta: 0:32:17  lr: 0.000200  loss: 1.5854 (2.4658)  loss_n_40: 0.3455 (0.5220)  loss_n_60: 0.3821 (0.5555)  loss_n_80: 0.4198 (0.6099)  loss_n_100: 0.4435 (0.6811)  triple_100: 0.0000 (0.0380)  triple_80: 0.0000 (0.0243)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0152)  time: 3.9184  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1240/1724]  eta: 0:31:37  lr: 0.000200  loss: 1.6395 (2.4604)  loss_n_40: 0.3683 (0.5208)  loss_n_60: 0.3976 (0.5544)  loss_n_80: 0.4257 (0.6087)  loss_n_100: 0.4582 (0.6797)  triple_100: 0.0000 (0.0377)  triple_80: 0.0000 (0.0241)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0151)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1250/1724]  eta: 0:30:58  lr: 0.000200  loss: 1.7316 (2.4558)  loss_n_40: 0.3862 (0.5204)  loss_n_60: 0.4223 (0.5535)  loss_n_80: 0.4514 (0.6076)  loss_n_100: 0.4827 (0.6783)  triple_100: 0.0000 (0.0374)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0197)  triple_40: 0.0000 (0.0150)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1260/1724]  eta: 0:30:19  lr: 0.000200  loss: 1.7176 (2.4500)  loss_n_40: 0.4046 (0.5193)  loss_n_60: 0.3932 (0.5524)  loss_n_80: 0.4642 (0.6064)  loss_n_100: 0.4685 (0.6768)  triple_100: 0.0000 (0.0371)  triple_80: 0.0000 (0.0237)  triple_60: 0.0000 (0.0195)  triple_40: 0.0000 (0.0149)  time: 3.9173  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1270/1724]  eta: 0:29:40  lr: 0.000200  loss: 1.6281 (2.4427)  loss_n_40: 0.3516 (0.5178)  loss_n_60: 0.3774 (0.5508)  loss_n_80: 0.4259 (0.6048)  loss_n_100: 0.4664 (0.6749)  triple_100: 0.0000 (0.0368)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0194)  triple_40: 0.0000 (0.0147)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1280/1724]  eta: 0:29:00  lr: 0.000200  loss: 1.5955 (2.4360)  loss_n_40: 0.3516 (0.5166)  loss_n_60: 0.3576 (0.5494)  loss_n_80: 0.3992 (0.6032)  loss_n_100: 0.4263 (0.6730)  triple_100: 0.0000 (0.0366)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0192)  triple_40: 0.0000 (0.0146)  time: 3.9164  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1290/1724]  eta: 0:28:21  lr: 0.000200  loss: 1.4822 (2.4313)  loss_n_40: 0.3419 (0.5154)  loss_n_60: 0.3458 (0.5480)  loss_n_80: 0.3859 (0.6016)  loss_n_100: 0.4195 (0.6711)  triple_100: 0.0000 (0.0363)  triple_80: 0.0000 (0.0236)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0152)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1300/1724]  eta: 0:27:42  lr: 0.000200  loss: 1.8430 (2.4283)  loss_n_40: 0.3739 (0.5146)  loss_n_60: 0.4070 (0.5474)  loss_n_80: 0.4438 (0.6010)  loss_n_100: 0.5109 (0.6705)  triple_100: 0.0000 (0.0361)  triple_80: 0.0000 (0.0236)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0151)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1310/1724]  eta: 0:27:03  lr: 0.000200  loss: 2.0525 (2.4257)  loss_n_40: 0.4091 (0.5141)  loss_n_60: 0.4624 (0.5470)  loss_n_80: 0.5353 (0.6006)  loss_n_100: 0.5892 (0.6700)  triple_100: 0.0000 (0.0359)  triple_80: 0.0000 (0.0234)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0150)  time: 3.9158  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1320/1724]  eta: 0:26:24  lr: 0.000200  loss: 1.8947 (2.4218)  loss_n_40: 0.4074 (0.5132)  loss_n_60: 0.4446 (0.5462)  loss_n_80: 0.4945 (0.5997)  loss_n_100: 0.5759 (0.6692)  triple_100: 0.0000 (0.0356)  triple_80: 0.0000 (0.0232)  triple_60: 0.0000 (0.0197)  triple_40: 0.0000 (0.0149)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1330/1724]  eta: 0:25:44  lr: 0.000200  loss: 1.8677 (2.4182)  loss_n_40: 0.3891 (0.5125)  loss_n_60: 0.4394 (0.5455)  loss_n_80: 0.4871 (0.5990)  loss_n_100: 0.5617 (0.6684)  triple_100: 0.0000 (0.0353)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0148)  time: 3.9156  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1340/1724]  eta: 0:25:05  lr: 0.000200  loss: 1.8012 (2.4134)  loss_n_40: 0.3891 (0.5117)  loss_n_60: 0.4331 (0.5446)  loss_n_80: 0.4862 (0.5979)  loss_n_100: 0.5123 (0.6671)  triple_100: 0.0000 (0.0351)  triple_80: 0.0000 (0.0229)  triple_60: 0.0000 (0.0194)  triple_40: 0.0000 (0.0146)  time: 3.9153  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1350/1724]  eta: 0:24:26  lr: 0.000200  loss: 1.7477 (2.4086)  loss_n_40: 0.3755 (0.5108)  loss_n_60: 0.4193 (0.5437)  loss_n_80: 0.4389 (0.5968)  loss_n_100: 0.4885 (0.6659)  triple_100: 0.0000 (0.0348)  triple_80: 0.0000 (0.0227)  triple_60: 0.0000 (0.0193)  triple_40: 0.0000 (0.0145)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1360/1724]  eta: 0:23:47  lr: 0.000200  loss: 1.6791 (2.4031)  loss_n_40: 0.3484 (0.5100)  loss_n_60: 0.3902 (0.5426)  loss_n_80: 0.4280 (0.5954)  loss_n_100: 0.4784 (0.6643)  triple_100: 0.0000 (0.0345)  triple_80: 0.0000 (0.0225)  triple_60: 0.0000 (0.0191)  triple_40: 0.0000 (0.0144)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1370/1724]  eta: 0:23:07  lr: 0.000200  loss: 1.7287 (2.3982)  loss_n_40: 0.3586 (0.5091)  loss_n_60: 0.3985 (0.5417)  loss_n_80: 0.4533 (0.5944)  loss_n_100: 0.4784 (0.6630)  triple_100: 0.0000 (0.0343)  triple_80: 0.0000 (0.0224)  triple_60: 0.0000 (0.0190)  triple_40: 0.0000 (0.0143)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1380/1724]  eta: 0:22:28  lr: 0.000200  loss: 1.5173 (2.3911)  loss_n_40: 0.3296 (0.5077)  loss_n_60: 0.3622 (0.5403)  loss_n_80: 0.3920 (0.5927)  loss_n_100: 0.4325 (0.6611)  triple_100: 0.0000 (0.0340)  triple_80: 0.0000 (0.0222)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0142)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1390/1724]  eta: 0:21:49  lr: 0.000200  loss: 1.5173 (2.4043)  loss_n_40: 0.3252 (0.5073)  loss_n_60: 0.3558 (0.5402)  loss_n_80: 0.3975 (0.5929)  loss_n_100: 0.4346 (0.6612)  triple_100: 0.0000 (0.0380)  triple_80: 0.0000 (0.0257)  triple_60: 0.0000 (0.0223)  triple_40: 0.0000 (0.0166)  time: 3.9180  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1400/1724]  eta: 0:21:10  lr: 0.000200  loss: 2.7373 (2.4075)  loss_n_40: 0.4942 (0.5077)  loss_n_60: 0.5778 (0.5412)  loss_n_80: 0.6504 (0.5941)  loss_n_100: 0.7249 (0.6627)  triple_100: 0.0000 (0.0377)  triple_80: 0.0000 (0.0255)  triple_60: 0.0000 (0.0222)  triple_40: 0.0000 (0.0165)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1410/1724]  eta: 0:20:31  lr: 0.000200  loss: 2.4986 (2.4093)  loss_n_40: 0.5076 (0.5080)  loss_n_60: 0.5778 (0.5417)  loss_n_80: 0.6504 (0.5948)  loss_n_100: 0.7827 (0.6637)  triple_100: 0.0000 (0.0375)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0220)  triple_40: 0.0000 (0.0164)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1420/1724]  eta: 0:19:51  lr: 0.000200  loss: 2.4227 (2.4081)  loss_n_40: 0.4846 (0.5078)  loss_n_60: 0.5507 (0.5414)  loss_n_80: 0.6213 (0.5947)  loss_n_100: 0.7186 (0.6638)  triple_100: 0.0000 (0.0372)  triple_80: 0.0000 (0.0251)  triple_60: 0.0000 (0.0218)  triple_40: 0.0000 (0.0163)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1430/1724]  eta: 0:19:12  lr: 0.000200  loss: 2.1275 (2.4063)  loss_n_40: 0.4565 (0.5077)  loss_n_60: 0.4857 (0.5411)  loss_n_80: 0.5420 (0.5943)  loss_n_100: 0.6423 (0.6634)  triple_100: 0.0000 (0.0370)  triple_80: 0.0000 (0.0250)  triple_60: 0.0000 (0.0217)  triple_40: 0.0000 (0.0162)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1440/1724]  eta: 0:18:33  lr: 0.000200  loss: 2.0213 (2.4034)  loss_n_40: 0.4378 (0.5072)  loss_n_60: 0.4857 (0.5407)  loss_n_80: 0.5251 (0.5937)  loss_n_100: 0.5791 (0.6627)  triple_100: 0.0000 (0.0367)  triple_80: 0.0000 (0.0248)  triple_60: 0.0000 (0.0215)  triple_40: 0.0000 (0.0160)  time: 3.9154  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [1450/1724]  eta: 0:17:54  lr: 0.000200  loss: 1.9565 (2.4002)  loss_n_40: 0.4156 (0.5067)  loss_n_60: 0.4532 (0.5401)  loss_n_80: 0.4982 (0.5930)  loss_n_100: 0.5572 (0.6620)  triple_100: 0.0000 (0.0364)  triple_80: 0.0000 (0.0246)  triple_60: 0.0000 (0.0214)  triple_40: 0.0000 (0.0159)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1460/1724]  eta: 0:17:15  lr: 0.000200  loss: 1.8636 (2.3964)  loss_n_40: 0.4156 (0.5060)  loss_n_60: 0.4348 (0.5393)  loss_n_80: 0.4791 (0.5923)  loss_n_100: 0.5366 (0.6611)  triple_100: 0.0000 (0.0362)  triple_80: 0.0000 (0.0245)  triple_60: 0.0000 (0.0212)  triple_40: 0.0000 (0.0158)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1470/1724]  eta: 0:16:35  lr: 0.000200  loss: 1.7686 (2.3920)  loss_n_40: 0.3935 (0.5052)  loss_n_60: 0.4177 (0.5385)  loss_n_80: 0.4539 (0.5913)  loss_n_100: 0.4970 (0.6600)  triple_100: 0.0000 (0.0359)  triple_80: 0.0000 (0.0243)  triple_60: 0.0000 (0.0211)  triple_40: 0.0000 (0.0157)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1480/1724]  eta: 0:15:56  lr: 0.000200  loss: 1.6913 (2.3882)  loss_n_40: 0.3935 (0.5048)  loss_n_60: 0.4091 (0.5378)  loss_n_80: 0.4332 (0.5904)  loss_n_100: 0.4658 (0.6588)  triple_100: 0.0000 (0.0357)  triple_80: 0.0000 (0.0241)  triple_60: 0.0000 (0.0210)  triple_40: 0.0000 (0.0156)  time: 3.9156  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1490/1724]  eta: 0:15:17  lr: 0.000200  loss: 1.6396 (2.3829)  loss_n_40: 0.3684 (0.5039)  loss_n_60: 0.3755 (0.5368)  loss_n_80: 0.4223 (0.5891)  loss_n_100: 0.4473 (0.6574)  triple_100: 0.0000 (0.0355)  triple_80: 0.0000 (0.0240)  triple_60: 0.0000 (0.0208)  triple_40: 0.0000 (0.0155)  time: 3.9151  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1500/1724]  eta: 0:14:38  lr: 0.000200  loss: 1.5263 (2.3783)  loss_n_40: 0.3421 (0.5031)  loss_n_60: 0.3755 (0.5359)  loss_n_80: 0.3886 (0.5880)  loss_n_100: 0.4458 (0.6562)  triple_100: 0.0000 (0.0352)  triple_80: 0.0000 (0.0238)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0154)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1510/1724]  eta: 0:13:58  lr: 0.000200  loss: 1.6609 (2.3741)  loss_n_40: 0.3795 (0.5025)  loss_n_60: 0.3940 (0.5351)  loss_n_80: 0.4160 (0.5870)  loss_n_100: 0.4640 (0.6550)  triple_100: 0.0000 (0.0350)  triple_80: 0.0000 (0.0236)  triple_60: 0.0000 (0.0205)  triple_40: 0.0000 (0.0153)  time: 3.9158  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1520/1724]  eta: 0:13:19  lr: 0.000200  loss: 1.6007 (2.3691)  loss_n_40: 0.3720 (0.5015)  loss_n_60: 0.3915 (0.5342)  loss_n_80: 0.4056 (0.5858)  loss_n_100: 0.4458 (0.6537)  triple_100: 0.0000 (0.0348)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0204)  triple_40: 0.0000 (0.0152)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1530/1724]  eta: 0:12:40  lr: 0.000200  loss: 1.5616 (2.3642)  loss_n_40: 0.3539 (0.5008)  loss_n_60: 0.3744 (0.5332)  loss_n_80: 0.3899 (0.5846)  loss_n_100: 0.4202 (0.6523)  triple_100: 0.0000 (0.0345)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0203)  triple_40: 0.0000 (0.0151)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1540/1724]  eta: 0:12:01  lr: 0.000200  loss: 1.5616 (2.3592)  loss_n_40: 0.3539 (0.4999)  loss_n_60: 0.3744 (0.5322)  loss_n_80: 0.3930 (0.5835)  loss_n_100: 0.4225 (0.6509)  triple_100: 0.0000 (0.0343)  triple_80: 0.0000 (0.0232)  triple_60: 0.0000 (0.0201)  triple_40: 0.0000 (0.0150)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1550/1724]  eta: 0:11:22  lr: 0.000200  loss: 1.5674 (2.3540)  loss_n_40: 0.3253 (0.4990)  loss_n_60: 0.3681 (0.5312)  loss_n_80: 0.4101 (0.5822)  loss_n_100: 0.4407 (0.6496)  triple_100: 0.0000 (0.0341)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0149)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1560/1724]  eta: 0:10:42  lr: 0.000200  loss: 1.5472 (2.3486)  loss_n_40: 0.3205 (0.4980)  loss_n_60: 0.3652 (0.5301)  loss_n_80: 0.3894 (0.5809)  loss_n_100: 0.4251 (0.6481)  triple_100: 0.0000 (0.0339)  triple_80: 0.0000 (0.0229)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0148)  time: 3.9153  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1570/1724]  eta: 0:10:03  lr: 0.000200  loss: 1.4916 (2.3432)  loss_n_40: 0.3155 (0.4970)  loss_n_60: 0.3619 (0.5290)  loss_n_80: 0.3667 (0.5796)  loss_n_100: 0.3913 (0.6466)  triple_100: 0.0000 (0.0337)  triple_80: 0.0000 (0.0227)  triple_60: 0.0000 (0.0198)  triple_40: 0.0000 (0.0147)  time: 3.9141  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1580/1724]  eta: 0:09:24  lr: 0.000200  loss: 1.3950 (2.3374)  loss_n_40: 0.3075 (0.4959)  loss_n_60: 0.3370 (0.5279)  loss_n_80: 0.3611 (0.5783)  loss_n_100: 0.3906 (0.6451)  triple_100: 0.0000 (0.0334)  triple_80: 0.0000 (0.0226)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0146)  time: 3.9136  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1590/1724]  eta: 0:08:45  lr: 0.000200  loss: 1.5587 (2.3406)  loss_n_40: 0.3591 (0.4957)  loss_n_60: 0.3679 (0.5279)  loss_n_80: 0.3891 (0.5784)  loss_n_100: 0.4430 (0.6453)  triple_100: 0.0000 (0.0355)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0197)  triple_40: 0.0000 (0.0147)  time: 3.9145  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1600/1724]  eta: 0:08:06  lr: 0.000200  loss: 3.2424 (2.3503)  loss_n_40: 0.6160 (0.4973)  loss_n_60: 0.7105 (0.5299)  loss_n_80: 0.8389 (0.5813)  loss_n_100: 0.9343 (0.6481)  triple_100: 0.0000 (0.0356)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0146)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1610/1724]  eta: 0:07:26  lr: 0.000200  loss: 3.4623 (2.3565)  loss_n_40: 0.7182 (0.4987)  loss_n_60: 0.7884 (0.5316)  loss_n_80: 0.9821 (0.5833)  loss_n_100: 1.0161 (0.6500)  triple_100: 0.0000 (0.0353)  triple_80: 0.0000 (0.0237)  triple_60: 0.0000 (0.0194)  triple_40: 0.0000 (0.0145)  time: 3.9149  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1620/1724]  eta: 0:06:47  lr: 0.000200  loss: 3.1444 (2.3609)  loss_n_40: 0.6788 (0.4996)  loss_n_60: 0.7404 (0.5326)  loss_n_80: 0.8573 (0.5849)  loss_n_100: 0.8988 (0.6515)  triple_100: 0.0000 (0.0351)  triple_80: 0.0000 (0.0236)  triple_60: 0.0000 (0.0193)  triple_40: 0.0000 (0.0144)  time: 3.9138  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1630/1724]  eta: 0:06:08  lr: 0.000200  loss: 2.7501 (2.3617)  loss_n_40: 0.5608 (0.4998)  loss_n_60: 0.6005 (0.5327)  loss_n_80: 0.7472 (0.5854)  loss_n_100: 0.7992 (0.6519)  triple_100: 0.0000 (0.0349)  triple_80: 0.0000 (0.0234)  triple_60: 0.0000 (0.0192)  triple_40: 0.0000 (0.0143)  time: 3.9144  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1640/1724]  eta: 0:05:29  lr: 0.000200  loss: 2.3532 (2.3606)  loss_n_40: 0.5295 (0.4998)  loss_n_60: 0.5309 (0.5326)  loss_n_80: 0.6075 (0.5853)  loss_n_100: 0.6680 (0.6516)  triple_100: 0.0000 (0.0347)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0191)  triple_40: 0.0000 (0.0142)  time: 3.9147  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1650/1724]  eta: 0:04:50  lr: 0.000200  loss: 2.0475 (2.3586)  loss_n_40: 0.4513 (0.4995)  loss_n_60: 0.4815 (0.5322)  loss_n_80: 0.5485 (0.5851)  loss_n_100: 0.5801 (0.6511)  triple_100: 0.0000 (0.0345)  triple_80: 0.0000 (0.0232)  triple_60: 0.0000 (0.0190)  triple_40: 0.0000 (0.0141)  time: 3.9141  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1660/1724]  eta: 0:04:10  lr: 0.000200  loss: 1.9569 (2.3561)  loss_n_40: 0.4244 (0.4990)  loss_n_60: 0.4453 (0.5318)  loss_n_80: 0.5141 (0.5846)  loss_n_100: 0.5481 (0.6505)  triple_100: 0.0000 (0.0343)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0188)  triple_40: 0.0000 (0.0141)  time: 3.9134  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1670/1724]  eta: 0:03:31  lr: 0.000200  loss: 1.9569 (2.3541)  loss_n_40: 0.4317 (0.4988)  loss_n_60: 0.4664 (0.5314)  loss_n_80: 0.5141 (0.5843)  loss_n_100: 0.5633 (0.6500)  triple_100: 0.0000 (0.0341)  triple_80: 0.0000 (0.0229)  triple_60: 0.0000 (0.0187)  triple_40: 0.0000 (0.0140)  time: 3.9138  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1680/1724]  eta: 0:02:52  lr: 0.000200  loss: 1.7853 (2.3504)  loss_n_40: 0.4013 (0.4980)  loss_n_60: 0.4195 (0.5307)  loss_n_80: 0.4687 (0.5835)  loss_n_100: 0.5051 (0.6490)  triple_100: 0.0000 (0.0339)  triple_80: 0.0000 (0.0227)  triple_60: 0.0000 (0.0186)  triple_40: 0.0000 (0.0139)  time: 3.9158  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [1690/1724]  eta: 0:02:13  lr: 0.000200  loss: 1.6741 (2.3467)  loss_n_40: 0.3678 (0.4975)  loss_n_60: 0.3933 (0.5300)  loss_n_80: 0.4463 (0.5827)  loss_n_100: 0.4718 (0.6480)  triple_100: 0.0000 (0.0337)  triple_80: 0.0000 (0.0226)  triple_60: 0.0000 (0.0185)  triple_40: 0.0000 (0.0138)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1700/1724]  eta: 0:01:34  lr: 0.000200  loss: 1.5071 (2.3420)  loss_n_40: 0.3286 (0.4965)  loss_n_60: 0.3571 (0.5290)  loss_n_80: 0.4053 (0.5817)  loss_n_100: 0.4287 (0.6467)  triple_100: 0.0000 (0.0335)  triple_80: 0.0000 (0.0225)  triple_60: 0.0000 (0.0184)  triple_40: 0.0000 (0.0137)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12]  [1710/1724]  eta: 0:00:54  lr: 0.000200  loss: 1.5385 (2.3378)  loss_n_40: 0.3375 (0.4959)  loss_n_60: 0.3571 (0.5281)  loss_n_80: 0.4053 (0.5807)  loss_n_100: 0.4331 (0.6455)  triple_100: 0.0000 (0.0333)  triple_80: 0.0000 (0.0223)  triple_60: 0.0000 (0.0183)  triple_40: 0.0000 (0.0136)  time: 3.9162  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1720/1724]  eta: 0:00:15  lr: 0.000200  loss: 1.6184 (2.3364)  loss_n_40: 0.3536 (0.4951)  loss_n_60: 0.3761 (0.5276)  loss_n_80: 0.4328 (0.5803)  loss_n_100: 0.4720 (0.6451)  triple_100: 0.0000 (0.0334)  triple_80: 0.0000 (0.0225)  triple_60: 0.0000 (0.0186)  triple_40: 0.0000 (0.0139)  time: 3.9153  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:12]  [1723/1724]  eta: 0:00:03  lr: 0.000200  loss: 1.8291 (2.3369)  loss_n_40: 0.4214 (0.4952)  loss_n_60: 0.4272 (0.5277)  loss_n_80: 0.4539 (0.5805)  loss_n_100: 0.4941 (0.6453)  triple_100: 0.0000 (0.0334)  triple_80: 0.0000 (0.0225)  triple_60: 0.0000 (0.0185)  triple_40: 0.0000 (0.0139)  time: 3.9153  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:12] Total time: 1:52:37 (3.9199 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 1.8291 (2.3369)  loss_n_40: 0.4214 (0.4952)  loss_n_60: 0.4272 (0.5277)  loss_n_80: 0.4539 (0.5805)  loss_n_100: 0.4941 (0.6453)  triple_100: 0.0000 (0.0334)  triple_80: 0.0000 (0.0225)  triple_60: 0.0000 (0.0185)  triple_40: 0.0000 (0.0139)\n",
      "Valid: [epoch:12]  [  0/845]  eta: 0:10:39  loss: 2.5339 (2.5339)  loss_n_40: 0.9057 (0.9057)  loss_n_60: 0.6084 (0.6084)  loss_n_80: 0.5000 (0.5000)  loss_n_100: 0.5197 (0.5197)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7564  data: 0.4189  max mem: 46473\n",
      "Valid: [epoch:12]  [ 10/845]  eta: 0:05:10  loss: 2.1677 (2.2221)  loss_n_40: 0.4499 (0.5071)  loss_n_60: 0.5075 (0.5126)  loss_n_80: 0.5258 (0.5730)  loss_n_100: 0.5960 (0.6226)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0069)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3720  data: 0.0382  max mem: 46473\n",
      "Valid: [epoch:12]  [ 20/845]  eta: 0:04:51  loss: 2.0482 (2.1525)  loss_n_40: 0.4517 (0.4872)  loss_n_60: 0.4797 (0.4987)  loss_n_80: 0.5764 (0.5632)  loss_n_100: 0.5720 (0.5999)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0036)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [ 30/845]  eta: 0:04:43  loss: 2.1819 (2.1970)  loss_n_40: 0.4566 (0.4895)  loss_n_60: 0.4849 (0.5101)  loss_n_80: 0.5764 (0.5742)  loss_n_100: 0.5838 (0.6208)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0024)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [ 40/845]  eta: 0:04:36  loss: 2.1526 (2.1604)  loss_n_40: 0.4441 (0.4845)  loss_n_60: 0.4760 (0.5024)  loss_n_80: 0.5045 (0.5602)  loss_n_100: 0.5838 (0.6114)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0018)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [ 50/845]  eta: 0:04:31  loss: 1.8995 (2.1289)  loss_n_40: 0.4074 (0.4744)  loss_n_60: 0.4319 (0.4945)  loss_n_80: 0.4716 (0.5538)  loss_n_100: 0.5339 (0.6047)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0015)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3334  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [ 60/845]  eta: 0:04:27  loss: 1.8995 (2.1057)  loss_n_40: 0.4127 (0.4685)  loss_n_60: 0.4317 (0.4900)  loss_n_80: 0.4997 (0.5489)  loss_n_100: 0.5249 (0.5971)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0012)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3333  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [ 70/845]  eta: 0:04:23  loss: 1.9634 (2.1115)  loss_n_40: 0.4127 (0.4741)  loss_n_60: 0.4335 (0.4914)  loss_n_80: 0.5227 (0.5499)  loss_n_100: 0.5668 (0.5951)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0011)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3334  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [ 80/845]  eta: 0:04:19  loss: 1.9789 (2.1251)  loss_n_40: 0.4304 (0.4729)  loss_n_60: 0.4415 (0.4897)  loss_n_80: 0.5546 (0.5529)  loss_n_100: 0.5882 (0.5961)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [ 90/845]  eta: 0:04:15  loss: 2.0526 (2.1429)  loss_n_40: 0.4518 (0.4782)  loss_n_60: 0.4698 (0.4967)  loss_n_80: 0.5585 (0.5552)  loss_n_100: 0.5882 (0.6009)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0120)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [100/845]  eta: 0:04:11  loss: 2.0649 (2.1538)  loss_n_40: 0.5071 (0.4795)  loss_n_60: 0.4788 (0.4983)  loss_n_80: 0.5585 (0.5598)  loss_n_100: 0.6212 (0.6054)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [110/845]  eta: 0:04:08  loss: 1.9364 (2.1414)  loss_n_40: 0.4380 (0.4754)  loss_n_60: 0.4599 (0.4954)  loss_n_80: 0.5139 (0.5575)  loss_n_100: 0.5635 (0.6032)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0098)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [120/845]  eta: 0:04:04  loss: 1.9151 (2.1340)  loss_n_40: 0.4278 (0.4742)  loss_n_60: 0.4481 (0.4941)  loss_n_80: 0.5317 (0.5582)  loss_n_100: 0.5321 (0.5985)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0090)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3335  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [130/845]  eta: 0:04:00  loss: 2.0753 (2.1404)  loss_n_40: 0.4594 (0.4769)  loss_n_60: 0.4607 (0.4956)  loss_n_80: 0.5474 (0.5591)  loss_n_100: 0.5678 (0.6005)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0083)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [140/845]  eta: 0:03:57  loss: 2.1158 (2.1514)  loss_n_40: 0.4780 (0.4795)  loss_n_60: 0.4982 (0.4982)  loss_n_80: 0.5880 (0.5632)  loss_n_100: 0.6269 (0.6027)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0077)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [150/845]  eta: 0:03:53  loss: 2.0467 (2.1431)  loss_n_40: 0.4455 (0.4778)  loss_n_60: 0.4961 (0.4968)  loss_n_80: 0.5421 (0.5597)  loss_n_100: 0.5536 (0.6016)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0072)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [160/845]  eta: 0:03:50  loss: 1.9904 (2.1570)  loss_n_40: 0.4160 (0.4764)  loss_n_60: 0.4487 (0.4968)  loss_n_80: 0.5035 (0.5597)  loss_n_100: 0.5627 (0.6036)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0187)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0019)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [170/845]  eta: 0:03:46  loss: 2.1626 (2.1670)  loss_n_40: 0.4763 (0.4796)  loss_n_60: 0.5023 (0.4988)  loss_n_80: 0.5506 (0.5620)  loss_n_100: 0.6346 (0.6072)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0176)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0017)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [180/845]  eta: 0:03:43  loss: 2.1626 (2.1679)  loss_n_40: 0.5136 (0.4805)  loss_n_60: 0.4815 (0.4986)  loss_n_80: 0.5506 (0.5624)  loss_n_100: 0.6313 (0.6080)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0017)  time: 0.3340  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:12]  [190/845]  eta: 0:03:40  loss: 1.9030 (2.1604)  loss_n_40: 0.4232 (0.4774)  loss_n_60: 0.4412 (0.4972)  loss_n_80: 0.5281 (0.5609)  loss_n_100: 0.5828 (0.6076)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0016)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [200/845]  eta: 0:03:36  loss: 2.1505 (2.1681)  loss_n_40: 0.4450 (0.4791)  loss_n_60: 0.4922 (0.5002)  loss_n_80: 0.5281 (0.5623)  loss_n_100: 0.6011 (0.6094)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0015)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [210/845]  eta: 0:03:33  loss: 2.2056 (2.1679)  loss_n_40: 0.4543 (0.4794)  loss_n_60: 0.5335 (0.5000)  loss_n_80: 0.5644 (0.5623)  loss_n_100: 0.6099 (0.6100)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0014)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [220/845]  eta: 0:03:29  loss: 2.2056 (2.1886)  loss_n_40: 0.4543 (0.4799)  loss_n_60: 0.4718 (0.5010)  loss_n_80: 0.5339 (0.5631)  loss_n_100: 0.5855 (0.6113)  triple_100: 0.0000 (0.0006)  triple_80: 0.0000 (0.0313)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0014)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [230/845]  eta: 0:03:26  loss: 1.8344 (2.1793)  loss_n_40: 0.4131 (0.4778)  loss_n_60: 0.4253 (0.4993)  loss_n_80: 0.4972 (0.5616)  loss_n_100: 0.5291 (0.6088)  triple_100: 0.0000 (0.0006)  triple_80: 0.0000 (0.0299)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0013)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [240/845]  eta: 0:03:22  loss: 1.8629 (2.1720)  loss_n_40: 0.3814 (0.4759)  loss_n_60: 0.4226 (0.4977)  loss_n_80: 0.5068 (0.5604)  loss_n_100: 0.5146 (0.6075)  triple_100: 0.0000 (0.0005)  triple_80: 0.0000 (0.0287)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0012)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [250/845]  eta: 0:03:19  loss: 1.9988 (2.1824)  loss_n_40: 0.4160 (0.4764)  loss_n_60: 0.4787 (0.4984)  loss_n_80: 0.5307 (0.5609)  loss_n_100: 0.5791 (0.6090)  triple_100: 0.0000 (0.0005)  triple_80: 0.0000 (0.0308)  triple_60: 0.0000 (0.0029)  triple_40: 0.0000 (0.0035)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [260/845]  eta: 0:03:16  loss: 2.1765 (2.1768)  loss_n_40: 0.4606 (0.4752)  loss_n_60: 0.4906 (0.4977)  loss_n_80: 0.5642 (0.5601)  loss_n_100: 0.6058 (0.6076)  triple_100: 0.0000 (0.0005)  triple_80: 0.0000 (0.0296)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0034)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [270/845]  eta: 0:03:12  loss: 2.1404 (2.1837)  loss_n_40: 0.4203 (0.4749)  loss_n_60: 0.4784 (0.4981)  loss_n_80: 0.5292 (0.5599)  loss_n_100: 0.5851 (0.6079)  triple_100: 0.0000 (0.0005)  triple_80: 0.0000 (0.0315)  triple_60: 0.0000 (0.0054)  triple_40: 0.0000 (0.0056)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [280/845]  eta: 0:03:09  loss: 2.0995 (2.1840)  loss_n_40: 0.4406 (0.4748)  loss_n_60: 0.4763 (0.4986)  loss_n_80: 0.5670 (0.5614)  loss_n_100: 0.5834 (0.6078)  triple_100: 0.0000 (0.0005)  triple_80: 0.0000 (0.0303)  triple_60: 0.0000 (0.0052)  triple_40: 0.0000 (0.0054)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [290/845]  eta: 0:03:06  loss: 2.0742 (2.1799)  loss_n_40: 0.4420 (0.4742)  loss_n_60: 0.4628 (0.4974)  loss_n_80: 0.5670 (0.5611)  loss_n_100: 0.5717 (0.6073)  triple_100: 0.0000 (0.0004)  triple_80: 0.0000 (0.0293)  triple_60: 0.0000 (0.0050)  triple_40: 0.0000 (0.0052)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [300/845]  eta: 0:03:02  loss: 2.0208 (2.1799)  loss_n_40: 0.4585 (0.4757)  loss_n_60: 0.4727 (0.4976)  loss_n_80: 0.5341 (0.5615)  loss_n_100: 0.5686 (0.6065)  triple_100: 0.0000 (0.0004)  triple_80: 0.0000 (0.0283)  triple_60: 0.0000 (0.0049)  triple_40: 0.0000 (0.0050)  time: 0.3343  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:12]  [310/845]  eta: 0:02:59  loss: 1.9657 (2.1762)  loss_n_40: 0.4944 (0.4764)  loss_n_60: 0.4591 (0.4975)  loss_n_80: 0.4908 (0.5599)  loss_n_100: 0.5302 (0.6050)  triple_100: 0.0000 (0.0004)  triple_80: 0.0000 (0.0274)  triple_60: 0.0000 (0.0047)  triple_40: 0.0000 (0.0049)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [320/845]  eta: 0:02:55  loss: 1.8635 (2.1733)  loss_n_40: 0.4487 (0.4757)  loss_n_60: 0.4283 (0.4974)  loss_n_80: 0.5057 (0.5591)  loss_n_100: 0.5457 (0.6049)  triple_100: 0.0000 (0.0004)  triple_80: 0.0000 (0.0266)  triple_60: 0.0000 (0.0046)  triple_40: 0.0000 (0.0047)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [330/845]  eta: 0:02:52  loss: 2.2367 (2.1767)  loss_n_40: 0.4621 (0.4776)  loss_n_60: 0.5019 (0.4998)  loss_n_80: 0.5669 (0.5594)  loss_n_100: 0.5566 (0.6047)  triple_100: 0.0000 (0.0004)  triple_80: 0.0000 (0.0258)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0046)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [340/845]  eta: 0:02:49  loss: 2.0492 (2.1704)  loss_n_40: 0.4621 (0.4764)  loss_n_60: 0.4681 (0.4983)  loss_n_80: 0.5144 (0.5585)  loss_n_100: 0.5373 (0.6030)  triple_100: 0.0000 (0.0004)  triple_80: 0.0000 (0.0250)  triple_60: 0.0000 (0.0043)  triple_40: 0.0000 (0.0045)  time: 0.3341  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:12]  [350/845]  eta: 0:02:45  loss: 2.0492 (2.1737)  loss_n_40: 0.4670 (0.4773)  loss_n_60: 0.4838 (0.4988)  loss_n_80: 0.5144 (0.5591)  loss_n_100: 0.5594 (0.6039)  triple_100: 0.0000 (0.0004)  triple_80: 0.0000 (0.0257)  triple_60: 0.0000 (0.0042)  triple_40: 0.0000 (0.0043)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [360/845]  eta: 0:02:42  loss: 2.2176 (2.1743)  loss_n_40: 0.4840 (0.4781)  loss_n_60: 0.5005 (0.4988)  loss_n_80: 0.5804 (0.5594)  loss_n_100: 0.5828 (0.6045)  triple_100: 0.0000 (0.0004)  triple_80: 0.0000 (0.0250)  triple_60: 0.0000 (0.0040)  triple_40: 0.0000 (0.0042)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [370/845]  eta: 0:02:39  loss: 2.1754 (2.1812)  loss_n_40: 0.4669 (0.4781)  loss_n_60: 0.4965 (0.4988)  loss_n_80: 0.5796 (0.5589)  loss_n_100: 0.5268 (0.6042)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0321)  triple_60: 0.0000 (0.0039)  triple_40: 0.0000 (0.0041)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [380/845]  eta: 0:02:35  loss: 1.9083 (2.1785)  loss_n_40: 0.4331 (0.4777)  loss_n_60: 0.4245 (0.4985)  loss_n_80: 0.5174 (0.5586)  loss_n_100: 0.5268 (0.6036)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0313)  triple_60: 0.0000 (0.0038)  triple_40: 0.0000 (0.0040)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [390/845]  eta: 0:02:32  loss: 2.1881 (2.1805)  loss_n_40: 0.4546 (0.4781)  loss_n_60: 0.4952 (0.4989)  loss_n_80: 0.5414 (0.5591)  loss_n_100: 0.5674 (0.6044)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0305)  triple_60: 0.0000 (0.0037)  triple_40: 0.0000 (0.0039)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [400/845]  eta: 0:02:29  loss: 2.2150 (2.1812)  loss_n_40: 0.4484 (0.4776)  loss_n_60: 0.4952 (0.4985)  loss_n_80: 0.5414 (0.5589)  loss_n_100: 0.5840 (0.6045)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0309)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0044)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [410/845]  eta: 0:02:25  loss: 2.0566 (2.1778)  loss_n_40: 0.4351 (0.4771)  loss_n_60: 0.4628 (0.4976)  loss_n_80: 0.5214 (0.5583)  loss_n_100: 0.5826 (0.6041)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0302)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0043)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [420/845]  eta: 0:02:22  loss: 1.8527 (2.1737)  loss_n_40: 0.4350 (0.4760)  loss_n_60: 0.4192 (0.4962)  loss_n_80: 0.4973 (0.5571)  loss_n_100: 0.5426 (0.6028)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0303)  triple_60: 0.0000 (0.0049)  triple_40: 0.0000 (0.0047)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [430/845]  eta: 0:02:18  loss: 2.1152 (2.1753)  loss_n_40: 0.4357 (0.4764)  loss_n_60: 0.4637 (0.4960)  loss_n_80: 0.5244 (0.5570)  loss_n_100: 0.5843 (0.6034)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0306)  triple_60: 0.0000 (0.0051)  triple_40: 0.0000 (0.0053)  time: 0.3338  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:12]  [440/845]  eta: 0:02:15  loss: 2.1152 (2.1724)  loss_n_40: 0.4333 (0.4760)  loss_n_60: 0.4870 (0.4953)  loss_n_80: 0.5280 (0.5564)  loss_n_100: 0.6044 (0.6030)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0299)  triple_60: 0.0000 (0.0049)  triple_40: 0.0000 (0.0051)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [450/845]  eta: 0:02:12  loss: 2.0300 (2.1687)  loss_n_40: 0.4279 (0.4751)  loss_n_60: 0.4498 (0.4944)  loss_n_80: 0.4947 (0.5559)  loss_n_100: 0.5471 (0.6026)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0292)  triple_60: 0.0000 (0.0048)  triple_40: 0.0000 (0.0050)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [460/845]  eta: 0:02:08  loss: 2.0367 (2.1663)  loss_n_40: 0.4559 (0.4753)  loss_n_60: 0.4438 (0.4939)  loss_n_80: 0.4988 (0.5557)  loss_n_100: 0.5471 (0.6016)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0286)  triple_60: 0.0000 (0.0047)  triple_40: 0.0000 (0.0049)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [470/845]  eta: 0:02:05  loss: 1.9778 (2.1619)  loss_n_40: 0.4437 (0.4741)  loss_n_60: 0.4438 (0.4929)  loss_n_80: 0.4988 (0.5548)  loss_n_100: 0.5574 (0.6011)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0280)  triple_60: 0.0000 (0.0046)  triple_40: 0.0000 (0.0048)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [480/845]  eta: 0:02:02  loss: 2.1184 (2.1639)  loss_n_40: 0.4375 (0.4748)  loss_n_60: 0.4870 (0.4932)  loss_n_80: 0.5500 (0.5557)  loss_n_100: 0.5763 (0.6020)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0274)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0047)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [490/845]  eta: 0:01:58  loss: 2.1869 (2.1611)  loss_n_40: 0.4533 (0.4743)  loss_n_60: 0.4888 (0.4927)  loss_n_80: 0.5589 (0.5553)  loss_n_100: 0.5590 (0.6013)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0268)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0046)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [500/845]  eta: 0:01:55  loss: 2.0942 (2.1599)  loss_n_40: 0.4254 (0.4741)  loss_n_60: 0.4736 (0.4930)  loss_n_80: 0.5212 (0.5550)  loss_n_100: 0.5590 (0.6012)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0263)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0045)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [510/845]  eta: 0:01:52  loss: 2.0118 (2.1595)  loss_n_40: 0.4457 (0.4740)  loss_n_60: 0.4607 (0.4928)  loss_n_80: 0.5288 (0.5553)  loss_n_100: 0.5595 (0.6015)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0258)  triple_60: 0.0000 (0.0043)  triple_40: 0.0000 (0.0044)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [520/845]  eta: 0:01:48  loss: 2.1368 (2.1602)  loss_n_40: 0.4568 (0.4740)  loss_n_60: 0.4821 (0.4930)  loss_n_80: 0.5740 (0.5556)  loss_n_100: 0.6250 (0.6023)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0042)  triple_40: 0.0000 (0.0043)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [530/845]  eta: 0:01:45  loss: 1.9462 (2.1580)  loss_n_40: 0.4459 (0.4738)  loss_n_60: 0.4490 (0.4927)  loss_n_80: 0.5700 (0.5555)  loss_n_100: 0.5459 (0.6014)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0248)  triple_60: 0.0000 (0.0041)  triple_40: 0.0000 (0.0043)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [540/845]  eta: 0:01:42  loss: 1.9076 (2.1567)  loss_n_40: 0.4327 (0.4742)  loss_n_60: 0.4258 (0.4924)  loss_n_80: 0.5034 (0.5552)  loss_n_100: 0.5184 (0.6009)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0244)  triple_60: 0.0000 (0.0040)  triple_40: 0.0000 (0.0042)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [550/845]  eta: 0:01:38  loss: 2.0680 (2.1554)  loss_n_40: 0.4619 (0.4743)  loss_n_60: 0.4531 (0.4928)  loss_n_80: 0.5352 (0.5548)  loss_n_100: 0.5184 (0.6001)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0040)  triple_40: 0.0000 (0.0041)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [560/845]  eta: 0:01:35  loss: 2.0670 (2.1547)  loss_n_40: 0.4525 (0.4746)  loss_n_60: 0.4488 (0.4926)  loss_n_80: 0.5497 (0.5550)  loss_n_100: 0.5435 (0.5998)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0039)  triple_40: 0.0000 (0.0040)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [570/845]  eta: 0:01:32  loss: 1.9870 (2.1561)  loss_n_40: 0.4364 (0.4761)  loss_n_60: 0.4488 (0.4933)  loss_n_80: 0.5516 (0.5551)  loss_n_100: 0.5438 (0.5995)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0231)  triple_60: 0.0000 (0.0038)  triple_40: 0.0000 (0.0040)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [580/845]  eta: 0:01:28  loss: 2.1139 (2.1554)  loss_n_40: 0.4443 (0.4758)  loss_n_60: 0.4675 (0.4930)  loss_n_80: 0.5506 (0.5555)  loss_n_100: 0.5608 (0.5995)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0227)  triple_60: 0.0000 (0.0038)  triple_40: 0.0000 (0.0039)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [590/845]  eta: 0:01:25  loss: 1.9517 (2.1518)  loss_n_40: 0.4432 (0.4751)  loss_n_60: 0.4537 (0.4922)  loss_n_80: 0.5286 (0.5546)  loss_n_100: 0.5581 (0.5989)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0223)  triple_60: 0.0000 (0.0037)  triple_40: 0.0000 (0.0038)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [600/845]  eta: 0:01:21  loss: 2.0513 (2.1549)  loss_n_40: 0.4456 (0.4756)  loss_n_60: 0.4941 (0.4932)  loss_n_80: 0.5347 (0.5547)  loss_n_100: 0.5393 (0.5987)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0219)  triple_60: 0.0000 (0.0036)  triple_40: 0.0000 (0.0038)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [610/845]  eta: 0:01:18  loss: 2.1870 (2.1548)  loss_n_40: 0.4832 (0.4754)  loss_n_60: 0.5214 (0.4933)  loss_n_80: 0.5800 (0.5550)  loss_n_100: 0.5845 (0.5989)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0216)  triple_60: 0.0000 (0.0036)  triple_40: 0.0000 (0.0037)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [620/845]  eta: 0:01:15  loss: 2.0658 (2.1543)  loss_n_40: 0.4790 (0.4761)  loss_n_60: 0.4528 (0.4930)  loss_n_80: 0.5802 (0.5552)  loss_n_100: 0.5318 (0.5984)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0212)  triple_60: 0.0000 (0.0035)  triple_40: 0.0000 (0.0036)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [630/845]  eta: 0:01:11  loss: 2.0221 (2.1524)  loss_n_40: 0.4309 (0.4754)  loss_n_60: 0.4585 (0.4927)  loss_n_80: 0.5563 (0.5549)  loss_n_100: 0.5606 (0.5983)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0209)  triple_60: 0.0000 (0.0035)  triple_40: 0.0000 (0.0036)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [640/845]  eta: 0:01:08  loss: 2.0681 (2.1519)  loss_n_40: 0.4309 (0.4759)  loss_n_60: 0.4673 (0.4928)  loss_n_80: 0.5180 (0.5546)  loss_n_100: 0.5690 (0.5979)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0206)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0035)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [650/845]  eta: 0:01:05  loss: 2.0825 (2.1524)  loss_n_40: 0.4491 (0.4759)  loss_n_60: 0.4673 (0.4928)  loss_n_80: 0.5111 (0.5552)  loss_n_100: 0.5646 (0.5983)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0202)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0035)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [660/845]  eta: 0:01:01  loss: 2.2121 (2.1543)  loss_n_40: 0.4545 (0.4760)  loss_n_60: 0.5061 (0.4932)  loss_n_80: 0.5837 (0.5560)  loss_n_100: 0.6517 (0.5993)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0199)  triple_60: 0.0000 (0.0033)  triple_40: 0.0000 (0.0034)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [670/845]  eta: 0:00:58  loss: 2.1942 (2.1535)  loss_n_40: 0.4757 (0.4760)  loss_n_60: 0.5061 (0.4931)  loss_n_80: 0.5889 (0.5562)  loss_n_100: 0.6209 (0.5989)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0196)  triple_60: 0.0000 (0.0033)  triple_40: 0.0000 (0.0034)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [680/845]  eta: 0:00:55  loss: 2.1569 (2.1585)  loss_n_40: 0.4670 (0.4759)  loss_n_60: 0.4869 (0.4930)  loss_n_80: 0.5833 (0.5569)  loss_n_100: 0.5890 (0.5998)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0209)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0046)  time: 0.3340  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:12]  [690/845]  eta: 0:00:51  loss: 2.2084 (2.1584)  loss_n_40: 0.4509 (0.4761)  loss_n_60: 0.4754 (0.4930)  loss_n_80: 0.5690 (0.5570)  loss_n_100: 0.6083 (0.5998)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0206)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0046)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [700/845]  eta: 0:00:48  loss: 2.2041 (2.1688)  loss_n_40: 0.4708 (0.4763)  loss_n_60: 0.4877 (0.4935)  loss_n_80: 0.5951 (0.5575)  loss_n_100: 0.6084 (0.6003)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0066)  triple_40: 0.0000 (0.0084)  time: 0.3335  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [710/845]  eta: 0:00:45  loss: 2.1843 (2.1670)  loss_n_40: 0.4371 (0.4757)  loss_n_60: 0.4961 (0.4931)  loss_n_80: 0.5554 (0.5573)  loss_n_100: 0.6084 (0.6003)  triple_100: 0.0000 (0.0028)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0065)  triple_40: 0.0000 (0.0083)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [720/845]  eta: 0:00:41  loss: 1.9828 (2.1684)  loss_n_40: 0.4308 (0.4761)  loss_n_60: 0.4678 (0.4933)  loss_n_80: 0.5302 (0.5578)  loss_n_100: 0.5799 (0.6005)  triple_100: 0.0000 (0.0028)  triple_80: 0.0000 (0.0234)  triple_60: 0.0000 (0.0064)  triple_40: 0.0000 (0.0082)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [730/845]  eta: 0:00:38  loss: 1.9490 (2.1671)  loss_n_40: 0.4353 (0.4755)  loss_n_60: 0.4548 (0.4928)  loss_n_80: 0.5148 (0.5578)  loss_n_100: 0.5655 (0.6008)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0063)  triple_40: 0.0000 (0.0081)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [740/845]  eta: 0:00:35  loss: 1.8746 (2.1678)  loss_n_40: 0.4385 (0.4765)  loss_n_60: 0.4171 (0.4935)  loss_n_80: 0.4989 (0.5576)  loss_n_100: 0.5238 (0.6004)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0227)  triple_60: 0.0000 (0.0062)  triple_40: 0.0000 (0.0080)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [750/845]  eta: 0:00:31  loss: 1.8950 (2.1646)  loss_n_40: 0.4416 (0.4765)  loss_n_60: 0.4281 (0.4929)  loss_n_80: 0.4989 (0.5568)  loss_n_100: 0.5173 (0.5993)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0224)  triple_60: 0.0000 (0.0062)  triple_40: 0.0000 (0.0079)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [760/845]  eta: 0:00:28  loss: 2.0619 (2.1641)  loss_n_40: 0.4192 (0.4766)  loss_n_60: 0.4398 (0.4926)  loss_n_80: 0.5152 (0.5570)  loss_n_100: 0.5048 (0.5993)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0221)  triple_60: 0.0000 (0.0061)  triple_40: 0.0000 (0.0078)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [770/845]  eta: 0:00:25  loss: 2.1174 (2.1652)  loss_n_40: 0.4528 (0.4769)  loss_n_60: 0.4699 (0.4926)  loss_n_80: 0.5783 (0.5576)  loss_n_100: 0.6146 (0.6000)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0218)  triple_60: 0.0000 (0.0060)  triple_40: 0.0000 (0.0077)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [780/845]  eta: 0:00:21  loss: 2.1809 (2.1665)  loss_n_40: 0.4873 (0.4771)  loss_n_60: 0.4802 (0.4933)  loss_n_80: 0.5890 (0.5581)  loss_n_100: 0.6165 (0.6003)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0216)  triple_60: 0.0000 (0.0059)  triple_40: 0.0000 (0.0076)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [790/845]  eta: 0:00:18  loss: 2.1205 (2.1655)  loss_n_40: 0.4665 (0.4774)  loss_n_60: 0.4909 (0.4932)  loss_n_80: 0.5473 (0.5579)  loss_n_100: 0.5961 (0.5999)  triple_100: 0.0000 (0.0025)  triple_80: 0.0000 (0.0213)  triple_60: 0.0000 (0.0059)  triple_40: 0.0000 (0.0075)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [800/845]  eta: 0:00:15  loss: 2.0972 (2.1656)  loss_n_40: 0.4629 (0.4776)  loss_n_60: 0.4850 (0.4932)  loss_n_80: 0.5198 (0.5578)  loss_n_100: 0.5529 (0.6003)  triple_100: 0.0000 (0.0025)  triple_80: 0.0000 (0.0210)  triple_60: 0.0000 (0.0058)  triple_40: 0.0000 (0.0074)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [810/845]  eta: 0:00:11  loss: 1.9843 (2.1647)  loss_n_40: 0.4736 (0.4776)  loss_n_60: 0.4636 (0.4929)  loss_n_80: 0.5102 (0.5578)  loss_n_100: 0.5529 (0.6002)  triple_100: 0.0000 (0.0025)  triple_80: 0.0000 (0.0208)  triple_60: 0.0000 (0.0057)  triple_40: 0.0000 (0.0073)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [820/845]  eta: 0:00:08  loss: 1.9557 (2.1620)  loss_n_40: 0.4235 (0.4766)  loss_n_60: 0.4313 (0.4927)  loss_n_80: 0.5102 (0.5571)  loss_n_100: 0.5344 (0.5997)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0205)  triple_60: 0.0000 (0.0056)  triple_40: 0.0000 (0.0072)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [830/845]  eta: 0:00:05  loss: 1.9714 (2.1610)  loss_n_40: 0.4171 (0.4766)  loss_n_60: 0.4236 (0.4924)  loss_n_80: 0.5049 (0.5570)  loss_n_100: 0.5621 (0.5996)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0203)  triple_60: 0.0000 (0.0056)  triple_40: 0.0000 (0.0071)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [840/845]  eta: 0:00:01  loss: 2.0193 (2.1610)  loss_n_40: 0.4418 (0.4770)  loss_n_60: 0.4344 (0.4924)  loss_n_80: 0.5541 (0.5571)  loss_n_100: 0.5635 (0.5996)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0200)  triple_60: 0.0000 (0.0055)  triple_40: 0.0000 (0.0070)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12]  [844/845]  eta: 0:00:00  loss: 2.0620 (2.1665)  loss_n_40: 0.4796 (0.4772)  loss_n_60: 0.4806 (0.4927)  loss_n_80: 0.5655 (0.5577)  loss_n_100: 0.5883 (0.6000)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0055)  triple_40: 0.0000 (0.0075)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:12] Total time: 0:04:42 (0.3345 s / it)\n",
      "Averaged stats: loss: 2.0620 (2.1665)  loss_n_40: 0.4796 (0.4772)  loss_n_60: 0.4806 (0.4927)  loss_n_80: 0.5655 (0.5577)  loss_n_100: 0.5883 (0.6000)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0055)  triple_40: 0.0000 (0.0075)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_12_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 0.600%\n",
      "Min loss_n_100: 0.575\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:13]  [   0/1724]  eta: 1:59:55  lr: 0.000200  loss: 2.4878 (2.4878)  loss_n_40: 0.4897 (0.4897)  loss_n_60: 0.5155 (0.5155)  loss_n_80: 0.6258 (0.6258)  loss_n_100: 0.6565 (0.6565)  triple_100: 0.0000 (0.0000)  triple_80: 0.2003 (0.2003)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1737  data: 0.4183  max mem: 46473\n",
      "Train: [epoch:13]  [  10/1724]  eta: 1:52:33  lr: 0.000200  loss: 2.1326 (2.1711)  loss_n_40: 0.4652 (0.4771)  loss_n_60: 0.4788 (0.4881)  loss_n_80: 0.5690 (0.5700)  loss_n_100: 0.5924 (0.6014)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0341)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0005)  time: 3.9400  data: 0.0382  max mem: 46473\n",
      "Train: [epoch:13]  [  20/1724]  eta: 1:51:35  lr: 0.000200  loss: 2.0283 (2.0633)  loss_n_40: 0.4402 (0.4521)  loss_n_60: 0.4681 (0.4642)  loss_n_80: 0.5334 (0.5408)  loss_n_100: 0.5706 (0.5881)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0179)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0002)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [  30/1724]  eta: 1:50:50  lr: 0.000200  loss: 1.8980 (2.0005)  loss_n_40: 0.4299 (0.4401)  loss_n_60: 0.4419 (0.4546)  loss_n_80: 0.4883 (0.5222)  loss_n_100: 0.5428 (0.5713)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0121)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0002)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [  40/1724]  eta: 1:50:08  lr: 0.000200  loss: 1.8020 (1.9322)  loss_n_40: 0.3728 (0.4306)  loss_n_60: 0.4098 (0.4391)  loss_n_80: 0.4483 (0.5005)  loss_n_100: 0.5014 (0.5528)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0092)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0001)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [  50/1724]  eta: 1:49:27  lr: 0.000200  loss: 1.6711 (1.8848)  loss_n_40: 0.3576 (0.4171)  loss_n_60: 0.3840 (0.4288)  loss_n_80: 0.4403 (0.4906)  loss_n_100: 0.4862 (0.5408)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0074)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0001)  time: 3.9186  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [  60/1724]  eta: 1:48:47  lr: 0.000200  loss: 1.7013 (1.8685)  loss_n_40: 0.3631 (0.4127)  loss_n_60: 0.3940 (0.4286)  loss_n_80: 0.4626 (0.4861)  loss_n_100: 0.5013 (0.5348)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0062)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0001)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [  70/1724]  eta: 1:48:06  lr: 0.000200  loss: 1.7301 (1.8475)  loss_n_40: 0.3777 (0.4104)  loss_n_60: 0.4104 (0.4263)  loss_n_80: 0.4377 (0.4797)  loss_n_100: 0.4794 (0.5258)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0053)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0001)  time: 3.9173  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [  80/1724]  eta: 1:47:25  lr: 0.000200  loss: 1.7053 (1.8302)  loss_n_40: 0.3876 (0.4109)  loss_n_60: 0.4121 (0.4236)  loss_n_80: 0.4324 (0.4722)  loss_n_100: 0.4753 (0.5188)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0046)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0001)  time: 3.9158  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [  90/1724]  eta: 1:46:45  lr: 0.000200  loss: 1.5654 (1.7902)  loss_n_40: 0.3617 (0.4026)  loss_n_60: 0.3563 (0.4146)  loss_n_80: 0.3973 (0.4617)  loss_n_100: 0.4276 (0.5071)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0041)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0001)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 100/1724]  eta: 1:46:05  lr: 0.000200  loss: 1.5095 (1.7702)  loss_n_40: 0.3350 (0.3983)  loss_n_60: 0.3563 (0.4107)  loss_n_80: 0.3929 (0.4574)  loss_n_100: 0.4135 (0.5000)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0037)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0001)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 110/1724]  eta: 1:45:26  lr: 0.000200  loss: 1.5265 (1.7678)  loss_n_40: 0.3350 (0.3946)  loss_n_60: 0.3641 (0.4073)  loss_n_80: 0.4122 (0.4532)  loss_n_100: 0.4233 (0.4943)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0034)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0151)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 120/1724]  eta: 1:44:46  lr: 0.000200  loss: 1.4996 (1.7501)  loss_n_40: 0.3150 (0.3897)  loss_n_60: 0.3593 (0.4040)  loss_n_80: 0.3815 (0.4494)  loss_n_100: 0.4233 (0.4900)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0031)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0139)  time: 3.9171  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 130/1724]  eta: 1:44:07  lr: 0.000200  loss: 1.6558 (1.7570)  loss_n_40: 0.3486 (0.3897)  loss_n_60: 0.3955 (0.4064)  loss_n_80: 0.4530 (0.4522)  loss_n_100: 0.4587 (0.4926)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0029)  triple_60: 0.0000 (0.0004)  triple_40: 0.0000 (0.0128)  time: 3.9160  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 140/1724]  eta: 1:43:27  lr: 0.000200  loss: 1.7006 (1.7476)  loss_n_40: 0.3581 (0.3866)  loss_n_60: 0.4049 (0.4052)  loss_n_80: 0.4453 (0.4505)  loss_n_100: 0.4831 (0.4904)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0027)  triple_60: 0.0000 (0.0004)  triple_40: 0.0000 (0.0119)  time: 3.9149  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 150/1724]  eta: 1:42:47  lr: 0.000200  loss: 1.6163 (1.7397)  loss_n_40: 0.3359 (0.3847)  loss_n_60: 0.3818 (0.4047)  loss_n_80: 0.4186 (0.4483)  loss_n_100: 0.4609 (0.4881)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0025)  triple_60: 0.0000 (0.0004)  triple_40: 0.0000 (0.0111)  time: 3.9148  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 160/1724]  eta: 1:42:08  lr: 0.000200  loss: 1.4647 (1.7260)  loss_n_40: 0.3411 (0.3823)  loss_n_60: 0.3511 (0.4018)  loss_n_80: 0.3780 (0.4447)  loss_n_100: 0.4063 (0.4840)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0023)  triple_60: 0.0000 (0.0003)  triple_40: 0.0000 (0.0104)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 170/1724]  eta: 1:41:28  lr: 0.000200  loss: 1.4647 (1.7210)  loss_n_40: 0.3520 (0.3821)  loss_n_60: 0.3482 (0.4013)  loss_n_80: 0.3796 (0.4433)  loss_n_100: 0.4063 (0.4819)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0022)  triple_60: 0.0000 (0.0003)  triple_40: 0.0000 (0.0098)  time: 3.9159  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 180/1724]  eta: 1:40:49  lr: 0.000200  loss: 1.4579 (1.7102)  loss_n_40: 0.3158 (0.3802)  loss_n_60: 0.3513 (0.3993)  loss_n_80: 0.3704 (0.4403)  loss_n_100: 0.4126 (0.4787)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0021)  triple_60: 0.0000 (0.0003)  triple_40: 0.0000 (0.0093)  time: 3.9147  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 190/1724]  eta: 1:40:10  lr: 0.000200  loss: 1.5411 (1.7249)  loss_n_40: 0.3438 (0.3811)  loss_n_60: 0.3568 (0.4003)  loss_n_80: 0.3876 (0.4415)  loss_n_100: 0.4339 (0.4813)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0049)  triple_60: 0.0000 (0.0037)  triple_40: 0.0000 (0.0105)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 200/1724]  eta: 1:39:31  lr: 0.000200  loss: 1.9398 (1.7403)  loss_n_40: 0.4284 (0.3832)  loss_n_60: 0.4350 (0.4028)  loss_n_80: 0.5019 (0.4451)  loss_n_100: 0.5514 (0.4860)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0067)  triple_60: 0.0000 (0.0041)  triple_40: 0.0000 (0.0108)  time: 3.9175  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 210/1724]  eta: 1:38:51  lr: 0.000200  loss: 1.7913 (1.7380)  loss_n_40: 0.4105 (0.3828)  loss_n_60: 0.4054 (0.4021)  loss_n_80: 0.4766 (0.4447)  loss_n_100: 0.5386 (0.4864)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0064)  triple_60: 0.0000 (0.0039)  triple_40: 0.0000 (0.0103)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 220/1724]  eta: 1:38:12  lr: 0.000200  loss: 1.6458 (1.7368)  loss_n_40: 0.3497 (0.3830)  loss_n_60: 0.3788 (0.4018)  loss_n_80: 0.4202 (0.4443)  loss_n_100: 0.4858 (0.4866)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0061)  triple_60: 0.0000 (0.0037)  triple_40: 0.0000 (0.0099)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 230/1724]  eta: 1:37:33  lr: 0.000200  loss: 1.5825 (1.7296)  loss_n_40: 0.3256 (0.3818)  loss_n_60: 0.3777 (0.4000)  loss_n_80: 0.4097 (0.4426)  loss_n_100: 0.4612 (0.4850)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0058)  triple_60: 0.0000 (0.0036)  triple_40: 0.0000 (0.0094)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 240/1724]  eta: 1:36:54  lr: 0.000200  loss: 1.4727 (1.7180)  loss_n_40: 0.3171 (0.3793)  loss_n_60: 0.3357 (0.3975)  loss_n_80: 0.3741 (0.4395)  loss_n_100: 0.4275 (0.4824)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0056)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0090)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 250/1724]  eta: 1:36:15  lr: 0.000200  loss: 1.4483 (1.7092)  loss_n_40: 0.3124 (0.3772)  loss_n_60: 0.3390 (0.3958)  loss_n_80: 0.3635 (0.4373)  loss_n_100: 0.4219 (0.4803)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0054)  triple_60: 0.0000 (0.0033)  triple_40: 0.0000 (0.0087)  time: 3.9195  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 260/1724]  eta: 1:35:36  lr: 0.000200  loss: 1.4900 (1.7052)  loss_n_40: 0.3231 (0.3770)  loss_n_60: 0.3501 (0.3955)  loss_n_80: 0.3944 (0.4361)  loss_n_100: 0.4264 (0.4788)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0051)  triple_60: 0.0000 (0.0032)  triple_40: 0.0000 (0.0083)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 270/1724]  eta: 1:34:57  lr: 0.000200  loss: 1.4736 (1.6957)  loss_n_40: 0.3193 (0.3751)  loss_n_60: 0.3498 (0.3936)  loss_n_80: 0.3718 (0.4335)  loss_n_100: 0.4155 (0.4763)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0050)  triple_60: 0.0000 (0.0030)  triple_40: 0.0000 (0.0080)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 280/1724]  eta: 1:34:17  lr: 0.000200  loss: 1.4217 (1.7152)  loss_n_40: 0.3078 (0.3737)  loss_n_60: 0.3303 (0.3920)  loss_n_80: 0.3682 (0.4318)  loss_n_100: 0.4111 (0.4745)  triple_100: 0.0000 (0.0092)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0145)  time: 3.9169  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 290/1724]  eta: 1:33:38  lr: 0.000200  loss: 1.7166 (1.7567)  loss_n_40: 0.3781 (0.3770)  loss_n_60: 0.4016 (0.3967)  loss_n_80: 0.4560 (0.4395)  loss_n_100: 0.5339 (0.4841)  triple_100: 0.0000 (0.0108)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0126)  triple_40: 0.0000 (0.0204)  time: 3.9159  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [ 300/1724]  eta: 1:32:59  lr: 0.000200  loss: 3.1334 (1.8176)  loss_n_40: 0.5812 (0.3866)  loss_n_60: 0.6523 (0.4089)  loss_n_80: 0.8595 (0.4572)  loss_n_100: 0.9722 (0.5065)  triple_100: 0.0000 (0.0107)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0121)  triple_40: 0.0000 (0.0197)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 310/1724]  eta: 1:32:19  lr: 0.000200  loss: 3.2192 (1.8600)  loss_n_40: 0.6242 (0.3960)  loss_n_60: 0.6877 (0.4179)  loss_n_80: 0.8695 (0.4688)  loss_n_100: 1.0300 (0.5208)  triple_100: 0.0000 (0.0104)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0117)  triple_40: 0.0000 (0.0191)  time: 3.9149  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 320/1724]  eta: 1:31:40  lr: 0.000200  loss: 2.8394 (1.8872)  loss_n_40: 0.6242 (0.4031)  loss_n_60: 0.6179 (0.4232)  loss_n_80: 0.7395 (0.4762)  loss_n_100: 0.8840 (0.5299)  triple_100: 0.0000 (0.0100)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0114)  triple_40: 0.0000 (0.0185)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 330/1724]  eta: 1:31:01  lr: 0.000200  loss: 2.5725 (1.8970)  loss_n_40: 0.5495 (0.4057)  loss_n_60: 0.5316 (0.4259)  loss_n_80: 0.6316 (0.4792)  loss_n_100: 0.7111 (0.5332)  triple_100: 0.0000 (0.0097)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0179)  time: 3.9171  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 340/1724]  eta: 1:30:22  lr: 0.000200  loss: 2.0573 (1.9020)  loss_n_40: 0.4791 (0.4073)  loss_n_60: 0.4802 (0.4274)  loss_n_80: 0.5404 (0.4807)  loss_n_100: 0.6242 (0.5351)  triple_100: 0.0000 (0.0095)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0107)  triple_40: 0.0000 (0.0174)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 350/1724]  eta: 1:29:43  lr: 0.000200  loss: 1.9867 (1.9042)  loss_n_40: 0.4405 (0.4084)  loss_n_60: 0.4533 (0.4285)  loss_n_80: 0.4924 (0.4812)  loss_n_100: 0.5694 (0.5360)  triple_100: 0.0000 (0.0092)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0169)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 360/1724]  eta: 1:29:03  lr: 0.000200  loss: 1.9176 (1.9049)  loss_n_40: 0.4315 (0.4097)  loss_n_60: 0.4410 (0.4293)  loss_n_80: 0.4713 (0.4810)  loss_n_100: 0.5389 (0.5363)  triple_100: 0.0000 (0.0089)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0165)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 370/1724]  eta: 1:28:24  lr: 0.000200  loss: 1.7723 (1.9016)  loss_n_40: 0.4138 (0.4097)  loss_n_60: 0.4111 (0.4291)  loss_n_80: 0.4438 (0.4802)  loss_n_100: 0.5092 (0.5352)  triple_100: 0.0000 (0.0087)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0160)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 380/1724]  eta: 1:27:45  lr: 0.000200  loss: 1.7396 (1.8978)  loss_n_40: 0.3797 (0.4088)  loss_n_60: 0.3968 (0.4286)  loss_n_80: 0.4362 (0.4796)  loss_n_100: 0.4992 (0.5346)  triple_100: 0.0000 (0.0085)  triple_80: 0.0000 (0.0125)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0156)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 390/1724]  eta: 1:27:06  lr: 0.000200  loss: 1.6155 (1.8910)  loss_n_40: 0.3618 (0.4076)  loss_n_60: 0.3787 (0.4274)  loss_n_80: 0.4190 (0.4780)  loss_n_100: 0.4829 (0.5329)  triple_100: 0.0000 (0.0082)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0152)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 400/1724]  eta: 1:26:27  lr: 0.000200  loss: 1.5951 (1.8851)  loss_n_40: 0.3588 (0.4073)  loss_n_60: 0.3787 (0.4266)  loss_n_80: 0.3998 (0.4764)  loss_n_100: 0.4625 (0.5310)  triple_100: 0.0000 (0.0080)  triple_80: 0.0000 (0.0119)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0148)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 410/1724]  eta: 1:25:47  lr: 0.000200  loss: 1.6497 (1.8780)  loss_n_40: 0.3679 (0.4068)  loss_n_60: 0.3843 (0.4252)  loss_n_80: 0.3976 (0.4746)  loss_n_100: 0.4567 (0.5286)  triple_100: 0.0000 (0.0078)  triple_80: 0.0000 (0.0116)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0145)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 420/1724]  eta: 1:25:08  lr: 0.000200  loss: 1.6294 (1.8722)  loss_n_40: 0.3610 (0.4059)  loss_n_60: 0.3806 (0.4243)  loss_n_80: 0.4148 (0.4733)  loss_n_100: 0.4567 (0.5269)  triple_100: 0.0000 (0.0077)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0141)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 430/1724]  eta: 1:24:29  lr: 0.000200  loss: 1.5921 (1.8658)  loss_n_40: 0.3517 (0.4051)  loss_n_60: 0.3682 (0.4234)  loss_n_80: 0.3976 (0.4715)  loss_n_100: 0.4506 (0.5250)  triple_100: 0.0000 (0.0075)  triple_80: 0.0000 (0.0110)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0138)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 440/1724]  eta: 1:23:50  lr: 0.000200  loss: 1.5418 (1.8594)  loss_n_40: 0.3509 (0.4045)  loss_n_60: 0.3682 (0.4224)  loss_n_80: 0.3886 (0.4698)  loss_n_100: 0.4276 (0.5228)  triple_100: 0.0000 (0.0073)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0135)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 450/1724]  eta: 1:23:11  lr: 0.000200  loss: 1.4731 (1.8527)  loss_n_40: 0.3196 (0.4043)  loss_n_60: 0.3548 (0.4213)  loss_n_80: 0.3806 (0.4678)  loss_n_100: 0.4037 (0.5204)  triple_100: 0.0000 (0.0071)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0132)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 460/1724]  eta: 1:22:32  lr: 0.000200  loss: 1.5018 (1.8456)  loss_n_40: 0.3196 (0.4032)  loss_n_60: 0.3589 (0.4199)  loss_n_80: 0.3807 (0.4662)  loss_n_100: 0.4037 (0.5182)  triple_100: 0.0000 (0.0070)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0129)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 470/1724]  eta: 1:21:52  lr: 0.000200  loss: 1.4704 (1.8393)  loss_n_40: 0.3259 (0.4020)  loss_n_60: 0.3512 (0.4190)  loss_n_80: 0.3841 (0.4647)  loss_n_100: 0.4092 (0.5162)  triple_100: 0.0000 (0.0068)  triple_80: 0.0000 (0.0101)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0126)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 480/1724]  eta: 1:21:13  lr: 0.000200  loss: 1.4044 (1.8304)  loss_n_40: 0.3206 (0.4004)  loss_n_60: 0.3311 (0.4173)  loss_n_80: 0.3627 (0.4625)  loss_n_100: 0.4009 (0.5136)  triple_100: 0.0000 (0.0067)  triple_80: 0.0000 (0.0099)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0124)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 490/1724]  eta: 1:20:34  lr: 0.000200  loss: 1.4281 (1.8231)  loss_n_40: 0.3183 (0.3992)  loss_n_60: 0.3363 (0.4160)  loss_n_80: 0.3640 (0.4607)  loss_n_100: 0.3936 (0.5114)  triple_100: 0.0000 (0.0066)  triple_80: 0.0000 (0.0097)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0121)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 500/1724]  eta: 1:19:55  lr: 0.000200  loss: 1.3740 (1.8146)  loss_n_40: 0.3118 (0.3979)  loss_n_60: 0.3286 (0.4143)  loss_n_80: 0.3572 (0.4586)  loss_n_100: 0.3887 (0.5087)  triple_100: 0.0000 (0.0064)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0119)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 510/1724]  eta: 1:19:16  lr: 0.000200  loss: 1.3587 (1.8078)  loss_n_40: 0.2889 (0.3964)  loss_n_60: 0.3177 (0.4128)  loss_n_80: 0.3568 (0.4569)  loss_n_100: 0.3833 (0.5065)  triple_100: 0.0000 (0.0063)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0119)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 520/1724]  eta: 1:18:36  lr: 0.000200  loss: 1.5572 (1.8051)  loss_n_40: 0.3276 (0.3961)  loss_n_60: 0.3552 (0.4123)  loss_n_80: 0.3989 (0.4563)  loss_n_100: 0.4271 (0.5059)  triple_100: 0.0000 (0.0062)  triple_80: 0.0000 (0.0092)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0117)  time: 3.9166  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 530/1724]  eta: 1:17:57  lr: 0.000200  loss: 1.6765 (1.8020)  loss_n_40: 0.3569 (0.3957)  loss_n_60: 0.3912 (0.4119)  loss_n_80: 0.4288 (0.4555)  loss_n_100: 0.4829 (0.5051)  triple_100: 0.0000 (0.0061)  triple_80: 0.0000 (0.0090)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0114)  time: 3.9163  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [ 540/1724]  eta: 1:17:18  lr: 0.000200  loss: 1.5871 (1.7976)  loss_n_40: 0.3413 (0.3948)  loss_n_60: 0.3714 (0.4111)  loss_n_80: 0.4065 (0.4546)  loss_n_100: 0.4496 (0.5039)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0089)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0112)  time: 3.9157  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 550/1724]  eta: 1:16:39  lr: 0.000200  loss: 1.5546 (1.7933)  loss_n_40: 0.3311 (0.3941)  loss_n_60: 0.3598 (0.4105)  loss_n_80: 0.4111 (0.4537)  loss_n_100: 0.4130 (0.5024)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0087)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0110)  time: 3.9150  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 560/1724]  eta: 1:16:00  lr: 0.000200  loss: 1.4655 (1.7858)  loss_n_40: 0.3127 (0.3927)  loss_n_60: 0.3413 (0.4090)  loss_n_80: 0.3808 (0.4518)  loss_n_100: 0.3978 (0.5002)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0086)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0108)  time: 3.9151  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 570/1724]  eta: 1:15:20  lr: 0.000200  loss: 1.3847 (1.7805)  loss_n_40: 0.3127 (0.3916)  loss_n_60: 0.3314 (0.4081)  loss_n_80: 0.3528 (0.4506)  loss_n_100: 0.3782 (0.4988)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0084)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0106)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 580/1724]  eta: 1:14:41  lr: 0.000200  loss: 1.5144 (1.7962)  loss_n_40: 0.3566 (0.3914)  loss_n_60: 0.3673 (0.4082)  loss_n_80: 0.3917 (0.4507)  loss_n_100: 0.4224 (0.4991)  triple_100: 0.0000 (0.0102)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0103)  triple_40: 0.0000 (0.0133)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 590/1724]  eta: 1:14:02  lr: 0.000200  loss: 2.3657 (1.8114)  loss_n_40: 0.4180 (0.3929)  loss_n_60: 0.5145 (0.4107)  loss_n_80: 0.5612 (0.4543)  loss_n_100: 0.6310 (0.5034)  triple_100: 0.0000 (0.0104)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0167)  time: 3.9160  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 600/1724]  eta: 1:13:23  lr: 0.000200  loss: 2.2940 (1.8166)  loss_n_40: 0.4313 (0.3939)  loss_n_60: 0.5145 (0.4118)  loss_n_80: 0.6095 (0.4562)  loss_n_100: 0.6807 (0.5055)  triple_100: 0.0000 (0.0102)  triple_80: 0.0000 (0.0126)  triple_60: 0.0000 (0.0099)  triple_40: 0.0000 (0.0165)  time: 3.9145  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 610/1724]  eta: 1:12:44  lr: 0.000200  loss: 2.0928 (1.8205)  loss_n_40: 0.4272 (0.3945)  loss_n_60: 0.4645 (0.4127)  loss_n_80: 0.5529 (0.4575)  loss_n_100: 0.6223 (0.5074)  triple_100: 0.0000 (0.0101)  triple_80: 0.0000 (0.0124)  triple_60: 0.0000 (0.0097)  triple_40: 0.0000 (0.0162)  time: 3.9156  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 620/1724]  eta: 1:12:04  lr: 0.000200  loss: 1.8820 (1.8214)  loss_n_40: 0.3975 (0.3947)  loss_n_60: 0.4356 (0.4131)  loss_n_80: 0.5068 (0.4581)  loss_n_100: 0.5800 (0.5079)  triple_100: 0.0000 (0.0099)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0159)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 630/1724]  eta: 1:11:25  lr: 0.000200  loss: 1.7961 (1.8213)  loss_n_40: 0.3816 (0.3948)  loss_n_60: 0.4075 (0.4133)  loss_n_80: 0.4635 (0.4582)  loss_n_100: 0.5238 (0.5082)  triple_100: 0.0000 (0.0098)  triple_80: 0.0000 (0.0120)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0157)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 640/1724]  eta: 1:10:46  lr: 0.000200  loss: 1.7764 (1.8209)  loss_n_40: 0.3678 (0.3952)  loss_n_60: 0.4075 (0.4134)  loss_n_80: 0.4311 (0.4580)  loss_n_100: 0.5160 (0.5082)  triple_100: 0.0000 (0.0096)  triple_80: 0.0000 (0.0118)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0154)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 650/1724]  eta: 1:10:07  lr: 0.000200  loss: 1.6778 (1.8190)  loss_n_40: 0.3634 (0.3950)  loss_n_60: 0.3915 (0.4132)  loss_n_80: 0.4268 (0.4576)  loss_n_100: 0.4896 (0.5078)  triple_100: 0.0000 (0.0095)  triple_80: 0.0000 (0.0116)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0152)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 660/1724]  eta: 1:09:28  lr: 0.000200  loss: 1.6778 (1.8157)  loss_n_40: 0.3605 (0.3946)  loss_n_60: 0.3915 (0.4127)  loss_n_80: 0.4172 (0.4569)  loss_n_100: 0.4647 (0.5068)  triple_100: 0.0000 (0.0093)  triple_80: 0.0000 (0.0114)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0150)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 670/1724]  eta: 1:08:48  lr: 0.000200  loss: 1.5251 (1.8120)  loss_n_40: 0.3295 (0.3940)  loss_n_60: 0.3659 (0.4120)  loss_n_80: 0.3859 (0.4560)  loss_n_100: 0.4431 (0.5060)  triple_100: 0.0000 (0.0092)  triple_80: 0.0000 (0.0112)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0147)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 680/1724]  eta: 1:08:09  lr: 0.000200  loss: 1.6435 (1.8101)  loss_n_40: 0.3673 (0.3943)  loss_n_60: 0.3723 (0.4118)  loss_n_80: 0.4023 (0.4555)  loss_n_100: 0.4431 (0.5052)  triple_100: 0.0000 (0.0090)  triple_80: 0.0000 (0.0111)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0145)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 690/1724]  eta: 1:07:30  lr: 0.000200  loss: 1.5791 (1.8068)  loss_n_40: 0.3673 (0.3938)  loss_n_60: 0.3790 (0.4113)  loss_n_80: 0.3944 (0.4547)  loss_n_100: 0.4290 (0.5042)  triple_100: 0.0000 (0.0089)  triple_80: 0.0000 (0.0109)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0143)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 700/1724]  eta: 1:06:51  lr: 0.000200  loss: 1.5379 (1.8037)  loss_n_40: 0.3418 (0.3934)  loss_n_60: 0.3633 (0.4108)  loss_n_80: 0.3944 (0.4540)  loss_n_100: 0.4290 (0.5033)  triple_100: 0.0000 (0.0088)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0141)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 710/1724]  eta: 1:06:12  lr: 0.000200  loss: 1.5366 (1.7995)  loss_n_40: 0.3418 (0.3928)  loss_n_60: 0.3633 (0.4101)  loss_n_80: 0.4043 (0.4530)  loss_n_100: 0.4250 (0.5021)  triple_100: 0.0000 (0.0087)  triple_80: 0.0000 (0.0106)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0139)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 720/1724]  eta: 1:05:33  lr: 0.000200  loss: 1.4538 (1.7955)  loss_n_40: 0.3323 (0.3921)  loss_n_60: 0.3391 (0.4094)  loss_n_80: 0.3464 (0.4521)  loss_n_100: 0.3815 (0.5010)  triple_100: 0.0000 (0.0085)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0137)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 730/1724]  eta: 1:04:53  lr: 0.000200  loss: 1.4571 (1.7907)  loss_n_40: 0.3251 (0.3914)  loss_n_60: 0.3466 (0.4087)  loss_n_80: 0.3497 (0.4508)  loss_n_100: 0.3871 (0.4994)  triple_100: 0.0000 (0.0084)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0135)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 740/1724]  eta: 1:04:14  lr: 0.000200  loss: 1.4571 (1.7857)  loss_n_40: 0.3355 (0.3906)  loss_n_60: 0.3466 (0.4079)  loss_n_80: 0.3497 (0.4495)  loss_n_100: 0.3723 (0.4978)  triple_100: 0.0000 (0.0083)  triple_80: 0.0000 (0.0102)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0133)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 750/1724]  eta: 1:03:35  lr: 0.000200  loss: 1.3033 (1.7796)  loss_n_40: 0.2964 (0.3895)  loss_n_60: 0.3121 (0.4067)  loss_n_80: 0.3237 (0.4480)  loss_n_100: 0.3539 (0.4960)  triple_100: 0.0000 (0.0082)  triple_80: 0.0000 (0.0100)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0132)  time: 3.9190  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 760/1724]  eta: 1:02:56  lr: 0.000200  loss: 1.3033 (1.7739)  loss_n_40: 0.2875 (0.3885)  loss_n_60: 0.3121 (0.4056)  loss_n_80: 0.3233 (0.4466)  loss_n_100: 0.3505 (0.4944)  triple_100: 0.0000 (0.0081)  triple_80: 0.0000 (0.0099)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0130)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 770/1724]  eta: 1:02:17  lr: 0.000200  loss: 1.3430 (1.7688)  loss_n_40: 0.2930 (0.3878)  loss_n_60: 0.3166 (0.4046)  loss_n_80: 0.3461 (0.4453)  loss_n_100: 0.3712 (0.4928)  triple_100: 0.0000 (0.0080)  triple_80: 0.0000 (0.0098)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0128)  time: 3.9197  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [ 780/1724]  eta: 1:01:38  lr: 0.000200  loss: 1.4068 (1.7652)  loss_n_40: 0.3063 (0.3873)  loss_n_60: 0.3312 (0.4039)  loss_n_80: 0.3530 (0.4443)  loss_n_100: 0.3790 (0.4918)  triple_100: 0.0000 (0.0079)  triple_80: 0.0000 (0.0097)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0127)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 790/1724]  eta: 1:00:59  lr: 0.000200  loss: 1.3516 (1.7594)  loss_n_40: 0.2975 (0.3861)  loss_n_60: 0.3277 (0.4029)  loss_n_80: 0.3524 (0.4429)  loss_n_100: 0.3789 (0.4902)  triple_100: 0.0000 (0.0078)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0125)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 800/1724]  eta: 1:00:19  lr: 0.000200  loss: 1.3516 (1.7589)  loss_n_40: 0.3061 (0.3859)  loss_n_60: 0.3277 (0.4024)  loss_n_80: 0.3543 (0.4420)  loss_n_100: 0.3789 (0.4891)  triple_100: 0.0000 (0.0082)  triple_80: 0.0000 (0.0102)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0129)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 810/1724]  eta: 0:59:40  lr: 0.000200  loss: 1.6729 (1.7779)  loss_n_40: 0.3439 (0.3856)  loss_n_60: 0.3986 (0.4026)  loss_n_80: 0.4259 (0.4424)  loss_n_100: 0.4558 (0.4897)  triple_100: 0.0000 (0.0131)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0113)  triple_40: 0.0000 (0.0169)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 820/1724]  eta: 0:59:01  lr: 0.000200  loss: 1.9345 (1.7816)  loss_n_40: 0.3581 (0.3858)  loss_n_60: 0.4521 (0.4034)  loss_n_80: 0.5178 (0.4439)  loss_n_100: 0.5894 (0.4916)  triple_100: 0.0000 (0.0129)  triple_80: 0.0000 (0.0161)  triple_60: 0.0000 (0.0112)  triple_40: 0.0000 (0.0167)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 830/1724]  eta: 0:58:22  lr: 0.000200  loss: 2.1177 (1.7856)  loss_n_40: 0.4157 (0.3865)  loss_n_60: 0.4606 (0.4041)  loss_n_80: 0.5792 (0.4455)  loss_n_100: 0.6567 (0.4934)  triple_100: 0.0000 (0.0128)  triple_80: 0.0000 (0.0159)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0165)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 840/1724]  eta: 0:57:43  lr: 0.000200  loss: 1.9800 (1.7868)  loss_n_40: 0.4205 (0.3871)  loss_n_60: 0.4357 (0.4043)  loss_n_80: 0.5299 (0.4460)  loss_n_100: 0.5785 (0.4939)  triple_100: 0.0000 (0.0126)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0163)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 850/1724]  eta: 0:57:03  lr: 0.000200  loss: 1.7480 (1.7858)  loss_n_40: 0.3988 (0.3870)  loss_n_60: 0.4028 (0.4042)  loss_n_80: 0.4492 (0.4459)  loss_n_100: 0.5042 (0.4938)  triple_100: 0.0000 (0.0125)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0161)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 860/1724]  eta: 0:56:24  lr: 0.000200  loss: 1.6731 (1.7842)  loss_n_40: 0.3717 (0.3869)  loss_n_60: 0.3930 (0.4040)  loss_n_80: 0.4275 (0.4455)  loss_n_100: 0.4735 (0.4935)  triple_100: 0.0000 (0.0123)  triple_80: 0.0000 (0.0154)  triple_60: 0.0000 (0.0107)  triple_40: 0.0000 (0.0159)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 870/1724]  eta: 0:55:45  lr: 0.000200  loss: 1.6479 (1.7828)  loss_n_40: 0.3648 (0.3870)  loss_n_60: 0.3840 (0.4039)  loss_n_80: 0.4074 (0.4452)  loss_n_100: 0.4565 (0.4931)  triple_100: 0.0000 (0.0122)  triple_80: 0.0000 (0.0152)  triple_60: 0.0000 (0.0105)  triple_40: 0.0000 (0.0157)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 880/1724]  eta: 0:55:06  lr: 0.000200  loss: 1.4849 (1.7786)  loss_n_40: 0.3404 (0.3863)  loss_n_60: 0.3512 (0.4032)  loss_n_80: 0.3652 (0.4442)  loss_n_100: 0.4131 (0.4920)  triple_100: 0.0000 (0.0120)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0155)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 890/1724]  eta: 0:54:27  lr: 0.000200  loss: 1.4329 (1.7761)  loss_n_40: 0.3260 (0.3862)  loss_n_60: 0.3349 (0.4027)  loss_n_80: 0.3615 (0.4435)  loss_n_100: 0.3880 (0.4912)  triple_100: 0.0000 (0.0119)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0103)  triple_40: 0.0000 (0.0153)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 900/1724]  eta: 0:53:48  lr: 0.000200  loss: 1.4471 (1.7725)  loss_n_40: 0.3200 (0.3857)  loss_n_60: 0.3374 (0.4021)  loss_n_80: 0.3740 (0.4426)  loss_n_100: 0.3880 (0.4902)  triple_100: 0.0000 (0.0118)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0152)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 910/1724]  eta: 0:53:08  lr: 0.000200  loss: 1.4598 (1.7695)  loss_n_40: 0.3226 (0.3854)  loss_n_60: 0.3473 (0.4017)  loss_n_80: 0.3639 (0.4418)  loss_n_100: 0.4066 (0.4893)  triple_100: 0.0000 (0.0116)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0150)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 920/1724]  eta: 0:52:29  lr: 0.000200  loss: 1.4531 (1.7669)  loss_n_40: 0.3485 (0.3851)  loss_n_60: 0.3473 (0.4013)  loss_n_80: 0.3639 (0.4412)  loss_n_100: 0.3958 (0.4887)  triple_100: 0.0000 (0.0115)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0148)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 930/1724]  eta: 0:51:50  lr: 0.000200  loss: 1.4697 (1.7640)  loss_n_40: 0.3653 (0.3847)  loss_n_60: 0.3560 (0.4010)  loss_n_80: 0.3573 (0.4403)  loss_n_100: 0.3958 (0.4878)  triple_100: 0.0000 (0.0114)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0099)  triple_40: 0.0000 (0.0147)  time: 3.9213  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 940/1724]  eta: 0:51:11  lr: 0.000200  loss: 1.4697 (1.7603)  loss_n_40: 0.3387 (0.3842)  loss_n_60: 0.3487 (0.4004)  loss_n_80: 0.3573 (0.4394)  loss_n_100: 0.3868 (0.4867)  triple_100: 0.0000 (0.0113)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0145)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 950/1724]  eta: 0:50:32  lr: 0.000200  loss: 1.4329 (1.7586)  loss_n_40: 0.3137 (0.3841)  loss_n_60: 0.3362 (0.4002)  loss_n_80: 0.3621 (0.4390)  loss_n_100: 0.3898 (0.4863)  triple_100: 0.0000 (0.0111)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0097)  triple_40: 0.0000 (0.0144)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 960/1724]  eta: 0:49:53  lr: 0.000200  loss: 1.3766 (1.7546)  loss_n_40: 0.3022 (0.3831)  loss_n_60: 0.3251 (0.3994)  loss_n_80: 0.3589 (0.4382)  loss_n_100: 0.3989 (0.4854)  triple_100: 0.0000 (0.0110)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0142)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 970/1724]  eta: 0:49:14  lr: 0.000200  loss: 1.2967 (1.7504)  loss_n_40: 0.2841 (0.3824)  loss_n_60: 0.3117 (0.3985)  loss_n_80: 0.3274 (0.4372)  loss_n_100: 0.3728 (0.4842)  triple_100: 0.0000 (0.0109)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0141)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [ 980/1724]  eta: 0:48:34  lr: 0.000200  loss: 1.2947 (1.7459)  loss_n_40: 0.2978 (0.3815)  loss_n_60: 0.3066 (0.3977)  loss_n_80: 0.3274 (0.4361)  loss_n_100: 0.3608 (0.4830)  triple_100: 0.0000 (0.0108)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0139)  time: 3.9195  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [ 990/1724]  eta: 0:47:55  lr: 0.000200  loss: 1.3452 (1.7422)  loss_n_40: 0.3060 (0.3810)  loss_n_60: 0.3210 (0.3970)  loss_n_80: 0.3305 (0.4352)  loss_n_100: 0.3608 (0.4819)  triple_100: 0.0000 (0.0107)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0138)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1000/1724]  eta: 0:47:16  lr: 0.000200  loss: 1.3924 (1.7388)  loss_n_40: 0.3348 (0.3805)  loss_n_60: 0.3335 (0.3963)  loss_n_80: 0.3585 (0.4344)  loss_n_100: 0.3747 (0.4809)  triple_100: 0.0000 (0.0106)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0092)  triple_40: 0.0000 (0.0137)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1010/1724]  eta: 0:46:37  lr: 0.000200  loss: 1.3520 (1.7351)  loss_n_40: 0.3255 (0.3798)  loss_n_60: 0.3384 (0.3957)  loss_n_80: 0.3408 (0.4335)  loss_n_100: 0.3716 (0.4799)  triple_100: 0.0000 (0.0105)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0135)  time: 3.9189  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [1020/1724]  eta: 0:45:58  lr: 0.000200  loss: 1.3515 (1.7313)  loss_n_40: 0.2966 (0.3791)  loss_n_60: 0.3262 (0.3950)  loss_n_80: 0.3318 (0.4326)  loss_n_100: 0.3569 (0.4789)  triple_100: 0.0000 (0.0104)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0134)  time: 3.9199  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1030/1724]  eta: 0:45:19  lr: 0.000200  loss: 1.5257 (1.7383)  loss_n_40: 0.3403 (0.3792)  loss_n_60: 0.3732 (0.3956)  loss_n_80: 0.3780 (0.4334)  loss_n_100: 0.4126 (0.4801)  triple_100: 0.0000 (0.0124)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0135)  time: 3.9215  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1040/1724]  eta: 0:44:39  lr: 0.000200  loss: 2.7125 (1.7507)  loss_n_40: 0.4521 (0.3811)  loss_n_60: 0.5683 (0.3982)  loss_n_80: 0.7095 (0.4370)  loss_n_100: 0.8238 (0.4844)  triple_100: 0.0000 (0.0128)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0097)  triple_40: 0.0000 (0.0133)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1050/1724]  eta: 0:44:00  lr: 0.000200  loss: 2.7125 (1.7578)  loss_n_40: 0.5013 (0.3821)  loss_n_60: 0.5780 (0.3993)  loss_n_80: 0.7362 (0.4387)  loss_n_100: 0.8238 (0.4866)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0132)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1060/1724]  eta: 0:43:21  lr: 0.000200  loss: 2.1822 (1.7635)  loss_n_40: 0.4746 (0.3834)  loss_n_60: 0.4877 (0.4005)  loss_n_80: 0.5734 (0.4404)  loss_n_100: 0.7026 (0.4886)  triple_100: 0.0000 (0.0134)  triple_80: 0.0000 (0.0146)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0131)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1070/1724]  eta: 0:42:42  lr: 0.000200  loss: 2.0655 (1.7658)  loss_n_40: 0.4570 (0.3838)  loss_n_60: 0.4599 (0.4010)  loss_n_80: 0.5266 (0.4412)  loss_n_100: 0.6077 (0.4895)  triple_100: 0.0000 (0.0133)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0130)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1080/1724]  eta: 0:42:03  lr: 0.000200  loss: 1.7607 (1.7659)  loss_n_40: 0.3884 (0.3839)  loss_n_60: 0.4112 (0.4011)  loss_n_80: 0.4762 (0.4414)  loss_n_100: 0.5213 (0.4898)  triple_100: 0.0000 (0.0131)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0128)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1090/1724]  eta: 0:41:23  lr: 0.000200  loss: 1.6337 (1.7644)  loss_n_40: 0.3619 (0.3837)  loss_n_60: 0.3661 (0.4009)  loss_n_80: 0.4123 (0.4412)  loss_n_100: 0.4760 (0.4895)  triple_100: 0.0000 (0.0130)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0127)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1100/1724]  eta: 0:40:44  lr: 0.000200  loss: 1.5881 (1.7635)  loss_n_40: 0.3622 (0.3837)  loss_n_60: 0.3593 (0.4008)  loss_n_80: 0.3984 (0.4410)  loss_n_100: 0.4621 (0.4893)  triple_100: 0.0000 (0.0129)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0092)  triple_40: 0.0000 (0.0126)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1110/1724]  eta: 0:40:05  lr: 0.000200  loss: 1.5794 (1.7618)  loss_n_40: 0.3579 (0.3835)  loss_n_60: 0.3589 (0.4005)  loss_n_80: 0.3963 (0.4406)  loss_n_100: 0.4419 (0.4889)  triple_100: 0.0000 (0.0128)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0125)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1120/1724]  eta: 0:39:26  lr: 0.000200  loss: 1.5229 (1.7604)  loss_n_40: 0.3403 (0.3833)  loss_n_60: 0.3594 (0.4003)  loss_n_80: 0.3986 (0.4403)  loss_n_100: 0.4338 (0.4886)  triple_100: 0.0000 (0.0127)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0124)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1130/1724]  eta: 0:38:47  lr: 0.000200  loss: 1.5585 (1.7586)  loss_n_40: 0.3403 (0.3831)  loss_n_60: 0.3608 (0.4001)  loss_n_80: 0.4060 (0.4399)  loss_n_100: 0.4489 (0.4881)  triple_100: 0.0000 (0.0126)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0123)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1140/1724]  eta: 0:38:08  lr: 0.000200  loss: 1.5084 (1.7565)  loss_n_40: 0.3300 (0.3828)  loss_n_60: 0.3557 (0.3997)  loss_n_80: 0.3971 (0.4394)  loss_n_100: 0.4237 (0.4876)  triple_100: 0.0000 (0.0125)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0122)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1150/1724]  eta: 0:37:28  lr: 0.000200  loss: 1.4787 (1.7544)  loss_n_40: 0.3324 (0.3826)  loss_n_60: 0.3469 (0.3994)  loss_n_80: 0.3623 (0.4388)  loss_n_100: 0.4013 (0.4869)  triple_100: 0.0000 (0.0123)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0121)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1160/1724]  eta: 0:36:49  lr: 0.000200  loss: 1.4251 (1.7523)  loss_n_40: 0.3324 (0.3825)  loss_n_60: 0.3367 (0.3991)  loss_n_80: 0.3546 (0.4383)  loss_n_100: 0.3916 (0.4862)  triple_100: 0.0000 (0.0122)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0119)  time: 3.9158  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1170/1724]  eta: 0:36:10  lr: 0.000200  loss: 1.3802 (1.7500)  loss_n_40: 0.3009 (0.3821)  loss_n_60: 0.3207 (0.3986)  loss_n_80: 0.3566 (0.4378)  loss_n_100: 0.3938 (0.4856)  triple_100: 0.0000 (0.0121)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0118)  time: 3.9160  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1180/1724]  eta: 0:35:31  lr: 0.000200  loss: 1.5160 (1.7483)  loss_n_40: 0.3530 (0.3820)  loss_n_60: 0.3563 (0.3984)  loss_n_80: 0.3700 (0.4373)  loss_n_100: 0.4317 (0.4852)  triple_100: 0.0000 (0.0120)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0117)  time: 3.9159  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1190/1724]  eta: 0:34:52  lr: 0.000200  loss: 1.8766 (1.7869)  loss_n_40: 0.4612 (0.3860)  loss_n_60: 0.4465 (0.4034)  loss_n_80: 0.4559 (0.4438)  loss_n_100: 0.5129 (0.4926)  triple_100: 0.0000 (0.0216)  triple_80: 0.0000 (0.0168)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0140)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1200/1724]  eta: 0:34:12  lr: 0.000200  loss: 5.1694 (1.8158)  loss_n_40: 1.0146 (0.3919)  loss_n_60: 1.0737 (0.4098)  loss_n_80: 1.3054 (0.4517)  loss_n_100: 1.5288 (0.5018)  triple_100: 0.0000 (0.0214)  triple_80: 0.0000 (0.0166)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0139)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1210/1724]  eta: 0:33:33  lr: 0.000200  loss: 4.7098 (1.8380)  loss_n_40: 0.9888 (0.3961)  loss_n_60: 1.0278 (0.4146)  loss_n_80: 1.2350 (0.4579)  loss_n_100: 1.4574 (0.5094)  triple_100: 0.0000 (0.0212)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0138)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1220/1724]  eta: 0:32:54  lr: 0.000200  loss: 4.1553 (1.8542)  loss_n_40: 0.8582 (0.3996)  loss_n_60: 0.9138 (0.4184)  loss_n_80: 1.0571 (0.4622)  loss_n_100: 1.2378 (0.5144)  triple_100: 0.0000 (0.0210)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0137)  time: 3.9156  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1230/1724]  eta: 0:32:15  lr: 0.000200  loss: 3.3376 (1.8633)  loss_n_40: 0.7214 (0.4020)  loss_n_60: 0.7448 (0.4205)  loss_n_80: 0.8663 (0.4645)  loss_n_100: 0.9736 (0.5172)  triple_100: 0.0000 (0.0209)  triple_80: 0.0000 (0.0162)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0136)  time: 3.9162  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1240/1724]  eta: 0:31:36  lr: 0.000200  loss: 2.7842 (1.8711)  loss_n_40: 0.6337 (0.4038)  loss_n_60: 0.6245 (0.4221)  loss_n_80: 0.6993 (0.4666)  loss_n_100: 0.8389 (0.5200)  triple_100: 0.0000 (0.0207)  triple_80: 0.0000 (0.0161)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0135)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1250/1724]  eta: 0:30:56  lr: 0.000200  loss: 2.6550 (1.8765)  loss_n_40: 0.6026 (0.4056)  loss_n_60: 0.5788 (0.4234)  loss_n_80: 0.6816 (0.4680)  loss_n_100: 0.7812 (0.5215)  triple_100: 0.0000 (0.0205)  triple_80: 0.0000 (0.0159)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0134)  time: 3.9180  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [1260/1724]  eta: 0:30:17  lr: 0.000200  loss: 2.4257 (1.8799)  loss_n_40: 0.5600 (0.4067)  loss_n_60: 0.5500 (0.4241)  loss_n_80: 0.5856 (0.4689)  loss_n_100: 0.6656 (0.5225)  triple_100: 0.0000 (0.0204)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0133)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1270/1724]  eta: 0:29:38  lr: 0.000200  loss: 2.1961 (1.8818)  loss_n_40: 0.5339 (0.4078)  loss_n_60: 0.4717 (0.4243)  loss_n_80: 0.5691 (0.4695)  loss_n_100: 0.6160 (0.5231)  triple_100: 0.0000 (0.0202)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0132)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1280/1724]  eta: 0:28:59  lr: 0.000200  loss: 2.0963 (1.8833)  loss_n_40: 0.5219 (0.4087)  loss_n_60: 0.4493 (0.4245)  loss_n_80: 0.5198 (0.4699)  loss_n_100: 0.5705 (0.5235)  triple_100: 0.0000 (0.0200)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0131)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1290/1724]  eta: 0:28:20  lr: 0.000200  loss: 1.9412 (1.8836)  loss_n_40: 0.4734 (0.4092)  loss_n_60: 0.4224 (0.4245)  loss_n_80: 0.4850 (0.4699)  loss_n_100: 0.5451 (0.5236)  triple_100: 0.0000 (0.0199)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0130)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1300/1724]  eta: 0:27:41  lr: 0.000200  loss: 1.8617 (1.8837)  loss_n_40: 0.4457 (0.4097)  loss_n_60: 0.4093 (0.4245)  loss_n_80: 0.4635 (0.4700)  loss_n_100: 0.5238 (0.5236)  triple_100: 0.0000 (0.0197)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0129)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1310/1724]  eta: 0:27:01  lr: 0.000200  loss: 1.8127 (1.8830)  loss_n_40: 0.4405 (0.4100)  loss_n_60: 0.3959 (0.4243)  loss_n_80: 0.4617 (0.4698)  loss_n_100: 0.5168 (0.5234)  triple_100: 0.0000 (0.0196)  triple_80: 0.0000 (0.0152)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0128)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1320/1724]  eta: 0:26:22  lr: 0.000200  loss: 1.7319 (1.8824)  loss_n_40: 0.4260 (0.4104)  loss_n_60: 0.3856 (0.4241)  loss_n_80: 0.4349 (0.4696)  loss_n_100: 0.4909 (0.5231)  triple_100: 0.0000 (0.0194)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0127)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1330/1724]  eta: 0:25:43  lr: 0.000200  loss: 1.6918 (1.8807)  loss_n_40: 0.4269 (0.4106)  loss_n_60: 0.3718 (0.4237)  loss_n_80: 0.4128 (0.4692)  loss_n_100: 0.4611 (0.5226)  triple_100: 0.0000 (0.0193)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0126)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1340/1724]  eta: 0:25:04  lr: 0.000200  loss: 1.6394 (1.8790)  loss_n_40: 0.4001 (0.4108)  loss_n_60: 0.3608 (0.4233)  loss_n_80: 0.4014 (0.4687)  loss_n_100: 0.4414 (0.5221)  triple_100: 0.0000 (0.0192)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0125)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1350/1724]  eta: 0:24:25  lr: 0.000200  loss: 1.6417 (1.8779)  loss_n_40: 0.4293 (0.4109)  loss_n_60: 0.3608 (0.4230)  loss_n_80: 0.4144 (0.4684)  loss_n_100: 0.4526 (0.5216)  triple_100: 0.0000 (0.0190)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0124)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1360/1724]  eta: 0:23:46  lr: 0.000200  loss: 1.8499 (1.8782)  loss_n_40: 0.4401 (0.4113)  loss_n_60: 0.4137 (0.4230)  loss_n_80: 0.4581 (0.4685)  loss_n_100: 0.5018 (0.5218)  triple_100: 0.0000 (0.0189)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0123)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1370/1724]  eta: 0:23:06  lr: 0.000200  loss: 1.9213 (1.8792)  loss_n_40: 0.4415 (0.4116)  loss_n_60: 0.4164 (0.4230)  loss_n_80: 0.4748 (0.4686)  loss_n_100: 0.5448 (0.5219)  triple_100: 0.0000 (0.0191)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0122)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1380/1724]  eta: 0:22:27  lr: 0.000200  loss: 1.8027 (1.8787)  loss_n_40: 0.4380 (0.4116)  loss_n_60: 0.4124 (0.4229)  loss_n_80: 0.4567 (0.4685)  loss_n_100: 0.5437 (0.5221)  triple_100: 0.0000 (0.0190)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0121)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1390/1724]  eta: 0:21:48  lr: 0.000200  loss: 1.6825 (1.8772)  loss_n_40: 0.3868 (0.4116)  loss_n_60: 0.3749 (0.4226)  loss_n_80: 0.4106 (0.4680)  loss_n_100: 0.4907 (0.5217)  triple_100: 0.0000 (0.0188)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0120)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1400/1724]  eta: 0:21:09  lr: 0.000200  loss: 1.6239 (1.8758)  loss_n_40: 0.4077 (0.4119)  loss_n_60: 0.3698 (0.4223)  loss_n_80: 0.3964 (0.4675)  loss_n_100: 0.4433 (0.5212)  triple_100: 0.0000 (0.0187)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0119)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1410/1724]  eta: 0:20:30  lr: 0.000200  loss: 1.5858 (1.8736)  loss_n_40: 0.4163 (0.4118)  loss_n_60: 0.3568 (0.4219)  loss_n_80: 0.3760 (0.4669)  loss_n_100: 0.4261 (0.5205)  triple_100: 0.0000 (0.0186)  triple_80: 0.0000 (0.0146)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0119)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1420/1724]  eta: 0:19:50  lr: 0.000200  loss: 1.5937 (1.8719)  loss_n_40: 0.4018 (0.4118)  loss_n_60: 0.3615 (0.4216)  loss_n_80: 0.3870 (0.4664)  loss_n_100: 0.4179 (0.5199)  triple_100: 0.0000 (0.0184)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0118)  time: 3.9185  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1430/1724]  eta: 0:19:11  lr: 0.000200  loss: 1.5855 (1.8698)  loss_n_40: 0.4052 (0.4116)  loss_n_60: 0.3578 (0.4211)  loss_n_80: 0.3923 (0.4659)  loss_n_100: 0.4166 (0.5193)  triple_100: 0.0000 (0.0183)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0117)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1440/1724]  eta: 0:18:32  lr: 0.000200  loss: 1.4765 (1.8673)  loss_n_40: 0.3659 (0.4114)  loss_n_60: 0.3372 (0.4206)  loss_n_80: 0.3664 (0.4653)  loss_n_100: 0.4138 (0.5186)  triple_100: 0.0000 (0.0182)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0116)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1450/1724]  eta: 0:17:53  lr: 0.000200  loss: 1.4957 (1.8652)  loss_n_40: 0.3593 (0.4112)  loss_n_60: 0.3389 (0.4201)  loss_n_80: 0.3697 (0.4647)  loss_n_100: 0.4096 (0.5179)  triple_100: 0.0000 (0.0181)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0115)  time: 3.9199  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1460/1724]  eta: 0:17:14  lr: 0.000200  loss: 1.5595 (1.8633)  loss_n_40: 0.3670 (0.4112)  loss_n_60: 0.3443 (0.4197)  loss_n_80: 0.3849 (0.4642)  loss_n_100: 0.4052 (0.5172)  triple_100: 0.0000 (0.0180)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0115)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1470/1724]  eta: 0:16:35  lr: 0.000200  loss: 1.5670 (1.8619)  loss_n_40: 0.3948 (0.4113)  loss_n_60: 0.3621 (0.4194)  loss_n_80: 0.3899 (0.4638)  loss_n_100: 0.4208 (0.5167)  triple_100: 0.0000 (0.0178)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0114)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1480/1724]  eta: 0:15:55  lr: 0.000200  loss: 1.7422 (1.8670)  loss_n_40: 0.4383 (0.4117)  loss_n_60: 0.3908 (0.4199)  loss_n_80: 0.4204 (0.4644)  loss_n_100: 0.4593 (0.5174)  triple_100: 0.0000 (0.0188)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0114)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1490/1724]  eta: 0:15:16  lr: 0.000200  loss: 2.4169 (1.8709)  loss_n_40: 0.5094 (0.4125)  loss_n_60: 0.5291 (0.4208)  loss_n_80: 0.6256 (0.4656)  loss_n_100: 0.6580 (0.5188)  triple_100: 0.0000 (0.0187)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0114)  time: 3.9178  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [1500/1724]  eta: 0:14:37  lr: 0.000200  loss: 2.1600 (1.8721)  loss_n_40: 0.4897 (0.4129)  loss_n_60: 0.4801 (0.4211)  loss_n_80: 0.5480 (0.4660)  loss_n_100: 0.6085 (0.5193)  triple_100: 0.0000 (0.0186)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0113)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1510/1724]  eta: 0:13:58  lr: 0.000200  loss: 1.9644 (1.8723)  loss_n_40: 0.4578 (0.4133)  loss_n_60: 0.4382 (0.4211)  loss_n_80: 0.4915 (0.4660)  loss_n_100: 0.5440 (0.5193)  triple_100: 0.0000 (0.0185)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0112)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1520/1724]  eta: 0:13:19  lr: 0.000200  loss: 1.7829 (1.8708)  loss_n_40: 0.4273 (0.4132)  loss_n_60: 0.4052 (0.4209)  loss_n_80: 0.4334 (0.4656)  loss_n_100: 0.4771 (0.5189)  triple_100: 0.0000 (0.0183)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0111)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1530/1724]  eta: 0:12:40  lr: 0.000200  loss: 1.6389 (1.8697)  loss_n_40: 0.3928 (0.4133)  loss_n_60: 0.3802 (0.4207)  loss_n_80: 0.4085 (0.4653)  loss_n_100: 0.4591 (0.5185)  triple_100: 0.0000 (0.0182)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0111)  time: 3.9199  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1540/1724]  eta: 0:12:00  lr: 0.000200  loss: 1.6179 (1.8688)  loss_n_40: 0.4246 (0.4135)  loss_n_60: 0.3760 (0.4206)  loss_n_80: 0.3996 (0.4651)  loss_n_100: 0.4424 (0.5182)  triple_100: 0.0000 (0.0181)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0110)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1550/1724]  eta: 0:11:21  lr: 0.000200  loss: 1.5344 (1.8666)  loss_n_40: 0.3820 (0.4133)  loss_n_60: 0.3538 (0.4201)  loss_n_80: 0.3795 (0.4645)  loss_n_100: 0.4239 (0.5175)  triple_100: 0.0000 (0.0180)  triple_80: 0.0000 (0.0146)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0109)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1560/1724]  eta: 0:10:42  lr: 0.000200  loss: 1.4967 (1.8653)  loss_n_40: 0.3695 (0.4135)  loss_n_60: 0.3386 (0.4199)  loss_n_80: 0.3503 (0.4641)  loss_n_100: 0.3929 (0.5169)  triple_100: 0.0000 (0.0179)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0109)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1570/1724]  eta: 0:10:03  lr: 0.000200  loss: 1.4819 (1.8631)  loss_n_40: 0.3695 (0.4134)  loss_n_60: 0.3362 (0.4194)  loss_n_80: 0.3587 (0.4636)  loss_n_100: 0.4033 (0.5163)  triple_100: 0.0000 (0.0177)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0108)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1580/1724]  eta: 0:09:24  lr: 0.000200  loss: 1.4416 (1.8608)  loss_n_40: 0.3682 (0.4132)  loss_n_60: 0.3253 (0.4189)  loss_n_80: 0.3587 (0.4630)  loss_n_100: 0.4002 (0.5155)  triple_100: 0.0000 (0.0176)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0107)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1590/1724]  eta: 0:08:44  lr: 0.000200  loss: 1.4272 (1.8580)  loss_n_40: 0.3427 (0.4127)  loss_n_60: 0.3080 (0.4183)  loss_n_80: 0.3515 (0.4623)  loss_n_100: 0.3891 (0.5147)  triple_100: 0.0000 (0.0175)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0108)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1600/1724]  eta: 0:08:05  lr: 0.000200  loss: 1.5356 (1.8567)  loss_n_40: 0.3556 (0.4127)  loss_n_60: 0.3390 (0.4179)  loss_n_80: 0.3730 (0.4619)  loss_n_100: 0.4120 (0.5143)  triple_100: 0.0000 (0.0175)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0107)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1610/1724]  eta: 0:07:26  lr: 0.000200  loss: 1.5382 (1.8551)  loss_n_40: 0.3850 (0.4128)  loss_n_60: 0.3507 (0.4176)  loss_n_80: 0.3852 (0.4614)  loss_n_100: 0.4218 (0.5137)  triple_100: 0.0000 (0.0174)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0106)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1620/1724]  eta: 0:06:47  lr: 0.000200  loss: 1.5699 (1.8547)  loss_n_40: 0.4044 (0.4128)  loss_n_60: 0.3559 (0.4173)  loss_n_80: 0.3852 (0.4611)  loss_n_100: 0.4282 (0.5133)  triple_100: 0.0000 (0.0175)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0106)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1630/1724]  eta: 0:06:08  lr: 0.000200  loss: 1.6730 (1.8535)  loss_n_40: 0.4044 (0.4128)  loss_n_60: 0.3659 (0.4169)  loss_n_80: 0.4166 (0.4608)  loss_n_100: 0.4678 (0.5130)  triple_100: 0.0000 (0.0174)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0105)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1640/1724]  eta: 0:05:29  lr: 0.000200  loss: 1.6018 (1.8515)  loss_n_40: 0.3961 (0.4127)  loss_n_60: 0.3547 (0.4165)  loss_n_80: 0.3884 (0.4603)  loss_n_100: 0.4504 (0.5125)  triple_100: 0.0000 (0.0173)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0104)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1650/1724]  eta: 0:04:49  lr: 0.000200  loss: 1.5425 (1.8497)  loss_n_40: 0.3928 (0.4127)  loss_n_60: 0.3398 (0.4161)  loss_n_80: 0.3755 (0.4598)  loss_n_100: 0.4088 (0.5118)  triple_100: 0.0000 (0.0172)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0104)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1660/1724]  eta: 0:04:10  lr: 0.000200  loss: 1.4407 (1.8475)  loss_n_40: 0.3897 (0.4127)  loss_n_60: 0.3181 (0.4155)  loss_n_80: 0.3626 (0.4592)  loss_n_100: 0.3894 (0.5111)  triple_100: 0.0000 (0.0170)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0103)  time: 3.9190  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1670/1724]  eta: 0:03:31  lr: 0.000200  loss: 1.4299 (1.8454)  loss_n_40: 0.3687 (0.4126)  loss_n_60: 0.3181 (0.4150)  loss_n_80: 0.3544 (0.4586)  loss_n_100: 0.3816 (0.5104)  triple_100: 0.0000 (0.0169)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0103)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1680/1724]  eta: 0:02:52  lr: 0.000200  loss: 1.3818 (1.8426)  loss_n_40: 0.3477 (0.4122)  loss_n_60: 0.3095 (0.4144)  loss_n_80: 0.3417 (0.4579)  loss_n_100: 0.3807 (0.5096)  triple_100: 0.0000 (0.0168)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0102)  time: 3.9196  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1690/1724]  eta: 0:02:13  lr: 0.000200  loss: 1.4401 (1.8440)  loss_n_40: 0.3482 (0.4121)  loss_n_60: 0.3312 (0.4147)  loss_n_80: 0.3573 (0.4582)  loss_n_100: 0.4024 (0.5100)  triple_100: 0.0000 (0.0170)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0102)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1700/1724]  eta: 0:01:34  lr: 0.000200  loss: 2.2983 (1.8472)  loss_n_40: 0.4643 (0.4130)  loss_n_60: 0.5220 (0.4154)  loss_n_80: 0.5790 (0.4589)  loss_n_100: 0.6248 (0.5108)  triple_100: 0.0000 (0.0170)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0102)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:13]  [1710/1724]  eta: 0:00:54  lr: 0.000200  loss: 2.1929 (1.8487)  loss_n_40: 0.5221 (0.4135)  loss_n_60: 0.5178 (0.4158)  loss_n_80: 0.5481 (0.4594)  loss_n_100: 0.6144 (0.5113)  triple_100: 0.0000 (0.0169)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0102)  time: 3.9180  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1720/1724]  eta: 0:00:15  lr: 0.000200  loss: 1.9787 (1.8485)  loss_n_40: 0.4781 (0.4137)  loss_n_60: 0.4378 (0.4158)  loss_n_80: 0.4873 (0.4593)  loss_n_100: 0.5296 (0.5111)  triple_100: 0.0000 (0.0168)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0101)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:13]  [1723/1724]  eta: 0:00:03  lr: 0.000200  loss: 1.8762 (1.8482)  loss_n_40: 0.4507 (0.4137)  loss_n_60: 0.4343 (0.4158)  loss_n_80: 0.4718 (0.4593)  loss_n_100: 0.5008 (0.5110)  triple_100: 0.0000 (0.0167)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0101)  time: 3.9172  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13] Total time: 1:52:34 (3.9180 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 1.8762 (1.8482)  loss_n_40: 0.4507 (0.4137)  loss_n_60: 0.4343 (0.4158)  loss_n_80: 0.4718 (0.4593)  loss_n_100: 0.5008 (0.5110)  triple_100: 0.0000 (0.0167)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0101)\n",
      "Valid: [epoch:13]  [  0/845]  eta: 0:10:14  loss: 1.4327 (1.4327)  loss_n_40: 0.3299 (0.3299)  loss_n_60: 0.3540 (0.3540)  loss_n_80: 0.3654 (0.3654)  loss_n_100: 0.3834 (0.3834)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7275  data: 0.3950  max mem: 46473\n",
      "Valid: [epoch:13]  [ 10/845]  eta: 0:05:08  loss: 1.6109 (1.7898)  loss_n_40: 0.3648 (0.4754)  loss_n_60: 0.3713 (0.4145)  loss_n_80: 0.4083 (0.4416)  loss_n_100: 0.4395 (0.4582)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3695  data: 0.0360  max mem: 46473\n",
      "Valid: [epoch:13]  [ 20/845]  eta: 0:04:50  loss: 1.5754 (1.6755)  loss_n_40: 0.3638 (0.4291)  loss_n_60: 0.3683 (0.3899)  loss_n_80: 0.3829 (0.4158)  loss_n_100: 0.4287 (0.4407)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [ 30/845]  eta: 0:04:42  loss: 1.5595 (1.6584)  loss_n_40: 0.3617 (0.4161)  loss_n_60: 0.3693 (0.3901)  loss_n_80: 0.3828 (0.4115)  loss_n_100: 0.4045 (0.4406)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [ 40/845]  eta: 0:04:36  loss: 1.5546 (1.6267)  loss_n_40: 0.3700 (0.4082)  loss_n_60: 0.3738 (0.3843)  loss_n_80: 0.3869 (0.4015)  loss_n_100: 0.4060 (0.4326)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [ 50/845]  eta: 0:04:31  loss: 1.5960 (1.6557)  loss_n_40: 0.3737 (0.4100)  loss_n_60: 0.3833 (0.3948)  loss_n_80: 0.3897 (0.4101)  loss_n_100: 0.4248 (0.4407)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [ 60/845]  eta: 0:04:27  loss: 1.5963 (1.6397)  loss_n_40: 0.3699 (0.4082)  loss_n_60: 0.3650 (0.3912)  loss_n_80: 0.4029 (0.4062)  loss_n_100: 0.4184 (0.4341)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [ 70/845]  eta: 0:04:23  loss: 1.5267 (1.6451)  loss_n_40: 0.3699 (0.4079)  loss_n_60: 0.3620 (0.3925)  loss_n_80: 0.3786 (0.4070)  loss_n_100: 0.4014 (0.4377)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [ 80/845]  eta: 0:04:19  loss: 1.6023 (1.6435)  loss_n_40: 0.3823 (0.4059)  loss_n_60: 0.3839 (0.3908)  loss_n_80: 0.3958 (0.4069)  loss_n_100: 0.4339 (0.4399)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [ 90/845]  eta: 0:04:15  loss: 1.6492 (1.6479)  loss_n_40: 0.3820 (0.4073)  loss_n_60: 0.3811 (0.3910)  loss_n_80: 0.3909 (0.4071)  loss_n_100: 0.4361 (0.4426)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [100/845]  eta: 0:04:11  loss: 1.6740 (1.6575)  loss_n_40: 0.3829 (0.4070)  loss_n_60: 0.4000 (0.3924)  loss_n_80: 0.4211 (0.4118)  loss_n_100: 0.4576 (0.4463)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [110/845]  eta: 0:04:08  loss: 1.6524 (1.6578)  loss_n_40: 0.3790 (0.4076)  loss_n_60: 0.3945 (0.3918)  loss_n_80: 0.4211 (0.4129)  loss_n_100: 0.4474 (0.4455)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [120/845]  eta: 0:04:04  loss: 1.5703 (1.6592)  loss_n_40: 0.3693 (0.4114)  loss_n_60: 0.3678 (0.3916)  loss_n_80: 0.3952 (0.4126)  loss_n_100: 0.3970 (0.4437)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [130/845]  eta: 0:04:00  loss: 1.4547 (1.6543)  loss_n_40: 0.3461 (0.4097)  loss_n_60: 0.3550 (0.3903)  loss_n_80: 0.3592 (0.4116)  loss_n_100: 0.4052 (0.4428)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [140/845]  eta: 0:03:57  loss: 1.4455 (1.6397)  loss_n_40: 0.3436 (0.4055)  loss_n_60: 0.3433 (0.3870)  loss_n_80: 0.3633 (0.4079)  loss_n_100: 0.4052 (0.4393)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [150/845]  eta: 0:03:53  loss: 1.4468 (1.6349)  loss_n_40: 0.3485 (0.4031)  loss_n_60: 0.3433 (0.3859)  loss_n_80: 0.3647 (0.4068)  loss_n_100: 0.3991 (0.4390)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [160/845]  eta: 0:03:50  loss: 1.6193 (1.6401)  loss_n_40: 0.3717 (0.4053)  loss_n_60: 0.3705 (0.3867)  loss_n_80: 0.4071 (0.4078)  loss_n_100: 0.4307 (0.4403)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [170/845]  eta: 0:03:47  loss: 1.7256 (1.6482)  loss_n_40: 0.3846 (0.4078)  loss_n_60: 0.3943 (0.3878)  loss_n_80: 0.4244 (0.4099)  loss_n_100: 0.4664 (0.4427)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [180/845]  eta: 0:03:43  loss: 1.6383 (1.6458)  loss_n_40: 0.3736 (0.4076)  loss_n_60: 0.3875 (0.3879)  loss_n_80: 0.4023 (0.4090)  loss_n_100: 0.4365 (0.4413)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [190/845]  eta: 0:03:40  loss: 1.5494 (1.6465)  loss_n_40: 0.3736 (0.4103)  loss_n_60: 0.3791 (0.3877)  loss_n_80: 0.3803 (0.4081)  loss_n_100: 0.3989 (0.4403)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [200/845]  eta: 0:03:36  loss: 1.7179 (1.6574)  loss_n_40: 0.4096 (0.4142)  loss_n_60: 0.4069 (0.3895)  loss_n_80: 0.4054 (0.4111)  loss_n_100: 0.4429 (0.4426)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [210/845]  eta: 0:03:33  loss: 1.7267 (1.6692)  loss_n_40: 0.3952 (0.4190)  loss_n_60: 0.4069 (0.3916)  loss_n_80: 0.4172 (0.4138)  loss_n_100: 0.4751 (0.4448)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [220/845]  eta: 0:03:29  loss: 1.5715 (1.6635)  loss_n_40: 0.3677 (0.4167)  loss_n_60: 0.3737 (0.3906)  loss_n_80: 0.3895 (0.4123)  loss_n_100: 0.4478 (0.4439)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [230/845]  eta: 0:03:26  loss: 1.5546 (1.6666)  loss_n_40: 0.3686 (0.4174)  loss_n_60: 0.3665 (0.3912)  loss_n_80: 0.3842 (0.4128)  loss_n_100: 0.4243 (0.4453)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:13]  [240/845]  eta: 0:03:23  loss: 1.5546 (1.6622)  loss_n_40: 0.3686 (0.4166)  loss_n_60: 0.3618 (0.3908)  loss_n_80: 0.3629 (0.4112)  loss_n_100: 0.4070 (0.4437)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [250/845]  eta: 0:03:19  loss: 1.4686 (1.6595)  loss_n_40: 0.3521 (0.4156)  loss_n_60: 0.3587 (0.3903)  loss_n_80: 0.3620 (0.4105)  loss_n_100: 0.3920 (0.4431)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [260/845]  eta: 0:03:16  loss: 1.5421 (1.6588)  loss_n_40: 0.3747 (0.4154)  loss_n_60: 0.3594 (0.3898)  loss_n_80: 0.3740 (0.4105)  loss_n_100: 0.4025 (0.4431)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [270/845]  eta: 0:03:12  loss: 1.6416 (1.6613)  loss_n_40: 0.3782 (0.4152)  loss_n_60: 0.3687 (0.3901)  loss_n_80: 0.3958 (0.4112)  loss_n_100: 0.4276 (0.4448)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [280/845]  eta: 0:03:09  loss: 1.5938 (1.6571)  loss_n_40: 0.3677 (0.4133)  loss_n_60: 0.3756 (0.3896)  loss_n_80: 0.4047 (0.4103)  loss_n_100: 0.4276 (0.4439)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [290/845]  eta: 0:03:06  loss: 1.5938 (1.6644)  loss_n_40: 0.3795 (0.4144)  loss_n_60: 0.3853 (0.3915)  loss_n_80: 0.4142 (0.4122)  loss_n_100: 0.4400 (0.4463)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [300/845]  eta: 0:03:02  loss: 1.7008 (1.6631)  loss_n_40: 0.3879 (0.4140)  loss_n_60: 0.3925 (0.3910)  loss_n_80: 0.4342 (0.4124)  loss_n_100: 0.4542 (0.4456)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [310/845]  eta: 0:02:59  loss: 1.6893 (1.6704)  loss_n_40: 0.3939 (0.4154)  loss_n_60: 0.3979 (0.3926)  loss_n_80: 0.4049 (0.4149)  loss_n_100: 0.4461 (0.4475)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [320/845]  eta: 0:02:56  loss: 1.7247 (1.6715)  loss_n_40: 0.4186 (0.4158)  loss_n_60: 0.4178 (0.3930)  loss_n_80: 0.4191 (0.4150)  loss_n_100: 0.4559 (0.4477)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [330/845]  eta: 0:02:52  loss: 1.6817 (1.6705)  loss_n_40: 0.3854 (0.4160)  loss_n_60: 0.3709 (0.3925)  loss_n_80: 0.3990 (0.4151)  loss_n_100: 0.4132 (0.4469)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [340/845]  eta: 0:02:49  loss: 1.4965 (1.6682)  loss_n_40: 0.3742 (0.4154)  loss_n_60: 0.3594 (0.3919)  loss_n_80: 0.3936 (0.4146)  loss_n_100: 0.4132 (0.4464)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [350/845]  eta: 0:02:45  loss: 1.6446 (1.6712)  loss_n_40: 0.3806 (0.4167)  loss_n_60: 0.3874 (0.3924)  loss_n_80: 0.3947 (0.4151)  loss_n_100: 0.4495 (0.4470)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [360/845]  eta: 0:02:42  loss: 1.6627 (1.6700)  loss_n_40: 0.3863 (0.4161)  loss_n_60: 0.3874 (0.3922)  loss_n_80: 0.4084 (0.4149)  loss_n_100: 0.4718 (0.4468)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [370/845]  eta: 0:02:39  loss: 1.6627 (1.6741)  loss_n_40: 0.3868 (0.4179)  loss_n_60: 0.3855 (0.3933)  loss_n_80: 0.4084 (0.4158)  loss_n_100: 0.4320 (0.4473)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [380/845]  eta: 0:02:35  loss: 1.6659 (1.6766)  loss_n_40: 0.4065 (0.4191)  loss_n_60: 0.3922 (0.3938)  loss_n_80: 0.4382 (0.4161)  loss_n_100: 0.4342 (0.4476)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [390/845]  eta: 0:02:32  loss: 1.6087 (1.6770)  loss_n_40: 0.3803 (0.4197)  loss_n_60: 0.3952 (0.3939)  loss_n_80: 0.4051 (0.4161)  loss_n_100: 0.4342 (0.4473)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [400/845]  eta: 0:02:29  loss: 1.5145 (1.6744)  loss_n_40: 0.3589 (0.4185)  loss_n_60: 0.3712 (0.3934)  loss_n_80: 0.3734 (0.4157)  loss_n_100: 0.4201 (0.4468)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [410/845]  eta: 0:02:25  loss: 1.4797 (1.6675)  loss_n_40: 0.3433 (0.4163)  loss_n_60: 0.3509 (0.3919)  loss_n_80: 0.3628 (0.4140)  loss_n_100: 0.3945 (0.4453)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [420/845]  eta: 0:02:22  loss: 1.4885 (1.6687)  loss_n_40: 0.3495 (0.4171)  loss_n_60: 0.3557 (0.3924)  loss_n_80: 0.3628 (0.4143)  loss_n_100: 0.3834 (0.4450)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [430/845]  eta: 0:02:19  loss: 1.6808 (1.6684)  loss_n_40: 0.3794 (0.4167)  loss_n_60: 0.3926 (0.3924)  loss_n_80: 0.3966 (0.4139)  loss_n_100: 0.4422 (0.4455)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [440/845]  eta: 0:02:15  loss: 1.7272 (1.6694)  loss_n_40: 0.3783 (0.4164)  loss_n_60: 0.3926 (0.3922)  loss_n_80: 0.3939 (0.4144)  loss_n_100: 0.4919 (0.4463)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [450/845]  eta: 0:02:12  loss: 1.7664 (1.6748)  loss_n_40: 0.4047 (0.4182)  loss_n_60: 0.3896 (0.3931)  loss_n_80: 0.4544 (0.4161)  loss_n_100: 0.5010 (0.4475)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [460/845]  eta: 0:02:09  loss: 1.7961 (1.6791)  loss_n_40: 0.4697 (0.4201)  loss_n_60: 0.4187 (0.3940)  loss_n_80: 0.4559 (0.4170)  loss_n_100: 0.4838 (0.4479)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [470/845]  eta: 0:02:05  loss: 1.5406 (1.6799)  loss_n_40: 0.3657 (0.4211)  loss_n_60: 0.3784 (0.3942)  loss_n_80: 0.3843 (0.4171)  loss_n_100: 0.4156 (0.4475)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [480/845]  eta: 0:02:02  loss: 1.6449 (1.6814)  loss_n_40: 0.3789 (0.4209)  loss_n_60: 0.3870 (0.3944)  loss_n_80: 0.4335 (0.4177)  loss_n_100: 0.4421 (0.4484)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:13]  [490/845]  eta: 0:01:58  loss: 1.7298 (1.6803)  loss_n_40: 0.3813 (0.4202)  loss_n_60: 0.3897 (0.3942)  loss_n_80: 0.4363 (0.4175)  loss_n_100: 0.4653 (0.4483)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3348  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [500/845]  eta: 0:01:55  loss: 1.5642 (1.6810)  loss_n_40: 0.3890 (0.4208)  loss_n_60: 0.3690 (0.3944)  loss_n_80: 0.3970 (0.4175)  loss_n_100: 0.4271 (0.4484)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [510/845]  eta: 0:01:52  loss: 1.6450 (1.6816)  loss_n_40: 0.3890 (0.4210)  loss_n_60: 0.3741 (0.3944)  loss_n_80: 0.3970 (0.4178)  loss_n_100: 0.4268 (0.4485)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [520/845]  eta: 0:01:48  loss: 1.7182 (1.6830)  loss_n_40: 0.3928 (0.4216)  loss_n_60: 0.3882 (0.3943)  loss_n_80: 0.4229 (0.4180)  loss_n_100: 0.4708 (0.4491)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [530/845]  eta: 0:01:45  loss: 1.7372 (1.6864)  loss_n_40: 0.4124 (0.4225)  loss_n_60: 0.3849 (0.3948)  loss_n_80: 0.4434 (0.4193)  loss_n_100: 0.4951 (0.4498)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [540/845]  eta: 0:01:42  loss: 1.8129 (1.6882)  loss_n_40: 0.4086 (0.4236)  loss_n_60: 0.3901 (0.3952)  loss_n_80: 0.4389 (0.4195)  loss_n_100: 0.4859 (0.4500)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [550/845]  eta: 0:01:38  loss: 1.6384 (1.6858)  loss_n_40: 0.3648 (0.4224)  loss_n_60: 0.3861 (0.3947)  loss_n_80: 0.4154 (0.4190)  loss_n_100: 0.4468 (0.4497)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [560/845]  eta: 0:01:35  loss: 1.6230 (1.6859)  loss_n_40: 0.3703 (0.4226)  loss_n_60: 0.3760 (0.3947)  loss_n_80: 0.4016 (0.4191)  loss_n_100: 0.4453 (0.4495)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [570/845]  eta: 0:01:32  loss: 1.6193 (1.6853)  loss_n_40: 0.3769 (0.4224)  loss_n_60: 0.3739 (0.3946)  loss_n_80: 0.3859 (0.4188)  loss_n_100: 0.4453 (0.4494)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [580/845]  eta: 0:01:28  loss: 1.4718 (1.6831)  loss_n_40: 0.3508 (0.4214)  loss_n_60: 0.3563 (0.3941)  loss_n_80: 0.3713 (0.4183)  loss_n_100: 0.4070 (0.4492)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [590/845]  eta: 0:01:25  loss: 1.4993 (1.6822)  loss_n_40: 0.3694 (0.4211)  loss_n_60: 0.3608 (0.3939)  loss_n_80: 0.3724 (0.4180)  loss_n_100: 0.4113 (0.4492)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [600/845]  eta: 0:01:22  loss: 1.5853 (1.6835)  loss_n_40: 0.3724 (0.4216)  loss_n_60: 0.3822 (0.3941)  loss_n_80: 0.3961 (0.4183)  loss_n_100: 0.4113 (0.4495)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [610/845]  eta: 0:01:18  loss: 1.7155 (1.6844)  loss_n_40: 0.3966 (0.4221)  loss_n_60: 0.4049 (0.3944)  loss_n_80: 0.4383 (0.4184)  loss_n_100: 0.4422 (0.4496)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [620/845]  eta: 0:01:15  loss: 1.6347 (1.6837)  loss_n_40: 0.3856 (0.4216)  loss_n_60: 0.3969 (0.3942)  loss_n_80: 0.3988 (0.4183)  loss_n_100: 0.4381 (0.4497)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [630/845]  eta: 0:01:12  loss: 1.6280 (1.6829)  loss_n_40: 0.3845 (0.4217)  loss_n_60: 0.3806 (0.3941)  loss_n_80: 0.4004 (0.4177)  loss_n_100: 0.4381 (0.4495)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [640/845]  eta: 0:01:08  loss: 1.6364 (1.6830)  loss_n_40: 0.3845 (0.4216)  loss_n_60: 0.3821 (0.3941)  loss_n_80: 0.4074 (0.4179)  loss_n_100: 0.4609 (0.4495)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [650/845]  eta: 0:01:05  loss: 1.5846 (1.6814)  loss_n_40: 0.3787 (0.4214)  loss_n_60: 0.3602 (0.3935)  loss_n_80: 0.3882 (0.4175)  loss_n_100: 0.4233 (0.4490)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [660/845]  eta: 0:01:01  loss: 1.5846 (1.6822)  loss_n_40: 0.3787 (0.4213)  loss_n_60: 0.3701 (0.3935)  loss_n_80: 0.3882 (0.4181)  loss_n_100: 0.4233 (0.4493)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [670/845]  eta: 0:00:58  loss: 1.6822 (1.6826)  loss_n_40: 0.3866 (0.4216)  loss_n_60: 0.3779 (0.3935)  loss_n_80: 0.4080 (0.4180)  loss_n_100: 0.4420 (0.4495)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:13]  [680/845]  eta: 0:00:55  loss: 1.7406 (1.6840)  loss_n_40: 0.4475 (0.4220)  loss_n_60: 0.3937 (0.3937)  loss_n_80: 0.4257 (0.4185)  loss_n_100: 0.4608 (0.4497)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:13]  [690/845]  eta: 0:00:51  loss: 1.7171 (1.6835)  loss_n_40: 0.4185 (0.4216)  loss_n_60: 0.3828 (0.3936)  loss_n_80: 0.4257 (0.4184)  loss_n_100: 0.4608 (0.4498)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [700/845]  eta: 0:00:48  loss: 1.6464 (1.6839)  loss_n_40: 0.3813 (0.4221)  loss_n_60: 0.3682 (0.3936)  loss_n_80: 0.4131 (0.4186)  loss_n_100: 0.4392 (0.4497)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [710/845]  eta: 0:00:45  loss: 1.6650 (1.6842)  loss_n_40: 0.3973 (0.4222)  loss_n_60: 0.3912 (0.3937)  loss_n_80: 0.4163 (0.4184)  loss_n_100: 0.4532 (0.4499)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [720/845]  eta: 0:00:41  loss: 1.6803 (1.6842)  loss_n_40: 0.4067 (0.4223)  loss_n_60: 0.3856 (0.3937)  loss_n_80: 0.4135 (0.4185)  loss_n_100: 0.4456 (0.4497)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [730/845]  eta: 0:00:38  loss: 1.6622 (1.6839)  loss_n_40: 0.3807 (0.4220)  loss_n_60: 0.3753 (0.3936)  loss_n_80: 0.3976 (0.4185)  loss_n_100: 0.4426 (0.4498)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:13]  [740/845]  eta: 0:00:35  loss: 1.5388 (1.6818)  loss_n_40: 0.3641 (0.4213)  loss_n_60: 0.3648 (0.3932)  loss_n_80: 0.3726 (0.4179)  loss_n_100: 0.4202 (0.4494)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [750/845]  eta: 0:00:31  loss: 1.4835 (1.6810)  loss_n_40: 0.3641 (0.4209)  loss_n_60: 0.3606 (0.3931)  loss_n_80: 0.3726 (0.4176)  loss_n_100: 0.4104 (0.4493)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [760/845]  eta: 0:00:28  loss: 1.6036 (1.6803)  loss_n_40: 0.3664 (0.4207)  loss_n_60: 0.3714 (0.3928)  loss_n_80: 0.3806 (0.4176)  loss_n_100: 0.4410 (0.4491)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [770/845]  eta: 0:00:25  loss: 1.6036 (1.6809)  loss_n_40: 0.3691 (0.4204)  loss_n_60: 0.3743 (0.3929)  loss_n_80: 0.4149 (0.4179)  loss_n_100: 0.4410 (0.4496)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [780/845]  eta: 0:00:21  loss: 1.6013 (1.6811)  loss_n_40: 0.3757 (0.4204)  loss_n_60: 0.3775 (0.3930)  loss_n_80: 0.4141 (0.4179)  loss_n_100: 0.4402 (0.4497)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [790/845]  eta: 0:00:18  loss: 1.5953 (1.6804)  loss_n_40: 0.3785 (0.4200)  loss_n_60: 0.3709 (0.3929)  loss_n_80: 0.4062 (0.4177)  loss_n_100: 0.4413 (0.4497)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [800/845]  eta: 0:00:15  loss: 1.5953 (1.6804)  loss_n_40: 0.3675 (0.4197)  loss_n_60: 0.3733 (0.3929)  loss_n_80: 0.4039 (0.4178)  loss_n_100: 0.4413 (0.4499)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [810/845]  eta: 0:00:11  loss: 1.6416 (1.6799)  loss_n_40: 0.3638 (0.4193)  loss_n_60: 0.3945 (0.3929)  loss_n_80: 0.4055 (0.4178)  loss_n_100: 0.4410 (0.4500)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [820/845]  eta: 0:00:08  loss: 1.7164 (1.6821)  loss_n_40: 0.3809 (0.4200)  loss_n_60: 0.3972 (0.3934)  loss_n_80: 0.4312 (0.4183)  loss_n_100: 0.4736 (0.4504)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [830/845]  eta: 0:00:05  loss: 1.6712 (1.6814)  loss_n_40: 0.3936 (0.4197)  loss_n_60: 0.3841 (0.3933)  loss_n_80: 0.4312 (0.4182)  loss_n_100: 0.4492 (0.4502)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [840/845]  eta: 0:00:01  loss: 1.5860 (1.6800)  loss_n_40: 0.3780 (0.4192)  loss_n_60: 0.3713 (0.3929)  loss_n_80: 0.4048 (0.4179)  loss_n_100: 0.4291 (0.4500)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13]  [844/845]  eta: 0:00:00  loss: 1.5860 (1.6802)  loss_n_40: 0.3780 (0.4191)  loss_n_60: 0.3698 (0.3929)  loss_n_80: 0.4048 (0.4180)  loss_n_100: 0.4283 (0.4501)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:13] Total time: 0:04:43 (0.3350 s / it)\n",
      "Averaged stats: loss: 1.5860 (1.6802)  loss_n_40: 0.3780 (0.4191)  loss_n_60: 0.3698 (0.3929)  loss_n_80: 0.4048 (0.4180)  loss_n_100: 0.4283 (0.4501)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_13_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 0.450%\n",
      "Min loss_n_100: 0.450\n",
      "Best Epoch: 13.000\n",
      "Train: [epoch:14]  [   0/1724]  eta: 1:58:57  lr: 0.000200  loss: 1.8791 (1.8791)  loss_n_40: 0.4626 (0.4626)  loss_n_60: 0.4644 (0.4644)  loss_n_80: 0.4616 (0.4616)  loss_n_100: 0.4906 (0.4906)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1402  data: 0.3847  max mem: 46473\n",
      "Train: [epoch:14]  [  10/1724]  eta: 1:52:37  lr: 0.000200  loss: 1.5590 (1.6346)  loss_n_40: 0.4060 (0.4203)  loss_n_60: 0.3669 (0.3823)  loss_n_80: 0.3798 (0.4038)  loss_n_100: 0.4029 (0.4281)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9428  data: 0.0352  max mem: 46473\n",
      "Train: [epoch:14]  [  20/1724]  eta: 1:51:42  lr: 0.000200  loss: 1.6128 (1.6462)  loss_n_40: 0.3913 (0.4132)  loss_n_60: 0.3674 (0.3847)  loss_n_80: 0.4065 (0.4115)  loss_n_100: 0.4228 (0.4368)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9233  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [  30/1724]  eta: 1:50:56  lr: 0.000200  loss: 1.5995 (1.6151)  loss_n_40: 0.3871 (0.4067)  loss_n_60: 0.3776 (0.3785)  loss_n_80: 0.3979 (0.4035)  loss_n_100: 0.4282 (0.4265)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [  40/1724]  eta: 1:50:13  lr: 0.000200  loss: 1.4351 (1.5659)  loss_n_40: 0.3644 (0.3970)  loss_n_60: 0.3384 (0.3677)  loss_n_80: 0.3467 (0.3878)  loss_n_100: 0.3836 (0.4133)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9201  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [  50/1724]  eta: 1:49:32  lr: 0.000200  loss: 1.4197 (1.5511)  loss_n_40: 0.3530 (0.3935)  loss_n_60: 0.3294 (0.3639)  loss_n_80: 0.3423 (0.3837)  loss_n_100: 0.3835 (0.4101)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9208  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [  60/1724]  eta: 1:48:51  lr: 0.000200  loss: 1.4312 (1.5399)  loss_n_40: 0.3687 (0.3923)  loss_n_60: 0.3334 (0.3599)  loss_n_80: 0.3545 (0.3814)  loss_n_100: 0.3843 (0.4062)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9218  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [  70/1724]  eta: 1:48:11  lr: 0.000200  loss: 1.4627 (1.5324)  loss_n_40: 0.3809 (0.3951)  loss_n_60: 0.3369 (0.3583)  loss_n_80: 0.3549 (0.3782)  loss_n_100: 0.3765 (0.4009)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [  80/1724]  eta: 1:47:31  lr: 0.000200  loss: 1.4071 (1.5280)  loss_n_40: 0.3645 (0.3939)  loss_n_60: 0.3340 (0.3570)  loss_n_80: 0.3476 (0.3776)  loss_n_100: 0.3584 (0.3995)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9219  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [  90/1724]  eta: 1:46:52  lr: 0.000200  loss: 1.3573 (1.5154)  loss_n_40: 0.3652 (0.3912)  loss_n_60: 0.3117 (0.3539)  loss_n_80: 0.3277 (0.3739)  loss_n_100: 0.3584 (0.3964)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9226  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 100/1724]  eta: 1:46:12  lr: 0.000200  loss: 1.3314 (1.5065)  loss_n_40: 0.3479 (0.3878)  loss_n_60: 0.3065 (0.3519)  loss_n_80: 0.3231 (0.3716)  loss_n_100: 0.3628 (0.3952)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9222  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [ 110/1724]  eta: 1:45:33  lr: 0.000200  loss: 1.2843 (1.4955)  loss_n_40: 0.3271 (0.3849)  loss_n_60: 0.2975 (0.3491)  loss_n_80: 0.3231 (0.3687)  loss_n_100: 0.3628 (0.3928)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9223  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 120/1724]  eta: 1:44:53  lr: 0.000200  loss: 1.2572 (1.4732)  loss_n_40: 0.3003 (0.3776)  loss_n_60: 0.2904 (0.3435)  loss_n_80: 0.3155 (0.3635)  loss_n_100: 0.3492 (0.3886)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9229  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 130/1724]  eta: 1:44:14  lr: 0.000200  loss: 1.3267 (1.4827)  loss_n_40: 0.3129 (0.3791)  loss_n_60: 0.3116 (0.3449)  loss_n_80: 0.3230 (0.3652)  loss_n_100: 0.3624 (0.3898)  triple_100: 0.0000 (0.0003)  triple_80: 0.0000 (0.0004)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0031)  time: 3.9228  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 140/1724]  eta: 1:43:34  lr: 0.000200  loss: 1.5237 (1.4813)  loss_n_40: 0.3708 (0.3775)  loss_n_60: 0.3474 (0.3441)  loss_n_80: 0.3904 (0.3654)  loss_n_100: 0.4131 (0.3908)  triple_100: 0.0000 (0.0003)  triple_80: 0.0000 (0.0003)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0029)  time: 3.9219  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 150/1724]  eta: 1:42:55  lr: 0.000200  loss: 1.3600 (1.4757)  loss_n_40: 0.3416 (0.3757)  loss_n_60: 0.3082 (0.3429)  loss_n_80: 0.3401 (0.3643)  loss_n_100: 0.3744 (0.3896)  triple_100: 0.0000 (0.0002)  triple_80: 0.0000 (0.0003)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0027)  time: 3.9215  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 160/1724]  eta: 1:42:15  lr: 0.000200  loss: 1.3339 (1.4815)  loss_n_40: 0.3416 (0.3773)  loss_n_60: 0.3108 (0.3436)  loss_n_80: 0.3373 (0.3651)  loss_n_100: 0.3712 (0.3903)  triple_100: 0.0000 (0.0002)  triple_80: 0.0000 (0.0011)  triple_60: 0.0000 (0.0010)  triple_40: 0.0000 (0.0028)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 170/1724]  eta: 1:41:36  lr: 0.000200  loss: 1.4098 (1.4792)  loss_n_40: 0.3501 (0.3757)  loss_n_60: 0.3323 (0.3430)  loss_n_80: 0.3518 (0.3649)  loss_n_100: 0.3860 (0.3907)  triple_100: 0.0000 (0.0002)  triple_80: 0.0000 (0.0010)  triple_60: 0.0000 (0.0009)  triple_40: 0.0000 (0.0027)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 180/1724]  eta: 1:40:56  lr: 0.000200  loss: 1.4615 (1.4825)  loss_n_40: 0.3717 (0.3770)  loss_n_60: 0.3324 (0.3435)  loss_n_80: 0.3586 (0.3656)  loss_n_100: 0.3920 (0.3919)  triple_100: 0.0000 (0.0002)  triple_80: 0.0000 (0.0010)  triple_60: 0.0000 (0.0009)  triple_40: 0.0000 (0.0025)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 190/1724]  eta: 1:40:17  lr: 0.000200  loss: 1.5544 (1.5023)  loss_n_40: 0.3931 (0.3779)  loss_n_60: 0.3461 (0.3453)  loss_n_80: 0.3739 (0.3688)  loss_n_100: 0.4099 (0.3964)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0031)  triple_60: 0.0000 (0.0036)  triple_40: 0.0000 (0.0024)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 200/1724]  eta: 1:39:38  lr: 0.000200  loss: 1.5845 (1.5084)  loss_n_40: 0.3869 (0.3775)  loss_n_60: 0.3566 (0.3464)  loss_n_80: 0.4088 (0.3713)  loss_n_100: 0.4535 (0.4000)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0029)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0023)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 210/1724]  eta: 1:38:58  lr: 0.000200  loss: 1.5651 (1.5270)  loss_n_40: 0.3748 (0.3797)  loss_n_60: 0.3455 (0.3474)  loss_n_80: 0.3999 (0.3728)  loss_n_100: 0.4369 (0.4014)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0028)  triple_60: 0.0000 (0.0032)  triple_40: 0.0000 (0.0154)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 220/1724]  eta: 1:38:19  lr: 0.000200  loss: 1.6445 (1.5455)  loss_n_40: 0.4154 (0.3832)  loss_n_60: 0.3607 (0.3516)  loss_n_80: 0.4191 (0.3784)  loss_n_100: 0.4304 (0.4077)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0027)  triple_60: 0.0000 (0.0031)  triple_40: 0.0000 (0.0147)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 230/1724]  eta: 1:37:39  lr: 0.000200  loss: 1.7853 (1.5627)  loss_n_40: 0.4221 (0.3862)  loss_n_60: 0.4110 (0.3558)  loss_n_80: 0.4543 (0.3834)  loss_n_100: 0.4888 (0.4137)  triple_100: 0.0000 (0.0040)  triple_80: 0.0000 (0.0026)  triple_60: 0.0000 (0.0029)  triple_40: 0.0000 (0.0141)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 240/1724]  eta: 1:37:00  lr: 0.000200  loss: 1.8356 (1.5752)  loss_n_40: 0.4395 (0.3888)  loss_n_60: 0.4317 (0.3587)  loss_n_80: 0.4759 (0.3871)  loss_n_100: 0.5077 (0.4181)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0025)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0135)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 250/1724]  eta: 1:36:20  lr: 0.000200  loss: 1.7307 (1.5717)  loss_n_40: 0.4395 (0.3882)  loss_n_60: 0.3750 (0.3577)  loss_n_80: 0.4248 (0.3863)  loss_n_100: 0.4466 (0.4178)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0024)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0129)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 260/1724]  eta: 1:35:41  lr: 0.000200  loss: 1.3713 (1.5712)  loss_n_40: 0.3507 (0.3893)  loss_n_60: 0.3119 (0.3576)  loss_n_80: 0.3532 (0.3860)  loss_n_100: 0.3935 (0.4175)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0023)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0124)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 270/1724]  eta: 1:35:01  lr: 0.000200  loss: 1.3635 (1.5637)  loss_n_40: 0.3482 (0.3883)  loss_n_60: 0.3162 (0.3559)  loss_n_80: 0.3358 (0.3842)  loss_n_100: 0.3638 (0.4152)  triple_100: 0.0000 (0.0034)  triple_80: 0.0000 (0.0022)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0120)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 280/1724]  eta: 1:34:22  lr: 0.000200  loss: 1.2940 (1.5554)  loss_n_40: 0.3369 (0.3865)  loss_n_60: 0.2936 (0.3539)  loss_n_80: 0.3321 (0.3822)  loss_n_100: 0.3542 (0.4134)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0021)  triple_60: 0.0000 (0.0024)  triple_40: 0.0000 (0.0116)  time: 3.9178  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 290/1724]  eta: 1:33:43  lr: 0.000200  loss: 1.2944 (1.5481)  loss_n_40: 0.3213 (0.3850)  loss_n_60: 0.3014 (0.3523)  loss_n_80: 0.3321 (0.3804)  loss_n_100: 0.3581 (0.4116)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0020)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0112)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 300/1724]  eta: 1:33:03  lr: 0.000200  loss: 1.3118 (1.5401)  loss_n_40: 0.3307 (0.3836)  loss_n_60: 0.3048 (0.3507)  loss_n_80: 0.3098 (0.3783)  loss_n_100: 0.3506 (0.4095)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0020)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0108)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 310/1724]  eta: 1:32:24  lr: 0.000200  loss: 1.3149 (1.5349)  loss_n_40: 0.3466 (0.3829)  loss_n_60: 0.3059 (0.3496)  loss_n_80: 0.3098 (0.3769)  loss_n_100: 0.3478 (0.4080)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0019)  triple_60: 0.0000 (0.0022)  triple_40: 0.0000 (0.0104)  time: 3.9189  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 320/1724]  eta: 1:31:45  lr: 0.000200  loss: 1.4137 (1.5319)  loss_n_40: 0.3602 (0.3829)  loss_n_60: 0.3294 (0.3490)  loss_n_80: 0.3378 (0.3761)  loss_n_100: 0.3775 (0.4070)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0018)  triple_60: 0.0000 (0.0022)  triple_40: 0.0000 (0.0101)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 330/1724]  eta: 1:31:05  lr: 0.000200  loss: 1.4137 (1.5299)  loss_n_40: 0.3602 (0.3825)  loss_n_60: 0.3147 (0.3484)  loss_n_80: 0.3465 (0.3756)  loss_n_100: 0.3775 (0.4063)  triple_100: 0.0000 (0.0028)  triple_80: 0.0000 (0.0020)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0098)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 340/1724]  eta: 1:30:26  lr: 0.000200  loss: 1.3699 (1.5418)  loss_n_40: 0.3492 (0.3815)  loss_n_60: 0.3129 (0.3476)  loss_n_80: 0.3352 (0.3744)  loss_n_100: 0.3772 (0.4055)  triple_100: 0.0000 (0.0069)  triple_80: 0.0000 (0.0067)  triple_60: 0.0000 (0.0054)  triple_40: 0.0000 (0.0137)  time: 3.9167  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [ 350/1724]  eta: 1:29:46  lr: 0.000200  loss: 1.6940 (1.5612)  loss_n_40: 0.3637 (0.3846)  loss_n_60: 0.3667 (0.3516)  loss_n_80: 0.4585 (0.3806)  loss_n_100: 0.4731 (0.4126)  triple_100: 0.0000 (0.0067)  triple_80: 0.0000 (0.0065)  triple_60: 0.0000 (0.0053)  triple_40: 0.0000 (0.0134)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 360/1724]  eta: 1:29:07  lr: 0.000200  loss: 2.1201 (1.5817)  loss_n_40: 0.4555 (0.3867)  loss_n_60: 0.4657 (0.3548)  loss_n_80: 0.5661 (0.3856)  loss_n_100: 0.6216 (0.4189)  triple_100: 0.0000 (0.0074)  triple_80: 0.0000 (0.0073)  triple_60: 0.0000 (0.0064)  triple_40: 0.0000 (0.0145)  time: 3.9171  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 370/1724]  eta: 1:28:28  lr: 0.000200  loss: 2.0997 (1.5970)  loss_n_40: 0.4773 (0.3901)  loss_n_60: 0.4589 (0.3580)  loss_n_80: 0.5560 (0.3900)  loss_n_100: 0.6187 (0.4242)  triple_100: 0.0000 (0.0072)  triple_80: 0.0000 (0.0071)  triple_60: 0.0000 (0.0062)  triple_40: 0.0000 (0.0141)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 380/1724]  eta: 1:27:49  lr: 0.000200  loss: 2.0859 (1.6060)  loss_n_40: 0.4932 (0.3922)  loss_n_60: 0.4507 (0.3600)  loss_n_80: 0.5266 (0.3926)  loss_n_100: 0.5535 (0.4273)  triple_100: 0.0000 (0.0070)  triple_80: 0.0000 (0.0069)  triple_60: 0.0000 (0.0061)  triple_40: 0.0000 (0.0138)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 390/1724]  eta: 1:27:09  lr: 0.000200  loss: 1.8177 (1.6110)  loss_n_40: 0.4517 (0.3936)  loss_n_60: 0.4135 (0.3615)  loss_n_80: 0.4396 (0.3937)  loss_n_100: 0.5087 (0.4292)  triple_100: 0.0000 (0.0068)  triple_80: 0.0000 (0.0067)  triple_60: 0.0000 (0.0059)  triple_40: 0.0000 (0.0134)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 400/1724]  eta: 1:26:30  lr: 0.000200  loss: 1.7862 (1.6144)  loss_n_40: 0.4357 (0.3945)  loss_n_60: 0.4055 (0.3624)  loss_n_80: 0.4359 (0.3947)  loss_n_100: 0.4927 (0.4307)  triple_100: 0.0000 (0.0066)  triple_80: 0.0000 (0.0066)  triple_60: 0.0000 (0.0058)  triple_40: 0.0000 (0.0131)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 410/1724]  eta: 1:25:51  lr: 0.000200  loss: 1.6758 (1.6157)  loss_n_40: 0.4178 (0.3952)  loss_n_60: 0.3804 (0.3630)  loss_n_80: 0.4233 (0.3950)  loss_n_100: 0.4577 (0.4312)  triple_100: 0.0000 (0.0065)  triple_80: 0.0000 (0.0064)  triple_60: 0.0000 (0.0056)  triple_40: 0.0000 (0.0128)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 420/1724]  eta: 1:25:11  lr: 0.000200  loss: 1.5947 (1.6162)  loss_n_40: 0.4133 (0.3958)  loss_n_60: 0.3623 (0.3633)  loss_n_80: 0.3984 (0.3951)  loss_n_100: 0.4349 (0.4315)  triple_100: 0.0000 (0.0063)  triple_80: 0.0000 (0.0063)  triple_60: 0.0000 (0.0055)  triple_40: 0.0000 (0.0125)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 430/1724]  eta: 1:24:32  lr: 0.000200  loss: 1.5416 (1.6153)  loss_n_40: 0.4210 (0.3963)  loss_n_60: 0.3418 (0.3631)  loss_n_80: 0.3676 (0.3948)  loss_n_100: 0.4271 (0.4312)  triple_100: 0.0000 (0.0062)  triple_80: 0.0000 (0.0061)  triple_60: 0.0000 (0.0054)  triple_40: 0.0000 (0.0122)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 440/1724]  eta: 1:23:53  lr: 0.000200  loss: 1.4975 (1.6124)  loss_n_40: 0.3924 (0.3959)  loss_n_60: 0.3411 (0.3626)  loss_n_80: 0.3676 (0.3942)  loss_n_100: 0.4201 (0.4306)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0060)  triple_60: 0.0000 (0.0053)  triple_40: 0.0000 (0.0119)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 450/1724]  eta: 1:23:14  lr: 0.000200  loss: 1.4095 (1.6085)  loss_n_40: 0.3621 (0.3958)  loss_n_60: 0.3164 (0.3615)  loss_n_80: 0.3380 (0.3930)  loss_n_100: 0.3848 (0.4297)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0058)  triple_60: 0.0000 (0.0051)  triple_40: 0.0000 (0.0116)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 460/1724]  eta: 1:22:34  lr: 0.000200  loss: 1.4095 (1.6056)  loss_n_40: 0.3621 (0.3960)  loss_n_60: 0.3099 (0.3609)  loss_n_80: 0.3339 (0.3922)  loss_n_100: 0.3766 (0.4287)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0057)  triple_60: 0.0000 (0.0050)  triple_40: 0.0000 (0.0114)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 470/1724]  eta: 1:21:55  lr: 0.000200  loss: 1.3425 (1.5979)  loss_n_40: 0.3378 (0.3947)  loss_n_60: 0.2995 (0.3592)  loss_n_80: 0.3280 (0.3902)  loss_n_100: 0.3607 (0.4266)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0056)  triple_60: 0.0000 (0.0049)  triple_40: 0.0000 (0.0111)  time: 3.9194  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 480/1724]  eta: 1:21:16  lr: 0.000200  loss: 1.2844 (1.5934)  loss_n_40: 0.3363 (0.3946)  loss_n_60: 0.2814 (0.3580)  loss_n_80: 0.2997 (0.3888)  loss_n_100: 0.3460 (0.4252)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0055)  triple_60: 0.0000 (0.0048)  triple_40: 0.0000 (0.0109)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 490/1724]  eta: 1:20:37  lr: 0.000200  loss: 1.3347 (1.5893)  loss_n_40: 0.3485 (0.3937)  loss_n_60: 0.3070 (0.3573)  loss_n_80: 0.3221 (0.3878)  loss_n_100: 0.3568 (0.4243)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0054)  triple_60: 0.0000 (0.0047)  triple_40: 0.0000 (0.0107)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 500/1724]  eta: 1:19:58  lr: 0.000200  loss: 1.3256 (1.5845)  loss_n_40: 0.3318 (0.3926)  loss_n_60: 0.3145 (0.3567)  loss_n_80: 0.3251 (0.3866)  loss_n_100: 0.3609 (0.4230)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0053)  triple_60: 0.0000 (0.0046)  triple_40: 0.0000 (0.0105)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 510/1724]  eta: 1:19:18  lr: 0.000200  loss: 1.3401 (1.5821)  loss_n_40: 0.3626 (0.3927)  loss_n_60: 0.3189 (0.3563)  loss_n_80: 0.3189 (0.3858)  loss_n_100: 0.3597 (0.4221)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0052)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0103)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 520/1724]  eta: 1:18:39  lr: 0.000200  loss: 1.3295 (1.5779)  loss_n_40: 0.3467 (0.3918)  loss_n_60: 0.3026 (0.3556)  loss_n_80: 0.3270 (0.3848)  loss_n_100: 0.3533 (0.4210)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0051)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0101)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 530/1724]  eta: 1:18:00  lr: 0.000200  loss: 1.3262 (1.5741)  loss_n_40: 0.3256 (0.3909)  loss_n_60: 0.3095 (0.3549)  loss_n_80: 0.3298 (0.3840)  loss_n_100: 0.3562 (0.4201)  triple_100: 0.0000 (0.0050)  triple_80: 0.0000 (0.0050)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0099)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 540/1724]  eta: 1:17:21  lr: 0.000200  loss: 1.3262 (1.5685)  loss_n_40: 0.3190 (0.3894)  loss_n_60: 0.3047 (0.3538)  loss_n_80: 0.3312 (0.3827)  loss_n_100: 0.3602 (0.4189)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0049)  triple_60: 0.0000 (0.0043)  triple_40: 0.0000 (0.0097)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 550/1724]  eta: 1:16:42  lr: 0.000200  loss: 1.1875 (1.5616)  loss_n_40: 0.2958 (0.3878)  loss_n_60: 0.2763 (0.3524)  loss_n_80: 0.2874 (0.3810)  loss_n_100: 0.3307 (0.4171)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0048)  triple_60: 0.0000 (0.0042)  triple_40: 0.0000 (0.0095)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 560/1724]  eta: 1:16:02  lr: 0.000200  loss: 1.2250 (1.5628)  loss_n_40: 0.3306 (0.3875)  loss_n_60: 0.2824 (0.3518)  loss_n_80: 0.2852 (0.3802)  loss_n_100: 0.3195 (0.4161)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0057)  triple_60: 0.0000 (0.0053)  triple_40: 0.0000 (0.0103)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 570/1724]  eta: 1:15:23  lr: 0.000200  loss: 1.9014 (1.5951)  loss_n_40: 0.4416 (0.3901)  loss_n_60: 0.4082 (0.3547)  loss_n_80: 0.4604 (0.3838)  loss_n_100: 0.4670 (0.4204)  triple_100: 0.0000 (0.0069)  triple_80: 0.0000 (0.0125)  triple_60: 0.0000 (0.0112)  triple_40: 0.0000 (0.0156)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 580/1724]  eta: 1:14:44  lr: 0.000200  loss: 2.4995 (1.6119)  loss_n_40: 0.5190 (0.3930)  loss_n_60: 0.5333 (0.3584)  loss_n_80: 0.6307 (0.3888)  loss_n_100: 0.7257 (0.4264)  triple_100: 0.0000 (0.0067)  triple_80: 0.0000 (0.0123)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0153)  time: 3.9166  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [ 590/1724]  eta: 1:14:04  lr: 0.000200  loss: 2.3227 (1.6188)  loss_n_40: 0.5187 (0.3948)  loss_n_60: 0.5230 (0.3600)  loss_n_80: 0.6064 (0.3908)  loss_n_100: 0.6556 (0.4287)  triple_100: 0.0000 (0.0066)  triple_80: 0.0000 (0.0121)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0151)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 600/1724]  eta: 1:13:25  lr: 0.000200  loss: 1.9038 (1.6228)  loss_n_40: 0.4748 (0.3958)  loss_n_60: 0.4458 (0.3610)  loss_n_80: 0.4889 (0.3922)  loss_n_100: 0.5232 (0.4301)  triple_100: 0.0000 (0.0065)  triple_80: 0.0000 (0.0119)  triple_60: 0.0000 (0.0106)  triple_40: 0.0000 (0.0148)  time: 3.9157  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 610/1724]  eta: 1:12:46  lr: 0.000200  loss: 1.7230 (1.6239)  loss_n_40: 0.4291 (0.3962)  loss_n_60: 0.3905 (0.3615)  loss_n_80: 0.4272 (0.3926)  loss_n_100: 0.4974 (0.4305)  triple_100: 0.0000 (0.0064)  triple_80: 0.0000 (0.0117)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0146)  time: 3.9156  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 620/1724]  eta: 1:12:07  lr: 0.000200  loss: 1.6530 (1.6253)  loss_n_40: 0.4224 (0.3970)  loss_n_60: 0.3877 (0.3619)  loss_n_80: 0.3944 (0.3931)  loss_n_100: 0.4451 (0.4308)  triple_100: 0.0000 (0.0063)  triple_80: 0.0000 (0.0115)  triple_60: 0.0000 (0.0103)  triple_40: 0.0000 (0.0143)  time: 3.9147  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 630/1724]  eta: 1:11:27  lr: 0.000200  loss: 1.5500 (1.6240)  loss_n_40: 0.4088 (0.3973)  loss_n_60: 0.3554 (0.3618)  loss_n_80: 0.3730 (0.3929)  loss_n_100: 0.4157 (0.4304)  triple_100: 0.0000 (0.0062)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0141)  time: 3.9153  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 640/1724]  eta: 1:10:48  lr: 0.000200  loss: 1.4841 (1.6222)  loss_n_40: 0.3796 (0.3970)  loss_n_60: 0.3360 (0.3615)  loss_n_80: 0.3644 (0.3925)  loss_n_100: 0.4101 (0.4301)  triple_100: 0.0000 (0.0061)  triple_80: 0.0000 (0.0111)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0139)  time: 3.9169  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 650/1724]  eta: 1:10:09  lr: 0.000200  loss: 1.4805 (1.6204)  loss_n_40: 0.3746 (0.3970)  loss_n_60: 0.3360 (0.3613)  loss_n_80: 0.3624 (0.3920)  loss_n_100: 0.4043 (0.4295)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0110)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0137)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 660/1724]  eta: 1:09:30  lr: 0.000200  loss: 1.5182 (1.6194)  loss_n_40: 0.3907 (0.3972)  loss_n_60: 0.3386 (0.3612)  loss_n_80: 0.3591 (0.3919)  loss_n_100: 0.4003 (0.4293)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0097)  triple_40: 0.0000 (0.0135)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 670/1724]  eta: 1:08:50  lr: 0.000200  loss: 1.4263 (1.6174)  loss_n_40: 0.3907 (0.3973)  loss_n_60: 0.3322 (0.3608)  loss_n_80: 0.3418 (0.3913)  loss_n_100: 0.3843 (0.4287)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0106)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0133)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 680/1724]  eta: 1:08:11  lr: 0.000200  loss: 1.3413 (1.6133)  loss_n_40: 0.3486 (0.3967)  loss_n_60: 0.3059 (0.3600)  loss_n_80: 0.3277 (0.3903)  loss_n_100: 0.3603 (0.4276)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0131)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 690/1724]  eta: 1:07:32  lr: 0.000200  loss: 1.3413 (1.6103)  loss_n_40: 0.3481 (0.3963)  loss_n_60: 0.3059 (0.3594)  loss_n_80: 0.3277 (0.3896)  loss_n_100: 0.3597 (0.4269)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0092)  triple_40: 0.0000 (0.0129)  time: 3.9157  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 700/1724]  eta: 1:06:53  lr: 0.000200  loss: 1.4179 (1.6072)  loss_n_40: 0.3578 (0.3958)  loss_n_60: 0.3071 (0.3587)  loss_n_80: 0.3437 (0.3890)  loss_n_100: 0.3705 (0.4261)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0102)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0127)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 710/1724]  eta: 1:06:14  lr: 0.000200  loss: 1.4122 (1.6049)  loss_n_40: 0.3578 (0.3957)  loss_n_60: 0.3082 (0.3583)  loss_n_80: 0.3365 (0.3884)  loss_n_100: 0.3705 (0.4255)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0100)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0125)  time: 3.9196  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 720/1724]  eta: 1:05:34  lr: 0.000200  loss: 1.3483 (1.6021)  loss_n_40: 0.3522 (0.3954)  loss_n_60: 0.3082 (0.3578)  loss_n_80: 0.3198 (0.3877)  loss_n_100: 0.3533 (0.4247)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0099)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0123)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 730/1724]  eta: 1:04:55  lr: 0.000200  loss: 1.3301 (1.5986)  loss_n_40: 0.3391 (0.3947)  loss_n_60: 0.2996 (0.3571)  loss_n_80: 0.3154 (0.3869)  loss_n_100: 0.3352 (0.4239)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0098)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0122)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 740/1724]  eta: 1:04:16  lr: 0.000200  loss: 1.2503 (1.5937)  loss_n_40: 0.3245 (0.3937)  loss_n_60: 0.2803 (0.3561)  loss_n_80: 0.2975 (0.3857)  loss_n_100: 0.3309 (0.4226)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0096)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0120)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 750/1724]  eta: 1:03:37  lr: 0.000200  loss: 1.2503 (1.5896)  loss_n_40: 0.3245 (0.3929)  loss_n_60: 0.2824 (0.3553)  loss_n_80: 0.2989 (0.3848)  loss_n_100: 0.3329 (0.4216)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0119)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 760/1724]  eta: 1:02:58  lr: 0.000200  loss: 1.2791 (1.5859)  loss_n_40: 0.3238 (0.3922)  loss_n_60: 0.2876 (0.3545)  loss_n_80: 0.3144 (0.3839)  loss_n_100: 0.3404 (0.4207)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0117)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 770/1724]  eta: 1:02:18  lr: 0.000200  loss: 1.2725 (1.5831)  loss_n_40: 0.3338 (0.3920)  loss_n_60: 0.2876 (0.3540)  loss_n_80: 0.3127 (0.3832)  loss_n_100: 0.3354 (0.4198)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0093)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0115)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 780/1724]  eta: 1:01:39  lr: 0.000200  loss: 1.2725 (1.5796)  loss_n_40: 0.3346 (0.3913)  loss_n_60: 0.2898 (0.3533)  loss_n_80: 0.3127 (0.3824)  loss_n_100: 0.3331 (0.4189)  triple_100: 0.0000 (0.0050)  triple_80: 0.0000 (0.0091)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0114)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 790/1724]  eta: 1:01:00  lr: 0.000200  loss: 1.2486 (1.5751)  loss_n_40: 0.3125 (0.3905)  loss_n_60: 0.2802 (0.3524)  loss_n_80: 0.2956 (0.3813)  loss_n_100: 0.3345 (0.4177)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0090)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0113)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 800/1724]  eta: 1:00:21  lr: 0.000200  loss: 1.2005 (1.5710)  loss_n_40: 0.3106 (0.3896)  loss_n_60: 0.2802 (0.3516)  loss_n_80: 0.3042 (0.3804)  loss_n_100: 0.3289 (0.4166)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0089)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0111)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 810/1724]  eta: 0:59:42  lr: 0.000200  loss: 1.4008 (1.5768)  loss_n_40: 0.3371 (0.3895)  loss_n_60: 0.3188 (0.3524)  loss_n_80: 0.3360 (0.3819)  loss_n_100: 0.3647 (0.4186)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0110)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 820/1724]  eta: 0:59:02  lr: 0.000200  loss: 1.8591 (1.5839)  loss_n_40: 0.3957 (0.3902)  loss_n_60: 0.4194 (0.3539)  loss_n_80: 0.5055 (0.3843)  loss_n_100: 0.5732 (0.4215)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0094)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0108)  time: 3.9189  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [ 830/1724]  eta: 0:58:23  lr: 0.000200  loss: 1.8777 (1.5884)  loss_n_40: 0.4213 (0.3908)  loss_n_60: 0.4363 (0.3550)  loss_n_80: 0.5015 (0.3857)  loss_n_100: 0.5779 (0.4233)  triple_100: 0.0000 (0.0059)  triple_80: 0.0000 (0.0092)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0107)  time: 3.9198  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 840/1724]  eta: 0:57:44  lr: 0.000200  loss: 1.8310 (1.5904)  loss_n_40: 0.4275 (0.3912)  loss_n_60: 0.4076 (0.3555)  loss_n_80: 0.4693 (0.3864)  loss_n_100: 0.5251 (0.4242)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0091)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0106)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 850/1724]  eta: 0:57:05  lr: 0.000200  loss: 1.6509 (1.5910)  loss_n_40: 0.4234 (0.3915)  loss_n_60: 0.3853 (0.3556)  loss_n_80: 0.4142 (0.3867)  loss_n_100: 0.4639 (0.4245)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0090)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0105)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 860/1724]  eta: 0:56:26  lr: 0.000200  loss: 1.5522 (1.5900)  loss_n_40: 0.4086 (0.3915)  loss_n_60: 0.3531 (0.3555)  loss_n_80: 0.3922 (0.3865)  loss_n_100: 0.3997 (0.4241)  triple_100: 0.0000 (0.0057)  triple_80: 0.0000 (0.0089)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0103)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 870/1724]  eta: 0:55:46  lr: 0.000200  loss: 1.5088 (1.5892)  loss_n_40: 0.3843 (0.3914)  loss_n_60: 0.3354 (0.3554)  loss_n_80: 0.3711 (0.3864)  loss_n_100: 0.3978 (0.4240)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0088)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0102)  time: 3.9191  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 880/1724]  eta: 0:55:07  lr: 0.000200  loss: 1.4138 (1.5860)  loss_n_40: 0.3619 (0.3908)  loss_n_60: 0.3244 (0.3548)  loss_n_80: 0.3520 (0.3857)  loss_n_100: 0.3829 (0.4231)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0087)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0101)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 890/1724]  eta: 0:54:28  lr: 0.000200  loss: 1.2943 (1.5830)  loss_n_40: 0.3350 (0.3903)  loss_n_60: 0.2938 (0.3542)  loss_n_80: 0.3019 (0.3849)  loss_n_100: 0.3315 (0.4223)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0086)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0100)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 900/1724]  eta: 0:53:49  lr: 0.000200  loss: 1.2882 (1.5802)  loss_n_40: 0.3242 (0.3900)  loss_n_60: 0.2881 (0.3536)  loss_n_80: 0.3116 (0.3842)  loss_n_100: 0.3411 (0.4215)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0085)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0099)  time: 3.9189  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 910/1724]  eta: 0:53:10  lr: 0.000200  loss: 1.2571 (1.5765)  loss_n_40: 0.3194 (0.3893)  loss_n_60: 0.2861 (0.3528)  loss_n_80: 0.3102 (0.3833)  loss_n_100: 0.3338 (0.4205)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0084)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0098)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 920/1724]  eta: 0:52:30  lr: 0.000200  loss: 1.2170 (1.5731)  loss_n_40: 0.3077 (0.3887)  loss_n_60: 0.2741 (0.3522)  loss_n_80: 0.2980 (0.3824)  loss_n_100: 0.3307 (0.4196)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0083)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0097)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 930/1724]  eta: 0:51:51  lr: 0.000200  loss: 1.2200 (1.5704)  loss_n_40: 0.3115 (0.3883)  loss_n_60: 0.2741 (0.3516)  loss_n_80: 0.3085 (0.3818)  loss_n_100: 0.3346 (0.4189)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0082)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0096)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 940/1724]  eta: 0:51:12  lr: 0.000200  loss: 1.2806 (1.5674)  loss_n_40: 0.3292 (0.3877)  loss_n_60: 0.2897 (0.3510)  loss_n_80: 0.3095 (0.3811)  loss_n_100: 0.3366 (0.4180)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0082)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0095)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 950/1724]  eta: 0:50:33  lr: 0.000200  loss: 1.2578 (1.5649)  loss_n_40: 0.3239 (0.3871)  loss_n_60: 0.2900 (0.3506)  loss_n_80: 0.3067 (0.3805)  loss_n_100: 0.3366 (0.4173)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0081)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0094)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 960/1724]  eta: 0:49:54  lr: 0.000200  loss: 1.2273 (1.5612)  loss_n_40: 0.2924 (0.3861)  loss_n_60: 0.2735 (0.3498)  loss_n_80: 0.2918 (0.3795)  loss_n_100: 0.3238 (0.4163)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0082)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0093)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 970/1724]  eta: 0:49:15  lr: 0.000200  loss: 1.2825 (1.5742)  loss_n_40: 0.3160 (0.3861)  loss_n_60: 0.2880 (0.3503)  loss_n_80: 0.3101 (0.3804)  loss_n_100: 0.3456 (0.4173)  triple_100: 0.0000 (0.0075)  triple_80: 0.0000 (0.0109)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0123)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [ 980/1724]  eta: 0:48:35  lr: 0.000200  loss: 2.2203 (1.6055)  loss_n_40: 0.4456 (0.3878)  loss_n_60: 0.4942 (0.3528)  loss_n_80: 0.5736 (0.3837)  loss_n_100: 0.6322 (0.4211)  triple_100: 0.0000 (0.0164)  triple_80: 0.0000 (0.0190)  triple_60: 0.0000 (0.0107)  triple_40: 0.0000 (0.0139)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [ 990/1724]  eta: 0:47:56  lr: 0.000200  loss: 3.5373 (1.6358)  loss_n_40: 0.7301 (0.3931)  loss_n_60: 0.7709 (0.3586)  loss_n_80: 0.8785 (0.3907)  loss_n_100: 0.9762 (0.4286)  triple_100: 0.0000 (0.0187)  triple_80: 0.0000 (0.0214)  triple_60: 0.0000 (0.0106)  triple_40: 0.0000 (0.0141)  time: 3.9167  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1000/1724]  eta: 0:47:17  lr: 0.000200  loss: 4.2037 (1.6599)  loss_n_40: 0.9102 (0.3994)  loss_n_60: 0.9197 (0.3642)  loss_n_80: 1.0515 (0.3970)  loss_n_100: 1.0827 (0.4351)  triple_100: 0.0000 (0.0185)  triple_80: 0.0000 (0.0212)  triple_60: 0.0000 (0.0105)  triple_40: 0.0000 (0.0140)  time: 3.9151  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1010/1724]  eta: 0:46:38  lr: 0.000200  loss: 3.4707 (1.6767)  loss_n_40: 0.9101 (0.4038)  loss_n_60: 0.8453 (0.3683)  loss_n_80: 0.8672 (0.4013)  loss_n_100: 0.9744 (0.4397)  triple_100: 0.0000 (0.0184)  triple_80: 0.0000 (0.0210)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0138)  time: 3.9156  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1020/1724]  eta: 0:45:58  lr: 0.000200  loss: 4.1662 (1.8001)  loss_n_40: 0.9231 (0.4153)  loss_n_60: 0.9160 (0.3827)  loss_n_80: 0.9436 (0.4179)  loss_n_100: 1.0143 (0.4566)  triple_100: 0.0000 (0.0381)  triple_80: 0.0000 (0.0394)  triple_60: 0.0000 (0.0264)  triple_40: 0.0000 (0.0239)  time: 3.9160  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1030/1724]  eta: 0:45:19  lr: 0.000200  loss: 10.6516 (1.8873)  loss_n_40: 2.3685 (0.4370)  loss_n_60: 2.4193 (0.4038)  loss_n_80: 2.5786 (0.4417)  loss_n_100: 2.5669 (0.4779)  triple_100: 0.0000 (0.0377)  triple_80: 0.0000 (0.0390)  triple_60: 0.0000 (0.0261)  triple_40: 0.0000 (0.0240)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1040/1724]  eta: 0:44:40  lr: 0.000200  loss: 11.2198 (1.9755)  loss_n_40: 2.6288 (0.4579)  loss_n_60: 2.6463 (0.4260)  loss_n_80: 2.9984 (0.4655)  loss_n_100: 2.8485 (0.5005)  triple_100: 0.0000 (0.0373)  triple_80: 0.0000 (0.0386)  triple_60: 0.0000 (0.0259)  triple_40: 0.0000 (0.0238)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1050/1724]  eta: 0:44:01  lr: 0.000200  loss: 10.5588 (2.0532)  loss_n_40: 2.4145 (0.4771)  loss_n_60: 2.5861 (0.4458)  loss_n_80: 2.7316 (0.4856)  loss_n_100: 2.7663 (0.5203)  triple_100: 0.0000 (0.0370)  triple_80: 0.0000 (0.0382)  triple_60: 0.0000 (0.0256)  triple_40: 0.0000 (0.0236)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1060/1724]  eta: 0:43:22  lr: 0.000200  loss: 10.0971 (2.1311)  loss_n_40: 2.3612 (0.4955)  loss_n_60: 2.5155 (0.4658)  loss_n_80: 2.5447 (0.5056)  loss_n_100: 2.4693 (0.5395)  triple_100: 0.0000 (0.0366)  triple_80: 0.0000 (0.0379)  triple_60: 0.0000 (0.0254)  triple_40: 0.0000 (0.0248)  time: 3.9161  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [1070/1724]  eta: 0:42:42  lr: 0.000200  loss: 10.7443 (2.2130)  loss_n_40: 2.4397 (0.5133)  loss_n_60: 2.6798 (0.4861)  loss_n_80: 2.7188 (0.5263)  loss_n_100: 2.6825 (0.5592)  triple_100: 0.0000 (0.0374)  triple_80: 0.0000 (0.0375)  triple_60: 0.0000 (0.0274)  triple_40: 0.0000 (0.0257)  time: 3.9155  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1080/1724]  eta: 0:42:03  lr: 0.000200  loss: 9.7794 (2.2760)  loss_n_40: 2.2619 (0.5274)  loss_n_60: 2.4396 (0.5028)  loss_n_80: 2.4689 (0.5429)  loss_n_100: 2.4798 (0.5760)  triple_100: 0.0000 (0.0371)  triple_80: 0.0000 (0.0373)  triple_60: 0.0000 (0.0272)  triple_40: 0.0000 (0.0254)  time: 3.9155  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1090/1724]  eta: 0:41:24  lr: 0.000200  loss: 9.2972 (2.3457)  loss_n_40: 2.1409 (0.5426)  loss_n_60: 2.3678 (0.5208)  loss_n_80: 2.4092 (0.5615)  loss_n_100: 2.4647 (0.5950)  triple_100: 0.0000 (0.0367)  triple_80: 0.0000 (0.0370)  triple_60: 0.0000 (0.0269)  triple_40: 0.0000 (0.0252)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1100/1724]  eta: 0:40:45  lr: 0.000200  loss: 9.9499 (2.4091)  loss_n_40: 2.0601 (0.5554)  loss_n_60: 2.4486 (0.5369)  loss_n_80: 2.6538 (0.5787)  loss_n_100: 2.6514 (0.6125)  triple_100: 0.0000 (0.0364)  triple_80: 0.0000 (0.0366)  triple_60: 0.0000 (0.0267)  triple_40: 0.0000 (0.0259)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1110/1724]  eta: 0:40:06  lr: 0.000200  loss: 8.9587 (2.4695)  loss_n_40: 1.8815 (0.5674)  loss_n_60: 2.2506 (0.5526)  loss_n_80: 2.4000 (0.5956)  loss_n_100: 2.4399 (0.6295)  triple_100: 0.0000 (0.0361)  triple_80: 0.0000 (0.0363)  triple_60: 0.0000 (0.0264)  triple_40: 0.0000 (0.0257)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1120/1724]  eta: 0:39:26  lr: 0.000200  loss: 9.0046 (2.5291)  loss_n_40: 1.8029 (0.5790)  loss_n_60: 2.2069 (0.5676)  loss_n_80: 2.4255 (0.6125)  loss_n_100: 2.5240 (0.6467)  triple_100: 0.0000 (0.0358)  triple_80: 0.0000 (0.0360)  triple_60: 0.0000 (0.0262)  triple_40: 0.0000 (0.0254)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1130/1724]  eta: 0:38:47  lr: 0.000200  loss: 9.0227 (2.5838)  loss_n_40: 1.8191 (0.5897)  loss_n_60: 2.1965 (0.5816)  loss_n_80: 2.4563 (0.6280)  loss_n_100: 2.5240 (0.6622)  triple_100: 0.0000 (0.0354)  triple_80: 0.0000 (0.0356)  triple_60: 0.0000 (0.0260)  triple_40: 0.0000 (0.0252)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1140/1724]  eta: 0:38:08  lr: 0.000200  loss: 7.5438 (2.6318)  loss_n_40: 1.6030 (0.5988)  loss_n_60: 1.8715 (0.5936)  loss_n_80: 2.0686 (0.6416)  loss_n_100: 2.1541 (0.6761)  triple_100: 0.0000 (0.0353)  triple_80: 0.0000 (0.0356)  triple_60: 0.0000 (0.0257)  triple_40: 0.0000 (0.0250)  time: 3.9171  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1150/1724]  eta: 0:37:29  lr: 0.000200  loss: 7.5175 (2.6811)  loss_n_40: 1.5255 (0.6077)  loss_n_60: 1.7974 (0.6057)  loss_n_80: 2.0673 (0.6557)  loss_n_100: 2.2623 (0.6910)  triple_100: 0.0000 (0.0350)  triple_80: 0.0000 (0.0358)  triple_60: 0.0000 (0.0255)  triple_40: 0.0000 (0.0248)  time: 3.9175  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1160/1724]  eta: 0:36:50  lr: 0.000200  loss: 8.3379 (2.7326)  loss_n_40: 1.6205 (0.6171)  loss_n_60: 1.9908 (0.6182)  loss_n_80: 2.2715 (0.6705)  loss_n_100: 2.4016 (0.7067)  triple_100: 0.0000 (0.0347)  triple_80: 0.0000 (0.0355)  triple_60: 0.0000 (0.0253)  triple_40: 0.0000 (0.0246)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1170/1724]  eta: 0:36:10  lr: 0.000200  loss: 8.3379 (2.7777)  loss_n_40: 1.6358 (0.6255)  loss_n_60: 1.9097 (0.6291)  loss_n_80: 2.2751 (0.6836)  loss_n_100: 2.4211 (0.7205)  triple_100: 0.0000 (0.0344)  triple_80: 0.0000 (0.0352)  triple_60: 0.0000 (0.0251)  triple_40: 0.0000 (0.0244)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1180/1724]  eta: 0:35:31  lr: 0.000200  loss: 7.6621 (2.8171)  loss_n_40: 1.5994 (0.6332)  loss_n_60: 1.8007 (0.6384)  loss_n_80: 2.0635 (0.6947)  loss_n_100: 2.2795 (0.7327)  triple_100: 0.0000 (0.0341)  triple_80: 0.0000 (0.0349)  triple_60: 0.0000 (0.0249)  triple_40: 0.0000 (0.0242)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1190/1724]  eta: 0:34:52  lr: 0.000200  loss: 7.6613 (2.8700)  loss_n_40: 1.5502 (0.6415)  loss_n_60: 1.7732 (0.6487)  loss_n_80: 2.0446 (0.7064)  loss_n_100: 2.1673 (0.7458)  triple_100: 0.0000 (0.0355)  triple_80: 0.0000 (0.0377)  triple_60: 0.0000 (0.0287)  triple_40: 0.0000 (0.0256)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1200/1724]  eta: 0:34:13  lr: 0.000200  loss: 8.0866 (2.9141)  loss_n_40: 1.6731 (0.6505)  loss_n_60: 1.9272 (0.6599)  loss_n_80: 2.1003 (0.7182)  loss_n_100: 2.3436 (0.7591)  triple_100: 0.0000 (0.0352)  triple_80: 0.0000 (0.0374)  triple_60: 0.0000 (0.0285)  triple_40: 0.0000 (0.0254)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1210/1724]  eta: 0:33:34  lr: 0.000200  loss: 7.7923 (2.9492)  loss_n_40: 1.6558 (0.6578)  loss_n_60: 1.8601 (0.6687)  loss_n_80: 1.9740 (0.7273)  loss_n_100: 2.2168 (0.7699)  triple_100: 0.0000 (0.0349)  triple_80: 0.0000 (0.0371)  triple_60: 0.0000 (0.0283)  triple_40: 0.0000 (0.0252)  time: 3.9198  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1220/1724]  eta: 0:32:55  lr: 0.000200  loss: 7.3263 (2.9815)  loss_n_40: 1.6082 (0.6653)  loss_n_60: 1.7308 (0.6770)  loss_n_80: 1.8643 (0.7356)  loss_n_100: 2.0683 (0.7793)  triple_100: 0.0000 (0.0346)  triple_80: 0.0000 (0.0368)  triple_60: 0.0000 (0.0280)  triple_40: 0.0000 (0.0250)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1230/1724]  eta: 0:32:15  lr: 0.000200  loss: 7.0712 (3.0130)  loss_n_40: 1.5783 (0.6722)  loss_n_60: 1.7200 (0.6850)  loss_n_80: 1.7642 (0.7437)  loss_n_100: 1.9545 (0.7888)  triple_100: 0.0000 (0.0343)  triple_80: 0.0000 (0.0365)  triple_60: 0.0000 (0.0278)  triple_40: 0.0000 (0.0248)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1240/1724]  eta: 0:31:36  lr: 0.000200  loss: 6.9905 (3.0440)  loss_n_40: 1.5612 (0.6790)  loss_n_60: 1.6748 (0.6928)  loss_n_80: 1.7642 (0.7519)  loss_n_100: 1.9663 (0.7979)  triple_100: 0.0000 (0.0340)  triple_80: 0.0000 (0.0362)  triple_60: 0.0000 (0.0276)  triple_40: 0.0000 (0.0246)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1250/1724]  eta: 0:30:57  lr: 0.000200  loss: 6.9138 (3.0722)  loss_n_40: 1.5612 (0.6856)  loss_n_60: 1.6424 (0.6998)  loss_n_80: 1.7201 (0.7590)  loss_n_100: 1.9149 (0.8063)  triple_100: 0.0000 (0.0338)  triple_80: 0.0000 (0.0359)  triple_60: 0.0000 (0.0274)  triple_40: 0.0000 (0.0244)  time: 3.9214  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1260/1724]  eta: 0:30:18  lr: 0.000200  loss: 6.5288 (3.0982)  loss_n_40: 1.5110 (0.6917)  loss_n_60: 1.5627 (0.7063)  loss_n_80: 1.6161 (0.7657)  loss_n_100: 1.8389 (0.8140)  triple_100: 0.0000 (0.0335)  triple_80: 0.0000 (0.0356)  triple_60: 0.0000 (0.0271)  triple_40: 0.0000 (0.0242)  time: 3.9222  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1270/1724]  eta: 0:29:39  lr: 0.000200  loss: 6.0437 (3.1202)  loss_n_40: 1.3696 (0.6969)  loss_n_60: 1.4332 (0.7119)  loss_n_80: 1.5025 (0.7714)  loss_n_100: 1.7131 (0.8204)  triple_100: 0.0000 (0.0332)  triple_80: 0.0000 (0.0354)  triple_60: 0.0000 (0.0269)  triple_40: 0.0000 (0.0240)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1280/1724]  eta: 0:28:59  lr: 0.000200  loss: 5.4978 (3.1381)  loss_n_40: 1.2841 (0.7012)  loss_n_60: 1.2928 (0.7164)  loss_n_80: 1.3415 (0.7759)  loss_n_100: 1.5829 (0.8261)  triple_100: 0.0000 (0.0330)  triple_80: 0.0000 (0.0351)  triple_60: 0.0000 (0.0267)  triple_40: 0.0000 (0.0238)  time: 3.9218  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1290/1724]  eta: 0:28:20  lr: 0.000200  loss: 5.2089 (3.1529)  loss_n_40: 1.2069 (0.7048)  loss_n_60: 1.2130 (0.7201)  loss_n_80: 1.2714 (0.7796)  loss_n_100: 1.4753 (0.8307)  triple_100: 0.0000 (0.0327)  triple_80: 0.0000 (0.0348)  triple_60: 0.0000 (0.0265)  triple_40: 0.0000 (0.0236)  time: 3.9211  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1300/1724]  eta: 0:27:41  lr: 0.000200  loss: 4.7554 (3.1658)  loss_n_40: 1.1131 (0.7078)  loss_n_60: 1.1121 (0.7234)  loss_n_80: 1.1776 (0.7829)  loss_n_100: 1.3526 (0.8349)  triple_100: 0.0000 (0.0325)  triple_80: 0.0000 (0.0346)  triple_60: 0.0000 (0.0263)  triple_40: 0.0000 (0.0234)  time: 3.9194  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [1310/1724]  eta: 0:27:02  lr: 0.000200  loss: 4.9976 (3.1804)  loss_n_40: 1.1297 (0.7113)  loss_n_60: 1.1927 (0.7272)  loss_n_80: 1.2482 (0.7867)  loss_n_100: 1.4068 (0.8394)  triple_100: 0.0000 (0.0322)  triple_80: 0.0000 (0.0343)  triple_60: 0.0000 (0.0261)  triple_40: 0.0000 (0.0232)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1320/1724]  eta: 0:26:23  lr: 0.000200  loss: 4.9976 (3.1930)  loss_n_40: 1.1297 (0.7143)  loss_n_60: 1.1927 (0.7304)  loss_n_80: 1.2321 (0.7899)  loss_n_100: 1.3745 (0.8434)  triple_100: 0.0000 (0.0320)  triple_80: 0.0000 (0.0340)  triple_60: 0.0000 (0.0259)  triple_40: 0.0000 (0.0231)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1330/1724]  eta: 0:25:44  lr: 0.000200  loss: 4.7040 (3.2053)  loss_n_40: 1.0202 (0.7165)  loss_n_60: 1.1220 (0.7331)  loss_n_80: 1.2104 (0.7931)  loss_n_100: 1.3650 (0.8480)  triple_100: 0.0000 (0.0317)  triple_80: 0.0000 (0.0338)  triple_60: 0.0000 (0.0257)  triple_40: 0.0000 (0.0233)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1340/1724]  eta: 0:25:04  lr: 0.000200  loss: 4.8072 (3.2205)  loss_n_40: 0.9854 (0.7192)  loss_n_60: 1.1149 (0.7363)  loss_n_80: 1.2294 (0.7968)  loss_n_100: 1.4802 (0.8527)  triple_100: 0.0000 (0.0315)  triple_80: 0.0000 (0.0341)  triple_60: 0.0000 (0.0268)  triple_40: 0.0000 (0.0231)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1350/1724]  eta: 0:24:25  lr: 0.000200  loss: 4.8072 (3.2320)  loss_n_40: 1.0489 (0.7217)  loss_n_60: 1.1149 (0.7391)  loss_n_80: 1.2430 (0.8000)  loss_n_100: 1.3830 (0.8565)  triple_100: 0.0000 (0.0313)  triple_80: 0.0000 (0.0338)  triple_60: 0.0000 (0.0266)  triple_40: 0.0000 (0.0230)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1360/1724]  eta: 0:23:46  lr: 0.000200  loss: 4.5334 (3.2437)  loss_n_40: 1.0164 (0.7241)  loss_n_60: 1.0604 (0.7417)  loss_n_80: 1.1533 (0.8028)  loss_n_100: 1.2834 (0.8599)  triple_100: 0.0000 (0.0310)  triple_80: 0.0000 (0.0336)  triple_60: 0.0000 (0.0264)  triple_40: 0.0000 (0.0243)  time: 3.9209  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1370/1724]  eta: 0:23:07  lr: 0.000200  loss: 4.2092 (3.2496)  loss_n_40: 0.9621 (0.7255)  loss_n_60: 1.0100 (0.7433)  loss_n_80: 1.0906 (0.8045)  loss_n_100: 1.2093 (0.8618)  triple_100: 0.0000 (0.0308)  triple_80: 0.0000 (0.0333)  triple_60: 0.0000 (0.0262)  triple_40: 0.0000 (0.0241)  time: 3.9206  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1380/1724]  eta: 0:22:28  lr: 0.000200  loss: 3.8411 (3.2541)  loss_n_40: 0.8614 (0.7265)  loss_n_60: 0.8999 (0.7446)  loss_n_80: 1.0129 (0.8060)  loss_n_100: 1.0859 (0.8632)  triple_100: 0.0000 (0.0306)  triple_80: 0.0000 (0.0333)  triple_60: 0.0000 (0.0260)  triple_40: 0.0000 (0.0239)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1390/1724]  eta: 0:21:48  lr: 0.000200  loss: 3.6529 (3.2567)  loss_n_40: 0.8349 (0.7272)  loss_n_60: 0.8729 (0.7454)  loss_n_80: 0.9630 (0.8069)  loss_n_100: 1.0068 (0.8641)  triple_100: 0.0000 (0.0304)  triple_80: 0.0000 (0.0331)  triple_60: 0.0000 (0.0259)  triple_40: 0.0000 (0.0237)  time: 3.9213  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1400/1724]  eta: 0:21:09  lr: 0.000200  loss: 3.3928 (3.2588)  loss_n_40: 0.7814 (0.7277)  loss_n_60: 0.8206 (0.7459)  loss_n_80: 0.8976 (0.8076)  loss_n_100: 0.9267 (0.8647)  triple_100: 0.0000 (0.0302)  triple_80: 0.0000 (0.0335)  triple_60: 0.0000 (0.0257)  triple_40: 0.0000 (0.0236)  time: 3.9205  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1410/1724]  eta: 0:20:30  lr: 0.000200  loss: 3.3786 (3.2602)  loss_n_40: 0.7685 (0.7282)  loss_n_60: 0.8068 (0.7464)  loss_n_80: 0.8677 (0.8081)  loss_n_100: 0.9238 (0.8653)  triple_100: 0.0000 (0.0299)  triple_80: 0.0000 (0.0333)  triple_60: 0.0000 (0.0255)  triple_40: 0.0000 (0.0234)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1420/1724]  eta: 0:19:51  lr: 0.000200  loss: 3.5055 (3.2659)  loss_n_40: 0.7732 (0.7290)  loss_n_60: 0.8187 (0.7473)  loss_n_80: 0.8981 (0.8095)  loss_n_100: 0.9686 (0.8669)  triple_100: 0.0000 (0.0315)  triple_80: 0.0000 (0.0332)  triple_60: 0.0000 (0.0253)  triple_40: 0.0000 (0.0232)  time: 3.9198  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1430/1724]  eta: 0:19:12  lr: 0.000200  loss: 4.1954 (3.2742)  loss_n_40: 0.8303 (0.7305)  loss_n_60: 0.8860 (0.7493)  loss_n_80: 1.0609 (0.8121)  loss_n_100: 1.1445 (0.8698)  triple_100: 0.0000 (0.0313)  triple_80: 0.0000 (0.0330)  triple_60: 0.0000 (0.0251)  triple_40: 0.0000 (0.0231)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1440/1724]  eta: 0:18:32  lr: 0.000200  loss: 4.2863 (3.2808)  loss_n_40: 0.9671 (0.7322)  loss_n_60: 1.0126 (0.7510)  loss_n_80: 1.1112 (0.8140)  loss_n_100: 1.1667 (0.8718)  triple_100: 0.0000 (0.0311)  triple_80: 0.0000 (0.0328)  triple_60: 0.0000 (0.0250)  triple_40: 0.0000 (0.0229)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1450/1724]  eta: 0:17:53  lr: 0.000200  loss: 3.7142 (3.2817)  loss_n_40: 0.8334 (0.7327)  loss_n_60: 0.8494 (0.7513)  loss_n_80: 0.9722 (0.8145)  loss_n_100: 1.0121 (0.8721)  triple_100: 0.0000 (0.0309)  triple_80: 0.0000 (0.0325)  triple_60: 0.0000 (0.0248)  triple_40: 0.0000 (0.0228)  time: 3.9211  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1460/1724]  eta: 0:17:14  lr: 0.000200  loss: 3.3223 (3.2842)  loss_n_40: 0.8068 (0.7330)  loss_n_60: 0.7941 (0.7519)  loss_n_80: 0.8676 (0.8155)  loss_n_100: 0.8706 (0.8731)  triple_100: 0.0000 (0.0311)  triple_80: 0.0000 (0.0323)  triple_60: 0.0000 (0.0246)  triple_40: 0.0000 (0.0226)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1470/1724]  eta: 0:16:35  lr: 0.000200  loss: 3.3122 (3.2845)  loss_n_40: 0.7126 (0.7329)  loss_n_60: 0.7616 (0.7520)  loss_n_80: 0.8593 (0.8160)  loss_n_100: 0.9473 (0.8737)  triple_100: 0.0000 (0.0309)  triple_80: 0.0000 (0.0321)  triple_60: 0.0000 (0.0244)  triple_40: 0.0000 (0.0224)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1480/1724]  eta: 0:15:56  lr: 0.000200  loss: 3.2282 (3.2849)  loss_n_40: 0.7147 (0.7332)  loss_n_60: 0.7496 (0.7522)  loss_n_80: 0.8494 (0.8163)  loss_n_100: 0.9280 (0.8739)  triple_100: 0.0000 (0.0307)  triple_80: 0.0000 (0.0319)  triple_60: 0.0000 (0.0243)  triple_40: 0.0000 (0.0223)  time: 3.9206  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1490/1724]  eta: 0:15:17  lr: 0.000200  loss: 3.0576 (3.2830)  loss_n_40: 0.7282 (0.7331)  loss_n_60: 0.7264 (0.7520)  loss_n_80: 0.7904 (0.8160)  loss_n_100: 0.8378 (0.8735)  triple_100: 0.0000 (0.0305)  triple_80: 0.0000 (0.0317)  triple_60: 0.0000 (0.0241)  triple_40: 0.0000 (0.0221)  time: 3.9205  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1500/1724]  eta: 0:14:37  lr: 0.000200  loss: 2.8378 (3.2812)  loss_n_40: 0.7119 (0.7331)  loss_n_60: 0.6912 (0.7517)  loss_n_80: 0.7190 (0.8157)  loss_n_100: 0.7654 (0.8729)  triple_100: 0.0000 (0.0303)  triple_80: 0.0000 (0.0315)  triple_60: 0.0000 (0.0240)  triple_40: 0.0000 (0.0220)  time: 3.9196  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1510/1724]  eta: 0:13:58  lr: 0.000200  loss: 2.6201 (3.2763)  loss_n_40: 0.6171 (0.7323)  loss_n_60: 0.6249 (0.7508)  loss_n_80: 0.6760 (0.8146)  loss_n_100: 0.6990 (0.8716)  triple_100: 0.0000 (0.0301)  triple_80: 0.0000 (0.0312)  triple_60: 0.0000 (0.0238)  triple_40: 0.0000 (0.0218)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1520/1724]  eta: 0:13:19  lr: 0.000200  loss: 2.5012 (3.2711)  loss_n_40: 0.5868 (0.7315)  loss_n_60: 0.6040 (0.7498)  loss_n_80: 0.6385 (0.8134)  loss_n_100: 0.6630 (0.8702)  triple_100: 0.0000 (0.0299)  triple_80: 0.0000 (0.0310)  triple_60: 0.0000 (0.0236)  triple_40: 0.0000 (0.0217)  time: 3.9205  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1530/1724]  eta: 0:12:40  lr: 0.000200  loss: 2.1897 (3.2638)  loss_n_40: 0.5296 (0.7300)  loss_n_60: 0.5208 (0.7482)  loss_n_80: 0.5548 (0.8117)  loss_n_100: 0.5943 (0.8683)  triple_100: 0.0000 (0.0297)  triple_80: 0.0000 (0.0308)  triple_60: 0.0000 (0.0235)  triple_40: 0.0000 (0.0216)  time: 3.9195  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1540/1724]  eta: 0:12:01  lr: 0.000200  loss: 2.3468 (3.2777)  loss_n_40: 0.5515 (0.7299)  loss_n_60: 0.5678 (0.7484)  loss_n_80: 0.6076 (0.8125)  loss_n_100: 0.6455 (0.8695)  triple_100: 0.0000 (0.0389)  triple_80: 0.0000 (0.0333)  triple_60: 0.0000 (0.0237)  triple_40: 0.0000 (0.0214)  time: 3.9159  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [1550/1724]  eta: 0:11:21  lr: 0.000200  loss: 4.6124 (3.2888)  loss_n_40: 0.9171 (0.7318)  loss_n_60: 0.9812 (0.7508)  loss_n_80: 1.2549 (0.8162)  loss_n_100: 1.3280 (0.8735)  triple_100: 0.0000 (0.0386)  triple_80: 0.0000 (0.0330)  triple_60: 0.0000 (0.0235)  triple_40: 0.0000 (0.0213)  time: 3.9155  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1560/1724]  eta: 0:10:42  lr: 0.000200  loss: 4.4622 (3.2947)  loss_n_40: 0.9752 (0.7333)  loss_n_60: 0.9838 (0.7520)  loss_n_80: 1.1722 (0.8180)  loss_n_100: 1.3224 (0.8756)  triple_100: 0.0000 (0.0384)  triple_80: 0.0000 (0.0328)  triple_60: 0.0000 (0.0234)  triple_40: 0.0000 (0.0211)  time: 3.9177  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1570/1724]  eta: 0:10:03  lr: 0.000200  loss: 3.8285 (3.2970)  loss_n_40: 0.8786 (0.7339)  loss_n_60: 0.8613 (0.7524)  loss_n_80: 1.0360 (0.8190)  loss_n_100: 1.1244 (0.8767)  triple_100: 0.0000 (0.0381)  triple_80: 0.0000 (0.0326)  triple_60: 0.0000 (0.0232)  triple_40: 0.0000 (0.0210)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1580/1724]  eta: 0:09:24  lr: 0.000200  loss: 3.4673 (3.2972)  loss_n_40: 0.7986 (0.7341)  loss_n_60: 0.7909 (0.7525)  loss_n_80: 0.9225 (0.8194)  loss_n_100: 0.9682 (0.8769)  triple_100: 0.0000 (0.0379)  triple_80: 0.0000 (0.0324)  triple_60: 0.0000 (0.0231)  triple_40: 0.0000 (0.0209)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1590/1724]  eta: 0:08:45  lr: 0.000200  loss: 3.1742 (3.2949)  loss_n_40: 0.7212 (0.7335)  loss_n_60: 0.7131 (0.7520)  loss_n_80: 0.8194 (0.8191)  loss_n_100: 0.8705 (0.8767)  triple_100: 0.0000 (0.0377)  triple_80: 0.0000 (0.0322)  triple_60: 0.0000 (0.0230)  triple_40: 0.0000 (0.0208)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1600/1724]  eta: 0:08:05  lr: 0.000200  loss: 2.8349 (3.2923)  loss_n_40: 0.6642 (0.7332)  loss_n_60: 0.6598 (0.7515)  loss_n_80: 0.7475 (0.8187)  loss_n_100: 0.7958 (0.8760)  triple_100: 0.0000 (0.0374)  triple_80: 0.0000 (0.0320)  triple_60: 0.0000 (0.0228)  triple_40: 0.0000 (0.0206)  time: 3.9181  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1610/1724]  eta: 0:07:26  lr: 0.000200  loss: 2.7787 (3.2889)  loss_n_40: 0.6053 (0.7326)  loss_n_60: 0.6565 (0.7508)  loss_n_80: 0.7199 (0.8181)  loss_n_100: 0.7445 (0.8752)  triple_100: 0.0000 (0.0372)  triple_80: 0.0000 (0.0318)  triple_60: 0.0000 (0.0227)  triple_40: 0.0000 (0.0205)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1620/1724]  eta: 0:06:47  lr: 0.000200  loss: 2.6137 (3.2844)  loss_n_40: 0.5903 (0.7318)  loss_n_60: 0.5950 (0.7499)  loss_n_80: 0.6880 (0.8172)  loss_n_100: 0.6912 (0.8740)  triple_100: 0.0000 (0.0370)  triple_80: 0.0000 (0.0316)  triple_60: 0.0000 (0.0225)  triple_40: 0.0000 (0.0204)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1630/1724]  eta: 0:06:08  lr: 0.000200  loss: 2.4225 (3.2793)  loss_n_40: 0.5744 (0.7310)  loss_n_60: 0.5751 (0.7489)  loss_n_80: 0.6335 (0.8160)  loss_n_100: 0.6467 (0.8725)  triple_100: 0.0000 (0.0367)  triple_80: 0.0000 (0.0314)  triple_60: 0.0000 (0.0224)  triple_40: 0.0000 (0.0202)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1640/1724]  eta: 0:05:29  lr: 0.000200  loss: 2.2097 (3.2729)  loss_n_40: 0.5039 (0.7297)  loss_n_60: 0.5360 (0.7477)  loss_n_80: 0.5744 (0.8146)  loss_n_100: 0.5770 (0.8709)  triple_100: 0.0000 (0.0365)  triple_80: 0.0000 (0.0312)  triple_60: 0.0000 (0.0223)  triple_40: 0.0000 (0.0201)  time: 3.9198  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1650/1724]  eta: 0:04:50  lr: 0.000200  loss: 2.2257 (3.2664)  loss_n_40: 0.4967 (0.7285)  loss_n_60: 0.5236 (0.7463)  loss_n_80: 0.5833 (0.8131)  loss_n_100: 0.5871 (0.8691)  triple_100: 0.0000 (0.0363)  triple_80: 0.0000 (0.0310)  triple_60: 0.0000 (0.0221)  triple_40: 0.0000 (0.0200)  time: 3.9201  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1660/1724]  eta: 0:04:10  lr: 0.000200  loss: 2.0208 (3.2589)  loss_n_40: 0.4689 (0.7270)  loss_n_60: 0.4768 (0.7447)  loss_n_80: 0.5290 (0.8113)  loss_n_100: 0.5428 (0.8670)  triple_100: 0.0000 (0.0361)  triple_80: 0.0000 (0.0309)  triple_60: 0.0000 (0.0220)  triple_40: 0.0000 (0.0199)  time: 3.9196  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1670/1724]  eta: 0:03:31  lr: 0.000200  loss: 2.0208 (3.2523)  loss_n_40: 0.4625 (0.7256)  loss_n_60: 0.4768 (0.7432)  loss_n_80: 0.5280 (0.8097)  loss_n_100: 0.5351 (0.8651)  triple_100: 0.0000 (0.0359)  triple_80: 0.0000 (0.0309)  triple_60: 0.0000 (0.0219)  triple_40: 0.0000 (0.0201)  time: 3.9193  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1680/1724]  eta: 0:02:52  lr: 0.000200  loss: 2.5430 (3.2492)  loss_n_40: 0.4741 (0.7243)  loss_n_60: 0.5533 (0.7426)  loss_n_80: 0.6258 (0.8092)  loss_n_100: 0.6293 (0.8650)  triple_100: 0.0000 (0.0356)  triple_80: 0.0000 (0.0307)  triple_60: 0.0000 (0.0217)  triple_40: 0.0000 (0.0199)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1690/1724]  eta: 0:02:13  lr: 0.000200  loss: 2.6342 (3.2503)  loss_n_40: 0.4877 (0.7231)  loss_n_60: 0.6403 (0.7423)  loss_n_80: 0.7002 (0.8086)  loss_n_100: 0.7815 (0.8643)  triple_100: 0.0000 (0.0354)  triple_80: 0.0000 (0.0336)  triple_60: 0.0000 (0.0231)  triple_40: 0.0000 (0.0198)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1700/1724]  eta: 0:01:34  lr: 0.000200  loss: 3.6048 (3.2742)  loss_n_40: 0.6708 (0.7238)  loss_n_60: 0.8262 (0.7451)  loss_n_80: 0.8823 (0.8132)  loss_n_100: 0.9120 (0.8703)  triple_100: 0.0000 (0.0362)  triple_80: 0.0000 (0.0371)  triple_60: 0.0000 (0.0261)  triple_40: 0.0000 (0.0223)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:14]  [1710/1724]  eta: 0:00:54  lr: 0.000200  loss: 6.3474 (3.2939)  loss_n_40: 0.8669 (0.7250)  loss_n_60: 1.3030 (0.7488)  loss_n_80: 1.8277 (0.8194)  loss_n_100: 2.2833 (0.8788)  triple_100: 0.0000 (0.0360)  triple_80: 0.0000 (0.0375)  triple_60: 0.0000 (0.0260)  triple_40: 0.0000 (0.0222)  time: 3.9171  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1720/1724]  eta: 0:00:15  lr: 0.000200  loss: 6.0712 (3.3060)  loss_n_40: 0.8974 (0.7262)  loss_n_60: 1.2689 (0.7512)  loss_n_80: 1.6804 (0.8234)  loss_n_100: 2.1652 (0.8842)  triple_100: 0.0000 (0.0358)  triple_80: 0.0000 (0.0373)  triple_60: 0.0000 (0.0258)  triple_40: 0.0000 (0.0221)  time: 3.9165  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14]  [1723/1724]  eta: 0:00:03  lr: 0.000200  loss: 5.4780 (3.3086)  loss_n_40: 0.8974 (0.7263)  loss_n_60: 1.1959 (0.7517)  loss_n_80: 1.5592 (0.8243)  loss_n_100: 1.8049 (0.8855)  triple_100: 0.0000 (0.0358)  triple_80: 0.0000 (0.0372)  triple_60: 0.0000 (0.0258)  triple_40: 0.0000 (0.0221)  time: 3.9170  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:14] Total time: 1:52:36 (3.9191 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 5.4780 (3.3086)  loss_n_40: 0.8974 (0.7263)  loss_n_60: 1.1959 (0.7517)  loss_n_80: 1.5592 (0.8243)  loss_n_100: 1.8049 (0.8855)  triple_100: 0.0000 (0.0358)  triple_80: 0.0000 (0.0372)  triple_60: 0.0000 (0.0258)  triple_40: 0.0000 (0.0221)\n",
      "Valid: [epoch:14]  [  0/845]  eta: 0:09:47  loss: 3.8825 (3.8825)  loss_n_40: 0.7315 (0.7315)  loss_n_60: 0.9611 (0.9611)  loss_n_80: 1.0389 (1.0389)  loss_n_100: 1.1510 (1.1510)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.6953  data: 0.3615  max mem: 46473\n",
      "Valid: [epoch:14]  [ 10/845]  eta: 0:05:06  loss: 3.8825 (4.1526)  loss_n_40: 0.7426 (0.8269)  loss_n_60: 0.8778 (0.9181)  loss_n_80: 1.0575 (1.1084)  loss_n_100: 1.2730 (1.2991)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3667  data: 0.0330  max mem: 46473\n",
      "Valid: [epoch:14]  [ 20/845]  eta: 0:04:49  loss: 4.1759 (4.4002)  loss_n_40: 0.7575 (0.8561)  loss_n_60: 0.8778 (0.9683)  loss_n_80: 1.1747 (1.1845)  loss_n_100: 1.3773 (1.3913)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [ 30/845]  eta: 0:04:41  loss: 4.3240 (4.3335)  loss_n_40: 0.7949 (0.8286)  loss_n_60: 0.9051 (0.9432)  loss_n_80: 1.2019 (1.1689)  loss_n_100: 1.4466 (1.3928)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:14]  [ 40/845]  eta: 0:04:35  loss: 4.3240 (4.4342)  loss_n_40: 0.8055 (0.8659)  loss_n_60: 0.9530 (0.9833)  loss_n_80: 1.2019 (1.1860)  loss_n_100: 1.4466 (1.3990)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [ 50/845]  eta: 0:04:31  loss: 4.3656 (4.4440)  loss_n_40: 0.8002 (0.8717)  loss_n_60: 0.9758 (0.9870)  loss_n_80: 1.1288 (1.1860)  loss_n_100: 1.4206 (1.3992)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [ 60/845]  eta: 0:04:26  loss: 4.1988 (4.4442)  loss_n_40: 0.7768 (0.8569)  loss_n_60: 0.9338 (0.9757)  loss_n_80: 1.1259 (1.1936)  loss_n_100: 1.4206 (1.4179)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [ 70/845]  eta: 0:04:22  loss: 4.0842 (4.4090)  loss_n_40: 0.7340 (0.8472)  loss_n_60: 0.8988 (0.9685)  loss_n_80: 1.1089 (1.1835)  loss_n_100: 1.3701 (1.4099)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [ 80/845]  eta: 0:04:18  loss: 4.0076 (4.4114)  loss_n_40: 0.7275 (0.8495)  loss_n_60: 0.8988 (0.9725)  loss_n_80: 1.0758 (1.1831)  loss_n_100: 1.2998 (1.4064)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [ 90/845]  eta: 0:04:15  loss: 4.0771 (4.4248)  loss_n_40: 0.7344 (0.8416)  loss_n_60: 0.9030 (0.9736)  loss_n_80: 1.1242 (1.1923)  loss_n_100: 1.3357 (1.4174)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [100/845]  eta: 0:04:11  loss: 4.2110 (4.4572)  loss_n_40: 0.7709 (0.8463)  loss_n_60: 0.9136 (0.9824)  loss_n_80: 1.1457 (1.2011)  loss_n_100: 1.3864 (1.4273)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [110/845]  eta: 0:04:07  loss: 4.2110 (4.4550)  loss_n_40: 0.8109 (0.8413)  loss_n_60: 0.9136 (0.9798)  loss_n_80: 1.1527 (1.2023)  loss_n_100: 1.4040 (1.4317)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [120/845]  eta: 0:04:04  loss: 4.0539 (4.4348)  loss_n_40: 0.7380 (0.8399)  loss_n_60: 0.8669 (0.9744)  loss_n_80: 1.1009 (1.1963)  loss_n_100: 1.3678 (1.4242)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [130/845]  eta: 0:04:00  loss: 4.0382 (4.4360)  loss_n_40: 0.7155 (0.8399)  loss_n_60: 0.8679 (0.9745)  loss_n_80: 1.0871 (1.1974)  loss_n_100: 1.3116 (1.4242)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [140/845]  eta: 0:03:57  loss: 4.7021 (4.4619)  loss_n_40: 0.7910 (0.8436)  loss_n_60: 0.9916 (0.9798)  loss_n_80: 1.2459 (1.2054)  loss_n_100: 1.3929 (1.4331)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [150/845]  eta: 0:03:53  loss: 4.7021 (4.4716)  loss_n_40: 0.7831 (0.8440)  loss_n_60: 0.9916 (0.9817)  loss_n_80: 1.2674 (1.2093)  loss_n_100: 1.4365 (1.4367)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [160/845]  eta: 0:03:50  loss: 4.0610 (4.4586)  loss_n_40: 0.7462 (0.8389)  loss_n_60: 0.9249 (0.9790)  loss_n_80: 1.1272 (1.2070)  loss_n_100: 1.3410 (1.4338)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [170/845]  eta: 0:03:46  loss: 4.0660 (4.4839)  loss_n_40: 0.7696 (0.8452)  loss_n_60: 0.9664 (0.9863)  loss_n_80: 1.1353 (1.2132)  loss_n_100: 1.3455 (1.4392)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [180/845]  eta: 0:03:43  loss: 4.2917 (4.4708)  loss_n_40: 0.8316 (0.8397)  loss_n_60: 0.9676 (0.9819)  loss_n_80: 1.1235 (1.2113)  loss_n_100: 1.3749 (1.4379)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [190/845]  eta: 0:03:40  loss: 3.9904 (4.4689)  loss_n_40: 0.7297 (0.8397)  loss_n_60: 0.8962 (0.9813)  loss_n_80: 1.1205 (1.2110)  loss_n_100: 1.3640 (1.4368)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [200/845]  eta: 0:03:36  loss: 4.2343 (4.4654)  loss_n_40: 0.7345 (0.8359)  loss_n_60: 0.9025 (0.9797)  loss_n_80: 1.1603 (1.2112)  loss_n_100: 1.4103 (1.4387)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [210/845]  eta: 0:03:33  loss: 4.0926 (4.4668)  loss_n_40: 0.7964 (0.8381)  loss_n_60: 0.9207 (0.9802)  loss_n_80: 1.1603 (1.2108)  loss_n_100: 1.3750 (1.4377)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [220/845]  eta: 0:03:29  loss: 4.0828 (4.4616)  loss_n_40: 0.8134 (0.8356)  loss_n_60: 0.9047 (0.9789)  loss_n_80: 1.2056 (1.2093)  loss_n_100: 1.3512 (1.4378)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [230/845]  eta: 0:03:26  loss: 4.5226 (4.4722)  loss_n_40: 0.7783 (0.8380)  loss_n_60: 0.9363 (0.9817)  loss_n_80: 1.2817 (1.2126)  loss_n_100: 1.4373 (1.4399)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [240/845]  eta: 0:03:23  loss: 4.2792 (4.4761)  loss_n_40: 0.7706 (0.8361)  loss_n_60: 0.9363 (0.9819)  loss_n_80: 1.1789 (1.2147)  loss_n_100: 1.4078 (1.4434)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [250/845]  eta: 0:03:19  loss: 4.1297 (4.4716)  loss_n_40: 0.7538 (0.8341)  loss_n_60: 0.8949 (0.9798)  loss_n_80: 1.1517 (1.2141)  loss_n_100: 1.4078 (1.4436)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [260/845]  eta: 0:03:16  loss: 4.0564 (4.4728)  loss_n_40: 0.7538 (0.8376)  loss_n_60: 0.8933 (0.9811)  loss_n_80: 1.0976 (1.2125)  loss_n_100: 1.3548 (1.4416)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [270/845]  eta: 0:03:12  loss: 4.0076 (4.4624)  loss_n_40: 0.7262 (0.8363)  loss_n_60: 0.8689 (0.9792)  loss_n_80: 1.0842 (1.2089)  loss_n_100: 1.3548 (1.4380)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [280/845]  eta: 0:03:09  loss: 4.0020 (4.4548)  loss_n_40: 0.7383 (0.8332)  loss_n_60: 0.8931 (0.9777)  loss_n_80: 1.1262 (1.2075)  loss_n_100: 1.3819 (1.4364)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:14]  [290/845]  eta: 0:03:06  loss: 4.0937 (4.4500)  loss_n_40: 0.7711 (0.8322)  loss_n_60: 0.8817 (0.9760)  loss_n_80: 1.1274 (1.2057)  loss_n_100: 1.3916 (1.4361)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [300/845]  eta: 0:03:02  loss: 4.0937 (4.4472)  loss_n_40: 0.7970 (0.8314)  loss_n_60: 0.9292 (0.9760)  loss_n_80: 1.1274 (1.2044)  loss_n_100: 1.3916 (1.4354)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [310/845]  eta: 0:02:59  loss: 4.5635 (4.4640)  loss_n_40: 0.7970 (0.8373)  loss_n_60: 0.9634 (0.9805)  loss_n_80: 1.2283 (1.2079)  loss_n_100: 1.4880 (1.4382)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [320/845]  eta: 0:02:56  loss: 4.4009 (4.4578)  loss_n_40: 0.7729 (0.8350)  loss_n_60: 0.9357 (0.9789)  loss_n_80: 1.2219 (1.2068)  loss_n_100: 1.4179 (1.4371)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [330/845]  eta: 0:02:52  loss: 4.1307 (4.4629)  loss_n_40: 0.7298 (0.8355)  loss_n_60: 0.8266 (0.9794)  loss_n_80: 1.1475 (1.2091)  loss_n_100: 1.4055 (1.4389)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [340/845]  eta: 0:02:49  loss: 4.2026 (4.4689)  loss_n_40: 0.7720 (0.8359)  loss_n_60: 0.9623 (0.9808)  loss_n_80: 1.2223 (1.2113)  loss_n_100: 1.4815 (1.4410)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [350/845]  eta: 0:02:45  loss: 4.2845 (4.4606)  loss_n_40: 0.7752 (0.8334)  loss_n_60: 0.9623 (0.9790)  loss_n_80: 1.2009 (1.2093)  loss_n_100: 1.4278 (1.4390)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [360/845]  eta: 0:02:42  loss: 4.0516 (4.4602)  loss_n_40: 0.7507 (0.8339)  loss_n_60: 0.8795 (0.9789)  loss_n_80: 1.1215 (1.2088)  loss_n_100: 1.3715 (1.4386)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [370/845]  eta: 0:02:39  loss: 4.1282 (4.4618)  loss_n_40: 0.7572 (0.8326)  loss_n_60: 0.8519 (0.9779)  loss_n_80: 1.1641 (1.2102)  loss_n_100: 1.4360 (1.4411)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [380/845]  eta: 0:02:35  loss: 4.1282 (4.4619)  loss_n_40: 0.7349 (0.8312)  loss_n_60: 0.8914 (0.9774)  loss_n_80: 1.1641 (1.2108)  loss_n_100: 1.3985 (1.4425)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [390/845]  eta: 0:02:32  loss: 4.0328 (4.4542)  loss_n_40: 0.7277 (0.8283)  loss_n_60: 0.8835 (0.9755)  loss_n_80: 1.0958 (1.2095)  loss_n_100: 1.3596 (1.4409)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [400/845]  eta: 0:02:29  loss: 4.1160 (4.4589)  loss_n_40: 0.7400 (0.8306)  loss_n_60: 0.8959 (0.9770)  loss_n_80: 1.1536 (1.2103)  loss_n_100: 1.3450 (1.4410)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [410/845]  eta: 0:02:25  loss: 4.2646 (4.4553)  loss_n_40: 0.7819 (0.8302)  loss_n_60: 0.8959 (0.9759)  loss_n_80: 1.1575 (1.2093)  loss_n_100: 1.4151 (1.4400)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [420/845]  eta: 0:02:22  loss: 4.2646 (4.4599)  loss_n_40: 0.7884 (0.8335)  loss_n_60: 0.9121 (0.9779)  loss_n_80: 1.2063 (1.2094)  loss_n_100: 1.3540 (1.4391)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [430/845]  eta: 0:02:19  loss: 4.0066 (4.4501)  loss_n_40: 0.7503 (0.8307)  loss_n_60: 0.8550 (0.9752)  loss_n_80: 1.0739 (1.2072)  loss_n_100: 1.2940 (1.4370)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [440/845]  eta: 0:02:15  loss: 4.0532 (4.4515)  loss_n_40: 0.7119 (0.8311)  loss_n_60: 0.8581 (0.9756)  loss_n_80: 1.1046 (1.2076)  loss_n_100: 1.3342 (1.4372)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [450/845]  eta: 0:02:12  loss: 4.0532 (4.4494)  loss_n_40: 0.7283 (0.8312)  loss_n_60: 0.8690 (0.9749)  loss_n_80: 1.1070 (1.2069)  loss_n_100: 1.3473 (1.4365)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [460/845]  eta: 0:02:08  loss: 4.0474 (4.4440)  loss_n_40: 0.7283 (0.8294)  loss_n_60: 0.8552 (0.9738)  loss_n_80: 1.0919 (1.2056)  loss_n_100: 1.3471 (1.4352)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [470/845]  eta: 0:02:05  loss: 4.1371 (4.4439)  loss_n_40: 0.7541 (0.8283)  loss_n_60: 0.9030 (0.9735)  loss_n_80: 1.0994 (1.2055)  loss_n_100: 1.4265 (1.4366)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [480/845]  eta: 0:02:02  loss: 4.4735 (4.4486)  loss_n_40: 0.8050 (0.8282)  loss_n_60: 1.0289 (0.9749)  loss_n_80: 1.2284 (1.2069)  loss_n_100: 1.4717 (1.4385)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [490/845]  eta: 0:01:58  loss: 4.2568 (4.4414)  loss_n_40: 0.7929 (0.8272)  loss_n_60: 1.0289 (0.9736)  loss_n_80: 1.1209 (1.2046)  loss_n_100: 1.3563 (1.4360)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [500/845]  eta: 0:01:55  loss: 4.0308 (4.4429)  loss_n_40: 0.7719 (0.8265)  loss_n_60: 0.8679 (0.9734)  loss_n_80: 1.0862 (1.2056)  loss_n_100: 1.3396 (1.4375)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [510/845]  eta: 0:01:52  loss: 4.2609 (4.4452)  loss_n_40: 0.7891 (0.8258)  loss_n_60: 0.9363 (0.9737)  loss_n_80: 1.1647 (1.2068)  loss_n_100: 1.4571 (1.4389)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [520/845]  eta: 0:01:48  loss: 4.2609 (4.4435)  loss_n_40: 0.7701 (0.8255)  loss_n_60: 0.9128 (0.9731)  loss_n_80: 1.1647 (1.2064)  loss_n_100: 1.4134 (1.4385)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [530/845]  eta: 0:01:45  loss: 4.2695 (4.4446)  loss_n_40: 0.7667 (0.8258)  loss_n_60: 0.8726 (0.9729)  loss_n_80: 1.1928 (1.2066)  loss_n_100: 1.4134 (1.4394)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:14]  [540/845]  eta: 0:01:42  loss: 4.4335 (4.4460)  loss_n_40: 0.7860 (0.8262)  loss_n_60: 0.9911 (0.9730)  loss_n_80: 1.1928 (1.2070)  loss_n_100: 1.4637 (1.4398)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [550/845]  eta: 0:01:38  loss: 4.3689 (4.4468)  loss_n_40: 0.7792 (0.8254)  loss_n_60: 0.9605 (0.9730)  loss_n_80: 1.1389 (1.2076)  loss_n_100: 1.4012 (1.4409)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [560/845]  eta: 0:01:35  loss: 4.1848 (4.4468)  loss_n_40: 0.7790 (0.8249)  loss_n_60: 0.9342 (0.9728)  loss_n_80: 1.1389 (1.2079)  loss_n_100: 1.4012 (1.4413)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [570/845]  eta: 0:01:32  loss: 4.0188 (4.4425)  loss_n_40: 0.7206 (0.8232)  loss_n_60: 0.8760 (0.9713)  loss_n_80: 1.1074 (1.2073)  loss_n_100: 1.3861 (1.4408)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [580/845]  eta: 0:01:28  loss: 4.0352 (4.4404)  loss_n_40: 0.7432 (0.8240)  loss_n_60: 0.8790 (0.9716)  loss_n_80: 1.1334 (1.2061)  loss_n_100: 1.3447 (1.4387)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [590/845]  eta: 0:01:25  loss: 4.2448 (4.4466)  loss_n_40: 0.8149 (0.8261)  loss_n_60: 0.9961 (0.9741)  loss_n_80: 1.1775 (1.2073)  loss_n_100: 1.3590 (1.4392)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [600/845]  eta: 0:01:22  loss: 4.2448 (4.4462)  loss_n_40: 0.8560 (0.8261)  loss_n_60: 0.9973 (0.9742)  loss_n_80: 1.1216 (1.2071)  loss_n_100: 1.3392 (1.4388)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [610/845]  eta: 0:01:18  loss: 4.0572 (4.4455)  loss_n_40: 0.7683 (0.8261)  loss_n_60: 0.8677 (0.9741)  loss_n_80: 1.1106 (1.2070)  loss_n_100: 1.3413 (1.4384)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [620/845]  eta: 0:01:15  loss: 4.0572 (4.4494)  loss_n_40: 0.7683 (0.8274)  loss_n_60: 0.8677 (0.9753)  loss_n_80: 1.1106 (1.2076)  loss_n_100: 1.3442 (1.4392)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [630/845]  eta: 0:01:11  loss: 4.0337 (4.4486)  loss_n_40: 0.7597 (0.8295)  loss_n_60: 0.8726 (0.9754)  loss_n_80: 1.0920 (1.2065)  loss_n_100: 1.2970 (1.4372)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [640/845]  eta: 0:01:08  loss: 4.0251 (4.4472)  loss_n_40: 0.7408 (0.8289)  loss_n_60: 0.8555 (0.9746)  loss_n_80: 1.1051 (1.2062)  loss_n_100: 1.3196 (1.4375)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [650/845]  eta: 0:01:05  loss: 4.1002 (4.4494)  loss_n_40: 0.7408 (0.8283)  loss_n_60: 0.8656 (0.9747)  loss_n_80: 1.1062 (1.2073)  loss_n_100: 1.3740 (1.4391)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [660/845]  eta: 0:01:01  loss: 4.1002 (4.4460)  loss_n_40: 0.7518 (0.8272)  loss_n_60: 0.8798 (0.9736)  loss_n_80: 1.1625 (1.2065)  loss_n_100: 1.3740 (1.4387)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [670/845]  eta: 0:00:58  loss: 4.3207 (4.4490)  loss_n_40: 0.7679 (0.8271)  loss_n_60: 0.9236 (0.9741)  loss_n_80: 1.1675 (1.2077)  loss_n_100: 1.3934 (1.4401)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [680/845]  eta: 0:00:55  loss: 4.3207 (4.4512)  loss_n_40: 0.7694 (0.8285)  loss_n_60: 0.9236 (0.9750)  loss_n_80: 1.1633 (1.2079)  loss_n_100: 1.4387 (1.4400)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [690/845]  eta: 0:00:51  loss: 4.2370 (4.4531)  loss_n_40: 0.7430 (0.8287)  loss_n_60: 0.8883 (0.9753)  loss_n_80: 1.1633 (1.2084)  loss_n_100: 1.4214 (1.4408)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [700/845]  eta: 0:00:48  loss: 4.0277 (4.4473)  loss_n_40: 0.7366 (0.8272)  loss_n_60: 0.8842 (0.9739)  loss_n_80: 1.1115 (1.2069)  loss_n_100: 1.3720 (1.4393)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [710/845]  eta: 0:00:45  loss: 4.0071 (4.4452)  loss_n_40: 0.7420 (0.8268)  loss_n_60: 0.8850 (0.9732)  loss_n_80: 1.0991 (1.2062)  loss_n_100: 1.3237 (1.4391)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [720/845]  eta: 0:00:41  loss: 4.0322 (4.4424)  loss_n_40: 0.7721 (0.8256)  loss_n_60: 0.8928 (0.9724)  loss_n_80: 1.0931 (1.2055)  loss_n_100: 1.3478 (1.4389)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [730/845]  eta: 0:00:38  loss: 4.0756 (4.4474)  loss_n_40: 0.7745 (0.8277)  loss_n_60: 0.9001 (0.9737)  loss_n_80: 1.1064 (1.2068)  loss_n_100: 1.3702 (1.4393)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [740/845]  eta: 0:00:35  loss: 4.2289 (4.4492)  loss_n_40: 0.7852 (0.8286)  loss_n_60: 0.9523 (0.9740)  loss_n_80: 1.1725 (1.2069)  loss_n_100: 1.3929 (1.4397)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [750/845]  eta: 0:00:31  loss: 4.1396 (4.4472)  loss_n_40: 0.7544 (0.8273)  loss_n_60: 0.9114 (0.9734)  loss_n_80: 1.1204 (1.2068)  loss_n_100: 1.4200 (1.4397)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [760/845]  eta: 0:00:28  loss: 4.1624 (4.4474)  loss_n_40: 0.7544 (0.8269)  loss_n_60: 0.9114 (0.9734)  loss_n_80: 1.1204 (1.2071)  loss_n_100: 1.4107 (1.4400)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [770/845]  eta: 0:00:25  loss: 4.0279 (4.4441)  loss_n_40: 0.7530 (0.8259)  loss_n_60: 0.9107 (0.9727)  loss_n_80: 1.1180 (1.2063)  loss_n_100: 1.3692 (1.4391)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [780/845]  eta: 0:00:21  loss: 4.0580 (4.4437)  loss_n_40: 0.7602 (0.8255)  loss_n_60: 0.9352 (0.9730)  loss_n_80: 1.1180 (1.2062)  loss_n_100: 1.3412 (1.4390)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:14]  [790/845]  eta: 0:00:18  loss: 4.1428 (4.4432)  loss_n_40: 0.8046 (0.8262)  loss_n_60: 0.9388 (0.9734)  loss_n_80: 1.1119 (1.2055)  loss_n_100: 1.3412 (1.4381)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [800/845]  eta: 0:00:15  loss: 4.0895 (4.4428)  loss_n_40: 0.7448 (0.8254)  loss_n_60: 0.9307 (0.9733)  loss_n_80: 1.1025 (1.2058)  loss_n_100: 1.3962 (1.4384)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [810/845]  eta: 0:00:11  loss: 4.2518 (4.4491)  loss_n_40: 0.7740 (0.8275)  loss_n_60: 0.9350 (0.9752)  loss_n_80: 1.2065 (1.2072)  loss_n_100: 1.4091 (1.4393)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [820/845]  eta: 0:00:08  loss: 4.2518 (4.4480)  loss_n_40: 0.7649 (0.8266)  loss_n_60: 0.9262 (0.9746)  loss_n_80: 1.2065 (1.2071)  loss_n_100: 1.4230 (1.4397)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [830/845]  eta: 0:00:05  loss: 4.0507 (4.4473)  loss_n_40: 0.7185 (0.8257)  loss_n_60: 0.8641 (0.9744)  loss_n_80: 1.1708 (1.2073)  loss_n_100: 1.4230 (1.4398)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [840/845]  eta: 0:00:01  loss: 4.1928 (4.4484)  loss_n_40: 0.7533 (0.8255)  loss_n_60: 0.8903 (0.9745)  loss_n_80: 1.1708 (1.2078)  loss_n_100: 1.3913 (1.4405)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14]  [844/845]  eta: 0:00:00  loss: 4.2149 (4.4460)  loss_n_40: 0.7533 (0.8249)  loss_n_60: 0.9197 (0.9738)  loss_n_80: 1.1708 (1.2074)  loss_n_100: 1.4478 (1.4399)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:14] Total time: 0:04:42 (0.3348 s / it)\n",
      "Averaged stats: loss: 4.2149 (4.4460)  loss_n_40: 0.7533 (0.8249)  loss_n_60: 0.9197 (0.9738)  loss_n_80: 1.1708 (1.2074)  loss_n_100: 1.4478 (1.4399)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_14_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 1.440%\n",
      "Min loss_n_100: 0.450\n",
      "Best Epoch: 13.000\n",
      "Train: [epoch:15]  [   0/1724]  eta: 2:01:14  lr: 0.000200  loss: 4.6468 (4.6468)  loss_n_40: 0.7962 (0.7962)  loss_n_60: 0.9843 (0.9843)  loss_n_80: 1.2770 (1.2770)  loss_n_100: 1.5892 (1.5892)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.2194  data: 0.4636  max mem: 46473\n",
      "Train: [epoch:15]  [  10/1724]  eta: 1:52:45  lr: 0.000200  loss: 4.2779 (4.2596)  loss_n_40: 0.7657 (0.8183)  loss_n_60: 0.9605 (0.9574)  loss_n_80: 1.1683 (1.1600)  loss_n_100: 1.3615 (1.3239)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9470  data: 0.0423  max mem: 46473\n",
      "Train: [epoch:15]  [  20/1724]  eta: 1:51:42  lr: 0.000200  loss: 3.8350 (4.0023)  loss_n_40: 0.7418 (0.7849)  loss_n_60: 0.8815 (0.9172)  loss_n_80: 1.0468 (1.0787)  loss_n_100: 1.1788 (1.2216)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [  30/1724]  eta: 1:50:53  lr: 0.000200  loss: 3.3253 (3.7234)  loss_n_40: 0.6582 (0.7315)  loss_n_60: 0.7729 (0.8550)  loss_n_80: 0.9414 (1.0042)  loss_n_100: 1.0345 (1.1328)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [  40/1724]  eta: 1:50:10  lr: 0.000200  loss: 2.9124 (3.5314)  loss_n_40: 0.5753 (0.6995)  loss_n_60: 0.6684 (0.8135)  loss_n_80: 0.7846 (0.9520)  loss_n_100: 0.8663 (1.0664)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [  50/1724]  eta: 1:49:28  lr: 0.000200  loss: 3.0896 (3.6667)  loss_n_40: 0.6124 (0.6961)  loss_n_60: 0.6897 (0.8102)  loss_n_80: 0.8522 (0.9624)  loss_n_100: 0.9394 (1.0905)  triple_100: 0.0000 (0.0326)  triple_80: 0.0000 (0.0402)  triple_60: 0.0000 (0.0348)  triple_40: 0.0000 (0.0000)  time: 3.9178  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [  60/1724]  eta: 1:48:48  lr: 0.000200  loss: 3.8736 (3.7503)  loss_n_40: 0.6677 (0.6950)  loss_n_60: 0.8930 (0.8263)  loss_n_80: 1.0487 (0.9902)  loss_n_100: 1.2559 (1.1350)  triple_100: 0.0000 (0.0411)  triple_80: 0.0000 (0.0336)  triple_60: 0.0000 (0.0291)  triple_40: 0.0000 (0.0000)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [  70/1724]  eta: 1:48:08  lr: 0.000200  loss: 3.8119 (3.7339)  loss_n_40: 0.6646 (0.6917)  loss_n_60: 0.8825 (0.8311)  loss_n_80: 1.0487 (0.9896)  loss_n_100: 1.1923 (1.1323)  triple_100: 0.0000 (0.0353)  triple_80: 0.0000 (0.0288)  triple_60: 0.0000 (0.0250)  triple_40: 0.0000 (0.0000)  time: 3.9194  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [  80/1724]  eta: 1:47:27  lr: 0.000200  loss: 3.2868 (3.6445)  loss_n_40: 0.5968 (0.6755)  loss_n_60: 0.7625 (0.8151)  loss_n_80: 0.8845 (0.9676)  loss_n_100: 1.0314 (1.1082)  triple_100: 0.0000 (0.0310)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0219)  triple_40: 0.0000 (0.0000)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [  90/1724]  eta: 1:46:48  lr: 0.000200  loss: 2.7580 (3.5312)  loss_n_40: 0.5251 (0.6610)  loss_n_60: 0.6315 (0.7926)  loss_n_80: 0.7384 (0.9377)  loss_n_100: 0.7929 (1.0703)  triple_100: 0.0000 (0.0276)  triple_80: 0.0000 (0.0225)  triple_60: 0.0000 (0.0195)  triple_40: 0.0000 (0.0000)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 100/1724]  eta: 1:46:08  lr: 0.000200  loss: 2.5306 (3.4279)  loss_n_40: 0.5093 (0.6449)  loss_n_60: 0.6114 (0.7723)  loss_n_80: 0.6766 (0.9112)  loss_n_100: 0.7470 (1.0368)  triple_100: 0.0000 (0.0248)  triple_80: 0.0000 (0.0203)  triple_60: 0.0000 (0.0176)  triple_40: 0.0000 (0.0000)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 110/1724]  eta: 1:45:28  lr: 0.000200  loss: 2.3621 (3.3188)  loss_n_40: 0.4658 (0.6271)  loss_n_60: 0.5584 (0.7507)  loss_n_80: 0.6491 (0.8824)  loss_n_100: 0.6865 (1.0016)  triple_100: 0.0000 (0.0226)  triple_80: 0.0000 (0.0184)  triple_60: 0.0000 (0.0160)  triple_40: 0.0000 (0.0000)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 120/1724]  eta: 1:44:48  lr: 0.000200  loss: 2.3253 (3.2545)  loss_n_40: 0.4597 (0.6192)  loss_n_60: 0.5584 (0.7379)  loss_n_80: 0.6046 (0.8634)  loss_n_100: 0.6476 (0.9778)  triple_100: 0.0000 (0.0246)  triple_80: 0.0000 (0.0169)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0000)  time: 3.9170  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 130/1724]  eta: 1:44:08  lr: 0.000200  loss: 2.2851 (3.1749)  loss_n_40: 0.4480 (0.6076)  loss_n_60: 0.5590 (0.7232)  loss_n_80: 0.5864 (0.8413)  loss_n_100: 0.6461 (0.9509)  triple_100: 0.0000 (0.0227)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0135)  triple_40: 0.0000 (0.0000)  time: 3.9150  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 140/1724]  eta: 1:43:29  lr: 0.000200  loss: 2.0645 (3.1120)  loss_n_40: 0.4277 (0.6007)  loss_n_60: 0.5233 (0.7117)  loss_n_80: 0.5337 (0.8235)  loss_n_100: 0.5962 (0.9279)  triple_100: 0.0000 (0.0211)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0126)  triple_40: 0.0000 (0.0000)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 150/1724]  eta: 1:42:49  lr: 0.000200  loss: 2.0354 (3.0399)  loss_n_40: 0.4053 (0.5901)  loss_n_60: 0.5061 (0.6978)  loss_n_80: 0.5169 (0.8032)  loss_n_100: 0.5873 (0.9038)  triple_100: 0.0000 (0.0197)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0118)  triple_40: 0.0000 (0.0000)  time: 3.9184  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [ 160/1724]  eta: 1:42:10  lr: 0.000200  loss: 1.9131 (2.9727)  loss_n_40: 0.3986 (0.5802)  loss_n_60: 0.4672 (0.6839)  loss_n_80: 0.4877 (0.7850)  loss_n_100: 0.5390 (0.8815)  triple_100: 0.0000 (0.0185)  triple_80: 0.0000 (0.0127)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0000)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 170/1724]  eta: 1:41:31  lr: 0.000200  loss: 1.8591 (2.9061)  loss_n_40: 0.3920 (0.5701)  loss_n_60: 0.4576 (0.6703)  loss_n_80: 0.4929 (0.7665)  loss_n_100: 0.5217 (0.8595)  triple_100: 0.0000 (0.0174)  triple_80: 0.0000 (0.0120)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0000)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 180/1724]  eta: 1:40:51  lr: 0.000200  loss: 1.8591 (2.8479)  loss_n_40: 0.3782 (0.5609)  loss_n_60: 0.4570 (0.6583)  loss_n_80: 0.4628 (0.7506)  loss_n_100: 0.5307 (0.8406)  triple_100: 0.0000 (0.0164)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0000)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 190/1724]  eta: 1:40:12  lr: 0.000200  loss: 1.8748 (2.8024)  loss_n_40: 0.3914 (0.5563)  loss_n_60: 0.4483 (0.6486)  loss_n_80: 0.4721 (0.7370)  loss_n_100: 0.5097 (0.8235)  triple_100: 0.0000 (0.0169)  triple_80: 0.0000 (0.0107)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0000)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 200/1724]  eta: 1:39:33  lr: 0.000200  loss: 1.8342 (2.7555)  loss_n_40: 0.3866 (0.5482)  loss_n_60: 0.4423 (0.6390)  loss_n_80: 0.4691 (0.7247)  loss_n_100: 0.5022 (0.8084)  triple_100: 0.0000 (0.0161)  triple_80: 0.0000 (0.0102)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0000)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 210/1724]  eta: 1:38:54  lr: 0.000200  loss: 1.7642 (2.7099)  loss_n_40: 0.3832 (0.5421)  loss_n_60: 0.4394 (0.6296)  loss_n_80: 0.4466 (0.7120)  loss_n_100: 0.4761 (0.7928)  triple_100: 0.0000 (0.0153)  triple_80: 0.0000 (0.0097)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0000)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 220/1724]  eta: 1:38:14  lr: 0.000200  loss: 1.8625 (2.6776)  loss_n_40: 0.4153 (0.5362)  loss_n_60: 0.4418 (0.6199)  loss_n_80: 0.4540 (0.7000)  loss_n_100: 0.4715 (0.7776)  triple_100: 0.0000 (0.0177)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0107)  triple_40: 0.0000 (0.0000)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 230/1724]  eta: 1:37:35  lr: 0.000200  loss: 1.9514 (2.6518)  loss_n_40: 0.4461 (0.5331)  loss_n_60: 0.4621 (0.6142)  loss_n_80: 0.5041 (0.6932)  loss_n_100: 0.5277 (0.7690)  triple_100: 0.0000 (0.0169)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0004)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 240/1724]  eta: 1:36:56  lr: 0.000200  loss: 1.9703 (2.6186)  loss_n_40: 0.4161 (0.5272)  loss_n_60: 0.4714 (0.6069)  loss_n_80: 0.5110 (0.6845)  loss_n_100: 0.5626 (0.7593)  triple_100: 0.0000 (0.0162)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0004)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 250/1724]  eta: 1:36:17  lr: 0.000200  loss: 1.8690 (2.5909)  loss_n_40: 0.4145 (0.5247)  loss_n_60: 0.4482 (0.6008)  loss_n_80: 0.4909 (0.6768)  loss_n_100: 0.5260 (0.7496)  triple_100: 0.0000 (0.0156)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0004)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 260/1724]  eta: 1:35:37  lr: 0.000200  loss: 1.9033 (2.5659)  loss_n_40: 0.4339 (0.5218)  loss_n_60: 0.4515 (0.5955)  loss_n_80: 0.4893 (0.6700)  loss_n_100: 0.5134 (0.7412)  triple_100: 0.0000 (0.0150)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0004)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 270/1724]  eta: 1:34:58  lr: 0.000200  loss: 1.8472 (2.5409)  loss_n_40: 0.4215 (0.5190)  loss_n_60: 0.4450 (0.5901)  loss_n_80: 0.4857 (0.6632)  loss_n_100: 0.5051 (0.7324)  triple_100: 0.0000 (0.0144)  triple_80: 0.0000 (0.0126)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0005)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 280/1724]  eta: 1:34:19  lr: 0.000200  loss: 1.7795 (2.5112)  loss_n_40: 0.4144 (0.5152)  loss_n_60: 0.4260 (0.5836)  loss_n_80: 0.4576 (0.6552)  loss_n_100: 0.4715 (0.7223)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0004)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 290/1724]  eta: 1:33:40  lr: 0.000200  loss: 1.6271 (2.4822)  loss_n_40: 0.3709 (0.5109)  loss_n_60: 0.3915 (0.5769)  loss_n_80: 0.4237 (0.6471)  loss_n_100: 0.4356 (0.7119)  triple_100: 0.0000 (0.0134)  triple_80: 0.0000 (0.0117)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0020)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 300/1724]  eta: 1:33:00  lr: 0.000200  loss: 1.5563 (2.4595)  loss_n_40: 0.3620 (0.5074)  loss_n_60: 0.3760 (0.5717)  loss_n_80: 0.4237 (0.6414)  loss_n_100: 0.4311 (0.7048)  triple_100: 0.0000 (0.0130)  triple_80: 0.0000 (0.0114)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0019)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 310/1724]  eta: 1:32:21  lr: 0.000200  loss: 1.7652 (2.4357)  loss_n_40: 0.4003 (0.5035)  loss_n_60: 0.4215 (0.5665)  loss_n_80: 0.4555 (0.6353)  loss_n_100: 0.4833 (0.6973)  triple_100: 0.0000 (0.0126)  triple_80: 0.0000 (0.0110)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0019)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 320/1724]  eta: 1:31:42  lr: 0.000200  loss: 1.6346 (2.4122)  loss_n_40: 0.3806 (0.5001)  loss_n_60: 0.3877 (0.5615)  loss_n_80: 0.4272 (0.6289)  loss_n_100: 0.4494 (0.6897)  triple_100: 0.0000 (0.0122)  triple_80: 0.0000 (0.0106)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0018)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 330/1724]  eta: 1:31:03  lr: 0.000200  loss: 1.5403 (2.3843)  loss_n_40: 0.3550 (0.4955)  loss_n_60: 0.3637 (0.5553)  loss_n_80: 0.3961 (0.6215)  loss_n_100: 0.4191 (0.6811)  triple_100: 0.0000 (0.0118)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0018)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 340/1724]  eta: 1:30:23  lr: 0.000200  loss: 1.4408 (2.3794)  loss_n_40: 0.3389 (0.4917)  loss_n_60: 0.3308 (0.5501)  loss_n_80: 0.3742 (0.6157)  loss_n_100: 0.3833 (0.6746)  triple_100: 0.0000 (0.0161)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0021)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 350/1724]  eta: 1:29:44  lr: 0.000200  loss: 2.4738 (2.4200)  loss_n_40: 0.4256 (0.4911)  loss_n_60: 0.5411 (0.5525)  loss_n_80: 0.6050 (0.6202)  loss_n_100: 0.7707 (0.6826)  triple_100: 0.0000 (0.0239)  triple_80: 0.0000 (0.0220)  triple_60: 0.0000 (0.0220)  triple_40: 0.0000 (0.0058)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 360/1724]  eta: 1:29:05  lr: 0.000200  loss: 2.9801 (2.4395)  loss_n_40: 0.4846 (0.4921)  loss_n_60: 0.6561 (0.5566)  loss_n_80: 0.7694 (0.6270)  loss_n_100: 0.9603 (0.6922)  triple_100: 0.0000 (0.0233)  triple_80: 0.0000 (0.0214)  triple_60: 0.0000 (0.0214)  triple_40: 0.0000 (0.0056)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 370/1724]  eta: 1:28:26  lr: 0.000200  loss: 3.1007 (2.4862)  loss_n_40: 0.5325 (0.4936)  loss_n_60: 0.7130 (0.5614)  loss_n_80: 0.8472 (0.6332)  loss_n_100: 0.9816 (0.7012)  triple_100: 0.0000 (0.0456)  triple_80: 0.0000 (0.0249)  triple_60: 0.0000 (0.0208)  triple_40: 0.0000 (0.0055)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 380/1724]  eta: 1:27:47  lr: 0.000200  loss: 2.7695 (2.4899)  loss_n_40: 0.4998 (0.4944)  loss_n_60: 0.6715 (0.5638)  loss_n_80: 0.7584 (0.6347)  loss_n_100: 0.8634 (0.7028)  triple_100: 0.0000 (0.0444)  triple_80: 0.0000 (0.0242)  triple_60: 0.0000 (0.0202)  triple_40: 0.0000 (0.0054)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 390/1724]  eta: 1:27:07  lr: 0.000200  loss: 2.4728 (2.4906)  loss_n_40: 0.5019 (0.4955)  loss_n_60: 0.6262 (0.5655)  loss_n_80: 0.6465 (0.6351)  loss_n_100: 0.7020 (0.7026)  triple_100: 0.0000 (0.0433)  triple_80: 0.0000 (0.0236)  triple_60: 0.0000 (0.0197)  triple_40: 0.0000 (0.0052)  time: 3.9177  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [ 400/1724]  eta: 1:26:28  lr: 0.000200  loss: 2.3500 (2.4875)  loss_n_40: 0.5019 (0.4959)  loss_n_60: 0.5809 (0.5652)  loss_n_80: 0.6109 (0.6335)  loss_n_100: 0.6304 (0.7002)  triple_100: 0.0000 (0.0422)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0078)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 410/1724]  eta: 1:25:49  lr: 0.000200  loss: 2.2420 (2.4832)  loss_n_40: 0.4226 (0.4955)  loss_n_60: 0.5367 (0.5651)  loss_n_80: 0.5879 (0.6327)  loss_n_100: 0.6445 (0.6995)  triple_100: 0.0000 (0.0412)  triple_80: 0.0000 (0.0225)  triple_60: 0.0000 (0.0192)  triple_40: 0.0000 (0.0076)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 420/1724]  eta: 1:25:10  lr: 0.000200  loss: 2.2553 (2.4788)  loss_n_40: 0.4349 (0.4951)  loss_n_60: 0.5412 (0.5650)  loss_n_80: 0.5951 (0.6321)  loss_n_100: 0.6713 (0.6985)  triple_100: 0.0000 (0.0402)  triple_80: 0.0000 (0.0219)  triple_60: 0.0000 (0.0187)  triple_40: 0.0000 (0.0074)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 430/1724]  eta: 1:24:31  lr: 0.000200  loss: 2.0708 (2.4666)  loss_n_40: 0.4162 (0.4931)  loss_n_60: 0.4964 (0.5631)  loss_n_80: 0.5544 (0.6294)  loss_n_100: 0.6004 (0.6948)  triple_100: 0.0000 (0.0393)  triple_80: 0.0000 (0.0214)  triple_60: 0.0000 (0.0183)  triple_40: 0.0000 (0.0072)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 440/1724]  eta: 1:23:51  lr: 0.000200  loss: 1.8755 (2.4545)  loss_n_40: 0.4027 (0.4920)  loss_n_60: 0.4661 (0.5612)  loss_n_80: 0.4856 (0.6262)  loss_n_100: 0.5176 (0.6909)  triple_100: 0.0000 (0.0384)  triple_80: 0.0000 (0.0209)  triple_60: 0.0000 (0.0179)  triple_40: 0.0000 (0.0070)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 450/1724]  eta: 1:23:12  lr: 0.000200  loss: 1.8541 (2.4428)  loss_n_40: 0.4181 (0.4915)  loss_n_60: 0.4426 (0.5593)  loss_n_80: 0.4581 (0.6230)  loss_n_100: 0.4702 (0.6866)  triple_100: 0.0000 (0.0375)  triple_80: 0.0000 (0.0205)  triple_60: 0.0000 (0.0175)  triple_40: 0.0000 (0.0069)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 460/1724]  eta: 1:22:33  lr: 0.000200  loss: 1.7309 (2.4275)  loss_n_40: 0.3946 (0.4896)  loss_n_60: 0.4259 (0.5565)  loss_n_80: 0.4411 (0.6192)  loss_n_100: 0.4682 (0.6817)  triple_100: 0.0000 (0.0367)  triple_80: 0.0000 (0.0200)  triple_60: 0.0000 (0.0171)  triple_40: 0.0000 (0.0067)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 470/1724]  eta: 1:21:54  lr: 0.000200  loss: 1.6356 (2.4158)  loss_n_40: 0.3946 (0.4891)  loss_n_60: 0.3951 (0.5543)  loss_n_80: 0.4187 (0.6159)  loss_n_100: 0.4455 (0.6776)  triple_100: 0.0000 (0.0359)  triple_80: 0.0000 (0.0196)  triple_60: 0.0000 (0.0167)  triple_40: 0.0000 (0.0066)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 480/1724]  eta: 1:21:14  lr: 0.000200  loss: 1.6356 (2.4011)  loss_n_40: 0.3770 (0.4874)  loss_n_60: 0.3951 (0.5516)  loss_n_80: 0.4230 (0.6121)  loss_n_100: 0.4455 (0.6728)  triple_100: 0.0000 (0.0352)  triple_80: 0.0000 (0.0192)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0065)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 490/1724]  eta: 1:20:35  lr: 0.000200  loss: 1.5453 (2.3827)  loss_n_40: 0.3449 (0.4846)  loss_n_60: 0.3706 (0.5477)  loss_n_80: 0.4004 (0.6075)  loss_n_100: 0.4193 (0.6672)  triple_100: 0.0000 (0.0345)  triple_80: 0.0000 (0.0188)  triple_60: 0.0000 (0.0160)  triple_40: 0.0000 (0.0064)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 500/1724]  eta: 1:19:56  lr: 0.000200  loss: 1.5993 (2.3706)  loss_n_40: 0.3543 (0.4827)  loss_n_60: 0.3762 (0.5449)  loss_n_80: 0.4071 (0.6045)  loss_n_100: 0.4329 (0.6634)  triple_100: 0.0000 (0.0342)  triple_80: 0.0000 (0.0184)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0067)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 510/1724]  eta: 1:19:17  lr: 0.000200  loss: 1.8968 (2.3622)  loss_n_40: 0.3889 (0.4810)  loss_n_60: 0.4460 (0.5433)  loss_n_80: 0.4623 (0.6030)  loss_n_100: 0.4743 (0.6613)  triple_100: 0.0000 (0.0335)  triple_80: 0.0000 (0.0181)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0066)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 520/1724]  eta: 1:18:38  lr: 0.000200  loss: 1.7313 (2.3504)  loss_n_40: 0.3837 (0.4790)  loss_n_60: 0.4235 (0.5408)  loss_n_80: 0.4518 (0.6004)  loss_n_100: 0.4731 (0.6580)  triple_100: 0.0000 (0.0329)  triple_80: 0.0000 (0.0177)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0065)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 530/1724]  eta: 1:17:58  lr: 0.000200  loss: 1.9223 (2.3586)  loss_n_40: 0.3854 (0.4781)  loss_n_60: 0.4689 (0.5412)  loss_n_80: 0.5206 (0.6020)  loss_n_100: 0.5474 (0.6614)  triple_100: 0.0000 (0.0329)  triple_80: 0.0000 (0.0186)  triple_60: 0.0000 (0.0180)  triple_40: 0.0000 (0.0064)  time: 3.9153  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 540/1724]  eta: 1:17:19  lr: 0.000200  loss: 2.3835 (2.3580)  loss_n_40: 0.4488 (0.4775)  loss_n_60: 0.5311 (0.5408)  loss_n_80: 0.6237 (0.6023)  loss_n_100: 0.7565 (0.6629)  triple_100: 0.0000 (0.0323)  triple_80: 0.0000 (0.0183)  triple_60: 0.0000 (0.0177)  triple_40: 0.0000 (0.0062)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 550/1724]  eta: 1:16:40  lr: 0.000200  loss: 2.2060 (2.3497)  loss_n_40: 0.4195 (0.4760)  loss_n_60: 0.4823 (0.5389)  loss_n_80: 0.5329 (0.6003)  loss_n_100: 0.6146 (0.6608)  triple_100: 0.0000 (0.0317)  triple_80: 0.0000 (0.0180)  triple_60: 0.0000 (0.0174)  triple_40: 0.0000 (0.0068)  time: 3.9154  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 560/1724]  eta: 1:16:00  lr: 0.000200  loss: 1.8177 (2.3389)  loss_n_40: 0.3900 (0.4744)  loss_n_60: 0.4155 (0.5367)  loss_n_80: 0.4673 (0.5977)  loss_n_100: 0.5240 (0.6577)  triple_100: 0.0000 (0.0311)  triple_80: 0.0000 (0.0176)  triple_60: 0.0000 (0.0170)  triple_40: 0.0000 (0.0066)  time: 3.9151  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 570/1724]  eta: 1:15:21  lr: 0.000200  loss: 1.7471 (2.3285)  loss_n_40: 0.3780 (0.4731)  loss_n_60: 0.4093 (0.5346)  loss_n_80: 0.4439 (0.5951)  loss_n_100: 0.4778 (0.6545)  triple_100: 0.0000 (0.0306)  triple_80: 0.0000 (0.0173)  triple_60: 0.0000 (0.0167)  triple_40: 0.0000 (0.0065)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 580/1724]  eta: 1:14:42  lr: 0.000200  loss: 1.6481 (2.3159)  loss_n_40: 0.3753 (0.4712)  loss_n_60: 0.3978 (0.5320)  loss_n_80: 0.4250 (0.5920)  loss_n_100: 0.4565 (0.6508)  triple_100: 0.0000 (0.0301)  triple_80: 0.0000 (0.0170)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0064)  time: 3.9149  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 590/1724]  eta: 1:14:03  lr: 0.000200  loss: 1.4566 (2.3016)  loss_n_40: 0.3389 (0.4691)  loss_n_60: 0.3467 (0.5290)  loss_n_80: 0.3874 (0.5883)  loss_n_100: 0.4058 (0.6464)  triple_100: 0.0000 (0.0295)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0063)  time: 3.9137  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 600/1724]  eta: 1:13:23  lr: 0.000200  loss: 1.4478 (2.2879)  loss_n_40: 0.3475 (0.4672)  loss_n_60: 0.3544 (0.5260)  loss_n_80: 0.3671 (0.5848)  loss_n_100: 0.3761 (0.6421)  triple_100: 0.0000 (0.0291)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0159)  triple_40: 0.0000 (0.0063)  time: 3.9143  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 610/1724]  eta: 1:12:44  lr: 0.000200  loss: 1.4287 (2.2726)  loss_n_40: 0.3274 (0.4647)  loss_n_60: 0.3443 (0.5227)  loss_n_80: 0.3684 (0.5810)  loss_n_100: 0.3771 (0.6375)  triple_100: 0.0000 (0.0286)  triple_80: 0.0000 (0.0162)  triple_60: 0.0000 (0.0156)  triple_40: 0.0000 (0.0062)  time: 3.9158  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 620/1724]  eta: 1:12:05  lr: 0.000200  loss: 1.3234 (2.2588)  loss_n_40: 0.3041 (0.4625)  loss_n_60: 0.3171 (0.5198)  loss_n_80: 0.3387 (0.5776)  loss_n_100: 0.3427 (0.6334)  triple_100: 0.0000 (0.0281)  triple_80: 0.0000 (0.0159)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0061)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 630/1724]  eta: 1:11:26  lr: 0.000200  loss: 1.4804 (2.2568)  loss_n_40: 0.3318 (0.4613)  loss_n_60: 0.3307 (0.5174)  loss_n_80: 0.3428 (0.5747)  loss_n_100: 0.3820 (0.6300)  triple_100: 0.0000 (0.0290)  triple_80: 0.0000 (0.0180)  triple_60: 0.0000 (0.0175)  triple_40: 0.0000 (0.0090)  time: 3.9152  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [ 640/1724]  eta: 1:10:47  lr: 0.000200  loss: 2.1476 (2.2679)  loss_n_40: 0.4538 (0.4618)  loss_n_60: 0.4638 (0.5194)  loss_n_80: 0.5379 (0.5776)  loss_n_100: 0.5699 (0.6341)  triple_100: 0.0000 (0.0298)  triple_80: 0.0000 (0.0190)  triple_60: 0.0000 (0.0172)  triple_40: 0.0000 (0.0089)  time: 3.9138  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 650/1724]  eta: 1:10:07  lr: 0.000200  loss: 2.8006 (2.2769)  loss_n_40: 0.5670 (0.4639)  loss_n_60: 0.6487 (0.5217)  loss_n_80: 0.7454 (0.5801)  loss_n_100: 0.8588 (0.6374)  triple_100: 0.0000 (0.0294)  triple_80: 0.0000 (0.0187)  triple_60: 0.0000 (0.0170)  triple_40: 0.0000 (0.0087)  time: 3.9146  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 660/1724]  eta: 1:09:28  lr: 0.000200  loss: 2.7034 (2.2813)  loss_n_40: 0.5731 (0.4650)  loss_n_60: 0.6437 (0.5230)  loss_n_80: 0.7107 (0.5816)  loss_n_100: 0.8057 (0.6391)  triple_100: 0.0000 (0.0289)  triple_80: 0.0000 (0.0184)  triple_60: 0.0000 (0.0167)  triple_40: 0.0000 (0.0086)  time: 3.9151  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 670/1724]  eta: 1:08:49  lr: 0.000200  loss: 2.3195 (2.2795)  loss_n_40: 0.4871 (0.4650)  loss_n_60: 0.5614 (0.5228)  loss_n_80: 0.6017 (0.5813)  loss_n_100: 0.6689 (0.6388)  triple_100: 0.0000 (0.0285)  triple_80: 0.0000 (0.0181)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0085)  time: 3.9144  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 680/1724]  eta: 1:08:10  lr: 0.000200  loss: 1.9414 (2.2740)  loss_n_40: 0.4348 (0.4646)  loss_n_60: 0.4689 (0.5218)  loss_n_80: 0.5172 (0.5800)  loss_n_100: 0.5916 (0.6370)  triple_100: 0.0000 (0.0281)  triple_80: 0.0000 (0.0179)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0083)  time: 3.9149  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 690/1724]  eta: 1:07:30  lr: 0.000200  loss: 1.7302 (2.2661)  loss_n_40: 0.3934 (0.4635)  loss_n_60: 0.4111 (0.5203)  loss_n_80: 0.4603 (0.5782)  loss_n_100: 0.4642 (0.6345)  triple_100: 0.0000 (0.0277)  triple_80: 0.0000 (0.0176)  triple_60: 0.0000 (0.0160)  triple_40: 0.0000 (0.0082)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 700/1724]  eta: 1:06:51  lr: 0.000200  loss: 1.7046 (2.2583)  loss_n_40: 0.3848 (0.4628)  loss_n_60: 0.4049 (0.5187)  loss_n_80: 0.4363 (0.5761)  loss_n_100: 0.4628 (0.6320)  triple_100: 0.0000 (0.0273)  triple_80: 0.0000 (0.0174)  triple_60: 0.0000 (0.0158)  triple_40: 0.0000 (0.0083)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 710/1724]  eta: 1:06:12  lr: 0.000200  loss: 1.6307 (2.2511)  loss_n_40: 0.3659 (0.4618)  loss_n_60: 0.3895 (0.5172)  loss_n_80: 0.4210 (0.5743)  loss_n_100: 0.4254 (0.6296)  triple_100: 0.0000 (0.0269)  triple_80: 0.0000 (0.0176)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0082)  time: 3.9157  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 720/1724]  eta: 1:05:33  lr: 0.000200  loss: 1.5146 (2.2408)  loss_n_40: 0.3344 (0.4600)  loss_n_60: 0.3756 (0.5151)  loss_n_80: 0.4030 (0.5719)  loss_n_100: 0.4214 (0.6266)  triple_100: 0.0000 (0.0265)  triple_80: 0.0000 (0.0173)  triple_60: 0.0000 (0.0153)  triple_40: 0.0000 (0.0081)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 730/1724]  eta: 1:04:54  lr: 0.000200  loss: 1.3955 (2.2292)  loss_n_40: 0.3146 (0.4582)  loss_n_60: 0.3418 (0.5126)  loss_n_80: 0.3711 (0.5689)  loss_n_100: 0.3805 (0.6231)  triple_100: 0.0000 (0.0262)  triple_80: 0.0000 (0.0171)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0079)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 740/1724]  eta: 1:04:14  lr: 0.000200  loss: 1.3808 (2.2188)  loss_n_40: 0.3197 (0.4568)  loss_n_60: 0.3269 (0.5104)  loss_n_80: 0.3512 (0.5662)  loss_n_100: 0.3640 (0.6199)  triple_100: 0.0000 (0.0258)  triple_80: 0.0000 (0.0169)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0078)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 750/1724]  eta: 1:03:35  lr: 0.000200  loss: 1.3185 (2.2076)  loss_n_40: 0.3198 (0.4551)  loss_n_60: 0.3178 (0.5080)  loss_n_80: 0.3435 (0.5634)  loss_n_100: 0.3503 (0.6165)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0166)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0077)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 760/1724]  eta: 1:02:56  lr: 0.000200  loss: 1.3439 (2.1970)  loss_n_40: 0.3188 (0.4534)  loss_n_60: 0.3178 (0.5057)  loss_n_80: 0.3482 (0.5608)  loss_n_100: 0.3568 (0.6134)  triple_100: 0.0000 (0.0251)  triple_80: 0.0000 (0.0164)  triple_60: 0.0000 (0.0145)  triple_40: 0.0000 (0.0076)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 770/1724]  eta: 1:02:17  lr: 0.000200  loss: 1.2885 (2.1855)  loss_n_40: 0.3015 (0.4515)  loss_n_60: 0.3101 (0.5032)  loss_n_80: 0.3340 (0.5579)  loss_n_100: 0.3484 (0.6100)  triple_100: 0.0000 (0.0248)  triple_80: 0.0000 (0.0162)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0075)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 780/1724]  eta: 1:01:38  lr: 0.000200  loss: 1.5678 (2.1810)  loss_n_40: 0.3305 (0.4507)  loss_n_60: 0.3795 (0.5021)  loss_n_80: 0.4116 (0.5567)  loss_n_100: 0.4102 (0.6084)  triple_100: 0.0000 (0.0247)  triple_80: 0.0000 (0.0168)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0075)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 790/1724]  eta: 1:00:59  lr: 0.000200  loss: 1.7646 (2.1775)  loss_n_40: 0.3859 (0.4500)  loss_n_60: 0.4102 (0.5012)  loss_n_80: 0.4604 (0.5556)  loss_n_100: 0.5059 (0.6073)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0169)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0074)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 800/1724]  eta: 1:00:19  lr: 0.000200  loss: 1.7459 (2.1725)  loss_n_40: 0.3702 (0.4491)  loss_n_60: 0.4239 (0.5002)  loss_n_80: 0.4633 (0.5545)  loss_n_100: 0.5145 (0.6059)  triple_100: 0.0000 (0.0246)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0073)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 810/1724]  eta: 0:59:40  lr: 0.000200  loss: 1.8419 (2.1701)  loss_n_40: 0.4055 (0.4491)  loss_n_60: 0.4499 (0.4999)  loss_n_80: 0.4789 (0.5539)  loss_n_100: 0.5145 (0.6050)  triple_100: 0.0000 (0.0243)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0072)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 820/1724]  eta: 0:59:01  lr: 0.000200  loss: 1.8372 (2.1643)  loss_n_40: 0.4055 (0.4483)  loss_n_60: 0.4399 (0.4988)  loss_n_80: 0.4715 (0.5524)  loss_n_100: 0.5003 (0.6033)  triple_100: 0.0000 (0.0240)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0071)  time: 3.9171  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 830/1724]  eta: 0:58:22  lr: 0.000200  loss: 1.6281 (2.1576)  loss_n_40: 0.3676 (0.4473)  loss_n_60: 0.3977 (0.4976)  loss_n_80: 0.4117 (0.5508)  loss_n_100: 0.4167 (0.6012)  triple_100: 0.0000 (0.0237)  triple_80: 0.0000 (0.0161)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0070)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 840/1724]  eta: 0:57:43  lr: 0.000200  loss: 1.5657 (2.1501)  loss_n_40: 0.3629 (0.4463)  loss_n_60: 0.3762 (0.4961)  loss_n_80: 0.4086 (0.5489)  loss_n_100: 0.4167 (0.5989)  triple_100: 0.0000 (0.0234)  triple_80: 0.0000 (0.0159)  triple_60: 0.0000 (0.0137)  triple_40: 0.0000 (0.0070)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 850/1724]  eta: 0:57:03  lr: 0.000200  loss: 1.4682 (2.1421)  loss_n_40: 0.3396 (0.4452)  loss_n_60: 0.3546 (0.4944)  loss_n_80: 0.3828 (0.5469)  loss_n_100: 0.3978 (0.5963)  triple_100: 0.0000 (0.0231)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0135)  triple_40: 0.0000 (0.0069)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 860/1724]  eta: 0:56:24  lr: 0.000200  loss: 1.4158 (2.1336)  loss_n_40: 0.3341 (0.4440)  loss_n_60: 0.3445 (0.4926)  loss_n_80: 0.3655 (0.5448)  loss_n_100: 0.3691 (0.5937)  triple_100: 0.0000 (0.0229)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0134)  triple_40: 0.0000 (0.0068)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 870/1724]  eta: 0:55:45  lr: 0.000200  loss: 1.4699 (2.1315)  loss_n_40: 0.3407 (0.4435)  loss_n_60: 0.3539 (0.4915)  loss_n_80: 0.3875 (0.5434)  loss_n_100: 0.3755 (0.5919)  triple_100: 0.0000 (0.0226)  triple_80: 0.0000 (0.0160)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0079)  time: 3.9173  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [ 880/1724]  eta: 0:55:06  lr: 0.000200  loss: 2.1207 (2.1403)  loss_n_40: 0.4348 (0.4440)  loss_n_60: 0.4805 (0.4920)  loss_n_80: 0.5534 (0.5442)  loss_n_100: 0.6098 (0.5930)  triple_100: 0.0000 (0.0291)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0146)  triple_40: 0.0000 (0.0078)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 890/1724]  eta: 0:54:27  lr: 0.000200  loss: 2.0802 (2.1372)  loss_n_40: 0.4348 (0.4433)  loss_n_60: 0.4805 (0.4914)  loss_n_80: 0.5350 (0.5436)  loss_n_100: 0.5823 (0.5925)  triple_100: 0.0000 (0.0287)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0144)  triple_40: 0.0000 (0.0077)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 900/1724]  eta: 0:53:48  lr: 0.000200  loss: 1.7490 (2.1318)  loss_n_40: 0.3493 (0.4422)  loss_n_60: 0.4004 (0.4903)  loss_n_80: 0.4589 (0.5424)  loss_n_100: 0.5319 (0.5913)  triple_100: 0.0000 (0.0284)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0076)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 910/1724]  eta: 0:53:08  lr: 0.000200  loss: 1.5915 (2.1251)  loss_n_40: 0.3278 (0.4410)  loss_n_60: 0.3665 (0.4889)  loss_n_80: 0.4319 (0.5408)  loss_n_100: 0.4610 (0.5894)  triple_100: 0.0000 (0.0281)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0075)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 920/1724]  eta: 0:52:29  lr: 0.000200  loss: 1.5219 (2.1191)  loss_n_40: 0.3278 (0.4401)  loss_n_60: 0.3665 (0.4876)  loss_n_80: 0.3997 (0.5393)  loss_n_100: 0.4333 (0.5877)  triple_100: 0.0000 (0.0278)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0139)  triple_40: 0.0000 (0.0075)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 930/1724]  eta: 0:51:50  lr: 0.000200  loss: 1.4941 (2.1128)  loss_n_40: 0.3350 (0.4391)  loss_n_60: 0.3719 (0.4864)  loss_n_80: 0.3892 (0.5377)  loss_n_100: 0.4114 (0.5860)  triple_100: 0.0000 (0.0275)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0074)  time: 3.9206  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 940/1724]  eta: 0:51:11  lr: 0.000200  loss: 1.4168 (2.1047)  loss_n_40: 0.3260 (0.4379)  loss_n_60: 0.3364 (0.4846)  loss_n_80: 0.3566 (0.5357)  loss_n_100: 0.3901 (0.5835)  triple_100: 0.0000 (0.0272)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0136)  triple_40: 0.0000 (0.0073)  time: 3.9196  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 950/1724]  eta: 0:50:32  lr: 0.000200  loss: 1.3327 (2.0975)  loss_n_40: 0.3179 (0.4368)  loss_n_60: 0.3262 (0.4831)  loss_n_80: 0.3393 (0.5339)  loss_n_100: 0.3444 (0.5814)  triple_100: 0.0000 (0.0269)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0135)  triple_40: 0.0000 (0.0073)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 960/1724]  eta: 0:49:53  lr: 0.000200  loss: 1.2951 (2.0897)  loss_n_40: 0.3179 (0.4355)  loss_n_60: 0.3150 (0.4815)  loss_n_80: 0.3297 (0.5319)  loss_n_100: 0.3444 (0.5791)  triple_100: 0.0000 (0.0266)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0133)  triple_40: 0.0000 (0.0072)  time: 3.9193  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [ 970/1724]  eta: 0:49:13  lr: 0.000200  loss: 1.3394 (2.0828)  loss_n_40: 0.3357 (0.4349)  loss_n_60: 0.3150 (0.4801)  loss_n_80: 0.3284 (0.5300)  loss_n_100: 0.3380 (0.5768)  triple_100: 0.0000 (0.0264)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0132)  triple_40: 0.0000 (0.0071)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 980/1724]  eta: 0:48:34  lr: 0.000200  loss: 1.3223 (2.0752)  loss_n_40: 0.3021 (0.4336)  loss_n_60: 0.3139 (0.4785)  loss_n_80: 0.3368 (0.5281)  loss_n_100: 0.3432 (0.5746)  triple_100: 0.0000 (0.0261)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0131)  triple_40: 0.0000 (0.0070)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [ 990/1724]  eta: 0:47:55  lr: 0.000200  loss: 1.2448 (2.0673)  loss_n_40: 0.2831 (0.4324)  loss_n_60: 0.3007 (0.4768)  loss_n_80: 0.3148 (0.5261)  loss_n_100: 0.3298 (0.5722)  triple_100: 0.0000 (0.0258)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0129)  triple_40: 0.0000 (0.0070)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1000/1724]  eta: 0:47:16  lr: 0.000200  loss: 1.2349 (2.0613)  loss_n_40: 0.2927 (0.4315)  loss_n_60: 0.2998 (0.4754)  loss_n_80: 0.3183 (0.5245)  loss_n_100: 0.3356 (0.5704)  triple_100: 0.0000 (0.0256)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0128)  triple_40: 0.0000 (0.0069)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1010/1724]  eta: 0:46:37  lr: 0.000200  loss: 1.2349 (2.0537)  loss_n_40: 0.2872 (0.4301)  loss_n_60: 0.2944 (0.4736)  loss_n_80: 0.3194 (0.5225)  loss_n_100: 0.3315 (0.5680)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0129)  triple_40: 0.0000 (0.0071)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1020/1724]  eta: 0:45:58  lr: 0.000200  loss: 1.4821 (2.0508)  loss_n_40: 0.3093 (0.4297)  loss_n_60: 0.3174 (0.4729)  loss_n_80: 0.3852 (0.5218)  loss_n_100: 0.4290 (0.5675)  triple_100: 0.0000 (0.0252)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0127)  triple_40: 0.0000 (0.0071)  time: 3.9162  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [1030/1724]  eta: 0:45:18  lr: 0.000200  loss: 1.6735 (2.0465)  loss_n_40: 0.3686 (0.4291)  loss_n_60: 0.3894 (0.4720)  loss_n_80: 0.4269 (0.5207)  loss_n_100: 0.4820 (0.5664)  triple_100: 0.0000 (0.0250)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0126)  triple_40: 0.0000 (0.0070)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1040/1724]  eta: 0:44:39  lr: 0.000200  loss: 1.5663 (2.0421)  loss_n_40: 0.3686 (0.4284)  loss_n_60: 0.3821 (0.4711)  loss_n_80: 0.4107 (0.5197)  loss_n_100: 0.4400 (0.5651)  triple_100: 0.0000 (0.0247)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0125)  triple_40: 0.0000 (0.0069)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1050/1724]  eta: 0:44:00  lr: 0.000200  loss: 1.4987 (2.0379)  loss_n_40: 0.3401 (0.4281)  loss_n_60: 0.3613 (0.4703)  loss_n_80: 0.3846 (0.5185)  loss_n_100: 0.4096 (0.5637)  triple_100: 0.0000 (0.0245)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0124)  triple_40: 0.0000 (0.0069)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1060/1724]  eta: 0:43:21  lr: 0.000200  loss: 1.4412 (2.0325)  loss_n_40: 0.3401 (0.4276)  loss_n_60: 0.3460 (0.4691)  loss_n_80: 0.3682 (0.5171)  loss_n_100: 0.3813 (0.5620)  triple_100: 0.0000 (0.0243)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0123)  triple_40: 0.0000 (0.0068)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1070/1724]  eta: 0:42:42  lr: 0.000200  loss: 1.3799 (2.0260)  loss_n_40: 0.3237 (0.4266)  loss_n_60: 0.3246 (0.4677)  loss_n_80: 0.3435 (0.5154)  loss_n_100: 0.3760 (0.5600)  triple_100: 0.0000 (0.0240)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0121)  triple_40: 0.0000 (0.0067)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1080/1724]  eta: 0:42:02  lr: 0.000200  loss: 1.2981 (2.0191)  loss_n_40: 0.3119 (0.4255)  loss_n_60: 0.3136 (0.4662)  loss_n_80: 0.3357 (0.5136)  loss_n_100: 0.3478 (0.5580)  triple_100: 0.0000 (0.0238)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0067)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1090/1724]  eta: 0:41:23  lr: 0.000200  loss: 1.1945 (2.0117)  loss_n_40: 0.2910 (0.4244)  loss_n_60: 0.2785 (0.4646)  loss_n_80: 0.2959 (0.5117)  loss_n_100: 0.3086 (0.5558)  triple_100: 0.0000 (0.0236)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0066)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1100/1724]  eta: 0:40:44  lr: 0.000200  loss: 1.1958 (2.0062)  loss_n_40: 0.2948 (0.4237)  loss_n_60: 0.2868 (0.4634)  loss_n_80: 0.3048 (0.5102)  loss_n_100: 0.3126 (0.5540)  triple_100: 0.0000 (0.0234)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0118)  triple_40: 0.0000 (0.0068)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1110/1724]  eta: 0:40:05  lr: 0.000200  loss: 1.2415 (1.9996)  loss_n_40: 0.3217 (0.4227)  loss_n_60: 0.2954 (0.4619)  loss_n_80: 0.3048 (0.5084)  loss_n_100: 0.3314 (0.5521)  triple_100: 0.0000 (0.0232)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0117)  triple_40: 0.0000 (0.0068)  time: 3.9190  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [1120/1724]  eta: 0:39:26  lr: 0.000200  loss: 1.2240 (1.9930)  loss_n_40: 0.2948 (0.4217)  loss_n_60: 0.2871 (0.4605)  loss_n_80: 0.3043 (0.5068)  loss_n_100: 0.3224 (0.5501)  triple_100: 0.0000 (0.0230)  triple_80: 0.0000 (0.0127)  triple_60: 0.0000 (0.0116)  triple_40: 0.0000 (0.0067)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1130/1724]  eta: 0:38:47  lr: 0.000200  loss: 1.2540 (2.0031)  loss_n_40: 0.2948 (0.4209)  loss_n_60: 0.2970 (0.4597)  loss_n_80: 0.3144 (0.5058)  loss_n_100: 0.3264 (0.5492)  triple_100: 0.0000 (0.0266)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0087)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1140/1724]  eta: 0:38:07  lr: 0.000200  loss: 1.9500 (2.0042)  loss_n_40: 0.4191 (0.4213)  loss_n_60: 0.4536 (0.4600)  loss_n_80: 0.5005 (0.5061)  loss_n_100: 0.5482 (0.5497)  triple_100: 0.0000 (0.0264)  triple_80: 0.0000 (0.0164)  triple_60: 0.0000 (0.0156)  triple_40: 0.0000 (0.0086)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1150/1724]  eta: 0:37:28  lr: 0.000200  loss: 2.1009 (2.0065)  loss_n_40: 0.4690 (0.4220)  loss_n_60: 0.4909 (0.4604)  loss_n_80: 0.5307 (0.5063)  loss_n_100: 0.5890 (0.5500)  triple_100: 0.0000 (0.0262)  triple_80: 0.0000 (0.0162)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0100)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1160/1724]  eta: 0:36:49  lr: 0.000200  loss: 1.8284 (2.0042)  loss_n_40: 0.4160 (0.4218)  loss_n_60: 0.4189 (0.4599)  loss_n_80: 0.4734 (0.5058)  loss_n_100: 0.5106 (0.5494)  triple_100: 0.0000 (0.0259)  triple_80: 0.0000 (0.0161)  triple_60: 0.0000 (0.0153)  triple_40: 0.0000 (0.0099)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1170/1724]  eta: 0:36:10  lr: 0.000200  loss: 1.6212 (2.0007)  loss_n_40: 0.3775 (0.4214)  loss_n_60: 0.3880 (0.4593)  loss_n_80: 0.4162 (0.5050)  loss_n_100: 0.4425 (0.5483)  triple_100: 0.0000 (0.0257)  triple_80: 0.0000 (0.0160)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0099)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1180/1724]  eta: 0:35:31  lr: 0.000200  loss: 1.4917 (1.9964)  loss_n_40: 0.3466 (0.4208)  loss_n_60: 0.3585 (0.4584)  loss_n_80: 0.3849 (0.5040)  loss_n_100: 0.3906 (0.5471)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0098)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1190/1724]  eta: 0:34:52  lr: 0.000200  loss: 1.4917 (1.9918)  loss_n_40: 0.3439 (0.4202)  loss_n_60: 0.3585 (0.4575)  loss_n_80: 0.3738 (0.5028)  loss_n_100: 0.3798 (0.5456)  triple_100: 0.0000 (0.0253)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0097)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1200/1724]  eta: 0:34:12  lr: 0.000200  loss: 1.5231 (1.9897)  loss_n_40: 0.3623 (0.4198)  loss_n_60: 0.3754 (0.4570)  loss_n_80: 0.3922 (0.5021)  loss_n_100: 0.4067 (0.5449)  triple_100: 0.0000 (0.0251)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0102)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1210/1724]  eta: 0:33:33  lr: 0.000200  loss: 1.6869 (1.9882)  loss_n_40: 0.3744 (0.4196)  loss_n_60: 0.3925 (0.4567)  loss_n_80: 0.4240 (0.5018)  loss_n_100: 0.4709 (0.5446)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0101)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1220/1724]  eta: 0:32:54  lr: 0.000200  loss: 1.6835 (1.9856)  loss_n_40: 0.3938 (0.4196)  loss_n_60: 0.3925 (0.4563)  loss_n_80: 0.4234 (0.5011)  loss_n_100: 0.4630 (0.5439)  triple_100: 0.0000 (0.0247)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0148)  triple_40: 0.0000 (0.0100)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1230/1724]  eta: 0:32:15  lr: 0.000200  loss: 1.6028 (1.9824)  loss_n_40: 0.3838 (0.4191)  loss_n_60: 0.3892 (0.4557)  loss_n_80: 0.3989 (0.5003)  loss_n_100: 0.4222 (0.5429)  triple_100: 0.0000 (0.0245)  triple_80: 0.0000 (0.0152)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0099)  time: 3.9156  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1240/1724]  eta: 0:31:36  lr: 0.000200  loss: 1.5458 (1.9779)  loss_n_40: 0.3572 (0.4186)  loss_n_60: 0.3747 (0.4549)  loss_n_80: 0.3907 (0.4992)  loss_n_100: 0.4121 (0.5415)  triple_100: 0.0000 (0.0243)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0146)  triple_40: 0.0000 (0.0099)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1250/1724]  eta: 0:30:56  lr: 0.000200  loss: 1.4940 (1.9737)  loss_n_40: 0.3441 (0.4181)  loss_n_60: 0.3608 (0.4540)  loss_n_80: 0.3579 (0.4981)  loss_n_100: 0.3774 (0.5403)  triple_100: 0.0000 (0.0241)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0145)  triple_40: 0.0000 (0.0098)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1260/1724]  eta: 0:30:17  lr: 0.000200  loss: 1.4086 (1.9697)  loss_n_40: 0.3379 (0.4177)  loss_n_60: 0.3382 (0.4533)  loss_n_80: 0.3523 (0.4970)  loss_n_100: 0.3683 (0.5390)  triple_100: 0.0000 (0.0239)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0097)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1270/1724]  eta: 0:29:38  lr: 0.000200  loss: 1.2930 (1.9641)  loss_n_40: 0.3230 (0.4168)  loss_n_60: 0.3058 (0.4521)  loss_n_80: 0.3155 (0.4956)  loss_n_100: 0.3488 (0.5373)  triple_100: 0.0000 (0.0237)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0096)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1280/1724]  eta: 0:28:59  lr: 0.000200  loss: 1.2636 (1.9585)  loss_n_40: 0.2988 (0.4159)  loss_n_60: 0.2954 (0.4509)  loss_n_80: 0.3019 (0.4942)  loss_n_100: 0.3099 (0.5357)  triple_100: 0.0000 (0.0235)  triple_80: 0.0000 (0.0146)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0095)  time: 3.9179  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [1290/1724]  eta: 0:28:20  lr: 0.000200  loss: 1.1902 (1.9523)  loss_n_40: 0.2791 (0.4149)  loss_n_60: 0.2782 (0.4495)  loss_n_80: 0.2971 (0.4927)  loss_n_100: 0.3092 (0.5339)  triple_100: 0.0000 (0.0233)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0095)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1300/1724]  eta: 0:27:41  lr: 0.000200  loss: 1.1333 (1.9468)  loss_n_40: 0.2761 (0.4140)  loss_n_60: 0.2748 (0.4483)  loss_n_80: 0.2888 (0.4911)  loss_n_100: 0.2994 (0.5322)  triple_100: 0.0000 (0.0232)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0095)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1310/1724]  eta: 0:27:01  lr: 0.000200  loss: 1.2808 (1.9435)  loss_n_40: 0.2903 (0.4134)  loss_n_60: 0.3049 (0.4475)  loss_n_80: 0.3227 (0.4903)  loss_n_100: 0.3503 (0.5313)  triple_100: 0.0000 (0.0230)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0095)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1320/1724]  eta: 0:26:22  lr: 0.000200  loss: 1.3846 (1.9426)  loss_n_40: 0.3215 (0.4129)  loss_n_60: 0.3206 (0.4467)  loss_n_80: 0.3522 (0.4895)  loss_n_100: 0.3819 (0.5303)  triple_100: 0.0000 (0.0235)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0144)  triple_40: 0.0000 (0.0098)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1330/1724]  eta: 0:25:43  lr: 0.000200  loss: 1.5815 (1.9410)  loss_n_40: 0.3416 (0.4126)  loss_n_60: 0.3660 (0.4464)  loss_n_80: 0.4157 (0.4892)  loss_n_100: 0.4548 (0.5301)  triple_100: 0.0000 (0.0233)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0097)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1340/1724]  eta: 0:25:04  lr: 0.000200  loss: 1.6786 (1.9383)  loss_n_40: 0.3424 (0.4123)  loss_n_60: 0.3835 (0.4459)  loss_n_80: 0.4209 (0.4886)  loss_n_100: 0.4681 (0.5294)  triple_100: 0.0000 (0.0231)  triple_80: 0.0000 (0.0152)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0096)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1350/1724]  eta: 0:24:25  lr: 0.000200  loss: 1.4749 (1.9348)  loss_n_40: 0.3410 (0.4117)  loss_n_60: 0.3392 (0.4452)  loss_n_80: 0.3817 (0.4877)  loss_n_100: 0.4051 (0.5284)  triple_100: 0.0000 (0.0230)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0096)  time: 3.9168  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [1360/1724]  eta: 0:23:46  lr: 0.000200  loss: 1.3967 (1.9308)  loss_n_40: 0.3226 (0.4111)  loss_n_60: 0.3346 (0.4444)  loss_n_80: 0.3462 (0.4867)  loss_n_100: 0.3658 (0.5272)  triple_100: 0.0000 (0.0228)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0095)  time: 3.9179  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [1370/1724]  eta: 0:23:06  lr: 0.000200  loss: 1.4009 (1.9308)  loss_n_40: 0.3360 (0.4110)  loss_n_60: 0.3352 (0.4440)  loss_n_80: 0.3550 (0.4864)  loss_n_100: 0.3658 (0.5269)  triple_100: 0.0000 (0.0231)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0101)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [1380/1724]  eta: 0:22:27  lr: 0.000200  loss: 2.8656 (1.9410)  loss_n_40: 0.4747 (0.4119)  loss_n_60: 0.5695 (0.4460)  loss_n_80: 0.7816 (0.4894)  loss_n_100: 0.8924 (0.5312)  triple_100: 0.0000 (0.0230)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0144)  triple_40: 0.0000 (0.0100)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1390/1724]  eta: 0:21:48  lr: 0.000200  loss: 2.9793 (1.9464)  loss_n_40: 0.4985 (0.4124)  loss_n_60: 0.6513 (0.4471)  loss_n_80: 0.8236 (0.4911)  loss_n_100: 1.0187 (0.5339)  triple_100: 0.0000 (0.0228)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0099)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1400/1724]  eta: 0:21:09  lr: 0.000200  loss: 2.4169 (1.9485)  loss_n_40: 0.4402 (0.4127)  loss_n_60: 0.5487 (0.4477)  loss_n_80: 0.6528 (0.4918)  loss_n_100: 0.7562 (0.5347)  triple_100: 0.0000 (0.0226)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0099)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1410/1724]  eta: 0:20:30  lr: 0.000200  loss: 2.0454 (1.9484)  loss_n_40: 0.4117 (0.4127)  loss_n_60: 0.4749 (0.4478)  loss_n_80: 0.5447 (0.4920)  loss_n_100: 0.5994 (0.5349)  triple_100: 0.0000 (0.0225)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0098)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1420/1724]  eta: 0:19:50  lr: 0.000200  loss: 1.8097 (1.9455)  loss_n_40: 0.3859 (0.4122)  loss_n_60: 0.4147 (0.4472)  loss_n_80: 0.4455 (0.4913)  loss_n_100: 0.4725 (0.5341)  triple_100: 0.0000 (0.0223)  triple_80: 0.0000 (0.0146)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0097)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1430/1724]  eta: 0:19:11  lr: 0.000200  loss: 1.5163 (1.9431)  loss_n_40: 0.3673 (0.4121)  loss_n_60: 0.3734 (0.4468)  loss_n_80: 0.3827 (0.4906)  loss_n_100: 0.4133 (0.5333)  triple_100: 0.0000 (0.0222)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0139)  triple_40: 0.0000 (0.0097)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1440/1724]  eta: 0:18:32  lr: 0.000200  loss: 1.5003 (1.9396)  loss_n_40: 0.3664 (0.4115)  loss_n_60: 0.3709 (0.4461)  loss_n_80: 0.3923 (0.4898)  loss_n_100: 0.4012 (0.5324)  triple_100: 0.0000 (0.0220)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0096)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1450/1724]  eta: 0:17:53  lr: 0.000200  loss: 1.4334 (1.9364)  loss_n_40: 0.3239 (0.4110)  loss_n_60: 0.3343 (0.4454)  loss_n_80: 0.3593 (0.4890)  loss_n_100: 0.3858 (0.5314)  triple_100: 0.0000 (0.0218)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0137)  triple_40: 0.0000 (0.0095)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1460/1724]  eta: 0:17:14  lr: 0.000200  loss: 1.3731 (1.9323)  loss_n_40: 0.3187 (0.4104)  loss_n_60: 0.3257 (0.4446)  loss_n_80: 0.3401 (0.4880)  loss_n_100: 0.3724 (0.5302)  triple_100: 0.0000 (0.0217)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0136)  triple_40: 0.0000 (0.0095)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1470/1724]  eta: 0:16:35  lr: 0.000200  loss: 1.3681 (1.9291)  loss_n_40: 0.3187 (0.4101)  loss_n_60: 0.3257 (0.4439)  loss_n_80: 0.3401 (0.4872)  loss_n_100: 0.3490 (0.5293)  triple_100: 0.0000 (0.0215)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0136)  triple_40: 0.0000 (0.0094)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1480/1724]  eta: 0:15:55  lr: 0.000200  loss: 1.4050 (1.9265)  loss_n_40: 0.3117 (0.4094)  loss_n_60: 0.3244 (0.4432)  loss_n_80: 0.3524 (0.4864)  loss_n_100: 0.3731 (0.5283)  triple_100: 0.0000 (0.0214)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0139)  triple_40: 0.0000 (0.0097)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1490/1724]  eta: 0:15:16  lr: 0.000200  loss: 1.7342 (1.9273)  loss_n_40: 0.3561 (0.4095)  loss_n_60: 0.4014 (0.4434)  loss_n_80: 0.4371 (0.4867)  loss_n_100: 0.4749 (0.5289)  triple_100: 0.0000 (0.0213)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0097)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1500/1724]  eta: 0:14:37  lr: 0.000200  loss: 1.9430 (1.9277)  loss_n_40: 0.4236 (0.4096)  loss_n_60: 0.4695 (0.4436)  loss_n_80: 0.5126 (0.4869)  loss_n_100: 0.5750 (0.5291)  triple_100: 0.0000 (0.0212)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0137)  triple_40: 0.0000 (0.0096)  time: 3.9154  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1510/1724]  eta: 0:13:58  lr: 0.000200  loss: 1.7746 (1.9260)  loss_n_40: 0.4066 (0.4095)  loss_n_60: 0.4245 (0.4433)  loss_n_80: 0.4684 (0.4866)  loss_n_100: 0.4903 (0.5286)  triple_100: 0.0000 (0.0211)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0136)  triple_40: 0.0000 (0.0096)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1520/1724]  eta: 0:13:19  lr: 0.000200  loss: 1.5568 (1.9234)  loss_n_40: 0.3606 (0.4091)  loss_n_60: 0.3710 (0.4428)  loss_n_80: 0.4058 (0.4860)  loss_n_100: 0.4267 (0.5279)  triple_100: 0.0000 (0.0209)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0135)  triple_40: 0.0000 (0.0095)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1530/1724]  eta: 0:12:40  lr: 0.000200  loss: 1.4695 (1.9199)  loss_n_40: 0.3289 (0.4086)  loss_n_60: 0.3536 (0.4421)  loss_n_80: 0.3782 (0.4851)  loss_n_100: 0.3942 (0.5268)  triple_100: 0.0000 (0.0208)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0134)  triple_40: 0.0000 (0.0094)  time: 3.9162  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [1540/1724]  eta: 0:12:00  lr: 0.000200  loss: 1.3685 (1.9164)  loss_n_40: 0.3170 (0.4081)  loss_n_60: 0.3346 (0.4414)  loss_n_80: 0.3489 (0.4842)  loss_n_100: 0.3620 (0.5257)  triple_100: 0.0000 (0.0206)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0133)  triple_40: 0.0000 (0.0094)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1550/1724]  eta: 0:11:21  lr: 0.000200  loss: 1.2310 (1.9119)  loss_n_40: 0.3022 (0.4074)  loss_n_60: 0.3088 (0.4405)  loss_n_80: 0.3133 (0.4831)  loss_n_100: 0.3249 (0.5244)  triple_100: 0.0000 (0.0205)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0132)  triple_40: 0.0000 (0.0093)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1560/1724]  eta: 0:10:42  lr: 0.000200  loss: 1.2113 (1.9074)  loss_n_40: 0.2805 (0.4066)  loss_n_60: 0.2921 (0.4396)  loss_n_80: 0.2988 (0.4820)  loss_n_100: 0.3044 (0.5230)  triple_100: 0.0000 (0.0204)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0131)  triple_40: 0.0000 (0.0092)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1570/1724]  eta: 0:10:03  lr: 0.000200  loss: 1.2113 (1.9037)  loss_n_40: 0.2817 (0.4061)  loss_n_60: 0.2930 (0.4388)  loss_n_80: 0.3087 (0.4810)  loss_n_100: 0.3237 (0.5219)  triple_100: 0.0000 (0.0202)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0131)  triple_40: 0.0000 (0.0092)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1580/1724]  eta: 0:09:24  lr: 0.000200  loss: 1.2298 (1.8996)  loss_n_40: 0.2974 (0.4054)  loss_n_60: 0.2996 (0.4380)  loss_n_80: 0.3194 (0.4800)  loss_n_100: 0.3237 (0.5207)  triple_100: 0.0000 (0.0201)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0130)  triple_40: 0.0000 (0.0091)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1590/1724]  eta: 0:08:44  lr: 0.000200  loss: 1.1712 (1.8949)  loss_n_40: 0.2756 (0.4046)  loss_n_60: 0.2762 (0.4370)  loss_n_80: 0.3060 (0.4789)  loss_n_100: 0.3058 (0.5193)  triple_100: 0.0000 (0.0200)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0129)  triple_40: 0.0000 (0.0091)  time: 3.9169  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [1600/1724]  eta: 0:08:05  lr: 0.000200  loss: 1.1712 (1.8907)  loss_n_40: 0.2828 (0.4040)  loss_n_60: 0.2857 (0.4361)  loss_n_80: 0.2987 (0.4778)  loss_n_100: 0.3058 (0.5179)  triple_100: 0.0000 (0.0199)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0128)  triple_40: 0.0000 (0.0090)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1610/1724]  eta: 0:07:26  lr: 0.000200  loss: 1.2861 (1.9085)  loss_n_40: 0.3137 (0.4041)  loss_n_60: 0.3130 (0.4368)  loss_n_80: 0.3174 (0.4790)  loss_n_100: 0.3131 (0.5197)  triple_100: 0.0000 (0.0272)  triple_80: 0.0000 (0.0164)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0103)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1620/1724]  eta: 0:06:47  lr: 0.000200  loss: 5.1442 (1.9322)  loss_n_40: 0.6596 (0.4072)  loss_n_60: 1.0282 (0.4421)  loss_n_80: 1.3197 (0.4861)  loss_n_100: 1.5697 (0.5277)  triple_100: 0.0000 (0.0273)  triple_80: 0.0000 (0.0166)  triple_60: 0.0000 (0.0150)  triple_40: 0.0000 (0.0103)  time: 3.9154  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1630/1724]  eta: 0:06:08  lr: 0.000200  loss: 5.1442 (1.9500)  loss_n_40: 0.8565 (0.4098)  loss_n_60: 1.1860 (0.4460)  loss_n_80: 1.4525 (0.4911)  loss_n_100: 1.7050 (0.5337)  triple_100: 0.0000 (0.0278)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0102)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1640/1724]  eta: 0:05:29  lr: 0.000200  loss: 4.2264 (1.9614)  loss_n_40: 0.8149 (0.4121)  loss_n_60: 0.9797 (0.4487)  loss_n_80: 1.1403 (0.4944)  loss_n_100: 1.2672 (0.5373)  triple_100: 0.0000 (0.0276)  triple_80: 0.0000 (0.0164)  triple_60: 0.0000 (0.0148)  triple_40: 0.0000 (0.0101)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1650/1724]  eta: 0:04:49  lr: 0.000200  loss: 3.4829 (1.9698)  loss_n_40: 0.7134 (0.4138)  loss_n_60: 0.8185 (0.4508)  loss_n_80: 0.9242 (0.4968)  loss_n_100: 0.9842 (0.5399)  triple_100: 0.0000 (0.0275)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0101)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1660/1724]  eta: 0:04:10  lr: 0.000200  loss: 2.8348 (1.9734)  loss_n_40: 0.6128 (0.4145)  loss_n_60: 0.6646 (0.4517)  loss_n_80: 0.7895 (0.4979)  loss_n_100: 0.8509 (0.5411)  triple_100: 0.0000 (0.0273)  triple_80: 0.0000 (0.0162)  triple_60: 0.0000 (0.0146)  triple_40: 0.0000 (0.0100)  time: 3.9170  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [1670/1724]  eta: 0:03:31  lr: 0.000200  loss: 2.5257 (1.9773)  loss_n_40: 0.5353 (0.4154)  loss_n_60: 0.5945 (0.4528)  loss_n_80: 0.6687 (0.4990)  loss_n_100: 0.7249 (0.5424)  triple_100: 0.0000 (0.0271)  triple_80: 0.0000 (0.0161)  triple_60: 0.0000 (0.0145)  triple_40: 0.0000 (0.0100)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1680/1724]  eta: 0:02:52  lr: 0.000200  loss: 2.2810 (1.9782)  loss_n_40: 0.4843 (0.4156)  loss_n_60: 0.5529 (0.4531)  loss_n_80: 0.5927 (0.4993)  loss_n_100: 0.6793 (0.5428)  triple_100: 0.0000 (0.0270)  triple_80: 0.0000 (0.0160)  triple_60: 0.0000 (0.0145)  triple_40: 0.0000 (0.0099)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1690/1724]  eta: 0:02:13  lr: 0.000200  loss: 2.1483 (1.9798)  loss_n_40: 0.4600 (0.4160)  loss_n_60: 0.5158 (0.4536)  loss_n_80: 0.5536 (0.4998)  loss_n_100: 0.6136 (0.5434)  triple_100: 0.0000 (0.0268)  triple_80: 0.0000 (0.0159)  triple_60: 0.0000 (0.0144)  triple_40: 0.0000 (0.0098)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1700/1724]  eta: 0:01:34  lr: 0.000200  loss: 1.9866 (1.9793)  loss_n_40: 0.4398 (0.4162)  loss_n_60: 0.4607 (0.4536)  loss_n_80: 0.5009 (0.4996)  loss_n_100: 0.5434 (0.5433)  triple_100: 0.0000 (0.0266)  triple_80: 0.0000 (0.0159)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0098)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1710/1724]  eta: 0:00:54  lr: 0.000200  loss: 1.7474 (1.9776)  loss_n_40: 0.4203 (0.4160)  loss_n_60: 0.4141 (0.4533)  loss_n_80: 0.4416 (0.4992)  loss_n_100: 0.4852 (0.5429)  triple_100: 0.0000 (0.0265)  triple_80: 0.0000 (0.0158)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0097)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:15]  [1720/1724]  eta: 0:00:15  lr: 0.000200  loss: 1.5961 (1.9752)  loss_n_40: 0.3731 (0.4157)  loss_n_60: 0.3859 (0.4529)  loss_n_80: 0.4034 (0.4986)  loss_n_100: 0.4339 (0.5422)  triple_100: 0.0000 (0.0263)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0097)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15]  [1723/1724]  eta: 0:00:03  lr: 0.000200  loss: 1.5961 (1.9747)  loss_n_40: 0.3673 (0.4157)  loss_n_60: 0.3859 (0.4528)  loss_n_80: 0.4034 (0.4985)  loss_n_100: 0.4435 (0.5421)  triple_100: 0.0000 (0.0263)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0097)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:15] Total time: 1:52:34 (3.9177 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 1.5961 (1.9747)  loss_n_40: 0.3673 (0.4157)  loss_n_60: 0.3859 (0.4528)  loss_n_80: 0.4034 (0.4985)  loss_n_100: 0.4435 (0.5421)  triple_100: 0.0000 (0.0263)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0097)\n",
      "Valid: [epoch:15]  [  0/845]  eta: 0:10:22  loss: 1.6060 (1.6060)  loss_n_40: 0.3376 (0.3376)  loss_n_60: 0.3935 (0.3935)  loss_n_80: 0.3964 (0.3964)  loss_n_100: 0.4785 (0.4785)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7366  data: 0.4005  max mem: 46473\n",
      "Valid: [epoch:15]  [ 10/845]  eta: 0:05:09  loss: 1.7052 (1.5683)  loss_n_40: 0.3376 (0.3438)  loss_n_60: 0.4061 (0.3794)  loss_n_80: 0.4187 (0.3975)  loss_n_100: 0.4865 (0.4476)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3705  data: 0.0365  max mem: 46473\n",
      "Valid: [epoch:15]  [ 20/845]  eta: 0:04:51  loss: 1.6772 (1.6240)  loss_n_40: 0.3348 (0.3598)  loss_n_60: 0.3940 (0.3908)  loss_n_80: 0.4187 (0.4114)  loss_n_100: 0.4865 (0.4619)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [ 30/845]  eta: 0:04:42  loss: 1.6772 (1.6965)  loss_n_40: 0.3704 (0.3818)  loss_n_60: 0.4108 (0.4107)  loss_n_80: 0.4437 (0.4282)  loss_n_100: 0.5003 (0.4757)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [ 40/845]  eta: 0:04:36  loss: 1.4851 (1.6383)  loss_n_40: 0.3440 (0.3706)  loss_n_60: 0.3605 (0.3973)  loss_n_80: 0.3545 (0.4143)  loss_n_100: 0.3959 (0.4562)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [ 50/845]  eta: 0:04:31  loss: 1.4209 (1.6071)  loss_n_40: 0.3185 (0.3605)  loss_n_60: 0.3266 (0.3878)  loss_n_80: 0.3529 (0.4074)  loss_n_100: 0.3734 (0.4514)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [ 60/845]  eta: 0:04:27  loss: 1.4992 (1.5978)  loss_n_40: 0.3373 (0.3604)  loss_n_60: 0.3543 (0.3849)  loss_n_80: 0.3774 (0.4046)  loss_n_100: 0.4185 (0.4480)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [ 70/845]  eta: 0:04:23  loss: 1.4926 (1.5840)  loss_n_40: 0.3373 (0.3569)  loss_n_60: 0.3487 (0.3790)  loss_n_80: 0.3738 (0.3990)  loss_n_100: 0.4185 (0.4422)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0070)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [ 80/845]  eta: 0:04:19  loss: 1.4926 (1.5875)  loss_n_40: 0.3366 (0.3566)  loss_n_60: 0.3487 (0.3798)  loss_n_80: 0.3738 (0.4003)  loss_n_100: 0.4337 (0.4448)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0061)  time: 0.3338  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:15]  [ 90/845]  eta: 0:04:15  loss: 1.4634 (1.5777)  loss_n_40: 0.3090 (0.3537)  loss_n_60: 0.3463 (0.3781)  loss_n_80: 0.3825 (0.3981)  loss_n_100: 0.4275 (0.4425)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0054)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [100/845]  eta: 0:04:11  loss: 1.4660 (1.5761)  loss_n_40: 0.3278 (0.3586)  loss_n_60: 0.3463 (0.3770)  loss_n_80: 0.3680 (0.3956)  loss_n_100: 0.4180 (0.4400)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0049)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [110/845]  eta: 0:04:08  loss: 1.4684 (1.5653)  loss_n_40: 0.3371 (0.3552)  loss_n_60: 0.3469 (0.3744)  loss_n_80: 0.3680 (0.3938)  loss_n_100: 0.4180 (0.4375)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0044)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [120/845]  eta: 0:04:04  loss: 1.3657 (1.5529)  loss_n_40: 0.3177 (0.3529)  loss_n_60: 0.3284 (0.3713)  loss_n_80: 0.3454 (0.3907)  loss_n_100: 0.3779 (0.4339)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0041)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [130/845]  eta: 0:04:00  loss: 1.4059 (1.5577)  loss_n_40: 0.3177 (0.3568)  loss_n_60: 0.3314 (0.3719)  loss_n_80: 0.3616 (0.3915)  loss_n_100: 0.3788 (0.4337)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0038)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [140/845]  eta: 0:03:57  loss: 1.4059 (1.5599)  loss_n_40: 0.3181 (0.3591)  loss_n_60: 0.3314 (0.3725)  loss_n_80: 0.3633 (0.3912)  loss_n_100: 0.3964 (0.4336)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0035)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [150/845]  eta: 0:03:53  loss: 1.4159 (1.5576)  loss_n_40: 0.3165 (0.3579)  loss_n_60: 0.3334 (0.3717)  loss_n_80: 0.3585 (0.3909)  loss_n_100: 0.3964 (0.4337)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0033)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [160/845]  eta: 0:03:50  loss: 1.4433 (1.5542)  loss_n_40: 0.3221 (0.3570)  loss_n_60: 0.3361 (0.3710)  loss_n_80: 0.3585 (0.3900)  loss_n_100: 0.4013 (0.4332)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0031)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [170/845]  eta: 0:03:47  loss: 1.5547 (1.5545)  loss_n_40: 0.3403 (0.3557)  loss_n_60: 0.3673 (0.3710)  loss_n_80: 0.3878 (0.3905)  loss_n_100: 0.4130 (0.4344)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0029)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [180/845]  eta: 0:03:43  loss: 1.5788 (1.5553)  loss_n_40: 0.3403 (0.3572)  loss_n_60: 0.3754 (0.3706)  loss_n_80: 0.3911 (0.3910)  loss_n_100: 0.4137 (0.4337)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0027)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [190/845]  eta: 0:03:40  loss: 1.4871 (1.5549)  loss_n_40: 0.3371 (0.3561)  loss_n_60: 0.3574 (0.3706)  loss_n_80: 0.3907 (0.3915)  loss_n_100: 0.4137 (0.4340)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0026)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [200/845]  eta: 0:03:36  loss: 1.3705 (1.5528)  loss_n_40: 0.3314 (0.3569)  loss_n_60: 0.3300 (0.3701)  loss_n_80: 0.3397 (0.3906)  loss_n_100: 0.3764 (0.4327)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0025)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [210/845]  eta: 0:03:33  loss: 1.2295 (1.5451)  loss_n_40: 0.2790 (0.3574)  loss_n_60: 0.2989 (0.3684)  loss_n_80: 0.3251 (0.3878)  loss_n_100: 0.3483 (0.4292)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0023)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [220/845]  eta: 0:03:29  loss: 1.2295 (1.5390)  loss_n_40: 0.2762 (0.3559)  loss_n_60: 0.2972 (0.3670)  loss_n_80: 0.3171 (0.3863)  loss_n_100: 0.3483 (0.4276)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0022)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [230/845]  eta: 0:03:26  loss: 1.3348 (1.5344)  loss_n_40: 0.3283 (0.3546)  loss_n_60: 0.3124 (0.3663)  loss_n_80: 0.3296 (0.3853)  loss_n_100: 0.3517 (0.4261)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0021)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [240/845]  eta: 0:03:23  loss: 1.3661 (1.5331)  loss_n_40: 0.3313 (0.3549)  loss_n_60: 0.3264 (0.3658)  loss_n_80: 0.3497 (0.3853)  loss_n_100: 0.3665 (0.4251)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0020)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [250/845]  eta: 0:03:19  loss: 1.4864 (1.5319)  loss_n_40: 0.3313 (0.3542)  loss_n_60: 0.3449 (0.3655)  loss_n_80: 0.3759 (0.3851)  loss_n_100: 0.3859 (0.4252)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0020)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [260/845]  eta: 0:03:16  loss: 1.5053 (1.5379)  loss_n_40: 0.3370 (0.3559)  loss_n_60: 0.3502 (0.3671)  loss_n_80: 0.3828 (0.3863)  loss_n_100: 0.4218 (0.4266)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0019)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [270/845]  eta: 0:03:12  loss: 1.7331 (1.5501)  loss_n_40: 0.3592 (0.3591)  loss_n_60: 0.4011 (0.3702)  loss_n_80: 0.4234 (0.3892)  loss_n_100: 0.4591 (0.4298)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0018)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [280/845]  eta: 0:03:09  loss: 1.3304 (1.5420)  loss_n_40: 0.3229 (0.3570)  loss_n_60: 0.3190 (0.3683)  loss_n_80: 0.3381 (0.3873)  loss_n_100: 0.3685 (0.4276)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0018)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [290/845]  eta: 0:03:06  loss: 1.3171 (1.5402)  loss_n_40: 0.3043 (0.3571)  loss_n_60: 0.3125 (0.3682)  loss_n_80: 0.3325 (0.3864)  loss_n_100: 0.3554 (0.4268)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0017)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [300/845]  eta: 0:03:02  loss: 1.5731 (1.5424)  loss_n_40: 0.3450 (0.3577)  loss_n_60: 0.3697 (0.3687)  loss_n_80: 0.3969 (0.3875)  loss_n_100: 0.4194 (0.4268)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0016)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [310/845]  eta: 0:02:59  loss: 1.5731 (1.5443)  loss_n_40: 0.3445 (0.3579)  loss_n_60: 0.3697 (0.3692)  loss_n_80: 0.4004 (0.3880)  loss_n_100: 0.4256 (0.4276)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0016)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [320/845]  eta: 0:02:56  loss: 1.5047 (1.5474)  loss_n_40: 0.3313 (0.3586)  loss_n_60: 0.3503 (0.3699)  loss_n_80: 0.3831 (0.3890)  loss_n_100: 0.4369 (0.4284)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0015)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [330/845]  eta: 0:02:52  loss: 1.6675 (1.5552)  loss_n_40: 0.3629 (0.3620)  loss_n_60: 0.3804 (0.3715)  loss_n_80: 0.4126 (0.3905)  loss_n_100: 0.4494 (0.4297)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0015)  time: 0.3342  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:15]  [340/845]  eta: 0:02:49  loss: 1.7292 (1.5578)  loss_n_40: 0.3812 (0.3628)  loss_n_60: 0.4087 (0.3719)  loss_n_80: 0.4410 (0.3911)  loss_n_100: 0.4852 (0.4306)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0014)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [350/845]  eta: 0:02:45  loss: 1.6557 (1.5621)  loss_n_40: 0.3812 (0.3641)  loss_n_60: 0.3925 (0.3731)  loss_n_80: 0.4127 (0.3920)  loss_n_100: 0.4288 (0.4315)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0014)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [360/845]  eta: 0:02:42  loss: 1.6557 (1.5696)  loss_n_40: 0.3769 (0.3659)  loss_n_60: 0.3925 (0.3750)  loss_n_80: 0.4127 (0.3939)  loss_n_100: 0.4482 (0.4334)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0014)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [370/845]  eta: 0:02:39  loss: 1.5717 (1.5704)  loss_n_40: 0.3506 (0.3654)  loss_n_60: 0.3759 (0.3751)  loss_n_80: 0.3887 (0.3944)  loss_n_100: 0.4370 (0.4341)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0013)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [380/845]  eta: 0:02:35  loss: 1.5250 (1.5690)  loss_n_40: 0.3378 (0.3647)  loss_n_60: 0.3528 (0.3747)  loss_n_80: 0.3851 (0.3942)  loss_n_100: 0.4271 (0.4341)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0013)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [390/845]  eta: 0:02:32  loss: 1.5815 (1.5718)  loss_n_40: 0.3458 (0.3656)  loss_n_60: 0.3747 (0.3755)  loss_n_80: 0.3949 (0.3945)  loss_n_100: 0.4662 (0.4350)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0013)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [400/845]  eta: 0:02:29  loss: 1.5991 (1.5753)  loss_n_40: 0.3687 (0.3665)  loss_n_60: 0.3839 (0.3763)  loss_n_80: 0.4044 (0.3954)  loss_n_100: 0.4654 (0.4358)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0012)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [410/845]  eta: 0:02:25  loss: 1.5934 (1.5755)  loss_n_40: 0.3590 (0.3661)  loss_n_60: 0.3839 (0.3765)  loss_n_80: 0.4001 (0.3955)  loss_n_100: 0.4594 (0.4362)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0012)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [420/845]  eta: 0:02:22  loss: 1.5818 (1.5755)  loss_n_40: 0.3328 (0.3658)  loss_n_60: 0.3770 (0.3766)  loss_n_80: 0.3819 (0.3953)  loss_n_100: 0.4410 (0.4366)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0012)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [430/845]  eta: 0:02:19  loss: 1.5649 (1.5726)  loss_n_40: 0.3307 (0.3648)  loss_n_60: 0.3748 (0.3759)  loss_n_80: 0.3675 (0.3947)  loss_n_100: 0.4155 (0.4360)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0011)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [440/845]  eta: 0:02:15  loss: 1.4412 (1.5714)  loss_n_40: 0.3219 (0.3640)  loss_n_60: 0.3373 (0.3757)  loss_n_80: 0.3558 (0.3946)  loss_n_100: 0.3880 (0.4360)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0011)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [450/845]  eta: 0:02:12  loss: 1.3424 (1.5686)  loss_n_40: 0.2800 (0.3631)  loss_n_60: 0.3244 (0.3749)  loss_n_80: 0.3546 (0.3941)  loss_n_100: 0.3835 (0.4354)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0011)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [460/845]  eta: 0:02:08  loss: 1.4838 (1.5705)  loss_n_40: 0.3214 (0.3642)  loss_n_60: 0.3325 (0.3752)  loss_n_80: 0.3560 (0.3943)  loss_n_100: 0.4136 (0.4357)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0011)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [470/845]  eta: 0:02:05  loss: 1.6180 (1.5771)  loss_n_40: 0.3688 (0.3667)  loss_n_60: 0.3755 (0.3767)  loss_n_80: 0.4215 (0.3957)  loss_n_100: 0.4661 (0.4370)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [480/845]  eta: 0:02:02  loss: 1.5441 (1.5766)  loss_n_40: 0.3401 (0.3660)  loss_n_60: 0.3740 (0.3764)  loss_n_80: 0.3966 (0.3958)  loss_n_100: 0.4563 (0.4374)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [490/845]  eta: 0:01:58  loss: 1.4842 (1.5739)  loss_n_40: 0.3334 (0.3652)  loss_n_60: 0.3406 (0.3758)  loss_n_80: 0.3688 (0.3952)  loss_n_100: 0.4195 (0.4367)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [500/845]  eta: 0:01:55  loss: 1.5504 (1.5768)  loss_n_40: 0.3336 (0.3656)  loss_n_60: 0.3530 (0.3765)  loss_n_80: 0.4077 (0.3960)  loss_n_100: 0.4431 (0.4378)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [510/845]  eta: 0:01:52  loss: 1.7004 (1.5790)  loss_n_40: 0.3473 (0.3662)  loss_n_60: 0.4165 (0.3770)  loss_n_80: 0.4255 (0.3966)  loss_n_100: 0.4562 (0.4382)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [520/845]  eta: 0:01:48  loss: 1.3961 (1.5773)  loss_n_40: 0.3431 (0.3661)  loss_n_60: 0.3191 (0.3765)  loss_n_80: 0.3530 (0.3960)  loss_n_100: 0.3940 (0.4377)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0009)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [530/845]  eta: 0:01:45  loss: 1.3590 (1.5761)  loss_n_40: 0.3038 (0.3661)  loss_n_60: 0.3045 (0.3761)  loss_n_80: 0.3450 (0.3955)  loss_n_100: 0.3617 (0.4374)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0009)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [540/845]  eta: 0:01:42  loss: 1.3764 (1.5794)  loss_n_40: 0.3414 (0.3666)  loss_n_60: 0.3169 (0.3769)  loss_n_80: 0.3433 (0.3965)  loss_n_100: 0.3748 (0.4386)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0009)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [550/845]  eta: 0:01:38  loss: 1.3764 (1.5758)  loss_n_40: 0.3414 (0.3654)  loss_n_60: 0.3185 (0.3761)  loss_n_80: 0.3433 (0.3956)  loss_n_100: 0.3768 (0.4378)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0009)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [560/845]  eta: 0:01:35  loss: 1.2357 (1.5710)  loss_n_40: 0.3022 (0.3643)  loss_n_60: 0.2835 (0.3749)  loss_n_80: 0.3147 (0.3945)  loss_n_100: 0.3385 (0.4365)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0009)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [570/845]  eta: 0:01:32  loss: 1.2757 (1.5707)  loss_n_40: 0.3146 (0.3640)  loss_n_60: 0.2978 (0.3748)  loss_n_80: 0.3297 (0.3945)  loss_n_100: 0.3410 (0.4366)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0009)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [580/845]  eta: 0:01:28  loss: 1.5171 (1.5729)  loss_n_40: 0.3273 (0.3642)  loss_n_60: 0.3565 (0.3753)  loss_n_80: 0.3890 (0.3951)  loss_n_100: 0.4390 (0.4374)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0008)  time: 0.3343  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:15]  [590/845]  eta: 0:01:25  loss: 1.5816 (1.5732)  loss_n_40: 0.3457 (0.3644)  loss_n_60: 0.3786 (0.3753)  loss_n_80: 0.3945 (0.3951)  loss_n_100: 0.4495 (0.4375)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0008)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [600/845]  eta: 0:01:22  loss: 1.5416 (1.5732)  loss_n_40: 0.3457 (0.3647)  loss_n_60: 0.3713 (0.3753)  loss_n_80: 0.3727 (0.3950)  loss_n_100: 0.4291 (0.4373)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0008)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [610/845]  eta: 0:01:18  loss: 1.6003 (1.5759)  loss_n_40: 0.3791 (0.3653)  loss_n_60: 0.3906 (0.3759)  loss_n_80: 0.3998 (0.3956)  loss_n_100: 0.4478 (0.4383)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0008)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [620/845]  eta: 0:01:15  loss: 1.6643 (1.5770)  loss_n_40: 0.3838 (0.3652)  loss_n_60: 0.3921 (0.3762)  loss_n_80: 0.4088 (0.3959)  loss_n_100: 0.4478 (0.4388)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0008)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [630/845]  eta: 0:01:11  loss: 1.6643 (1.5790)  loss_n_40: 0.3674 (0.3658)  loss_n_60: 0.3926 (0.3766)  loss_n_80: 0.4088 (0.3964)  loss_n_100: 0.4478 (0.4394)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0008)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [640/845]  eta: 0:01:08  loss: 1.5678 (1.5783)  loss_n_40: 0.3605 (0.3654)  loss_n_60: 0.3926 (0.3764)  loss_n_80: 0.3878 (0.3964)  loss_n_100: 0.4093 (0.4393)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0008)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [650/845]  eta: 0:01:05  loss: 1.2947 (1.5761)  loss_n_40: 0.3193 (0.3648)  loss_n_60: 0.3000 (0.3759)  loss_n_80: 0.3281 (0.3960)  loss_n_100: 0.3485 (0.4387)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0008)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [660/845]  eta: 0:01:01  loss: 1.3685 (1.5736)  loss_n_40: 0.2989 (0.3641)  loss_n_60: 0.3302 (0.3753)  loss_n_80: 0.3588 (0.3954)  loss_n_100: 0.3684 (0.4381)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0007)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [670/845]  eta: 0:00:58  loss: 1.5224 (1.5740)  loss_n_40: 0.3268 (0.3642)  loss_n_60: 0.3503 (0.3752)  loss_n_80: 0.3749 (0.3956)  loss_n_100: 0.4530 (0.4382)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0007)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [680/845]  eta: 0:00:55  loss: 1.5985 (1.5728)  loss_n_40: 0.3478 (0.3640)  loss_n_60: 0.3885 (0.3750)  loss_n_80: 0.3927 (0.3952)  loss_n_100: 0.4271 (0.4379)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0007)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [690/845]  eta: 0:00:51  loss: 1.5090 (1.5724)  loss_n_40: 0.3310 (0.3637)  loss_n_60: 0.3443 (0.3749)  loss_n_80: 0.3889 (0.3952)  loss_n_100: 0.4218 (0.4379)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0007)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [700/845]  eta: 0:00:48  loss: 1.5967 (1.5734)  loss_n_40: 0.3310 (0.3641)  loss_n_60: 0.3697 (0.3753)  loss_n_80: 0.3889 (0.3953)  loss_n_100: 0.4024 (0.4380)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0007)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [710/845]  eta: 0:00:45  loss: 1.5967 (1.5753)  loss_n_40: 0.3473 (0.3650)  loss_n_60: 0.3729 (0.3759)  loss_n_80: 0.3945 (0.3957)  loss_n_100: 0.4130 (0.4380)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0007)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [720/845]  eta: 0:00:41  loss: 1.5571 (1.5749)  loss_n_40: 0.3268 (0.3652)  loss_n_60: 0.3608 (0.3757)  loss_n_80: 0.3820 (0.3956)  loss_n_100: 0.4118 (0.4378)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0007)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [730/845]  eta: 0:00:38  loss: 1.4253 (1.5778)  loss_n_40: 0.3316 (0.3656)  loss_n_60: 0.3349 (0.3762)  loss_n_80: 0.3527 (0.3964)  loss_n_100: 0.3746 (0.4389)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0007)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [740/845]  eta: 0:00:35  loss: 1.3731 (1.5779)  loss_n_40: 0.3316 (0.3657)  loss_n_60: 0.3239 (0.3762)  loss_n_80: 0.3478 (0.3963)  loss_n_100: 0.3696 (0.4387)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0011)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [750/845]  eta: 0:00:31  loss: 1.5461 (1.5801)  loss_n_40: 0.3401 (0.3661)  loss_n_60: 0.3672 (0.3767)  loss_n_80: 0.3964 (0.3969)  loss_n_100: 0.4422 (0.4394)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0011)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [760/845]  eta: 0:00:28  loss: 1.5770 (1.5791)  loss_n_40: 0.3525 (0.3659)  loss_n_60: 0.3672 (0.3764)  loss_n_80: 0.3978 (0.3967)  loss_n_100: 0.4426 (0.4390)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0011)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [770/845]  eta: 0:00:25  loss: 1.5510 (1.5819)  loss_n_40: 0.3399 (0.3669)  loss_n_60: 0.3618 (0.3774)  loss_n_80: 0.3923 (0.3971)  loss_n_100: 0.4426 (0.4395)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0011)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [780/845]  eta: 0:00:21  loss: 1.2978 (1.5783)  loss_n_40: 0.3045 (0.3659)  loss_n_60: 0.3110 (0.3765)  loss_n_80: 0.3332 (0.3963)  loss_n_100: 0.3594 (0.4386)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0011)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [790/845]  eta: 0:00:18  loss: 1.2486 (1.5789)  loss_n_40: 0.3025 (0.3658)  loss_n_60: 0.3021 (0.3766)  loss_n_80: 0.3332 (0.3965)  loss_n_100: 0.3515 (0.4389)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [800/845]  eta: 0:00:15  loss: 1.4856 (1.5778)  loss_n_40: 0.3240 (0.3652)  loss_n_60: 0.3438 (0.3763)  loss_n_80: 0.3732 (0.3963)  loss_n_100: 0.4391 (0.4389)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [810/845]  eta: 0:00:11  loss: 1.5917 (1.5790)  loss_n_40: 0.3442 (0.3652)  loss_n_60: 0.3847 (0.3766)  loss_n_80: 0.3922 (0.3967)  loss_n_100: 0.4613 (0.4395)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [820/845]  eta: 0:00:08  loss: 1.5717 (1.5773)  loss_n_40: 0.3442 (0.3649)  loss_n_60: 0.3726 (0.3762)  loss_n_80: 0.3922 (0.3963)  loss_n_100: 0.3926 (0.4389)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [830/845]  eta: 0:00:05  loss: 1.5217 (1.5782)  loss_n_40: 0.3449 (0.3648)  loss_n_60: 0.3589 (0.3764)  loss_n_80: 0.3815 (0.3966)  loss_n_100: 0.3936 (0.4394)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3343  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:15]  [840/845]  eta: 0:00:01  loss: 1.6049 (1.5804)  loss_n_40: 0.3527 (0.3654)  loss_n_60: 0.3759 (0.3769)  loss_n_80: 0.4094 (0.3972)  loss_n_100: 0.4415 (0.4399)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15]  [844/845]  eta: 0:00:00  loss: 1.5782 (1.5790)  loss_n_40: 0.3527 (0.3651)  loss_n_60: 0.3602 (0.3766)  loss_n_80: 0.4003 (0.3968)  loss_n_100: 0.4286 (0.4395)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:15] Total time: 0:04:42 (0.3348 s / it)\n",
      "Averaged stats: loss: 1.5782 (1.5790)  loss_n_40: 0.3527 (0.3651)  loss_n_60: 0.3602 (0.3766)  loss_n_80: 0.4003 (0.3968)  loss_n_100: 0.4286 (0.4395)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0010)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_15_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 0.440%\n",
      "Min loss_n_100: 0.440\n",
      "Best Epoch: 15.000\n",
      "Train: [epoch:16]  [   0/1724]  eta: 1:59:45  lr: 0.000200  loss: 1.5153 (1.5153)  loss_n_40: 0.3391 (0.3391)  loss_n_60: 0.3674 (0.3674)  loss_n_80: 0.3865 (0.3865)  loss_n_100: 0.4224 (0.4224)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1677  data: 0.3918  max mem: 46473\n",
      "Train: [epoch:16]  [  10/1724]  eta: 1:52:32  lr: 0.000200  loss: 1.6196 (1.6811)  loss_n_40: 0.3645 (0.3801)  loss_n_60: 0.3999 (0.4066)  loss_n_80: 0.4213 (0.4226)  loss_n_100: 0.4774 (0.4632)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0000)  time: 3.9397  data: 0.0358  max mem: 46473\n",
      "Train: [epoch:16]  [  20/1724]  eta: 1:51:34  lr: 0.000200  loss: 1.6631 (1.6917)  loss_n_40: 0.3869 (0.3850)  loss_n_60: 0.3999 (0.4073)  loss_n_80: 0.4286 (0.4243)  loss_n_100: 0.4774 (0.4706)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0000)  time: 3.9168  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [  30/1724]  eta: 1:50:48  lr: 0.000200  loss: 1.5486 (1.6335)  loss_n_40: 0.3607 (0.3725)  loss_n_60: 0.3767 (0.3910)  loss_n_80: 0.3930 (0.4105)  loss_n_100: 0.4401 (0.4549)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0030)  triple_40: 0.0000 (0.0016)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [  40/1724]  eta: 1:50:06  lr: 0.000200  loss: 1.5344 (1.6265)  loss_n_40: 0.3369 (0.3726)  loss_n_60: 0.3619 (0.3888)  loss_n_80: 0.3930 (0.4112)  loss_n_100: 0.4293 (0.4503)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0012)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [  50/1724]  eta: 1:49:25  lr: 0.000200  loss: 1.5126 (1.6105)  loss_n_40: 0.3555 (0.3710)  loss_n_60: 0.3612 (0.3856)  loss_n_80: 0.3917 (0.4074)  loss_n_100: 0.4207 (0.4436)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0018)  triple_40: 0.0000 (0.0010)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [  60/1724]  eta: 1:48:44  lr: 0.000200  loss: 1.4008 (1.5824)  loss_n_40: 0.3252 (0.3653)  loss_n_60: 0.3337 (0.3791)  loss_n_80: 0.3668 (0.4003)  loss_n_100: 0.3818 (0.4336)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0015)  triple_40: 0.0000 (0.0025)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [  70/1724]  eta: 1:48:04  lr: 0.000200  loss: 1.4008 (1.5692)  loss_n_40: 0.3253 (0.3622)  loss_n_60: 0.3497 (0.3767)  loss_n_80: 0.3668 (0.3978)  loss_n_100: 0.3750 (0.4290)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0013)  triple_40: 0.0000 (0.0022)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [  80/1724]  eta: 1:47:24  lr: 0.000200  loss: 1.3668 (1.5512)  loss_n_40: 0.3378 (0.3594)  loss_n_60: 0.3484 (0.3727)  loss_n_80: 0.3429 (0.3928)  loss_n_100: 0.3564 (0.4231)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0012)  triple_40: 0.0000 (0.0019)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [  90/1724]  eta: 1:46:44  lr: 0.000200  loss: 1.3800 (1.5634)  loss_n_40: 0.3482 (0.3588)  loss_n_60: 0.3353 (0.3711)  loss_n_80: 0.3564 (0.3912)  loss_n_100: 0.3714 (0.4195)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0048)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0152)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 100/1724]  eta: 1:46:04  lr: 0.000200  loss: 1.5324 (1.5861)  loss_n_40: 0.3549 (0.3628)  loss_n_60: 0.3565 (0.3757)  loss_n_80: 0.3955 (0.3974)  loss_n_100: 0.4344 (0.4297)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0043)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0137)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 110/1724]  eta: 1:45:25  lr: 0.000200  loss: 1.7744 (1.6087)  loss_n_40: 0.3971 (0.3661)  loss_n_60: 0.4086 (0.3808)  loss_n_80: 0.4565 (0.4046)  loss_n_100: 0.5232 (0.4385)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0039)  triple_60: 0.0000 (0.0022)  triple_40: 0.0000 (0.0125)  time: 3.9147  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 120/1724]  eta: 1:44:45  lr: 0.000200  loss: 1.7441 (1.6144)  loss_n_40: 0.3790 (0.3663)  loss_n_60: 0.4086 (0.3819)  loss_n_80: 0.4500 (0.4064)  loss_n_100: 0.4917 (0.4402)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0060)  triple_60: 0.0000 (0.0021)  triple_40: 0.0000 (0.0115)  time: 3.9157  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 130/1724]  eta: 1:44:06  lr: 0.000200  loss: 1.5212 (1.6023)  loss_n_40: 0.3470 (0.3642)  loss_n_60: 0.3689 (0.3795)  loss_n_80: 0.3852 (0.4043)  loss_n_100: 0.4203 (0.4363)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0055)  triple_60: 0.0000 (0.0019)  triple_40: 0.0000 (0.0106)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 140/1724]  eta: 1:43:26  lr: 0.000200  loss: 1.4280 (1.5979)  loss_n_40: 0.3500 (0.3655)  loss_n_60: 0.3447 (0.3789)  loss_n_80: 0.3661 (0.4032)  loss_n_100: 0.3791 (0.4336)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0051)  triple_60: 0.0000 (0.0018)  triple_40: 0.0000 (0.0098)  time: 3.9168  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 150/1724]  eta: 1:42:47  lr: 0.000200  loss: 1.4196 (1.5809)  loss_n_40: 0.3500 (0.3622)  loss_n_60: 0.3447 (0.3753)  loss_n_80: 0.3540 (0.3991)  loss_n_100: 0.3680 (0.4287)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0048)  triple_60: 0.0000 (0.0016)  triple_40: 0.0000 (0.0092)  time: 3.9166  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 160/1724]  eta: 1:42:08  lr: 0.000200  loss: 1.3045 (1.5628)  loss_n_40: 0.3029 (0.3588)  loss_n_60: 0.3089 (0.3714)  loss_n_80: 0.3334 (0.3947)  loss_n_100: 0.3513 (0.4233)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0045)  triple_60: 0.0000 (0.0015)  triple_40: 0.0000 (0.0086)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 170/1724]  eta: 1:41:28  lr: 0.000200  loss: 1.2744 (1.5478)  loss_n_40: 0.2999 (0.3566)  loss_n_60: 0.3043 (0.3680)  loss_n_80: 0.3244 (0.3907)  loss_n_100: 0.3513 (0.4187)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0042)  triple_60: 0.0000 (0.0015)  triple_40: 0.0000 (0.0081)  time: 3.9150  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 180/1724]  eta: 1:40:49  lr: 0.000200  loss: 1.3013 (1.5331)  loss_n_40: 0.3136 (0.3544)  loss_n_60: 0.3106 (0.3647)  loss_n_80: 0.3147 (0.3868)  loss_n_100: 0.3355 (0.4142)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0040)  triple_60: 0.0000 (0.0014)  triple_40: 0.0000 (0.0077)  time: 3.9155  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 190/1724]  eta: 1:40:09  lr: 0.000200  loss: 1.3013 (1.5229)  loss_n_40: 0.3136 (0.3530)  loss_n_60: 0.3106 (0.3624)  loss_n_80: 0.3126 (0.3844)  loss_n_100: 0.3230 (0.4106)  triple_100: 0.0000 (0.0001)  triple_80: 0.0000 (0.0039)  triple_60: 0.0000 (0.0013)  triple_40: 0.0000 (0.0073)  time: 3.9167  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [ 200/1724]  eta: 1:39:30  lr: 0.000200  loss: 1.3566 (1.5309)  loss_n_40: 0.3297 (0.3533)  loss_n_60: 0.3267 (0.3636)  loss_n_80: 0.3488 (0.3865)  loss_n_100: 0.3683 (0.4136)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0045)  triple_60: 0.0000 (0.0012)  triple_40: 0.0000 (0.0069)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 210/1724]  eta: 1:38:51  lr: 0.000200  loss: 1.5461 (1.5411)  loss_n_40: 0.3666 (0.3540)  loss_n_60: 0.3752 (0.3655)  loss_n_80: 0.3977 (0.3896)  loss_n_100: 0.4442 (0.4178)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0050)  triple_60: 0.0000 (0.0012)  triple_40: 0.0000 (0.0066)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 220/1724]  eta: 1:38:12  lr: 0.000200  loss: 1.5461 (1.5425)  loss_n_40: 0.3432 (0.3535)  loss_n_60: 0.3610 (0.3656)  loss_n_80: 0.4143 (0.3905)  loss_n_100: 0.4455 (0.4193)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0048)  triple_60: 0.0000 (0.0011)  triple_40: 0.0000 (0.0063)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 230/1724]  eta: 1:37:33  lr: 0.000200  loss: 1.4591 (1.5385)  loss_n_40: 0.3195 (0.3529)  loss_n_60: 0.3511 (0.3648)  loss_n_80: 0.3754 (0.3896)  loss_n_100: 0.4028 (0.4182)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0046)  triple_60: 0.0000 (0.0011)  triple_40: 0.0000 (0.0060)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 240/1724]  eta: 1:36:53  lr: 0.000200  loss: 1.4599 (1.5477)  loss_n_40: 0.3443 (0.3538)  loss_n_60: 0.3527 (0.3652)  loss_n_80: 0.3722 (0.3900)  loss_n_100: 0.4021 (0.4183)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0044)  triple_60: 0.0000 (0.0010)  triple_40: 0.0000 (0.0106)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 250/1724]  eta: 1:36:14  lr: 0.000200  loss: 1.4799 (1.5482)  loss_n_40: 0.3512 (0.3547)  loss_n_60: 0.3657 (0.3656)  loss_n_80: 0.3758 (0.3903)  loss_n_100: 0.4039 (0.4180)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0042)  triple_60: 0.0000 (0.0010)  triple_40: 0.0000 (0.0102)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 260/1724]  eta: 1:35:35  lr: 0.000200  loss: 1.4699 (1.5445)  loss_n_40: 0.3439 (0.3545)  loss_n_60: 0.3571 (0.3647)  loss_n_80: 0.3758 (0.3897)  loss_n_100: 0.3841 (0.4168)  triple_100: 0.0000 (0.0040)  triple_80: 0.0000 (0.0041)  triple_60: 0.0000 (0.0010)  triple_40: 0.0000 (0.0098)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 270/1724]  eta: 1:34:56  lr: 0.000200  loss: 1.3470 (1.5393)  loss_n_40: 0.3221 (0.3545)  loss_n_60: 0.3179 (0.3635)  loss_n_80: 0.3441 (0.3883)  loss_n_100: 0.3546 (0.4148)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0039)  triple_60: 0.0000 (0.0009)  triple_40: 0.0000 (0.0094)  time: 3.9156  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 280/1724]  eta: 1:34:16  lr: 0.000200  loss: 1.3611 (1.5369)  loss_n_40: 0.3669 (0.3560)  loss_n_60: 0.3123 (0.3630)  loss_n_80: 0.3352 (0.3872)  loss_n_100: 0.3504 (0.4129)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0038)  triple_60: 0.0000 (0.0009)  triple_40: 0.0000 (0.0094)  time: 3.9168  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 290/1724]  eta: 1:33:37  lr: 0.000200  loss: 1.3323 (1.5293)  loss_n_40: 0.3416 (0.3551)  loss_n_60: 0.3138 (0.3614)  loss_n_80: 0.3301 (0.3851)  loss_n_100: 0.3458 (0.4105)  triple_100: 0.0000 (0.0036)  triple_80: 0.0000 (0.0037)  triple_60: 0.0000 (0.0009)  triple_40: 0.0000 (0.0090)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 300/1724]  eta: 1:32:58  lr: 0.000200  loss: 1.2467 (1.5187)  loss_n_40: 0.3160 (0.3533)  loss_n_60: 0.2983 (0.3591)  loss_n_80: 0.3068 (0.3825)  loss_n_100: 0.3165 (0.4073)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0035)  triple_60: 0.0000 (0.0008)  triple_40: 0.0000 (0.0087)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 310/1724]  eta: 1:32:19  lr: 0.000200  loss: 1.1811 (1.5127)  loss_n_40: 0.2838 (0.3531)  loss_n_60: 0.2858 (0.3578)  loss_n_80: 0.2947 (0.3807)  loss_n_100: 0.3078 (0.4050)  triple_100: 0.0000 (0.0034)  triple_80: 0.0000 (0.0034)  triple_60: 0.0000 (0.0008)  triple_40: 0.0000 (0.0085)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 320/1724]  eta: 1:31:40  lr: 0.000200  loss: 1.2323 (1.5058)  loss_n_40: 0.3098 (0.3525)  loss_n_60: 0.3008 (0.3562)  loss_n_80: 0.3065 (0.3788)  loss_n_100: 0.3199 (0.4028)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0033)  triple_60: 0.0000 (0.0008)  triple_40: 0.0000 (0.0082)  time: 3.9153  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 330/1724]  eta: 1:31:00  lr: 0.000200  loss: 1.3960 (1.5157)  loss_n_40: 0.3233 (0.3516)  loss_n_60: 0.3178 (0.3565)  loss_n_80: 0.3449 (0.3803)  loss_n_100: 0.3665 (0.4054)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0060)  triple_60: 0.0000 (0.0030)  triple_40: 0.0000 (0.0098)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 340/1724]  eta: 1:30:21  lr: 0.000200  loss: 1.7898 (1.5281)  loss_n_40: 0.3669 (0.3529)  loss_n_60: 0.4064 (0.3583)  loss_n_80: 0.4527 (0.3828)  loss_n_100: 0.5108 (0.4089)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0068)  triple_60: 0.0000 (0.0029)  triple_40: 0.0000 (0.0095)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 350/1724]  eta: 1:29:42  lr: 0.000200  loss: 1.7057 (1.5301)  loss_n_40: 0.3783 (0.3532)  loss_n_60: 0.4001 (0.3587)  loss_n_80: 0.4357 (0.3836)  loss_n_100: 0.4771 (0.4101)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0066)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0092)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 360/1724]  eta: 1:29:03  lr: 0.000200  loss: 1.6121 (1.5319)  loss_n_40: 0.3643 (0.3540)  loss_n_60: 0.3812 (0.3595)  loss_n_80: 0.4060 (0.3840)  loss_n_100: 0.4397 (0.4106)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0064)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0090)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 370/1724]  eta: 1:28:24  lr: 0.000200  loss: 1.4319 (1.5312)  loss_n_40: 0.3330 (0.3537)  loss_n_60: 0.3445 (0.3592)  loss_n_80: 0.3641 (0.3836)  loss_n_100: 0.3801 (0.4098)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0069)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0099)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 380/1724]  eta: 1:27:44  lr: 0.000200  loss: 1.2895 (1.5243)  loss_n_40: 0.3031 (0.3523)  loss_n_60: 0.3127 (0.3578)  loss_n_80: 0.3275 (0.3819)  loss_n_100: 0.3411 (0.4080)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0067)  triple_60: 0.0000 (0.0026)  triple_40: 0.0000 (0.0096)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 390/1724]  eta: 1:27:05  lr: 0.000200  loss: 1.2356 (1.5190)  loss_n_40: 0.2934 (0.3513)  loss_n_60: 0.3009 (0.3569)  loss_n_80: 0.3178 (0.3807)  loss_n_100: 0.3334 (0.4064)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0065)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0094)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 400/1724]  eta: 1:26:26  lr: 0.000200  loss: 1.2261 (1.5128)  loss_n_40: 0.2901 (0.3502)  loss_n_60: 0.2922 (0.3556)  loss_n_80: 0.3102 (0.3792)  loss_n_100: 0.3253 (0.4047)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0064)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0092)  time: 3.9169  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 410/1724]  eta: 1:25:47  lr: 0.000200  loss: 1.2544 (1.5182)  loss_n_40: 0.3053 (0.3510)  loss_n_60: 0.2943 (0.3557)  loss_n_80: 0.3102 (0.3790)  loss_n_100: 0.3373 (0.4043)  triple_100: 0.0000 (0.0071)  triple_80: 0.0000 (0.0073)  triple_60: 0.0000 (0.0049)  triple_40: 0.0000 (0.0089)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 420/1724]  eta: 1:25:08  lr: 0.000200  loss: 1.9095 (1.5371)  loss_n_40: 0.3970 (0.3527)  loss_n_60: 0.4386 (0.3596)  loss_n_80: 0.4617 (0.3848)  loss_n_100: 0.4828 (0.4120)  triple_100: 0.0000 (0.0074)  triple_80: 0.0000 (0.0071)  triple_60: 0.0000 (0.0048)  triple_40: 0.0000 (0.0087)  time: 3.9178  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 430/1724]  eta: 1:24:29  lr: 0.000200  loss: 1.9296 (1.5427)  loss_n_40: 0.3970 (0.3530)  loss_n_60: 0.4386 (0.3606)  loss_n_80: 0.5344 (0.3869)  loss_n_100: 0.6173 (0.4149)  triple_100: 0.0000 (0.0072)  triple_80: 0.0000 (0.0069)  triple_60: 0.0000 (0.0047)  triple_40: 0.0000 (0.0085)  time: 3.9194  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [ 440/1724]  eta: 1:23:49  lr: 0.000200  loss: 1.6373 (1.5430)  loss_n_40: 0.3529 (0.3531)  loss_n_60: 0.3847 (0.3608)  loss_n_80: 0.4233 (0.3871)  loss_n_100: 0.4609 (0.4153)  triple_100: 0.0000 (0.0070)  triple_80: 0.0000 (0.0068)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0083)  time: 3.9191  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 450/1724]  eta: 1:23:10  lr: 0.000200  loss: 1.4247 (1.5400)  loss_n_40: 0.3462 (0.3526)  loss_n_60: 0.3407 (0.3602)  loss_n_80: 0.3568 (0.3865)  loss_n_100: 0.3840 (0.4147)  triple_100: 0.0000 (0.0069)  triple_80: 0.0000 (0.0066)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0082)  time: 3.9185  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 460/1724]  eta: 1:22:31  lr: 0.000200  loss: 1.2998 (1.5335)  loss_n_40: 0.3004 (0.3513)  loss_n_60: 0.3077 (0.3588)  loss_n_80: 0.3328 (0.3849)  loss_n_100: 0.3627 (0.4130)  triple_100: 0.0000 (0.0067)  triple_80: 0.0000 (0.0065)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0080)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 470/1724]  eta: 1:21:52  lr: 0.000200  loss: 1.2448 (1.5281)  loss_n_40: 0.2978 (0.3505)  loss_n_60: 0.2955 (0.3577)  loss_n_80: 0.3073 (0.3836)  loss_n_100: 0.3207 (0.4114)  triple_100: 0.0000 (0.0066)  triple_80: 0.0000 (0.0063)  triple_60: 0.0000 (0.0043)  triple_40: 0.0000 (0.0078)  time: 3.9177  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 480/1724]  eta: 1:21:13  lr: 0.000200  loss: 1.2037 (1.5206)  loss_n_40: 0.2929 (0.3492)  loss_n_60: 0.2880 (0.3561)  loss_n_80: 0.3021 (0.3817)  loss_n_100: 0.3158 (0.4092)  triple_100: 0.0000 (0.0064)  triple_80: 0.0000 (0.0062)  triple_60: 0.0000 (0.0042)  triple_40: 0.0000 (0.0076)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 490/1724]  eta: 1:20:34  lr: 0.000200  loss: 1.2084 (1.6042)  loss_n_40: 0.3142 (0.3503)  loss_n_60: 0.2930 (0.3579)  loss_n_80: 0.3066 (0.3841)  loss_n_100: 0.3159 (0.4120)  triple_100: 0.0000 (0.0303)  triple_80: 0.0000 (0.0280)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0218)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 500/1724]  eta: 1:19:54  lr: 0.000200  loss: 4.9274 (1.7532)  loss_n_40: 0.6776 (0.3615)  loss_n_60: 0.9224 (0.3761)  loss_n_80: 1.2240 (0.4079)  loss_n_100: 1.5400 (0.4421)  triple_100: 0.0000 (0.0678)  triple_80: 0.0000 (0.0554)  triple_60: 0.0000 (0.0211)  triple_40: 0.0000 (0.0213)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 510/1724]  eta: 1:19:15  lr: 0.000200  loss: 5.8562 (1.8343)  loss_n_40: 0.9843 (0.3758)  loss_n_60: 1.3294 (0.3950)  loss_n_80: 1.5623 (0.4305)  loss_n_100: 1.8368 (0.4706)  triple_100: 0.0000 (0.0665)  triple_80: 0.0000 (0.0543)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0209)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 520/1724]  eta: 1:18:36  lr: 0.000200  loss: 5.3634 (1.8938)  loss_n_40: 0.8967 (0.3838)  loss_n_60: 1.1592 (0.4080)  loss_n_80: 1.4297 (0.4480)  loss_n_100: 1.7609 (0.4947)  triple_100: 0.0000 (0.0652)  triple_80: 0.0000 (0.0533)  triple_60: 0.0000 (0.0203)  triple_40: 0.0000 (0.0205)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 530/1724]  eta: 1:17:57  lr: 0.000200  loss: 4.3375 (1.9301)  loss_n_40: 0.7303 (0.3898)  loss_n_60: 0.9391 (0.4159)  loss_n_80: 1.1143 (0.4587)  loss_n_100: 1.4594 (0.5093)  triple_100: 0.0000 (0.0640)  triple_80: 0.0000 (0.0523)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0201)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 540/1724]  eta: 1:17:18  lr: 0.000200  loss: 3.5239 (1.9535)  loss_n_40: 0.6030 (0.3939)  loss_n_60: 0.7805 (0.4217)  loss_n_80: 0.9593 (0.4660)  loss_n_100: 1.0999 (0.5185)  triple_100: 0.0000 (0.0628)  triple_80: 0.0000 (0.0513)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0198)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 550/1724]  eta: 1:16:39  lr: 0.000200  loss: 2.9199 (1.9644)  loss_n_40: 0.5257 (0.3962)  loss_n_60: 0.6593 (0.4247)  loss_n_80: 0.7504 (0.4698)  loss_n_100: 0.8754 (0.5231)  triple_100: 0.0000 (0.0617)  triple_80: 0.0000 (0.0504)  triple_60: 0.0000 (0.0192)  triple_40: 0.0000 (0.0194)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 560/1724]  eta: 1:15:59  lr: 0.000200  loss: 2.4714 (1.9796)  loss_n_40: 0.5303 (0.4016)  loss_n_60: 0.5722 (0.4291)  loss_n_80: 0.6424 (0.4738)  loss_n_100: 0.7185 (0.5272)  triple_100: 0.0000 (0.0606)  triple_80: 0.0000 (0.0495)  triple_60: 0.0000 (0.0189)  triple_40: 0.0000 (0.0190)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 570/1724]  eta: 1:15:20  lr: 0.000200  loss: 2.4304 (1.9850)  loss_n_40: 0.5303 (0.4039)  loss_n_60: 0.5722 (0.4308)  loss_n_80: 0.6023 (0.4757)  loss_n_100: 0.6726 (0.5293)  triple_100: 0.0000 (0.0595)  triple_80: 0.0000 (0.0486)  triple_60: 0.0000 (0.0185)  triple_40: 0.0000 (0.0187)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 580/1724]  eta: 1:14:41  lr: 0.000200  loss: 2.1254 (1.9877)  loss_n_40: 0.4519 (0.4057)  loss_n_60: 0.4912 (0.4319)  loss_n_80: 0.5407 (0.4766)  loss_n_100: 0.5863 (0.5303)  triple_100: 0.0000 (0.0585)  triple_80: 0.0000 (0.0478)  triple_60: 0.0000 (0.0182)  triple_40: 0.0000 (0.0187)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 590/1724]  eta: 1:14:02  lr: 0.000200  loss: 2.2025 (1.9941)  loss_n_40: 0.4579 (0.4079)  loss_n_60: 0.5040 (0.4337)  loss_n_80: 0.5649 (0.4788)  loss_n_100: 0.6479 (0.5331)  triple_100: 0.0000 (0.0575)  triple_80: 0.0000 (0.0470)  triple_60: 0.0000 (0.0179)  triple_40: 0.0000 (0.0184)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 600/1724]  eta: 1:13:23  lr: 0.000200  loss: 2.1511 (1.9932)  loss_n_40: 0.4451 (0.4085)  loss_n_60: 0.4954 (0.4340)  loss_n_80: 0.5452 (0.4791)  loss_n_100: 0.6037 (0.5332)  triple_100: 0.0000 (0.0566)  triple_80: 0.0000 (0.0462)  triple_60: 0.0000 (0.0176)  triple_40: 0.0000 (0.0181)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 610/1724]  eta: 1:12:44  lr: 0.000200  loss: 1.9254 (1.9926)  loss_n_40: 0.4298 (0.4090)  loss_n_60: 0.4459 (0.4343)  loss_n_80: 0.4860 (0.4794)  loss_n_100: 0.5434 (0.5335)  triple_100: 0.0000 (0.0556)  triple_80: 0.0000 (0.0456)  triple_60: 0.0000 (0.0173)  triple_40: 0.0000 (0.0178)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 620/1724]  eta: 1:12:04  lr: 0.000200  loss: 1.8318 (1.9888)  loss_n_40: 0.4153 (0.4093)  loss_n_60: 0.4347 (0.4340)  loss_n_80: 0.4568 (0.4787)  loss_n_100: 0.5036 (0.5326)  triple_100: 0.0000 (0.0547)  triple_80: 0.0000 (0.0448)  triple_60: 0.0000 (0.0170)  triple_40: 0.0000 (0.0175)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 630/1724]  eta: 1:11:25  lr: 0.000200  loss: 1.6706 (1.9832)  loss_n_40: 0.3781 (0.4087)  loss_n_60: 0.3896 (0.4333)  loss_n_80: 0.4091 (0.4778)  loss_n_100: 0.4370 (0.5314)  triple_100: 0.0000 (0.0539)  triple_80: 0.0000 (0.0441)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0172)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 640/1724]  eta: 1:10:46  lr: 0.000200  loss: 1.5348 (1.9749)  loss_n_40: 0.3548 (0.4076)  loss_n_60: 0.3637 (0.4319)  loss_n_80: 0.3942 (0.4761)  loss_n_100: 0.4231 (0.5292)  triple_100: 0.0000 (0.0530)  triple_80: 0.0000 (0.0434)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0170)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 650/1724]  eta: 1:10:07  lr: 0.000200  loss: 1.6818 (1.9785)  loss_n_40: 0.3681 (0.4076)  loss_n_60: 0.3915 (0.4325)  loss_n_80: 0.4306 (0.4768)  loss_n_100: 0.4751 (0.5304)  triple_100: 0.0000 (0.0528)  triple_80: 0.0000 (0.0435)  triple_60: 0.0000 (0.0171)  triple_40: 0.0000 (0.0177)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 660/1724]  eta: 1:09:28  lr: 0.000200  loss: 2.0497 (1.9806)  loss_n_40: 0.4030 (0.4079)  loss_n_60: 0.4852 (0.4335)  loss_n_80: 0.5389 (0.4779)  loss_n_100: 0.6116 (0.5320)  triple_100: 0.0000 (0.0520)  triple_80: 0.0000 (0.0428)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0174)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 670/1724]  eta: 1:08:49  lr: 0.000200  loss: 2.1147 (1.9822)  loss_n_40: 0.4580 (0.4096)  loss_n_60: 0.5021 (0.4347)  loss_n_80: 0.5211 (0.4783)  loss_n_100: 0.5874 (0.5324)  triple_100: 0.0000 (0.0513)  triple_80: 0.0000 (0.0422)  triple_60: 0.0000 (0.0166)  triple_40: 0.0000 (0.0172)  time: 3.9174  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [ 680/1724]  eta: 1:08:09  lr: 0.000200  loss: 1.8604 (1.9801)  loss_n_40: 0.4600 (0.4094)  loss_n_60: 0.4800 (0.4350)  loss_n_80: 0.4669 (0.4782)  loss_n_100: 0.5072 (0.5321)  triple_100: 0.0000 (0.0505)  triple_80: 0.0000 (0.0416)  triple_60: 0.0000 (0.0164)  triple_40: 0.0000 (0.0169)  time: 3.9184  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [ 690/1724]  eta: 1:07:30  lr: 0.000200  loss: 1.7186 (1.9762)  loss_n_40: 0.3623 (0.4092)  loss_n_60: 0.4201 (0.4347)  loss_n_80: 0.4518 (0.4776)  loss_n_100: 0.4868 (0.5312)  triple_100: 0.0000 (0.0498)  triple_80: 0.0000 (0.0410)  triple_60: 0.0000 (0.0161)  triple_40: 0.0000 (0.0167)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 700/1724]  eta: 1:06:51  lr: 0.000200  loss: 1.5877 (1.9702)  loss_n_40: 0.3755 (0.4088)  loss_n_60: 0.3907 (0.4340)  loss_n_80: 0.4070 (0.4762)  loss_n_100: 0.4314 (0.5294)  triple_100: 0.0000 (0.0491)  triple_80: 0.0000 (0.0404)  triple_60: 0.0000 (0.0159)  triple_40: 0.0000 (0.0164)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 710/1724]  eta: 1:06:12  lr: 0.000200  loss: 1.5759 (1.9673)  loss_n_40: 0.3902 (0.4091)  loss_n_60: 0.3887 (0.4340)  loss_n_80: 0.3933 (0.4757)  loss_n_100: 0.3961 (0.5285)  triple_100: 0.0000 (0.0484)  triple_80: 0.0000 (0.0398)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0162)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 720/1724]  eta: 1:05:33  lr: 0.000200  loss: 1.4607 (1.9608)  loss_n_40: 0.3528 (0.4085)  loss_n_60: 0.3486 (0.4329)  loss_n_80: 0.3900 (0.4743)  loss_n_100: 0.4031 (0.5267)  triple_100: 0.0000 (0.0477)  triple_80: 0.0000 (0.0393)  triple_60: 0.0000 (0.0154)  triple_40: 0.0000 (0.0160)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 730/1724]  eta: 1:04:54  lr: 0.000200  loss: 1.3940 (1.9526)  loss_n_40: 0.3190 (0.4075)  loss_n_60: 0.3341 (0.4316)  loss_n_80: 0.3436 (0.4723)  loss_n_100: 0.3722 (0.5244)  triple_100: 0.0000 (0.0471)  triple_80: 0.0000 (0.0387)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0158)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 740/1724]  eta: 1:04:14  lr: 0.000200  loss: 1.4307 (1.9457)  loss_n_40: 0.3234 (0.4068)  loss_n_60: 0.3271 (0.4304)  loss_n_80: 0.3382 (0.4708)  loss_n_100: 0.3637 (0.5224)  triple_100: 0.0000 (0.0464)  triple_80: 0.0000 (0.0382)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0155)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 750/1724]  eta: 1:03:35  lr: 0.000200  loss: 1.4700 (1.9396)  loss_n_40: 0.3412 (0.4062)  loss_n_60: 0.3375 (0.4293)  loss_n_80: 0.3631 (0.4695)  loss_n_100: 0.3852 (0.5209)  triple_100: 0.0000 (0.0458)  triple_80: 0.0000 (0.0377)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0153)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 760/1724]  eta: 1:02:56  lr: 0.000200  loss: 1.3446 (1.9305)  loss_n_40: 0.3367 (0.4049)  loss_n_60: 0.3178 (0.4276)  loss_n_80: 0.3415 (0.4674)  loss_n_100: 0.3594 (0.5183)  triple_100: 0.0000 (0.0452)  triple_80: 0.0000 (0.0372)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0151)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 770/1724]  eta: 1:02:17  lr: 0.000200  loss: 1.4907 (1.9363)  loss_n_40: 0.3384 (0.4049)  loss_n_60: 0.3582 (0.4282)  loss_n_80: 0.3717 (0.4682)  loss_n_100: 0.3998 (0.5194)  triple_100: 0.0000 (0.0465)  triple_80: 0.0000 (0.0390)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0149)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 780/1724]  eta: 1:01:38  lr: 0.000200  loss: 2.2060 (1.9395)  loss_n_40: 0.4085 (0.4051)  loss_n_60: 0.5107 (0.4292)  loss_n_80: 0.5868 (0.4697)  loss_n_100: 0.6499 (0.5213)  triple_100: 0.0000 (0.0460)  triple_80: 0.0000 (0.0385)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0147)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 790/1724]  eta: 1:00:58  lr: 0.000200  loss: 2.2258 (1.9435)  loss_n_40: 0.4190 (0.4058)  loss_n_60: 0.5142 (0.4306)  loss_n_80: 0.5990 (0.4712)  loss_n_100: 0.6678 (0.5232)  triple_100: 0.0000 (0.0454)  triple_80: 0.0000 (0.0380)  triple_60: 0.0000 (0.0148)  triple_40: 0.0000 (0.0146)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 800/1724]  eta: 1:00:19  lr: 0.000200  loss: 2.0812 (1.9427)  loss_n_40: 0.4089 (0.4058)  loss_n_60: 0.4835 (0.4307)  loss_n_80: 0.5289 (0.4714)  loss_n_100: 0.6097 (0.5234)  triple_100: 0.0000 (0.0448)  triple_80: 0.0000 (0.0375)  triple_60: 0.0000 (0.0146)  triple_40: 0.0000 (0.0144)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 810/1724]  eta: 0:59:40  lr: 0.000200  loss: 1.7097 (1.9395)  loss_n_40: 0.3706 (0.4054)  loss_n_60: 0.3989 (0.4304)  loss_n_80: 0.4435 (0.4709)  loss_n_100: 0.4826 (0.5228)  triple_100: 0.0000 (0.0443)  triple_80: 0.0000 (0.0371)  triple_60: 0.0000 (0.0144)  triple_40: 0.0000 (0.0142)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 820/1724]  eta: 0:59:01  lr: 0.000200  loss: 1.5860 (1.9359)  loss_n_40: 0.3663 (0.4053)  loss_n_60: 0.3804 (0.4300)  loss_n_80: 0.4106 (0.4703)  loss_n_100: 0.4347 (0.5218)  triple_100: 0.0000 (0.0437)  triple_80: 0.0000 (0.0366)  triple_60: 0.0000 (0.0142)  triple_40: 0.0000 (0.0140)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 830/1724]  eta: 0:58:22  lr: 0.000200  loss: 1.6477 (1.9330)  loss_n_40: 0.3778 (0.4051)  loss_n_60: 0.3997 (0.4297)  loss_n_80: 0.4185 (0.4699)  loss_n_100: 0.4408 (0.5211)  triple_100: 0.0000 (0.0432)  triple_80: 0.0000 (0.0362)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0139)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 840/1724]  eta: 0:57:42  lr: 0.000200  loss: 1.5543 (1.9275)  loss_n_40: 0.3645 (0.4044)  loss_n_60: 0.3658 (0.4287)  loss_n_80: 0.3971 (0.4688)  loss_n_100: 0.4029 (0.5196)  triple_100: 0.0000 (0.0427)  triple_80: 0.0000 (0.0358)  triple_60: 0.0000 (0.0139)  triple_40: 0.0000 (0.0137)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 850/1724]  eta: 0:57:03  lr: 0.000200  loss: 1.5342 (1.9252)  loss_n_40: 0.3631 (0.4044)  loss_n_60: 0.3517 (0.4285)  loss_n_80: 0.3880 (0.4683)  loss_n_100: 0.3921 (0.5186)  triple_100: 0.0000 (0.0422)  triple_80: 0.0000 (0.0357)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0135)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 860/1724]  eta: 0:56:24  lr: 0.000200  loss: 1.5210 (1.9200)  loss_n_40: 0.3635 (0.4038)  loss_n_60: 0.3697 (0.4276)  loss_n_80: 0.3895 (0.4672)  loss_n_100: 0.4006 (0.5172)  triple_100: 0.0000 (0.0417)  triple_80: 0.0000 (0.0353)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0134)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 870/1724]  eta: 0:55:45  lr: 0.000200  loss: 1.4551 (1.9147)  loss_n_40: 0.3293 (0.4030)  loss_n_60: 0.3460 (0.4268)  loss_n_80: 0.3680 (0.4661)  loss_n_100: 0.3934 (0.5158)  triple_100: 0.0000 (0.0412)  triple_80: 0.0000 (0.0349)  triple_60: 0.0000 (0.0137)  triple_40: 0.0000 (0.0132)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 880/1724]  eta: 0:55:06  lr: 0.000200  loss: 1.3816 (1.9090)  loss_n_40: 0.3210 (0.4023)  loss_n_60: 0.3293 (0.4257)  loss_n_80: 0.3564 (0.4648)  loss_n_100: 0.3728 (0.5143)  triple_100: 0.0000 (0.0407)  triple_80: 0.0000 (0.0345)  triple_60: 0.0000 (0.0135)  triple_40: 0.0000 (0.0131)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 890/1724]  eta: 0:54:27  lr: 0.000200  loss: 1.3104 (1.9036)  loss_n_40: 0.3134 (0.4018)  loss_n_60: 0.3148 (0.4248)  loss_n_80: 0.3306 (0.4636)  loss_n_100: 0.3519 (0.5127)  triple_100: 0.0000 (0.0403)  triple_80: 0.0000 (0.0341)  triple_60: 0.0000 (0.0134)  triple_40: 0.0000 (0.0129)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 900/1724]  eta: 0:53:47  lr: 0.000200  loss: 1.3119 (1.8972)  loss_n_40: 0.3414 (0.4012)  loss_n_60: 0.3148 (0.4236)  loss_n_80: 0.3306 (0.4621)  loss_n_100: 0.3379 (0.5107)  triple_100: 0.0000 (0.0398)  triple_80: 0.0000 (0.0338)  triple_60: 0.0000 (0.0132)  triple_40: 0.0000 (0.0128)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 910/1724]  eta: 0:53:08  lr: 0.000200  loss: 1.2762 (1.8896)  loss_n_40: 0.3015 (0.4000)  loss_n_60: 0.3047 (0.4222)  loss_n_80: 0.3063 (0.4604)  loss_n_100: 0.3166 (0.5085)  triple_100: 0.0000 (0.0394)  triple_80: 0.0000 (0.0334)  triple_60: 0.0000 (0.0131)  triple_40: 0.0000 (0.0126)  time: 3.9176  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [ 920/1724]  eta: 0:52:29  lr: 0.000200  loss: 1.1558 (1.8822)  loss_n_40: 0.2676 (0.3987)  loss_n_60: 0.2807 (0.4207)  loss_n_80: 0.2980 (0.4587)  loss_n_100: 0.3091 (0.5065)  triple_100: 0.0000 (0.0390)  triple_80: 0.0000 (0.0330)  triple_60: 0.0000 (0.0129)  triple_40: 0.0000 (0.0125)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 930/1724]  eta: 0:51:50  lr: 0.000200  loss: 1.1976 (1.8750)  loss_n_40: 0.2818 (0.3977)  loss_n_60: 0.2887 (0.4193)  loss_n_80: 0.3036 (0.4571)  loss_n_100: 0.3110 (0.5045)  triple_100: 0.0000 (0.0385)  triple_80: 0.0000 (0.0327)  triple_60: 0.0000 (0.0128)  triple_40: 0.0000 (0.0124)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 940/1724]  eta: 0:51:11  lr: 0.000200  loss: 1.1674 (1.8676)  loss_n_40: 0.2725 (0.3965)  loss_n_60: 0.2803 (0.4178)  loss_n_80: 0.3013 (0.4554)  loss_n_100: 0.3259 (0.5025)  triple_100: 0.0000 (0.0381)  triple_80: 0.0000 (0.0323)  triple_60: 0.0000 (0.0127)  triple_40: 0.0000 (0.0122)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 950/1724]  eta: 0:50:32  lr: 0.000200  loss: 1.1674 (1.8614)  loss_n_40: 0.2614 (0.3954)  loss_n_60: 0.2788 (0.4165)  loss_n_80: 0.3013 (0.4538)  loss_n_100: 0.3261 (0.5006)  triple_100: 0.0000 (0.0377)  triple_80: 0.0000 (0.0324)  triple_60: 0.0000 (0.0127)  triple_40: 0.0000 (0.0122)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 960/1724]  eta: 0:49:52  lr: 0.000200  loss: 1.3057 (1.8565)  loss_n_40: 0.2946 (0.3945)  loss_n_60: 0.3020 (0.4156)  loss_n_80: 0.3392 (0.4528)  loss_n_100: 0.3613 (0.4995)  triple_100: 0.0000 (0.0373)  triple_80: 0.0000 (0.0320)  triple_60: 0.0000 (0.0125)  triple_40: 0.0000 (0.0121)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 970/1724]  eta: 0:49:13  lr: 0.000200  loss: 1.2918 (1.8506)  loss_n_40: 0.2985 (0.3937)  loss_n_60: 0.3064 (0.4144)  loss_n_80: 0.3383 (0.4515)  loss_n_100: 0.3655 (0.4980)  triple_100: 0.0000 (0.0370)  triple_80: 0.0000 (0.0317)  triple_60: 0.0000 (0.0124)  triple_40: 0.0000 (0.0120)  time: 3.9149  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 980/1724]  eta: 0:48:34  lr: 0.000200  loss: 1.2241 (1.8451)  loss_n_40: 0.2889 (0.3929)  loss_n_60: 0.2888 (0.4134)  loss_n_80: 0.3114 (0.4503)  loss_n_100: 0.3270 (0.4964)  triple_100: 0.0000 (0.0366)  triple_80: 0.0000 (0.0314)  triple_60: 0.0000 (0.0123)  triple_40: 0.0000 (0.0119)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [ 990/1724]  eta: 0:47:55  lr: 0.000200  loss: 1.1385 (1.8386)  loss_n_40: 0.2603 (0.3918)  loss_n_60: 0.2744 (0.4121)  loss_n_80: 0.2974 (0.4488)  loss_n_100: 0.3125 (0.4947)  triple_100: 0.0000 (0.0362)  triple_80: 0.0000 (0.0311)  triple_60: 0.0000 (0.0122)  triple_40: 0.0000 (0.0117)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1000/1724]  eta: 0:47:16  lr: 0.000200  loss: 1.1564 (1.8326)  loss_n_40: 0.2681 (0.3909)  loss_n_60: 0.2767 (0.4110)  loss_n_80: 0.2997 (0.4474)  loss_n_100: 0.3232 (0.4930)  triple_100: 0.0000 (0.0359)  triple_80: 0.0000 (0.0308)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0116)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1010/1724]  eta: 0:46:36  lr: 0.000200  loss: 1.3474 (1.8316)  loss_n_40: 0.3211 (0.3903)  loss_n_60: 0.3275 (0.4105)  loss_n_80: 0.3333 (0.4470)  loss_n_100: 0.3670 (0.4927)  triple_100: 0.0000 (0.0357)  triple_80: 0.0000 (0.0312)  triple_60: 0.0000 (0.0121)  triple_40: 0.0000 (0.0122)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1020/1724]  eta: 0:45:57  lr: 0.000200  loss: 1.5160 (1.8286)  loss_n_40: 0.3265 (0.3898)  loss_n_60: 0.3555 (0.4099)  loss_n_80: 0.3772 (0.4464)  loss_n_100: 0.4138 (0.4920)  triple_100: 0.0000 (0.0354)  triple_80: 0.0000 (0.0310)  triple_60: 0.0000 (0.0121)  triple_40: 0.0000 (0.0121)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1030/1724]  eta: 0:45:18  lr: 0.000200  loss: 1.4478 (1.8249)  loss_n_40: 0.3299 (0.3892)  loss_n_60: 0.3524 (0.4093)  loss_n_80: 0.3711 (0.4457)  loss_n_100: 0.4112 (0.4911)  triple_100: 0.0000 (0.0350)  triple_80: 0.0000 (0.0307)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0120)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1040/1724]  eta: 0:44:39  lr: 0.000200  loss: 1.4379 (1.8208)  loss_n_40: 0.3101 (0.3885)  loss_n_60: 0.3392 (0.4086)  loss_n_80: 0.3544 (0.4448)  loss_n_100: 0.4055 (0.4902)  triple_100: 0.0000 (0.0347)  triple_80: 0.0000 (0.0304)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0118)  time: 3.9156  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1050/1724]  eta: 0:44:00  lr: 0.000200  loss: 1.3348 (1.8161)  loss_n_40: 0.3042 (0.3877)  loss_n_60: 0.3197 (0.4078)  loss_n_80: 0.3474 (0.4438)  loss_n_100: 0.3704 (0.4889)  triple_100: 0.0000 (0.0344)  triple_80: 0.0000 (0.0301)  triple_60: 0.0000 (0.0117)  triple_40: 0.0000 (0.0117)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1060/1724]  eta: 0:43:21  lr: 0.000200  loss: 1.3264 (1.8133)  loss_n_40: 0.3069 (0.3874)  loss_n_60: 0.3217 (0.4072)  loss_n_80: 0.3319 (0.4429)  loss_n_100: 0.3600 (0.4878)  triple_100: 0.0000 (0.0340)  triple_80: 0.0000 (0.0298)  triple_60: 0.0000 (0.0116)  triple_40: 0.0000 (0.0125)  time: 3.9149  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1070/1724]  eta: 0:42:41  lr: 0.000200  loss: 1.3555 (1.8095)  loss_n_40: 0.3443 (0.3870)  loss_n_60: 0.3289 (0.4066)  loss_n_80: 0.3372 (0.4421)  loss_n_100: 0.3611 (0.4867)  triple_100: 0.0000 (0.0337)  triple_80: 0.0000 (0.0295)  triple_60: 0.0000 (0.0115)  triple_40: 0.0000 (0.0124)  time: 3.9134  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1080/1724]  eta: 0:42:02  lr: 0.000200  loss: 1.3013 (1.8043)  loss_n_40: 0.3054 (0.3862)  loss_n_60: 0.3020 (0.4056)  loss_n_80: 0.3243 (0.4409)  loss_n_100: 0.3309 (0.4852)  triple_100: 0.0000 (0.0334)  triple_80: 0.0000 (0.0292)  triple_60: 0.0000 (0.0114)  triple_40: 0.0000 (0.0122)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1090/1724]  eta: 0:41:23  lr: 0.000200  loss: 1.3220 (1.8008)  loss_n_40: 0.2966 (0.3857)  loss_n_60: 0.3180 (0.4051)  loss_n_80: 0.3414 (0.4403)  loss_n_100: 0.3539 (0.4843)  triple_100: 0.0000 (0.0331)  triple_80: 0.0000 (0.0290)  triple_60: 0.0000 (0.0113)  triple_40: 0.0000 (0.0121)  time: 3.9205  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1100/1724]  eta: 0:40:44  lr: 0.000200  loss: 1.3333 (1.7970)  loss_n_40: 0.2935 (0.3849)  loss_n_60: 0.3057 (0.4041)  loss_n_80: 0.3480 (0.4394)  loss_n_100: 0.3794 (0.4832)  triple_100: 0.0000 (0.0328)  triple_80: 0.0000 (0.0288)  triple_60: 0.0000 (0.0115)  triple_40: 0.0000 (0.0123)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1110/1724]  eta: 0:40:05  lr: 0.000200  loss: 1.4053 (1.7947)  loss_n_40: 0.3318 (0.3845)  loss_n_60: 0.3288 (0.4039)  loss_n_80: 0.3561 (0.4390)  loss_n_100: 0.3974 (0.4827)  triple_100: 0.0000 (0.0325)  triple_80: 0.0000 (0.0286)  triple_60: 0.0000 (0.0114)  triple_40: 0.0000 (0.0122)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1120/1724]  eta: 0:39:26  lr: 0.000200  loss: 1.5263 (1.7920)  loss_n_40: 0.3330 (0.3840)  loss_n_60: 0.3636 (0.4034)  loss_n_80: 0.3820 (0.4385)  loss_n_100: 0.4101 (0.4821)  triple_100: 0.0000 (0.0322)  triple_80: 0.0000 (0.0283)  triple_60: 0.0000 (0.0113)  triple_40: 0.0000 (0.0121)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1130/1724]  eta: 0:38:46  lr: 0.000200  loss: 1.3949 (1.7888)  loss_n_40: 0.3291 (0.3836)  loss_n_60: 0.3376 (0.4029)  loss_n_80: 0.3551 (0.4379)  loss_n_100: 0.3748 (0.4812)  triple_100: 0.0000 (0.0319)  triple_80: 0.0000 (0.0281)  triple_60: 0.0000 (0.0112)  triple_40: 0.0000 (0.0120)  time: 3.9171  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [1140/1724]  eta: 0:38:07  lr: 0.000200  loss: 1.3453 (1.7852)  loss_n_40: 0.3141 (0.3831)  loss_n_60: 0.3278 (0.4024)  loss_n_80: 0.3450 (0.4371)  loss_n_100: 0.3663 (0.4802)  triple_100: 0.0000 (0.0316)  triple_80: 0.0000 (0.0278)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0119)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1150/1724]  eta: 0:37:28  lr: 0.000200  loss: 1.2198 (1.7808)  loss_n_40: 0.2777 (0.3825)  loss_n_60: 0.2933 (0.4015)  loss_n_80: 0.3167 (0.4361)  loss_n_100: 0.3244 (0.4789)  triple_100: 0.0000 (0.0314)  triple_80: 0.0000 (0.0276)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0118)  time: 3.9172  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [1160/1724]  eta: 0:36:49  lr: 0.000200  loss: 1.1623 (1.7764)  loss_n_40: 0.2738 (0.3818)  loss_n_60: 0.2844 (0.4007)  loss_n_80: 0.2952 (0.4352)  loss_n_100: 0.3068 (0.4777)  triple_100: 0.0000 (0.0311)  triple_80: 0.0000 (0.0273)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0117)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1170/1724]  eta: 0:36:10  lr: 0.000200  loss: 1.1426 (1.7713)  loss_n_40: 0.2738 (0.3812)  loss_n_60: 0.2725 (0.3997)  loss_n_80: 0.2888 (0.4339)  loss_n_100: 0.2986 (0.4762)  triple_100: 0.0000 (0.0308)  triple_80: 0.0000 (0.0271)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0116)  time: 3.9162  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [1180/1724]  eta: 0:35:30  lr: 0.000200  loss: 1.1263 (1.7663)  loss_n_40: 0.2675 (0.3805)  loss_n_60: 0.2725 (0.3987)  loss_n_80: 0.2858 (0.4327)  loss_n_100: 0.2986 (0.4747)  triple_100: 0.0000 (0.0306)  triple_80: 0.0000 (0.0269)  triple_60: 0.0000 (0.0107)  triple_40: 0.0000 (0.0115)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1190/1724]  eta: 0:34:51  lr: 0.000200  loss: 1.1245 (1.7619)  loss_n_40: 0.2675 (0.3799)  loss_n_60: 0.2742 (0.3979)  loss_n_80: 0.2865 (0.4317)  loss_n_100: 0.3014 (0.4734)  triple_100: 0.0000 (0.0303)  triple_80: 0.0000 (0.0266)  triple_60: 0.0000 (0.0106)  triple_40: 0.0000 (0.0114)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1200/1724]  eta: 0:34:12  lr: 0.000200  loss: 1.1246 (1.7571)  loss_n_40: 0.2938 (0.3793)  loss_n_60: 0.2855 (0.3970)  loss_n_80: 0.2865 (0.4305)  loss_n_100: 0.2912 (0.4719)  triple_100: 0.0000 (0.0301)  triple_80: 0.0000 (0.0264)  triple_60: 0.0000 (0.0105)  triple_40: 0.0000 (0.0113)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1210/1724]  eta: 0:33:33  lr: 0.000200  loss: 1.0486 (1.7514)  loss_n_40: 0.2498 (0.3784)  loss_n_60: 0.2517 (0.3958)  loss_n_80: 0.2629 (0.4292)  loss_n_100: 0.2732 (0.4703)  triple_100: 0.0000 (0.0298)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0112)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1220/1724]  eta: 0:32:54  lr: 0.000200  loss: 1.0641 (1.7460)  loss_n_40: 0.2596 (0.3776)  loss_n_60: 0.2517 (0.3947)  loss_n_80: 0.2748 (0.4279)  loss_n_100: 0.2847 (0.4688)  triple_100: 0.0000 (0.0296)  triple_80: 0.0000 (0.0260)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0111)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1230/1724]  eta: 0:32:15  lr: 0.000200  loss: 1.0467 (1.7408)  loss_n_40: 0.2596 (0.3767)  loss_n_60: 0.2504 (0.3936)  loss_n_80: 0.2705 (0.4267)  loss_n_100: 0.2799 (0.4673)  triple_100: 0.0000 (0.0293)  triple_80: 0.0000 (0.0258)  triple_60: 0.0000 (0.0103)  triple_40: 0.0000 (0.0110)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1240/1724]  eta: 0:31:35  lr: 0.000200  loss: 1.0124 (1.7360)  loss_n_40: 0.2473 (0.3760)  loss_n_60: 0.2420 (0.3927)  loss_n_80: 0.2605 (0.4256)  loss_n_100: 0.2786 (0.4660)  triple_100: 0.0000 (0.0291)  triple_80: 0.0000 (0.0256)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0109)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1250/1724]  eta: 0:30:56  lr: 0.000200  loss: 1.1453 (1.7405)  loss_n_40: 0.2620 (0.3753)  loss_n_60: 0.2677 (0.3920)  loss_n_80: 0.2769 (0.4249)  loss_n_100: 0.2885 (0.4653)  triple_100: 0.0000 (0.0305)  triple_80: 0.0000 (0.0275)  triple_60: 0.0000 (0.0121)  triple_40: 0.0000 (0.0129)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1260/1724]  eta: 0:30:17  lr: 0.000200  loss: 2.0429 (1.7436)  loss_n_40: 0.3834 (0.3759)  loss_n_60: 0.4447 (0.3928)  loss_n_80: 0.4969 (0.4259)  loss_n_100: 0.5625 (0.4667)  triple_100: 0.0000 (0.0303)  triple_80: 0.0000 (0.0273)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0128)  time: 3.9158  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [1270/1724]  eta: 0:29:38  lr: 0.000200  loss: 2.0524 (1.7451)  loss_n_40: 0.4358 (0.3763)  loss_n_60: 0.4651 (0.3932)  loss_n_80: 0.5344 (0.4265)  loss_n_100: 0.5755 (0.4674)  triple_100: 0.0000 (0.0301)  triple_80: 0.0000 (0.0270)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0127)  time: 3.9157  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1280/1724]  eta: 0:28:59  lr: 0.000200  loss: 1.8108 (1.7451)  loss_n_40: 0.4173 (0.3765)  loss_n_60: 0.4234 (0.3934)  loss_n_80: 0.4658 (0.4266)  loss_n_100: 0.4990 (0.4674)  triple_100: 0.0000 (0.0298)  triple_80: 0.0000 (0.0268)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0126)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1290/1724]  eta: 0:28:20  lr: 0.000200  loss: 1.6326 (1.7436)  loss_n_40: 0.3751 (0.3764)  loss_n_60: 0.3862 (0.3933)  loss_n_80: 0.4206 (0.4263)  loss_n_100: 0.4515 (0.4671)  triple_100: 0.0000 (0.0296)  triple_80: 0.0000 (0.0266)  triple_60: 0.0000 (0.0118)  triple_40: 0.0000 (0.0125)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1300/1724]  eta: 0:27:40  lr: 0.000200  loss: 1.4477 (1.7412)  loss_n_40: 0.3356 (0.3761)  loss_n_60: 0.3508 (0.3929)  loss_n_80: 0.3770 (0.4258)  loss_n_100: 0.3983 (0.4664)  triple_100: 0.0000 (0.0294)  triple_80: 0.0000 (0.0264)  triple_60: 0.0000 (0.0117)  triple_40: 0.0000 (0.0124)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1310/1724]  eta: 0:27:01  lr: 0.000200  loss: 1.4403 (1.7392)  loss_n_40: 0.3401 (0.3760)  loss_n_60: 0.3447 (0.3926)  loss_n_80: 0.3644 (0.4254)  loss_n_100: 0.3599 (0.4658)  triple_100: 0.0000 (0.0291)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.0116)  triple_40: 0.0000 (0.0124)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1320/1724]  eta: 0:26:22  lr: 0.000200  loss: 1.3067 (1.7355)  loss_n_40: 0.3084 (0.3755)  loss_n_60: 0.3171 (0.3920)  loss_n_80: 0.3232 (0.4246)  loss_n_100: 0.3362 (0.4647)  triple_100: 0.0000 (0.0289)  triple_80: 0.0000 (0.0260)  triple_60: 0.0000 (0.0115)  triple_40: 0.0000 (0.0123)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1330/1724]  eta: 0:25:43  lr: 0.000200  loss: 1.2427 (1.7318)  loss_n_40: 0.3032 (0.3748)  loss_n_60: 0.3007 (0.3913)  loss_n_80: 0.3096 (0.4238)  loss_n_100: 0.3215 (0.4637)  triple_100: 0.0000 (0.0287)  triple_80: 0.0000 (0.0258)  triple_60: 0.0000 (0.0114)  triple_40: 0.0000 (0.0122)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1340/1724]  eta: 0:25:04  lr: 0.000200  loss: 1.2471 (1.7287)  loss_n_40: 0.2998 (0.3743)  loss_n_60: 0.2985 (0.3907)  loss_n_80: 0.3187 (0.4231)  loss_n_100: 0.3261 (0.4629)  triple_100: 0.0000 (0.0285)  triple_80: 0.0000 (0.0256)  triple_60: 0.0000 (0.0113)  triple_40: 0.0000 (0.0123)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1350/1724]  eta: 0:24:25  lr: 0.000200  loss: 1.2648 (1.7259)  loss_n_40: 0.2996 (0.3740)  loss_n_60: 0.3082 (0.3901)  loss_n_80: 0.3264 (0.4225)  loss_n_100: 0.3507 (0.4622)  triple_100: 0.0000 (0.0283)  triple_80: 0.0000 (0.0255)  triple_60: 0.0000 (0.0112)  triple_40: 0.0000 (0.0122)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1360/1724]  eta: 0:23:45  lr: 0.000200  loss: 1.2386 (1.7221)  loss_n_40: 0.2835 (0.3734)  loss_n_60: 0.2897 (0.3894)  loss_n_80: 0.3051 (0.4216)  loss_n_100: 0.3382 (0.4612)  triple_100: 0.0000 (0.0281)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0112)  triple_40: 0.0000 (0.0121)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1370/1724]  eta: 0:23:06  lr: 0.000200  loss: 1.2391 (1.7191)  loss_n_40: 0.3001 (0.3730)  loss_n_60: 0.3011 (0.3888)  loss_n_80: 0.3067 (0.4209)  loss_n_100: 0.3312 (0.4602)  triple_100: 0.0000 (0.0279)  triple_80: 0.0000 (0.0251)  triple_60: 0.0000 (0.0112)  triple_40: 0.0000 (0.0120)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1380/1724]  eta: 0:22:27  lr: 0.000200  loss: 1.2359 (1.7153)  loss_n_40: 0.2946 (0.3723)  loss_n_60: 0.3062 (0.3882)  loss_n_80: 0.3127 (0.4200)  loss_n_100: 0.3210 (0.4592)  triple_100: 0.0000 (0.0277)  triple_80: 0.0000 (0.0249)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0119)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1390/1724]  eta: 0:21:48  lr: 0.000200  loss: 1.2044 (1.7122)  loss_n_40: 0.2879 (0.3720)  loss_n_60: 0.3013 (0.3876)  loss_n_80: 0.2985 (0.4193)  loss_n_100: 0.3089 (0.4582)  triple_100: 0.0000 (0.0275)  triple_80: 0.0000 (0.0248)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0118)  time: 3.9159  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [1400/1724]  eta: 0:21:09  lr: 0.000200  loss: 1.2044 (1.7086)  loss_n_40: 0.2950 (0.3714)  loss_n_60: 0.2991 (0.3870)  loss_n_80: 0.2985 (0.4184)  loss_n_100: 0.3103 (0.4572)  triple_100: 0.0000 (0.0273)  triple_80: 0.0000 (0.0246)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0117)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1410/1724]  eta: 0:20:29  lr: 0.000200  loss: 1.1707 (1.7094)  loss_n_40: 0.2910 (0.3709)  loss_n_60: 0.2815 (0.3864)  loss_n_80: 0.2985 (0.4176)  loss_n_100: 0.3202 (0.4562)  triple_100: 0.0000 (0.0279)  triple_80: 0.0000 (0.0256)  triple_60: 0.0000 (0.0117)  triple_40: 0.0000 (0.0131)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1420/1724]  eta: 0:19:50  lr: 0.000200  loss: 1.4375 (1.7085)  loss_n_40: 0.3021 (0.3707)  loss_n_60: 0.3421 (0.3863)  loss_n_80: 0.3645 (0.4176)  loss_n_100: 0.3828 (0.4562)  triple_100: 0.0000 (0.0277)  triple_80: 0.0000 (0.0255)  triple_60: 0.0000 (0.0116)  triple_40: 0.0000 (0.0130)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1430/1724]  eta: 0:19:11  lr: 0.000200  loss: 1.5516 (1.7084)  loss_n_40: 0.3362 (0.3705)  loss_n_60: 0.3759 (0.3864)  loss_n_80: 0.4139 (0.4177)  loss_n_100: 0.4487 (0.4563)  triple_100: 0.0000 (0.0275)  triple_80: 0.0000 (0.0256)  triple_60: 0.0000 (0.0116)  triple_40: 0.0000 (0.0129)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1440/1724]  eta: 0:18:32  lr: 0.000200  loss: 1.5359 (1.7075)  loss_n_40: 0.3337 (0.3704)  loss_n_60: 0.3625 (0.3863)  loss_n_80: 0.3923 (0.4176)  loss_n_100: 0.4373 (0.4562)  triple_100: 0.0000 (0.0273)  triple_80: 0.0000 (0.0254)  triple_60: 0.0000 (0.0115)  triple_40: 0.0000 (0.0128)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1450/1724]  eta: 0:17:53  lr: 0.000200  loss: 1.5173 (1.7050)  loss_n_40: 0.3337 (0.3700)  loss_n_60: 0.3447 (0.3858)  loss_n_80: 0.3798 (0.4171)  loss_n_100: 0.4032 (0.4555)  triple_100: 0.0000 (0.0271)  triple_80: 0.0000 (0.0252)  triple_60: 0.0000 (0.0115)  triple_40: 0.0000 (0.0127)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1460/1724]  eta: 0:17:14  lr: 0.000200  loss: 1.3024 (1.7023)  loss_n_40: 0.2977 (0.3696)  loss_n_60: 0.3098 (0.3853)  loss_n_80: 0.3315 (0.4165)  loss_n_100: 0.3502 (0.4549)  triple_100: 0.0000 (0.0270)  triple_80: 0.0000 (0.0250)  triple_60: 0.0000 (0.0114)  triple_40: 0.0000 (0.0127)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1470/1724]  eta: 0:16:34  lr: 0.000200  loss: 1.2560 (1.6991)  loss_n_40: 0.2943 (0.3691)  loss_n_60: 0.2945 (0.3847)  loss_n_80: 0.3101 (0.4157)  loss_n_100: 0.3435 (0.4541)  triple_100: 0.0000 (0.0268)  triple_80: 0.0000 (0.0249)  triple_60: 0.0000 (0.0113)  triple_40: 0.0000 (0.0126)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1480/1724]  eta: 0:15:55  lr: 0.000200  loss: 1.1839 (1.6966)  loss_n_40: 0.2862 (0.3689)  loss_n_60: 0.2854 (0.3843)  loss_n_80: 0.3013 (0.4151)  loss_n_100: 0.3165 (0.4532)  triple_100: 0.0000 (0.0266)  triple_80: 0.0000 (0.0247)  triple_60: 0.0000 (0.0112)  triple_40: 0.0000 (0.0125)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1490/1724]  eta: 0:15:16  lr: 0.000200  loss: 1.1675 (1.6931)  loss_n_40: 0.2832 (0.3683)  loss_n_60: 0.2841 (0.3837)  loss_n_80: 0.2926 (0.4143)  loss_n_100: 0.3087 (0.4523)  triple_100: 0.0000 (0.0264)  triple_80: 0.0000 (0.0245)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0124)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1500/1724]  eta: 0:14:37  lr: 0.000200  loss: 1.1801 (1.6898)  loss_n_40: 0.2818 (0.3680)  loss_n_60: 0.2740 (0.3830)  loss_n_80: 0.2893 (0.4135)  loss_n_100: 0.2970 (0.4513)  triple_100: 0.0000 (0.0262)  triple_80: 0.0000 (0.0244)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0123)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1510/1724]  eta: 0:13:58  lr: 0.000200  loss: 1.2059 (1.6873)  loss_n_40: 0.2943 (0.3677)  loss_n_60: 0.2756 (0.3826)  loss_n_80: 0.2958 (0.4129)  loss_n_100: 0.3147 (0.4506)  triple_100: 0.0000 (0.0261)  triple_80: 0.0000 (0.0242)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0123)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1520/1724]  eta: 0:13:19  lr: 0.000200  loss: 1.1728 (1.6840)  loss_n_40: 0.2895 (0.3672)  loss_n_60: 0.2756 (0.3819)  loss_n_80: 0.2875 (0.4121)  loss_n_100: 0.3093 (0.4497)  triple_100: 0.0000 (0.0259)  triple_80: 0.0000 (0.0240)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0122)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1530/1724]  eta: 0:12:39  lr: 0.000200  loss: 1.1379 (1.6809)  loss_n_40: 0.2895 (0.3668)  loss_n_60: 0.2717 (0.3814)  loss_n_80: 0.2797 (0.4113)  loss_n_100: 0.2978 (0.4488)  triple_100: 0.0000 (0.0257)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0121)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1540/1724]  eta: 0:12:00  lr: 0.000200  loss: 1.1163 (1.6770)  loss_n_40: 0.2825 (0.3661)  loss_n_60: 0.2717 (0.3806)  loss_n_80: 0.2710 (0.4104)  loss_n_100: 0.2849 (0.4477)  triple_100: 0.0000 (0.0256)  triple_80: 0.0000 (0.0237)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0121)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1550/1724]  eta: 0:11:21  lr: 0.000200  loss: 1.1477 (1.6738)  loss_n_40: 0.2876 (0.3656)  loss_n_60: 0.2648 (0.3800)  loss_n_80: 0.2792 (0.4097)  loss_n_100: 0.2925 (0.4467)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0236)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0120)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1560/1724]  eta: 0:10:42  lr: 0.000200  loss: 1.2102 (1.6707)  loss_n_40: 0.2937 (0.3652)  loss_n_60: 0.2704 (0.3794)  loss_n_80: 0.2918 (0.4090)  loss_n_100: 0.3091 (0.4458)  triple_100: 0.0000 (0.0252)  triple_80: 0.0000 (0.0234)  triple_60: 0.0000 (0.0107)  triple_40: 0.0000 (0.0119)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1570/1724]  eta: 0:10:03  lr: 0.000200  loss: 1.0969 (1.6672)  loss_n_40: 0.2584 (0.3646)  loss_n_60: 0.2648 (0.3787)  loss_n_80: 0.2815 (0.4082)  loss_n_100: 0.2871 (0.4449)  triple_100: 0.0000 (0.0251)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0106)  triple_40: 0.0000 (0.0118)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1580/1724]  eta: 0:09:24  lr: 0.000200  loss: 1.0450 (1.6642)  loss_n_40: 0.2542 (0.3643)  loss_n_60: 0.2499 (0.3781)  loss_n_80: 0.2636 (0.4074)  loss_n_100: 0.2832 (0.4440)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0231)  triple_60: 0.0000 (0.0105)  triple_40: 0.0000 (0.0118)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1590/1724]  eta: 0:08:44  lr: 0.000200  loss: 1.3206 (1.6645)  loss_n_40: 0.2869 (0.3640)  loss_n_60: 0.3068 (0.3780)  loss_n_80: 0.3430 (0.4074)  loss_n_100: 0.3641 (0.4440)  triple_100: 0.0000 (0.0248)  triple_80: 0.0000 (0.0232)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0121)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1600/1724]  eta: 0:08:05  lr: 0.000200  loss: 1.7404 (1.6668)  loss_n_40: 0.3483 (0.3642)  loss_n_60: 0.4089 (0.3786)  loss_n_80: 0.4546 (0.4080)  loss_n_100: 0.5122 (0.4448)  triple_100: 0.0000 (0.0247)  triple_80: 0.0000 (0.0234)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0120)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1610/1724]  eta: 0:07:26  lr: 0.000200  loss: 1.8679 (1.6700)  loss_n_40: 0.3642 (0.3644)  loss_n_60: 0.4331 (0.3791)  loss_n_80: 0.4845 (0.4087)  loss_n_100: 0.5502 (0.4458)  triple_100: 0.0000 (0.0256)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0110)  triple_40: 0.0000 (0.0119)  time: 3.9171  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [1620/1724]  eta: 0:06:47  lr: 0.000200  loss: 2.0576 (1.6727)  loss_n_40: 0.3968 (0.3646)  loss_n_60: 0.4622 (0.3796)  loss_n_80: 0.5581 (0.4097)  loss_n_100: 0.6479 (0.4472)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0234)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0118)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1630/1724]  eta: 0:06:08  lr: 0.000200  loss: 2.0967 (1.6740)  loss_n_40: 0.3914 (0.3647)  loss_n_60: 0.4368 (0.3799)  loss_n_80: 0.5370 (0.4101)  loss_n_100: 0.6385 (0.4477)  triple_100: 0.0000 (0.0253)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0119)  time: 3.9170  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [1640/1724]  eta: 0:05:29  lr: 0.000200  loss: 1.6976 (1.6738)  loss_n_40: 0.3777 (0.3648)  loss_n_60: 0.4014 (0.3799)  loss_n_80: 0.4369 (0.4101)  loss_n_100: 0.4808 (0.4478)  triple_100: 0.0000 (0.0251)  triple_80: 0.0000 (0.0234)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0118)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1650/1724]  eta: 0:04:49  lr: 0.000200  loss: 1.5650 (1.6727)  loss_n_40: 0.3605 (0.3647)  loss_n_60: 0.3634 (0.3797)  loss_n_80: 0.3777 (0.4099)  loss_n_100: 0.4179 (0.4474)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0232)  triple_60: 0.0000 (0.0107)  triple_40: 0.0000 (0.0121)  time: 3.9161  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1660/1724]  eta: 0:04:10  lr: 0.000200  loss: 1.4915 (1.6721)  loss_n_40: 0.3483 (0.3647)  loss_n_60: 0.3567 (0.3797)  loss_n_80: 0.3833 (0.4099)  loss_n_100: 0.3985 (0.4473)  triple_100: 0.0000 (0.0248)  triple_80: 0.0000 (0.0231)  triple_60: 0.0000 (0.0106)  triple_40: 0.0000 (0.0121)  time: 3.9165  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [1670/1724]  eta: 0:03:31  lr: 0.000200  loss: 1.4915 (1.6707)  loss_n_40: 0.3365 (0.3645)  loss_n_60: 0.3567 (0.3795)  loss_n_80: 0.3815 (0.4096)  loss_n_100: 0.4110 (0.4469)  triple_100: 0.0000 (0.0247)  triple_80: 0.0000 (0.0230)  triple_60: 0.0000 (0.0106)  triple_40: 0.0000 (0.0120)  time: 3.9170  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [1680/1724]  eta: 0:02:52  lr: 0.000200  loss: 1.3047 (1.6681)  loss_n_40: 0.3205 (0.3642)  loss_n_60: 0.3134 (0.3790)  loss_n_80: 0.3326 (0.4090)  loss_n_100: 0.3564 (0.4462)  triple_100: 0.0000 (0.0245)  triple_80: 0.0000 (0.0228)  triple_60: 0.0000 (0.0105)  triple_40: 0.0000 (0.0119)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1690/1724]  eta: 0:02:13  lr: 0.000200  loss: 1.4427 (1.6757)  loss_n_40: 0.3261 (0.3642)  loss_n_60: 0.3353 (0.3792)  loss_n_80: 0.3521 (0.4094)  loss_n_100: 0.3734 (0.4468)  triple_100: 0.0000 (0.0260)  triple_80: 0.0000 (0.0243)  triple_60: 0.0000 (0.0121)  triple_40: 0.0000 (0.0136)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1700/1724]  eta: 0:01:34  lr: 0.000200  loss: 1.9678 (1.6775)  loss_n_40: 0.3914 (0.3646)  loss_n_60: 0.4460 (0.3798)  loss_n_80: 0.5132 (0.4101)  loss_n_100: 0.5552 (0.4475)  triple_100: 0.0000 (0.0258)  triple_80: 0.0000 (0.0241)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0135)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:16]  [1710/1724]  eta: 0:00:54  lr: 0.000200  loss: 1.9507 (1.6795)  loss_n_40: 0.4415 (0.3653)  loss_n_60: 0.4491 (0.3802)  loss_n_80: 0.5154 (0.4107)  loss_n_100: 0.5389 (0.4480)  triple_100: 0.0000 (0.0257)  triple_80: 0.0000 (0.0242)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0134)  time: 3.9167  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [1720/1724]  eta: 0:00:15  lr: 0.000200  loss: 1.9507 (1.6809)  loss_n_40: 0.4637 (0.3659)  loss_n_60: 0.4491 (0.3806)  loss_n_80: 0.5019 (0.4111)  loss_n_100: 0.5309 (0.4484)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0242)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0134)  time: 3.9172  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16]  [1723/1724]  eta: 0:00:03  lr: 0.000200  loss: 1.9318 (1.6812)  loss_n_40: 0.4637 (0.3660)  loss_n_60: 0.4491 (0.3807)  loss_n_80: 0.5019 (0.4112)  loss_n_100: 0.5242 (0.4484)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0241)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0133)  time: 3.9180  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:16] Total time: 1:52:33 (3.9173 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 1.9318 (1.6812)  loss_n_40: 0.4637 (0.3660)  loss_n_60: 0.4491 (0.3807)  loss_n_80: 0.5019 (0.4112)  loss_n_100: 0.5242 (0.4484)  triple_100: 0.0000 (0.0255)  triple_80: 0.0000 (0.0241)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0133)\n",
      "Valid: [epoch:16]  [  0/845]  eta: 0:09:47  loss: 1.5030 (1.5030)  loss_n_40: 0.4069 (0.4069)  loss_n_60: 0.3463 (0.3463)  loss_n_80: 0.3729 (0.3729)  loss_n_100: 0.3769 (0.3769)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.6957  data: 0.3590  max mem: 46473\n",
      "Valid: [epoch:16]  [ 10/845]  eta: 0:05:06  loss: 1.5705 (1.6388)  loss_n_40: 0.3912 (0.4489)  loss_n_60: 0.3518 (0.3691)  loss_n_80: 0.3793 (0.4085)  loss_n_100: 0.3939 (0.4122)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3668  data: 0.0327  max mem: 46473\n",
      "Valid: [epoch:16]  [ 20/845]  eta: 0:04:49  loss: 1.6038 (1.6752)  loss_n_40: 0.3978 (0.4448)  loss_n_60: 0.3576 (0.3843)  loss_n_80: 0.4014 (0.4164)  loss_n_100: 0.4092 (0.4297)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [ 30/845]  eta: 0:04:41  loss: 1.6061 (1.6738)  loss_n_40: 0.4047 (0.4486)  loss_n_60: 0.3652 (0.3882)  loss_n_80: 0.4192 (0.4099)  loss_n_100: 0.4124 (0.4272)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [ 40/845]  eta: 0:04:35  loss: 1.6843 (1.6784)  loss_n_40: 0.4087 (0.4377)  loss_n_60: 0.4040 (0.3907)  loss_n_80: 0.4290 (0.4149)  loss_n_100: 0.4423 (0.4352)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3336  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [ 50/845]  eta: 0:04:31  loss: 1.6638 (1.6572)  loss_n_40: 0.3844 (0.4399)  loss_n_60: 0.4061 (0.3873)  loss_n_80: 0.4030 (0.4049)  loss_n_100: 0.4423 (0.4251)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [ 60/845]  eta: 0:04:26  loss: 1.4243 (1.6352)  loss_n_40: 0.3626 (0.4318)  loss_n_60: 0.3259 (0.3812)  loss_n_80: 0.3555 (0.4018)  loss_n_100: 0.3596 (0.4205)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [ 70/845]  eta: 0:04:22  loss: 1.5002 (1.6300)  loss_n_40: 0.3831 (0.4294)  loss_n_60: 0.3381 (0.3799)  loss_n_80: 0.3661 (0.4012)  loss_n_100: 0.3770 (0.4195)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [ 80/845]  eta: 0:04:18  loss: 1.5002 (1.6047)  loss_n_40: 0.3723 (0.4214)  loss_n_60: 0.3335 (0.3736)  loss_n_80: 0.3551 (0.3960)  loss_n_100: 0.3682 (0.4138)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:16]  [ 90/845]  eta: 0:04:15  loss: 1.4219 (1.6066)  loss_n_40: 0.3734 (0.4200)  loss_n_60: 0.3378 (0.3739)  loss_n_80: 0.3682 (0.3981)  loss_n_100: 0.3682 (0.4147)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:16]  [100/845]  eta: 0:04:11  loss: 1.6541 (1.6328)  loss_n_40: 0.4021 (0.4286)  loss_n_60: 0.3870 (0.3800)  loss_n_80: 0.4238 (0.4034)  loss_n_100: 0.4347 (0.4208)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [110/845]  eta: 0:04:07  loss: 1.7547 (1.6388)  loss_n_40: 0.4124 (0.4271)  loss_n_60: 0.4115 (0.3812)  loss_n_80: 0.4464 (0.4061)  loss_n_100: 0.4657 (0.4244)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [120/845]  eta: 0:04:04  loss: 1.7717 (1.6450)  loss_n_40: 0.4124 (0.4305)  loss_n_60: 0.4132 (0.3824)  loss_n_80: 0.4464 (0.4080)  loss_n_100: 0.4403 (0.4241)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:16]  [130/845]  eta: 0:04:00  loss: 1.5984 (1.6403)  loss_n_40: 0.3920 (0.4302)  loss_n_60: 0.3756 (0.3818)  loss_n_80: 0.4090 (0.4065)  loss_n_100: 0.3843 (0.4219)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [140/845]  eta: 0:03:57  loss: 1.5984 (1.6427)  loss_n_40: 0.4128 (0.4324)  loss_n_60: 0.3642 (0.3825)  loss_n_80: 0.3876 (0.4055)  loss_n_100: 0.3974 (0.4223)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [150/845]  eta: 0:03:53  loss: 1.7421 (1.6452)  loss_n_40: 0.4199 (0.4340)  loss_n_60: 0.4101 (0.3830)  loss_n_80: 0.4042 (0.4053)  loss_n_100: 0.4152 (0.4229)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [160/845]  eta: 0:03:50  loss: 1.6463 (1.6409)  loss_n_40: 0.4125 (0.4319)  loss_n_60: 0.3836 (0.3822)  loss_n_80: 0.4073 (0.4047)  loss_n_100: 0.4152 (0.4222)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [170/845]  eta: 0:03:46  loss: 1.5050 (1.6343)  loss_n_40: 0.3697 (0.4282)  loss_n_60: 0.3389 (0.3804)  loss_n_80: 0.3997 (0.4041)  loss_n_100: 0.3981 (0.4216)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [180/845]  eta: 0:03:43  loss: 1.5878 (1.6384)  loss_n_40: 0.3692 (0.4277)  loss_n_60: 0.3583 (0.3812)  loss_n_80: 0.4152 (0.4059)  loss_n_100: 0.4459 (0.4236)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [190/845]  eta: 0:03:40  loss: 1.5482 (1.6279)  loss_n_40: 0.3888 (0.4244)  loss_n_60: 0.3462 (0.3788)  loss_n_80: 0.3950 (0.4040)  loss_n_100: 0.3935 (0.4208)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [200/845]  eta: 0:03:36  loss: 1.3893 (1.6213)  loss_n_40: 0.3591 (0.4231)  loss_n_60: 0.3236 (0.3773)  loss_n_80: 0.3491 (0.4022)  loss_n_100: 0.3548 (0.4187)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:16]  [210/845]  eta: 0:03:33  loss: 1.2908 (1.6122)  loss_n_40: 0.3392 (0.4198)  loss_n_60: 0.3099 (0.3753)  loss_n_80: 0.3407 (0.4004)  loss_n_100: 0.3540 (0.4168)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:16]  [220/845]  eta: 0:03:29  loss: 1.4850 (1.6216)  loss_n_40: 0.3912 (0.4236)  loss_n_60: 0.3494 (0.3777)  loss_n_80: 0.3808 (0.4017)  loss_n_100: 0.3911 (0.4187)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [230/845]  eta: 0:03:26  loss: 1.5541 (1.6205)  loss_n_40: 0.3979 (0.4224)  loss_n_60: 0.3853 (0.3775)  loss_n_80: 0.3946 (0.4019)  loss_n_100: 0.4101 (0.4187)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [240/845]  eta: 0:03:23  loss: 1.7121 (1.6210)  loss_n_40: 0.3979 (0.4226)  loss_n_60: 0.4010 (0.3777)  loss_n_80: 0.4124 (0.4019)  loss_n_100: 0.4157 (0.4188)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [250/845]  eta: 0:03:19  loss: 1.7121 (1.6165)  loss_n_40: 0.4225 (0.4210)  loss_n_60: 0.4010 (0.3766)  loss_n_80: 0.4124 (0.4011)  loss_n_100: 0.4157 (0.4178)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [260/845]  eta: 0:03:16  loss: 1.4890 (1.6182)  loss_n_40: 0.3737 (0.4215)  loss_n_60: 0.3513 (0.3766)  loss_n_80: 0.3838 (0.4020)  loss_n_100: 0.3914 (0.4182)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [270/845]  eta: 0:03:12  loss: 1.5202 (1.6136)  loss_n_40: 0.3729 (0.4195)  loss_n_60: 0.3629 (0.3754)  loss_n_80: 0.3872 (0.4013)  loss_n_100: 0.3956 (0.4173)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [280/845]  eta: 0:03:09  loss: 1.4954 (1.6121)  loss_n_40: 0.3729 (0.4191)  loss_n_60: 0.3495 (0.3754)  loss_n_80: 0.3771 (0.4006)  loss_n_100: 0.3956 (0.4169)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [290/845]  eta: 0:03:06  loss: 1.3729 (1.6026)  loss_n_40: 0.3557 (0.4160)  loss_n_60: 0.3168 (0.3732)  loss_n_80: 0.3448 (0.3988)  loss_n_100: 0.3571 (0.4147)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [300/845]  eta: 0:03:02  loss: 1.2881 (1.6011)  loss_n_40: 0.3253 (0.4151)  loss_n_60: 0.3148 (0.3727)  loss_n_80: 0.3448 (0.3988)  loss_n_100: 0.3558 (0.4146)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [310/845]  eta: 0:02:59  loss: 1.5638 (1.6002)  loss_n_40: 0.3842 (0.4141)  loss_n_60: 0.3652 (0.3724)  loss_n_80: 0.4027 (0.3989)  loss_n_100: 0.4235 (0.4148)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [320/845]  eta: 0:02:56  loss: 1.4866 (1.5958)  loss_n_40: 0.3754 (0.4122)  loss_n_60: 0.3536 (0.3714)  loss_n_80: 0.3866 (0.3983)  loss_n_100: 0.4012 (0.4139)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [330/845]  eta: 0:02:52  loss: 1.4896 (1.5959)  loss_n_40: 0.3858 (0.4119)  loss_n_60: 0.3535 (0.3715)  loss_n_80: 0.3866 (0.3985)  loss_n_100: 0.3962 (0.4140)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [340/845]  eta: 0:02:49  loss: 1.5113 (1.5949)  loss_n_40: 0.3928 (0.4114)  loss_n_60: 0.3535 (0.3712)  loss_n_80: 0.3986 (0.3985)  loss_n_100: 0.3883 (0.4138)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [350/845]  eta: 0:02:45  loss: 1.5186 (1.5970)  loss_n_40: 0.3828 (0.4109)  loss_n_60: 0.3646 (0.3718)  loss_n_80: 0.4004 (0.3994)  loss_n_100: 0.4126 (0.4149)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [360/845]  eta: 0:02:42  loss: 1.7376 (1.6020)  loss_n_40: 0.3773 (0.4128)  loss_n_60: 0.4129 (0.3730)  loss_n_80: 0.4341 (0.4004)  loss_n_100: 0.4732 (0.4159)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [370/845]  eta: 0:02:39  loss: 1.4863 (1.5982)  loss_n_40: 0.3758 (0.4117)  loss_n_60: 0.3745 (0.3722)  loss_n_80: 0.3885 (0.3994)  loss_n_100: 0.4028 (0.4149)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:16]  [380/845]  eta: 0:02:35  loss: 1.4678 (1.5988)  loss_n_40: 0.3747 (0.4122)  loss_n_60: 0.3373 (0.3728)  loss_n_80: 0.3642 (0.3991)  loss_n_100: 0.3482 (0.4147)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [390/845]  eta: 0:02:32  loss: 1.3014 (1.5932)  loss_n_40: 0.3339 (0.4102)  loss_n_60: 0.3169 (0.3716)  loss_n_80: 0.3448 (0.3980)  loss_n_100: 0.3578 (0.4134)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [400/845]  eta: 0:02:29  loss: 1.3874 (1.5948)  loss_n_40: 0.3643 (0.4112)  loss_n_60: 0.3215 (0.3719)  loss_n_80: 0.3454 (0.3979)  loss_n_100: 0.3635 (0.4138)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [410/845]  eta: 0:02:25  loss: 1.6502 (1.5973)  loss_n_40: 0.4118 (0.4116)  loss_n_60: 0.3884 (0.3727)  loss_n_80: 0.3936 (0.3988)  loss_n_100: 0.4001 (0.4142)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [420/845]  eta: 0:02:22  loss: 1.7371 (1.5988)  loss_n_40: 0.4210 (0.4122)  loss_n_60: 0.3949 (0.3731)  loss_n_80: 0.4229 (0.3989)  loss_n_100: 0.4246 (0.4145)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [430/845]  eta: 0:02:19  loss: 1.5969 (1.5995)  loss_n_40: 0.3846 (0.4114)  loss_n_60: 0.3585 (0.3732)  loss_n_80: 0.4084 (0.3995)  loss_n_100: 0.4246 (0.4154)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [440/845]  eta: 0:02:15  loss: 1.5284 (1.5977)  loss_n_40: 0.3752 (0.4109)  loss_n_60: 0.3730 (0.3728)  loss_n_80: 0.3887 (0.3991)  loss_n_100: 0.3931 (0.4149)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [450/845]  eta: 0:02:12  loss: 1.6173 (1.6005)  loss_n_40: 0.4075 (0.4112)  loss_n_60: 0.3730 (0.3735)  loss_n_80: 0.4252 (0.4000)  loss_n_100: 0.4272 (0.4158)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [460/845]  eta: 0:02:08  loss: 1.5560 (1.6006)  loss_n_40: 0.3799 (0.4105)  loss_n_60: 0.3604 (0.3735)  loss_n_80: 0.4071 (0.4003)  loss_n_100: 0.4096 (0.4162)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [470/845]  eta: 0:02:05  loss: 1.6850 (1.6020)  loss_n_40: 0.3799 (0.4111)  loss_n_60: 0.3395 (0.3738)  loss_n_80: 0.3764 (0.4003)  loss_n_100: 0.4111 (0.4168)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [480/845]  eta: 0:02:02  loss: 1.7336 (1.6030)  loss_n_40: 0.4089 (0.4108)  loss_n_60: 0.4075 (0.3741)  loss_n_80: 0.4328 (0.4008)  loss_n_100: 0.4532 (0.4172)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [490/845]  eta: 0:01:58  loss: 1.5298 (1.6007)  loss_n_40: 0.3910 (0.4104)  loss_n_60: 0.3443 (0.3735)  loss_n_80: 0.3800 (0.4003)  loss_n_100: 0.3892 (0.4165)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [500/845]  eta: 0:01:55  loss: 1.4455 (1.5994)  loss_n_40: 0.3640 (0.4095)  loss_n_60: 0.3364 (0.3733)  loss_n_80: 0.3751 (0.4002)  loss_n_100: 0.3890 (0.4164)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [510/845]  eta: 0:01:52  loss: 1.4190 (1.5972)  loss_n_40: 0.3660 (0.4089)  loss_n_60: 0.3327 (0.3727)  loss_n_80: 0.3489 (0.3997)  loss_n_100: 0.3589 (0.4159)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [520/845]  eta: 0:01:48  loss: 1.5773 (1.5973)  loss_n_40: 0.3852 (0.4088)  loss_n_60: 0.3607 (0.3727)  loss_n_80: 0.4042 (0.3998)  loss_n_100: 0.4141 (0.4160)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [530/845]  eta: 0:01:45  loss: 1.5859 (1.5969)  loss_n_40: 0.3852 (0.4086)  loss_n_60: 0.3641 (0.3728)  loss_n_80: 0.4042 (0.3997)  loss_n_100: 0.4190 (0.4159)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [540/845]  eta: 0:01:42  loss: 1.5031 (1.6002)  loss_n_40: 0.3792 (0.4100)  loss_n_60: 0.3499 (0.3738)  loss_n_80: 0.3995 (0.4002)  loss_n_100: 0.3958 (0.4163)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [550/845]  eta: 0:01:38  loss: 1.6324 (1.5999)  loss_n_40: 0.4005 (0.4098)  loss_n_60: 0.3703 (0.3736)  loss_n_80: 0.3997 (0.4003)  loss_n_100: 0.4098 (0.4162)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [560/845]  eta: 0:01:35  loss: 1.6702 (1.6033)  loss_n_40: 0.3903 (0.4107)  loss_n_60: 0.3917 (0.3747)  loss_n_80: 0.4272 (0.4011)  loss_n_100: 0.4114 (0.4168)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [570/845]  eta: 0:01:32  loss: 1.6707 (1.6041)  loss_n_40: 0.3879 (0.4111)  loss_n_60: 0.3928 (0.3749)  loss_n_80: 0.4060 (0.4011)  loss_n_100: 0.4114 (0.4170)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [580/845]  eta: 0:01:28  loss: 1.5320 (1.6047)  loss_n_40: 0.3877 (0.4115)  loss_n_60: 0.3638 (0.3752)  loss_n_80: 0.3800 (0.4011)  loss_n_100: 0.3834 (0.4169)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [590/845]  eta: 0:01:25  loss: 1.6907 (1.6050)  loss_n_40: 0.3966 (0.4119)  loss_n_60: 0.3781 (0.3752)  loss_n_80: 0.4190 (0.4010)  loss_n_100: 0.4272 (0.4169)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [600/845]  eta: 0:01:22  loss: 1.7650 (1.6065)  loss_n_40: 0.4201 (0.4126)  loss_n_60: 0.4067 (0.3755)  loss_n_80: 0.4195 (0.4012)  loss_n_100: 0.4386 (0.4172)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [610/845]  eta: 0:01:18  loss: 1.4941 (1.6047)  loss_n_40: 0.3948 (0.4119)  loss_n_60: 0.3503 (0.3750)  loss_n_80: 0.3778 (0.4009)  loss_n_100: 0.3848 (0.4169)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [620/845]  eta: 0:01:15  loss: 1.4941 (1.6057)  loss_n_40: 0.3874 (0.4117)  loss_n_60: 0.3546 (0.3753)  loss_n_80: 0.3713 (0.4013)  loss_n_100: 0.3749 (0.4174)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:16]  [630/845]  eta: 0:01:11  loss: 1.7390 (1.6082)  loss_n_40: 0.4109 (0.4121)  loss_n_60: 0.3969 (0.3758)  loss_n_80: 0.4416 (0.4020)  loss_n_100: 0.4695 (0.4182)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [640/845]  eta: 0:01:08  loss: 1.5291 (1.6054)  loss_n_40: 0.3789 (0.4113)  loss_n_60: 0.3410 (0.3752)  loss_n_80: 0.3920 (0.4013)  loss_n_100: 0.4125 (0.4175)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [650/845]  eta: 0:01:05  loss: 1.3030 (1.6025)  loss_n_40: 0.3322 (0.4109)  loss_n_60: 0.3121 (0.3746)  loss_n_80: 0.3326 (0.4005)  loss_n_100: 0.3437 (0.4165)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [660/845]  eta: 0:01:01  loss: 1.3299 (1.6016)  loss_n_40: 0.3227 (0.4105)  loss_n_60: 0.3121 (0.3744)  loss_n_80: 0.3374 (0.4003)  loss_n_100: 0.3527 (0.4163)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [670/845]  eta: 0:00:58  loss: 1.4464 (1.6017)  loss_n_40: 0.3693 (0.4111)  loss_n_60: 0.3319 (0.3744)  loss_n_80: 0.3697 (0.4001)  loss_n_100: 0.3838 (0.4161)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [680/845]  eta: 0:00:55  loss: 1.5348 (1.6016)  loss_n_40: 0.3921 (0.4112)  loss_n_60: 0.3506 (0.3743)  loss_n_80: 0.3820 (0.4000)  loss_n_100: 0.3976 (0.4161)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [690/845]  eta: 0:00:51  loss: 1.6464 (1.6021)  loss_n_40: 0.3793 (0.4111)  loss_n_60: 0.3623 (0.3743)  loss_n_80: 0.4366 (0.4003)  loss_n_100: 0.4063 (0.4164)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [700/845]  eta: 0:00:48  loss: 1.2933 (1.6021)  loss_n_40: 0.3213 (0.4114)  loss_n_60: 0.3098 (0.3743)  loss_n_80: 0.3388 (0.4000)  loss_n_100: 0.3516 (0.4164)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [710/845]  eta: 0:00:45  loss: 1.4930 (1.6037)  loss_n_40: 0.3647 (0.4116)  loss_n_60: 0.3535 (0.3749)  loss_n_80: 0.3857 (0.4004)  loss_n_100: 0.3879 (0.4169)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [720/845]  eta: 0:00:41  loss: 1.4930 (1.6027)  loss_n_40: 0.3761 (0.4112)  loss_n_60: 0.3583 (0.3748)  loss_n_80: 0.3868 (0.4001)  loss_n_100: 0.3879 (0.4166)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [730/845]  eta: 0:00:38  loss: 1.5222 (1.6032)  loss_n_40: 0.4032 (0.4113)  loss_n_60: 0.3583 (0.3750)  loss_n_80: 0.3724 (0.4002)  loss_n_100: 0.3711 (0.4167)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [740/845]  eta: 0:00:35  loss: 1.6133 (1.6028)  loss_n_40: 0.4012 (0.4114)  loss_n_60: 0.3594 (0.3749)  loss_n_80: 0.3724 (0.3999)  loss_n_100: 0.4126 (0.4166)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [750/845]  eta: 0:00:31  loss: 1.6133 (1.6035)  loss_n_40: 0.3968 (0.4112)  loss_n_60: 0.3594 (0.3750)  loss_n_80: 0.3974 (0.4002)  loss_n_100: 0.4155 (0.4171)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [760/845]  eta: 0:00:28  loss: 1.5060 (1.6023)  loss_n_40: 0.3899 (0.4108)  loss_n_60: 0.3340 (0.3747)  loss_n_80: 0.3842 (0.4000)  loss_n_100: 0.3853 (0.4168)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [770/845]  eta: 0:00:25  loss: 1.3798 (1.6018)  loss_n_40: 0.3635 (0.4107)  loss_n_60: 0.3247 (0.3746)  loss_n_80: 0.3406 (0.3999)  loss_n_100: 0.3510 (0.4166)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [780/845]  eta: 0:00:21  loss: 1.3204 (1.5982)  loss_n_40: 0.3422 (0.4096)  loss_n_60: 0.2958 (0.3738)  loss_n_80: 0.3388 (0.3991)  loss_n_100: 0.3456 (0.4157)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [790/845]  eta: 0:00:18  loss: 1.4495 (1.6003)  loss_n_40: 0.3682 (0.4101)  loss_n_60: 0.3624 (0.3744)  loss_n_80: 0.3585 (0.3996)  loss_n_100: 0.3564 (0.4163)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [800/845]  eta: 0:00:15  loss: 1.7178 (1.6015)  loss_n_40: 0.4086 (0.4103)  loss_n_60: 0.4045 (0.3747)  loss_n_80: 0.4465 (0.3999)  loss_n_100: 0.4629 (0.4167)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [810/845]  eta: 0:00:11  loss: 1.7792 (1.6032)  loss_n_40: 0.4353 (0.4112)  loss_n_60: 0.4072 (0.3750)  loss_n_80: 0.4441 (0.4002)  loss_n_100: 0.4629 (0.4169)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [820/845]  eta: 0:00:08  loss: 1.7101 (1.6040)  loss_n_40: 0.3861 (0.4112)  loss_n_60: 0.3891 (0.3752)  loss_n_80: 0.4029 (0.4005)  loss_n_100: 0.4133 (0.4171)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [830/845]  eta: 0:00:05  loss: 1.4045 (1.6023)  loss_n_40: 0.3510 (0.4109)  loss_n_60: 0.3268 (0.3748)  loss_n_80: 0.3683 (0.4000)  loss_n_100: 0.3760 (0.4166)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [840/845]  eta: 0:00:01  loss: 1.3895 (1.6021)  loss_n_40: 0.3688 (0.4107)  loss_n_60: 0.3328 (0.3748)  loss_n_80: 0.3510 (0.4000)  loss_n_100: 0.3547 (0.4166)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16]  [844/845]  eta: 0:00:00  loss: 1.5191 (1.6020)  loss_n_40: 0.3844 (0.4106)  loss_n_60: 0.3566 (0.3748)  loss_n_80: 0.3848 (0.4000)  loss_n_100: 0.3760 (0.4166)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:16] Total time: 0:04:42 (0.3348 s / it)\n",
      "Averaged stats: loss: 1.5191 (1.6020)  loss_n_40: 0.3844 (0.4106)  loss_n_60: 0.3566 (0.3748)  loss_n_80: 0.3848 (0.4000)  loss_n_100: 0.3760 (0.4166)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_16_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 0.417%\n",
      "Min loss_n_100: 0.417\n",
      "Best Epoch: 16.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [   0/1724]  eta: 2:00:52  lr: 0.000200  loss: 1.6381 (1.6381)  loss_n_40: 0.4586 (0.4586)  loss_n_60: 0.3483 (0.3483)  loss_n_80: 0.4082 (0.4082)  loss_n_100: 0.4231 (0.4231)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.2070  data: 0.4511  max mem: 46473\n",
      "Train: [epoch:17]  [  10/1724]  eta: 1:52:43  lr: 0.000200  loss: 1.5732 (1.6457)  loss_n_40: 0.4185 (0.4306)  loss_n_60: 0.3700 (0.3849)  loss_n_80: 0.3926 (0.4071)  loss_n_100: 0.4092 (0.4232)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9458  data: 0.0412  max mem: 46473\n",
      "Train: [epoch:17]  [  20/1724]  eta: 1:51:41  lr: 0.000200  loss: 1.5387 (1.5572)  loss_n_40: 0.3923 (0.4033)  loss_n_60: 0.3603 (0.3679)  loss_n_80: 0.3739 (0.3855)  loss_n_100: 0.3890 (0.4005)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [  30/1724]  eta: 1:50:53  lr: 0.000200  loss: 1.3911 (1.5059)  loss_n_40: 0.3528 (0.3924)  loss_n_60: 0.3320 (0.3566)  loss_n_80: 0.3362 (0.3710)  loss_n_100: 0.3570 (0.3859)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [  40/1724]  eta: 1:50:10  lr: 0.000200  loss: 1.3388 (1.4991)  loss_n_40: 0.3398 (0.3880)  loss_n_60: 0.3189 (0.3515)  loss_n_80: 0.3312 (0.3646)  loss_n_100: 0.3489 (0.3802)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0024)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0124)  time: 3.9185  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [  50/1724]  eta: 1:49:29  lr: 0.000200  loss: 1.2639 (1.4587)  loss_n_40: 0.3360 (0.3780)  loss_n_60: 0.2996 (0.3430)  loss_n_80: 0.3279 (0.3550)  loss_n_100: 0.3370 (0.3708)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0019)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0100)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [  60/1724]  eta: 1:48:48  lr: 0.000200  loss: 1.3226 (1.4487)  loss_n_40: 0.3442 (0.3783)  loss_n_60: 0.3078 (0.3404)  loss_n_80: 0.3279 (0.3523)  loss_n_100: 0.3408 (0.3678)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0016)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0084)  time: 3.9182  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [  70/1724]  eta: 1:48:07  lr: 0.000200  loss: 1.3226 (1.4295)  loss_n_40: 0.3442 (0.3735)  loss_n_60: 0.3206 (0.3359)  loss_n_80: 0.3288 (0.3481)  loss_n_100: 0.3408 (0.3635)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0014)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0072)  time: 3.9176  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [  80/1724]  eta: 1:47:27  lr: 0.000200  loss: 1.1903 (1.4016)  loss_n_40: 0.3134 (0.3661)  loss_n_60: 0.2971 (0.3304)  loss_n_80: 0.2991 (0.3406)  loss_n_100: 0.3106 (0.3553)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0012)  triple_60: 0.0000 (0.0003)  triple_40: 0.0000 (0.0077)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [  90/1724]  eta: 1:46:47  lr: 0.000200  loss: 1.2098 (1.3875)  loss_n_40: 0.3081 (0.3625)  loss_n_60: 0.2914 (0.3268)  loss_n_80: 0.2999 (0.3373)  loss_n_100: 0.3118 (0.3526)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0011)  triple_60: 0.0000 (0.0003)  triple_40: 0.0000 (0.0068)  time: 3.9165  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 100/1724]  eta: 1:46:07  lr: 0.000200  loss: 1.2098 (1.3708)  loss_n_40: 0.2937 (0.3566)  loss_n_60: 0.2821 (0.3230)  loss_n_80: 0.2999 (0.3346)  loss_n_100: 0.3118 (0.3491)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0010)  triple_60: 0.0000 (0.0003)  triple_40: 0.0000 (0.0062)  time: 3.9176  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 110/1724]  eta: 1:45:27  lr: 0.000200  loss: 1.1564 (1.3642)  loss_n_40: 0.3190 (0.3559)  loss_n_60: 0.2789 (0.3216)  loss_n_80: 0.2874 (0.3333)  loss_n_100: 0.3006 (0.3468)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0009)  triple_60: 0.0000 (0.0002)  triple_40: 0.0000 (0.0056)  time: 3.9169  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 120/1724]  eta: 1:44:47  lr: 0.000200  loss: 1.2270 (1.3499)  loss_n_40: 0.3350 (0.3530)  loss_n_60: 0.2789 (0.3183)  loss_n_80: 0.2894 (0.3295)  loss_n_100: 0.3008 (0.3430)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0008)  triple_60: 0.0000 (0.0002)  triple_40: 0.0000 (0.0051)  time: 3.9167  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 130/1724]  eta: 1:44:08  lr: 0.000200  loss: 1.2363 (1.3402)  loss_n_40: 0.3002 (0.3500)  loss_n_60: 0.2898 (0.3160)  loss_n_80: 0.2933 (0.3273)  loss_n_100: 0.3030 (0.3412)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0008)  triple_60: 0.0000 (0.0002)  triple_40: 0.0000 (0.0048)  time: 3.9163  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 140/1724]  eta: 1:43:28  lr: 0.000200  loss: 1.1134 (1.3225)  loss_n_40: 0.2742 (0.3455)  loss_n_60: 0.2726 (0.3121)  loss_n_80: 0.2736 (0.3229)  loss_n_100: 0.2875 (0.3366)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0007)  triple_60: 0.0000 (0.0002)  triple_40: 0.0000 (0.0044)  time: 3.9155  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 150/1724]  eta: 1:42:48  lr: 0.000200  loss: 1.0399 (1.3092)  loss_n_40: 0.2662 (0.3418)  loss_n_60: 0.2434 (0.3093)  loss_n_80: 0.2556 (0.3198)  loss_n_100: 0.2665 (0.3334)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0007)  triple_60: 0.0000 (0.0002)  triple_40: 0.0000 (0.0041)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 160/1724]  eta: 1:42:09  lr: 0.000200  loss: 1.0871 (1.3077)  loss_n_40: 0.2673 (0.3379)  loss_n_60: 0.2608 (0.3070)  loss_n_80: 0.2695 (0.3180)  loss_n_100: 0.2885 (0.3320)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0038)  triple_60: 0.0000 (0.0018)  triple_40: 0.0000 (0.0059)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 170/1724]  eta: 1:41:30  lr: 0.000200  loss: 1.4483 (1.3241)  loss_n_40: 0.3278 (0.3393)  loss_n_60: 0.3146 (0.3105)  loss_n_80: 0.3484 (0.3235)  loss_n_100: 0.3806 (0.3383)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0036)  triple_60: 0.0000 (0.0017)  triple_40: 0.0000 (0.0055)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 180/1724]  eta: 1:40:50  lr: 0.000200  loss: 1.5730 (1.3422)  loss_n_40: 0.3690 (0.3427)  loss_n_60: 0.3655 (0.3145)  loss_n_80: 0.3972 (0.3290)  loss_n_100: 0.4466 (0.3443)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0034)  triple_60: 0.0000 (0.0016)  triple_40: 0.0000 (0.0052)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 190/1724]  eta: 1:40:11  lr: 0.000200  loss: 1.5730 (1.3485)  loss_n_40: 0.3808 (0.3451)  loss_n_60: 0.3509 (0.3158)  loss_n_80: 0.3825 (0.3306)  loss_n_100: 0.4069 (0.3458)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0032)  triple_60: 0.0000 (0.0015)  triple_40: 0.0000 (0.0050)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 200/1724]  eta: 1:39:31  lr: 0.000200  loss: 1.4496 (1.3554)  loss_n_40: 0.3695 (0.3471)  loss_n_60: 0.3458 (0.3176)  loss_n_80: 0.3598 (0.3324)  loss_n_100: 0.3693 (0.3477)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0030)  triple_60: 0.0000 (0.0014)  triple_40: 0.0000 (0.0047)  time: 3.9170  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 210/1724]  eta: 1:38:52  lr: 0.000200  loss: 1.3079 (1.3490)  loss_n_40: 0.3306 (0.3454)  loss_n_60: 0.3093 (0.3164)  loss_n_80: 0.3344 (0.3311)  loss_n_100: 0.3429 (0.3460)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0029)  triple_60: 0.0000 (0.0014)  triple_40: 0.0000 (0.0045)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 220/1724]  eta: 1:38:13  lr: 0.000200  loss: 1.2735 (1.3567)  loss_n_40: 0.2986 (0.3437)  loss_n_60: 0.2955 (0.3160)  loss_n_80: 0.3263 (0.3310)  loss_n_100: 0.3429 (0.3464)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0064)  triple_60: 0.0000 (0.0013)  triple_40: 0.0000 (0.0106)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 230/1724]  eta: 1:37:34  lr: 0.000200  loss: 1.2919 (1.3593)  loss_n_40: 0.2986 (0.3435)  loss_n_60: 0.3072 (0.3167)  loss_n_80: 0.3296 (0.3322)  loss_n_100: 0.3534 (0.3482)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0061)  triple_60: 0.0000 (0.0012)  triple_40: 0.0000 (0.0102)  time: 3.9170  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [ 240/1724]  eta: 1:36:54  lr: 0.000200  loss: 1.3029 (1.4108)  loss_n_40: 0.3028 (0.3426)  loss_n_60: 0.3058 (0.3166)  loss_n_80: 0.3317 (0.3328)  loss_n_100: 0.3466 (0.3487)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0231)  triple_60: 0.0000 (0.0168)  triple_40: 0.0000 (0.0291)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 250/1724]  eta: 1:36:15  lr: 0.000200  loss: 2.3161 (1.4948)  loss_n_40: 0.4163 (0.3481)  loss_n_60: 0.4057 (0.3289)  loss_n_80: 0.4765 (0.3496)  loss_n_100: 0.5254 (0.3704)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0445)  triple_60: 0.0000 (0.0205)  triple_40: 0.0000 (0.0318)  time: 3.9172  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 260/1724]  eta: 1:35:36  lr: 0.000200  loss: 2.7152 (1.5377)  loss_n_40: 0.4957 (0.3550)  loss_n_60: 0.6195 (0.3393)  loss_n_80: 0.7177 (0.3631)  loss_n_100: 0.8306 (0.3861)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0428)  triple_60: 0.0000 (0.0197)  triple_40: 0.0000 (0.0305)  time: 3.9156  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 270/1724]  eta: 1:34:56  lr: 0.000200  loss: 2.4923 (1.5658)  loss_n_40: 0.5117 (0.3618)  loss_n_60: 0.5767 (0.3459)  loss_n_80: 0.6736 (0.3720)  loss_n_100: 0.7347 (0.3956)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0412)  triple_60: 0.0000 (0.0190)  triple_40: 0.0000 (0.0294)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 280/1724]  eta: 1:34:17  lr: 0.000200  loss: 1.9098 (1.5737)  loss_n_40: 0.4041 (0.3634)  loss_n_60: 0.4329 (0.3481)  loss_n_80: 0.5334 (0.3758)  loss_n_100: 0.5394 (0.3990)  triple_100: 0.0000 (0.0010)  triple_80: 0.0000 (0.0397)  triple_60: 0.0000 (0.0183)  triple_40: 0.0000 (0.0284)  time: 3.9152  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 290/1724]  eta: 1:33:38  lr: 0.000200  loss: 1.5541 (1.5743)  loss_n_40: 0.3515 (0.3635)  loss_n_60: 0.3610 (0.3487)  loss_n_80: 0.4145 (0.3774)  loss_n_100: 0.4332 (0.4002)  triple_100: 0.0000 (0.0010)  triple_80: 0.0000 (0.0384)  triple_60: 0.0000 (0.0177)  triple_40: 0.0000 (0.0274)  time: 3.9150  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 300/1724]  eta: 1:32:58  lr: 0.000200  loss: 1.4994 (1.5705)  loss_n_40: 0.3426 (0.3634)  loss_n_60: 0.3526 (0.3485)  loss_n_80: 0.3969 (0.3774)  loss_n_100: 0.3977 (0.3996)  triple_100: 0.0000 (0.0010)  triple_80: 0.0000 (0.0371)  triple_60: 0.0000 (0.0171)  triple_40: 0.0000 (0.0265)  time: 3.9155  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 310/1724]  eta: 1:32:19  lr: 0.000200  loss: 1.4941 (1.5702)  loss_n_40: 0.3504 (0.3642)  loss_n_60: 0.3526 (0.3489)  loss_n_80: 0.3755 (0.3778)  loss_n_100: 0.3977 (0.4003)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0359)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0256)  time: 3.9160  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 320/1724]  eta: 1:31:40  lr: 0.000200  loss: 1.4548 (1.5645)  loss_n_40: 0.3504 (0.3634)  loss_n_60: 0.3222 (0.3481)  loss_n_80: 0.3502 (0.3771)  loss_n_100: 0.3792 (0.3994)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0348)  triple_60: 0.0000 (0.0160)  triple_40: 0.0000 (0.0248)  time: 3.9163  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 330/1724]  eta: 1:31:01  lr: 0.000200  loss: 1.3283 (1.5592)  loss_n_40: 0.3142 (0.3631)  loss_n_60: 0.3142 (0.3473)  loss_n_80: 0.3396 (0.3762)  loss_n_100: 0.3600 (0.3984)  triple_100: 0.0000 (0.0009)  triple_80: 0.0000 (0.0337)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0241)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 340/1724]  eta: 1:30:22  lr: 0.000200  loss: 1.4198 (1.5590)  loss_n_40: 0.3293 (0.3632)  loss_n_60: 0.3345 (0.3476)  loss_n_80: 0.3657 (0.3763)  loss_n_100: 0.3747 (0.3987)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0327)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0234)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 350/1724]  eta: 1:29:42  lr: 0.000200  loss: 1.7906 (1.5709)  loss_n_40: 0.3594 (0.3636)  loss_n_60: 0.3919 (0.3503)  loss_n_80: 0.4443 (0.3807)  loss_n_100: 0.5201 (0.4052)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0318)  triple_60: 0.0000 (0.0151)  triple_40: 0.0000 (0.0227)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 360/1724]  eta: 1:29:03  lr: 0.000200  loss: 1.6465 (1.5681)  loss_n_40: 0.3304 (0.3628)  loss_n_60: 0.3660 (0.3499)  loss_n_80: 0.4443 (0.3807)  loss_n_100: 0.5177 (0.4057)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0309)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0221)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 370/1724]  eta: 1:28:24  lr: 0.000200  loss: 1.5265 (1.5668)  loss_n_40: 0.3167 (0.3620)  loss_n_60: 0.3414 (0.3494)  loss_n_80: 0.3658 (0.3802)  loss_n_100: 0.4003 (0.4055)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0314)  triple_60: 0.0000 (0.0148)  triple_40: 0.0000 (0.0221)  time: 3.9195  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 380/1724]  eta: 1:27:45  lr: 0.000200  loss: 1.5549 (1.5666)  loss_n_40: 0.3427 (0.3620)  loss_n_60: 0.3507 (0.3496)  loss_n_80: 0.4003 (0.3807)  loss_n_100: 0.4144 (0.4064)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0306)  triple_60: 0.0000 (0.0144)  triple_40: 0.0000 (0.0215)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 390/1724]  eta: 1:27:06  lr: 0.000200  loss: 1.5383 (1.5646)  loss_n_40: 0.3550 (0.3616)  loss_n_60: 0.3559 (0.3495)  loss_n_80: 0.4003 (0.3809)  loss_n_100: 0.4200 (0.4064)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0298)  triple_60: 0.0000 (0.0140)  triple_40: 0.0000 (0.0210)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 400/1724]  eta: 1:26:27  lr: 0.000200  loss: 1.4712 (1.5609)  loss_n_40: 0.3550 (0.3621)  loss_n_60: 0.3352 (0.3489)  loss_n_80: 0.3584 (0.3801)  loss_n_100: 0.3757 (0.4054)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0291)  triple_60: 0.0000 (0.0137)  triple_40: 0.0000 (0.0205)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 410/1724]  eta: 1:25:47  lr: 0.000200  loss: 1.3127 (1.5558)  loss_n_40: 0.3390 (0.3614)  loss_n_60: 0.3177 (0.3482)  loss_n_80: 0.3312 (0.3791)  loss_n_100: 0.3340 (0.4041)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0283)  triple_60: 0.0000 (0.0133)  triple_40: 0.0000 (0.0200)  time: 3.9185  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 420/1724]  eta: 1:25:08  lr: 0.000200  loss: 1.2530 (1.5476)  loss_n_40: 0.3070 (0.3600)  loss_n_60: 0.2987 (0.3467)  loss_n_80: 0.3171 (0.3774)  loss_n_100: 0.3305 (0.4021)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0277)  triple_60: 0.0000 (0.0130)  triple_40: 0.0000 (0.0195)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 430/1724]  eta: 1:24:29  lr: 0.000200  loss: 1.2611 (1.5433)  loss_n_40: 0.3089 (0.3600)  loss_n_60: 0.3007 (0.3461)  loss_n_80: 0.3171 (0.3764)  loss_n_100: 0.3333 (0.4008)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0270)  triple_60: 0.0000 (0.0127)  triple_40: 0.0000 (0.0190)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 440/1724]  eta: 1:23:50  lr: 0.000200  loss: 1.2591 (1.5355)  loss_n_40: 0.3211 (0.3586)  loss_n_60: 0.3007 (0.3448)  loss_n_80: 0.3081 (0.3747)  loss_n_100: 0.3273 (0.3988)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0264)  triple_60: 0.0000 (0.0124)  triple_40: 0.0000 (0.0186)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 450/1724]  eta: 1:23:11  lr: 0.000200  loss: 1.1126 (1.5263)  loss_n_40: 0.2744 (0.3568)  loss_n_60: 0.2686 (0.3431)  loss_n_80: 0.2804 (0.3726)  loss_n_100: 0.2940 (0.3965)  triple_100: 0.0000 (0.0012)  triple_80: 0.0000 (0.0258)  triple_60: 0.0000 (0.0122)  triple_40: 0.0000 (0.0182)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 460/1724]  eta: 1:22:31  lr: 0.000200  loss: 1.1749 (1.5196)  loss_n_40: 0.2874 (0.3556)  loss_n_60: 0.2764 (0.3418)  loss_n_80: 0.2955 (0.3712)  loss_n_100: 0.3107 (0.3949)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0119)  triple_40: 0.0000 (0.0178)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 470/1724]  eta: 1:21:52  lr: 0.000200  loss: 1.2222 (1.5134)  loss_n_40: 0.2875 (0.3546)  loss_n_60: 0.2878 (0.3407)  loss_n_80: 0.3060 (0.3697)  loss_n_100: 0.3239 (0.3934)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0247)  triple_60: 0.0000 (0.0116)  triple_40: 0.0000 (0.0175)  time: 3.9157  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [ 480/1724]  eta: 1:21:13  lr: 0.000200  loss: 1.2149 (1.5082)  loss_n_40: 0.3027 (0.3537)  loss_n_60: 0.2878 (0.3397)  loss_n_80: 0.3042 (0.3684)  loss_n_100: 0.3204 (0.3921)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0242)  triple_60: 0.0000 (0.0114)  triple_40: 0.0000 (0.0175)  time: 3.9162  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 490/1724]  eta: 1:20:34  lr: 0.000200  loss: 1.1831 (1.5009)  loss_n_40: 0.2571 (0.3520)  loss_n_60: 0.2699 (0.3383)  loss_n_80: 0.2987 (0.3669)  loss_n_100: 0.3179 (0.3905)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0237)  triple_60: 0.0000 (0.0112)  triple_40: 0.0000 (0.0172)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 500/1724]  eta: 1:19:55  lr: 0.000200  loss: 1.0602 (1.4919)  loss_n_40: 0.2507 (0.3501)  loss_n_60: 0.2506 (0.3365)  loss_n_80: 0.2679 (0.3650)  loss_n_100: 0.2764 (0.3883)  triple_100: 0.0000 (0.0011)  triple_80: 0.0000 (0.0233)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0168)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 510/1724]  eta: 1:19:15  lr: 0.000200  loss: 1.1296 (1.4903)  loss_n_40: 0.2707 (0.3490)  loss_n_60: 0.2739 (0.3360)  loss_n_80: 0.2894 (0.3645)  loss_n_100: 0.2927 (0.3879)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0231)  triple_60: 0.0000 (0.0114)  triple_40: 0.0000 (0.0170)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 520/1724]  eta: 1:18:36  lr: 0.000200  loss: 1.3692 (1.4991)  loss_n_40: 0.3209 (0.3494)  loss_n_60: 0.3180 (0.3368)  loss_n_80: 0.3523 (0.3655)  loss_n_100: 0.3769 (0.3891)  triple_100: 0.0000 (0.0034)  triple_80: 0.0000 (0.0267)  triple_60: 0.0000 (0.0113)  triple_40: 0.0000 (0.0169)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 530/1724]  eta: 1:17:57  lr: 0.000200  loss: 1.7162 (1.5028)  loss_n_40: 0.3836 (0.3502)  loss_n_60: 0.4025 (0.3379)  loss_n_80: 0.4370 (0.3669)  loss_n_100: 0.4621 (0.3906)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0262)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0166)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 540/1724]  eta: 1:17:18  lr: 0.000200  loss: 1.6210 (1.5058)  loss_n_40: 0.3624 (0.3510)  loss_n_60: 0.3778 (0.3391)  loss_n_80: 0.4213 (0.3680)  loss_n_100: 0.4481 (0.3915)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0257)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0163)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 550/1724]  eta: 1:16:39  lr: 0.000200  loss: 1.4480 (1.5039)  loss_n_40: 0.3426 (0.3508)  loss_n_60: 0.3541 (0.3392)  loss_n_80: 0.3704 (0.3677)  loss_n_100: 0.3797 (0.3910)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0253)  triple_60: 0.0000 (0.0107)  triple_40: 0.0000 (0.0160)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 560/1724]  eta: 1:16:00  lr: 0.000200  loss: 1.3512 (1.5024)  loss_n_40: 0.3213 (0.3508)  loss_n_60: 0.3256 (0.3392)  loss_n_80: 0.3262 (0.3675)  loss_n_100: 0.3493 (0.3907)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0248)  triple_60: 0.0000 (0.0105)  triple_40: 0.0000 (0.0157)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 570/1724]  eta: 1:15:20  lr: 0.000200  loss: 1.2854 (1.4985)  loss_n_40: 0.3084 (0.3503)  loss_n_60: 0.3193 (0.3387)  loss_n_80: 0.3237 (0.3666)  loss_n_100: 0.3368 (0.3896)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0244)  triple_60: 0.0000 (0.0103)  triple_40: 0.0000 (0.0155)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 580/1724]  eta: 1:14:41  lr: 0.000200  loss: 1.3210 (1.4976)  loss_n_40: 0.3388 (0.3506)  loss_n_60: 0.3298 (0.3389)  loss_n_80: 0.3312 (0.3665)  loss_n_100: 0.3368 (0.3893)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0239)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0152)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 590/1724]  eta: 1:14:02  lr: 0.000200  loss: 1.3429 (1.4933)  loss_n_40: 0.3401 (0.3499)  loss_n_60: 0.3333 (0.3383)  loss_n_80: 0.3312 (0.3656)  loss_n_100: 0.3360 (0.3881)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0235)  triple_60: 0.0000 (0.0099)  triple_40: 0.0000 (0.0149)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 600/1724]  eta: 1:13:23  lr: 0.000200  loss: 1.1601 (1.4884)  loss_n_40: 0.2844 (0.3491)  loss_n_60: 0.2753 (0.3375)  loss_n_80: 0.2942 (0.3644)  loss_n_100: 0.3056 (0.3868)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0232)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0147)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 610/1724]  eta: 1:12:44  lr: 0.000200  loss: 1.1597 (1.4840)  loss_n_40: 0.2844 (0.3484)  loss_n_60: 0.2745 (0.3368)  loss_n_80: 0.2878 (0.3634)  loss_n_100: 0.2993 (0.3857)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0228)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0144)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 620/1724]  eta: 1:12:05  lr: 0.000200  loss: 1.2292 (1.4797)  loss_n_40: 0.2904 (0.3478)  loss_n_60: 0.2793 (0.3359)  loss_n_80: 0.3127 (0.3625)  loss_n_100: 0.3222 (0.3846)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0224)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0142)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 630/1724]  eta: 1:11:25  lr: 0.000200  loss: 1.1680 (1.4737)  loss_n_40: 0.2719 (0.3466)  loss_n_60: 0.2746 (0.3348)  loss_n_80: 0.2963 (0.3611)  loss_n_100: 0.3097 (0.3831)  triple_100: 0.0000 (0.0028)  triple_80: 0.0000 (0.0221)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0140)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 640/1724]  eta: 1:10:46  lr: 0.000200  loss: 1.0498 (1.4693)  loss_n_40: 0.2616 (0.3458)  loss_n_60: 0.2505 (0.3341)  loss_n_80: 0.2582 (0.3600)  loss_n_100: 0.2711 (0.3818)  triple_100: 0.0000 (0.0028)  triple_80: 0.0000 (0.0217)  triple_60: 0.0000 (0.0092)  triple_40: 0.0000 (0.0139)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 650/1724]  eta: 1:10:07  lr: 0.000200  loss: 1.1320 (1.4648)  loss_n_40: 0.2777 (0.3448)  loss_n_60: 0.2702 (0.3334)  loss_n_80: 0.2860 (0.3590)  loss_n_100: 0.2936 (0.3807)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0214)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0137)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 660/1724]  eta: 1:09:28  lr: 0.000200  loss: 1.1238 (1.4597)  loss_n_40: 0.2725 (0.3441)  loss_n_60: 0.2702 (0.3325)  loss_n_80: 0.2826 (0.3578)  loss_n_100: 0.2936 (0.3792)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0211)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0135)  time: 3.9181  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 670/1724]  eta: 1:08:49  lr: 0.000200  loss: 1.0773 (1.4554)  loss_n_40: 0.2610 (0.3431)  loss_n_60: 0.2676 (0.3318)  loss_n_80: 0.2737 (0.3568)  loss_n_100: 0.2878 (0.3782)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0207)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0133)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 680/1724]  eta: 1:08:10  lr: 0.000200  loss: 1.0907 (1.4506)  loss_n_40: 0.2655 (0.3421)  loss_n_60: 0.2676 (0.3309)  loss_n_80: 0.2813 (0.3557)  loss_n_100: 0.2999 (0.3771)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0204)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0131)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 690/1724]  eta: 1:07:30  lr: 0.000200  loss: 1.0840 (1.4454)  loss_n_40: 0.2643 (0.3411)  loss_n_60: 0.2586 (0.3300)  loss_n_80: 0.2783 (0.3545)  loss_n_100: 0.2860 (0.3757)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0201)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0129)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 700/1724]  eta: 1:06:51  lr: 0.000200  loss: 1.0508 (1.4397)  loss_n_40: 0.2497 (0.3402)  loss_n_60: 0.2511 (0.3289)  loss_n_80: 0.2491 (0.3530)  loss_n_100: 0.2837 (0.3741)  triple_100: 0.0000 (0.0025)  triple_80: 0.0000 (0.0198)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0127)  time: 3.9160  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 710/1724]  eta: 1:06:12  lr: 0.000200  loss: 0.9512 (1.4343)  loss_n_40: 0.2493 (0.3392)  loss_n_60: 0.2311 (0.3278)  loss_n_80: 0.2375 (0.3517)  loss_n_100: 0.2540 (0.3727)  triple_100: 0.0000 (0.0025)  triple_80: 0.0000 (0.0196)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0125)  time: 3.9167  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [ 720/1724]  eta: 1:05:33  lr: 0.000200  loss: 0.9574 (1.4344)  loss_n_40: 0.2266 (0.3383)  loss_n_60: 0.2261 (0.3269)  loss_n_80: 0.2389 (0.3508)  loss_n_100: 0.2540 (0.3719)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0203)  triple_60: 0.0000 (0.0097)  triple_40: 0.0000 (0.0135)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 730/1724]  eta: 1:04:54  lr: 0.000200  loss: 1.4725 (1.4380)  loss_n_40: 0.3225 (0.3386)  loss_n_60: 0.3287 (0.3277)  loss_n_80: 0.3854 (0.3520)  loss_n_100: 0.4229 (0.3735)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0200)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0133)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 740/1724]  eta: 1:04:14  lr: 0.000200  loss: 1.5818 (1.4402)  loss_n_40: 0.3729 (0.3391)  loss_n_60: 0.3686 (0.3283)  loss_n_80: 0.4161 (0.3527)  loss_n_100: 0.4607 (0.3745)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0197)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0131)  time: 3.9183  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 750/1724]  eta: 1:03:35  lr: 0.000200  loss: 1.6182 (1.4466)  loss_n_40: 0.3661 (0.3396)  loss_n_60: 0.3686 (0.3290)  loss_n_80: 0.4080 (0.3536)  loss_n_100: 0.4588 (0.3756)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0214)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0136)  time: 3.9173  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 760/1724]  eta: 1:02:56  lr: 0.000200  loss: 1.5591 (1.4472)  loss_n_40: 0.3397 (0.3395)  loss_n_60: 0.3619 (0.3293)  loss_n_80: 0.3888 (0.3540)  loss_n_100: 0.4243 (0.3761)  triple_100: 0.0000 (0.0041)  triple_80: 0.0000 (0.0211)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0134)  time: 3.9166  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 770/1724]  eta: 1:02:17  lr: 0.000200  loss: 1.4026 (1.4465)  loss_n_40: 0.3246 (0.3394)  loss_n_60: 0.3321 (0.3295)  loss_n_80: 0.3550 (0.3540)  loss_n_100: 0.3736 (0.3761)  triple_100: 0.0000 (0.0040)  triple_80: 0.0000 (0.0208)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0132)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 780/1724]  eta: 1:01:38  lr: 0.000200  loss: 1.3541 (1.4460)  loss_n_40: 0.3246 (0.3393)  loss_n_60: 0.3293 (0.3297)  loss_n_80: 0.3452 (0.3540)  loss_n_100: 0.3736 (0.3761)  triple_100: 0.0000 (0.0040)  triple_80: 0.0000 (0.0206)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0131)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 790/1724]  eta: 1:00:59  lr: 0.000200  loss: 1.3328 (1.4444)  loss_n_40: 0.3253 (0.3392)  loss_n_60: 0.3219 (0.3295)  loss_n_80: 0.3331 (0.3537)  loss_n_100: 0.3409 (0.3757)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0203)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0129)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 800/1724]  eta: 1:00:19  lr: 0.000200  loss: 1.2419 (1.4422)  loss_n_40: 0.3087 (0.3388)  loss_n_60: 0.3041 (0.3292)  loss_n_80: 0.3109 (0.3532)  loss_n_100: 0.3304 (0.3751)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0201)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0127)  time: 3.9184  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 810/1724]  eta: 0:59:40  lr: 0.000200  loss: 1.1730 (1.4385)  loss_n_40: 0.2844 (0.3382)  loss_n_60: 0.2810 (0.3286)  loss_n_80: 0.2854 (0.3523)  loss_n_100: 0.3122 (0.3742)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0198)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0126)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 820/1724]  eta: 0:59:01  lr: 0.000200  loss: 1.1823 (1.4370)  loss_n_40: 0.2981 (0.3382)  loss_n_60: 0.2800 (0.3284)  loss_n_80: 0.2903 (0.3520)  loss_n_100: 0.3062 (0.3737)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0196)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0124)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 830/1724]  eta: 0:58:22  lr: 0.000200  loss: 1.2244 (1.4352)  loss_n_40: 0.3078 (0.3381)  loss_n_60: 0.2916 (0.3282)  loss_n_80: 0.2974 (0.3516)  loss_n_100: 0.3080 (0.3733)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0193)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0123)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 840/1724]  eta: 0:57:43  lr: 0.000200  loss: 1.1349 (1.4320)  loss_n_40: 0.2932 (0.3374)  loss_n_60: 0.2755 (0.3276)  loss_n_80: 0.2834 (0.3509)  loss_n_100: 0.3018 (0.3724)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0191)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0121)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 850/1724]  eta: 0:57:04  lr: 0.000200  loss: 1.1349 (1.4295)  loss_n_40: 0.2703 (0.3370)  loss_n_60: 0.2743 (0.3272)  loss_n_80: 0.2891 (0.3504)  loss_n_100: 0.3046 (0.3718)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0189)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0120)  time: 3.9195  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 860/1724]  eta: 0:56:24  lr: 0.000200  loss: 1.2110 (1.4284)  loss_n_40: 0.2977 (0.3369)  loss_n_60: 0.2954 (0.3272)  loss_n_80: 0.2990 (0.3502)  loss_n_100: 0.3115 (0.3715)  triple_100: 0.0000 (0.0036)  triple_80: 0.0000 (0.0187)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0119)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 870/1724]  eta: 0:55:45  lr: 0.000200  loss: 1.1739 (1.4257)  loss_n_40: 0.2942 (0.3365)  loss_n_60: 0.2861 (0.3268)  loss_n_80: 0.2888 (0.3495)  loss_n_100: 0.3014 (0.3707)  triple_100: 0.0000 (0.0036)  triple_80: 0.0000 (0.0184)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0117)  time: 3.9203  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 880/1724]  eta: 0:55:06  lr: 0.000200  loss: 1.0839 (1.4221)  loss_n_40: 0.2599 (0.3357)  loss_n_60: 0.2621 (0.3261)  loss_n_80: 0.2729 (0.3487)  loss_n_100: 0.2866 (0.3699)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0184)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0116)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 890/1724]  eta: 0:54:27  lr: 0.000200  loss: 1.0520 (1.4192)  loss_n_40: 0.2527 (0.3352)  loss_n_60: 0.2538 (0.3255)  loss_n_80: 0.2607 (0.3480)  loss_n_100: 0.2771 (0.3691)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0182)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0115)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 900/1724]  eta: 0:53:48  lr: 0.000200  loss: 1.0520 (1.4166)  loss_n_40: 0.2598 (0.3347)  loss_n_60: 0.2519 (0.3250)  loss_n_80: 0.2680 (0.3475)  loss_n_100: 0.2868 (0.3685)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0180)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0113)  time: 3.9218  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 910/1724]  eta: 0:53:09  lr: 0.000200  loss: 1.1071 (1.4137)  loss_n_40: 0.2598 (0.3341)  loss_n_60: 0.2598 (0.3245)  loss_n_80: 0.2777 (0.3468)  loss_n_100: 0.2874 (0.3678)  triple_100: 0.0000 (0.0034)  triple_80: 0.0000 (0.0178)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0112)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 920/1724]  eta: 0:52:29  lr: 0.000200  loss: 1.1129 (1.4103)  loss_n_40: 0.2731 (0.3335)  loss_n_60: 0.2707 (0.3239)  loss_n_80: 0.2777 (0.3460)  loss_n_100: 0.2874 (0.3669)  triple_100: 0.0000 (0.0034)  triple_80: 0.0000 (0.0176)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0111)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 930/1724]  eta: 0:51:50  lr: 0.000200  loss: 1.0477 (1.4061)  loss_n_40: 0.2583 (0.3327)  loss_n_60: 0.2466 (0.3230)  loss_n_80: 0.2625 (0.3450)  loss_n_100: 0.2716 (0.3658)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0174)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0110)  time: 3.9189  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 940/1724]  eta: 0:51:11  lr: 0.000200  loss: 1.0411 (1.4022)  loss_n_40: 0.2446 (0.3319)  loss_n_60: 0.2466 (0.3222)  loss_n_80: 0.2625 (0.3441)  loss_n_100: 0.2643 (0.3648)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0172)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0108)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [ 950/1724]  eta: 0:50:32  lr: 0.000200  loss: 1.0393 (1.3984)  loss_n_40: 0.2444 (0.3311)  loss_n_60: 0.2478 (0.3214)  loss_n_80: 0.2616 (0.3433)  loss_n_100: 0.2734 (0.3638)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0170)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0107)  time: 3.9194  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [ 960/1724]  eta: 0:49:53  lr: 0.000200  loss: 0.9968 (1.3942)  loss_n_40: 0.2457 (0.3303)  loss_n_60: 0.2341 (0.3206)  loss_n_80: 0.2502 (0.3423)  loss_n_100: 0.2638 (0.3628)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0168)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0106)  time: 3.9208  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 970/1724]  eta: 0:49:14  lr: 0.000200  loss: 1.0173 (1.3908)  loss_n_40: 0.2551 (0.3296)  loss_n_60: 0.2487 (0.3198)  loss_n_80: 0.2512 (0.3415)  loss_n_100: 0.2677 (0.3619)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0105)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 980/1724]  eta: 0:48:34  lr: 0.000200  loss: 1.0541 (1.3878)  loss_n_40: 0.2624 (0.3289)  loss_n_60: 0.2502 (0.3192)  loss_n_80: 0.2647 (0.3408)  loss_n_100: 0.2848 (0.3612)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0105)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [ 990/1724]  eta: 0:47:55  lr: 0.000200  loss: 1.0441 (1.3845)  loss_n_40: 0.2400 (0.3282)  loss_n_60: 0.2443 (0.3185)  loss_n_80: 0.2673 (0.3400)  loss_n_100: 0.2852 (0.3605)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0104)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1000/1724]  eta: 0:47:16  lr: 0.000200  loss: 1.2454 (1.3917)  loss_n_40: 0.2963 (0.3285)  loss_n_60: 0.2879 (0.3195)  loss_n_80: 0.2957 (0.3415)  loss_n_100: 0.3269 (0.3623)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0174)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0111)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1010/1724]  eta: 0:46:37  lr: 0.000200  loss: 2.1836 (1.4035)  loss_n_40: 0.3945 (0.3294)  loss_n_60: 0.4445 (0.3214)  loss_n_80: 0.5163 (0.3439)  loss_n_100: 0.5987 (0.3653)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0172)  triple_60: 0.0000 (0.0092)  triple_40: 0.0000 (0.0115)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1020/1724]  eta: 0:45:58  lr: 0.000200  loss: 2.1443 (1.4102)  loss_n_40: 0.4209 (0.3303)  loss_n_60: 0.4993 (0.3229)  loss_n_80: 0.5634 (0.3459)  loss_n_100: 0.6412 (0.3678)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0170)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0114)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1030/1724]  eta: 0:45:19  lr: 0.000200  loss: 1.9307 (1.4148)  loss_n_40: 0.4227 (0.3311)  loss_n_60: 0.4356 (0.3239)  loss_n_80: 0.4934 (0.3472)  loss_n_100: 0.5842 (0.3696)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0169)  triple_60: 0.0000 (0.0092)  triple_40: 0.0000 (0.0113)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1040/1724]  eta: 0:44:39  lr: 0.000200  loss: 1.7831 (1.4177)  loss_n_40: 0.4144 (0.3319)  loss_n_60: 0.3999 (0.3245)  loss_n_80: 0.4576 (0.3481)  loss_n_100: 0.4969 (0.3707)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0112)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1050/1724]  eta: 0:44:00  lr: 0.000200  loss: 1.5634 (1.4185)  loss_n_40: 0.3977 (0.3323)  loss_n_60: 0.3650 (0.3248)  loss_n_80: 0.3968 (0.3484)  loss_n_100: 0.4200 (0.3709)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0111)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1060/1724]  eta: 0:43:21  lr: 0.000200  loss: 1.3427 (1.4178)  loss_n_40: 0.3204 (0.3325)  loss_n_60: 0.3131 (0.3247)  loss_n_80: 0.3419 (0.3483)  loss_n_100: 0.3432 (0.3707)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0164)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0110)  time: 3.9176  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1070/1724]  eta: 0:42:42  lr: 0.000200  loss: 1.3625 (1.4189)  loss_n_40: 0.3250 (0.3328)  loss_n_60: 0.3003 (0.3249)  loss_n_80: 0.3465 (0.3486)  loss_n_100: 0.3421 (0.3708)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0163)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0110)  time: 3.9182  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1080/1724]  eta: 0:42:03  lr: 0.000200  loss: 1.4276 (1.4194)  loss_n_40: 0.3357 (0.3330)  loss_n_60: 0.3360 (0.3252)  loss_n_80: 0.3659 (0.3487)  loss_n_100: 0.3887 (0.3710)  triple_100: 0.0000 (0.0056)  triple_80: 0.0000 (0.0162)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0109)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1090/1724]  eta: 0:41:24  lr: 0.000200  loss: 1.3949 (1.4191)  loss_n_40: 0.3357 (0.3330)  loss_n_60: 0.3434 (0.3254)  loss_n_80: 0.3518 (0.3487)  loss_n_100: 0.3694 (0.3710)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0160)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0108)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1100/1724]  eta: 0:40:44  lr: 0.000200  loss: 1.3789 (1.4187)  loss_n_40: 0.3271 (0.3330)  loss_n_60: 0.3434 (0.3255)  loss_n_80: 0.3505 (0.3487)  loss_n_100: 0.3524 (0.3708)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0159)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0107)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1110/1724]  eta: 0:40:05  lr: 0.000200  loss: 1.3201 (1.4183)  loss_n_40: 0.3234 (0.3330)  loss_n_60: 0.3407 (0.3256)  loss_n_80: 0.3377 (0.3487)  loss_n_100: 0.3351 (0.3706)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0106)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1120/1724]  eta: 0:39:26  lr: 0.000200  loss: 1.2600 (1.4166)  loss_n_40: 0.2917 (0.3328)  loss_n_60: 0.3100 (0.3254)  loss_n_80: 0.3180 (0.3484)  loss_n_100: 0.3159 (0.3701)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0105)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1130/1724]  eta: 0:38:47  lr: 0.000200  loss: 1.1273 (1.4146)  loss_n_40: 0.2798 (0.3324)  loss_n_60: 0.2776 (0.3251)  loss_n_80: 0.2827 (0.3480)  loss_n_100: 0.2807 (0.3695)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0104)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1140/1724]  eta: 0:38:08  lr: 0.000200  loss: 1.0913 (1.4116)  loss_n_40: 0.2624 (0.3317)  loss_n_60: 0.2664 (0.3246)  loss_n_80: 0.2743 (0.3473)  loss_n_100: 0.2807 (0.3687)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0103)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1150/1724]  eta: 0:37:28  lr: 0.000200  loss: 1.0913 (1.4091)  loss_n_40: 0.2624 (0.3313)  loss_n_60: 0.2615 (0.3242)  loss_n_80: 0.2730 (0.3468)  loss_n_100: 0.2826 (0.3679)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0152)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0102)  time: 3.9193  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1160/1724]  eta: 0:36:49  lr: 0.000200  loss: 1.1140 (1.4066)  loss_n_40: 0.2848 (0.3309)  loss_n_60: 0.2815 (0.3237)  loss_n_80: 0.2750 (0.3462)  loss_n_100: 0.2714 (0.3672)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0101)  time: 3.9194  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1170/1724]  eta: 0:36:10  lr: 0.000200  loss: 1.1017 (1.4049)  loss_n_40: 0.2600 (0.3304)  loss_n_60: 0.2664 (0.3234)  loss_n_80: 0.2784 (0.3457)  loss_n_100: 0.2796 (0.3666)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0103)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1180/1724]  eta: 0:35:31  lr: 0.000200  loss: 1.2335 (1.4043)  loss_n_40: 0.2667 (0.3301)  loss_n_60: 0.2799 (0.3233)  loss_n_80: 0.3133 (0.3457)  loss_n_100: 0.3285 (0.3666)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0102)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1190/1724]  eta: 0:34:52  lr: 0.000200  loss: 1.4507 (1.4067)  loss_n_40: 0.3033 (0.3301)  loss_n_60: 0.3550 (0.3238)  loss_n_80: 0.3831 (0.3465)  loss_n_100: 0.3982 (0.3676)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0101)  time: 3.9176  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [1200/1724]  eta: 0:34:13  lr: 0.000200  loss: 1.4586 (1.4075)  loss_n_40: 0.3464 (0.3304)  loss_n_60: 0.3541 (0.3241)  loss_n_80: 0.3841 (0.3468)  loss_n_100: 0.4134 (0.3679)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0101)  time: 3.9170  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1210/1724]  eta: 0:33:33  lr: 0.000200  loss: 1.3133 (1.4059)  loss_n_40: 0.2910 (0.3300)  loss_n_60: 0.3124 (0.3238)  loss_n_80: 0.3307 (0.3465)  loss_n_100: 0.3478 (0.3676)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0100)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1220/1724]  eta: 0:32:54  lr: 0.000200  loss: 1.1943 (1.4047)  loss_n_40: 0.2763 (0.3299)  loss_n_60: 0.2816 (0.3237)  loss_n_80: 0.3120 (0.3462)  loss_n_100: 0.3286 (0.3672)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0146)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0099)  time: 3.9168  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1230/1724]  eta: 0:32:15  lr: 0.000200  loss: 1.3306 (1.4049)  loss_n_40: 0.2962 (0.3299)  loss_n_60: 0.3119 (0.3237)  loss_n_80: 0.3258 (0.3463)  loss_n_100: 0.3379 (0.3673)  triple_100: 0.0000 (0.0053)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0098)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1240/1724]  eta: 0:31:36  lr: 0.000200  loss: 1.4376 (1.4063)  loss_n_40: 0.3237 (0.3301)  loss_n_60: 0.3314 (0.3240)  loss_n_80: 0.3632 (0.3467)  loss_n_100: 0.4030 (0.3680)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0097)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1250/1724]  eta: 0:30:57  lr: 0.000200  loss: 1.3620 (1.4058)  loss_n_40: 0.2949 (0.3300)  loss_n_60: 0.3189 (0.3239)  loss_n_80: 0.3505 (0.3467)  loss_n_100: 0.3927 (0.3680)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0097)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1260/1724]  eta: 0:30:17  lr: 0.000200  loss: 1.2764 (1.4046)  loss_n_40: 0.3011 (0.3299)  loss_n_60: 0.3007 (0.3238)  loss_n_80: 0.3213 (0.3464)  loss_n_100: 0.3496 (0.3677)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0096)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1270/1724]  eta: 0:29:38  lr: 0.000200  loss: 1.2083 (1.4026)  loss_n_40: 0.2891 (0.3295)  loss_n_60: 0.2899 (0.3234)  loss_n_80: 0.2965 (0.3459)  loss_n_100: 0.3080 (0.3671)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0095)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1280/1724]  eta: 0:28:59  lr: 0.000200  loss: 1.1654 (1.4011)  loss_n_40: 0.2874 (0.3293)  loss_n_60: 0.2796 (0.3232)  loss_n_80: 0.2876 (0.3456)  loss_n_100: 0.3071 (0.3667)  triple_100: 0.0000 (0.0051)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0094)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1290/1724]  eta: 0:28:20  lr: 0.000200  loss: 1.2187 (1.4004)  loss_n_40: 0.3041 (0.3294)  loss_n_60: 0.3003 (0.3232)  loss_n_80: 0.3027 (0.3454)  loss_n_100: 0.3074 (0.3664)  triple_100: 0.0000 (0.0050)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0094)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1300/1724]  eta: 0:27:41  lr: 0.000200  loss: 1.0447 (1.3976)  loss_n_40: 0.2485 (0.3288)  loss_n_60: 0.2516 (0.3226)  loss_n_80: 0.2656 (0.3448)  loss_n_100: 0.2763 (0.3657)  triple_100: 0.0000 (0.0050)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0093)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1310/1724]  eta: 0:27:02  lr: 0.000200  loss: 1.0447 (1.3963)  loss_n_40: 0.2438 (0.3283)  loss_n_60: 0.2516 (0.3223)  loss_n_80: 0.2656 (0.3444)  loss_n_100: 0.2745 (0.3652)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0093)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1320/1724]  eta: 0:26:22  lr: 0.000200  loss: 1.2587 (1.3962)  loss_n_40: 0.2715 (0.3283)  loss_n_60: 0.2813 (0.3223)  loss_n_80: 0.3116 (0.3444)  loss_n_100: 0.3463 (0.3654)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0093)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1330/1724]  eta: 0:25:43  lr: 0.000200  loss: 1.3588 (1.3962)  loss_n_40: 0.3139 (0.3283)  loss_n_60: 0.3132 (0.3223)  loss_n_80: 0.3529 (0.3445)  loss_n_100: 0.3735 (0.3655)  triple_100: 0.0000 (0.0049)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0092)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1340/1724]  eta: 0:25:04  lr: 0.000200  loss: 1.2930 (1.3955)  loss_n_40: 0.3072 (0.3283)  loss_n_60: 0.3051 (0.3222)  loss_n_80: 0.3356 (0.3444)  loss_n_100: 0.3430 (0.3653)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0135)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0091)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1350/1724]  eta: 0:24:25  lr: 0.000200  loss: 1.2119 (1.3938)  loss_n_40: 0.2989 (0.3280)  loss_n_60: 0.2871 (0.3218)  loss_n_80: 0.3043 (0.3440)  loss_n_100: 0.3197 (0.3649)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0091)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1360/1724]  eta: 0:23:46  lr: 0.000200  loss: 1.1929 (1.3922)  loss_n_40: 0.2885 (0.3277)  loss_n_60: 0.2871 (0.3216)  loss_n_80: 0.2888 (0.3436)  loss_n_100: 0.3018 (0.3644)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0090)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1370/1724]  eta: 0:23:06  lr: 0.000200  loss: 1.1501 (1.3900)  loss_n_40: 0.2800 (0.3273)  loss_n_60: 0.2703 (0.3212)  loss_n_80: 0.2848 (0.3432)  loss_n_100: 0.3018 (0.3638)  triple_100: 0.0000 (0.0047)  triple_80: 0.0000 (0.0132)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0090)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1380/1724]  eta: 0:22:27  lr: 0.000200  loss: 1.0807 (1.3874)  loss_n_40: 0.2584 (0.3268)  loss_n_60: 0.2600 (0.3206)  loss_n_80: 0.2764 (0.3425)  loss_n_100: 0.2859 (0.3631)  triple_100: 0.0000 (0.0047)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0089)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1390/1724]  eta: 0:21:48  lr: 0.000200  loss: 0.9836 (1.3854)  loss_n_40: 0.2301 (0.3262)  loss_n_60: 0.2397 (0.3202)  loss_n_80: 0.2474 (0.3420)  loss_n_100: 0.2607 (0.3625)  triple_100: 0.0000 (0.0047)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0092)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1400/1724]  eta: 0:21:09  lr: 0.000200  loss: 1.1016 (1.3840)  loss_n_40: 0.2450 (0.3260)  loss_n_60: 0.2669 (0.3199)  loss_n_80: 0.2795 (0.3416)  loss_n_100: 0.2783 (0.3621)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0129)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0092)  time: 3.9159  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1410/1724]  eta: 0:20:30  lr: 0.000200  loss: 1.1640 (1.3826)  loss_n_40: 0.2868 (0.3258)  loss_n_60: 0.2765 (0.3197)  loss_n_80: 0.2921 (0.3413)  loss_n_100: 0.3074 (0.3618)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0091)  time: 3.9157  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1420/1724]  eta: 0:19:51  lr: 0.000200  loss: 1.1635 (1.3809)  loss_n_40: 0.2698 (0.3255)  loss_n_60: 0.2751 (0.3193)  loss_n_80: 0.2818 (0.3410)  loss_n_100: 0.2946 (0.3613)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0127)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0091)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1430/1724]  eta: 0:19:11  lr: 0.000200  loss: 1.0122 (1.3782)  loss_n_40: 0.2467 (0.3250)  loss_n_60: 0.2394 (0.3188)  loss_n_80: 0.2515 (0.3403)  loss_n_100: 0.2595 (0.3606)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0126)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0090)  time: 3.9169  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [1440/1724]  eta: 0:18:32  lr: 0.000200  loss: 1.0122 (1.3772)  loss_n_40: 0.2584 (0.3247)  loss_n_60: 0.2408 (0.3185)  loss_n_80: 0.2535 (0.3400)  loss_n_100: 0.2627 (0.3602)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0127)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0090)  time: 3.9169  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1450/1724]  eta: 0:17:53  lr: 0.000200  loss: 1.2044 (1.3766)  loss_n_40: 0.2706 (0.3245)  loss_n_60: 0.2840 (0.3185)  loss_n_80: 0.3077 (0.3399)  loss_n_100: 0.3279 (0.3602)  triple_100: 0.0000 (0.0045)  triple_80: 0.0000 (0.0126)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0089)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1460/1724]  eta: 0:17:14  lr: 0.000200  loss: 1.2742 (1.3763)  loss_n_40: 0.2868 (0.3245)  loss_n_60: 0.3102 (0.3185)  loss_n_80: 0.3267 (0.3399)  loss_n_100: 0.3521 (0.3602)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0125)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0088)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1470/1724]  eta: 0:16:35  lr: 0.000200  loss: 1.2510 (1.3751)  loss_n_40: 0.3039 (0.3242)  loss_n_60: 0.3056 (0.3183)  loss_n_80: 0.3146 (0.3396)  loss_n_100: 0.3431 (0.3599)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0124)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0088)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1480/1724]  eta: 0:15:55  lr: 0.000200  loss: 1.1411 (1.3735)  loss_n_40: 0.2764 (0.3239)  loss_n_60: 0.2770 (0.3180)  loss_n_80: 0.2881 (0.3392)  loss_n_100: 0.3049 (0.3595)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0123)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0087)  time: 3.9181  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1490/1724]  eta: 0:15:16  lr: 0.000200  loss: 1.0299 (1.3709)  loss_n_40: 0.2420 (0.3234)  loss_n_60: 0.2480 (0.3175)  loss_n_80: 0.2602 (0.3386)  loss_n_100: 0.2760 (0.3588)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0087)  time: 3.9190  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1500/1724]  eta: 0:14:37  lr: 0.000200  loss: 1.0848 (1.3858)  loss_n_40: 0.2612 (0.3234)  loss_n_60: 0.2573 (0.3177)  loss_n_80: 0.2688 (0.3392)  loss_n_100: 0.2791 (0.3596)  triple_100: 0.0000 (0.0093)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0103)  triple_40: 0.0000 (0.0106)  time: 3.9193  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1510/1724]  eta: 0:13:58  lr: 0.000200  loss: 3.1210 (1.4033)  loss_n_40: 0.4006 (0.3258)  loss_n_60: 0.5308 (0.3214)  loss_n_80: 0.6826 (0.3440)  loss_n_100: 0.8778 (0.3656)  triple_100: 0.0000 (0.0100)  triple_80: 0.0000 (0.0156)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0105)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1520/1724]  eta: 0:13:19  lr: 0.000200  loss: 4.2301 (1.4216)  loss_n_40: 0.7336 (0.3288)  loss_n_60: 0.8898 (0.3252)  loss_n_80: 1.1584 (0.3493)  loss_n_100: 1.3621 (0.3721)  triple_100: 0.0000 (0.0099)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0103)  triple_40: 0.0000 (0.0104)  time: 3.9184  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1530/1724]  eta: 0:12:40  lr: 0.000200  loss: 3.5983 (1.4329)  loss_n_40: 0.7191 (0.3308)  loss_n_60: 0.8228 (0.3279)  loss_n_80: 0.9477 (0.3524)  loss_n_100: 1.0893 (0.3759)  triple_100: 0.0000 (0.0099)  triple_80: 0.0000 (0.0154)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0104)  time: 3.9179  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1540/1724]  eta: 0:12:00  lr: 0.000200  loss: 2.7056 (1.4401)  loss_n_40: 0.5648 (0.3321)  loss_n_60: 0.6340 (0.3296)  loss_n_80: 0.7057 (0.3544)  loss_n_100: 0.8208 (0.3784)  triple_100: 0.0000 (0.0098)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0103)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1550/1724]  eta: 0:11:21  lr: 0.000200  loss: 2.3239 (1.4451)  loss_n_40: 0.4698 (0.3329)  loss_n_60: 0.5404 (0.3309)  loss_n_80: 0.6060 (0.3559)  loss_n_100: 0.6837 (0.3800)  triple_100: 0.0000 (0.0097)  triple_80: 0.0000 (0.0152)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0102)  time: 3.9184  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1560/1724]  eta: 0:10:42  lr: 0.000200  loss: 2.0283 (1.4483)  loss_n_40: 0.4519 (0.3336)  loss_n_60: 0.4768 (0.3318)  loss_n_80: 0.5286 (0.3569)  loss_n_100: 0.5714 (0.3811)  triple_100: 0.0000 (0.0097)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0102)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1570/1724]  eta: 0:10:03  lr: 0.000200  loss: 1.8680 (1.4504)  loss_n_40: 0.4103 (0.3340)  loss_n_60: 0.4527 (0.3324)  loss_n_80: 0.4832 (0.3575)  loss_n_100: 0.5087 (0.3819)  triple_100: 0.0000 (0.0096)  triple_80: 0.0000 (0.0150)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0101)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1580/1724]  eta: 0:09:24  lr: 0.000200  loss: 1.7161 (1.4518)  loss_n_40: 0.3701 (0.3343)  loss_n_60: 0.4088 (0.3328)  loss_n_80: 0.4447 (0.3579)  loss_n_100: 0.4765 (0.3824)  triple_100: 0.0000 (0.0096)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0099)  triple_40: 0.0000 (0.0100)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1590/1724]  eta: 0:08:45  lr: 0.000200  loss: 1.6692 (1.4529)  loss_n_40: 0.3769 (0.3346)  loss_n_60: 0.3898 (0.3331)  loss_n_80: 0.4062 (0.3582)  loss_n_100: 0.4516 (0.3828)  triple_100: 0.0000 (0.0095)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0100)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1600/1724]  eta: 0:08:05  lr: 0.000200  loss: 1.5728 (1.4537)  loss_n_40: 0.3769 (0.3348)  loss_n_60: 0.3727 (0.3334)  loss_n_80: 0.3866 (0.3585)  loss_n_100: 0.4357 (0.3832)  triple_100: 0.0000 (0.0094)  triple_80: 0.0000 (0.0148)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0099)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1610/1724]  eta: 0:07:26  lr: 0.000200  loss: 1.4751 (1.4544)  loss_n_40: 0.3499 (0.3350)  loss_n_60: 0.3454 (0.3336)  loss_n_80: 0.3802 (0.3587)  loss_n_100: 0.4203 (0.3835)  triple_100: 0.0000 (0.0094)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0098)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1620/1724]  eta: 0:06:47  lr: 0.000200  loss: 1.4713 (1.4546)  loss_n_40: 0.3434 (0.3351)  loss_n_60: 0.3454 (0.3336)  loss_n_80: 0.3727 (0.3587)  loss_n_100: 0.4047 (0.3836)  triple_100: 0.0000 (0.0093)  triple_80: 0.0000 (0.0146)  triple_60: 0.0000 (0.0098)  triple_40: 0.0000 (0.0098)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1630/1724]  eta: 0:06:08  lr: 0.000200  loss: 1.4560 (1.4542)  loss_n_40: 0.3434 (0.3351)  loss_n_60: 0.3490 (0.3336)  loss_n_80: 0.3548 (0.3587)  loss_n_100: 0.4010 (0.3836)  triple_100: 0.0000 (0.0093)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0097)  triple_40: 0.0000 (0.0097)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1640/1724]  eta: 0:05:29  lr: 0.000200  loss: 1.3429 (1.4536)  loss_n_40: 0.3161 (0.3350)  loss_n_60: 0.3161 (0.3335)  loss_n_80: 0.3358 (0.3586)  loss_n_100: 0.3666 (0.3836)  triple_100: 0.0000 (0.0092)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0097)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1650/1724]  eta: 0:04:49  lr: 0.000200  loss: 1.3502 (1.4532)  loss_n_40: 0.3186 (0.3349)  loss_n_60: 0.3161 (0.3335)  loss_n_80: 0.3425 (0.3586)  loss_n_100: 0.3720 (0.3836)  triple_100: 0.0000 (0.0091)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0096)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1660/1724]  eta: 0:04:10  lr: 0.000200  loss: 1.3502 (1.4530)  loss_n_40: 0.3336 (0.3350)  loss_n_60: 0.3104 (0.3334)  loss_n_80: 0.3415 (0.3585)  loss_n_100: 0.3594 (0.3835)  triple_100: 0.0000 (0.0091)  triple_80: 0.0000 (0.0142)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0095)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1670/1724]  eta: 0:03:31  lr: 0.000200  loss: 1.3297 (1.4515)  loss_n_40: 0.3065 (0.3348)  loss_n_60: 0.3057 (0.3331)  loss_n_80: 0.3166 (0.3582)  loss_n_100: 0.3469 (0.3832)  triple_100: 0.0000 (0.0090)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0095)  time: 3.9190  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [1680/1724]  eta: 0:02:52  lr: 0.000200  loss: 1.1875 (1.4499)  loss_n_40: 0.2757 (0.3345)  loss_n_60: 0.2802 (0.3328)  loss_n_80: 0.3013 (0.3578)  loss_n_100: 0.3339 (0.3828)  triple_100: 0.0000 (0.0090)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0094)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1690/1724]  eta: 0:02:13  lr: 0.000200  loss: 1.1426 (1.4483)  loss_n_40: 0.2669 (0.3342)  loss_n_60: 0.2629 (0.3325)  loss_n_80: 0.2930 (0.3574)  loss_n_100: 0.3159 (0.3824)  triple_100: 0.0000 (0.0089)  triple_80: 0.0000 (0.0140)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0094)  time: 3.9185  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1700/1724]  eta: 0:01:34  lr: 0.000200  loss: 1.1426 (1.4471)  loss_n_40: 0.3001 (0.3341)  loss_n_60: 0.2629 (0.3322)  loss_n_80: 0.2854 (0.3571)  loss_n_100: 0.3139 (0.3821)  triple_100: 0.0000 (0.0089)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0093)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:17]  [1710/1724]  eta: 0:00:54  lr: 0.000200  loss: 1.1781 (1.4454)  loss_n_40: 0.2971 (0.3338)  loss_n_60: 0.2823 (0.3319)  loss_n_80: 0.2910 (0.3567)  loss_n_100: 0.3192 (0.3817)  triple_100: 0.0000 (0.0088)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0093)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1720/1724]  eta: 0:00:15  lr: 0.000200  loss: 1.1560 (1.4445)  loss_n_40: 0.2894 (0.3337)  loss_n_60: 0.2756 (0.3317)  loss_n_80: 0.2885 (0.3565)  loss_n_100: 0.3062 (0.3814)  triple_100: 0.0000 (0.0088)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0094)  time: 3.9191  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17]  [1723/1724]  eta: 0:00:03  lr: 0.000200  loss: 1.1529 (1.4441)  loss_n_40: 0.2831 (0.3336)  loss_n_60: 0.2641 (0.3316)  loss_n_80: 0.2881 (0.3564)  loss_n_100: 0.3061 (0.3813)  triple_100: 0.0000 (0.0088)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0093)  time: 3.9189  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:17] Total time: 1:52:35 (3.9183 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 1.1529 (1.4441)  loss_n_40: 0.2831 (0.3336)  loss_n_60: 0.2641 (0.3316)  loss_n_80: 0.2881 (0.3564)  loss_n_100: 0.3061 (0.3813)  triple_100: 0.0000 (0.0088)  triple_80: 0.0000 (0.0137)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0093)\n",
      "Valid: [epoch:17]  [  0/845]  eta: 0:10:03  loss: 0.9919 (0.9919)  loss_n_40: 0.2266 (0.2266)  loss_n_60: 0.2317 (0.2317)  loss_n_80: 0.2627 (0.2627)  loss_n_100: 0.2709 (0.2709)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7139  data: 0.3811  max mem: 46473\n",
      "Valid: [epoch:17]  [ 10/845]  eta: 0:05:07  loss: 0.9823 (1.1096)  loss_n_40: 0.2266 (0.2557)  loss_n_60: 0.2302 (0.2550)  loss_n_80: 0.2525 (0.2804)  loss_n_100: 0.2709 (0.3185)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3686  data: 0.0348  max mem: 46473\n",
      "Valid: [epoch:17]  [ 20/845]  eta: 0:04:50  loss: 1.0564 (1.1870)  loss_n_40: 0.2453 (0.2848)  loss_n_60: 0.2366 (0.2753)  loss_n_80: 0.2755 (0.2959)  loss_n_100: 0.2961 (0.3310)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3338  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [ 30/845]  eta: 0:04:42  loss: 1.0564 (1.1431)  loss_n_40: 0.2454 (0.2791)  loss_n_60: 0.2455 (0.2641)  loss_n_80: 0.2755 (0.2840)  loss_n_100: 0.2941 (0.3159)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [ 40/845]  eta: 0:04:36  loss: 1.0347 (1.1349)  loss_n_40: 0.2415 (0.2732)  loss_n_60: 0.2381 (0.2614)  loss_n_80: 0.2559 (0.2836)  loss_n_100: 0.2750 (0.3168)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [ 50/845]  eta: 0:04:31  loss: 1.0347 (1.1374)  loss_n_40: 0.2415 (0.2705)  loss_n_60: 0.2381 (0.2631)  loss_n_80: 0.2559 (0.2857)  loss_n_100: 0.2827 (0.3182)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [ 60/845]  eta: 0:04:27  loss: 0.9224 (1.1380)  loss_n_40: 0.2379 (0.2707)  loss_n_60: 0.2245 (0.2645)  loss_n_80: 0.2354 (0.2864)  loss_n_100: 0.2650 (0.3165)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [ 70/845]  eta: 0:04:23  loss: 1.1008 (1.1464)  loss_n_40: 0.2596 (0.2734)  loss_n_60: 0.2561 (0.2656)  loss_n_80: 0.2884 (0.2886)  loss_n_100: 0.3090 (0.3189)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [ 80/845]  eta: 0:04:19  loss: 1.1673 (1.1484)  loss_n_40: 0.2643 (0.2725)  loss_n_60: 0.2572 (0.2661)  loss_n_80: 0.2980 (0.2895)  loss_n_100: 0.3241 (0.3204)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [ 90/845]  eta: 0:04:15  loss: 1.1673 (1.1503)  loss_n_40: 0.2481 (0.2711)  loss_n_60: 0.2650 (0.2664)  loss_n_80: 0.3072 (0.2904)  loss_n_100: 0.3470 (0.3224)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [100/845]  eta: 0:04:11  loss: 1.2600 (1.1691)  loss_n_40: 0.2748 (0.2779)  loss_n_60: 0.2777 (0.2714)  loss_n_80: 0.3064 (0.2932)  loss_n_100: 0.3583 (0.3266)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [110/845]  eta: 0:04:08  loss: 1.2067 (1.1748)  loss_n_40: 0.2792 (0.2800)  loss_n_60: 0.2730 (0.2726)  loss_n_80: 0.3094 (0.2949)  loss_n_100: 0.3426 (0.3273)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [120/845]  eta: 0:04:04  loss: 1.0032 (1.1645)  loss_n_40: 0.2432 (0.2764)  loss_n_60: 0.2376 (0.2704)  loss_n_80: 0.2640 (0.2929)  loss_n_100: 0.2861 (0.3248)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [130/845]  eta: 0:04:01  loss: 0.9958 (1.1698)  loss_n_40: 0.2475 (0.2791)  loss_n_60: 0.2344 (0.2721)  loss_n_80: 0.2597 (0.2937)  loss_n_100: 0.2861 (0.3249)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [140/845]  eta: 0:03:57  loss: 1.2270 (1.1725)  loss_n_40: 0.2700 (0.2806)  loss_n_60: 0.2795 (0.2724)  loss_n_80: 0.2992 (0.2939)  loss_n_100: 0.3354 (0.3257)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [150/845]  eta: 0:03:54  loss: 1.2308 (1.1788)  loss_n_40: 0.2872 (0.2820)  loss_n_60: 0.2824 (0.2738)  loss_n_80: 0.2976 (0.2954)  loss_n_100: 0.3354 (0.3276)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [160/845]  eta: 0:03:50  loss: 1.1509 (1.1766)  loss_n_40: 0.2753 (0.2815)  loss_n_60: 0.2755 (0.2735)  loss_n_80: 0.2974 (0.2950)  loss_n_100: 0.3102 (0.3266)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [170/845]  eta: 0:03:47  loss: 1.0915 (1.1791)  loss_n_40: 0.2548 (0.2827)  loss_n_60: 0.2494 (0.2739)  loss_n_80: 0.2812 (0.2950)  loss_n_100: 0.3085 (0.3274)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:17]  [180/845]  eta: 0:03:43  loss: 1.0901 (1.1749)  loss_n_40: 0.2548 (0.2816)  loss_n_60: 0.2494 (0.2726)  loss_n_80: 0.2804 (0.2939)  loss_n_100: 0.2981 (0.3268)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [190/845]  eta: 0:03:40  loss: 1.1316 (1.1760)  loss_n_40: 0.2674 (0.2821)  loss_n_60: 0.2660 (0.2730)  loss_n_80: 0.2872 (0.2940)  loss_n_100: 0.3044 (0.3268)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [200/845]  eta: 0:03:36  loss: 1.0933 (1.1698)  loss_n_40: 0.2553 (0.2801)  loss_n_60: 0.2524 (0.2715)  loss_n_80: 0.2813 (0.2927)  loss_n_100: 0.3044 (0.3255)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [210/845]  eta: 0:03:33  loss: 1.0627 (1.1666)  loss_n_40: 0.2371 (0.2789)  loss_n_60: 0.2410 (0.2706)  loss_n_80: 0.2698 (0.2922)  loss_n_100: 0.2890 (0.3248)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [220/845]  eta: 0:03:29  loss: 1.0722 (1.1670)  loss_n_40: 0.2540 (0.2784)  loss_n_60: 0.2422 (0.2708)  loss_n_80: 0.2822 (0.2925)  loss_n_100: 0.3061 (0.3252)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [230/845]  eta: 0:03:26  loss: 1.1682 (1.1705)  loss_n_40: 0.2566 (0.2794)  loss_n_60: 0.2705 (0.2713)  loss_n_80: 0.3031 (0.2937)  loss_n_100: 0.3232 (0.3261)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [240/845]  eta: 0:03:23  loss: 1.0976 (1.1693)  loss_n_40: 0.2634 (0.2793)  loss_n_60: 0.2541 (0.2711)  loss_n_80: 0.2838 (0.2933)  loss_n_100: 0.3101 (0.3256)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [250/845]  eta: 0:03:19  loss: 1.1587 (1.1700)  loss_n_40: 0.2634 (0.2799)  loss_n_60: 0.2633 (0.2713)  loss_n_80: 0.2876 (0.2932)  loss_n_100: 0.3351 (0.3256)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [260/845]  eta: 0:03:16  loss: 1.1878 (1.1727)  loss_n_40: 0.2663 (0.2805)  loss_n_60: 0.2671 (0.2717)  loss_n_80: 0.3121 (0.2941)  loss_n_100: 0.3410 (0.3265)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [270/845]  eta: 0:03:12  loss: 1.2291 (1.1706)  loss_n_40: 0.2588 (0.2797)  loss_n_60: 0.2671 (0.2713)  loss_n_80: 0.2999 (0.2936)  loss_n_100: 0.3487 (0.3260)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [280/845]  eta: 0:03:09  loss: 1.0964 (1.1680)  loss_n_40: 0.2368 (0.2785)  loss_n_60: 0.2450 (0.2706)  loss_n_80: 0.2891 (0.2932)  loss_n_100: 0.3168 (0.3257)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [290/845]  eta: 0:03:06  loss: 0.9955 (1.1644)  loss_n_40: 0.2234 (0.2771)  loss_n_60: 0.2346 (0.2698)  loss_n_80: 0.2633 (0.2925)  loss_n_100: 0.2885 (0.3250)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [300/845]  eta: 0:03:02  loss: 0.9955 (1.1619)  loss_n_40: 0.2234 (0.2759)  loss_n_60: 0.2301 (0.2693)  loss_n_80: 0.2633 (0.2921)  loss_n_100: 0.2885 (0.3246)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [310/845]  eta: 0:02:59  loss: 1.1588 (1.1632)  loss_n_40: 0.2547 (0.2756)  loss_n_60: 0.2677 (0.2695)  loss_n_80: 0.3019 (0.2927)  loss_n_100: 0.3411 (0.3254)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [320/845]  eta: 0:02:56  loss: 1.1608 (1.1623)  loss_n_40: 0.2547 (0.2751)  loss_n_60: 0.2677 (0.2692)  loss_n_80: 0.3023 (0.2926)  loss_n_100: 0.3420 (0.3254)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [330/845]  eta: 0:02:52  loss: 1.1608 (1.1631)  loss_n_40: 0.2598 (0.2756)  loss_n_60: 0.2598 (0.2694)  loss_n_80: 0.3000 (0.2927)  loss_n_100: 0.3207 (0.3254)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [340/845]  eta: 0:02:49  loss: 1.2053 (1.1654)  loss_n_40: 0.2623 (0.2761)  loss_n_60: 0.2736 (0.2699)  loss_n_80: 0.3000 (0.2933)  loss_n_100: 0.3207 (0.3261)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [350/845]  eta: 0:02:46  loss: 1.0110 (1.1637)  loss_n_40: 0.2385 (0.2765)  loss_n_60: 0.2260 (0.2695)  loss_n_80: 0.2584 (0.2923)  loss_n_100: 0.2841 (0.3254)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [360/845]  eta: 0:02:42  loss: 0.9557 (1.1610)  loss_n_40: 0.2165 (0.2758)  loss_n_60: 0.2150 (0.2689)  loss_n_80: 0.2474 (0.2915)  loss_n_100: 0.2637 (0.3247)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [370/845]  eta: 0:02:39  loss: 0.9867 (1.1588)  loss_n_40: 0.2419 (0.2750)  loss_n_60: 0.2319 (0.2683)  loss_n_80: 0.2483 (0.2912)  loss_n_100: 0.2846 (0.3242)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [380/845]  eta: 0:02:35  loss: 0.9776 (1.1548)  loss_n_40: 0.2388 (0.2739)  loss_n_60: 0.2299 (0.2675)  loss_n_80: 0.2428 (0.2903)  loss_n_100: 0.2704 (0.3231)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [390/845]  eta: 0:02:32  loss: 1.0579 (1.1541)  loss_n_40: 0.2385 (0.2735)  loss_n_60: 0.2451 (0.2673)  loss_n_80: 0.2785 (0.2903)  loss_n_100: 0.2968 (0.3229)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [400/845]  eta: 0:02:29  loss: 1.1455 (1.1574)  loss_n_40: 0.2619 (0.2744)  loss_n_60: 0.2565 (0.2679)  loss_n_80: 0.3036 (0.2910)  loss_n_100: 0.3426 (0.3240)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [410/845]  eta: 0:02:25  loss: 1.2773 (1.1600)  loss_n_40: 0.2797 (0.2753)  loss_n_60: 0.2955 (0.2685)  loss_n_80: 0.3189 (0.2915)  loss_n_100: 0.3648 (0.3247)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [420/845]  eta: 0:02:22  loss: 1.2208 (1.1601)  loss_n_40: 0.2946 (0.2753)  loss_n_60: 0.2800 (0.2685)  loss_n_80: 0.3129 (0.2916)  loss_n_100: 0.3292 (0.3247)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:17]  [430/845]  eta: 0:02:19  loss: 1.0644 (1.1622)  loss_n_40: 0.2428 (0.2763)  loss_n_60: 0.2548 (0.2690)  loss_n_80: 0.2793 (0.2920)  loss_n_100: 0.2984 (0.3249)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [440/845]  eta: 0:02:15  loss: 1.2130 (1.1634)  loss_n_40: 0.2656 (0.2764)  loss_n_60: 0.2744 (0.2693)  loss_n_80: 0.3088 (0.2924)  loss_n_100: 0.3001 (0.3254)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [450/845]  eta: 0:02:12  loss: 1.2130 (1.1629)  loss_n_40: 0.2656 (0.2760)  loss_n_60: 0.2747 (0.2691)  loss_n_80: 0.3112 (0.2923)  loss_n_100: 0.3547 (0.3255)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [460/845]  eta: 0:02:09  loss: 1.1074 (1.1617)  loss_n_40: 0.2531 (0.2756)  loss_n_60: 0.2584 (0.2687)  loss_n_80: 0.2924 (0.2920)  loss_n_100: 0.3215 (0.3253)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [470/845]  eta: 0:02:05  loss: 1.1011 (1.1608)  loss_n_40: 0.2477 (0.2755)  loss_n_60: 0.2428 (0.2684)  loss_n_80: 0.2834 (0.2918)  loss_n_100: 0.3041 (0.3252)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [480/845]  eta: 0:02:02  loss: 1.1147 (1.1599)  loss_n_40: 0.2477 (0.2750)  loss_n_60: 0.2515 (0.2682)  loss_n_80: 0.2839 (0.2917)  loss_n_100: 0.3216 (0.3250)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [490/845]  eta: 0:01:58  loss: 1.1484 (1.1598)  loss_n_40: 0.2597 (0.2750)  loss_n_60: 0.2607 (0.2681)  loss_n_80: 0.2973 (0.2916)  loss_n_100: 0.3305 (0.3251)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [500/845]  eta: 0:01:55  loss: 1.0593 (1.1609)  loss_n_40: 0.2498 (0.2753)  loss_n_60: 0.2472 (0.2684)  loss_n_80: 0.2761 (0.2918)  loss_n_100: 0.3009 (0.3254)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [510/845]  eta: 0:01:52  loss: 1.0704 (1.1617)  loss_n_40: 0.2498 (0.2754)  loss_n_60: 0.2399 (0.2686)  loss_n_80: 0.2761 (0.2921)  loss_n_100: 0.3102 (0.3256)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [520/845]  eta: 0:01:48  loss: 1.1393 (1.1627)  loss_n_40: 0.2705 (0.2756)  loss_n_60: 0.2601 (0.2689)  loss_n_80: 0.2850 (0.2923)  loss_n_100: 0.3327 (0.3259)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [530/845]  eta: 0:01:45  loss: 1.1393 (1.1631)  loss_n_40: 0.2705 (0.2761)  loss_n_60: 0.2601 (0.2689)  loss_n_80: 0.2850 (0.2923)  loss_n_100: 0.3327 (0.3258)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [540/845]  eta: 0:01:42  loss: 1.2108 (1.1640)  loss_n_40: 0.2714 (0.2768)  loss_n_60: 0.2696 (0.2691)  loss_n_80: 0.3201 (0.2924)  loss_n_100: 0.3446 (0.3257)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [550/845]  eta: 0:01:38  loss: 1.0597 (1.1638)  loss_n_40: 0.2493 (0.2766)  loss_n_60: 0.2365 (0.2691)  loss_n_80: 0.2707 (0.2923)  loss_n_100: 0.2933 (0.3257)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [560/845]  eta: 0:01:35  loss: 1.0597 (1.1627)  loss_n_40: 0.2493 (0.2762)  loss_n_60: 0.2365 (0.2688)  loss_n_80: 0.2646 (0.2922)  loss_n_100: 0.2828 (0.3255)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [570/845]  eta: 0:01:32  loss: 1.0734 (1.1623)  loss_n_40: 0.2522 (0.2762)  loss_n_60: 0.2519 (0.2686)  loss_n_80: 0.2663 (0.2920)  loss_n_100: 0.3057 (0.3255)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [580/845]  eta: 0:01:28  loss: 1.1821 (1.1655)  loss_n_40: 0.2544 (0.2771)  loss_n_60: 0.2713 (0.2694)  loss_n_80: 0.2893 (0.2927)  loss_n_100: 0.3484 (0.3263)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [590/845]  eta: 0:01:25  loss: 1.1250 (1.1635)  loss_n_40: 0.2544 (0.2764)  loss_n_60: 0.2623 (0.2690)  loss_n_80: 0.2890 (0.2923)  loss_n_100: 0.3173 (0.3257)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [600/845]  eta: 0:01:22  loss: 1.0093 (1.1635)  loss_n_40: 0.2322 (0.2769)  loss_n_60: 0.2246 (0.2689)  loss_n_80: 0.2636 (0.2922)  loss_n_100: 0.2848 (0.3255)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [610/845]  eta: 0:01:18  loss: 1.0125 (1.1634)  loss_n_40: 0.2375 (0.2771)  loss_n_60: 0.2338 (0.2689)  loss_n_80: 0.2636 (0.2921)  loss_n_100: 0.2874 (0.3253)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [620/845]  eta: 0:01:15  loss: 1.0891 (1.1632)  loss_n_40: 0.2547 (0.2770)  loss_n_60: 0.2546 (0.2688)  loss_n_80: 0.2686 (0.2922)  loss_n_100: 0.2966 (0.3253)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [630/845]  eta: 0:01:12  loss: 1.1142 (1.1643)  loss_n_40: 0.2548 (0.2778)  loss_n_60: 0.2546 (0.2691)  loss_n_80: 0.2764 (0.2923)  loss_n_100: 0.3099 (0.3252)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [640/845]  eta: 0:01:08  loss: 1.0242 (1.1622)  loss_n_40: 0.2443 (0.2774)  loss_n_60: 0.2313 (0.2686)  loss_n_80: 0.2545 (0.2918)  loss_n_100: 0.2788 (0.3245)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:17]  [650/845]  eta: 0:01:05  loss: 1.0383 (1.1623)  loss_n_40: 0.2443 (0.2773)  loss_n_60: 0.2384 (0.2686)  loss_n_80: 0.2663 (0.2918)  loss_n_100: 0.2918 (0.3246)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [660/845]  eta: 0:01:01  loss: 1.1557 (1.1627)  loss_n_40: 0.2606 (0.2772)  loss_n_60: 0.2643 (0.2687)  loss_n_80: 0.2998 (0.2920)  loss_n_100: 0.3367 (0.3248)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [670/845]  eta: 0:00:58  loss: 1.1557 (1.1653)  loss_n_40: 0.2746 (0.2782)  loss_n_60: 0.2663 (0.2693)  loss_n_80: 0.2998 (0.2926)  loss_n_100: 0.3367 (0.3253)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:17]  [680/845]  eta: 0:00:55  loss: 1.1425 (1.1635)  loss_n_40: 0.2575 (0.2776)  loss_n_60: 0.2560 (0.2688)  loss_n_80: 0.2795 (0.2922)  loss_n_100: 0.3102 (0.3249)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [690/845]  eta: 0:00:51  loss: 0.9792 (1.1613)  loss_n_40: 0.2298 (0.2771)  loss_n_60: 0.2266 (0.2683)  loss_n_80: 0.2501 (0.2917)  loss_n_100: 0.2697 (0.3243)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [700/845]  eta: 0:00:48  loss: 1.0727 (1.1625)  loss_n_40: 0.2560 (0.2772)  loss_n_60: 0.2487 (0.2686)  loss_n_80: 0.2789 (0.2920)  loss_n_100: 0.3076 (0.3247)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [710/845]  eta: 0:00:45  loss: 1.1457 (1.1612)  loss_n_40: 0.2733 (0.2768)  loss_n_60: 0.2599 (0.2683)  loss_n_80: 0.2867 (0.2917)  loss_n_100: 0.3220 (0.3244)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [720/845]  eta: 0:00:41  loss: 1.0070 (1.1609)  loss_n_40: 0.2389 (0.2768)  loss_n_60: 0.2344 (0.2683)  loss_n_80: 0.2520 (0.2916)  loss_n_100: 0.2754 (0.3242)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [730/845]  eta: 0:00:38  loss: 1.0036 (1.1631)  loss_n_40: 0.2324 (0.2774)  loss_n_60: 0.2314 (0.2687)  loss_n_80: 0.2527 (0.2921)  loss_n_100: 0.2840 (0.3248)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [740/845]  eta: 0:00:35  loss: 1.2490 (1.1650)  loss_n_40: 0.2697 (0.2781)  loss_n_60: 0.2794 (0.2691)  loss_n_80: 0.3240 (0.2925)  loss_n_100: 0.3606 (0.3253)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [750/845]  eta: 0:00:31  loss: 1.1925 (1.1632)  loss_n_40: 0.2628 (0.2776)  loss_n_60: 0.2748 (0.2687)  loss_n_80: 0.3095 (0.2921)  loss_n_100: 0.2977 (0.3248)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [760/845]  eta: 0:00:28  loss: 0.9777 (1.1630)  loss_n_40: 0.2286 (0.2776)  loss_n_60: 0.2333 (0.2686)  loss_n_80: 0.2489 (0.2921)  loss_n_100: 0.2768 (0.3247)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [770/845]  eta: 0:00:25  loss: 1.0775 (1.1624)  loss_n_40: 0.2362 (0.2775)  loss_n_60: 0.2476 (0.2686)  loss_n_80: 0.2837 (0.2919)  loss_n_100: 0.3001 (0.3244)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [780/845]  eta: 0:00:21  loss: 1.0775 (1.1620)  loss_n_40: 0.2461 (0.2773)  loss_n_60: 0.2476 (0.2684)  loss_n_80: 0.2837 (0.2919)  loss_n_100: 0.3001 (0.3244)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [790/845]  eta: 0:00:18  loss: 1.1170 (1.1633)  loss_n_40: 0.2542 (0.2776)  loss_n_60: 0.2567 (0.2688)  loss_n_80: 0.2859 (0.2922)  loss_n_100: 0.3177 (0.3247)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [800/845]  eta: 0:00:15  loss: 1.1696 (1.1634)  loss_n_40: 0.2505 (0.2777)  loss_n_60: 0.2603 (0.2688)  loss_n_80: 0.2949 (0.2920)  loss_n_100: 0.3428 (0.3248)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [810/845]  eta: 0:00:11  loss: 1.1026 (1.1622)  loss_n_40: 0.2468 (0.2773)  loss_n_60: 0.2553 (0.2685)  loss_n_80: 0.2645 (0.2918)  loss_n_100: 0.3141 (0.3245)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [820/845]  eta: 0:00:08  loss: 1.1026 (1.1644)  loss_n_40: 0.2575 (0.2779)  loss_n_60: 0.2553 (0.2690)  loss_n_80: 0.2866 (0.2924)  loss_n_100: 0.3141 (0.3251)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [830/845]  eta: 0:00:05  loss: 1.0799 (1.1655)  loss_n_40: 0.2607 (0.2785)  loss_n_60: 0.2472 (0.2694)  loss_n_80: 0.2756 (0.2924)  loss_n_100: 0.3027 (0.3252)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [840/845]  eta: 0:00:01  loss: 1.1717 (1.1656)  loss_n_40: 0.2648 (0.2784)  loss_n_60: 0.2606 (0.2694)  loss_n_80: 0.2996 (0.2925)  loss_n_100: 0.3408 (0.3253)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17]  [844/845]  eta: 0:00:00  loss: 1.0799 (1.1644)  loss_n_40: 0.2607 (0.2780)  loss_n_60: 0.2472 (0.2691)  loss_n_80: 0.2756 (0.2922)  loss_n_100: 0.2963 (0.3250)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:17] Total time: 0:04:43 (0.3350 s / it)\n",
      "Averaged stats: loss: 1.0799 (1.1644)  loss_n_40: 0.2607 (0.2780)  loss_n_60: 0.2472 (0.2691)  loss_n_80: 0.2756 (0.2922)  loss_n_100: 0.2963 (0.3250)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_17_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 0.325%\n",
      "Min loss_n_100: 0.325\n",
      "Best Epoch: 17.000\n",
      "Train: [epoch:18]  [   0/1724]  eta: 1:59:01  lr: 0.000200  loss: 1.2032 (1.2032)  loss_n_40: 0.2707 (0.2707)  loss_n_60: 0.2772 (0.2772)  loss_n_80: 0.3093 (0.3093)  loss_n_100: 0.3460 (0.3460)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1422  data: 0.3894  max mem: 46473\n",
      "Train: [epoch:18]  [  10/1724]  eta: 1:52:34  lr: 0.000200  loss: 1.1979 (1.1955)  loss_n_40: 0.2707 (0.2799)  loss_n_60: 0.2772 (0.2802)  loss_n_80: 0.3049 (0.3038)  loss_n_100: 0.3260 (0.3317)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9407  data: 0.0356  max mem: 46473\n",
      "Train: [epoch:18]  [  20/1724]  eta: 1:51:37  lr: 0.000200  loss: 1.1568 (1.1848)  loss_n_40: 0.2830 (0.2897)  loss_n_60: 0.2696 (0.2780)  loss_n_80: 0.2913 (0.2966)  loss_n_100: 0.3052 (0.3205)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9201  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [  30/1724]  eta: 1:50:51  lr: 0.000200  loss: 1.1425 (1.1804)  loss_n_40: 0.2816 (0.2943)  loss_n_60: 0.2652 (0.2763)  loss_n_80: 0.2814 (0.2937)  loss_n_100: 0.2948 (0.3162)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [  40/1724]  eta: 1:50:08  lr: 0.000200  loss: 1.1135 (1.1672)  loss_n_40: 0.2816 (0.2958)  loss_n_60: 0.2603 (0.2732)  loss_n_80: 0.2727 (0.2875)  loss_n_100: 0.2960 (0.3108)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9176  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [  50/1724]  eta: 1:49:27  lr: 0.000200  loss: 1.2896 (2.0151)  loss_n_40: 0.3715 (0.3405)  loss_n_60: 0.2938 (0.3517)  loss_n_80: 0.2963 (0.3982)  loss_n_100: 0.3313 (0.4556)  triple_100: 0.0000 (0.1623)  triple_80: 0.0000 (0.1065)  triple_60: 0.0000 (0.0732)  triple_40: 0.0000 (0.1272)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [  60/1724]  eta: 1:48:47  lr: 0.000200  loss: 4.3079 (2.3734)  loss_n_40: 0.6634 (0.4158)  loss_n_60: 0.8353 (0.4519)  loss_n_80: 1.0676 (0.5177)  loss_n_100: 1.2623 (0.5947)  triple_100: 0.0000 (0.1357)  triple_80: 0.0000 (0.0890)  triple_60: 0.0000 (0.0612)  triple_40: 0.0000 (0.1074)  time: 3.9195  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [  70/1724]  eta: 1:48:07  lr: 0.000200  loss: 3.7708 (2.5537)  loss_n_40: 0.7102 (0.4507)  loss_n_60: 0.8684 (0.5071)  loss_n_80: 1.0312 (0.5854)  loss_n_100: 1.1761 (0.6726)  triple_100: 0.0000 (0.1166)  triple_80: 0.0000 (0.0765)  triple_60: 0.0000 (0.0526)  triple_40: 0.0000 (0.0923)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [  80/1724]  eta: 1:47:27  lr: 0.000200  loss: 3.1278 (2.5667)  loss_n_40: 0.5709 (0.4606)  loss_n_60: 0.7166 (0.5214)  loss_n_80: 0.8057 (0.5996)  loss_n_100: 0.9359 (0.6888)  triple_100: 0.0000 (0.1022)  triple_80: 0.0000 (0.0670)  triple_60: 0.0000 (0.0461)  triple_40: 0.0000 (0.0809)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [  90/1724]  eta: 1:46:47  lr: 0.000200  loss: 2.2204 (2.5091)  loss_n_40: 0.4651 (0.4601)  loss_n_60: 0.5343 (0.5179)  loss_n_80: 0.6038 (0.5907)  loss_n_100: 0.6693 (0.6768)  triple_100: 0.0000 (0.0910)  triple_80: 0.0000 (0.0597)  triple_60: 0.0000 (0.0410)  triple_40: 0.0000 (0.0720)  time: 3.9177  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 100/1724]  eta: 1:46:07  lr: 0.000200  loss: 1.9005 (2.4371)  loss_n_40: 0.4229 (0.4537)  loss_n_60: 0.4443 (0.5075)  loss_n_80: 0.4704 (0.5779)  loss_n_100: 0.5165 (0.6605)  triple_100: 0.0000 (0.0820)  triple_80: 0.0000 (0.0538)  triple_60: 0.0000 (0.0370)  triple_40: 0.0000 (0.0649)  time: 3.9177  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 110/1724]  eta: 1:45:27  lr: 0.000200  loss: 1.7284 (2.3749)  loss_n_40: 0.3788 (0.4486)  loss_n_60: 0.4005 (0.4993)  loss_n_80: 0.4314 (0.5662)  loss_n_100: 0.4697 (0.6446)  triple_100: 0.0000 (0.0746)  triple_80: 0.0000 (0.0489)  triple_60: 0.0000 (0.0337)  triple_40: 0.0000 (0.0590)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 120/1724]  eta: 1:44:48  lr: 0.000200  loss: 1.6603 (2.3185)  loss_n_40: 0.3765 (0.4434)  loss_n_60: 0.4005 (0.4913)  loss_n_80: 0.4314 (0.5549)  loss_n_100: 0.4596 (0.6306)  triple_100: 0.0000 (0.0684)  triple_80: 0.0000 (0.0449)  triple_60: 0.0000 (0.0309)  triple_40: 0.0000 (0.0541)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 130/1724]  eta: 1:44:09  lr: 0.000200  loss: 1.4891 (2.2497)  loss_n_40: 0.3733 (0.4367)  loss_n_60: 0.3623 (0.4798)  loss_n_80: 0.3787 (0.5399)  loss_n_100: 0.3939 (0.6101)  triple_100: 0.0000 (0.0632)  triple_80: 0.0000 (0.0414)  triple_60: 0.0000 (0.0285)  triple_40: 0.0000 (0.0500)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 140/1724]  eta: 1:43:29  lr: 0.000200  loss: 1.4561 (2.2002)  loss_n_40: 0.3350 (0.4308)  loss_n_60: 0.3543 (0.4716)  loss_n_80: 0.3675 (0.5290)  loss_n_100: 0.3893 (0.5966)  triple_100: 0.0000 (0.0587)  triple_80: 0.0000 (0.0389)  triple_60: 0.0000 (0.0265)  triple_40: 0.0000 (0.0481)  time: 3.9203  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 150/1724]  eta: 1:42:50  lr: 0.000200  loss: 1.5223 (2.1671)  loss_n_40: 0.3501 (0.4277)  loss_n_60: 0.3620 (0.4674)  loss_n_80: 0.3978 (0.5234)  loss_n_100: 0.4256 (0.5879)  triple_100: 0.0000 (0.0548)  triple_80: 0.0000 (0.0363)  triple_60: 0.0000 (0.0247)  triple_40: 0.0000 (0.0449)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 160/1724]  eta: 1:42:11  lr: 0.000200  loss: 1.6125 (2.1305)  loss_n_40: 0.3612 (0.4234)  loss_n_60: 0.3801 (0.4617)  loss_n_80: 0.4252 (0.5162)  loss_n_100: 0.4312 (0.5784)  triple_100: 0.0000 (0.0514)  triple_80: 0.0000 (0.0341)  triple_60: 0.0000 (0.0232)  triple_40: 0.0000 (0.0421)  time: 3.9195  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 170/1724]  eta: 1:41:32  lr: 0.000200  loss: 1.5219 (2.0895)  loss_n_40: 0.3336 (0.4173)  loss_n_60: 0.3647 (0.4546)  loss_n_80: 0.3901 (0.5079)  loss_n_100: 0.4147 (0.5678)  triple_100: 0.0000 (0.0484)  triple_80: 0.0000 (0.0321)  triple_60: 0.0000 (0.0218)  triple_40: 0.0000 (0.0396)  time: 3.9201  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 180/1724]  eta: 1:40:52  lr: 0.000200  loss: 1.2474 (2.0463)  loss_n_40: 0.3028 (0.4111)  loss_n_60: 0.3143 (0.4469)  loss_n_80: 0.3270 (0.4984)  loss_n_100: 0.3342 (0.5559)  triple_100: 0.0000 (0.0457)  triple_80: 0.0000 (0.0303)  triple_60: 0.0000 (0.0206)  triple_40: 0.0000 (0.0374)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 190/1724]  eta: 1:40:13  lr: 0.000200  loss: 1.3563 (2.0156)  loss_n_40: 0.3069 (0.4074)  loss_n_60: 0.3202 (0.4418)  loss_n_80: 0.3511 (0.4918)  loss_n_100: 0.3636 (0.5475)  triple_100: 0.0000 (0.0433)  triple_80: 0.0000 (0.0287)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0355)  time: 3.9222  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 200/1724]  eta: 1:39:34  lr: 0.000200  loss: 1.4508 (1.9970)  loss_n_40: 0.3091 (0.4030)  loss_n_60: 0.3388 (0.4371)  loss_n_80: 0.3700 (0.4867)  loss_n_100: 0.4104 (0.5420)  triple_100: 0.0000 (0.0412)  triple_80: 0.0000 (0.0285)  triple_60: 0.0000 (0.0228)  triple_40: 0.0000 (0.0358)  time: 3.9224  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 210/1724]  eta: 1:38:55  lr: 0.000200  loss: 1.6363 (1.9834)  loss_n_40: 0.3389 (0.4017)  loss_n_60: 0.3629 (0.4350)  loss_n_80: 0.4136 (0.4848)  loss_n_100: 0.4626 (0.5397)  triple_100: 0.0000 (0.0392)  triple_80: 0.0000 (0.0271)  triple_60: 0.0000 (0.0217)  triple_40: 0.0000 (0.0341)  time: 3.9196  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 220/1724]  eta: 1:38:16  lr: 0.000200  loss: 1.6316 (1.9659)  loss_n_40: 0.3579 (0.4006)  loss_n_60: 0.3717 (0.4321)  loss_n_80: 0.4153 (0.4812)  loss_n_100: 0.4648 (0.5354)  triple_100: 0.0000 (0.0375)  triple_80: 0.0000 (0.0259)  triple_60: 0.0000 (0.0208)  triple_40: 0.0000 (0.0325)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 230/1724]  eta: 1:37:36  lr: 0.000200  loss: 1.5900 (1.9497)  loss_n_40: 0.3712 (0.3992)  loss_n_60: 0.3662 (0.4293)  loss_n_80: 0.4146 (0.4780)  loss_n_100: 0.4526 (0.5317)  triple_100: 0.0000 (0.0358)  triple_80: 0.0000 (0.0248)  triple_60: 0.0000 (0.0199)  triple_40: 0.0000 (0.0311)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 240/1724]  eta: 1:36:57  lr: 0.000200  loss: 1.3808 (1.9266)  loss_n_40: 0.3396 (0.3965)  loss_n_60: 0.3254 (0.4253)  loss_n_80: 0.3480 (0.4727)  loss_n_100: 0.3749 (0.5251)  triple_100: 0.0000 (0.0343)  triple_80: 0.0000 (0.0237)  triple_60: 0.0000 (0.0190)  triple_40: 0.0000 (0.0298)  time: 3.9192  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 250/1724]  eta: 1:36:18  lr: 0.000200  loss: 1.3436 (1.9135)  loss_n_40: 0.3159 (0.3956)  loss_n_60: 0.3196 (0.4235)  loss_n_80: 0.3454 (0.4694)  loss_n_100: 0.3670 (0.5205)  triple_100: 0.0000 (0.0330)  triple_80: 0.0000 (0.0228)  triple_60: 0.0000 (0.0200)  triple_40: 0.0000 (0.0287)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 260/1724]  eta: 1:35:39  lr: 0.000200  loss: 1.4188 (1.8972)  loss_n_40: 0.3434 (0.3942)  loss_n_60: 0.3440 (0.4210)  loss_n_80: 0.3565 (0.4659)  loss_n_100: 0.3882 (0.5157)  triple_100: 0.0000 (0.0317)  triple_80: 0.0000 (0.0219)  triple_60: 0.0000 (0.0193)  triple_40: 0.0000 (0.0276)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 270/1724]  eta: 1:34:59  lr: 0.000200  loss: 1.4568 (1.8808)  loss_n_40: 0.3374 (0.3921)  loss_n_60: 0.3440 (0.4183)  loss_n_80: 0.3728 (0.4625)  loss_n_100: 0.3882 (0.5112)  triple_100: 0.0000 (0.0305)  triple_80: 0.0000 (0.0211)  triple_60: 0.0000 (0.0186)  triple_40: 0.0000 (0.0265)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 280/1724]  eta: 1:34:20  lr: 0.000200  loss: 1.3823 (1.8609)  loss_n_40: 0.3311 (0.3895)  loss_n_60: 0.3331 (0.4148)  loss_n_80: 0.3441 (0.4579)  loss_n_100: 0.3664 (0.5055)  triple_100: 0.0000 (0.0295)  triple_80: 0.0000 (0.0204)  triple_60: 0.0000 (0.0179)  triple_40: 0.0000 (0.0256)  time: 3.9181  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [ 290/1724]  eta: 1:33:41  lr: 0.000200  loss: 1.3893 (1.8499)  loss_n_40: 0.3311 (0.3895)  loss_n_60: 0.3398 (0.4133)  loss_n_80: 0.3380 (0.4553)  loss_n_100: 0.3723 (0.5017)  triple_100: 0.0000 (0.0284)  triple_80: 0.0000 (0.0197)  triple_60: 0.0000 (0.0173)  triple_40: 0.0000 (0.0247)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 300/1724]  eta: 1:33:01  lr: 0.000200  loss: 1.3055 (1.8297)  loss_n_40: 0.3065 (0.3861)  loss_n_60: 0.3130 (0.4095)  loss_n_80: 0.3371 (0.4508)  loss_n_100: 0.3503 (0.4961)  triple_100: 0.0000 (0.0275)  triple_80: 0.0000 (0.0190)  triple_60: 0.0000 (0.0167)  triple_40: 0.0000 (0.0239)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 310/1724]  eta: 1:32:22  lr: 0.000200  loss: 1.2056 (1.8096)  loss_n_40: 0.2833 (0.3831)  loss_n_60: 0.2799 (0.4056)  loss_n_80: 0.3017 (0.4462)  loss_n_100: 0.3128 (0.4904)  triple_100: 0.0000 (0.0266)  triple_80: 0.0000 (0.0184)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0231)  time: 3.9177  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 320/1724]  eta: 1:31:43  lr: 0.000200  loss: 1.0875 (1.7866)  loss_n_40: 0.2601 (0.3790)  loss_n_60: 0.2692 (0.4011)  loss_n_80: 0.2858 (0.4409)  loss_n_100: 0.2897 (0.4839)  triple_100: 0.0000 (0.0258)  triple_80: 0.0000 (0.0178)  triple_60: 0.0000 (0.0157)  triple_40: 0.0000 (0.0224)  time: 3.9179  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 330/1724]  eta: 1:31:03  lr: 0.000200  loss: 1.1030 (1.7695)  loss_n_40: 0.2578 (0.3765)  loss_n_60: 0.2687 (0.3977)  loss_n_80: 0.2823 (0.4369)  loss_n_100: 0.2813 (0.4792)  triple_100: 0.0000 (0.0250)  triple_80: 0.0000 (0.0173)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0217)  time: 3.9176  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 340/1724]  eta: 1:30:24  lr: 0.000200  loss: 1.1030 (1.7487)  loss_n_40: 0.2547 (0.3728)  loss_n_60: 0.2616 (0.3935)  loss_n_80: 0.2823 (0.4320)  loss_n_100: 0.3022 (0.4734)  triple_100: 0.0000 (0.0243)  triple_80: 0.0000 (0.0168)  triple_60: 0.0000 (0.0147)  triple_40: 0.0000 (0.0211)  time: 3.9170  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 350/1724]  eta: 1:29:45  lr: 0.000200  loss: 1.1534 (1.7680)  loss_n_40: 0.2624 (0.3713)  loss_n_60: 0.2691 (0.3923)  loss_n_80: 0.3027 (0.4310)  loss_n_100: 0.3199 (0.4723)  triple_100: 0.0000 (0.0327)  triple_80: 0.0000 (0.0254)  triple_60: 0.0000 (0.0212)  triple_40: 0.0000 (0.0217)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 360/1724]  eta: 1:29:06  lr: 0.000200  loss: 1.7693 (1.7730)  loss_n_40: 0.3385 (0.3712)  loss_n_60: 0.4062 (0.3938)  loss_n_80: 0.4818 (0.4337)  loss_n_100: 0.5368 (0.4758)  triple_100: 0.0000 (0.0318)  triple_80: 0.0000 (0.0250)  triple_60: 0.0000 (0.0207)  triple_40: 0.0000 (0.0211)  time: 3.9173  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 370/1724]  eta: 1:28:26  lr: 0.000200  loss: 1.7329 (1.7702)  loss_n_40: 0.3624 (0.3707)  loss_n_60: 0.3977 (0.3938)  loss_n_80: 0.4818 (0.4337)  loss_n_100: 0.5368 (0.4760)  triple_100: 0.0000 (0.0309)  triple_80: 0.0000 (0.0244)  triple_60: 0.0000 (0.0201)  triple_40: 0.0000 (0.0206)  time: 3.9163  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 380/1724]  eta: 1:27:47  lr: 0.000200  loss: 1.5174 (1.7648)  loss_n_40: 0.3456 (0.3705)  loss_n_60: 0.3705 (0.3934)  loss_n_80: 0.4008 (0.4328)  loss_n_100: 0.4392 (0.4748)  triple_100: 0.0000 (0.0301)  triple_80: 0.0000 (0.0237)  triple_60: 0.0000 (0.0196)  triple_40: 0.0000 (0.0200)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 390/1724]  eta: 1:27:08  lr: 0.000200  loss: 1.4404 (1.7546)  loss_n_40: 0.3414 (0.3693)  loss_n_60: 0.3471 (0.3918)  loss_n_80: 0.3662 (0.4305)  loss_n_100: 0.3962 (0.4720)  triple_100: 0.0000 (0.0293)  triple_80: 0.0000 (0.0231)  triple_60: 0.0000 (0.0191)  triple_40: 0.0000 (0.0195)  time: 3.9173  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 400/1724]  eta: 1:26:29  lr: 0.000200  loss: 1.3864 (1.7468)  loss_n_40: 0.3284 (0.3690)  loss_n_60: 0.3244 (0.3906)  loss_n_80: 0.3479 (0.4287)  loss_n_100: 0.3739 (0.4697)  triple_100: 0.0000 (0.0286)  triple_80: 0.0000 (0.0225)  triple_60: 0.0000 (0.0186)  triple_40: 0.0000 (0.0190)  time: 3.9180  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 410/1724]  eta: 1:25:49  lr: 0.000200  loss: 1.3522 (1.7381)  loss_n_40: 0.3284 (0.3685)  loss_n_60: 0.3246 (0.3893)  loss_n_80: 0.3372 (0.4266)  loss_n_100: 0.3507 (0.4671)  triple_100: 0.0000 (0.0279)  triple_80: 0.0000 (0.0220)  triple_60: 0.0000 (0.0181)  triple_40: 0.0000 (0.0186)  time: 3.9178  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 420/1724]  eta: 1:25:10  lr: 0.000200  loss: 1.2769 (1.7258)  loss_n_40: 0.3043 (0.3667)  loss_n_60: 0.3076 (0.3871)  loss_n_80: 0.3234 (0.4238)  loss_n_100: 0.3313 (0.4637)  triple_100: 0.0000 (0.0272)  triple_80: 0.0000 (0.0215)  triple_60: 0.0000 (0.0177)  triple_40: 0.0000 (0.0181)  time: 3.9185  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 430/1724]  eta: 1:24:31  lr: 0.000200  loss: 1.2442 (1.7154)  loss_n_40: 0.3027 (0.3655)  loss_n_60: 0.3026 (0.3853)  loss_n_80: 0.3114 (0.4214)  loss_n_100: 0.3231 (0.4607)  triple_100: 0.0000 (0.0266)  triple_80: 0.0000 (0.0210)  triple_60: 0.0000 (0.0173)  triple_40: 0.0000 (0.0177)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 440/1724]  eta: 1:23:52  lr: 0.000200  loss: 1.1913 (1.7024)  loss_n_40: 0.3027 (0.3635)  loss_n_60: 0.2824 (0.3828)  loss_n_80: 0.2934 (0.4184)  loss_n_100: 0.3112 (0.4570)  triple_100: 0.0000 (0.0260)  triple_80: 0.0000 (0.0205)  triple_60: 0.0000 (0.0169)  triple_40: 0.0000 (0.0173)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 450/1724]  eta: 1:23:12  lr: 0.000200  loss: 1.1874 (1.6914)  loss_n_40: 0.2840 (0.3620)  loss_n_60: 0.2794 (0.3809)  loss_n_80: 0.2903 (0.4158)  loss_n_100: 0.3071 (0.4538)  triple_100: 0.0000 (0.0254)  triple_80: 0.0000 (0.0200)  triple_60: 0.0000 (0.0165)  triple_40: 0.0000 (0.0169)  time: 3.9171  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 460/1724]  eta: 1:22:33  lr: 0.000200  loss: 1.2917 (1.6836)  loss_n_40: 0.3333 (0.3617)  loss_n_60: 0.3072 (0.3794)  loss_n_80: 0.3170 (0.4139)  loss_n_100: 0.3363 (0.4514)  triple_100: 0.0000 (0.0249)  triple_80: 0.0000 (0.0196)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0165)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 470/1724]  eta: 1:21:54  lr: 0.000200  loss: 1.3106 (1.6753)  loss_n_40: 0.3333 (0.3606)  loss_n_60: 0.3061 (0.3778)  loss_n_80: 0.3286 (0.4119)  loss_n_100: 0.3395 (0.4490)  triple_100: 0.0000 (0.0243)  triple_80: 0.0000 (0.0192)  triple_60: 0.0000 (0.0162)  triple_40: 0.0000 (0.0163)  time: 3.9175  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 480/1724]  eta: 1:21:15  lr: 0.000200  loss: 1.1875 (1.6644)  loss_n_40: 0.2861 (0.3590)  loss_n_60: 0.2823 (0.3756)  loss_n_80: 0.3035 (0.4094)  loss_n_100: 0.3138 (0.4460)  triple_100: 0.0000 (0.0238)  triple_80: 0.0000 (0.0188)  triple_60: 0.0000 (0.0158)  triple_40: 0.0000 (0.0160)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 490/1724]  eta: 1:20:35  lr: 0.000200  loss: 1.1053 (1.6527)  loss_n_40: 0.2625 (0.3572)  loss_n_60: 0.2562 (0.3732)  loss_n_80: 0.2695 (0.4066)  loss_n_100: 0.2884 (0.4427)  triple_100: 0.0000 (0.0234)  triple_80: 0.0000 (0.0184)  triple_60: 0.0000 (0.0155)  triple_40: 0.0000 (0.0156)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 500/1724]  eta: 1:19:56  lr: 0.000200  loss: 1.0231 (1.6408)  loss_n_40: 0.2499 (0.3552)  loss_n_60: 0.2487 (0.3709)  loss_n_80: 0.2571 (0.4038)  loss_n_100: 0.2650 (0.4394)  triple_100: 0.0000 (0.0229)  triple_80: 0.0000 (0.0180)  triple_60: 0.0000 (0.0152)  triple_40: 0.0000 (0.0153)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 510/1724]  eta: 1:19:17  lr: 0.000200  loss: 1.1034 (1.6305)  loss_n_40: 0.2718 (0.3538)  loss_n_60: 0.2635 (0.3689)  loss_n_80: 0.2679 (0.4014)  loss_n_100: 0.2779 (0.4364)  triple_100: 0.0000 (0.0224)  triple_80: 0.0000 (0.0177)  triple_60: 0.0000 (0.0149)  triple_40: 0.0000 (0.0150)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 520/1724]  eta: 1:18:38  lr: 0.000200  loss: 1.0514 (1.6195)  loss_n_40: 0.2590 (0.3519)  loss_n_60: 0.2572 (0.3667)  loss_n_80: 0.2675 (0.3988)  loss_n_100: 0.2704 (0.4333)  triple_100: 0.0000 (0.0220)  triple_80: 0.0000 (0.0174)  triple_60: 0.0000 (0.0146)  triple_40: 0.0000 (0.0147)  time: 3.9204  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [ 530/1724]  eta: 1:17:59  lr: 0.000200  loss: 1.0514 (1.6096)  loss_n_40: 0.2586 (0.3504)  loss_n_60: 0.2568 (0.3648)  loss_n_80: 0.2633 (0.3965)  loss_n_100: 0.2684 (0.4305)  triple_100: 0.0000 (0.0216)  triple_80: 0.0000 (0.0170)  triple_60: 0.0000 (0.0143)  triple_40: 0.0000 (0.0145)  time: 3.9202  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 540/1724]  eta: 1:17:20  lr: 0.000200  loss: 1.0592 (1.5994)  loss_n_40: 0.2626 (0.3487)  loss_n_60: 0.2597 (0.3628)  loss_n_80: 0.2674 (0.3941)  loss_n_100: 0.2723 (0.4276)  triple_100: 0.0000 (0.0212)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0141)  triple_40: 0.0000 (0.0142)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 550/1724]  eta: 1:16:40  lr: 0.000200  loss: 0.9885 (1.5885)  loss_n_40: 0.2413 (0.3469)  loss_n_60: 0.2433 (0.3606)  loss_n_80: 0.2475 (0.3915)  loss_n_100: 0.2550 (0.4245)  triple_100: 0.0000 (0.0208)  triple_80: 0.0000 (0.0164)  triple_60: 0.0000 (0.0138)  triple_40: 0.0000 (0.0139)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 560/1724]  eta: 1:16:01  lr: 0.000200  loss: 0.9841 (1.5789)  loss_n_40: 0.2450 (0.3456)  loss_n_60: 0.2374 (0.3588)  loss_n_80: 0.2469 (0.3892)  loss_n_100: 0.2380 (0.4216)  triple_100: 0.0000 (0.0204)  triple_80: 0.0000 (0.0161)  triple_60: 0.0000 (0.0136)  triple_40: 0.0000 (0.0137)  time: 3.9191  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 570/1724]  eta: 1:15:22  lr: 0.000200  loss: 1.1550 (1.5727)  loss_n_40: 0.2941 (0.3446)  loss_n_60: 0.2878 (0.3574)  loss_n_80: 0.2731 (0.3874)  loss_n_100: 0.2855 (0.4195)  triple_100: 0.0000 (0.0206)  triple_80: 0.0000 (0.0162)  triple_60: 0.0000 (0.0134)  triple_40: 0.0000 (0.0135)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 580/1724]  eta: 1:14:43  lr: 0.000200  loss: 1.2177 (1.5669)  loss_n_40: 0.2791 (0.3434)  loss_n_60: 0.2877 (0.3562)  loss_n_80: 0.3092 (0.3863)  loss_n_100: 0.3314 (0.4184)  triple_100: 0.0000 (0.0202)  triple_80: 0.0000 (0.0160)  triple_60: 0.0000 (0.0132)  triple_40: 0.0000 (0.0132)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 590/1724]  eta: 1:14:04  lr: 0.000200  loss: 1.2403 (1.5630)  loss_n_40: 0.2682 (0.3424)  loss_n_60: 0.2877 (0.3554)  loss_n_80: 0.3373 (0.3856)  loss_n_100: 0.3580 (0.4176)  triple_100: 0.0000 (0.0200)  triple_80: 0.0000 (0.0159)  triple_60: 0.0000 (0.0130)  triple_40: 0.0000 (0.0130)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 600/1724]  eta: 1:13:24  lr: 0.000200  loss: 1.4687 (1.5700)  loss_n_40: 0.3137 (0.3430)  loss_n_60: 0.3240 (0.3564)  loss_n_80: 0.3660 (0.3871)  loss_n_100: 0.4025 (0.4194)  triple_100: 0.0000 (0.0207)  triple_80: 0.0000 (0.0178)  triple_60: 0.0000 (0.0128)  triple_40: 0.0000 (0.0128)  time: 3.9179  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 610/1724]  eta: 1:12:45  lr: 0.000200  loss: 1.8736 (1.5752)  loss_n_40: 0.3622 (0.3433)  loss_n_60: 0.4227 (0.3576)  loss_n_80: 0.5121 (0.3891)  loss_n_100: 0.6073 (0.4221)  triple_100: 0.0000 (0.0203)  triple_80: 0.0000 (0.0175)  triple_60: 0.0000 (0.0126)  triple_40: 0.0000 (0.0126)  time: 3.9175  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 620/1724]  eta: 1:12:06  lr: 0.000200  loss: 1.8292 (1.5769)  loss_n_40: 0.3622 (0.3438)  loss_n_60: 0.4137 (0.3583)  loss_n_80: 0.4868 (0.3900)  loss_n_100: 0.5146 (0.4228)  triple_100: 0.0000 (0.0200)  triple_80: 0.0000 (0.0173)  triple_60: 0.0000 (0.0124)  triple_40: 0.0000 (0.0124)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 630/1724]  eta: 1:11:27  lr: 0.000200  loss: 1.5648 (1.5744)  loss_n_40: 0.3477 (0.3436)  loss_n_60: 0.3687 (0.3581)  loss_n_80: 0.3906 (0.3896)  loss_n_100: 0.3934 (0.4220)  triple_100: 0.0000 (0.0197)  triple_80: 0.0000 (0.0170)  triple_60: 0.0000 (0.0122)  triple_40: 0.0000 (0.0122)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 640/1724]  eta: 1:10:48  lr: 0.000200  loss: 1.3476 (1.5716)  loss_n_40: 0.3085 (0.3434)  loss_n_60: 0.3195 (0.3579)  loss_n_80: 0.3416 (0.3890)  loss_n_100: 0.3499 (0.4212)  triple_100: 0.0000 (0.0194)  triple_80: 0.0000 (0.0167)  triple_60: 0.0000 (0.0120)  triple_40: 0.0000 (0.0120)  time: 3.9177  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 650/1724]  eta: 1:10:08  lr: 0.000200  loss: 1.1975 (1.5647)  loss_n_40: 0.2762 (0.3422)  loss_n_60: 0.2936 (0.3566)  loss_n_80: 0.3049 (0.3874)  loss_n_100: 0.3169 (0.4192)  triple_100: 0.0000 (0.0191)  triple_80: 0.0000 (0.0165)  triple_60: 0.0000 (0.0118)  triple_40: 0.0000 (0.0118)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 660/1724]  eta: 1:09:29  lr: 0.000200  loss: 1.1306 (1.5601)  loss_n_40: 0.2684 (0.3416)  loss_n_60: 0.2776 (0.3559)  loss_n_80: 0.2917 (0.3863)  loss_n_100: 0.3035 (0.4180)  triple_100: 0.0000 (0.0188)  triple_80: 0.0000 (0.0162)  triple_60: 0.0000 (0.0116)  triple_40: 0.0000 (0.0116)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 670/1724]  eta: 1:08:50  lr: 0.000200  loss: 1.1222 (1.5543)  loss_n_40: 0.2691 (0.3407)  loss_n_60: 0.2775 (0.3549)  loss_n_80: 0.2832 (0.3850)  loss_n_100: 0.2864 (0.4162)  triple_100: 0.0000 (0.0185)  triple_80: 0.0000 (0.0160)  triple_60: 0.0000 (0.0115)  triple_40: 0.0000 (0.0115)  time: 3.9190  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 680/1724]  eta: 1:08:11  lr: 0.000200  loss: 1.1016 (1.5487)  loss_n_40: 0.2753 (0.3401)  loss_n_60: 0.2775 (0.3540)  loss_n_80: 0.2777 (0.3835)  loss_n_100: 0.2864 (0.4145)  triple_100: 0.0000 (0.0182)  triple_80: 0.0000 (0.0157)  triple_60: 0.0000 (0.0113)  triple_40: 0.0000 (0.0113)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 690/1724]  eta: 1:07:32  lr: 0.000200  loss: 1.1847 (1.5433)  loss_n_40: 0.2771 (0.3393)  loss_n_60: 0.2936 (0.3530)  loss_n_80: 0.2888 (0.3822)  loss_n_100: 0.3094 (0.4130)  triple_100: 0.0000 (0.0180)  triple_80: 0.0000 (0.0155)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0111)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 700/1724]  eta: 1:06:52  lr: 0.000200  loss: 1.1595 (1.5376)  loss_n_40: 0.2705 (0.3384)  loss_n_60: 0.2786 (0.3519)  loss_n_80: 0.2898 (0.3808)  loss_n_100: 0.3069 (0.4113)  triple_100: 0.0000 (0.0177)  triple_80: 0.0000 (0.0153)  triple_60: 0.0000 (0.0111)  triple_40: 0.0000 (0.0110)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 710/1724]  eta: 1:06:13  lr: 0.000200  loss: 1.0622 (1.5314)  loss_n_40: 0.2705 (0.3374)  loss_n_60: 0.2561 (0.3506)  loss_n_80: 0.2746 (0.3794)  loss_n_100: 0.2835 (0.4096)  triple_100: 0.0000 (0.0175)  triple_80: 0.0000 (0.0151)  triple_60: 0.0000 (0.0109)  triple_40: 0.0000 (0.0109)  time: 3.9183  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 720/1724]  eta: 1:05:34  lr: 0.000200  loss: 1.0666 (1.5266)  loss_n_40: 0.2630 (0.3369)  loss_n_60: 0.2550 (0.3497)  loss_n_80: 0.2725 (0.3782)  loss_n_100: 0.2879 (0.4082)  triple_100: 0.0000 (0.0172)  triple_80: 0.0000 (0.0149)  triple_60: 0.0000 (0.0108)  triple_40: 0.0000 (0.0107)  time: 3.9190  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 730/1724]  eta: 1:04:55  lr: 0.000200  loss: 1.0860 (1.5210)  loss_n_40: 0.2630 (0.3362)  loss_n_60: 0.2665 (0.3486)  loss_n_80: 0.2780 (0.3767)  loss_n_100: 0.2926 (0.4066)  triple_100: 0.0000 (0.0170)  triple_80: 0.0000 (0.0147)  triple_60: 0.0000 (0.0106)  triple_40: 0.0000 (0.0106)  time: 3.9196  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 740/1724]  eta: 1:04:16  lr: 0.000200  loss: 1.0860 (1.5150)  loss_n_40: 0.2654 (0.3353)  loss_n_60: 0.2665 (0.3474)  loss_n_80: 0.2780 (0.3753)  loss_n_100: 0.2807 (0.4048)  triple_100: 0.0000 (0.0168)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0105)  triple_40: 0.0000 (0.0104)  time: 3.9194  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 750/1724]  eta: 1:03:37  lr: 0.000200  loss: 1.1057 (1.5096)  loss_n_40: 0.2695 (0.3345)  loss_n_60: 0.2673 (0.3464)  loss_n_80: 0.2733 (0.3740)  loss_n_100: 0.2775 (0.4032)  triple_100: 0.0000 (0.0165)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0103)  triple_40: 0.0000 (0.0103)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 760/1724]  eta: 1:02:57  lr: 0.000200  loss: 1.1057 (1.5057)  loss_n_40: 0.2767 (0.3341)  loss_n_60: 0.2705 (0.3457)  loss_n_80: 0.2733 (0.3730)  loss_n_100: 0.2846 (0.4021)  triple_100: 0.0000 (0.0163)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0102)  time: 3.9185  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [ 770/1724]  eta: 1:02:18  lr: 0.000200  loss: 1.0043 (1.4985)  loss_n_40: 0.2400 (0.3328)  loss_n_60: 0.2454 (0.3442)  loss_n_80: 0.2544 (0.3712)  loss_n_100: 0.2646 (0.4001)  triple_100: 0.0000 (0.0161)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0100)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 780/1724]  eta: 1:01:39  lr: 0.000200  loss: 1.1581 (1.5014)  loss_n_40: 0.3085 (0.3329)  loss_n_60: 0.2663 (0.3444)  loss_n_80: 0.2722 (0.3716)  loss_n_100: 0.3082 (0.4005)  triple_100: 0.0000 (0.0163)  triple_80: 0.0000 (0.0144)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0109)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 790/1724]  eta: 1:01:00  lr: 0.000200  loss: 1.6208 (1.5038)  loss_n_40: 0.3305 (0.3332)  loss_n_60: 0.3517 (0.3449)  loss_n_80: 0.3882 (0.3722)  loss_n_100: 0.4433 (0.4016)  triple_100: 0.0000 (0.0161)  triple_80: 0.0000 (0.0145)  triple_60: 0.0000 (0.0105)  triple_40: 0.0000 (0.0108)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 800/1724]  eta: 1:00:21  lr: 0.000200  loss: 1.3883 (1.5014)  loss_n_40: 0.2884 (0.3327)  loss_n_60: 0.3281 (0.3445)  loss_n_80: 0.3621 (0.3718)  loss_n_100: 0.3957 (0.4011)  triple_100: 0.0000 (0.0159)  triple_80: 0.0000 (0.0143)  triple_60: 0.0000 (0.0104)  triple_40: 0.0000 (0.0107)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 810/1724]  eta: 0:59:41  lr: 0.000200  loss: 1.2520 (1.4983)  loss_n_40: 0.2824 (0.3323)  loss_n_60: 0.2939 (0.3439)  loss_n_80: 0.3238 (0.3712)  loss_n_100: 0.3385 (0.4003)  triple_100: 0.0000 (0.0157)  triple_80: 0.0000 (0.0141)  triple_60: 0.0000 (0.0102)  triple_40: 0.0000 (0.0105)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 820/1724]  eta: 0:59:02  lr: 0.000200  loss: 1.1578 (1.4942)  loss_n_40: 0.2732 (0.3316)  loss_n_60: 0.2790 (0.3432)  loss_n_80: 0.2972 (0.3703)  loss_n_100: 0.3138 (0.3992)  triple_100: 0.0000 (0.0155)  triple_80: 0.0000 (0.0139)  triple_60: 0.0000 (0.0101)  triple_40: 0.0000 (0.0104)  time: 3.9188  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 830/1724]  eta: 0:58:23  lr: 0.000200  loss: 1.1299 (1.4906)  loss_n_40: 0.2634 (0.3311)  loss_n_60: 0.2718 (0.3425)  loss_n_80: 0.2856 (0.3695)  loss_n_100: 0.2968 (0.3981)  triple_100: 0.0000 (0.0154)  triple_80: 0.0000 (0.0138)  triple_60: 0.0000 (0.0100)  triple_40: 0.0000 (0.0103)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 840/1724]  eta: 0:57:44  lr: 0.000200  loss: 1.1299 (1.4871)  loss_n_40: 0.2811 (0.3308)  loss_n_60: 0.2787 (0.3420)  loss_n_80: 0.2767 (0.3686)  loss_n_100: 0.2869 (0.3970)  triple_100: 0.0000 (0.0152)  triple_80: 0.0000 (0.0136)  triple_60: 0.0000 (0.0099)  triple_40: 0.0000 (0.0101)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 850/1724]  eta: 0:57:05  lr: 0.000200  loss: 1.1088 (1.4829)  loss_n_40: 0.2812 (0.3303)  loss_n_60: 0.2716 (0.3412)  loss_n_80: 0.2741 (0.3675)  loss_n_100: 0.2785 (0.3957)  triple_100: 0.0000 (0.0150)  triple_80: 0.0000 (0.0134)  triple_60: 0.0000 (0.0097)  triple_40: 0.0000 (0.0100)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 860/1724]  eta: 0:56:25  lr: 0.000200  loss: 1.1088 (1.4805)  loss_n_40: 0.2812 (0.3301)  loss_n_60: 0.2687 (0.3409)  loss_n_80: 0.2741 (0.3669)  loss_n_100: 0.2857 (0.3949)  triple_100: 0.0000 (0.0148)  triple_80: 0.0000 (0.0133)  triple_60: 0.0000 (0.0096)  triple_40: 0.0000 (0.0099)  time: 3.9183  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 870/1724]  eta: 0:55:46  lr: 0.000200  loss: 1.0985 (1.4765)  loss_n_40: 0.2848 (0.3295)  loss_n_60: 0.2654 (0.3401)  loss_n_80: 0.2722 (0.3660)  loss_n_100: 0.2777 (0.3937)  triple_100: 0.0000 (0.0146)  triple_80: 0.0000 (0.0131)  triple_60: 0.0000 (0.0095)  triple_40: 0.0000 (0.0098)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 880/1724]  eta: 0:55:07  lr: 0.000200  loss: 1.0652 (1.4720)  loss_n_40: 0.2582 (0.3288)  loss_n_60: 0.2535 (0.3392)  loss_n_80: 0.2704 (0.3649)  loss_n_100: 0.2775 (0.3925)  triple_100: 0.0000 (0.0145)  triple_80: 0.0000 (0.0130)  triple_60: 0.0000 (0.0094)  triple_40: 0.0000 (0.0097)  time: 3.9222  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 890/1724]  eta: 0:54:28  lr: 0.000200  loss: 1.0402 (1.4672)  loss_n_40: 0.2589 (0.3282)  loss_n_60: 0.2534 (0.3382)  loss_n_80: 0.2593 (0.3637)  loss_n_100: 0.2728 (0.3911)  triple_100: 0.0000 (0.0143)  triple_80: 0.0000 (0.0128)  triple_60: 0.0000 (0.0093)  triple_40: 0.0000 (0.0096)  time: 3.9223  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 900/1724]  eta: 0:53:49  lr: 0.000200  loss: 0.9323 (1.4619)  loss_n_40: 0.2286 (0.3273)  loss_n_60: 0.2245 (0.3371)  loss_n_80: 0.2390 (0.3624)  loss_n_100: 0.2508 (0.3896)  triple_100: 0.0000 (0.0142)  triple_80: 0.0000 (0.0127)  triple_60: 0.0000 (0.0092)  triple_40: 0.0000 (0.0095)  time: 3.9227  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 910/1724]  eta: 0:53:10  lr: 0.000200  loss: 1.1050 (1.4580)  loss_n_40: 0.2580 (0.3268)  loss_n_60: 0.2638 (0.3363)  loss_n_80: 0.2545 (0.3614)  loss_n_100: 0.2814 (0.3885)  triple_100: 0.0000 (0.0140)  triple_80: 0.0000 (0.0125)  triple_60: 0.0000 (0.0091)  triple_40: 0.0000 (0.0094)  time: 3.9215  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 920/1724]  eta: 0:52:30  lr: 0.000200  loss: 1.0135 (1.4525)  loss_n_40: 0.2507 (0.3259)  loss_n_60: 0.2448 (0.3352)  loss_n_80: 0.2511 (0.3601)  loss_n_100: 0.2625 (0.3869)  triple_100: 0.0000 (0.0139)  triple_80: 0.0000 (0.0124)  triple_60: 0.0000 (0.0090)  triple_40: 0.0000 (0.0093)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 930/1724]  eta: 0:51:51  lr: 0.000200  loss: 0.9027 (1.4470)  loss_n_40: 0.2364 (0.3249)  loss_n_60: 0.2206 (0.3340)  loss_n_80: 0.2233 (0.3587)  loss_n_100: 0.2368 (0.3853)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0123)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0092)  time: 3.9183  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 940/1724]  eta: 0:51:12  lr: 0.000200  loss: 0.9091 (1.4420)  loss_n_40: 0.2306 (0.3241)  loss_n_60: 0.2223 (0.3330)  loss_n_80: 0.2261 (0.3574)  loss_n_100: 0.2384 (0.3839)  triple_100: 0.0000 (0.0136)  triple_80: 0.0000 (0.0122)  triple_60: 0.0000 (0.0089)  triple_40: 0.0000 (0.0091)  time: 3.9182  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 950/1724]  eta: 0:50:33  lr: 0.000200  loss: 1.0483 (1.4383)  loss_n_40: 0.2475 (0.3235)  loss_n_60: 0.2516 (0.3323)  loss_n_80: 0.2645 (0.3566)  loss_n_100: 0.2780 (0.3829)  triple_100: 0.0000 (0.0134)  triple_80: 0.0000 (0.0120)  triple_60: 0.0000 (0.0088)  triple_40: 0.0000 (0.0090)  time: 3.9194  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 960/1724]  eta: 0:49:54  lr: 0.000200  loss: 1.0759 (1.4341)  loss_n_40: 0.2475 (0.3226)  loss_n_60: 0.2555 (0.3314)  loss_n_80: 0.2658 (0.3556)  loss_n_100: 0.2830 (0.3818)  triple_100: 0.0000 (0.0133)  triple_80: 0.0000 (0.0119)  triple_60: 0.0000 (0.0087)  triple_40: 0.0000 (0.0089)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 970/1724]  eta: 0:49:14  lr: 0.000200  loss: 0.9951 (1.4299)  loss_n_40: 0.2379 (0.3218)  loss_n_60: 0.2366 (0.3305)  loss_n_80: 0.2507 (0.3546)  loss_n_100: 0.2668 (0.3807)  triple_100: 0.0000 (0.0131)  triple_80: 0.0000 (0.0118)  triple_60: 0.0000 (0.0086)  triple_40: 0.0000 (0.0088)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [ 980/1724]  eta: 0:48:35  lr: 0.000200  loss: 1.0073 (1.4264)  loss_n_40: 0.2607 (0.3213)  loss_n_60: 0.2449 (0.3299)  loss_n_80: 0.2530 (0.3537)  loss_n_100: 0.2549 (0.3796)  triple_100: 0.0000 (0.0130)  triple_80: 0.0000 (0.0117)  triple_60: 0.0000 (0.0085)  triple_40: 0.0000 (0.0087)  time: 3.9207  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [ 990/1724]  eta: 0:47:56  lr: 0.000200  loss: 1.0506 (1.4231)  loss_n_40: 0.2809 (0.3209)  loss_n_60: 0.2520 (0.3292)  loss_n_80: 0.2604 (0.3529)  loss_n_100: 0.2827 (0.3786)  triple_100: 0.0000 (0.0129)  triple_80: 0.0000 (0.0116)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0087)  time: 3.9199  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1000/1724]  eta: 0:47:17  lr: 0.000200  loss: 0.9948 (1.4197)  loss_n_40: 0.2426 (0.3204)  loss_n_60: 0.2367 (0.3284)  loss_n_80: 0.2542 (0.3521)  loss_n_100: 0.2633 (0.3777)  triple_100: 0.0000 (0.0127)  triple_80: 0.0000 (0.0115)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0086)  time: 3.9198  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [1010/1724]  eta: 0:46:38  lr: 0.000200  loss: 1.0617 (1.4169)  loss_n_40: 0.2737 (0.3201)  loss_n_60: 0.2559 (0.3279)  loss_n_80: 0.2662 (0.3514)  loss_n_100: 0.2783 (0.3769)  triple_100: 0.0000 (0.0126)  triple_80: 0.0000 (0.0114)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0085)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1020/1724]  eta: 0:45:59  lr: 0.000200  loss: 1.1003 (1.4141)  loss_n_40: 0.2737 (0.3196)  loss_n_60: 0.2601 (0.3273)  loss_n_80: 0.2675 (0.3507)  loss_n_100: 0.2888 (0.3762)  triple_100: 0.0000 (0.0125)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0084)  time: 3.9189  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1030/1724]  eta: 0:45:19  lr: 0.000200  loss: 1.1003 (1.4114)  loss_n_40: 0.2555 (0.3192)  loss_n_60: 0.2601 (0.3268)  loss_n_80: 0.2675 (0.3501)  loss_n_100: 0.2888 (0.3754)  triple_100: 0.0000 (0.0124)  triple_80: 0.0000 (0.0111)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0083)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1040/1724]  eta: 0:44:40  lr: 0.000200  loss: 1.0274 (1.4082)  loss_n_40: 0.2446 (0.3186)  loss_n_60: 0.2516 (0.3260)  loss_n_80: 0.2526 (0.3492)  loss_n_100: 0.2683 (0.3745)  triple_100: 0.0000 (0.0123)  triple_80: 0.0000 (0.0110)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0084)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1050/1724]  eta: 0:44:01  lr: 0.000200  loss: 1.0274 (1.4051)  loss_n_40: 0.2446 (0.3180)  loss_n_60: 0.2493 (0.3254)  loss_n_80: 0.2553 (0.3485)  loss_n_100: 0.2741 (0.3737)  triple_100: 0.0000 (0.0121)  triple_80: 0.0000 (0.0109)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0083)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1060/1724]  eta: 0:43:22  lr: 0.000200  loss: 1.1510 (1.4036)  loss_n_40: 0.2727 (0.3179)  loss_n_60: 0.2668 (0.3251)  loss_n_80: 0.2925 (0.3482)  loss_n_100: 0.3112 (0.3733)  triple_100: 0.0000 (0.0120)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0082)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1070/1724]  eta: 0:42:43  lr: 0.000200  loss: 1.1558 (1.4010)  loss_n_40: 0.2743 (0.3175)  loss_n_60: 0.2776 (0.3246)  loss_n_80: 0.2949 (0.3476)  loss_n_100: 0.3219 (0.3727)  triple_100: 0.0000 (0.0119)  triple_80: 0.0000 (0.0107)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0081)  time: 3.9207  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1080/1724]  eta: 0:42:03  lr: 0.000200  loss: 1.1121 (1.3987)  loss_n_40: 0.2743 (0.3172)  loss_n_60: 0.2636 (0.3241)  loss_n_80: 0.2781 (0.3470)  loss_n_100: 0.2916 (0.3720)  triple_100: 0.0000 (0.0118)  triple_80: 0.0000 (0.0106)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0081)  time: 3.9204  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1090/1724]  eta: 0:41:24  lr: 0.000200  loss: 1.1262 (1.3964)  loss_n_40: 0.2764 (0.3170)  loss_n_60: 0.2777 (0.3237)  loss_n_80: 0.2823 (0.3464)  loss_n_100: 0.2915 (0.3713)  triple_100: 0.0000 (0.0117)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0080)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1100/1724]  eta: 0:40:45  lr: 0.000200  loss: 1.0445 (1.3929)  loss_n_40: 0.2492 (0.3165)  loss_n_60: 0.2542 (0.3230)  loss_n_80: 0.2666 (0.3455)  loss_n_100: 0.2786 (0.3703)  triple_100: 0.0000 (0.0116)  triple_80: 0.0000 (0.0104)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0079)  time: 3.9201  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1110/1724]  eta: 0:40:06  lr: 0.000200  loss: 0.9515 (1.3891)  loss_n_40: 0.2396 (0.3159)  loss_n_60: 0.2338 (0.3222)  loss_n_80: 0.2401 (0.3445)  loss_n_100: 0.2497 (0.3692)  triple_100: 0.0000 (0.0115)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0079)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1120/1724]  eta: 0:39:27  lr: 0.000200  loss: 0.9853 (1.3856)  loss_n_40: 0.2423 (0.3152)  loss_n_60: 0.2248 (0.3214)  loss_n_80: 0.2383 (0.3437)  loss_n_100: 0.2432 (0.3682)  triple_100: 0.0000 (0.0114)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0079)  time: 3.9210  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1130/1724]  eta: 0:38:47  lr: 0.000200  loss: 1.0448 (1.3837)  loss_n_40: 0.2589 (0.3150)  loss_n_60: 0.2474 (0.3210)  loss_n_80: 0.2604 (0.3432)  loss_n_100: 0.2690 (0.3676)  triple_100: 0.0000 (0.0113)  triple_80: 0.0000 (0.0102)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0078)  time: 3.9206  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1140/1724]  eta: 0:38:08  lr: 0.000200  loss: 0.9994 (1.3799)  loss_n_40: 0.2428 (0.3143)  loss_n_60: 0.2414 (0.3202)  loss_n_80: 0.2566 (0.3423)  loss_n_100: 0.2757 (0.3666)  triple_100: 0.0000 (0.0112)  triple_80: 0.0000 (0.0101)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0078)  time: 3.9197  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1150/1724]  eta: 0:37:29  lr: 0.000200  loss: 1.0581 (1.3778)  loss_n_40: 0.2431 (0.3139)  loss_n_60: 0.2536 (0.3198)  loss_n_80: 0.2726 (0.3418)  loss_n_100: 0.2891 (0.3661)  triple_100: 0.0000 (0.0111)  triple_80: 0.0000 (0.0100)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0077)  time: 3.9201  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1160/1724]  eta: 0:36:50  lr: 0.000200  loss: 1.1083 (1.3756)  loss_n_40: 0.2700 (0.3136)  loss_n_60: 0.2666 (0.3194)  loss_n_80: 0.2820 (0.3412)  loss_n_100: 0.2926 (0.3654)  triple_100: 0.0000 (0.0110)  triple_80: 0.0000 (0.0099)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0076)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1170/1724]  eta: 0:36:11  lr: 0.000200  loss: 1.0405 (1.3732)  loss_n_40: 0.2583 (0.3133)  loss_n_60: 0.2470 (0.3190)  loss_n_80: 0.2552 (0.3407)  loss_n_100: 0.2753 (0.3647)  triple_100: 0.0000 (0.0109)  triple_80: 0.0000 (0.0098)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0076)  time: 3.9200  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1180/1724]  eta: 0:35:32  lr: 0.000200  loss: 1.0203 (1.3700)  loss_n_40: 0.2600 (0.3127)  loss_n_60: 0.2410 (0.3183)  loss_n_80: 0.2576 (0.3399)  loss_n_100: 0.2687 (0.3638)  triple_100: 0.0000 (0.0108)  triple_80: 0.0000 (0.0097)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0075)  time: 3.9201  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1190/1724]  eta: 0:34:52  lr: 0.000200  loss: 0.9969 (1.3665)  loss_n_40: 0.2412 (0.3121)  loss_n_60: 0.2402 (0.3175)  loss_n_80: 0.2517 (0.3390)  loss_n_100: 0.2589 (0.3629)  triple_100: 0.0000 (0.0108)  triple_80: 0.0000 (0.0096)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0075)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1200/1724]  eta: 0:34:13  lr: 0.000200  loss: 0.9236 (1.3635)  loss_n_40: 0.2263 (0.3116)  loss_n_60: 0.2234 (0.3169)  loss_n_80: 0.2341 (0.3383)  loss_n_100: 0.2449 (0.3620)  triple_100: 0.0000 (0.0107)  triple_80: 0.0000 (0.0096)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0074)  time: 3.9196  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1210/1724]  eta: 0:33:34  lr: 0.000200  loss: 0.9420 (1.3608)  loss_n_40: 0.2414 (0.3111)  loss_n_60: 0.2256 (0.3163)  loss_n_80: 0.2341 (0.3376)  loss_n_100: 0.2458 (0.3612)  triple_100: 0.0000 (0.0106)  triple_80: 0.0000 (0.0096)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0073)  time: 3.9212  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1220/1724]  eta: 0:32:55  lr: 0.000200  loss: 0.9680 (1.3576)  loss_n_40: 0.2501 (0.3106)  loss_n_60: 0.2350 (0.3156)  loss_n_80: 0.2296 (0.3368)  loss_n_100: 0.2458 (0.3603)  triple_100: 0.0000 (0.0105)  triple_80: 0.0000 (0.0095)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0073)  time: 3.9217  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1230/1724]  eta: 0:32:16  lr: 0.000200  loss: 1.0870 (1.3594)  loss_n_40: 0.2562 (0.3102)  loss_n_60: 0.2595 (0.3154)  loss_n_80: 0.2853 (0.3366)  loss_n_100: 0.2997 (0.3602)  triple_100: 0.0000 (0.0110)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0083)  time: 3.9200  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1240/1724]  eta: 0:31:36  lr: 0.000200  loss: 1.4791 (1.3640)  loss_n_40: 0.2814 (0.3103)  loss_n_60: 0.3185 (0.3158)  loss_n_80: 0.3631 (0.3375)  loss_n_100: 0.4107 (0.3614)  triple_100: 0.0000 (0.0117)  triple_80: 0.0000 (0.0110)  triple_60: 0.0000 (0.0079)  triple_40: 0.0000 (0.0083)  time: 3.9191  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [1250/1724]  eta: 0:30:57  lr: 0.000200  loss: 1.6353 (1.3663)  loss_n_40: 0.3296 (0.3105)  loss_n_60: 0.3768 (0.3164)  loss_n_80: 0.4325 (0.3384)  loss_n_100: 0.4690 (0.3624)  triple_100: 0.0000 (0.0116)  triple_80: 0.0000 (0.0109)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0082)  time: 3.9183  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1260/1724]  eta: 0:30:18  lr: 0.000200  loss: 1.5814 (1.3676)  loss_n_40: 0.3313 (0.3107)  loss_n_60: 0.3625 (0.3167)  loss_n_80: 0.3961 (0.3388)  loss_n_100: 0.4514 (0.3630)  triple_100: 0.0000 (0.0115)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0078)  triple_40: 0.0000 (0.0081)  time: 3.9179  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1270/1724]  eta: 0:29:39  lr: 0.000200  loss: 1.4537 (1.3686)  loss_n_40: 0.3397 (0.3109)  loss_n_60: 0.3568 (0.3171)  loss_n_80: 0.3720 (0.3391)  loss_n_100: 0.4346 (0.3635)  triple_100: 0.0000 (0.0114)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0077)  triple_40: 0.0000 (0.0081)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1280/1724]  eta: 0:29:00  lr: 0.000200  loss: 1.4315 (1.3687)  loss_n_40: 0.3243 (0.3111)  loss_n_60: 0.3450 (0.3173)  loss_n_80: 0.3499 (0.3392)  loss_n_100: 0.3767 (0.3636)  triple_100: 0.0000 (0.0113)  triple_80: 0.0000 (0.0107)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0080)  time: 3.9176  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1290/1724]  eta: 0:28:20  lr: 0.000200  loss: 1.2864 (1.3677)  loss_n_40: 0.2954 (0.3109)  loss_n_60: 0.3169 (0.3172)  loss_n_80: 0.3197 (0.3389)  loss_n_100: 0.3374 (0.3633)  triple_100: 0.0000 (0.0112)  triple_80: 0.0000 (0.0106)  triple_60: 0.0000 (0.0076)  triple_40: 0.0000 (0.0080)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1300/1724]  eta: 0:27:41  lr: 0.000200  loss: 1.1861 (1.3667)  loss_n_40: 0.2848 (0.3109)  loss_n_60: 0.2867 (0.3170)  loss_n_80: 0.2872 (0.3387)  loss_n_100: 0.3250 (0.3630)  triple_100: 0.0000 (0.0111)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0079)  time: 3.9191  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1310/1724]  eta: 0:27:02  lr: 0.000200  loss: 1.2461 (1.3666)  loss_n_40: 0.3034 (0.3111)  loss_n_60: 0.3048 (0.3171)  loss_n_80: 0.3165 (0.3387)  loss_n_100: 0.3366 (0.3629)  triple_100: 0.0000 (0.0111)  triple_80: 0.0000 (0.0104)  triple_60: 0.0000 (0.0075)  triple_40: 0.0000 (0.0078)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1320/1724]  eta: 0:26:23  lr: 0.000200  loss: 1.2157 (1.3650)  loss_n_40: 0.2930 (0.3109)  loss_n_60: 0.2918 (0.3168)  loss_n_80: 0.3127 (0.3383)  loss_n_100: 0.3182 (0.3625)  triple_100: 0.0000 (0.0110)  triple_80: 0.0000 (0.0104)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0078)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1330/1724]  eta: 0:25:44  lr: 0.000200  loss: 1.0835 (1.3638)  loss_n_40: 0.2706 (0.3108)  loss_n_60: 0.2581 (0.3167)  loss_n_80: 0.2801 (0.3380)  loss_n_100: 0.2848 (0.3621)  triple_100: 0.0000 (0.0109)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0077)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1340/1724]  eta: 0:25:04  lr: 0.000200  loss: 1.1282 (1.3622)  loss_n_40: 0.2701 (0.3106)  loss_n_60: 0.2714 (0.3163)  loss_n_80: 0.2801 (0.3376)  loss_n_100: 0.2944 (0.3617)  triple_100: 0.0000 (0.0108)  triple_80: 0.0000 (0.0102)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0077)  time: 3.9196  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1350/1724]  eta: 0:24:25  lr: 0.000200  loss: 1.0748 (1.3602)  loss_n_40: 0.2549 (0.3103)  loss_n_60: 0.2634 (0.3160)  loss_n_80: 0.2682 (0.3371)  loss_n_100: 0.2900 (0.3612)  triple_100: 0.0000 (0.0107)  triple_80: 0.0000 (0.0101)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0076)  time: 3.9199  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1360/1724]  eta: 0:23:46  lr: 0.000200  loss: 1.0543 (1.3579)  loss_n_40: 0.2542 (0.3100)  loss_n_60: 0.2571 (0.3155)  loss_n_80: 0.2675 (0.3365)  loss_n_100: 0.2816 (0.3605)  triple_100: 0.0000 (0.0107)  triple_80: 0.0000 (0.0100)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0075)  time: 3.9203  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1370/1724]  eta: 0:23:07  lr: 0.000200  loss: 1.2010 (1.3584)  loss_n_40: 0.2905 (0.3100)  loss_n_60: 0.2811 (0.3156)  loss_n_80: 0.2907 (0.3367)  loss_n_100: 0.3069 (0.3607)  triple_100: 0.0000 (0.0106)  triple_80: 0.0000 (0.0100)  triple_60: 0.0000 (0.0074)  triple_40: 0.0000 (0.0075)  time: 3.9205  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1380/1724]  eta: 0:22:28  lr: 0.000200  loss: 1.4704 (1.3632)  loss_n_40: 0.3242 (0.3104)  loss_n_60: 0.3401 (0.3163)  loss_n_80: 0.3720 (0.3375)  loss_n_100: 0.4180 (0.3616)  triple_100: 0.0000 (0.0117)  triple_80: 0.0000 (0.0109)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0074)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1390/1724]  eta: 0:21:49  lr: 0.000200  loss: 1.6323 (1.3653)  loss_n_40: 0.3654 (0.3108)  loss_n_60: 0.4005 (0.3169)  loss_n_80: 0.4313 (0.3381)  loss_n_100: 0.4644 (0.3624)  triple_100: 0.0000 (0.0116)  triple_80: 0.0000 (0.0108)  triple_60: 0.0000 (0.0073)  triple_40: 0.0000 (0.0074)  time: 3.9196  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1400/1724]  eta: 0:21:09  lr: 0.000200  loss: 1.5923 (1.3665)  loss_n_40: 0.3594 (0.3112)  loss_n_60: 0.3878 (0.3173)  loss_n_80: 0.4120 (0.3386)  loss_n_100: 0.4431 (0.3626)  triple_100: 0.0000 (0.0116)  triple_80: 0.0000 (0.0107)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0073)  time: 3.9198  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1410/1724]  eta: 0:20:30  lr: 0.000200  loss: 1.4053 (1.3666)  loss_n_40: 0.3151 (0.3113)  loss_n_60: 0.3472 (0.3174)  loss_n_80: 0.3528 (0.3387)  loss_n_100: 0.3691 (0.3627)  triple_100: 0.0000 (0.0115)  triple_80: 0.0000 (0.0106)  triple_60: 0.0000 (0.0072)  triple_40: 0.0000 (0.0073)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1420/1724]  eta: 0:19:51  lr: 0.000200  loss: 1.2475 (1.3654)  loss_n_40: 0.2788 (0.3110)  loss_n_60: 0.3032 (0.3173)  loss_n_80: 0.3255 (0.3385)  loss_n_100: 0.3399 (0.3624)  triple_100: 0.0000 (0.0114)  triple_80: 0.0000 (0.0106)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0072)  time: 3.9173  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1430/1724]  eta: 0:19:12  lr: 0.000200  loss: 1.1642 (1.3645)  loss_n_40: 0.2738 (0.3109)  loss_n_60: 0.2825 (0.3172)  loss_n_80: 0.2984 (0.3383)  loss_n_100: 0.3155 (0.3621)  triple_100: 0.0000 (0.0113)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0072)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1440/1724]  eta: 0:18:33  lr: 0.000200  loss: 1.2251 (1.3631)  loss_n_40: 0.2789 (0.3106)  loss_n_60: 0.2998 (0.3169)  loss_n_80: 0.3131 (0.3380)  loss_n_100: 0.3215 (0.3618)  triple_100: 0.0000 (0.0112)  triple_80: 0.0000 (0.0104)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0071)  time: 3.9198  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1450/1724]  eta: 0:17:53  lr: 0.000200  loss: 1.1816 (1.3620)  loss_n_40: 0.2752 (0.3104)  loss_n_60: 0.2918 (0.3167)  loss_n_80: 0.3082 (0.3376)  loss_n_100: 0.3051 (0.3613)  triple_100: 0.0000 (0.0113)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0071)  triple_40: 0.0000 (0.0071)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1460/1724]  eta: 0:17:14  lr: 0.000200  loss: 1.3136 (1.3652)  loss_n_40: 0.3119 (0.3105)  loss_n_60: 0.3085 (0.3173)  loss_n_80: 0.3501 (0.3387)  loss_n_100: 0.3796 (0.3629)  triple_100: 0.0000 (0.0113)  triple_80: 0.0000 (0.0106)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0070)  time: 3.9190  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1470/1724]  eta: 0:16:35  lr: 0.000200  loss: 1.8247 (1.3690)  loss_n_40: 0.3195 (0.3107)  loss_n_60: 0.4137 (0.3180)  loss_n_80: 0.4725 (0.3399)  loss_n_100: 0.5648 (0.3647)  triple_100: 0.0000 (0.0112)  triple_80: 0.0000 (0.0106)  triple_60: 0.0000 (0.0070)  triple_40: 0.0000 (0.0070)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1480/1724]  eta: 0:15:56  lr: 0.000200  loss: 1.5473 (1.3697)  loss_n_40: 0.3210 (0.3108)  loss_n_60: 0.3466 (0.3182)  loss_n_80: 0.4091 (0.3402)  loss_n_100: 0.4536 (0.3651)  triple_100: 0.0000 (0.0111)  triple_80: 0.0000 (0.0105)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0069)  time: 3.9189  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [1490/1724]  eta: 0:15:17  lr: 0.000200  loss: 1.4035 (1.3695)  loss_n_40: 0.2999 (0.3107)  loss_n_60: 0.3251 (0.3181)  loss_n_80: 0.3601 (0.3402)  loss_n_100: 0.4064 (0.3653)  triple_100: 0.0000 (0.0111)  triple_80: 0.0000 (0.0104)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0069)  time: 3.9206  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1500/1724]  eta: 0:14:37  lr: 0.000200  loss: 1.2680 (1.3686)  loss_n_40: 0.2832 (0.3105)  loss_n_60: 0.2984 (0.3180)  loss_n_80: 0.3203 (0.3400)  loss_n_100: 0.3455 (0.3651)  triple_100: 0.0000 (0.0110)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0068)  time: 3.9199  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1510/1724]  eta: 0:13:58  lr: 0.000200  loss: 1.1741 (1.3669)  loss_n_40: 0.2698 (0.3102)  loss_n_60: 0.2848 (0.3176)  loss_n_80: 0.2974 (0.3396)  loss_n_100: 0.3262 (0.3647)  triple_100: 0.0000 (0.0109)  triple_80: 0.0000 (0.0103)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0068)  time: 3.9197  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1520/1724]  eta: 0:13:19  lr: 0.000200  loss: 1.1443 (1.3662)  loss_n_40: 0.2698 (0.3102)  loss_n_60: 0.2747 (0.3175)  loss_n_80: 0.2849 (0.3394)  loss_n_100: 0.3049 (0.3645)  triple_100: 0.0000 (0.0108)  triple_80: 0.0000 (0.0102)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0067)  time: 3.9203  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1530/1724]  eta: 0:12:40  lr: 0.000200  loss: 1.1443 (1.3645)  loss_n_40: 0.2835 (0.3099)  loss_n_60: 0.2747 (0.3173)  loss_n_80: 0.2849 (0.3390)  loss_n_100: 0.2981 (0.3640)  triple_100: 0.0000 (0.0108)  triple_80: 0.0000 (0.0101)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0067)  time: 3.9193  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1540/1724]  eta: 0:12:01  lr: 0.000200  loss: 1.0650 (1.3628)  loss_n_40: 0.2509 (0.3096)  loss_n_60: 0.2616 (0.3169)  loss_n_80: 0.2695 (0.3386)  loss_n_100: 0.2848 (0.3636)  triple_100: 0.0000 (0.0107)  triple_80: 0.0000 (0.0101)  triple_60: 0.0000 (0.0067)  triple_40: 0.0000 (0.0067)  time: 3.9189  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1550/1724]  eta: 0:11:21  lr: 0.000200  loss: 1.0123 (1.3608)  loss_n_40: 0.2452 (0.3093)  loss_n_60: 0.2422 (0.3165)  loss_n_80: 0.2523 (0.3381)  loss_n_100: 0.2774 (0.3630)  triple_100: 0.0000 (0.0106)  triple_80: 0.0000 (0.0100)  triple_60: 0.0000 (0.0066)  triple_40: 0.0000 (0.0066)  time: 3.9191  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1560/1724]  eta: 0:10:42  lr: 0.000200  loss: 1.0138 (1.3593)  loss_n_40: 0.2402 (0.3090)  loss_n_60: 0.2449 (0.3162)  loss_n_80: 0.2563 (0.3377)  loss_n_100: 0.2819 (0.3626)  triple_100: 0.0000 (0.0106)  triple_80: 0.0000 (0.0100)  triple_60: 0.0000 (0.0066)  triple_40: 0.0000 (0.0066)  time: 3.9192  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1570/1724]  eta: 0:10:03  lr: 0.000200  loss: 1.0013 (1.3568)  loss_n_40: 0.2542 (0.3086)  loss_n_60: 0.2420 (0.3157)  loss_n_80: 0.2482 (0.3371)  loss_n_100: 0.2669 (0.3619)  triple_100: 0.0000 (0.0105)  triple_80: 0.0000 (0.0099)  triple_60: 0.0000 (0.0065)  triple_40: 0.0000 (0.0065)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1580/1724]  eta: 0:09:24  lr: 0.000200  loss: 0.9798 (1.3547)  loss_n_40: 0.2461 (0.3082)  loss_n_60: 0.2396 (0.3153)  loss_n_80: 0.2403 (0.3366)  loss_n_100: 0.2522 (0.3613)  triple_100: 0.0000 (0.0104)  triple_80: 0.0000 (0.0098)  triple_60: 0.0000 (0.0065)  triple_40: 0.0000 (0.0065)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1590/1724]  eta: 0:08:45  lr: 0.000200  loss: 1.0065 (1.3556)  loss_n_40: 0.2485 (0.3080)  loss_n_60: 0.2457 (0.3151)  loss_n_80: 0.2528 (0.3364)  loss_n_100: 0.2759 (0.3612)  triple_100: 0.0000 (0.0107)  triple_80: 0.0000 (0.0098)  triple_60: 0.0000 (0.0069)  triple_40: 0.0000 (0.0075)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1600/1724]  eta: 0:08:05  lr: 0.000200  loss: 2.6178 (1.3732)  loss_n_40: 0.3844 (0.3096)  loss_n_60: 0.4771 (0.3179)  loss_n_80: 0.6089 (0.3403)  loss_n_100: 0.7246 (0.3660)  triple_100: 0.0000 (0.0138)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0068)  triple_40: 0.0000 (0.0075)  time: 3.9182  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1610/1724]  eta: 0:07:26  lr: 0.000200  loss: 3.5988 (1.3903)  loss_n_40: 0.5977 (0.3119)  loss_n_60: 0.7753 (0.3209)  loss_n_80: 0.9732 (0.3441)  loss_n_100: 1.1271 (0.3705)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0112)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0095)  time: 3.9167  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1620/1724]  eta: 0:06:47  lr: 0.000200  loss: 3.4149 (1.4030)  loss_n_40: 0.6491 (0.3142)  loss_n_60: 0.7661 (0.3237)  loss_n_80: 0.8901 (0.3473)  loss_n_100: 0.9730 (0.3743)  triple_100: 0.0000 (0.0138)  triple_80: 0.0000 (0.0117)  triple_60: 0.0000 (0.0084)  triple_40: 0.0000 (0.0095)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1630/1724]  eta: 0:06:08  lr: 0.000200  loss: 3.1427 (1.4130)  loss_n_40: 0.6489 (0.3163)  loss_n_60: 0.7706 (0.3265)  loss_n_80: 0.7773 (0.3499)  loss_n_100: 0.8740 (0.3771)  triple_100: 0.0000 (0.0137)  triple_80: 0.0000 (0.0117)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0094)  time: 3.9177  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1640/1724]  eta: 0:05:29  lr: 0.000200  loss: 2.8050 (1.4200)  loss_n_40: 0.5696 (0.3176)  loss_n_60: 0.7089 (0.3285)  loss_n_80: 0.7271 (0.3517)  loss_n_100: 0.7923 (0.3792)  triple_100: 0.0000 (0.0136)  triple_80: 0.0000 (0.0116)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0094)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1650/1724]  eta: 0:04:50  lr: 0.000200  loss: 2.3404 (1.4251)  loss_n_40: 0.4948 (0.3187)  loss_n_60: 0.5903 (0.3300)  loss_n_80: 0.6009 (0.3531)  loss_n_100: 0.6588 (0.3808)  triple_100: 0.0000 (0.0136)  triple_80: 0.0000 (0.0115)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0093)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1660/1724]  eta: 0:04:10  lr: 0.000200  loss: 2.1681 (1.4289)  loss_n_40: 0.4718 (0.3196)  loss_n_60: 0.5410 (0.3310)  loss_n_80: 0.5620 (0.3540)  loss_n_100: 0.6088 (0.3819)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0114)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0093)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1670/1724]  eta: 0:03:31  lr: 0.000200  loss: 1.8099 (1.4305)  loss_n_40: 0.4301 (0.3200)  loss_n_60: 0.4313 (0.3315)  loss_n_80: 0.4411 (0.3544)  loss_n_100: 0.4970 (0.3824)  triple_100: 0.0000 (0.0134)  triple_80: 0.0000 (0.0115)  triple_60: 0.0000 (0.0082)  triple_40: 0.0000 (0.0092)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1680/1724]  eta: 0:02:52  lr: 0.000200  loss: 1.5845 (1.4316)  loss_n_40: 0.3890 (0.3205)  loss_n_60: 0.3901 (0.3318)  loss_n_80: 0.3881 (0.3546)  loss_n_100: 0.4391 (0.3827)  triple_100: 0.0000 (0.0133)  triple_80: 0.0000 (0.0114)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0092)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1690/1724]  eta: 0:02:13  lr: 0.000200  loss: 1.5600 (1.4326)  loss_n_40: 0.3862 (0.3209)  loss_n_60: 0.3810 (0.3321)  loss_n_80: 0.3791 (0.3549)  loss_n_100: 0.4166 (0.3830)  triple_100: 0.0000 (0.0132)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0081)  triple_40: 0.0000 (0.0091)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1700/1724]  eta: 0:01:34  lr: 0.000200  loss: 1.4013 (1.4321)  loss_n_40: 0.3249 (0.3209)  loss_n_60: 0.3283 (0.3321)  loss_n_80: 0.3515 (0.3548)  loss_n_100: 0.3973 (0.3830)  triple_100: 0.0000 (0.0132)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0080)  triple_40: 0.0000 (0.0091)  time: 3.9184  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:18]  [1710/1724]  eta: 0:00:54  lr: 0.000200  loss: 1.4500 (1.4336)  loss_n_40: 0.3363 (0.3211)  loss_n_60: 0.3380 (0.3322)  loss_n_80: 0.3565 (0.3548)  loss_n_100: 0.3793 (0.3831)  triple_100: 0.0000 (0.0134)  triple_80: 0.0000 (0.0113)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0093)  time: 3.9191  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18]  [1720/1724]  eta: 0:00:15  lr: 0.000200  loss: 1.7753 (1.4371)  loss_n_40: 0.3946 (0.3218)  loss_n_60: 0.4030 (0.3329)  loss_n_80: 0.4099 (0.3557)  loss_n_100: 0.4895 (0.3843)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0115)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0092)  time: 3.9190  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [1723/1724]  eta: 0:00:03  lr: 0.000200  loss: 1.8176 (1.4379)  loss_n_40: 0.3971 (0.3220)  loss_n_60: 0.4072 (0.3330)  loss_n_80: 0.4505 (0.3559)  loss_n_100: 0.5033 (0.3845)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0115)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0092)  time: 3.9187  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:18] Total time: 1:52:36 (3.9193 s / it)\n",
      "Averaged stats: lr: 0.000200  loss: 1.8176 (1.4379)  loss_n_40: 0.3971 (0.3220)  loss_n_60: 0.4072 (0.3330)  loss_n_80: 0.4505 (0.3559)  loss_n_100: 0.5033 (0.3845)  triple_100: 0.0000 (0.0135)  triple_80: 0.0000 (0.0115)  triple_60: 0.0000 (0.0083)  triple_40: 0.0000 (0.0092)\n",
      "Valid: [epoch:18]  [  0/845]  eta: 0:10:20  loss: 1.8451 (1.8451)  loss_n_40: 0.5073 (0.5073)  loss_n_60: 0.4450 (0.4450)  loss_n_80: 0.4444 (0.4444)  loss_n_100: 0.4484 (0.4484)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.7340  data: 0.4012  max mem: 46473\n",
      "Valid: [epoch:18]  [ 10/845]  eta: 0:05:09  loss: 1.8451 (1.9227)  loss_n_40: 0.4841 (0.4811)  loss_n_60: 0.4455 (0.4562)  loss_n_80: 0.4444 (0.4788)  loss_n_100: 0.4709 (0.5066)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3708  data: 0.0366  max mem: 46473\n",
      "Valid: [epoch:18]  [ 20/845]  eta: 0:04:51  loss: 1.8066 (1.8871)  loss_n_40: 0.4209 (0.4513)  loss_n_60: 0.4311 (0.4456)  loss_n_80: 0.4424 (0.4795)  loss_n_100: 0.4729 (0.5106)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [ 30/845]  eta: 0:04:42  loss: 1.7681 (1.9163)  loss_n_40: 0.4050 (0.4570)  loss_n_60: 0.4205 (0.4504)  loss_n_80: 0.4591 (0.4830)  loss_n_100: 0.4959 (0.5259)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [ 40/845]  eta: 0:04:36  loss: 1.7403 (1.9289)  loss_n_40: 0.4154 (0.4534)  loss_n_60: 0.4110 (0.4538)  loss_n_80: 0.4591 (0.4886)  loss_n_100: 0.4923 (0.5332)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3337  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [ 50/845]  eta: 0:04:31  loss: 1.7083 (1.9179)  loss_n_40: 0.4287 (0.4548)  loss_n_60: 0.4010 (0.4517)  loss_n_80: 0.4269 (0.4834)  loss_n_100: 0.4637 (0.5279)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [ 60/845]  eta: 0:04:27  loss: 1.7575 (1.9766)  loss_n_40: 0.4646 (0.4607)  loss_n_60: 0.4145 (0.4643)  loss_n_80: 0.4495 (0.5029)  loss_n_100: 0.4680 (0.5488)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0002  max mem: 46473\n",
      "Valid: [epoch:18]  [ 70/845]  eta: 0:04:23  loss: 2.1177 (1.9762)  loss_n_40: 0.4222 (0.4579)  loss_n_60: 0.5036 (0.4643)  loss_n_80: 0.5085 (0.5031)  loss_n_100: 0.5972 (0.5509)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [ 80/845]  eta: 0:04:19  loss: 2.1011 (2.0117)  loss_n_40: 0.4318 (0.4627)  loss_n_60: 0.4806 (0.4721)  loss_n_80: 0.5262 (0.5141)  loss_n_100: 0.5969 (0.5628)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [ 90/845]  eta: 0:04:15  loss: 2.1367 (2.0254)  loss_n_40: 0.5035 (0.4710)  loss_n_60: 0.4841 (0.4754)  loss_n_80: 0.5364 (0.5154)  loss_n_100: 0.5904 (0.5636)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [100/845]  eta: 0:04:11  loss: 2.0676 (2.0232)  loss_n_40: 0.5025 (0.4726)  loss_n_60: 0.4783 (0.4747)  loss_n_80: 0.5034 (0.5143)  loss_n_100: 0.5604 (0.5616)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [110/845]  eta: 0:04:08  loss: 1.7384 (2.0094)  loss_n_40: 0.4573 (0.4707)  loss_n_60: 0.4049 (0.4714)  loss_n_80: 0.4654 (0.5100)  loss_n_100: 0.4664 (0.5573)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [120/845]  eta: 0:04:04  loss: 1.8494 (1.9969)  loss_n_40: 0.4153 (0.4674)  loss_n_60: 0.3974 (0.4683)  loss_n_80: 0.4649 (0.5072)  loss_n_100: 0.5117 (0.5540)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [130/845]  eta: 0:04:01  loss: 1.9675 (2.0273)  loss_n_40: 0.4172 (0.4704)  loss_n_60: 0.4577 (0.4757)  loss_n_80: 0.5404 (0.5162)  loss_n_100: 0.5687 (0.5650)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [140/845]  eta: 0:03:57  loss: 1.9675 (2.0141)  loss_n_40: 0.4431 (0.4678)  loss_n_60: 0.4577 (0.4726)  loss_n_80: 0.4980 (0.5132)  loss_n_100: 0.5577 (0.5605)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [150/845]  eta: 0:03:54  loss: 1.6472 (2.0061)  loss_n_40: 0.4316 (0.4680)  loss_n_60: 0.3994 (0.4703)  loss_n_80: 0.4452 (0.5104)  loss_n_100: 0.4397 (0.5574)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [160/845]  eta: 0:03:50  loss: 1.7882 (1.9986)  loss_n_40: 0.4498 (0.4696)  loss_n_60: 0.4062 (0.4687)  loss_n_80: 0.4171 (0.5068)  loss_n_100: 0.4489 (0.5535)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [170/845]  eta: 0:03:47  loss: 1.6812 (1.9865)  loss_n_40: 0.4468 (0.4698)  loss_n_60: 0.3960 (0.4664)  loss_n_80: 0.4165 (0.5029)  loss_n_100: 0.4293 (0.5474)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [180/845]  eta: 0:03:43  loss: 1.7322 (1.9851)  loss_n_40: 0.4263 (0.4692)  loss_n_60: 0.3907 (0.4661)  loss_n_80: 0.4480 (0.5026)  loss_n_100: 0.4351 (0.5472)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [190/845]  eta: 0:03:40  loss: 1.9299 (1.9895)  loss_n_40: 0.4564 (0.4705)  loss_n_60: 0.4666 (0.4680)  loss_n_80: 0.4726 (0.5034)  loss_n_100: 0.5135 (0.5476)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [200/845]  eta: 0:03:36  loss: 2.0009 (1.9876)  loss_n_40: 0.4580 (0.4693)  loss_n_60: 0.4805 (0.4675)  loss_n_80: 0.5160 (0.5033)  loss_n_100: 0.5583 (0.5475)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [210/845]  eta: 0:03:33  loss: 1.9583 (1.9851)  loss_n_40: 0.4284 (0.4693)  loss_n_60: 0.4461 (0.4668)  loss_n_80: 0.4966 (0.5023)  loss_n_100: 0.5538 (0.5468)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [220/845]  eta: 0:03:30  loss: 1.9578 (1.9831)  loss_n_40: 0.4690 (0.4692)  loss_n_60: 0.4415 (0.4655)  loss_n_80: 0.4870 (0.5007)  loss_n_100: 0.4995 (0.5449)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:18]  [230/845]  eta: 0:03:26  loss: 1.7076 (1.9780)  loss_n_40: 0.4383 (0.4688)  loss_n_60: 0.4056 (0.4645)  loss_n_80: 0.4378 (0.4997)  loss_n_100: 0.4466 (0.5425)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [240/845]  eta: 0:03:23  loss: 1.7648 (1.9727)  loss_n_40: 0.4158 (0.4674)  loss_n_60: 0.4017 (0.4632)  loss_n_80: 0.4638 (0.4984)  loss_n_100: 0.4756 (0.5412)  triple_100: 0.0000 (0.0025)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [250/845]  eta: 0:03:19  loss: 1.8209 (1.9789)  loss_n_40: 0.4324 (0.4683)  loss_n_60: 0.4374 (0.4651)  loss_n_80: 0.4948 (0.5001)  loss_n_100: 0.5126 (0.5429)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [260/845]  eta: 0:03:16  loss: 1.9102 (1.9878)  loss_n_40: 0.4787 (0.4692)  loss_n_60: 0.4444 (0.4668)  loss_n_80: 0.4948 (0.5028)  loss_n_100: 0.5277 (0.5467)  triple_100: 0.0000 (0.0023)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [270/845]  eta: 0:03:13  loss: 1.9619 (1.9855)  loss_n_40: 0.4732 (0.4686)  loss_n_60: 0.4444 (0.4663)  loss_n_80: 0.4771 (0.5026)  loss_n_100: 0.5277 (0.5458)  triple_100: 0.0000 (0.0022)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [280/845]  eta: 0:03:09  loss: 1.7810 (1.9894)  loss_n_40: 0.4162 (0.4699)  loss_n_60: 0.4394 (0.4670)  loss_n_80: 0.4732 (0.5035)  loss_n_100: 0.4949 (0.5468)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [290/845]  eta: 0:03:06  loss: 2.0329 (1.9949)  loss_n_40: 0.4891 (0.4708)  loss_n_60: 0.4711 (0.4683)  loss_n_80: 0.4912 (0.5051)  loss_n_100: 0.5652 (0.5486)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [300/845]  eta: 0:03:02  loss: 2.0329 (1.9948)  loss_n_40: 0.4647 (0.4706)  loss_n_60: 0.4711 (0.4683)  loss_n_80: 0.5191 (0.5052)  loss_n_100: 0.5652 (0.5486)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [310/845]  eta: 0:02:59  loss: 1.9023 (1.9921)  loss_n_40: 0.4647 (0.4715)  loss_n_60: 0.4368 (0.4678)  loss_n_80: 0.4820 (0.5041)  loss_n_100: 0.5496 (0.5467)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [320/845]  eta: 0:02:56  loss: 1.7906 (1.9929)  loss_n_40: 0.4654 (0.4719)  loss_n_60: 0.4245 (0.4676)  loss_n_80: 0.4526 (0.5039)  loss_n_100: 0.4541 (0.5465)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [330/845]  eta: 0:02:52  loss: 1.8797 (1.9906)  loss_n_40: 0.4482 (0.4720)  loss_n_60: 0.4308 (0.4669)  loss_n_80: 0.4790 (0.5031)  loss_n_100: 0.4933 (0.5457)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3341  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [340/845]  eta: 0:02:49  loss: 2.0570 (1.9940)  loss_n_40: 0.4765 (0.4724)  loss_n_60: 0.4721 (0.4680)  loss_n_80: 0.4953 (0.5039)  loss_n_100: 0.5564 (0.5470)  triple_100: 0.0000 (0.0028)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3339  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [350/845]  eta: 0:02:46  loss: 1.8387 (1.9895)  loss_n_40: 0.4426 (0.4714)  loss_n_60: 0.4238 (0.4670)  loss_n_80: 0.4890 (0.5027)  loss_n_100: 0.5285 (0.5457)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [360/845]  eta: 0:02:42  loss: 1.7174 (1.9871)  loss_n_40: 0.4120 (0.4710)  loss_n_60: 0.4007 (0.4661)  loss_n_80: 0.4486 (0.5022)  loss_n_100: 0.4758 (0.5452)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [370/845]  eta: 0:02:39  loss: 1.6960 (1.9833)  loss_n_40: 0.4120 (0.4704)  loss_n_60: 0.3864 (0.4652)  loss_n_80: 0.4285 (0.5013)  loss_n_100: 0.4684 (0.5439)  triple_100: 0.0000 (0.0026)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3349  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [380/845]  eta: 0:02:35  loss: 1.8888 (1.9877)  loss_n_40: 0.4819 (0.4716)  loss_n_60: 0.4543 (0.4664)  loss_n_80: 0.4571 (0.5021)  loss_n_100: 0.5085 (0.5451)  triple_100: 0.0000 (0.0025)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [390/845]  eta: 0:02:32  loss: 2.1124 (1.9914)  loss_n_40: 0.4850 (0.4716)  loss_n_60: 0.4883 (0.4672)  loss_n_80: 0.5189 (0.5034)  loss_n_100: 0.5671 (0.5468)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [400/845]  eta: 0:02:29  loss: 2.0459 (1.9988)  loss_n_40: 0.4776 (0.4728)  loss_n_60: 0.4801 (0.4689)  loss_n_80: 0.5137 (0.5056)  loss_n_100: 0.5671 (0.5492)  triple_100: 0.0000 (0.0024)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [410/845]  eta: 0:02:25  loss: 2.0636 (2.0033)  loss_n_40: 0.4832 (0.4737)  loss_n_60: 0.5023 (0.4701)  loss_n_80: 0.5292 (0.5069)  loss_n_100: 0.5941 (0.5505)  triple_100: 0.0000 (0.0023)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [420/845]  eta: 0:02:22  loss: 2.0636 (2.0099)  loss_n_40: 0.4869 (0.4741)  loss_n_60: 0.4983 (0.4717)  loss_n_80: 0.5292 (0.5088)  loss_n_100: 0.5982 (0.5531)  triple_100: 0.0000 (0.0023)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [430/845]  eta: 0:02:19  loss: 1.9909 (2.0067)  loss_n_40: 0.4799 (0.4740)  loss_n_60: 0.4662 (0.4707)  loss_n_80: 0.5075 (0.5078)  loss_n_100: 0.5651 (0.5520)  triple_100: 0.0000 (0.0022)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [440/845]  eta: 0:02:15  loss: 1.9301 (2.0089)  loss_n_40: 0.4485 (0.4740)  loss_n_60: 0.4451 (0.4715)  loss_n_80: 0.4956 (0.5086)  loss_n_100: 0.5356 (0.5527)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [450/845]  eta: 0:02:12  loss: 2.0070 (2.0071)  loss_n_40: 0.4268 (0.4735)  loss_n_60: 0.4729 (0.4710)  loss_n_80: 0.4864 (0.5080)  loss_n_100: 0.5284 (0.5525)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [460/845]  eta: 0:02:09  loss: 1.8382 (2.0038)  loss_n_40: 0.4336 (0.4735)  loss_n_60: 0.4404 (0.4702)  loss_n_80: 0.4313 (0.5068)  loss_n_100: 0.4559 (0.5512)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [470/845]  eta: 0:02:05  loss: 1.9429 (2.0032)  loss_n_40: 0.4430 (0.4733)  loss_n_60: 0.4529 (0.4701)  loss_n_80: 0.4638 (0.5066)  loss_n_100: 0.5206 (0.5512)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:18]  [480/845]  eta: 0:02:02  loss: 1.9429 (2.0021)  loss_n_40: 0.4509 (0.4729)  loss_n_60: 0.4576 (0.4697)  loss_n_80: 0.5014 (0.5067)  loss_n_100: 0.5237 (0.5508)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [490/845]  eta: 0:01:58  loss: 1.7842 (1.9996)  loss_n_40: 0.4284 (0.4724)  loss_n_60: 0.4173 (0.4691)  loss_n_80: 0.4763 (0.5061)  loss_n_100: 0.4769 (0.5501)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [500/845]  eta: 0:01:55  loss: 1.7395 (1.9991)  loss_n_40: 0.4205 (0.4720)  loss_n_60: 0.4110 (0.4689)  loss_n_80: 0.4555 (0.5062)  loss_n_100: 0.4897 (0.5500)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [510/845]  eta: 0:01:52  loss: 1.8967 (1.9996)  loss_n_40: 0.4126 (0.4719)  loss_n_60: 0.4450 (0.4690)  loss_n_80: 0.4998 (0.5064)  loss_n_100: 0.5174 (0.5504)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [520/845]  eta: 0:01:48  loss: 1.8967 (1.9983)  loss_n_40: 0.4126 (0.4713)  loss_n_60: 0.4450 (0.4687)  loss_n_80: 0.5045 (0.5062)  loss_n_100: 0.5266 (0.5502)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [530/845]  eta: 0:01:45  loss: 1.9244 (2.0001)  loss_n_40: 0.4361 (0.4713)  loss_n_60: 0.4707 (0.4693)  loss_n_80: 0.4963 (0.5068)  loss_n_100: 0.5261 (0.5510)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [540/845]  eta: 0:01:42  loss: 1.7690 (1.9941)  loss_n_40: 0.4279 (0.4703)  loss_n_60: 0.4368 (0.4680)  loss_n_80: 0.4711 (0.5054)  loss_n_100: 0.4624 (0.5486)  triple_100: 0.0000 (0.0018)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [550/845]  eta: 0:01:38  loss: 1.7283 (1.9948)  loss_n_40: 0.4207 (0.4697)  loss_n_60: 0.3969 (0.4684)  loss_n_80: 0.4486 (0.5058)  loss_n_100: 0.4358 (0.5492)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [560/845]  eta: 0:01:35  loss: 1.9481 (1.9940)  loss_n_40: 0.4306 (0.4700)  loss_n_60: 0.4533 (0.4681)  loss_n_80: 0.4995 (0.5054)  loss_n_100: 0.5440 (0.5488)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [570/845]  eta: 0:01:32  loss: 2.0187 (1.9945)  loss_n_40: 0.4783 (0.4698)  loss_n_60: 0.4670 (0.4681)  loss_n_80: 0.5063 (0.5058)  loss_n_100: 0.5382 (0.5491)  triple_100: 0.0000 (0.0017)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [580/845]  eta: 0:01:28  loss: 1.6508 (1.9892)  loss_n_40: 0.4149 (0.4691)  loss_n_60: 0.3870 (0.4668)  loss_n_80: 0.4209 (0.5043)  loss_n_100: 0.4596 (0.5474)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [590/845]  eta: 0:01:25  loss: 1.6165 (1.9898)  loss_n_40: 0.4269 (0.4693)  loss_n_60: 0.3870 (0.4671)  loss_n_80: 0.4117 (0.5044)  loss_n_100: 0.4329 (0.5473)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [600/845]  eta: 0:01:22  loss: 1.8084 (1.9870)  loss_n_40: 0.4400 (0.4689)  loss_n_60: 0.4331 (0.4663)  loss_n_80: 0.4438 (0.5037)  loss_n_100: 0.4581 (0.5465)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [610/845]  eta: 0:01:18  loss: 1.8964 (1.9847)  loss_n_40: 0.4365 (0.4686)  loss_n_60: 0.4331 (0.4658)  loss_n_80: 0.4750 (0.5031)  loss_n_100: 0.4646 (0.5457)  triple_100: 0.0000 (0.0016)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [620/845]  eta: 0:01:15  loss: 1.6469 (1.9804)  loss_n_40: 0.4287 (0.4683)  loss_n_60: 0.3884 (0.4650)  loss_n_80: 0.4104 (0.5016)  loss_n_100: 0.4192 (0.5439)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [630/845]  eta: 0:01:12  loss: 1.6469 (1.9796)  loss_n_40: 0.4303 (0.4682)  loss_n_60: 0.3959 (0.4648)  loss_n_80: 0.4012 (0.5014)  loss_n_100: 0.4329 (0.5437)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [640/845]  eta: 0:01:08  loss: 1.8895 (1.9798)  loss_n_40: 0.4372 (0.4676)  loss_n_60: 0.4369 (0.4648)  loss_n_80: 0.4891 (0.5017)  loss_n_100: 0.5107 (0.5443)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [650/845]  eta: 0:01:05  loss: 1.8260 (1.9779)  loss_n_40: 0.4367 (0.4675)  loss_n_60: 0.4120 (0.4643)  loss_n_80: 0.4462 (0.5012)  loss_n_100: 0.4888 (0.5435)  triple_100: 0.0000 (0.0015)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [660/845]  eta: 0:01:01  loss: 1.7174 (1.9773)  loss_n_40: 0.4187 (0.4673)  loss_n_60: 0.4012 (0.4642)  loss_n_80: 0.4445 (0.5010)  loss_n_100: 0.4512 (0.5433)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [670/845]  eta: 0:00:58  loss: 1.8972 (1.9784)  loss_n_40: 0.4187 (0.4676)  loss_n_60: 0.4471 (0.4647)  loss_n_80: 0.4625 (0.5012)  loss_n_100: 0.5430 (0.5436)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [680/845]  eta: 0:00:55  loss: 1.9862 (1.9794)  loss_n_40: 0.4674 (0.4678)  loss_n_60: 0.4811 (0.4649)  loss_n_80: 0.5072 (0.5014)  loss_n_100: 0.5430 (0.5439)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [690/845]  eta: 0:00:51  loss: 1.9862 (1.9795)  loss_n_40: 0.4807 (0.4683)  loss_n_60: 0.4624 (0.4650)  loss_n_80: 0.5072 (0.5012)  loss_n_100: 0.5360 (0.5437)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [700/845]  eta: 0:00:48  loss: 2.0198 (1.9793)  loss_n_40: 0.5064 (0.4688)  loss_n_60: 0.4674 (0.4651)  loss_n_80: 0.5010 (0.5009)  loss_n_100: 0.5291 (0.5431)  triple_100: 0.0000 (0.0014)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [710/845]  eta: 0:00:45  loss: 1.9065 (1.9785)  loss_n_40: 0.4490 (0.4687)  loss_n_60: 0.4314 (0.4650)  loss_n_80: 0.4861 (0.5007)  loss_n_100: 0.4650 (0.5427)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [720/845]  eta: 0:00:41  loss: 1.6988 (1.9753)  loss_n_40: 0.4159 (0.4681)  loss_n_60: 0.4049 (0.4642)  loss_n_80: 0.4117 (0.4999)  loss_n_100: 0.4426 (0.5418)  triple_100: 0.0000 (0.0013)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3345  data: 0.0001  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:18]  [730/845]  eta: 0:00:38  loss: 1.8257 (1.9774)  loss_n_40: 0.4359 (0.4682)  loss_n_60: 0.4262 (0.4646)  loss_n_80: 0.4918 (0.5002)  loss_n_100: 0.5270 (0.5423)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [740/845]  eta: 0:00:35  loss: 2.1014 (1.9785)  loss_n_40: 0.4767 (0.4689)  loss_n_60: 0.4757 (0.4647)  loss_n_80: 0.5172 (0.5005)  loss_n_100: 0.5512 (0.5423)  triple_100: 0.0000 (0.0021)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [750/845]  eta: 0:00:31  loss: 1.9909 (1.9782)  loss_n_40: 0.4579 (0.4686)  loss_n_60: 0.4483 (0.4647)  loss_n_80: 0.5005 (0.5005)  loss_n_100: 0.5319 (0.5424)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [760/845]  eta: 0:00:28  loss: 1.7277 (1.9804)  loss_n_40: 0.4212 (0.4687)  loss_n_60: 0.4281 (0.4652)  loss_n_80: 0.4562 (0.5012)  loss_n_100: 0.4818 (0.5433)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [770/845]  eta: 0:00:25  loss: 1.8757 (1.9817)  loss_n_40: 0.4151 (0.4686)  loss_n_60: 0.4645 (0.4655)  loss_n_80: 0.4695 (0.5016)  loss_n_100: 0.5101 (0.5440)  triple_100: 0.0000 (0.0020)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [780/845]  eta: 0:00:21  loss: 1.8757 (1.9811)  loss_n_40: 0.4139 (0.4687)  loss_n_60: 0.4575 (0.4654)  loss_n_80: 0.4845 (0.5014)  loss_n_100: 0.5026 (0.5436)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [790/845]  eta: 0:00:18  loss: 1.9851 (1.9821)  loss_n_40: 0.4365 (0.4688)  loss_n_60: 0.4448 (0.4656)  loss_n_80: 0.4848 (0.5016)  loss_n_100: 0.5600 (0.5441)  triple_100: 0.0000 (0.0019)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3346  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [800/845]  eta: 0:00:15  loss: 2.0644 (1.9827)  loss_n_40: 0.4669 (0.4691)  loss_n_60: 0.4893 (0.4657)  loss_n_80: 0.4848 (0.5016)  loss_n_100: 0.5674 (0.5440)  triple_100: 0.0000 (0.0023)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3342  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [810/845]  eta: 0:00:11  loss: 1.8221 (1.9810)  loss_n_40: 0.4316 (0.4689)  loss_n_60: 0.4213 (0.4653)  loss_n_80: 0.4659 (0.5011)  loss_n_100: 0.4762 (0.5433)  triple_100: 0.0000 (0.0023)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3340  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [820/845]  eta: 0:00:08  loss: 1.8221 (1.9812)  loss_n_40: 0.4316 (0.4689)  loss_n_60: 0.4213 (0.4655)  loss_n_80: 0.4688 (0.5012)  loss_n_100: 0.4660 (0.5434)  triple_100: 0.0000 (0.0023)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3344  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [830/845]  eta: 0:00:05  loss: 1.6989 (1.9810)  loss_n_40: 0.4163 (0.4686)  loss_n_60: 0.4103 (0.4654)  loss_n_80: 0.4461 (0.5012)  loss_n_100: 0.4678 (0.5435)  triple_100: 0.0000 (0.0022)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3347  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [840/845]  eta: 0:00:01  loss: 1.8039 (1.9805)  loss_n_40: 0.4307 (0.4687)  loss_n_60: 0.4265 (0.4653)  loss_n_80: 0.4593 (0.5012)  loss_n_100: 0.4678 (0.5430)  triple_100: 0.0000 (0.0022)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18]  [844/845]  eta: 0:00:00  loss: 1.6848 (1.9795)  loss_n_40: 0.4307 (0.4684)  loss_n_60: 0.3989 (0.4651)  loss_n_80: 0.4461 (0.5010)  loss_n_100: 0.4576 (0.5428)  triple_100: 0.0000 (0.0022)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 0.3343  data: 0.0001  max mem: 46473\n",
      "Valid: [epoch:18] Total time: 0:04:43 (0.3350 s / it)\n",
      "Averaged stats: loss: 1.6848 (1.9795)  loss_n_40: 0.4307 (0.4684)  loss_n_60: 0.3989 (0.4651)  loss_n_80: 0.4461 (0.5010)  loss_n_100: 0.4576 (0.5428)  triple_100: 0.0000 (0.0022)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/epoch_18_input_n_20.png\n",
      "loss_n_100 of the network on the 845 valid images: 0.543%\n",
      "Min loss_n_100: 0.325\n",
      "Best Epoch: 17.000\n",
      "Train: [epoch:19]  [   0/1724]  eta: 2:00:04  lr: 0.000200  loss: 2.1523 (2.1523)  loss_n_40: 0.5353 (0.5353)  loss_n_60: 0.5280 (0.5280)  loss_n_80: 0.5382 (0.5382)  loss_n_100: 0.5507 (0.5507)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 4.1787  data: 0.4262  max mem: 46473\n",
      "Train: [epoch:19]  [  10/1724]  eta: 1:52:37  lr: 0.000200  loss: 1.8581 (1.9348)  loss_n_40: 0.4952 (0.4799)  loss_n_60: 0.4377 (0.4541)  loss_n_80: 0.4714 (0.4816)  loss_n_100: 0.5122 (0.5193)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9425  data: 0.0389  max mem: 46473\n",
      "Train: [epoch:19]  [  20/1724]  eta: 1:51:36  lr: 0.000200  loss: 1.8670 (1.9198)  loss_n_40: 0.4540 (0.4659)  loss_n_60: 0.4377 (0.4505)  loss_n_80: 0.4714 (0.4825)  loss_n_100: 0.5153 (0.5209)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9174  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [  30/1724]  eta: 1:50:50  lr: 0.000200  loss: 1.7503 (1.8217)  loss_n_40: 0.4311 (0.4469)  loss_n_60: 0.4194 (0.4297)  loss_n_80: 0.4251 (0.4563)  loss_n_100: 0.4266 (0.4889)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9164  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [  40/1724]  eta: 1:50:08  lr: 0.000200  loss: 1.5245 (1.7375)  loss_n_40: 0.3867 (0.4307)  loss_n_60: 0.3664 (0.4102)  loss_n_80: 0.3796 (0.4333)  loss_n_100: 0.4022 (0.4633)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0000)  time: 3.9183  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [  50/1724]  eta: 1:49:26  lr: 0.000200  loss: 1.5440 (1.7192)  loss_n_40: 0.3867 (0.4223)  loss_n_60: 0.3664 (0.4040)  loss_n_80: 0.3833 (0.4287)  loss_n_100: 0.4012 (0.4585)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0057)  time: 3.9185  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [  60/1724]  eta: 1:48:46  lr: 0.000200  loss: 1.5182 (1.6768)  loss_n_40: 0.3569 (0.4104)  loss_n_60: 0.3482 (0.3933)  loss_n_80: 0.3923 (0.4184)  loss_n_100: 0.4175 (0.4500)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0047)  time: 3.9186  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [  70/1724]  eta: 1:48:06  lr: 0.000200  loss: 1.4567 (1.6477)  loss_n_40: 0.3569 (0.4053)  loss_n_60: 0.3447 (0.3866)  loss_n_80: 0.3625 (0.4107)  loss_n_100: 0.3867 (0.4410)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0041)  time: 3.9180  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [  80/1724]  eta: 1:47:26  lr: 0.000200  loss: 1.3901 (1.6074)  loss_n_40: 0.3510 (0.4007)  loss_n_60: 0.3252 (0.3769)  loss_n_80: 0.3421 (0.3987)  loss_n_100: 0.3650 (0.4275)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0036)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [  90/1724]  eta: 1:46:46  lr: 0.000200  loss: 1.2620 (1.5773)  loss_n_40: 0.3379 (0.3946)  loss_n_60: 0.3030 (0.3702)  loss_n_80: 0.3083 (0.3909)  loss_n_100: 0.3270 (0.4185)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0032)  time: 3.9182  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:19]  [ 100/1724]  eta: 1:46:07  lr: 0.000200  loss: 1.3591 (1.5989)  loss_n_40: 0.3379 (0.3925)  loss_n_60: 0.3046 (0.3689)  loss_n_80: 0.3284 (0.3914)  loss_n_100: 0.3700 (0.4197)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0263)  time: 3.9182  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 110/1724]  eta: 1:45:27  lr: 0.000200  loss: 1.5404 (1.5960)  loss_n_40: 0.3476 (0.3901)  loss_n_60: 0.3450 (0.3683)  loss_n_80: 0.4060 (0.3923)  loss_n_100: 0.4513 (0.4214)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0240)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 120/1724]  eta: 1:44:47  lr: 0.000200  loss: 1.5877 (1.6030)  loss_n_40: 0.3770 (0.3911)  loss_n_60: 0.3639 (0.3702)  loss_n_80: 0.4060 (0.3951)  loss_n_100: 0.4458 (0.4247)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0220)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 130/1724]  eta: 1:44:08  lr: 0.000200  loss: 1.4025 (1.5903)  loss_n_40: 0.3588 (0.3874)  loss_n_60: 0.3268 (0.3673)  loss_n_80: 0.3596 (0.3925)  loss_n_100: 0.3838 (0.4228)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0000)  triple_40: 0.0000 (0.0203)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 140/1724]  eta: 1:43:28  lr: 0.000200  loss: 1.3323 (1.5781)  loss_n_40: 0.3180 (0.3833)  loss_n_60: 0.3150 (0.3642)  loss_n_80: 0.3300 (0.3894)  loss_n_100: 0.3642 (0.4196)  triple_100: 0.0000 (0.0000)  triple_80: 0.0000 (0.0000)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0189)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 150/1724]  eta: 1:42:49  lr: 0.000200  loss: 1.3196 (1.5720)  loss_n_40: 0.3180 (0.3789)  loss_n_60: 0.2943 (0.3597)  loss_n_80: 0.3200 (0.3850)  loss_n_100: 0.3534 (0.4156)  triple_100: 0.0000 (0.0068)  triple_80: 0.0000 (0.0026)  triple_60: 0.0000 (0.0034)  triple_40: 0.0000 (0.0200)  time: 3.9179  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 160/1724]  eta: 1:42:10  lr: 0.000200  loss: 1.5002 (1.5790)  loss_n_40: 0.3466 (0.3768)  loss_n_60: 0.3356 (0.3605)  loss_n_80: 0.3779 (0.3882)  loss_n_100: 0.4279 (0.4211)  triple_100: 0.0000 (0.0079)  triple_80: 0.0000 (0.0025)  triple_60: 0.0000 (0.0032)  triple_40: 0.0000 (0.0188)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 170/1724]  eta: 1:41:30  lr: 0.000200  loss: 1.6550 (1.5865)  loss_n_40: 0.3537 (0.3764)  loss_n_60: 0.3727 (0.3624)  loss_n_80: 0.4305 (0.3914)  loss_n_100: 0.4905 (0.4258)  triple_100: 0.0000 (0.0075)  triple_80: 0.0000 (0.0023)  triple_60: 0.0000 (0.0030)  triple_40: 0.0000 (0.0177)  time: 3.9179  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 180/1724]  eta: 1:40:51  lr: 0.000200  loss: 1.5596 (1.5810)  loss_n_40: 0.3456 (0.3749)  loss_n_60: 0.3616 (0.3617)  loss_n_80: 0.4093 (0.3904)  loss_n_100: 0.4548 (0.4252)  triple_100: 0.0000 (0.0071)  triple_80: 0.0000 (0.0022)  triple_60: 0.0000 (0.0028)  triple_40: 0.0000 (0.0167)  time: 3.9170  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 190/1724]  eta: 1:40:12  lr: 0.000200  loss: 1.4470 (1.5746)  loss_n_40: 0.3421 (0.3745)  loss_n_60: 0.3480 (0.3611)  loss_n_80: 0.3552 (0.3885)  loss_n_100: 0.4024 (0.4232)  triple_100: 0.0000 (0.0067)  triple_80: 0.0000 (0.0021)  triple_60: 0.0000 (0.0027)  triple_40: 0.0000 (0.0158)  time: 3.9174  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 200/1724]  eta: 1:39:32  lr: 0.000200  loss: 1.4579 (1.5723)  loss_n_40: 0.3501 (0.3733)  loss_n_60: 0.3472 (0.3610)  loss_n_80: 0.3538 (0.3880)  loss_n_100: 0.3950 (0.4227)  triple_100: 0.0000 (0.0064)  triple_80: 0.0000 (0.0020)  triple_60: 0.0000 (0.0025)  triple_40: 0.0000 (0.0163)  time: 3.9173  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 210/1724]  eta: 1:38:53  lr: 0.000200  loss: 1.4166 (1.5610)  loss_n_40: 0.3277 (0.3712)  loss_n_60: 0.3268 (0.3587)  loss_n_80: 0.3520 (0.3854)  loss_n_100: 0.3807 (0.4198)  triple_100: 0.0000 (0.0060)  triple_80: 0.0000 (0.0019)  triple_60: 0.0000 (0.0024)  triple_40: 0.0000 (0.0156)  time: 3.9161  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 220/1724]  eta: 1:38:14  lr: 0.000200  loss: 1.2329 (1.5461)  loss_n_40: 0.3090 (0.3686)  loss_n_60: 0.2908 (0.3556)  loss_n_80: 0.2958 (0.3817)  loss_n_100: 0.3216 (0.4154)  triple_100: 0.0000 (0.0058)  triple_80: 0.0000 (0.0018)  triple_60: 0.0000 (0.0023)  triple_40: 0.0000 (0.0149)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 230/1724]  eta: 1:37:34  lr: 0.000200  loss: 1.1959 (1.5332)  loss_n_40: 0.3069 (0.3661)  loss_n_60: 0.2855 (0.3532)  loss_n_80: 0.2951 (0.3785)  loss_n_100: 0.3168 (0.4117)  triple_100: 0.0000 (0.0055)  triple_80: 0.0000 (0.0017)  triple_60: 0.0000 (0.0022)  triple_40: 0.0000 (0.0142)  time: 3.9177  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 240/1724]  eta: 1:36:55  lr: 0.000200  loss: 1.2654 (1.5307)  loss_n_40: 0.3092 (0.3641)  loss_n_60: 0.3026 (0.3514)  loss_n_80: 0.3080 (0.3769)  loss_n_100: 0.3313 (0.4105)  triple_100: 0.0000 (0.0054)  triple_80: 0.0000 (0.0020)  triple_60: 0.0000 (0.0054)  triple_40: 0.0000 (0.0150)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 250/1724]  eta: 1:36:16  lr: 0.000200  loss: 1.4888 (1.5315)  loss_n_40: 0.3354 (0.3642)  loss_n_60: 0.3297 (0.3516)  loss_n_80: 0.3741 (0.3775)  loss_n_100: 0.4068 (0.4115)  triple_100: 0.0000 (0.0052)  triple_80: 0.0000 (0.0019)  triple_60: 0.0000 (0.0052)  triple_40: 0.0000 (0.0144)  time: 3.9177  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 260/1724]  eta: 1:35:37  lr: 0.000200  loss: 1.4223 (1.5257)  loss_n_40: 0.3482 (0.3634)  loss_n_60: 0.3161 (0.3502)  loss_n_80: 0.3589 (0.3762)  loss_n_100: 0.4063 (0.4103)  triple_100: 0.0000 (0.0050)  triple_80: 0.0000 (0.0019)  triple_60: 0.0000 (0.0050)  triple_40: 0.0000 (0.0138)  time: 3.9182  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 270/1724]  eta: 1:34:57  lr: 0.000200  loss: 1.3105 (1.5157)  loss_n_40: 0.3289 (0.3616)  loss_n_60: 0.3018 (0.3481)  loss_n_80: 0.3209 (0.3738)  loss_n_100: 0.3508 (0.4076)  triple_100: 0.0000 (0.0048)  triple_80: 0.0000 (0.0018)  triple_60: 0.0000 (0.0048)  triple_40: 0.0000 (0.0133)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 280/1724]  eta: 1:34:18  lr: 0.000200  loss: 1.1829 (1.5055)  loss_n_40: 0.3060 (0.3594)  loss_n_60: 0.2810 (0.3462)  loss_n_80: 0.2924 (0.3713)  loss_n_100: 0.3223 (0.4047)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0017)  triple_60: 0.0000 (0.0046)  triple_40: 0.0000 (0.0129)  time: 3.9172  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 290/1724]  eta: 1:33:39  lr: 0.000200  loss: 1.1599 (1.5069)  loss_n_40: 0.2921 (0.3580)  loss_n_60: 0.2759 (0.3449)  loss_n_80: 0.2898 (0.3697)  loss_n_100: 0.3081 (0.4026)  triple_100: 0.0000 (0.0047)  triple_80: 0.0000 (0.0059)  triple_60: 0.0000 (0.0056)  triple_40: 0.0000 (0.0154)  time: 3.9166  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 300/1724]  eta: 1:32:59  lr: 0.000200  loss: 1.3546 (1.5070)  loss_n_40: 0.3182 (0.3571)  loss_n_60: 0.3161 (0.3452)  loss_n_80: 0.3610 (0.3705)  loss_n_100: 0.3983 (0.4036)  triple_100: 0.0000 (0.0046)  triple_80: 0.0000 (0.0057)  triple_60: 0.0000 (0.0054)  triple_40: 0.0000 (0.0149)  time: 3.9169  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 310/1724]  eta: 1:32:20  lr: 0.000200  loss: 1.3921 (1.5007)  loss_n_40: 0.3027 (0.3551)  loss_n_60: 0.3223 (0.3442)  loss_n_80: 0.3610 (0.3695)  loss_n_100: 0.3852 (0.4022)  triple_100: 0.0000 (0.0044)  triple_80: 0.0000 (0.0055)  triple_60: 0.0000 (0.0053)  triple_40: 0.0000 (0.0144)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 320/1724]  eta: 1:31:41  lr: 0.000200  loss: 1.2692 (1.4923)  loss_n_40: 0.2959 (0.3534)  loss_n_60: 0.3048 (0.3428)  loss_n_80: 0.3267 (0.3676)  loss_n_100: 0.3387 (0.3999)  triple_100: 0.0000 (0.0043)  triple_80: 0.0000 (0.0053)  triple_60: 0.0000 (0.0051)  triple_40: 0.0000 (0.0140)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 330/1724]  eta: 1:31:02  lr: 0.000200  loss: 1.1710 (1.4828)  loss_n_40: 0.2868 (0.3515)  loss_n_60: 0.2917 (0.3411)  loss_n_80: 0.2952 (0.3654)  loss_n_100: 0.3139 (0.3970)  triple_100: 0.0000 (0.0042)  triple_80: 0.0000 (0.0052)  triple_60: 0.0000 (0.0050)  triple_40: 0.0000 (0.0135)  time: 3.9183  data: 0.0002  max mem: 46473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:19]  [ 340/1724]  eta: 1:30:23  lr: 0.000200  loss: 1.1389 (1.4749)  loss_n_40: 0.2894 (0.3503)  loss_n_60: 0.2776 (0.3397)  loss_n_80: 0.2798 (0.3634)  loss_n_100: 0.2862 (0.3944)  triple_100: 0.0000 (0.0040)  triple_80: 0.0000 (0.0050)  triple_60: 0.0000 (0.0048)  triple_40: 0.0000 (0.0131)  time: 3.9178  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 350/1724]  eta: 1:29:43  lr: 0.000200  loss: 1.1602 (1.4669)  loss_n_40: 0.3031 (0.3492)  loss_n_60: 0.2776 (0.3384)  loss_n_80: 0.2874 (0.3614)  loss_n_100: 0.3044 (0.3917)  triple_100: 0.0000 (0.0039)  triple_80: 0.0000 (0.0049)  triple_60: 0.0000 (0.0047)  triple_40: 0.0000 (0.0128)  time: 3.9165  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 360/1724]  eta: 1:29:04  lr: 0.000200  loss: 1.1602 (1.4581)  loss_n_40: 0.3093 (0.3477)  loss_n_60: 0.2728 (0.3367)  loss_n_80: 0.2874 (0.3594)  loss_n_100: 0.2963 (0.3889)  triple_100: 0.0000 (0.0038)  triple_80: 0.0000 (0.0047)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0124)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 370/1724]  eta: 1:28:25  lr: 0.000200  loss: 1.2471 (1.4594)  loss_n_40: 0.3148 (0.3471)  loss_n_60: 0.3000 (0.3366)  loss_n_80: 0.3068 (0.3595)  loss_n_100: 0.3325 (0.3891)  triple_100: 0.0000 (0.0037)  triple_80: 0.0000 (0.0062)  triple_60: 0.0000 (0.0051)  triple_40: 0.0000 (0.0121)  time: 3.9185  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 380/1724]  eta: 1:27:46  lr: 0.000200  loss: 1.3837 (1.4564)  loss_n_40: 0.3068 (0.3462)  loss_n_60: 0.3222 (0.3360)  loss_n_80: 0.3516 (0.3591)  loss_n_100: 0.3898 (0.3888)  triple_100: 0.0000 (0.0036)  triple_80: 0.0000 (0.0060)  triple_60: 0.0000 (0.0050)  triple_40: 0.0000 (0.0118)  time: 3.9173  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 390/1724]  eta: 1:27:07  lr: 0.000200  loss: 1.1778 (1.4477)  loss_n_40: 0.2875 (0.3443)  loss_n_60: 0.2865 (0.3342)  loss_n_80: 0.3015 (0.3571)  loss_n_100: 0.3376 (0.3864)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0059)  triple_60: 0.0000 (0.0049)  triple_40: 0.0000 (0.0115)  time: 3.9172  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 400/1724]  eta: 1:26:27  lr: 0.000200  loss: 1.0944 (1.4436)  loss_n_40: 0.2707 (0.3429)  loss_n_60: 0.2597 (0.3329)  loss_n_80: 0.2774 (0.3557)  loss_n_100: 0.2925 (0.3848)  triple_100: 0.0000 (0.0036)  triple_80: 0.0000 (0.0063)  triple_60: 0.0000 (0.0057)  triple_40: 0.0000 (0.0117)  time: 3.9189  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 410/1724]  eta: 1:25:48  lr: 0.000200  loss: 1.3477 (1.4432)  loss_n_40: 0.3057 (0.3425)  loss_n_60: 0.3021 (0.3328)  loss_n_80: 0.3461 (0.3560)  loss_n_100: 0.3679 (0.3853)  triple_100: 0.0000 (0.0035)  triple_80: 0.0000 (0.0061)  triple_60: 0.0000 (0.0056)  triple_40: 0.0000 (0.0114)  time: 3.9186  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 420/1724]  eta: 1:25:09  lr: 0.000200  loss: 1.4101 (1.4431)  loss_n_40: 0.3263 (0.3426)  loss_n_60: 0.3203 (0.3326)  loss_n_80: 0.3579 (0.3563)  loss_n_100: 0.4066 (0.3856)  triple_100: 0.0000 (0.0034)  triple_80: 0.0000 (0.0060)  triple_60: 0.0000 (0.0054)  triple_40: 0.0000 (0.0111)  time: 3.9178  data: 0.0002  max mem: 46473\n",
      "Train: [epoch:19]  [ 430/1724]  eta: 1:24:30  lr: 0.000200  loss: 1.4041 (1.4410)  loss_n_40: 0.3476 (0.3424)  loss_n_60: 0.3176 (0.3322)  loss_n_80: 0.3551 (0.3560)  loss_n_100: 0.3699 (0.3850)  triple_100: 0.0000 (0.0034)  triple_80: 0.0000 (0.0059)  triple_60: 0.0000 (0.0053)  triple_40: 0.0000 (0.0108)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 440/1724]  eta: 1:23:51  lr: 0.000200  loss: 1.2962 (1.4376)  loss_n_40: 0.3248 (0.3422)  loss_n_60: 0.2972 (0.3316)  loss_n_80: 0.3293 (0.3552)  loss_n_100: 0.3424 (0.3839)  triple_100: 0.0000 (0.0033)  triple_80: 0.0000 (0.0057)  triple_60: 0.0000 (0.0052)  triple_40: 0.0000 (0.0106)  time: 3.9178  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 450/1724]  eta: 1:23:11  lr: 0.000200  loss: 1.2451 (1.4322)  loss_n_40: 0.3144 (0.3415)  loss_n_60: 0.2936 (0.3304)  loss_n_80: 0.3165 (0.3539)  loss_n_100: 0.3232 (0.3821)  triple_100: 0.0000 (0.0032)  triple_80: 0.0000 (0.0056)  triple_60: 0.0000 (0.0051)  triple_40: 0.0000 (0.0104)  time: 3.9171  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 460/1724]  eta: 1:22:32  lr: 0.000200  loss: 1.1572 (1.4281)  loss_n_40: 0.2922 (0.3403)  loss_n_60: 0.2699 (0.3292)  loss_n_80: 0.2779 (0.3525)  loss_n_100: 0.2815 (0.3804)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0059)  triple_60: 0.0000 (0.0050)  triple_40: 0.0000 (0.0117)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 470/1724]  eta: 1:21:53  lr: 0.000200  loss: 1.1447 (1.4220)  loss_n_40: 0.2726 (0.3388)  loss_n_60: 0.2683 (0.3280)  loss_n_80: 0.2724 (0.3512)  loss_n_100: 0.2869 (0.3788)  triple_100: 0.0000 (0.0031)  triple_80: 0.0000 (0.0058)  triple_60: 0.0000 (0.0049)  triple_40: 0.0000 (0.0114)  time: 3.9187  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 480/1724]  eta: 1:21:14  lr: 0.000200  loss: 1.0717 (1.4147)  loss_n_40: 0.2660 (0.3374)  loss_n_60: 0.2567 (0.3266)  loss_n_80: 0.2638 (0.3494)  loss_n_100: 0.2758 (0.3766)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0057)  triple_60: 0.0000 (0.0048)  triple_40: 0.0000 (0.0112)  time: 3.9181  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 490/1724]  eta: 1:20:35  lr: 0.000200  loss: 1.0424 (1.4098)  loss_n_40: 0.2660 (0.3365)  loss_n_60: 0.2506 (0.3257)  loss_n_80: 0.2568 (0.3483)  loss_n_100: 0.2745 (0.3752)  triple_100: 0.0000 (0.0030)  triple_80: 0.0000 (0.0056)  triple_60: 0.0000 (0.0047)  triple_40: 0.0000 (0.0110)  time: 3.9176  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 500/1724]  eta: 1:19:55  lr: 0.000200  loss: 1.0147 (1.4021)  loss_n_40: 0.2494 (0.3349)  loss_n_60: 0.2465 (0.3242)  loss_n_80: 0.2543 (0.3464)  loss_n_100: 0.2650 (0.3729)  triple_100: 0.0000 (0.0029)  triple_80: 0.0000 (0.0055)  triple_60: 0.0000 (0.0046)  triple_40: 0.0000 (0.0107)  time: 3.9179  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 510/1724]  eta: 1:19:16  lr: 0.000200  loss: 0.9943 (1.3961)  loss_n_40: 0.2452 (0.3339)  loss_n_60: 0.2402 (0.3230)  loss_n_80: 0.2472 (0.3450)  loss_n_100: 0.2589 (0.3711)  triple_100: 0.0000 (0.0028)  triple_80: 0.0000 (0.0054)  triple_60: 0.0000 (0.0045)  triple_40: 0.0000 (0.0105)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 520/1724]  eta: 1:18:37  lr: 0.000200  loss: 1.0382 (1.3905)  loss_n_40: 0.2643 (0.3328)  loss_n_60: 0.2545 (0.3219)  loss_n_80: 0.2600 (0.3437)  loss_n_100: 0.2612 (0.3693)  triple_100: 0.0000 (0.0028)  triple_80: 0.0000 (0.0053)  triple_60: 0.0000 (0.0044)  triple_40: 0.0000 (0.0103)  time: 3.9175  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 530/1724]  eta: 1:17:58  lr: 0.000200  loss: 1.0382 (1.3843)  loss_n_40: 0.2702 (0.3319)  loss_n_60: 0.2545 (0.3207)  loss_n_80: 0.2578 (0.3420)  loss_n_100: 0.2640 (0.3673)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0052)  triple_60: 0.0000 (0.0043)  triple_40: 0.0000 (0.0101)  time: 3.9188  data: 0.0001  max mem: 46473\n",
      "Train: [epoch:19]  [ 540/1724]  eta: 1:17:19  lr: 0.000200  loss: 1.0225 (1.3792)  loss_n_40: 0.2631 (0.3307)  loss_n_60: 0.2498 (0.3195)  loss_n_80: 0.2525 (0.3406)  loss_n_100: 0.2640 (0.3656)  triple_100: 0.0000 (0.0027)  triple_80: 0.0000 (0.0051)  triple_60: 0.0000 (0.0047)  triple_40: 0.0000 (0.0103)  time: 3.9203  data: 0.0001  max mem: 46473\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--batch-size 4 \\\n",
    "--epochs 1000 \\\n",
    "--min-lr 5e-6 \\\n",
    "--lr 2e-4 \\\n",
    "--data-set 'Sinogram' \\\n",
    "--model-name 'Seqeunce_UNet_Hidden_bottle' \\\n",
    "--criterion 'Perceptual_L1_Triple_Loss' \\\n",
    "--criterion_mode '1:1' \\\n",
    "--output_dir '/workspace/sunggu/4.Dose_img2img/model/Seqeunce_UNet_Hidden_bottle' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/Seqeunce_UNet_Hidden_bottle/low2high/' \\\n",
    "--validate-every 5 \\\n",
    "--num_workers 8 \\\n",
    "--multi-gpu-mode 'DataParallel' \\\n",
    "--teacher_forcing \"False\"\n",
    "\n",
    "# --resume '/workspace/sunggu/4.Dose_img2img/model/[Sequence_All_Hidden_Unet]Dose Unet/epoch_6_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "def list_sort_nicely(l):   \n",
    "    def tryint(s):        \n",
    "        try:            \n",
    "            return int(s)        \n",
    "        except:            \n",
    "            return s\n",
    "        \n",
    "    def alphanum_key(s):\n",
    "        return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "    l.sort(key=alphanum_key)    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_20_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_NPY/Valid/*/20/*/*/*.npy'))\n",
    "n_40_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_NPY/Valid/*/40/*/*/*.npy'))\n",
    "n_60_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_NPY/Valid/*/60/*/*/*.npy'))\n",
    "n_80_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_NPY/Valid/*/80/*/*/*.npy'))\n",
    "n_100_imgs  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_NPY/Valid/*/X/*/*/*.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_windowing_V2(x):\n",
    "    x = np.clip(x, a_min=0.250, a_max=0.270)\n",
    "    x -= x.min()\n",
    "    x /= x.max()  \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n20  = np.load(n_20_imgs[20])\n",
    "n40  = np.load(n_40_imgs[20])\n",
    "n60  = np.load(n_60_imgs[20])\n",
    "n80  = np.load(n_80_imgs[20])\n",
    "n100 = np.load(n_100_imgs[20])\n",
    "\n",
    "\n",
    "n20   = visual_windowing_V2(n20) \n",
    "n40   = visual_windowing_V2(n40)  \n",
    "n60   = visual_windowing_V2(n60) \n",
    "n80   = visual_windowing_V2(n80)  \n",
    "n100  = visual_windowing_V2(n100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x432 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(24,6))\n",
    "\n",
    "plt.subplot(141)\n",
    "a = np.abs(n100-n80)\n",
    "a[a==0] = 1e-100\n",
    "plt.title('n100 - n80')\n",
    "plt.imshow(np.log(a), 'gray')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.clim(0, -6);\n",
    "\n",
    "plt.subplot(142)\n",
    "a = np.abs(n100-n60)\n",
    "a[a==0] = 1e-100\n",
    "plt.title('n100 - n60')\n",
    "plt.imshow(np.log(a), 'gray')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.clim(0, -6);\n",
    "\n",
    "\n",
    "plt.subplot(143)\n",
    "a = np.abs(n100-n40)\n",
    "a[a==0] = 1e-100\n",
    "plt.title('n100 - n40')\n",
    "plt.imshow(np.log(a), 'gray')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.clim(0, -6);\n",
    "\n",
    "\n",
    "plt.subplot(144)\n",
    "a = np.abs(n100-n20)\n",
    "a[a==0] = 1e-100\n",
    "\n",
    "plt.title('n100 - n20')\n",
    "plt.imshow(np.log(a), 'gray')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.clim(0, -6);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x432 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(24,6))\n",
    "\n",
    "plt.subplot(141)\n",
    "a = np.abs(n100-n80)\n",
    "a[a==0] = 1e-100\n",
    "plt.title('n100 - n80')\n",
    "plt.imshow(np.log(a), 'gray')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.clim(0, -6);\n",
    "\n",
    "plt.subplot(142)\n",
    "a = np.abs(n80-n60)\n",
    "a[a==0] = 1e-100\n",
    "plt.title('n80 - n60')\n",
    "plt.imshow(np.log(a), 'gray')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.clim(0, -6);\n",
    "\n",
    "\n",
    "plt.subplot(143)\n",
    "a = np.abs(n60-n40)\n",
    "a[a==0] = 1e-100\n",
    "plt.title('n60 - n40')\n",
    "plt.imshow(np.log(a), 'gray')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.clim(0, -6);\n",
    "\n",
    "\n",
    "plt.subplot(144)\n",
    "a = np.abs(n40-n20)\n",
    "a[a==0] = 1e-100\n",
    "\n",
    "plt.title('n40 - n20')\n",
    "plt.imshow(np.log(a), 'gray')\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.clim(0, -6);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7bf824f048>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAADJBklEQVR4nOy9d3yc9ZU1fp7pvXe1UbUs94ZxwRjTTE8BQtgAKQuEzZK22V+y6btv3rybZHeTJckmmywJyZKQUEPvYBtwwTauki2rS6Myvffy/P6Q783IkowNODGg+/nwwR6PpJnR89zvveeec64giiLmYi7mYi6qQ/LXfgFzMRdzcfbFXGKYi7mYi2kxlxjmYi7mYlrMJYa5mIu5mBZziWEu5mIupsVcYpiLuZiLaXFGEoMgCJsFQegWBKFXEISvnImfMRdzMRdnLoR3mscgCIIUwDEAFwPwAdgN4KOiKHa9oz9oLuZiLs5YnImK4RwAvaIo9ouiWADwBwDXnIGfMxdzMRdnKGRn4HvWABip+rsPwOqTfYEgCHP0y7mYizMfIVEU7afyxDORGE4pBEG4DcBtf62fPxdz8T6MoVN94plIDKMA6qr+Xnv8sSkhiuIvAPwCmKsY5mIuzrY4ExjDbgCtgiA0CoKgAHADgMfOwM+Zi7mYizMU73jFIIpiSRCEvwfwLAApgF+Jotj5Tv+cuZiLuThz8Y6PK9/Si5hrJeZiLv4SsVcUxZWn8sQ55uNczMVcTIu5xDAXczEX02IuMczFXMzFtJhLDHMxF3MxLeYSw1zMxVxMi7nEMBdzMRfTYi4xzMVczMW0mEsMczEXczEt/moiqrl4d4ZMJoPRaIRKpUKxWEQqlUI2m8XZQJSbi3cu5hLDXLxpyGQytLS04IILLsD555+Pjo4O2Gw2hMNhDA4Owufz4U9/+hNeeeUVZDKZv/bLnYt3IOYo0XMxa8hkMjQ1NeHiiy/GOeecA0EQUCqVoFQqUV9fj0wmg0qlgnnz5kEul2PLli344Q9/iP3796NSqfy1X/5cTI9TpkTPJYazOKRSKWQyGeRyOQDAYDBApVJBr9dDJpMhlUoBALRaLcxmM+LxOAYHB5HNZpHNZt/yzSkIAhwOB5YsWQK1Wo1gMIixsTEkEgmUy2Xo9Xp4vV44nU7o9Xq4XC6o1Wq0trbC6XTi3nvvxb333otisfiOfRZz8Y7EKSeGuVbiLAulUgmj0Qi1Wg2z2QyVSoX29nYAgF6vh0qlgkQiQSwWQ39/P6RSKaxWK9xuN8rlMjo6OqBWqyEIAiYmJnD48GEEAgEkk8lTxgHsdjuWLVuGiYkJdHV1oVAo8L+pVCrYbDaMjY1hcHAQKpUKOp0OgUAAEokEixYtwqWXXgpRFPHggw9y8pqLd1fMVQxnQajVajidTq4IFAoFcrkc9Ho9MpkM8vk8stks8vk88vk8crkcSqUS8vk8JBIJZDIZDAYDVxJLly6F1+tFsVhEc3MzjEYj+vr6cN9996Gzs3PWBCEIArRaLSQSCeRyOURRRCaTQS6XAwDI5XKo1WqYTCZEo1Ekk0nIZDLodDpUKhVOPnV1dbjhhhsgCAJ+/vOfI5FI/CU/zrmYPeZaiXdD6PV6rFmzBh0dHQiHw4jH4xgdHUUwGEQwGESpVEK5XD7tlkCj0cBisUChUGDt2rW44IIL0NTUhFKphN///vfYvXs3AoEAMpkMisUiCoUCJwtBEAAA8+bNw6JFi9DX14d9+/bxv0skEmi1WgiCMOWGFwRhSsIxmUy4+uqrYTAY8Jvf/AbJZPLtflxz8fZjLjGczaFQKLBo0SJs3rwZbW1t2LZtG1544QVEIhGkUql3dPSn0+mwZMkSnHfeediwYQMcDgfC4TBGR0exc+dOHDhwAJ2dnVNKfqlUigsvvBDNzc04dOgQ9uzZg1wuB7lcjqamJixZsgQajQY7d+6Ez+dDoVCY0m5Uv8+NGzfC4XDg4YcfftOJhSAIkEqlXP1UKhWk02lOXuVyGVqtFi6XC2vWrEFDQwOMRiMqlQp8Ph+6u7vR1dWFkZGROfBz5pjDGM7W0Ol0OO+887By5Ur4/X68+uqreP3115HNZk/6dXSSU5xq8kilUti+fTsGBgZQKpVw0UUXQavVwuv1wu/3o7u7G/l8fsrXSKVS5HI5ZLNZqNVquFwuBAIBlEolJJNJBINB1NXVoba2FgqFArFYDD6fb9rNWCgU8NJLL2HTpk24+uqr8ac//Ynbkur3ZTAYsHTpUmzcuBHLli2DxWLhiuTAgQM4cOAAMpkMSqUSXC4XzjvvPKxatYpxFaVSCZVKBUEQ4Pf78fjjj+Puu+9GZ2fntPc2F6cWc4nhLxTUt9OEYdu2bdi1axfy+fysN7lMJoPZbIZarYbD4YBCoUClUuETMpFIMN5wshBFEWNjY/j1r3+NkZERXHfddViyZAkEQYDNZoNGo0FXVxcEQYDJZIJGo4HJZIJSqYRarYZSqUS5XEahUMDY2Bjy+Tw0Gg18Ph96enpQqVRmfQ+lUglbt27Ftddei5tvvhkPP/wwQqEQDAYD1q1bh7Vr1+Kiiy5CY2MjJBIJ9Ho9UqkUdu/ejSNHjmDfvn3YvXs3bDYb2tvbUVtbC5PJhFwuxzhHuVyGyWSC2WyGQqHAxz72MVx99dXYsmULvve9750UV5mLmWOulfgLhSAIUCgUkEqlfJOdDATU6XRYsWIFzj//fEgkElgsFpTLZeRyOWg0GuTzeQSDQfT09GD37t3w+/2nNB6USqU499xzceedd6K9vR16vR59fX04evQoyuUyYrEYQqEQMpkMtFotxsfH0dvby4njhhtuwJ133oklS5ZgeHgYP/3pT/Gzn/1sWiVwYphMJtxxxx1oaWnBwMAAWlpasGnTJthsNgwODqK3t5ef+8ILL2Dr1q0YHx9HKpWCUqnEvHnzcN5556G+vh5erxcOhwPlchlDQ0MwmUxwuVxQKpUIBoPQarWw2+1wu93o6+vDt771LTz22GNv+hrfBzGHMZwNQVUCJQG5XI5KpYJyuTzr1+h0OqxatQqLFi1Ce3s7Ojo6EI/HkUqlkE6nEQqFoFQqYbPZuA8PBoPYv38/tmzZgv7+/jdNEHK5HBdeeCFuv/12LFy4EIlEAv39/UgkEhgZGYHP58OhQ4cQDoeRSCQQi8VQLpfx6U9/Gj/4wQ+gVqv5e5XLZfz+97/HV7/6Vfh8vhk/A4VCAb1ej8svvxw33HAD3G43CoUCEokExsfHsWXLFoyMjMBsNmNgYACHDh1iPMNsNsPlcvHnIooi4vE4JBIJBgcHceTIEahUKsyfPx/z5s1DsVhEe3s75HI5bDYbampqEIlEcPfdd+Ouu+5CPB5/67/Qd3/MYQx/7ZBKpZBIJFN63De7YWtqanD11VdjzZo1cLvdMBgMyOVy8Pv98Pv9KJVK8Pv9KJfLcDgcsFqt8Hq9WLBgATweD5YuXYpdu3bhpZdewujo6KwJqFgsYuvWrWhsbITBYIBMJmN8QC6XY2JiAvv37+eWYeXKlbjsssvw2c9+dkpSoPf5sY99DEuXLsWXv/xlPPfcc1N+rt1uR0tLCzo6OrBu3TrI5XL09/cjHA7jxRdfxLZt2xAIBCCXyyGVSpFOpyGVSnH++edj1apV3N5QG3bw4EHs378fUqkUoVAI/f39kEgkiEajOHjwIADgoosuwoIFC3jcarFYcOuttyKfz+OXv/wlotHoW/qdvp9iLjGcgZDL5RAEYUakfqaQSCRwuVzYtGkTrr/+ekgkEgSDQXR1daGnpwfpdBrlcpnReUEQkMvlkEwmMTIywiSjefPm4YYbbsCCBQvw3HPPYceOHbMSjLLZLB544AFIpVKcd955/Hrp+0okElx88cX4yle+gnXr1kGpVM76+gVBwKJFi/Dwww/j2WefxU9+8hO8+uqrKJVKqKurg9frxcqVK+FwONDV1YXDhw9j+/bt6O7u5mRZjZN4PB7GEzQaDaRSKYLBIPbs2YO+vj6k02mUSiWEw2FIpVJotVqkUink83mk02ns2bMHtbW1kMvlyOfzPA0577zzoNfrcffddyMajaKxsRHBYJCT7lz8OeZaiXc4ZDIZJBLJKScFtVqNjo4OXHjhhViwYAEWLVqEffv24bnnnsPo6Cij8ZQYdDodyuUyg4LJZBKZTAYKhQLnnHMOli1bhtraWgSDQTz55JN48sknT/paDAYDn87RaJSTzPz583HxxRdDp9Od9meQy+Xw3HPP4T/+4z9QLBbR2tqKCy+8EH6/H/fddx/6+vpmLekNBgM2b96MCy+8EPPmzUO5XMbY2BiGh4eRSqUYBxkdHcXo6ChMJhNPJEwmEyQSCVQqFex2O6xWKxYsWACTyYRwOIxCoYB8Po9du3ZBrVbjAx/4ADQaDQ4dOoRHHnkEhw8fRl9f33uZyj3XSvw141STgtvtxqZNm7BgwQLWJTz33HN44403cPToUf4+dENQxSCTyZDNZvnfK5UKRkdHkUgk4PP5sHr1arS1teGKK66A3+/Hrl27Zm0rEokEnn76aYyPj+MTn/gELr74YjQ0NEChULzl969SqXD11VfjnHPOwV133YU9e/bg8OHDeO6553DgwIFZQVe5XI5ly5Zh7dq1WLRoEaLRKHp6enDo0CGUSiU0NzfDYDAwbgNMtl/5fB7lchlNTU2wWCzo6enB3r17USqVUKlUsHHjRmi1WgDAwMAAJBIJmpqaYDAY0Nrainnz5uGcc87B0aNH8fDDD+O+++573wOVc4nhHY7qklQul894+kgkEjgcDqxbtw7Lly9HXV0dLBYL3njjDdx///0AJm/2YrHIN7RUKoVSqYTVakW5XEY0GoUoilAoFBBFERKJBNlsFoODgyiXy8jn89iwYQM++tGPolAoYP/+/bOWy6VSCV6vFzfffPNbqhBmC5fLhW984xt48cUX8b3vfe+kSQEA5s+fj4suugjNzc2QSqV4+umnsXPnTsRiMQBAd3c3FAoFNBoNT0/C4TCPOYPBIFPH0+k0IpEINBoNNBoNvF4v4z42mw2ZTAbHjh3j349Op4Ner8fmzZshiiLuu+++9zUHYi4xnKEgsdNMiYHYiLW1tSiVSlAoFDh48CC2b98Ov98PvV4PnU6HXC7HvX0qlYJOp4MoitBoNIhEItxiCILA7UWxWERXVxcqlQosFguWLVuG6667DsViEQcPHpzxxlQqlbjtttve0aRAoVarccUVV6Curg7XXnvtlLFkddhsNnzsYx/DOeecg3K5jN7eXrz66qvo7u5m3kIul0OhUGBtRiqVQqVSgcPhQDKZxODgIGKxGOrq6pDL5RCPx9HZ2YlcLofLL78cixcv5qRQzZWora1FW1sb0uk0CoUCFi1ahLGxMWzZsuWUq7/3WsxZu70DIZFIIJH8+aNUqVTwer0znjgqlQoqlQoGgwEej4cR9T179mBoaAhyuRylUgnFYhFSqRRqtRoSiQRGoxEajYYTCQFrwCSuUZ1AQqEQhoaG8NJLL8Hn88HpdGL+/PmztgeLFi3C6tWrz8AnMxmCIGDJkiX41re+xQSv6lAqlVi3bh1aWlogl8sxODiIrVu3IhAIoFAooFKpsGuUVCpFpVKBRCLhqUMymUShUIBEIoFGo4FarUapVIJcLkcikUBXVxd27tyJsbExqFQqaLVa5PN5DA4Ooru7m0e1pVIJ2WwWsVgMFouFx57vx5irGN6B0Ol0U0RCer0e2Wx2Sl+v0+mwdOlSzJ8/H729vdDpdHA4HEin0+jq6kJvby8SiQQTmcrlMsxmM5+KMpmMT0yNRgNBEGC1WpnHQKpMShalUgmDg4M4evQoampqmEE5U7JauXIlDAYD/z2fz+Pll19GIBCAIAjwer1YuHAhqzero1KpQBAEpmxnMhmUy2XI5XKoVKopz928eTOcTucUvoMgCJg/fz7WrVsHu92ObDaL119/Hfv370ehUGALOfpehLXQ65TJZKyhqK2tRXd3N6LRKGKxGKRSKYOTIyMj2L9/P09YKpUKJiYmMDAwgP7+/imfTyqVwvj4OJvQjI6OIhaLva/Yk3OJ4W2GRqPh0wsA8/yHh4cBTKLsl112GW699VasWrUKwWAQP/7xjxGPxxGJRKBUKjE+Ps5lrCAIyGazUCgUPOGo/q9YLCKZTCKXy0EURdY0qFQq5HI5fk4oFIIgCDhy5AhkMhmKxeKsI8cNGzZM+ftzzz2Hj370o0in0wAmjWAsFgvuuOMO3HTTTXj55Zdxww03QC6X45lnnoFUKsWll16K4eFh3HjjjRgaGoLX68WHP/xh3HjjjXA4HPx9vF7vlMRgs9mwZs0aqNVqTExMwOfz4fDhwxgdHUWxWIRWq+XPmD5PAhXVajW0Wi1UKhXS6fSUJOVyuZDP56FSqWA0GhEKhbB7927U1dWhrq6Ok+jIyAhGRkag1WqxceNG6PV6RKNRHD16FMFgEBqNholSAwMD/Jm812MuMbyNkEgkUCqVDI4RsDU+Pg5RFLFu3Tr867/+K1avXs0lKd3g4XAYIyMjPG/XarXc+0qlUh5BxmIxlEol2O12CIKAZDLJLUd1O0HAYqVSYaKQRCJBIpFAOp1mr4WZgpJaPB7HoUOH0N7ejquvvhoPPvggisUi0uk00uk0fvWrXyEQCOB3v/sdNm7cCI/Hg/vvvx8SiQRr167Frbfeitdeew0A4PP5sH37dtx999149NFH0dTUBJlMBo/HM+Vn03ucmJiARCLB0NAQ8yhEUWSWJ00JUqkU08IFQYBEIkEqlYJGo4FCoYDBYEA+n4fVaoUgCDzKrFQqyGazGBoa4lGmXq8HMEn4OnDgALxeLzweD3K5HCcaYpza7Xa0trYiEonMKBh7r8UcxvA2QqvVolgs8o1VX1/PlmtGoxE//OEPsX79+il9ajabRU9PD1KpFAKBAEKhEADwia5UKhlnIAl2Pp9HNBpFoVCAQqHgUSXdGDTGVKvVMBqNsFqtfMqSzRu1GieqNAFgfHwcAPDtb38bGzZswOWXX44NGzbgf/7nf7BgwQJ+XjKZxDPPPINwOIwXXngB+Xwer732GiKRCAN91VGpVNDZ2Yl7770XAPhGrY5EIoGBgQGMjIygv78fhw8fRjAY5PdN04dCocCVAjCJq1TjDYSfaLValMtlxmJyuRzGxsZQLpeRTqeZGyKTyWCz2fj1BAIB7NixA7t27UIqlYLX6+UqRRRFBAIBHD58GBaLBStXrpzGAH2vxVxieIshlUqh1+u5tLRarVi6dCnfzPPmzcO8efOmfV0ymYRcLofL5ZpC9VUqlRBFkUthujFoxFapVJjspFaroVAo2AaO6MSUWCQSCUwmE/+bRqPh07caJKXIZDIIBoN44oknIIoient78dWvfhULFy7EQw89BK/XCwDcf5NPwq5duzA8PIyJiQmYTCa+WRQKBb7whS/g2muvhSiK+NnPfoY33ngDAKbxKUqlEvR6PURRRCQSQbFY5CkL3czZbBapVIp/NiW8ZDLJHhaJRII9Kal6kMlkSKfTkMlkMJlM3FKRE5bVaoXT6eTXcfToURw6dAg9PT0wGAywWCzTXuvBgwcxNjaGefPmwWw2v72L6CyOucTwFqOxsZFvYLVajQ9/+MMwGo0IBAIAgBUrVnCpWh3pdBp9fX0IhULQ6/VQq9VIJBIMpFEyIKyBKgK6oJPJJKRSKURRRKVSYZBPKpUy0YeSls1mg1arhcFggNPpZK+DE6NQKCCbzfJrB4BoNIp7770X8+bNw+LFiwFMtkHVvIpUKsU0arlcjlWrVgGYPM0XLFjAmgS/34/BwUHIZDK4XK4pP1sURb5Ba2pq0NbWBovFwlJuSmTRaJSTAH3u9HlFo1FEo1HE43Fmh5KxCxm/kPqSwFGlUgmDwcBsSWCSsTk8PIy+vj4cOHAAcrl82giXJO+9vb1YvXo1mpubT//ieRfEXGJ4C2E0GtHQ0IBgMAhgkpizdOlSDA0NIZfLwePx4POf//yMZbtCoeBxIgBuHcgAlloIKo+LxeKUioC4DAC4lKZWIp/PIxQKQa1Ww+12w+l0splJMpmE2+2G1Wqd9pqITkymsxSEb9As/+KLL+Ybau3atVOeK5PJsHz5cgCTFcjf/u3f4sUXXwQwyfCkfztxZEoYBrE/HQ4HJBIJe0vSuLZUKvEYlxSfcrkcCoWClZqxWAzpdBqxWAy5XI4nFvRnrVYLhULBXhPJZBIajQZGo5FfjyiKKJVKSKfTbHDrdDphMpkglUr5ealUCr29vVi/fv17Mjm8aWIQBOFXgiAEBEE4XPWYRRCE5wVB6Dn+f/PxxwVBEO4SBKFXEISDgiAsP5Mv/q8RUqkUixYtwrFjx3h0uG7dOhw4cAC7du0CAFx++eVobW2d8evJi9Hn8+HIkSPQaDQwm82w2+2QyWTIZDKYmJhAqVTidoAqBp1OB41GA51Ox3N9lUrFNxFVIBaLhXkSWq0Wx44dw9DQEFwu14wVA4F2jY2NUx5/7bXX8IlPfAJbtmyBTqfDtddei0QiAYVCgdra2inPFUVxRsGWUqnEl7/8ZdTV1QHAtFaGQEGamBAwSBMW0oSYTCY2laF2gjAeYkMWCgVuKwqFAiYmJhAKhZBIJPj/UqkUFosFpVIJwWAQ+Xx+SlUgk8l4JFsulzlJe71etLS0wGw2c8Lv6+vDc889h8WLF7/n2opTqRjuAbD5hMe+AuBFURRbAbx4/O8AcBmA1uP/3QbgZ+/Myzw7QhAENDY2IhQK8cht8eLF0Ol0ePLJJ5HNZiEIAs4///wZqwUA7FmYyWSwd+9eSKVStLS0wGAw8H/UStApWalUuGQm5iPRfgEwVmEwGGA2m3kXhcfjQW9vLx5//HEcPXoUEolkyoVNUalUkEgk0NfXN+XxY8eO4d5770Uul4PX60VNTQ2rGAcGBvh5xLF49NFHp71faj927NiBfD6P2traKcmBfCrK5TISiQSMRiNqampQLpdhNBphs9lgNBp5ZFqtGQHAEx2aUpCrNVVThNlMTEwwKAwAnZ2d2LlzJwYGBqBQKHD11Vfj/vvvxzPPPINnnnkGt9xyCztmka3dRRddhA0bNvB0h7whmpqacOutt0Kj0ZzW9XQ2x5uOK0VR3CYIgveEh68BsPH4n38DYAuALx9//LfiZK27UxAEkyAIblEUx9+xV/xXDEL7Dx8+zNhCW1sbdu7cidHRUQCTFOCamppZv4dCoUBLSwt27tyJTCaDwcFBLFq0iC3bwuEwALDBKt1YMpmMwT2r1cr28TTW1Gq1fNrpdDrY7Xb4/X7s3r0b2WwWo6OjCAQCfANVk3VEUcSePXtw6NChKa+VTuETNRbJZBK7d+/m19PU1ITu7m4MDg5Oe7/ZbBZf/OIXoVQqcf7556OhoWFKYiID2LGxMYyPj8NoNKK1tRXDw8MIBAKoVCqcIKldomkDsUNjsRh0Oh1rU6iySqVSzAolPkJLSwv8fj/eeOMNDA8PQyqV4v/7//4/fOYzn5kyMVm7di0sFgvuuusudoqSSqXwer0wGo1cHanVahQKBUilUixevBg7d+580+vo3RBvlcfgrLrZJwA4j/+5BsBI1fN8xx+blhgEQbgNk1XFuyJoBt/b28sjM4PBgGAwOMVeHZheLp/4fRYsWMBmp88++yz0ej27FRHLb2xsDMFgEGq1mlsFl8uFRCIBg8GAZDIJlUrFpzXdYGRpJpfL8cYbbzAAWKlUWJlJUw6KtrY27Nu3b5ouYO3atbBarXjooYcwMDCAvr4+6HQ6RCIRhMNhnjR4vV7s2LGD+RwzRT6fx3PPPTftZ8tkMmg0GgwPD+Ppp59GsVjElVdeiQULFrCPAo1mK5UK8xPGx8cRCoV4NFmpVKDX6zmxUsUhk8mgUqlQV1eH9vZ2tLe3Y9++fRgeHkalUoHX68WNN944bYyqVqvxzW9+E8eOHcOTTz6JZDKJBx54AIsWLYLb7WZmZDQaxa9//WtIpVKsWbMGFosFkUhk1s/h3RJvG3w8Xh2cNldUFMVfiKK48lT14X/t8Hq9iEajfLGSL+Pu3bun3BAEdp0s1q5dC5VKhVKphDfeeAP/9V//hXvvvReJRAKbNm3C6tWrsWDBAh6leTweZvxlMhluC2QyGd8I9DyXywWJRMICJEpYdrsdTqeTJxgUEokEjY2NaGtrm6YLePHFF9HX1weHw4FMJoPx8XEsXLgQADA8PMx7JcxmM5566qlT+hxPJAaRdqFSqSAej2NkZARPPPEEpFIpmpubGRNRKBQolUqQSCSora1FfX0907iNRiNKpRLTlokoRt4SWq0Wa9euxfr167k66uvrQ6lUwgc/+MFpkxIKk8mEH//4x4yPjI+PY9u2bcjlcpxIiARF5LCOjo6THgzvlnir78AvCIIbAI7/n+ZcowDqqp5Xe/yxd3WoVCp2Wq6OQCAw5cYEJk+3N7MOW7VqFS688EIAkxfW8PAwnnjiCdx9990oFArYtGkTLrnkEmzcuBG1tbWwWq1Ip9NIpVJ8YpI7tFarRUNDA1paWljzsHXrVuzfv38KZ4CATJ1ON+V0JD7ETOa0dBONjY1BFEUcOHCAR5e9vb38/fV6/Yyj2dmiupUg7gUt2AGAkZERbNmyBWazGTU1NTAYDKirq4PD4WCbfRJL1dbWMihIEx6pVMpiqGKxCLfbjaVLl0IURfzpT3/Ca6+9hmKxiPr6etx66638embSQjQ2NuKb3/wmA5K5XA7d3d3TEiwAjI2NwefzzTj5ebfFW20lHgNwC4B/Pf7/R6se/3tBEP4AYDWA+LsdXxAEAR0dHRgZGZlyo4miOON2JQKkThZqtRqf+tSn8Oyzz7IgqFKp4ODBg/j3f/93fOpTn4LVasW6desY8AsEAkgkElCpVHA4HEyT1mq1aGpq4pP3kUceYdl1ddDeS5PJNGVkaLFYYLVaoVQqYTabp3AZTgyz2YzVq1fjJz/5CY4dO8ZofiwWwxe/+EUcPnwYXV1dJ33vSqUSy5Ytw65du5jDUFNTg4mJiSk3Jsmlb7rpJtTW1rIJDbE/ibNBvpparZarBoVCwQzQ1tZWNDQ0YOfOnTh69CieffZZBok//vGPo6mpiX9mMBjkcWZ13HDDDXjwwQfx7LPPApgcsVYqFTQ2NqKvr49ftyiKGB4eRkdHB+tZ3q3xpolBEIT7MAk02gRB8AH4FiYTwv2CIHwKwBCA648//SkAlwPoBZAB8Ikz8Jr/ouFwOGA0GnHgwIFp/0bLUmifJMX27dtx2223zTqZAMDz76NHj/JjlUoF+/fvx7e+9S20tLTgsssuYw8BckVOp9N8ISqVSqTTab6QH3/8cezevXtGHr8oilzdVNN53W43LBYLjh49ig9+8IN45plnmGNxYsRiMRw7dgzAZFlNJfPY2BhzEN4sMcybNw8//vGPcc0112BsbAxyuRyxWAz5fB4Wi4XbE2Jg/uIXv2Crt/nz56Ouro4rsmg0imw2C5lMBlEUeeRrs9ngdrtx7rnnIpPJYOvWrQiFQlx1AZPiLdqvSWG1WmdsA3Q6Hb7yla9gy5YtrE2Jx+Ow2Wwwm81TMAUCkL1e75Tf7bstTmUq8dFZ/unCGZ4rAvjM231RZ0tIJBJs2LABBw4cmNEaraGhAeeeey5eeumlKYlh69at6OvrQ0tLy6zf22q14qabbsI3vvGNaTdyJBLB66+/jkOHDqGhoQELFizA4sWLmdDjcDh4Zp/P51nY88orr8xq4ZZOpxEMBlEsFmGxWFj9KYoi/vZv/xaPPvooBEHApZdeyjb1J8bvfvc7xiFoigIAXV1d8Pv9nDRmC71ej6997WssPx8bG4PT6UQul4PJZMLSpUsxNjY2BQQdHR3Ffffdh3A4jCuvvBJr1qxBOBxGbW0t4vE4RFFk3oJer4dWq2Vwd2xsDA8//DAGBwfhcrn4PQmCgE9/+tPTKOsntgbVsWbNGqxduxYvv/wyf27Dw8Ns8FItZ/f7/XA6ndDr9e/anZ1z6sqThMvlgkajwcjIyKzP8fl8U04MQRAgl8uxbds2Zi+qVCrWQtDGaEEQcNttt+Hxxx+fdcSVzWZx9OhRHD16FI899hg7ItfV1cHtdjNbUqVSYWJi4qS7IScmJtgqrprQY7PZ8OSTT3Ji27ZtG9xu94yJQSKRoLW1lcVSSqUS+XyeqweHwzENh6mOj3zkI2hqakI6ncbSpUuxbds29l40GAyoVCp48cUXp01HMpkMHn30UezYsQNLly7FsmXL2COCbOSz2SxEUcT4+Dj27t3LOzmTySTsdjuzJgFgyZIluPPOO08LJFQqlbjxxhs5MQCTeBI5RlU7U1UqFQwODqKmpmYKAPxuirnEMEsIgoDVq1fjwIEDs+6VHBoa4rEXhcfjwRVXXIFisciuTAMDA6wnUKvV+OpXvwqHwwGbzYb/+q//wjXXXHPS5AOA2Y+5XA7hcBjd3d1wu93weDxobW2FTCaD0+mcFd9IJBLweDwQBAH79u0DMHmxd3R04Pnnn+fnRSKRWcdtF110ET72sY/hpptuAjDp/LRnzx74fD74/X584QtfwG233TarV+Ldd9+N3/zmN5g3bx5vmPJ4PDCbzYhGo0gkErO2X6Iowu/349lnn8VLL73EjlakRM3lckySqk4sZIhD1YzNZsMPfvAD2O32k37eMwVxG6o/n7GxMdTV1U3z94zFYmhra4Pdbj8pbnO2xrt/rnKGgsQ1R44cmfU5JGSiUCgUuOiii+BwOKaoGome293djd/+9rf43e9+x6fIsmXL8L3vfW/aHP3NIpvNor+/H0eOHOEWgeb9M0Uul0MsFmOdAKk6TwTaZguHw4Hvfe97bLoCAJ/85Cfhdrt5PPiRj3wEd9xxx6ySZFEUUSwWcfjwYQwODsJqtaKhoQE1NTVcdp+KdTsZ0ZDgaWhoCH6/n+XZFFKpFEuXLkU+n0exWITRaMTdd9+Niy666JTe84nR1taG+vr6KY+RqGqmFm5oaAgtLS0nxZrO1phLDLPEypUrEQqFTssp2OPxMB+AKMvkMkQekPF4HD/60Y+meBdce+21uOWWW97SBRSJRPDGG2+wNdxsZWs2m+WN13q9HlKpFIVCAU899dQplbqbN2/GggULWC4OgHkFwGS5L5FI8PWvfx0f//jHT+m1W61WmM1mmEwmWCwWpjG/U2E0GhGJRDA0NASJRILPf/7zuOKKK6Y9j2jPQ0NDGBkZYQD0xJBIJFi2bNm0x8vl8oyvOxgMIhKJvC0r/r9WzCWGGUKhUKC5uXlWR+OZQiaTYePGjSxmUqlUSCaTvClaoVDw30dHR/Hf//3ffDrK5XJ89atfnWKKcqpB/IojR47MunWKnjcyMoJkMsmgZbFYxP79+0/p5zz55JO4/vrrYTKZuGr47W9/yzdRJpPBH/7wB3z6058+Zeafx+NhB6tYLIZoNHrSvZ6nE3a7HRaLBYODgygWi9i0aRP+4R/+YRrAuHPnTnzuc5/DZZddho997GO48cYb8ZGPfAQ/+MEPZsRLTuf1kR8nEaTeTTGXGGYIj8eDoaEhTExMnPLXmEwmLF68mPc8AJMnTCAQwODgINuxLV68GKtWrUIsFmPnJGDS/ek73/nOrPZrbxa0QRvArJWHz+dDJpNhNydqc04lwuEwHnvsMXR2djIb8ejRo1xRKZVKvPzyy3j44YenYBYnC1pum0wmEY/HEY1G35FVcTqdDg0NDchms8hkMjAYDPg//+f/TCNhFYtFPPXUU7ynk0hjsVgM999/P/75n/95ClmtUqm86Tj2xEilUmhtbT3pir+zMeYSwwkhCAIuuOAC9PT0nNbpIJfLMTIyglAohGQyyfJkciiORCI477zzsGnTJmzYsAHz5s3DsWPHppSgV111Fb7+9a9Pc2I+3ZjN8nxiYgLpdBparfakozmlUomrrrpqmj+jx+PBokWLsGbNGgBgoxZgslXp7u5mR+sTe/ETg0xbSBgFnPoGr5OFUqlEe3s7tFotS7fvuOMOnHPOOVOel0qlcODAAVZcejweuN1uzJ8/H+3t7bBarTh48CAeeOABTlY7d+5Ef3//ab2efD6PYDB4yljO2RJzU4kTgkgubzYlqA6JRAKr1YpkMgmLxcLtwt69ezE+Po7e3l4sXLiQXYSGh4dhNpuxfft2ZubR9/n7v/97HD58GL///e/f8piLlJ8nTlMSiQSOHDmCcrnM39tgMPDSXAqDwcDtRnVceumlsNvtbPVWHUqlEg0NDdi+fTvi8Thuvvlm3H///cyXODGcTidb4ZFN/dtZUU87OGpqauB0Otny/ZxzzsEXvvAFxkLy+TyeffZZPPzww9wW0VJcsuwnJmUoFMIDDzyAaDQKh8OB73znO29JINXf3w+PxwO/3/+W399fOuYSwwmxbNky9PT0nBboaLPZ0Nrainw+D71ez3sZjh07xjbvHo8HHo8HiUQC0WiUzUVO5B7odDr86Ec/QiQSwdNPP/2W3oNEIoHb7cbo6OiU91GpVLBnz54p0ucvf/nLiEQi+OEPf8jVSzAYnDKvp/jjH/8IlUqFefPmTVNJGo1GfP3rX8cTTzyBZDKJX/7ylydd1rJgwQJEIhEYjUauFN4qhZhs5XQ6HcxmM7LZLPr6+rBkyRLcd999U3wdH330Ufz85z/H8PAw2tvb0dTUhLa2Nhw5cgQ9PT0YGRlBV1cXOjo64Ha7MTQ0hO9+97soFouzjq3fLOLxOC8Xere4S8+1ElWh1WqxcuVK9PT0nPLXSCQSdHR0oLm5GRqNBt3d3di2bRsOHz7MU4J169bh0ksvhVKphF6vZwTeZrPNKD6y2Wz43//9X2zefKI/zpuHIAhQq9XQaDQzfu/x8XGEw2GuEOLxOIxG40lbC4pkMomf//zn6O7untYzl8tlPP7443zzxOPxGUlSFN3d3bjnnntYPEUjx9MN0rKcf/75WLJkCdrb26FUKrF+/Xo88MADXN2IooidO3fivvvu4w3cZrMZ8XgcO3fuxMMPP4ynn34ahw4dYtdqSgaZTOYtJwUAUzwm3y0xVzFURWtrK/r7+0/rArVYLGhpaYFKpYLf78e+fft4LEg3/4UXXsithlwuh81mQz6fP+l40mq14t5778Xf/d3f4ZFHHjnl1eyiKEKlUsHpdKJUKk1D+mkNG51cP/rRj6ZY4L9ZlEol3jdRHf39/fjP//zPGcFDp9OJTZs2YceOHfD5fJwIEokEisUiZDIZBgcHZx0TniysVivOP/981NfXs2PT6tWrsW7duik34t69e/Hb3/4WsVhsCndCp9Ohp6cHnZ2dKBaLKJVK6OjoQH19PdRqNex2O+bNm4fu7u63BYzG43G4XK6TelacTTFXMRwPiUSCRYsWYf/+/adV7tXX10MikeDw4cN45ZVXMDw8jNraWnziE5/AFVdcgYsuuoiFP/l8nolFr7/+Og4ePHjS7221WvE///M/+Ld/+7dpHosni2KxCLPZjObm5mmgV7lcZo0BPfd0sQzypKyOEzUO1VEoFHDLLbdg165d02TOpVIJIyMjOHr06GmPKuVyOVpaWtirQRAELFu2DJs3b56SFHK5HJ566qkpfhpEeGpqakJzczO3PfF4HDqdDlarFaIowuv1oqOj420DwqFQ6F3l0/DueaVnOEg/MBtYNlNQ2V6pVLBv3z4MDg7CaDTilltuQVNTExQKBfx+P4aGhhCJRHg0Vy6XMTw8zKDlyUKv1+POO+/E888/j8suu+yULq50Oo1isQi73Y66urppFugkOwbwjnkHLFmyBBdffPGM/xaNRnHzzTfjwQcfxJe+9CVs3LgRwGTC6O7uxu7du9lx+3SCgMZAIIBdu3bBYrFg+fLl0yoxsoFTq9VoampCsVhEIBBgjolKpcL8+fNZpdnf388r8iQSyWljTjOFRCLBtdde+67xhZxLDMdj8eLFGBgYOK1ekmzV9Ho9BEGARqPBBz/4QSxduhT9/f3Yv38/tmzZgpdeegmDg4O8Xq67uxurV6/G7bfffkobjQRBQHt7O+655x588IMffFM8IJ/PY3R0FMFgEDqdDrW1tVNuFlpcA5zchu50IhAI4M4775yVh0H//tvf/hbf/va3OaFGo1F2Uzqd0Ov1aGxsRDabRVdXF+x2Oy699NIZWYa0fZy4JsuXL4fBYEAul2PB09jYGFeKExMTOHLkCEwmE0wmEy8RejuRzWbR2tqKtra2t/V9/lIxlxgwOeq64IILTovQJJFI0NzczOSV2tpa3HTTTbjiiiuQz+exYMECtLe3w2az8U0wODiIQ4cOob+/Hx//+MexdOnS03qdDocDv/zlL/HjH/8YCxcuPKngqLOzE/F4HI2NjViyZMmUG1YUxSnmIqdLxW5qapoGPmazWSxdunQaX6A6KpUKfvOb38BgMMBms7Ef4+lKk2kRLjAp+Tabzbjtttu4bSL9QjXRjOjXGo2GfTEtFguy2Szi8TgEQcDatWtZ2zA2NoZ9+/YhkUhAq9W+bb1DNpvFr371q7mpxLspHA4HrFbrSVH0E4M2TZPXX1NTE6655hoel3k8HrS3t2PFihVobGyETqdjiu3tt9+O9evXv6WLzWw244477sCLL76Iz3/+87NWHNlsFuPj48jn89BoNLP6GtINczqxcuXKaS2Ix+Nhq7WTBa2jNxqNEAQB6XT6tKsFWvobjUaxaNEi/OhHP5qyLGdsbAz3338/J5xyuQyfz4fh4WF0dnbyfol8Po9wOIxYLIZUKoWOjg58+ctfxsUXX4xKpYIXXngBzzzzDBYuXHhaGM9s0dnZOY00drbGXGLAZK8aDAZPe8U57UZMpVJYu3Yt24qTLFqpVMJqtaKrqwu9vb1obm7Gddddhw9/+MNvG8witeP3vve9WcdgIyMjOHbsGDKZDGpqaqaV2VKpFFdeeSXcbvdp/WytVjttoY7VasVrr72GZ5555qRfWy6X8dBDD6G2tpbFS6c6cQEm26pisYjBwUGce+65+PWvf42Ojo4pz6G19TTloO1fTz/9NF5++WXeiUHGsTqdDmq1Gq+//jpisRg+85nP4KqrrgIwiTkNDg5OUZW+1cjn82htbT2l0fBfO+bGlZjU2RPYdKpBFYNEIsHChQuxevVqiKLI249IgNXT04MDBw7gQx/6EO688040NzefMmeAVr7TGE6hUMBqtXKVIJfLWeb8j//4j9NGYcViEUNDQ2hoaGBPx+pR7MUXX4yvfOUrePXVV0/5fdP3rV7rBkz25T/96U9PCUQcGBjAhz70IWzfvp0l46caarUaHo8HV111Ff7hH/5hWuWSy+WgVCqxbt06ToRSqRQLFixgtSv5S+p0OnaD+tjHPoZgMIhMJoPa2lr80z/9E8bHx7Fz5068/vrrp/z6ThaZTAbJZBJms/m0qtO/RrzvE4NCoUBHRwf+8Ic/nPbX0jaqO++8Ey0tLTh06BAGBweRy+UQCAR4h8T555+PO+64Y9oKuOpeP5PJoKenh7cpHzx4kJeu0CJXvV6PFStWoK2tDTfeeCNaWlogk8nwyU9+Ei6XC5/85Cen3Jjkf0B98vz58yGRSDAxMQGJRIIbbrgBGo3mtBmHjz/++LRJx89+9rNTXrYSjUZx2WWX4fDhw9i+ffspfQ3tzXC5XLjtttvwqU99ahrCXy6XEQwGeVpR3aJcccUV+MIXvoDHHnsMw8PDEEURUqkU0WiUt4PTIt2enh6sX78e//Ef/4G/+7u/w8GDB98RbIB8JDo6OrBt27a3/f3OZLzvE4PBYEBTU9NpjSmro7m5Geeccw5EUUQsFmMB1fr163HDDTegqalpxrahWCzi+eefx/j4OLcfXV1d0Gg0LEEmhyO/349gMAiZTIannnoKjzzyCHbs2IHLL78cf/M3fwObzYYrr7wSd999N26//fYpqs10Oo3+/n5cdNFFMBqNcLvd2L17N8bGxqBUKnH06NHTVgzG43HWNUilUpTLZWzfvv2Ub55QKASVSoULLrgAW7ZsedPnC4IAu92OtrY2fOlLX8Lll18+I91aKpVO2ZFZ/RyNRoOvfvWraGhowLe+9S2MjY2htbUV4XAYJpMJjY2NSKVSXFEZjUZs2LABP/jBD3DrrbciEAhw9fZ2wufz4YILLsCrr756VgOR7/vEIJVKMTg4+Ka7IGYKiUSClStXwmg0Ih6PIxwOQy6Xo6mpCTfffPNJ+9Lu7m48++yzCAaDkEqlqKmp4fXv1R6ItIS1oaEBJpOJK4ljx47h2LFj2Lt3Lz7/+c9j+fLluPLKK/HEE0/g61//Op577jkWS9HWJqfTCavVCrvdjpGREVQqFQwMDJxWKV8dMpkMmzdvxpNPPnlaF7lCoeB9lafydUajEatWrcJXvvIVrFu37i1PCFQqFW655RbIZDJ89atfxejoKAwGA2KxGGNM5Pzd09MDj8eDZcuW4frrr8dzzz2HoaGht3SdVIff78eSJUv4556t8b4HH2tra+H3+09qcjJbtLe349prr+XtUFu3bsW+ffuwYcOGkyaF8fFx/OpXv8LIyAhPDCQSCTPuaMQpiiIkEgkMBgPUajWkUilaW1vh8XiYx//UU0/h5ptvxksvvQRRFLF8+XL84Q9/wM0338wchUKhwE7Xer0eNTU1WLduHZYtW4bBwcG3PKOXSqW49dZbT1sDsHTpUrS3t7N9HjCZLE5sTwRBgNvtxkc/+lF8//vfn5YURFHk5HKq70Emk+Hmm2/G888/j7/5m79BKpVCNpvF4OAg7wL1+/0YHBzECy+8gJGREaxYsQK5XI73YAKTAOfJRGKzRSaTgdlsnnVKdLbE+75iWLx48Sl7DVaH0+nEP/3TP2HhwoUYHBzEa6+9hieffBIXXnghr3GbKfL5PP77v/8br7zyCtavXw+Xy4V8Ps8ux3q9HiaTCQMDA3A4HCxJNhgM7O/Q1NSEcDjM7L1gMIjPfe5z+Jd/+RdcddVVMBgM+P73v4+enh68+uqrkEgkiMViiMVi0Ov1UKvVkMvlMBqNb8t2TCaToa6uDgsXLsRrr712yl9HOyUtFgsMBgOi0Sgv5aUELZVKccUVV+Cf/umfsGzZsim8iVwuh4GBAQwMDODAgQOwWq3weDxobm5GQ0PDm7ILSXjV0tICl8uFe+65Bz6fD7lcDoVCgXUNJpMJ8Xic6dGpVAo1NTUYHBycojc5nUilUhgaGpq2U+Rsi/d1YpDJZFi9ejVeeeWVkz6PthwVCgU0NDRAJpPhAx/4AC666CL09vZi165d2L17N5YuXYqvfe1rs16YgUAAv/3tb/HHP/6RV7UrlUoIggClUomBgQEkEgmo1Wp2HtLr9fD7/airq4NMJmMgUaPRoFgsIh6PI5PJYHh4GHfffTfvhrDZbPja176G66+/HplMBqtWrcJVV12F9vb2KUw+kiu/lYopl8vhiSeeOO1x58aNG/nnNzQ0IB6Po6GhAclkEqFQCKIoYtmyZfjJT34yzRatv78fjzzyCPtKHD16lDd+NzU14dxzz8XFF1+Mtra2N016CoUCn/zkJ7F582Y8+OCD+Pd//3ccPHgQpVIJLpcLZrMZLS0tOPfcc/Gxj30M//7v/86rAE53tE1BC2lO9zP7S8f7OjEoFAo29ThZqNVqtjY3GAxYsmQJrrvuOnR3d+PBBx/ESy+9BJlMhl//+tdTiDbVMTIygttvvx0vv/wyrFYr2tvbkclkkMlkUKlUmPBDN2htbS2i0SivvBcEgXc4yOVyXoWXzWahVCrhcrmQTCbx05/+FOFwGB/+8IexceNGfOYzn8GuXbvw3e9+FytWrEC5XMYrr7yCoaEhOJ1OrFq1CnfddRc+85nPnLa0uFwu41vf+tZpz+UbGxuRz+fR3d0NqVQKh8OB+fPnY2hoCIODgyiXy1ixYsWUpFAqlbBjxw78/ve/h9/vh0ajgcPhQGtrKwRBQGdnJwYHBxGPx3HkyBG0t7dj8+bNaG9vPyntm5bk3nnnndDr9fjHf/xH/lx3796NXC4Hp9OJiy++GC+88ALy+TyT2N5KUOWxfPnys9qf4X2NMbS2tkIikZy0pJPL5dDpdOyIHAwG4XA4UF9fj76+PuzevRvRaBQXXHDBrC1EIpHAv/zLv+D555/nEZpCoUA2m0UoFEIqlUKlUkGpVOK17gB4OavVakWxWEQ4HIYoimxLr1Kp0Nrairq6Ou5ZQ6EQYx0KhQLf/va38ac//QkrV66EIAhc/qdSKYyPj2NsbAzXXXcdPvCBD7ylz5AUkqcaGo0GTqcTg4ODPA1xuVzI5XLo6enh3ZonqkL37t2LX//610in0/xZuVwuNDU1YdmyZVizZg28Xi8kEglCoRCeeuop/Od//ie2bt16SuNYqVSKW265BXfddRf7a0gkEnR3d6OzsxP5fB4qlQrj4+NvuVqg6OnpQVtb29smuZ3JOHtf2V8g2traUC6XT4o0G41GNDY2IplMsqxYrVaz4zL12J/73OdmLF1HRkbwL//yL3jwwQfR1tYGiUSCbDaLbDbL69/L5TIymQycTieCwSCX2XRBK5VKVCoV7sONRiOUSiW6u7sRj8dhsVig0WiQz+chkUi4jy2VSrxNujqam5uxaNEi7Nu3D/F4HK2trbj55pvx8MMPv20V4ZtFW1sbli9fjqeffho7d+6EwWBAY2MjhoaGoFKp0NDQgJGREXz0o3/ejDg0NITf//73yOVycLlckMlk0Gg0nLADgQA0Gg2DmYIgIJPJIBwO46677sJrr72Gj3/8429Ka5bJZPjIRz6CXC6He++9FxaLBXK5HNFoFLlcDmq1eta9nqcT/f39KBaLZ/W+ifd1Yujo6MDevXv5xJtpHbrFYkFNTQ1brRNXYf/+/RgbG4PZbMZll13Gvo3VceTIEXzhC1/AwYMH4fV60d7ejnw+j0AgwEAjjSSlUikUCgWKxSLS6TTi8TiKxSJPIJxOJ5RKJVOIk8kki5AsFgscDgeCwSAMBgOMRiNGRkYwMjKC5ubmaa+LBENkYPvqq6+ip6fnjK9SUygU+NznPscr+hwOBzZv3gy3240nnngCWq0W+XweF198MVdfuVwO99xzD3p6euByudihmlidcrkcer0e5XIZyWQSWq2WvRvL5TIGBgZw9OhRDA0N4dprr8WyZctgt9tnvSnlcjluuukmJBIJPPLII1CpVCiVStBoNO+YMjIajSIej8NgMLwluflfIt63iUEikWD+/Pm455572CDE5XIhkUhMKRUrlQrPuTOZDJqammA2m3HkyBEcPXoUH/jAB7B58+ZpfezRo0fxta99Dfl8HitXrmT2ot1uh8FgYMyCTEbIwLVQKMBkMqFcLiMWizEdenR0FPX19bzunnQaxWIROp0Ooigyey+fz2NkZAQ7duxgsPTEkMvlOOeccyCXyxEIBHDo0KF3bKfDbNHR0YHly5cjnU7jiiuuwLp162AymVAoFCCRSLB//34cPXqUPRpFUcRzzz2H3bt3w2Aw8Ges0Wjg8/lQKBRgtVohk8kgk8l4HZxEIkE6nWYdhEQiwZYtW/Dss89ixYoV+OxnP4vVq1fPChIrlUrcdNNN2LNnDzo7O5HL5aBSqbBy5Ur+3b2dKBQKUCqVsNvtZ21ieN9iDEQaIhCJToQT24FkMomDBw+ip6cHUqmUT7hAIMCc/RMVjoODg/jGN76BoaEhmM1m6HQ6aLVauFwuLFq0iOm6xBocGhrC0NAQtFotTCYTEokEVxIymYxPN1qgK5VKodPp4PF44HQ6YbFYYDab0dTUBKPRyOPXAwcOTANWfT4ftm3bhtdffx3hcBg7d+7Eyy+/jPHxcbS0tJxRX8K+vj6sW7cO3/jGN6BUKrkK0uv1OPfcczFv3jwsX74cKpUKR44cwf79+/GLX/wCxWIRcrkcBoMBWq0WOp0OTqcTWq2W92P4/X5Eo1EYDAYeg9Lno9frUSqVkEwm8dprr+GOO+7A7bffjtdff33WZGi323HjjTdiYGAAQ0NDCAaDWL58+TTB1luJUqkEmUw2oyfn2RLv68SgUCg4Y3d0dGDZsmXTSCuBQADj4+OoVCqwWCyor6+HKIpQKBT46Ec/Om3slM/n8eCDDyIcDkOj0UCr1UKv18Pj8aBSqbCTEJ1ktD9SpVIhEokglUohnU5DFEXU1NRAIpFw21G9OLVSqUCtVsNqtUKlUjEBR6vVwmazIR6PIxgMoquri5FvURTxox/9COeffz7OO+88XHnllejr60OxWMQll1yCn/3sZ/jjH/942j4RJwulUsnlfzKZRCaTmTbFyGQyOHDgAMLhMNrb27FkyRK8+OKL+P3vf49wOMzr78i7gezZcrkcxsfH+d9pUbDdboder4fD4YAoikgkErzHQqPRIJFI4JlnnsHnPvc5/OlPf5oVnNywYQNWrlyJHTt2YM+ePSiVSjjvvPPetjpSJpPBYDCc1W5O79vEYLfbkUgkEA6HAQB1dXWw2+3TxkckRAImk4dSqcTY2BjWrFmD9evXT3vu1q1b8cYbbzD12GQyMTnJ7/cjn89Dp9NBoVBgaGgIUqkUbrebx48Wi4V3W1gsFl7UajKZ2IKcbgydTgedTodisQipVMqtRKVSYeXnnj17+D0WCgXWJhQKBezZswcLFizAfffdh+9///u44IILsHnzZvzxj3/EunXr3vZnvHDhQtx3331sqiKRSHDjjTfi29/+Nj8nEolgx44dePrpp1EsFnHOOedg4cKFSCaTCIfDXBERd6BQKCAajSKbzcJms0GpVCKbzfLUiD5jhUIBrVYLj8czpdIgo1yZTIaDBw/i29/+Nn72s5/N2B4YDAb84Ac/gNlsxq5du/D0009DqVS+7WmCKIrIZrPvyIKdMxXv28TQ0dGBQqHANz394mdbeiIIAuRyOSYmJqDRaHDttddOQ/sHBgbw1FNPsccgMNnLq9VquN1u3qEQi8Ugk8lQqVRQKBQ4QdGOS5osFAoFSKVSPinz+TzUajXC4TCfWpTMaJSaz+chlUp5nBmNRtmZSqFQ4PLLL+fXS3Rrkh/v378f4+PjaG1txQMPPIANGza8pc9WEASsXLkSDz30EK688krY7Xao1WpcddVV+M53vjOF+qzVahGNRlFXV4dPfvKTaGtrg1ar5TbBaDSivr4eGo2GW6pcLscsUFEUEYlEGHeJx+MYGhpiE5hisQiXy4Vzzz0XK1euhMfjwdKlS7Fy5Uq0tbWhUCjgd7/7HZ588skZ38vy5ctx4403YmhoCK+//jpkMhlsNttb+lyq3zOR5s7WeNPEIAhCnSAILwuC0CUIQqcgCJ87/rhFEITnBUHoOf5/8/HHBUEQ7hIEoVcQhIOCICw/02/irUR9fT2fLsCkfmH79u2zUqNpROZ2u/GRj3xkmutRMBjEr3/9a4yOjkKlUjG3gPZE0olULaHWarWIx+M8my8WiyiXyzxtoMpAqVRCoVCgUqnAZDIhnU4jmUxCKpUinU7zgtpCoQCFQsGcfnI56urq4vHYJz7xCSxZsgTAZJW0ceNGpFIpvPDCC9i3bx+2bduG3t5euFwu/OEPf8AnPvGJad4LM4VEIsGll16K22+/Hd///vfx9NNP8+bv7373u/jjH/+IL3/5yzh69CheeeUV7Nixg/t7q9WK6667jseJfr8ffr8fo6OjiEQicDqdbAdHGgW1Wo1cLscbs/R6PSKRCO9wyGQyGBsb4+Ti8XjgcDjQ3t6OxsZGtLa2YtmyZTCZTBgcHMRdd9014/YxQRBw4403wmQyYceOHTAajbjhhhvellcmmc28VfHaXyJOpSYqAfgHURTfEARBD2CvIAjPA/g4gBdFUfxXQRC+AuArAL4M4DIArcf/Ww3gZ8f/f9aEUqnE4sWL+YYBpnojzBQulwttbW3YsGHDtNFkLpfDQw89xNUE8GdiVC6XQy6XY1AsFArBaDTyzyLijNlsRqFQQKFQgFarhVKphFwu54kE8RGsVit0Oh3i8TjK5TJSqRTMZjPkcjmkUilisRgymQwbwppMJrz44ovwer1YvXo1Ghsbcf/99+OJJ57A4sWL4XA40Nvbi/HxcR7Lvvzyy8hms2hra8MvfvEL3HnnnXjppZeQz+dx8OBBHDlyBPl8nll8oiji0ksvxQ9+8IMZT1O3242rrroKfr8fv/rVr3DkyBHezOVyubBkyRKYzWYIgoCRkRG8+OKL6O/v5/cWiUSQy+UYnPV4PIhEIkwfV6lUiMVivDxHLpcjFAqhXC7zfkwCVWnXh0QiYYn7+Pg4jh07hkceeQSf/exnp73+mpoa3HzzzfjKV74CQRBwySWX4IEHHnjLUn1qad4uUepMxpsmBlEUxwGMH/9zUhCEIwBqAFwDYOPxp/0GwBZMJoZrAPxWnLzydwqCYBIEwX38+5wVodPp0Nraih07dpxSOadWq7Fy5UqsXr0aHR0d0xR+27dvx3PPPYdUKgWLxYLGxkYeG9IeCavVinA4jFKpBLVazdUCbdaWyWSQSCQYHBxEc3Mz+xUSZkCltSAI8Hq9OHDgAHQ6HWpqaiAIAiKRCC9QoVFnKBSCxWJBKpXCvffeC6/XC6fTiba2Nnzxi1/k91Aul1EsFrk3T6VSePbZZ7Ft2zZ4vV54vV588IMfZAt0qp7kcjl6e3shiiKMRiNCoRBTiKlVikajSCQScDgcMJvNPPUhZmM1AatQKOAPf/gD9u3bh0qlwskuEAhAq9Wit7cXhUKB6d90kycSCeRyOWQyGRiNRq6+jEYjNBoNLBYLJ8t0Og2n0wmbzYZMJgO9Xs+2/s888ww++clPzqjy/MAHPoCf/OQnePTRR2EwGHDhhRfiN7/5zVuiNFssFgiCcFbLrk8LRREEwQtgGYBdAJxVN/sEAOfxP9cAqK7JfMcfO2sSA20h6uzsfNNfrEajwfnnnw+v14v58+dPm1ocPnwYjz/+OCQSCQuiMpkMisUiTCYT5HI5OzrRDoOxsTFeHFs9LjUajbw5SqPR8DhTEASUSiXI5XJWXTocDmQyGa4cFAoFlEolEokExsbGIJPJeMY/MjKCfD6Pe+65B7fffvs0ujHdWH6/H5VKBYlEgg1SDx48yKa3oiiyNZnX64Ver8fAwAC0Wi12796N0dFRaDQaXHbZZTjvvPMQDocxPDwMrVaLm2++GbW1taipqUGlUpnmNC2KIgYHB3HkyBGEQiGe3oiiCIPBAKfTyTs5gMk+PRAIQCqVcvvmcrm42lKr1SiXy5BIJMjn84jFYpBKpcw2pZEh7ZSIxWLw+/0IBALTEgMwieV88YtfxL/+67/C5/Nh06ZNePnllzE4OHja15/FYmGw+WyNU04MgiDoADwE4POiKCZOODVFQRBOizYnCMJtAG47na95p2Lp0qXw+/04dOjQSZ8nlUpx9dVX47zzzoPVakVLS8uUf08kErj33nvR39+PmpoahEIhyOVy1NXVIZfLIRaLcYVAEl6NRoNkMolcLodSqcR9dCaTgdVqRV1dHQKBANxuN48zZTIZqztJSKVQKNjlqVgscmIhV2iNRsM26uSG/NRTT0GpVOL666+H2+2GIAiIRqO4++67kcvl0NTUhEqlgmAwyIBmd3c30uk0ZDIZ5HI5fD4f+vr6MDIygrGxMUgkEhiNRt4uLQgCtmzZAkEQoFKpMDo6igsvvBBOpxPlchkdHR1Maurq6kIgEEA8HkepVEJnZycnxVgshmw2y+8ll8sxAEkTiGQyCb1ej2KxCJVKxRMLojLn83lEo1FIpVJIJBJEo1HMmzePuSNarRYSiQStra0oFos4ePAgBgYG0NTUNOP18OEPfxhPP/009u3bh1WrVuGCCy7APffcc9qMUbfbDb/ff8YJZW8nTikxCIIgx2RS+J0oig8ff9hPLYIgCG4AgeOPjwKo1srWHn9sSoii+AsAvzj+/c8sF7cqZDIZLr74Yrz44ovs2ThbLFq0CNdddx0mJiawYsWKKdVCpVLBk08+icHBQcjlckgkEthsNuRyOYRCIZhMJj7xqeylP3s8HjYGaWlpgSiKkMlk8Pv9KBQKkMvl0Gg0KJVKvAeTSFSUCLLZLIrFIrPy8vk8EokEbDYb2tvbEQwGedu1wWDA0NAQent78cwzzyCZTMLlcsFms+G1117Dww8/jAsvvBAXXnghlEolnnjiCfT19SGRSCCRSCAYDEKtVnOFUygUIIoiO1aRuSoF8TDK5TK0Wi0uueQSqFQqpFIp6PV6LFiwAMeOHcPhw4cxPDyMXC6H5uZmyGQyOJ1OuN1uHDt2jP0baaEPJctkMolgMIhsNotyuQybzYZSqYRMJgOtVotwOMyKVQL5iOtBfpfENq2vr8fw8DCL1YaGhlAul2fkKuh0OnziE5/A9773Pbz++utobGyEQqE4LX0JAc+7du16108lBAB3AzgiiuJ/VP3TYwBuOf7nWwA8WvX4zcenE+cCiJ9N+ILX68XatWtx9OjRk/5iVCoV1q1bh3A4DJvNNg1wDIVC2LFjByqVCjKZDAKBAFQqFdra2lAqlVAqlVgpGA6H2YeRqgA6rUqlEiKRCFQqFWpqatiCnm6YcrnMG5HS6TRftIIgTHERojYkn88jHo8z5bq2thYbN27E2rVrodFoMDExgUAggCeffBL//M//jK1bt8LlcmHt2rU80rvjjjvw93//93zhZ7NZpNNpBjYtFgtkMhlqamrYgs5oNDI4aLVakcvlEA6H0draym5WWq0WKpUKQ0NDvA2Lpi3ZbBYjIyM4cOAA0uk0otEoSqUS7HY7E7tEUeQ2oFgsMnEqm82ygzZhGIlEgissmvCoVCr+Pg6HA42NjbDZbBAEgcei3d3d6O/vn/W62LhxIzZt2oTdu3cjn8+f0sSmOqRSKWpraxGJRM64NuXtxKnMXNYBuAnAJkEQ9h//73IA/wrgYkEQegBcdPzvAPAUgH4AvQB+CeDv3vmX/dbjqquuQrlcxoEDB076vPr6eixevBj19fXYtGnTlGqhVCrhlVde4T7e4/GgVCphYmICqVQKWq0WqVSK0XQ6bUkZSaCT3W7nkSQp+Ox2O8xmM0qlEvL5PGw2G8rlMgONBERarVa43W6USiUGOqsdiACwmYvP54PT6cTy5cv5Z8lkMraL0+l0qFQq7HlIc//169fDYDBAqVQiHA5DEARIJBIUCgWoVCpefSeVShkspbK/p6cH2WwWixYtYiyBuBXkQ+nz+XgJj0KhwMjICIaHh7FlyxZ0d3fDYDAgn89zoo3H4zzlEQSByWOJRIJfF33moijCarUin88jFAphaGiI8RyTyQS73Y5yucyfucfj4eT7xz/+cYqhbnUolUp86EMfQrFYRCqVgt1uP63rj+zvz/Y4lanEqwBm04deOMPzRQCfeZuv64yEy+XC9ddfjyeffBLHjh2b9XlSqRRLliyB0WiE1+udNoIbHh7G66+/DovFwiebx+PhdiGXy/EOg1wux2AfnYTA5E1it9vh8/kgl8sZ3CPiC3Ea6OaIRqPQ6XTcOxPAptFooFAo+IYhRqBCoUAymWREnjgYsViM7dKDwSAGBwfR1taG4eFh7Nu3j8d7NTU17HhNYCBVKvF4HAsXLoTD4WB8hHZgEK2bsA6VSoVKpYLu7m6kUinEYjH4fD4cPnwYExMTrPmgRKhQKDA2Ngav14v169ejVCohm81CpVLB7/cjFotBLpfDZrOxnXwqleIxZTAYRCqVgsFg4N0fdDpbLBbodDr+7AKBACqVCuMTiUQCqVSKTXZ//OMfzyjVbm1tRVNTE0KhEJqamnDkyJFTnk4QAHq2x/uK+XjZZZehVCrhnnvuOamVmVwuR0NDA7sLVYcoinj55ZcxPDyMUqkEq9XKQJvZbGbbNfrlE8BE+yvT6TTS6TS0Wi0ymQwKhQLS6TR/H9ojQZLs/v5+aDQa3plAp288Hp+yiFWj0cBqtSIejyMajfIIkQC7SCQCo9GIxYsXQ6fTIZFIsLM1jTYPHTqErVu34rHHHsOf/vQn6PV61NfX8w0lCALK5TInTKPRyJRsMpnJZrMMFC5evBjt7e0YHh7Gq6++il27dqG3txfBYBChUAiCIPAWqEBgEqJSKBRoaWnBsmXLUFtbC4/Hw45VDoeDzV9p6pDL5WA0GqFSqaBSqSCRSHgaQZUFCcyoLUmlUkgkEhgaGmLdi1QqZRKUw+GAz+fDQw89NCMJSS6X484770Q+n4fJZDotMRTpWc7mUSXwPkoMGo0GGzduxOOPP44jR46c9LkEHOr1+mlqw4mJCWzbto0puISKE8pMpydhAZQgiMJrt9vZuzEWi8FkMvGYTRAEqNVqLFy4EDKZDBMTEyiVSsyMpEkBTTTI7o3QeKvVCqPRCL/fj0wmw+NLOjUjkQg0Gg0ymQxLlYmVqdFoIJPJuPdPp9NoaWnB1VdfjY9//ONYsmQJsyoVCgVGR0d5vCkIAvfLJpMJGzZswIIFC9DY2AiHw4FoNIpIJAIADMBms1kEg0EEAgFks1le/qLVajFv3jy4XC709/fzzWuxWKBWq2E0GpkHkM1mEQ6HUSgUIAgCBEFAMplktikpL4vFIpRKJVcstKU8m81yS0WCNLPZDJvNBq/Xix07duCVV16ZEQtoa2vDggULIJPJpi0SOlnQdXA6C5T/GvG+8WNYvXo1JBIJ/vCHP7ypeKWpqQlutxvnnnvuNHR69+7dSCaTsNlsSKfTUKlUrLAkkQ+RhAiVl0gkcLvdLKcmKi+pKrVaLUKhEEqlEmKx2JRN1PX19QwqWiwW5PN5BINBWK1WWK1W5jAUCgUeeZLWgiYbZrMZ4+PjKBaL7HBESL9Op0NDQwO8Xi9rK0qlEoxGI+bNm4clS5Ygk8lgZGQEnZ2d2L59O44dO8Ykp3nz5kGj0WBsbAwOhwPXXXcdNm3axLwOssX3er0YHh5GPB7nk7/apo4WC0skEtjtdr55SBVJGEMkEpk2BapUKojH42x4QxyQfD7PnzdNhqg1k8vlcDgcnHSrvR4kEgnzTh577DG0tLSgvr5+ynUglUrxoQ99CL/61a+waNEiZoO+WZRKJSQSCa6QztZ4XyQGlUqFD33oQ3jyySen+RMQUk0lPyH5CxYsmFYtZLNZHDx4kHtZKmEB8IWn0+mm9LREpKExG3k62u121NXVIZ1OT7mgh4aGMDY2BrfbzWM4upiJOyKTyZg6TacdjeMInyBcgsrtfD7PbU5NTQ0CgQBKpRIaGxtxwQUXQKfTIZ1OM3lp48aNTO/W6XSYP38+5s+fj6uuuopNUlQqFaRSKVKpFEqlEjMKT0ym5LsQDodhsViwfPlyZDIZHDx4ENlsFplMhp2YKKmGw2FuVchen4DCRCLBCZWs+QjYtFgsKBaLsNlsKBQKSKVSXEFUKhVYrVamT5MRr1arZcCyehVeIpFANBrFnj17UFdXN831acGCBTj33HOxY8cOtLa24vDhw9OuPTLfoetLKpWykO5sjvdFYiBV3YnGHA6HAwsWLMDu3bsZczCbzTjnnHOwYsWKaRfCwYMHMTIywvPxUqnEykcaOZLGweVyQaFQwOfz8VyfwEmHw4FCocA2bQ6HA3q9nolE1adtpVKBRqNhFWU4HIbH4+EJBM3po9Eon45arRaiKCIajbKNGW2Aptc9MDAAg8GA5uZmNDY2QiKRYGhoCGq1GjU1NTCZTKxiLBaLTMQKhUJMM6b2h0Re9Hqp3aGKgKomlUoFjUaDQqHAuyKOHTvGCc1kMrGd3fj4OO/MIG0DSdQTiQSMRiOkUimvmKMblxINTQ1cLhdisRgSiQTMZjOKxSITz2iiQxOKdDrN75lOdrfbjYmJCXZdqg6pVIpLLrkEwWAQhUKBR+CUhMrlMurr65FOpzE6Osp8FaKOn83xnk8M9Mvbtm3blGpBEAS0tbWxuSgwOYrasGEDVq1aNY02XCgU8NRTTyGZTMLr9UIul/MSFypZiZhUKBRQKpUQDAbZm5ESBwDuscnJiaoGlUoFr9fLr5u0E2q1Gi6XC+VyGePj47DZbAxeJpNJ2O12vqCphyX9A7UZBA7SBUsYCmEkLS0tPFY9cOAADhw4gPHxccY99u7dy20GjVjdbjcbpzgcDqjVajQ3N2PevHnctlx33XXQ6/VQqVTQ6/WIxWLYv38/WltbedRHsnMSTBGZiXASu93OHA6ifNfW1nI1ZDAYeBQpiiKCwSCvwaOEpNVq4XQ6efJQ7QpFr4FITwaDAclkkn0ciIV5YmIAJunNixcvxujoKIxGI5O+ADB2QqY85XIZ+Xx+ysbxszXe84mhsbERHR0d+M53vjOlB6SV9aQNACY1FMuXL0dTU9O0aiEQCExh+M2bNw+9vb0YHh5m+zbaZkyMRKVSyeQaunEJeCTwUKfT8felE5NO37GxMa5KdDodAoEAA2r5fB6pVIpPTalUCqPRCJ/PB7PZDLVazd+rUqnwGJG8IklDQaNLeryrqwtHjx5FNBrFyMgIwuEwA6j0vkjCXd1XE/gnl8uxdOlSbm2CwSAuueQSbmGItBWPxxEIBPjkJ3CU/CYAMKuTqOP0d5PJxMxK+swCgQAWLFjAJrrU5lRXX/S5q1QqJBIJHmdGo1FuXYhsRXyTVCrFJK8TDwuKZcuWobOzEy6XC+FwmFWTUql0mtFwJBLBgQMH0NzcjL17974Tl/gZifd8YrjooovQ39+P3t7eKY+TZ0Fvby+P/Gw2G9xu9zTSiiiKOHjwIJRKJRwOB2KxGEuhiX1IJSKdpsTMo4tZJpOxNyE9plQqmcpMWAIwKcWm01EmkyEYDDJZqXorllKpZIJPOp1mPgMtxjGZTKxfoLk+lcikOSBNx+7duzExMYGJiQkMDQ2xpRr5PFCLQMxNck6q/owoYY2MjLC4iTZ1ezweuN1utLS0IBaL4dixYwiFQpBIJOy2FI1GMTAwALvdDpfLhUAgwFMEhUKBUCiEbDYLs9nM0xVBEFhWbbPZMDo6Cr1eD6PRyBUHtTTEihRFEe3t7Zws6XMhmTtNl2jBsCAIjPsAwP79+3H33Xfj29/+NqxWK/R6PWpra9HS0oLOzk7+TCQSCerq6hj8TSaTKJVKeOyxxzB//nzYbDaEQqF3+Ip/Z+I9nRgUCgVaW1uxfft2xhBkMhkWLFiA5cuXI5VK4dFHJ5ncEokELpcLixcvnlYyxmIxvPDCC7ypeHx8nJlxNBKkE9tutzPfnsAvovKSzoF62EgkwqcbJYlMJgO1Ws1gI5XDVGLH43EGMWtqahCLxaDT6WAymaDRaFBXV8e4A53uRHKistxut7OgSyaTobu7Gz6fj41niV9ByYwmHw6Hg5fezLZohrAA0lP4fD786U9/QkdHB1asWMELaLu6uqDX65FKpXgi4HA4+P2SkIumDZQMCGCMRqM8HSIcJhAIMPWZOBq05o/8F+RyObd0arWaAWJqt1QqFStf9Xo9/16SySSDk7/73e/w05/+FDabDd/85jchCAKWL1+Ol156iZ8PgCcp9PumSCQS2LNnD2w2GwvkzrZ4TycGkjxXqyhbWlrwgQ98AGazmbUOwOR0Qq1WT6sWKpUKXnrpJRbfFAoFOBwOxONxyGQyBjOJ0+D3+7l8pRaFQDHCMggDIBCMFJeVSoV9HMkrgEp08jUkMpJOp+OfqVar2T49n89jeHiYMQ/yIaCWgRaz1NTUwG63Y2BgAIVCAdlsltshYgISPpFMJqdYqxHyT6cqBblaEe5CnwMtjO3t7cWKFSuwePFiFAoF+P1+1inQhiqbzYbh4WGeiBDfg3AK+uxIWenxeHDkyBEGO8mKnnQq9NlRAqXKYGRkBBaLhSsWnU7HCTeZTLJvA/1uqRIEgPPOOw8//OEP8V//9V+4/PLLsWrVKrjdbixbtgxms5k5CqIo4ujRo+jt7Z220q5cLrNs/GyM93RiIAPQat4C+SHQLJlu7Pr6emzcuHHaevJcLod9+/bx3LxQKECj0fBojUZlRKQhJh2RgIjmTOU3qShNJhOPG2UyGXp7e9n2nDQJyWSSjVhoeQpNOChJUStDwJbP58Po6CisVisMBgPjG3K5nDkAALi9mJiY4E1X8XicS1viSJDBbCqVYuMUIkRJpdJpVODqzd30fPIeCIfDSKVSUCqVrCchLIAk4iTYAsAbuQn/INESkbDIwg0A4wVmsxkymYw5C4IgIBwO8yZtwjgo6HuRCMzn87E+RKFQIJ1O8wFDFcOiRYtgNBoRCATwH//xH/jd734HqVSKtrY2WK3WKeSlkzFs3+0iqndtNDY2svaf4vDhw9i3bx9EUcSxY8f4l2O1WrFixYppOyJ6e3uRTCZ5pAiAN0MRdgBMMiITiQSam5uh1+t57k6lNZW3AHhnBPkb5HI5NDQ0sAM0LZGRy+VIJpMYGxtDNpuFx+Nhzwa1Wg29Xg+TyYRUKgW/349jx44hFosx9Zf8DyQSCZvNhkIhRCIRriwymcyUG7HabIZaILI7p7LfaDSy7Lv660hYZbFY2O6eQD5C+4m/QB4MVBmQbX6pVGKwk4RSVAml02n09/dzQqckQlJt+qzpPdGiIJlMxiNXhULBv0faG0oaEIVCAZfLxYpREpUpFApOsMDkhu4rrrgCwOQIm64v2kh+YhCpbKY4G9sI4D1eMXg8nmkCqFKphGPHjsHtdvONSjTkEwUzoigy98FoNDKwRyUtldipVAqNjY0scAqHw+y1UCwWMTIywhMBGq3RTUVsv3g8zvJqmjIQik9CHyLq0IVGyWH79u2QSqVYtGgRALDvAAGsNNUgXEAqlbLYSCKRYHR0lC3aSXxVPS0g/0piCRIhi9oAm80Gk8mE1atXw+fzsXPT6Ogoj3DpBM/lchgbG0OhUOCbmUabVFGFQqEpbUw4HOb1cw6Hg7UfMpkMbrcb5XJ5ShVA5Tm9V1J/kkyb3LepSiD8IZPJMJ+B+AikVg0GgxgfH+dlt7fddhsefvhhHDt2DK+//jo2bNgAu92O+vr6KcpdiUSCpqYmVt6+W+I9nRgAzGi4mclk0NfXx30fzd9PdH6m7UVqtRrxeJzFO1Ra081ORJlyuQy/38/jPLPZjEwmw2PKYrGIRCLBJXA+n0dzczPK5TJ8Ph8j8+T6TAxHm83G40wCtqpPUYPBwL21XC5n/UCxWGQXanJ5ol6dyndKUi6Xi3UX1OKQSpTKcAI1iSFJ1nUk2Gpvb4fNZmM8JBwOs6kMLaElnUIwGITT6eREEwgE+ESmFobYgaSFcDgcUKlUCIVCTAkn/QMxMGmBD40ZSaQGgKshMr6pdoeiVoEqGeKplMtl3v5FO0ilUinWrFmDb37zm3j++ed5p6VSqcQNN9yALVu2TPHsHBoaesuO0F6vF4sXL4ZEIsHOnTv/YhqL92xikEgkWLVqFYNk1VGpVNhFGAD0ej2am5sZraZIpVIYGRnhC5bAu1QqxTsSSZNQXWKTRoFuKtpFSeYltDEpFArxjUG+C0ajES6XC5VKBePj49wvJxIJBsgATNk3QdOFSCQyxfiF7ObJrs1ut0+ZGvT29kKv16OhoQEKhYInFYTQ63Q6XoBDkvF0Os36B5vNhrGxMfaLoNKe2hUyThkfH+f+nshcRqMREokEXV1dPLqLx+O8UapYLLLoqxrVp2RMIDFxHih5EpBJE55yucxJlGjZVquV6ebxeJxxCBp9AmAeCuENqVQKhw4dwrJlyzg5fOlLX8Itt9wCuVzO49z29nao1Wr+PQGYNSlQG3Xi9UmhVCqxefNmbN68Gc3NzYjFYvjSl76EXbt2neJd8NbjPYsxkOFIX1/ftA9eFEUG2SQSCfR6PWpqaqZ9j+ryj55XLpd5rwEBdASy+f1+pj1XqwiJL9DQ0MAqRTJWpWkHbWemcR4lmtraWjQ0NHCrAkxqFzQaDdN/yRWZGHo0BiPQk0poOoEJMPR4PGhqakJHRwfsdjtqamoglUrR2tqKxsZGLFiwAMuWLYPD4cDq1auxevVq1NTUYMGCBawloDV64XCYWyBiMVL1QMzQ4eFhTqg1NTXsbkUVFt2wxJ0gYRgw2b9TxUN9fCgUgsFgQF1dHcrlMk8ZotEotwfEtiRAlFoWSlREx85ms2xJT79fEr0R3pNIJPDwww/za5JIJPjhD3+IJUuWYGBgAMBka3iqkwaTyTRN1n/idfrKK6/g3nvvxQsvvACHw4Gf//znvAn8TMZ7tmIgKTDpEaqjpqZmimlKtUKyOjo7O6FUKvkUFUWRx156vZ5VgURsIqs2AiVJO2AymZBMJpFKpeD1ellOTZUBfU8i8ZCgighRdIplMhnY7XYepxFjkdoVqVQKn8/HlQGxAum10QZoukkWLVrESXJkZAQejwdtbW0QBIEnJBqNBn6/H2q1mhF/ojf7fD6euhBRCwBqa2sxb948BjepJKcqhCotomMT/4LoyhMTE2x/J5PJ4HA4YLFYmBZNjETCWaoFcDS58Pv9kMvlcDqdLCozGo1Qq9UsAdfpdPxZq9VqBINB5kmQ0Y7ZbOZkPTY2hj179sDhcOBv/uZvUCwWceTIEQSDQX4NtFJvNgeo6qD2crYoFAro7OxEV1cXHnnkEfz4xz/GN7/5Tfy///f/cPPNN/P1eybiPVsxEJB24k5C2stAZZzRaMSmTZumZW6aMxPYGI/HeZxWvYOBwDeJRMInGfX35JFIvg4kbKKqgmzLaDkrMR1JBUk4RDKZRCwWw8DAAHK5HJubUNXS2to6ZW5P5bXFYuGV8el0mqcX5LmYy+Vw+PBhRCIRmM1m1NXVcUJobGxEW1sbzGYz6uvrp4B0dMOsWrUK+XyeE8bExAQDdzKZDK2trTj//PPR2tqK5uZmeL1e3qcRj8dZdUhTEr1eD4vFAovFwh6Y5PhMegqfzweTycSgMrlMER6UTCYhl8sZA6E2jX4vdA1QC0eUcSKAEeZA1xABn2azGSqVCuFwGL/61a/g8/mmVDlUJVArdGKcOJUgDUV1yzFbEMmsv78fn/3sZ/H666/jmmuuedOvezvxnk0MVP4FAoFp82KagQNgBuGJ+AL12QTE0c1tMplYSERgI8maCcxMp9OcVIiCTMAd7YEgARNNGcgKjW7gdDrNjMVwOMxehoQdEJWZnKTy+TzGxsYYJCSQj04VqVTK/AG6mchV2el0Ys2aNUy3pjYnGo2yQzTxNQAwIYgqpmorOuKHxONxmM1m6PV6NDY2YuHChfx/0ovE43HY7XZWmtJ2K2JskmiMNnZTy0aMTBqPEsuTWjiyxKNWhBIR6RhIE0FVC1nrxeNxpkVTJUaWe7ShnJI+AZR33XUXDhw4wGYtMpkMy5cvn5YIqFKiMJlMaG5uPmkrQa+lOhKJBP7t3/4NyWRyVu3GOxHv2VbCarWyrqE6iC1YzU6rq6ub9vVUFRBvvrm5mUtQKttphEVy4lwuB4fDwXwEugnD4TDLn6PRKGsDYrEYCoUCPB4P6urqkM1mmcxErQaV6KSGrPaVpP6drNRo/TvhG6SWrFQqPNZLpVKoq6tjXQYpCKl8p9eWz+dx9OhRHukajUbeh+F0Oln2rVAooNFoWFtBHIT+/n5otVoUi0XU19ejXC4jHA7D5XLxpi6/3w+ZTIb6+nreoCWVSmGxWDA0NASFQgGz2czTkkAgwDeE3W5HKBRifgaZrgDg1okmR+RFQSNY4jKQxZzFYmEsKB6PM/OTRsSEkeh0OtTV1eFTn/oUu4YTU5VCIpFg8eLFMJlMU0p9k8kEpVKJUCgEpVKJhoYGGI3Gk/IYqOUNBoNTHs9ms3jmmWemGAu/0/GeTQzEkT8ReKxeDwdMsiNJ6lwdpOcnQKu+vp5HarSCjYhIxLADwH00laUkbCJbMpqhk0FIJBJBoVDgvpZuIppsEO3aarXyqJAUhxKJhFWUmUyGvQfoZpBKpWhoaGClI1UEZF5LFyVdeLQYh3wfCKeRyWRob29HV1cXVyckmKI/U8KVyWTQ6XQYGRlBX18fGhoauAoinwiyn6fWZnx8nMeewOQNQTgMyatDoRCLqQBMYU0SwFooFHivJ40vg8EgzGYzjEYjzGYzcxqIdk7aCtKD0I1OFSPhILRyb+HChbjgggtOutTW4/GwnT8FmcsAky0KJfATb/oTY+nSpXjxxRenMUyJCXqm4j3bShBIRhcSBfXHtA/AZDLN6ARMxBuSRxMfn07O0dFRLi9J9JTJZBAKhXgb9djYGGKxGLsSkYiJXIeIXl0qlXjERx6I0WgUoVAIarUaCoUCgUAAg4ODLBU3m81sXEpjVAC844GMVsTji2e7u7uZwZlMJjE4OMgJhVbH2Ww2XhDrdDphtVr51CRqMI0l/X4/dDodamtr+b12dnYyD6Kuro5BQKJFU4Kqr69Ha2sr60n8fj9KpRJsNhs0Gg1XMWTcSkQsaofImZp4CmTEQi5aTqeTzWtJfFWdFNPpNEuriSlJr4/aIarK6PohPQnZzFOIooi77rprio9oS0vLtAOJWjO6tihJnMxmsFKpYOPGjbPazZ9J1uR7NjEAmJGeCkyeNgT6NDQ0TLNwA8CUZhI6EYNOqVTyiU9bq2k5DI3DqPSl0lupVKJQKCAUCjH7MBqNstKSbhhqQVQqFYaHh9HT08MlLY3jPB4PL4clLCOVSmFsbAzhcJhvbAAsfKKRaywWYxScJM209JZWwCeTSQZu6aYLhUKM2BPjUa1Ws6TZarXCYrGgpqaGpwBarRZ2u51Hs6VSifkbRNbasGED2trauKUym83sdkQ3eTqdRiKR4M/Y4XBAqVQy1kNtAjE5iQo+MjIyhfVJjEqq1Mjhm7AIp9PJP58MfSkJZbNZSCQS1NbWoqOjY8qOkf7+fvzzP/8z7r77bn7MaDTO6C5Onx+xY48dO3bSqUQqlYJarcbmzZtPWqGciXjPJgYi8BAuUB00bpRIJFi/fv20qgIAVwWpVIr1/sQqrFQqcDqd8Pl8kEqlU3wLiQlJ4hwS4FBLQDcJjbMI6KKFtxqNhm9Mkm5rNBo0NzezlRrpKYDJ5EfKTeL3E2gVO77iPZFIMLoPgNmCdKGSacrQ0BBPW4i0Y7fbGaxVKBS8l6JSqaCnpwfj4+M8bly6dOkUGjH5J5CTdDAY5NOZKNuEzVByIB9HrVYLm83Gn7fBYGAXJNJv0OdHRiw09SDKtclkYrFZIpFgMxhiVpKmhRIvuV7L5XJks1lks1n09fUhGo0yrdvpdE7hKRw4cIAnLNQK6fV6tLe3T7meBEGA3W5nElxnZ+eb7k5NJBI4evQorrnmmhnb3TMZ79nEQCDaib0ZEYfoQmtoaJhR4EICJnITJu1CoVBALpfj0ywWi8FgMLAnAp1O1K/SjUIbl2OxGLRaLRoaGrgNIRo02cCl02l4vV52iI5EIkgmkwy2EcWZwEQ6jeVy+ZS9l8FgEMPDw5BKpbyUlyoXcnmiFW7EeSDTF/JcBCarp+rxIpGqqsVasVgMyWSSWZFEOycREtHK6TMFJkFCg8HAmEkoFGKCEX0PklLT9CaRSHAiFwSB+3+ygSc5NwGRNMGpNpgh8lQikWDAl74Xyb8JRCYLPfJ6OPEQoZNcrVZPMettbGycsliGkgZdj7QD9GRRKpXwxhtvwGQy4eabb55ViHUm4j2bGIg2e+JKc+IXEP13JmITADYFEQQBDQ0NfCpJpVK2FiMRDjEnScmpUCh461MgEGD0nU4mQRB4YkGmJHTz0Jo1GncCf95FQMg9MFmuUr9L691oNySN3ejfaQO3VqtFb28vVylkX1+pVHhkW6lUeNEL/cyamho4HA7mOQB/Birtdju7OtPyGnKIopaDyF70+dN7cLvd7JEQCoVw4MABqFQqOJ1OrlhaWlq4VTGbzQyI9vX1YXx8fMqkhpiqZOlGZLNKpQK9Xs97Nwg8Jo0FVTikg6GRJ1UTlETpv+q45JJL8Mgjj7AmhGLNmjVYtGgRYwm0QmCm6vRk0d3djX379uHjH//4ae2veLvxnk0MhFqfuIy2XC7zZIKs2mYKcvUhfgAh2HTTkGcC9bHk80A+jaIoIhKJMJnIbrfD7XajUChgbGxsypJW0im4XC4mStGNRAxLWiJDY1Q68chYhU4/Ii4ZjUZezlK93o1AVdIfpNNp5mjQxR2Px7ndADBFbESvl8awVCnQQhw6kYmHAYDZpzS1IA4I+RuQxoLoydTXl0olDA4OYnx8nCcNdrsdDoeDJwdWq5XLfpJ7k1kuvT+y0qffJ/FTKIkRh4SqLToEamtrGeClx6vxBfpsVqxYgYceegj/+7//y4+vWLECS5cuZeBQpVKhqakJBoOBmamnEslkEg8/PLlg/kyTmqrjPTuuDIVCiMfjbOxKpRyRYugmnW0paSqVgtVqRW1tLYLBIPL5PFwu15Q9kwaDgftW0v1T20EVCbHjCNMgExVqIUj9KJPJeLcCbZYirIKmBzRJIeIW0Xyp7B0cHIRCoYDFYuEFNiT99vv9PGUgFiM5JZPFnN1ux8TEBFu2E6eCsA5iAQKTY163241QKDRlpwV9DsSgpNdOnw0RhJLJJLdXZrOZv57wBo1Gw0t9SEtB7R+Bg8RY7O3thSiKXAnQ8l+qjGjrFS2vIb/Malt+umbI15KmIsFgkHdbqFSqaYmBPguJRIK7774bn/rUp5iLsXz5cvh8PgwODjI+RBOb11577U1bCYrXX38dzzzzDD74wQ/iF7/4xYyK4Xc63tOJgXZCKhQKnvkmk0mMj48zgDRb3yaXy1nWazKZuMqgGT+N8MgLkE6qSqWCiYkJCIIAj8fDEmiaw9O8nhJLPp/n/pgsyIgMBUwCUFqtlkVWdNKTw7QoigzQpVIpNDU18ap4j8fDYFttbS38fj+zKGnrNMmYS6USy6ZJRk6zd71ez1+XTqe5LfH5fMxBIEBXEAQMDAygrq6OE4VGo0E8HmflI8muyUqtuqKgDdzk4+h0OjEwMMDJgHZZUolPtu40daDvQy5TRCFfvHgxKpUKCoUCt0HUPhDNnRKGVCplLIi4EblcDo2NjTMeJGRsW+39QToMamsUCgXrHoiTcqqRyWTw2muv4aqrrmIr/TMd79nEQMzAmpoaBtmAyQ+ZxoA0654p6MQaHx9nngABVYFAAGazmV2iCWCkE7XaR4CYdERIslqtSCaTXHVQyZ9OpxEOhxnEih3fa2mz2Rh7IDowVTMmk4mdowjspERGY0gSQFUzFMPhMOrq6lj7UF9fz25GZF9HpiwA2DtSoVDAbrdzuwD82SsTAEuqqTKplk0DkwAc3TCkiyDTV2pXaPxJrYbb7WZvRHK8ptOXXldjYyOPb+lxMpAdHh4GMAn2Ef05m81iaGgIoVAILS0t3NLRIULENr1ez20SveaZFs8sXrwY3/3ud7Fo0aIpEwuihtPvcXh4mAHj07V127dvH0qlEhYuXIjBwcHT+tq3Eu/ZxECLR1wu15SbXxRFzrh0ms4UUqmUd0xSEsnn8wiFQuwkRO5GROUlgFGn03GJTXp+Ij/RDUwTDZ1Ox8SXiYkJtLa2IhqNMlPRbrejWCxifHycdy6Ss/HExASPOalsp5uZTFzoBiXyEJXluVwO/f39fFMQHgD8eZ+D2WxmOzSNRsPfm3gRpHCUyWQIBAK8wIUIWMAkNT0YDHIVQGYpdPIplUq4XC4mnpGgyu12Q6VSsUpUp9Nx+0ftl91uh1arZYSf3q9CoYDT6UQsFmNtBG3UokQ2Pj6OSqXCzE2qXogOTQAuUatJnBYOh6dtt1YqlbjzzjunXUNarRYKhQK1tbWor6/HyMgIm++cbgwODmLnzp0z0vfPRLxnwcdyuYxXXnmFff0pyNK8+iSbKTQaDcxmMzPniCtQLBZhMBiYYksbn2gERieezWZDQ0MDtxOk/aeRo1Qq5VOavA9JWyCTyWA0GhGPx3mxjFarRUtLC1u/9fb2wu/3M2ZARqs0daFkRcrAcrmMvr4+DAwMIBqNcq9MICuNIo8dO8b4BakmiQVIlQxttSI7ODJ2pYkNKUeByQuaqNvUetE0YHh4GF1dXQiFQpDL5aipqeEJBHkkkBaF9oTSVINGuDQ2JpcnmogQh8Lr9fLJX01eIvUm7f0ke71AIIBIJMILdAn7IFEafcancuKbzWYYDAZYrVYIgsBGvieO0E8lUqkU/ud//gf19fUz4hzvtNv0ezYxAMC2bdtgMBhwwQUXTHmc2ILAnx2AZgqaPJASkLT7BoOBL35C3+VyOaP9qVQK8XgcsViM/RpLpRK3HzQSdLlcbJmu0+ngcrnYNcjpdCKfz/NWZIvFwtMLcomiSoRclEhXQLZmWq2WR4rj4+Ms4KrelE26CvJeMBgMnCyIr0HJgfYs0AlLpC76L5lMTpma0OlMGAC1cSMjI+jt7cX4+DhXYwT20eZtmuokEokpy3ppZybZ3xGmQL8vUnuOjIxwVVFdMY6Pj6Ovrw9jY2M8GaDdD9TKUPKRyWSwWq1wu92Mk5DB7Knc3AqFAhMTEzAYDEzgqp44nW4cOHCAX1N1SKXSGWn9byfe04lhYGAAL774Itra2qZUB9lsFmNjY/B4PLOWdbR8hU4jMjqhU2V0dJRtyckqnU5vi8XCrQxd/ETfpX6ffATpAiNiEYm2lEolr6YvlUro7e3FyMgIC7lo9EcehWSoSpZ1MpkMdXV1qK+v5xOa6NS0aJUQc1J4EruRTuzY8S1QNNajDdHEKgTALkmtra3cv9fW1jKPgPwuiSFpNBpRX1/PFZLD4YDRaORRYDQaRU9PD7q6uviGJYzI5/MhGAwiHo+zjJkMdonIRFgDtXVkJ0d2/dTKkYCJqj+SaBPPhDAHojADYM8Gl8t1Sie0Wq3GwMAAvyYihc1G1X+zCIVCeP7556fJrSnRv5Pxpq9QEAQVgG0AlMef/6Aoit8SBKERwB8AWAHsBXCTKIoFQRCUAH4LYAWAMICPiKI4+I6+6lOMfD6Pl156CWvWrOHeEfiz8QWV2DMFAVhkIFIsFlkuG4lEWHpNp6xKpUI0GsXExAQTi6g8pcqD2gla7EJ6CsIOCMcYHBxk3gONPoFJezOalFD5T5Jqah8I3KOkVm14Sz4HPp+P9RokBiPqeDweh1KpRC6XY9yBBEFElyYREJ2s9D5GR0eRTqfZWJc2Z5GbEoGS/f39GBwcZBIZUcYlEglLqwlgJFyAtA001TGZTHwSSyQS1qnQwh+DwcD0dHqNRExLJBLckvl8Pk7OVIUlk0m+XsjrgaTZarX6lE/86t8BaVGIJPdWolKpYOvWreyuXb1acWxs7C19z9niVN5hHsAmURSXAFgKYLMgCOcC+B6AH4qi2AIgCuBTx5//KQDR44//8Pjz/mqxa9cu2Gw2zJ8/f8rjpCOYrZUg4g3tGrBarby+nNiUdMLSpILk08SYLJVKcLvdvNEImJSDkx8A9ePEvyeilFQq5UWt4XCYMQGatNAIkRh/ZG0/NjbG/gbZbJbBReIVkDkLXfBkYJrP59HX14ehoSF+76OjozwCJeoy0cmJLUo3L9G43W43UqkU+vr6WAVqMpnQ1NQEp9OJ/v5+vPLKK9i7dy/C4TBqamrgcrlQX18PtVqNUCiEWCzGlmwKhYI9IIPBIFPKSZhG7kuk5SCSFbEnSXBFztiUfA0GA6tSyZ/B5XKx5Lq2thZNTU18E1PSMZlMp6VZqE6adChptdoZ/UVPNahyIoxDrVYjFou94xu03zQxiJNBhvjy4/+JADYBePD4478B8IHjf77m+N9x/N8vFP6SJO8TggxI169fP6WEoxN3eHh4RiCJGHjEnkun08wepPXmNLYjrQAArgaoHCXTFWo1qpFwmqvr9Xr2ewgGg7wMl9awEfBHGggSaBFwlslkeOJAOATNyakioRKeSnxigBKbkfpf2kVBZCGv1wubzcZVCtGGSTlK41PiAhAVnRIXiam6u7uZBdrS0oL58+dDqVTCYrHA6XTyZzk8PIxQKIRkMolAIMCJlGzQyEOSGKG0l6N6nKtQKPj7JRIJNmQh8I/ARmovaZkQuWmT76bL5YLRaGSCXFtb2zSK/cmiWodCdnGiKPJuircaxKwFwAfCO73V6pRenSAIUkEQ9gMIAHgeQB+AmCiKJAj3AaA0WANgBACO/3sck+3Gid/zNkEQ9giCsOdtvYM3iVKphMcffxwrV66c0odRKb179+4Zde1yuZy9DknRSD6MBCoKgsDUYDqtyBmafCBJ209lLRFeCN3P5/Po7u4G8GfhF83bGxoa2LdREAT2GVSr1exA5XA4oFAoYDAYuPSnxEVjQGDyIiUqMS3fJRyFpNVUCYiiCK/Xi0QiAZ/Px0AijSyp4qmvr2dDHDJNdblc/DmRZJpo05Sc6uvrcc4558Dj8SCTyTBuQKY5hClEIhEMDAwwdd3pdEKv1/ONTOxNEn9ls1n2ZaBEFQ6HmT49PDzM1VJfX9+UarHaCIbGrgTCUgV4ulZqpKQ9dOgQt3QKhQKXXHLJFIHV24kztebulBKDKIplURSXAqgFcA6A9pN/xSl9z1+IorhSFMWVb/d7vVns2rUL6XR6iu02jbwI0T8xBEHA+eefz6W2w+GA1WqF0+lkdSb1pOTapFAomLdPJzYBYkRSKpfL8Hq9TIs2Go0IBoPo7u7mkSiBlETrJptx8kMcHx+fArCRwazH42HRU3WSogrCbrejrq4OTqeTZcgkciKVqNfrZXCUkiEBd6VSicVdJEOemJiA3+9HuVxm7CGTyWBwcJC9JURRRG1tLRYvXgyn08lmt9UlOmlaCK8xGAyora1FpVJBNBqd0ubkcjlkMhl2labXR5UAaSKogiDDl/HxcTa/dTqdLNZKJpNsEkzjaWpfyHNzbGyMKemnGjT5ql51X1NTg5aWlnd8vPhOx2nVM6IoxgC8DGANAJMgCFSb1wIYPf7nUQB1AHD8342YBCH/apFKpfD0009j4cKFU34h1LPP5tRLbkdDQ0MsHyb5Lo3JPB4PL4WpnvcbjUbo9XrE43HkcjlGzonkREnE7Xajra2NZ/zUTlDbQ67RJAYimq1KpcLIyMgUAJOk2USdJldqSjCxWAwtLS1s/EpjQkp0ZJxLjEhqFQhE83q9cLlc6Onp4RbJbrdzn05VmNvtZv0GvT4q410uF2pqapBKpRCNRjmhkLqTxnqhUIi3VxHnhABbALwZjFoRt9sNm83G5itGo5GrCOJ4ENGJdlmkUilEIhEmLpF/Ju37IE8ISsKne8r39PTweJd+l42NjSwQO5vjTRODIAh2QRBMx/+sBnAxgCOYTBDXHn/aLQAePf7nx47/Hcf//SXxTNU7pxHbt29HbW3tlHkv7Ynw+Xwzfg35H3Z1deHVV19FOBxmsotGo2EBFZWhbrebx5fkgehyuRiZp3Jy//797EhEOgjye2hvb2cKLhGegEkeg81m4xV4pVIJPp+PTyOSBJPdPZ28JF4KBALo6+vj+X97ezvq6+vh9XrR0tICu92OQCCA/v5+nm6k02kuremmI7MWo9HIqkVicGq1WnaycjgcPP4j6ziNRoOamhrY7Xa+2ZVKJdxuNwOhlKyJsBQOhzE6OoqRkREMDg6y9wRhGLFYjPELpVLJ40ZRFJHJZCAIAidTastozwclF+JQVGM5xLYUBAF1dXUndXOeLfr7+xGPx3mFgUQiQWtrK7tYnc1xKhWDG8DLgiAcBLAbwPOiKD4B4MsAvigIQi8mMQTytrobgPX4418E8JV3/mWffgQCAfh8PpxzzjlTjFtpOjFTED++p6cHR44cQVdXF4/DyJiVnJaAP1OEaTxFVmN0MtbV1XEVQfsTSCVIQqVAIIBKpcLybRrx0VSAxE1GoxEtLS3QaDRMlCKPhUQiwUxDcpumkR/ZrLtcLtTV1cHr9TLJymKxwO/3Y2RkhAG+UqmEnp4eZhLSKXv06FH2nqgmfAFgK/ZkMgmDwYD29nbY7XaMjY1hYGCAcQAyvZXJZGw+29TUhPb2dtTW1rLAiXZG0DYw0jHo9XpOdIRrBAIBblMsFgvb7wFgPQuRhKxWK3NMKJEolUoWTUWjUcZrqhW6pxq0LIi+jvQb9Hs5m+NNeQyiKB4EsGyGx/sxiTec+HgOwHXvyKt7B6NcLuPpp5/GRz7ykSmLPsbHx7F3715cfvnl075GEASsXr0av//971EsFmGz2VghSKQnAsPINZls5WkUJggCnE4nTMeXtNL3qWbdEXOQcA8yGCHgkDgCdLIBkyYnExMTPGcnqzKTyYS+vj7e0EzCLaIF+3w+tLe3o6amBvl8njkWNLIDgK6uLrZMo12RkUgEe/fuxf79+9nyrq2tjUtsQt3Jji2fz6OpqQk1NTW8/o2AQlJW0hiPxo608JcozaRmJbYmLZGJRqPIZDKoq6tj/wmXy4XBwUHmDVQqFUQiEWZJApMj6urkVV31kGybBF1U8fn9fiSTSdhstmniqZMFcWVmenymfRFnW7xnRVQzxfDwMO856OzsBPDnNWDUIpwYLS0tUKvV7ItANya5MpNKkgRCZE1GCkiSVFNLQFz3gYEBPgUdDgffqLRTkbj55Efg8/ngdrvh9XqZowBMWpWHQiEMDg6irq6OkxMJiurq6thFynR8CzThEFRGE2ZBa+rF42vrHA4Hsw+z2Syr+ogCTlZ0tPqNRpiE5pODEWEDlECJSk2tmlQq5baM+AS5XI7t5GgBLmk/SO9A7lc0utTr9QwI0yi3WmAllUqZ3kxkLYfDgcHBQaaH02dCJjJer5df+0wahdliYmICo6Oj0x6ndnIuMZxFkcvl0NPTg8WLF+PIkSO8k/DAgQMIhUJ8YlZHa2srmpqa2OGZkG6DwYDh4WHI5XK2SQ8Gg8xh8Pv9bORCZrJ6vZ6l0WRdRiw/n8/HUwCaeBAgSRen1+vF2NgYxsfHMTY2htraWuYdEAWbSEEkEZdKpexApdPpYLfb2fGpVCoxKEp7GCQSCZqbm5m3QaBhMplEqVRCfX39FH4GJYdCoQCfzwedTgev18vGuAD4JiVjFQIU8/k8t2U0kiUAkhIHgZ+kOCVzXJqc0Jo+0i/QDgrijQDg10cTDUqeVKlQhUBTBDLMIQk3jZlPJ1577TWWfFNQVUmqzbM5zu5Xdwais7MTK1eunDKTDgaDsy4INRgMuOiii9DU1MQnKK11p2qARlwul4uFUuSVEAwG2bnZ4/Gw70B9fT3cbjfq6upgt9uRyWS4dSC2HiH1KpUKSqUSsViMR5NECqL9mZlMhtWK5MDc3NzMhjE0XiSmIADeUk2uzFSWE59g8eLF7BVBpKNCocDvE/gzHySfz8NkMqGlpQVNTU1YtGgR04dJ+0ELdqo3elN1QNMGqgaIW0E0bjJypRvV4/Hw+LimpobHl8Q7oAkEfT6UzIkjQSxQUqhaLBYeOVPVQ4mD9nuczim/f//+aUIrAkDp9ZzNcXa/ujMQExMTUKvVsNvtU/QB27dvn0abBiZ/meeffz527drFM3y5XI58Pg+bzcbLbmmNmcvlwtDQELcapNojJSTdfHTD0NiMBD7kKgSAnxeLxaBWq1lHQNZnUqkUIyMjzH6LxWJwuVyMepOk22q18riTWInAJB5APgp0KlavmiczF1JV5vN5WK1WtLe3cysyMDCAsbExuN1udHR0AACrPyORCJqampDP5/kGpHamr68Pa9asQT6fZ9+MdDrNK+nod0PVTSqVgtlsZlclem979uxBf38/bDYbM0JpYSy1EalUioVP5IBNbVexWOSWz2w2cxs0MTEBpVKJtrY2eDyeWZe+zBTi8S3rJwYJ7MhT8myO911iSCQSGBgYwJo1a3Ds2DFmp7388su46aabZvRoaG1t5fXsTU1NcLvd7GNYvSaeWgDCFOrr65lpVy6X2WSVvs7j8SCbzXIvSjqMmpoadi8mqzhacAuA7cVoL4JcLkdLSwuPTYlURWPN3t5eVjkmk0m43W6MjIywhoNIVdU4A+2pIFflxsZGyGQyRKNR2Gw23kDtdrvZqk4ul/PNXVNTg6GhIeYwUNvS1taG3bt386lJmopkMsn+B1T2U+XU398Ps9nMbYhSqUSxWMTo6CgDkS6Xi5mfZPFWrREBwK5XiUQCZrMZQ0NDvGOCKhYSZtECY6KTn2jOcrJIp9MzuizRSJn4MGdznN2v7gxEpVLB9u3bsXz58ilMttdee21WQZXp+GZimrUDYGIQ7WOoViASWDY2NoZIJMIaC9p7STsTyM9x3rx58Hq9TFOmlqG/v5+nFFSRyOVyTgxkfUanHRmPVC+2pWqFbgai+pLwisaYxL8gUtTIyAgLuqgkJpVhKpXiE1Gn0+H888/HvHnzmErsdDpZj0HJwePx8ONmsxkNDQ1IJBK8KJYmMaVSiYlJVKV4PB7mP5CjNGk2HA4HWlpauIIhJiW1AdUbwmizllqt5nV1hGFQ4iLqN7l5x+PxaUtm3iwikQj6+vqmPU7yeK1We9a3Eu+7xABMjuNUKhXq6+v5sfHxcezevXvG56tUKixZsoTZj6Ioor6+nkeXxBIkMI6k1tQTkwyYdiMQS5K8GmtqarjEpIkASY5pREYqSqVSiaNHj/KuChrp0ena1NTERB9i7JFnJQBuDajPrt5VQcxLMkchM936+npeCUcTERIb0YYpuokMBgOkUimOHDkCqVTKkm6JRMJtEPlhDA8Ps1NWOp1GbW0tDAYDampq0NTUxKQjEryRWIt4GbQNu7a2FolEgtWf9F4JvCQMhLgN8+bN4/dFhjXVACyBzOTJeTrCKWASX5jpkDEajbDZbOxneTbH+zIxJBIJ9Pf3o6OjgwGlfD6PgwcPzvo169evh8ViYWJMJpNh+3e5XM7tA00JaGRGZifVJCgaXVLPS2W0RCJhFycCAMk/oBqRp5k6sS7pZCdaMjkvETZAhiikISB2HwCmHtPrTSQSbMFODtaU/BwOB2sfiLilVCoxPj7O/hYkniqVSuyuTd4I1KKQOzZNXggoNRgM3Brlcjl2etbr9TAajUzkIjITSbpJn0JMRpVKhXA4zDoWmgpRawZMtgwrV66Ew+FAIpGA3W7n10sJzeVysbDtVKNSqeDAgQPTltoCk34atbW1zLc4m+PsrmfOUJD/4fr16/HYY4/xL3Hr1q34x3/8xxmJLHV1dWwyQs5KdNoSgk27FYnHQMQcj8czhXpN4zySa1czDUnOncvl2Buyvr6eBVRkoKpWqxEMBtnbkUA3GtvRNIPGp+LxVW90guv1egwMDDD1mhiChcLkclnagUHOxlR1uFwuZDIZPp0lEgmDdkajkRmfCoWCMQFiYTocDtZI1NbWolQqYWhoiC3buru72TMhEAjwdIf2XRC/gLwZaGs40ZVpqkDjSgIfVSoVPB4Pc0eUSiWi0Si3krTFCgALv4hMRlXaqUYymcS+ffumkZukUinWrFkDi8WCvXv3ziWGszX27duH66+/Hi6Xi8lCe/bsQWdnJ5YvXz7t+eTItGfPHjZCpZX1dKpQT5xOp1npSO1HMpnEwMAA5s+fz60EGaAQV0GlUmFiYoKdo7PZLPfLhNTTwpVKpcKnmt/vZ/xCrVYzoJpKpVjYRXZoVF5HIhE0NjYyhkFjRJvNxiBgPp9HQ0MDr2ujSkCtVsPpdDKdmFSeVNGQ4xVVLd3d3SgUCkwu0ul0sFgs3B7QSU++kqFQiE1votEor/aj1qlcLjOduZpQBYCrF1Ja0viYcCBqW4heThWKVCrF0aNHkUgk+PdP/o9EdjqVGBwcxMDAwLRWwWg0YvHixRAEAbt27Xo7l+5fJN6XrQQwCRAplUqsXr2af+mxWAxPPvnkjM+XSqVYtGgRzGYzn8QEsFHpS6voS6US6urqeCdELBbji5I8DCKRCPfbLS0tvOiFKL1E3yWaNJXeRLCi1wRMjh1p8Q1VAEQ7pi3dNPYkKjcxCcnfgQhPVqsVSqWS8QLCAGgvRvXuyUgkwp8dUYBp8QxpSIhT0NjYyMi+0WhkejZVR7T9iqYxZN1Go0SDwQCDwcBtFO2aIHUkTQ5IOUmbyakyoMkEicLI5o1+r+3t7WxFTxZ9AE5bI9HT04OhoaFpX1NbW8sTkn379p3y9/trxfu2YohEIujp6cGqVavwwAMPMOnnwQcfxJ133jnNlEMQBNx5552Ix+M4dOgQEokEGhsbGSCk05nKbNraFIlE2Gmorq6OkwJ5L2SzWWZJElhJlQQARslpPwIpBomGPDIygnnz5jFTL5PJ8Ho8AGwIU19fz+pK0h+QxkIikbB8mjQExBzMZDLsdaDX6/n9UbIjg9zW1lYoFAoEg0Fe7kL6DJJx025NAnDpcyEVKb1+cpSqNrbx+/1QKBRoaGhgtylSSZK9HIGjJHwi96tUKsXiKCJi0fIdUqCGw2F4vV4YDAZ236LR8umMFg8cOMAMSgqZTIa1a9di4cKF2Lp164wTi7Mt3rcVAwBs2bKF9xVQdHV14cUXX5zx+Q6HA5/+9KdhtVoRiUSQSqW4V/R4PKirq0NdXR10Oh0DZ3a7ndWHhUIBvb297IBsMplQU1PDlUO1mIhIQg6Hgxl7ZFVGOgg65UgHAYBBu2AwCL/fz5oAMlANhUK8F5OUizS2JNMTcm4mRSVt2IpGo0wsoq+hSoXe88jICLcddKLTDUar8MifEZjUqlDioT97PB44HA5UKhUmdVHbUalUmJ8wMTGBgYEB+P1+rjRosU51oqCdFwSk0kSGQNGxsTEkk0neCk6uVrQP5FQrhlgshi1btkxZP6dQKHDuuedi9erVkEgk+M///M/TWk/314r3dWLYu3cvtFrtFEyhVCrhl7/85ZSV5tUxf/58XHPNNTzL9/l86Orq4glFIBCAxWJhVyGyUaNlt+Q67XK5oNfreRsWqf5aW1uxatUqJkeRlJvMTGn7UjgcRiKRgFQq5TLZYDDAbDbz8l1iMhI/gMxlaG5PYB15D5CkORKJoLe3l6cpBGjSAppsNotQKASLxYLGxkYmOdEpTaIsaokoERAmMDY2hr6+Ph5fWq1WaDQa9PX18X5Ncrsifce8efNgMBjYu5GSKWlQCNcgkhaRxAiDGB8fx+joKGMkxI4kPIY+V6rI3G43ampq+PM6laBroToUCgWWL1+OFStW4NChQ+8KfAF4nycGv9+PoaEh3HrrrVNah1dffRV79+6d8WsEQcB1112Ha665hk9mmiwQ7hAMBtkaLRKJsMOTKIqoqamB0+lEbW0tTCYTb3Em8Q/tNyBcgUprsoujsWipVEJnZydXDzS1IJMYEg6Nj48jk8kwUYloxXK5nOnFkUgEo6OjU1bcqdVqdHR0cDIi8E6j0cDtdrPMWy6Xs4CKxqT5fJ5t2KmiogkL+TPabDY2c4lGo1wdEeBHfBCa9NCSIAJFaVJApi2Dg4MIBAIwGo0M7oqiCLvdznJ5u93OtHCyrSfyExGcSHFps9l4CnKqsWXLFjYFpiDjGbvdjp/+9KezHjhnW7yvE0O5XMbLL7+MhQsX4sILL2RZbTqdxv333z/rtiGVSoUPfehDaGpqgkwmw9KlS5mqS+IhIjSR6UoqleITnaTOdLHTKU8qRlId0t7J8fFxtLa2oqWlhbUXhNQTF4I0HGRoSo5PJBmnm48EX7Q+ntbOk1t0d3c3yuUyPB4Pj2LJayEWi7FCkMxSSOlIlmjkzky8CqKYU5Kj7VhOp5NHqoRlVJ/SRNKamJhg/AYAez+k02nodDpeKgz8mSJOI18CLqn9ovEpAK4kSO1IW8yponO73TwWPpXI5XJ45ZVXpl0zOp0Oq1atQmdnJ5599tnTvEL/evG+TgwAsGPHDvh8PmzYsGFK1fDII49Mk81Wh8FgwA033IDly5fzijm/349AIACHw4Ha2lo2QSkUCnzxkRDL5/NhbGyMtRtkLgJgyjYkIhnR3yORCBuwUAiCwBUKiaXUajVrB6hFcDqdvBTG4/Hwzkkag5L0mTwTent7YTabYbPZeEksUZzF4yvkRkZGIJfL4XK5uGJoa2vj703gH53OFosFtbW1vJmJSE3RaBQ6nY6BUVJNkpEuAbc0tiQ6OlVdZIdP28VJCk+Ky+olNWQSQ2xIcsei0bLf7+elOKdKXfb5fNixY8eUxzQaDT7xiU9g06ZN+L//9//y4qB3Q7zvE0MikcArr7wybSuVz+fDz372s5OWki6XC1deeSVGR0dx7NgxZLNZHD58GIODg5iYmIDP52MiEE0b6JQnII0ucALdEokE8yNoNEhKyYmJCWYpSqVS2O12NDQ0QK/Xs0KTphuiKGLhwoW8w4HYgOTRmM/n2RRFJpOx9wIxN0ulEvf6tPHZ4/Ggo6ODvRnJ5YgwhnK5jM7OTuzduxdvvPEG+vv72Q5fqVSitbUVVqsV+f+/vW8Pb7K8+//cSXNs0kOSpqc0SY9QLKcKqEUUGDBEGZ5gwOvGcDq3idNXX3/qu+nl3OVp1w5uY875gpfODcTTpiI4VBRRFETKsaWl5zY9pG3Spk2aHp/fH833uwRKW1SgxedzXVxNnqTpTfs893Pf3+/n0N3NhCVg0BuRLmBylzYYDNwponQtIkr19vay1X1HRwfb2UdHR3P9oLW1FV1dXUhLS8PkyZORmZkJk8nE2xuqa+j1ep60qSVL9GpanY0GO3bsOCUN6uqrr8bdd9+NXbt24eOPPz6j8/J84xvbriRIkoQ33ngDS5cuxSWXXIJ33nmHJ4Pnn38ea9euxcSJp3fLt9vtyMzM5EIYtc+am5vZno1YesRLoJoDaSrMZjNzCGw2GwfNkkTb5XKxESu9j9SQRJGOj4+HJEnc3aD8C/IzIJk4WZ1ptVrmPxiNRtTV1XEVnr7P7Xajr68PWVlZPFHQBUpELsrUKCsrY3clKgJmZmYiNTUVra2t3HGh+gutiqjVS63Y6Oho3i6QLR1J05OSklhDQlsDctAmopZOp+NWK4nNaKsVCATQ1dXFqxmdTsfsVWJcEvOTfl+jsYzv7u7GP//5z4gbS0JCAlauXInm5mY88sgj46ITEY5v/IoBAMrKylBaWopVq1ZFCGbcbjc2btw4bLKxUqnEtGnT2D2Zag20fNdoNCwxJmMSmhDS09NhNpvZ0YgMTfr6+tjenUJWADCRqru7G11dXSgqKoLP50NiYiLbv7eFAmxVKhUv9Y8dO8ZyaaJy0zKaCnVUkCTDktbWVjQ1NaGkpARlZWW8T/f5fOju7kZNTQ1cLheLwkjpOXXqVGRnZwMYbOGSIpRo1tSyjI2NxYkTJzhHk1ya6MIkZ2qSnft8PtTX13Mxk8ZK9O/c3FzOvqAgoLi4uAhyF21fqBgbruOg3wtpMSRJQnZ29qi2EkeOHMG+ffsizolrr70WV1xxBZ555plht6RjFfLEgME9/ebNmzF16lRcfvnlEa9t2rRpREKKzWbD1KlT0d3dzexCWnVQwY80A1S1J78DhUIBr9cLr9eLpqYmVFZWoq6ujkVJycnJ6OjoQE1NDZ/ser0eiYmJSEtLY10GeTHQBa7RaFBTUwO/349gMMhxdOQARXdZ8h2glQ11THJzc3Hddddh+vTpzFmgXE6r1cqrKKvVCp1Ox5brxMMg+TZZydPFrtVq4XA4oFKp0NzcDJ/Ph6ysLKSkpPA4qWZAxiukvaBCIJnnkudjeAQdFTeJok5J0+E0aOI1aDQaZoi2tLSgtraWbf7j4uKGtPobCq+//jq3jAHA4XDghhtugMvlwr/+9a8xr6QcCvLEEMKnn36K48ePY/Xq1RFFyIaGBmzatGnYP65CoUB+fj5ycnL4RKYWWCAQQEtLC3w+HxuIkBkLkYBiY2P5zkoXNbkIUUGPHI9JH0EcBKVSyXH2XV1dXNUniXJiYiKcTie3CanAR5Rs4k9QdZ6IPnl5ecjPz0d2djYcDgccDgcSEhKYqBXu4BxuoUZjSkhIYFEWEYqOHj2K7u5uuFwuBAIBZGZmRljK0YTQ3NyMYDCImpoaNDc3Q6/XM42afCxpGwIAvb29OHLkCGpqatjLglZegUAA5eXlPFmRhTvpPyhpipiX5NFJpKuR0NbWhm3btvFzIQQKCgpw8cUX48UXXxzSyWk8QJ4YQvD7/di0aRNmz56NqVOn8nFJkrB58+bTmrgQzGYzcnNz2T2pq6uLawp0kYYXGml/TGKiQCCA6upqxMXFYerUqZwgTft1GiNxFNxuN08cxEkItz2zWCxsbNLX18dZDxaLBUlJSbBarRz8otFokJSUxEYxNL6Wlha+SGm7Ea6zoCIkeTCq1WpmZ1JmB1ncE4OSUrzCC52kwcjNzUVmZibzNeLi4lhjQC5T4anXVC8gBSRZ6RMPgnIzKfuC6jCk4aA6AhnlhJu2kOPVSCDhHSE2NhYzZsyAx+PBK6+88iXPxvOPb3zxMRy7du1CcXExlixZgi+++II57ydOnMBbb72FtWvXDvv9EyZMiGjbxcfHc+GPGIINDQ1QKBRcECOOAOVMEjWYZMp+vx8mkwlJSUmIiorCiRMnoNPpmI5NXgJU3GpsbGRthEqlgl6vh8/n44BbMpUJBALcmfD5fLxFoG4JxcSR3RyF+7rdbjZO6enpQUVFBWw2G2s+qFBI3Q/yQKBAG7VaDSEEjEYjdDodDh06xDUW8pwgG33KDSWCU09PD0fVk68FJXynpqYyQ5QmMermUKuU2KZUeB0YGOCfTbZ7NJmmp6ePeL709/dj06ZNEeExdrsdc+fOxY4dO1BbW/tlT8XzDnnFEIa2tjasX78eeXl5mDlzJh8fGBjAc889d4o45mQYjUbMnDmT8zBpJUCFSUpeTk5O5j0wFTa9Xi+bsxDNlyaN8OW62+1GVVUVOjs72Y9Bq9XC7/ejs7OTjVZ6e3tZzkxOS11dXTh+/DhnRpCyEQAXRrVaLUpLS1FaWor6+nrmIZCXAW1hqHZCzk0NDQ0oKSnBgQMHcOjQIRQVFfGdHQCbv5CzVFxcHNctKDaQvC+ptUp/E0mSeNulVqu5e0BhPhRxFwwGER8fD7PZzBMCTTgej4c7MNTSpZZlXV0dXC4Xu2rFxMRwO3Q41NfXn0JaSk9Ph8lkwpYtW8ZlbYEgrxhOwq5du7BkyRLMmzcPe/fuZROXffv2Yfv27Vi+fPiQrby8POzcuRMnTpxg8RItSykCjZ5TO7OzsxOpqaksiAqfWEj1SLoFIi1ptVokJycjPj4+Qhrc3NzMOgDiD9CSnYpwpEGoq6tjlabX64XL5UJ2djZ6e3tx/PhxVFVVcXekrq4Ou3btQmZmJqsaq6urmRlJoTZEEmpvb2eXpdzcXOYgUH2gtbWVnZmozZeQkMA5D7T9ISFUb28vb2No66RUKrkbQ4zOcL4G6UGIYBYIBJCamsodm3CZdzAYRHJyMoxGI2w226g8Ht944w2WZwODrMx58+bh0KFD40JaPRzkieEkULFq1apVePXVV9nuraenB7/+9a/xrW99iy/OoUDmLCRpprTr5ORkvnCIi09KSCJAUeGLnJbIlNRoNHJVnZyP/H4/tzG1Wi0uuugi1NbWQpIkVhASOYkq/Wq1musKDQ0NaGhowMSJE9nspa6uDgkJCTCbzUhPT0d3dzdaW1tRXV2NtrY2DtQxGo0ct0fSb9qPp6WlITU1lQuTVquVeRPErlQqlfB6vWzKWl9fj5aWFmYgEt2aCEPEjaAVTvhE0d/fj97eXv7euro6Tq8iY95JkyaxuUx0dDRniVLgLLFOA4EAcnNzkZOTM+J50tXVhc2bN0e0sidPnoxFixbhT3/605h3aBoJ8lZiCHz00UdQqVSYP39+RGX64MGDIxaUoqKisHjxYiQmJjLZiIQ9ZIXW3t7O2wi6m5PIidqYpEyki4eWyhQISxmQlZWVqKioYCdqh8OBzMxMXq2QTRk5IBOjDxgsrFIMHBUN6+rqmEU5efJkOJ1ONjeh4FzSLiQnJ7OfAQD2mMjIyMCUKVOQnZ3NtQ6K2SspKUFzczMv48l/MjU1lY1q6fdIjtNE4CLPSWKDUr4HrYY8Hg9UKhV3RkjtSclSALgWQ8a95JlJRCrSV4yE3bt3RwjtVCoVFi5cCL1ejw8++OAMzraxCXnFMAQOHz6Ml19+GdnZ2XA6nTh+/DiAwZNp/fr1WLFiBScxDYXp06cjNzcXBw4cQHZ2NtuzJSQkMJnK4XBw5iWtAMgmjfrnpMQjDYTX68XAwADMZjP38cm+nlYUCoUCbrebi3XEFiwvL+clO1m2CyHQ09OD8vJyNpahar7JZEJ0dDSys7ORlpaGiooKtLa2sl6CzGC7urqQkpKCqKgo2O125Ofnw+l0wu12s1ozXBSmUqm4W9HY2MhxcdStMRgM6O3t5TxJyr2k7QCRs6jeQNZrZOxit9t5dRTeVVGr1fzzrVYrTpw4gb6+PlZ00rZjuL8rob+/H88++yy3eoHBldLSpUuxe/fucWHEMhLkFcMQ6Ovrw0cffQS73Y7JkydHCJaKiorw2muvDfv9UVFRWLFiBVJTU7m37vP5mLZLTEWycSf7cmCw7RkbGwubzcZ3SpvNxtbjZCtHdGhqEwaDQVRWVnJrkdSRjY2N3Nun1Q/F8dGFRoU4q9WK1tZWHDt2DHV1daitrUV8fDwuu+wyJCcnc35EamoqnE4ndDodUlJS4HQ6MXnyZMyZMwd2u52X+LSVUalUbBVHXQHaUtFdv7u7myeGjo4O9Pf3s50b8Up8Ph8XW8ljghijTU1NnJAdvoqhXIqUlBTeihDFPDo6mjtHbrebRVsjobi4GO+99x4/VygUmDdvHmw2G1566aVxR38eCvLEcBocOXIEzc3NmDJlSoRL8MDAAJ566qmIotNQSE5Oxm233cZLU/IpBAZrAtQKVCgUnBTlcDjY88BsNjMhiiaF+Ph4mEwm5h5Q+5LMTsIZgSqVijUYkiQhIyODe/xtbW08EYWLhIgcpVQq0djYyNJwtVoNp9PJeZqLFi3CokWLMHPmTMyZMwcpKSnsLVlfX89CsaamJni9XgghOEODaiBE7QYGL97q6mp2rSaFaE9PD4fzZmVlcd4n+UnSSgwYTOBOTk7mVYYQgluv9H+m3wt1YrxeL3w+HxobG2E2mzlibzhQhypcKRkTE4Mrr7wSLpcLn3322WhOrzEPeWI4DTo6OvDuu+9izpw5mDBhQsRrRUVFWL9+/SkW4SfD4XBg9erVEELg+PHjaGhoYK+EuLg4vquS4MdkMjEhSQjByke6mKxWK5KTk5GRkcEnO604/H4/nE4nHA4HBgYGuGBIn0V3VgqC1Wg0bBlHLELaplCYbWNjI/bt24f33nuPl/uJiYlcwDSZTKyRoEmNuA6VlZX8mFynS0pKONhFpVJBCMEXGKU9NTc3c6Q93fVpO1JTU4PKykomOfX09MDtdrNPJRVmSRdBXIiWlha43W7e0lA9gRy0hRCYNWvWqIJlmpqa8Oqrr/JzhUKBBQsW4IorrsCmTZtGJMKNF8gTwzAgpeX3vve9iCKkJEl45plnRtWSysvLw6JFi5jgQ2Gvvb29nLuYl5fH1m80aVC3ghSMZONGNvLl5eXwer1ISEhgqnJMTAy7O1FSk8ViYU4DdToMBgPq6+tZrBUdHQ2z2cwFTvKi1Gg0qK+vx+HDh3H8+HEO0KWLKTo6mhWV7e3tXImnO7VWq8XAwAC8Xi+zG4nWnZ6eDpvNBr1ez+xF4h/QakqpVMJsNrO3JNGh6V9jYyNaWlrgcrl4q0Z8EJJuOxwOJCYmQpIk3tLRyoFSqgwGw6gITQDw9ttvR8irzWYz1qxZA4/Hgy1btpzhGTZ2MeqJQQihFEIUCiG2hp6nCyH2CiHKhBBbhBDq0HFN6HlZ6HXnWRr7WYfX68XmzZtx+eWXY968eRG97dbWVjz22GNDJg6FQwiBiRMnIi0tDY2NjexMTGKfzMxMdm4C/qOgJHdp6uuT7RhJhXNycmC1WtmP0OPxoLS0FAcPHkQwGOR+fWNjI/MhUlJS+P9AyVDkSdDQ0MBdgJiYGO6Q2Gw2JhVRp0CtVrPxK4XAnjhxArGxsdxWdDqdbCVHYjEKgSH3Z2Iq0lYkJyeH6wpElabuAQmyiM9BExLZzBGdmyYlnU7HIbbkcN3V1QWfz4empiZIksR1iaysrFHpIjo7O/HXv/41YqWYkZGBSZMmYcuWLWhoaDjjc2ys4kxWDHcCKA57/iSA30uSlAXAC+CHoeM/BOANHf996H3jFlu3boVKpcLDDz/McmLCW2+9heeee25EhltUVBRmzZoVkTQlSRK3EZVKJerr6xETEwODwYCioiK43W4kJSVhwoQJnIFA0fA9PT1Qq9VIS0tDS0sLAoEAMyUNBgMXICkDg1iTtHWhuoPf70dhYSFqamrQ2dmJnp4evlioQ2IwGPiuTUGwfr8fzc3NcLlcnAjt9Xrh8Xjg8XjQ3t7O2weNRoP4+Hiua4TH8xE3ggRP9LtJS0vjJG5a2YRve0ijQSxPymuglRX5RlC+BXVfaDVCHSCSv8+YMWNUhq/vvPMODh06xM8NBgMWLFgAj8eDzZs3j2um48kY1cQghLABuBrAhtBzAWA+ANpsvQDg2tDjZaHnCL3+LTFam90xiIaGBmzcuBGTJk3C8uXLI5SXfX19eOKJJ7idORzsdjvsdjtqampQWFjIy1Faxms0GraVJ6GUz+fjjoHX60VUVBQvi8mfknIhSIadnJzMtQe1Wo3MzEwolUpWMAYCAW4lxsbGwuPxsLM1hbZQFJ3NZoPRaOR2YDAYRHV1NZqampCQkIApU6awGzXJm+kOHQgEuDNCjE1K2yKBVmVlJXclXC4Xp3xpNBq+mMmynoRRbW1tEb4RQghkZmbCbDaz/oTiAnU6HVpaWlgzQdb4lIHh9XqRnp4+qhZlZ2dnhPW7EAKzZ8/GrFmz8Lvf/W5c6yKGwmhXDE8B+H8AiOZlBtAmSRKpR+oApIYepwKoBYDQ6+2h90dACPEjIcR+IcT+Lzf0cwNJkvDiiy9i9+7dWL58OW699VYOgwEG+f0/+clPRiw6qdVqTJ48GSUlJTh27Bg6OjrQ19eH0tJS9Pb2Ij09nbUV2dnZbHJC1GkKzqUoN7JBI75CdXU1W7EZDAY0NDQwz8DtdrMKk+ocZC1Pd1ZgsOCqVCo5i4FWJmSKajAYkJGRgby8PBiNRqSnp7PiMtzqjcZNUXuBQIAj7chNmu7uJIiyWq0Ryd2Ux0n+EyRNp6JpRkYGnE5nhLcEJYJTDB/5QFJxlYxyycUqNjYWc+fOHdV5cLJzuEajYV3M9u3bL6jVAjCKiUEIcQ0AtyRJQ/upf0lIkvSsJEkzJEma8XV+7tmAz+fDI488gtTUVCxfvhxZWVkRr+/evRu//e1vRzw5Jk2ahJSUFHi9XnzyySf4/PPPUVpais7OTg61nTRpEhcTBwYG+C4Z7iCdmZnJ7Ubah5OlGe1ziRbt8XhgMpmY/adSqbj/T9b11GUghqPdbmdjFbKe6+rqgsvl4pj47u5ulJWVsdWc1WplmnF9fT3v2emC7OrqYh/Mzs5OTg4nqXMgEGC1JmVOuN1uTuAiNeTAwAC7VBEfgpyvKBuTLNyo2EgTDK0kWltb0djYiClTpsBut4/49w8EAli/fn2E9bvJZEJ+fj7ef//9UyzjLwSMZsUwG8B3hBBVAF7C4BbiDwDihBDEnLQBcIUeuwCkAUDo9VgA476Hs3//frz00kvQarWYM2dOhPpuYGAAzz77bMT+cyjEx8fjpptuQk9PD/bt24fi4mJER0fzCZyYmAiHw8F364GBATQ0NMBoNCIzM5OX3ZWVlaitrYVarcakSZNgsVi4PkF+hXQR0b6eEqE6OjrYxoxep6xGusiovdfV1QWNRoPU1FSmP1MOBZGQJEmC3W5nDkA4EYvStqxWK8zm/ywaydyV6M3h8nNKkiLrOa1WyxkVZHFvNBqRlpbGrts1NTUIBoMwm81sCmuz2RATE8PFSHKZpg6HRqPBokWLRhU/9/HHH2PXrl0Rx5xOJ/x+P7Zv3z7qc2g8YcTfiiRJD0iSZJMkyQlgJYCdkiT9F4APANwYetsaAG+EHr8Zeo7Q6zulC2Cd1dfXh7/85S9Qq9W44447cM0110Rw6ltbW/HrX/+aU5eHghAC8+bNw89+9jNOXqqrq8OxY8dQU1ODlpYWlJSUsApRoVBwcbKtrQ1arZZ9BxISEpCTkwOTycQrAiEE/H4/JEmCz+djuXRdXR1vJyjbkdqXFosFADhdqqOjg23XA4EALBYLcy2odUqdjejoaHa19ng8vEogPwf6LNJ2KJVKWK1W5lRotVouOJKojEhNLS0tMJvNMJvNLIemMaSkpLD2guoaROEmXQZxGGJjY7moCgwWbltbW5GTk8NmscOhq6sL69evj5Dc6/V6XHLJJUM6Q18o+Co8hvsA3C2EKMNgDWFj6PhGAObQ8bsB3P/Vhjh2cOzYMTz11FNITU3Ft7/97VNUlm+++SZ27Ngx7GcolUqsXbsWTz/9NC699FLuo1900UUcMEPWYmQwQtbuRIVOTU2FwWBAW1sb6uvrMTAwACEELBYLoqKiONeC6gm0f6clr0ajQUNDA6qqquD3+7mNCIC1Cd3d3XC73QgEAqivr8eRI0d4C1FRUYGamhqmK4fbo3k8ngh/SbJmpwvIZDKxwQw9J24FGbOSkzbRlinvMjMzEwqFgrMmLRYLp18Tx4NWW0T7BhChI+nr60N8fDwKCgpG1Yl47733IlYLCoUC3/72tzFt2jTs2LFjWKPg8YwzElFJkvQhgA9DjysAzBriPUEAw5sWjFNIkoR//etfuOuuuzB16lTYbLYITz+/348HHngAOTk5w0p31Wo1Vq9eje985zsoLi5mk5OGhgaeFKjASZ2CmJgYlJSUwO12w2AwIDs7m2PsSEhE3IDq6mo2oCV7dnJbJvISyY2Tk5ORlpYGYPAiDbdfb2lp4ZUA/aMiJgmnyElKoVCgvLyc7fSpLWg0GtHT08MTTkNDA3dSSO5Mug/qxuj1er5DCyG4BkHKUOI2AOBVSiAQgE6ni0jQpuAdm82GjIwMuN1uaLVaLFmyZFSrhZKSEjz22GMRRq/Jycm47rrrsHfvXl6FXIiQ1ZVniMbGRrz++utYt24dFi1ahOPHj0eQnI4ePYrvf//72LBhA/Ly8ob9LIovo3CYTz75hI1aSEbd3d3NCdr0c5RKZYQLcnt7O2pqargj0N/fzwKrqKgoVFRUsHGLVqtFdXU1FAoFm5v09vay9wOFyKpUKsTFxXGXIjU1lVupJL7q7e1FQ0MDdxcyMjLYQIVcqvR6PesUqC2oUCjQ0dEBs9kMt9vNnQPaLqWlpbEzdlZWFvR6PWdckKcChd4C4FUJGdHQhEh5HhqNBlVVVRBCYO7cuewYNRxaWlrw0EMP4fPPP4/4e912223Q6XR4+eWXz/jcGU+QKdFfAhs2bEBVVRVWrVqFG264gTkFhL1792L58uV47733RtRTAIN3xYyMDKxevRorVqxATk4OE3WIMkwX78DAAOrq6jgAlwxNCwoKmDGYlJSEQCCA0tJSNDc3M8mH7Nja29uh1+uRmZmJtLQ03ttTQhbF3huNRg6vpS5JW1tbxHKf8jHJ0n5gYACVlZURAb7hDtAAWMtA6dnENaAgHvJU6O7uZhNbysYkE1lqo1JHgvgTKSkpUKlUqKysZJbjrl27UFhYiJycnFF1ITo7O/HQQw/hjTfe4DErlUosW7YM6enpePzxx9Hc3PwlzpzxA3nF8CVQUVGBhx56CC+++CLuueceHDlyBAcPHox4z/Hjx/GDH/wAd9xxB9auXQur1Tri5yqVStjtdiQkJEAIgb///e9oamrik99oNLLPI3EZAPBdnNqNZJJKy22n0wmPx8NCo+LiYgSDQbS0tLA/Ad2RaWKgO7xGo0FlZSX7KiYmJrIrU39/P2s8gsEgczLIzJZs0yiUhoxcgMEWcEVFBadyd3R0MBeE2opk/x4XFwez2QyXy4WoqKgIzwjiQdAWjHgNALhAWVdXh0suuQTTp08f8W8wMDCA1157DX/7298i/BZyc3Nxyy234Omnnx73tm2jgbxi+JLYvn07XnnlFWRmZmL16tVM4Q2Hy+XCL37xC8yfPx8PPvggqqurR/XZOp0OV111FfLy8uD3+9HW1sbGrhT6Qgw/WjJXVFRw642W4xkZGVAoFPB4POxqVFxczGzCtrY25iWQspAMVmmfX19fj7a2Nk6lam9vZ6ESMHiB06REKkiTycTtwa6uLkiSBIvFAqfTyRMKAC4gxsXFcVS8JEnc+aCovdjYWNjtdmRnZ8NqtfKESLoNWkXQz5ckiVWgRqMR+fn5uOqqqyLk86fDgQMH8Jvf/CbCmk2n0+H6669HYWEh3nrrrQuOzDQU5InhS6K7uxsPPvggCgsLMX/+fFx55ZVDGoj29fXh2LFjePTRR7FkyRJs27ZtVNsLo9GIO++8EzNnzmRPROo+EFFJr9czqQcYXKKTyQot+bOzs1kARfwDMoOJiYlBd3c3J1xpNBp0dXXB4XBgypQpcDqdnENBPguxsbFoa2vjtmp9fT3XJpxOJ5xOJyZMmICsrCxoNBro9XrodDr2XDQYDKwgJRAhqbOzk7dDJDjzeDzsHkUeC21tbUhKSmKSFmkiEhISEB8fz3buHo8HUVFRuPLKK0elnmxsbMRjjz0WQXEXQmDOnDnIysrC+vXrmW9xoUOeGL4CXC4X7r//fiQkJODHP/4xZs+efVp3YUmSUFRUhO9973v4y1/+MizfgZCYmIglS5ago6MDFRUV7HwcnusYPlkQcUmhUDCVmrYcFM7icDgwceJEpKenQ6PR8CRFqwadTsdaCvJYNBqNiI+P59YgJVl98cUX+OKLL1ip2dPTA4fDAafTifb2drS0tMBoNMJoNLKPQk9PD0pKSnhyq6ioQFdXF7tZAYOdGJPJxLZ4tAWhiYBcsV0uFytEKaSWPpe+x2az4dJLLx3R9bmrqwu//OUvsXXr1oiciOzsbNx4443461//ioqKitGeGuMeYiwsi4QQ538QXxJCCHz/+9/HE088gbKyMjz//PP44IMP0NjYeFpJtsFgwN1334177713VOYgR48exa9+9Sv09/ezuWp8fDzb0Dc3N7OCkbgDwGBrze/3o6enBxqNBi0tLUhNTeWMyZqaGqYdEyeBXKD8fj8sFgvcbjfXNeLi4jB9+nQmSVVXV8Pj8SA7O5t9DnJzcyGEQEVFBdOTycGJTFrq6upYUFVfX8/hM42NjUxYcjqdXFsJj5YjSToRpsgdKxAIIC0tjanXVHOYO3cuZs+ePSxnYWBgAE8//TTuvffeiBVBdHQ0fvKTn8DlcuHll18e1UpvjOOL0UoQ5BXDV4QkSfj73/+OW2+9FQaDAb/5zW+wYcMG3HHHHbj00ksjrNMInZ2deOyxx3D77bePaBEHDJq9PPDAA4iKikJVVRWamppQVFTE+Zbl5eVMVCJuQXjEmk6nY82CQqHggqDdbkdiYiLsdjskSYJOp0NGRgYCgQAOHDiA0tJSxMTEwGaz8UqBGIjJyclIT09HYmIiuru7eWXg9Xpx5MgRuFwuNDQ0MBnJarViYGAAzc3NbB5DgbsxMTFISkriYFvqWtTV1aG7uztC55CSksJELpKak5S8oaEBvb29CAQCqKyshN/vx+TJk0ckMh09ehTPPPNMxKSgUqk41Pedd965ECaFM4I8MXwN6O/vx9tvv41rr70Wzz33HCZNmoR169bhjjvuwLJlyyL204S+vj784x//wMqVK7F3794RGXTTpk3Do48+isTERM5DaGpqQkVFBffr+/v7WVHZ2dnJvgsejwc1NTVob2/nIFdgkE8QCAQ4eSk2NhaxsbGIj4/nGgEpEylol/Ic6PtpSxIdHY20tDROgKLOBBX8KBaOiFJWq5XzI4izEB0djaSkJFgsFiZ1RUVF8bjJHo+o1LTlIM1GIBBgv8mUlBQsX74csbGxw/5evV4vHn74YRQVFUUcz8nJwYoVK/Dqq69GsCi/KZAnhq8JkiShuroa9957LxYvXox///vfmDRpEm644Qbk5eUNucft7+/Hrl27cPXVV+PJJ5+MMBgdCpmZmbjvvvuQkJDABB+DwcCkHwputVgsMJvN0Ol0bHqSkZHB7lA6nQ6BQAAej4dTpRobG9HR0cFjSE9Ph9VqRVdXFyorK+F2u2G32zFx4kR0dXXxBEQ0aXJmovxNjUbDvAK6w1NCFulASBwWHx/PxrGJiYnQarWcYEUFUWJhUv0DGGSa6vV67hLo9XrU1taivLwcl156KaZNmzbs77OtrQ0///nPsW3btohOg06nw9KlS9HQ0IB33333TE6DCwbyxPA1Y2BgAAcPHsS6detw3333AQDWrl2LVatWweFwDPk9ra2teOihh3DNNddgz549w64enE4nfvGLX8DpdKK+vp79FqleQClNdCetqamB1+tFTEwMZ0kQyPmJLkaiV5NbE6VFezweaDQaZGRk8ERDfhLElCRbdgrYCZ+I6KtWq4XD4eAIOqVSiY6ODkRFRSErK4uLit3d3WhsbGRTWBpLX18fu2CRP6Xb7YbX60UwGORg2qVLl2LZsmXDKic9Hg/uuOMO/N///V8EXwEArFYrJk+ejHfeeWfEvNILFfLEcJYQDAaxY8cO3Hnnneju7sZtt92GtWvXcgDMyejr68PHH3+M6667Dhs3boyojJ8Mu92OX/3qV7j22mvR2NiI2tpa1NbWwuPxQKFQwOVyYffu3aiqquJwF5oc3G53hPUZCZDIVLarq4sFW2TOkpaWhokTJ8JgMKC1tZW9E0geTUVAj8fD9Gez2cyEKzJnIRYnMLgNoQmQBFIZGRlsWUfGNeSr0NnZiaSkJJhMJo7tI6t8rVbLCs8rrrgC3/3ud4flLHi9Xqxbtw6bN28+5fesUqkwa9YsHDx4cERB3IUMeWI4y3C5XHjggQfw4Ycf4vrrr8d9992HBQsWnDbYxO1242c/+xluv/121NXVnfZzzWYzVq9ejSeeeAKLFy/mQiR1JpqamjgUVq1Wo7Ozk41ZgEEtAFX8Ozo62KxVq9XC6/Xi6NGj6OvrY8JSTEwMW7wB//FNoBYqCaEMBgOTg+g9lB5FEw7d6UtLS9nYlfwUSEnZ2dnJHpLd3d2sswjPsXS5XNwCBYCCggLceOONw04Kra2tuO2227Bly5YhC4r5+flYuXIl3n///XGfP/lVIFOizwHa29vx6KOP4uDBg/jpT3+KxMRE+Hw+FBYWDslnCAaDePbZZ7Fnzx488sgjp10WKxQKzJo1C9OnT0dJSQl2796NDz/8EHq9njMTqDDo8/nQ09MDk8kEi8XCPovkpmQ0GtnPgeLpo6OjWatA3Q7qdJAHBFGSyXqObO7JZam5uZml1h0dHYiJiYHT6QQAVFVVcTYn+T/09/dzcTQ7O5uzPmNiYjhfM1ydGR0dDYvFgptuugl5eXnD5k42NTXhxz/+Md58880ht2sWiwWrV6/GoUOHRjTdudAh8xjOIchA9O6774bf78e7776LXbt2oaam5rQ0W4PBgHvuuQd33XXXkN2NcPT396O8vBwHDhxAUVERysrKAIDzLXt6emC32+FwOBAMBrF//374/X6kp6dDkiTYbDZ4PB6eIHp7e1mTQIrOnJwcdnKijAlSUJITdEZGBmpra1nkRa5SwOCEQisRj8fDeRZURPT7/WhpaYFSqYTNZkNmZiaOHTsGr9cLt9uN/v5+mM1mBAIBKJVKXHPNNbj44ovZcOZ08Hq9+MEPfnBaSrPBYMCNN96IadOm4fHHH79QJdWj5jHIE8N5QEpKCu655x5cfPHF2L9/P55//nmcOHHilCIYQQiBSy65BI8++uhpqdcno62tDYWFhfjkk09w+PBhvgsTbTg2NhYVFRXw+/3cfbBarWytTq5NAFiCTVoNi8XCGga32w2bzQaXy4WysjIoFAokJCSgtrYWKSkpfMFHRUVx16K+vh6pqamwWCzc2SBXaJocSM2ZkZGBvr4+7Nu3jyey1NRULFiwACtWrGBC1XDweDy4/fbb8fLLLw+5UlCr1bjuuutwzTXX4Le//e0pgrgLCPLEMNYRFxeHW265BYsXL8aJEyfw2WefYe/evSgtLT1tV8JkMmHdunW46667RmV5DoA9Irdt24Y9e/YwrVilUiEpKQkejwd6vR7t7e0oLy/n2kdPTw9SUlJY3ZiRkYGJEydyolNraysXGMko1uUatP1MTExEX18fMjMzeeVBQTJ1dXVsEKNSqdDc3MxS6/7+fuZZUMfEZDKhvr4eR48ehcfjwbRp03DTTTdh5syZowqJKSsrwz333IOtW7eedlJYvHgxli9fjg0bNuCjjz66kEVS8sQwHqBUKjF9+nT89Kc/hdPpRGFhIV544QW2URsKCoUC+fn5ePzxx09JxxoOZK+2c+dOfPbZZ6ivr+c6AfESamtrmRvQ1NSECRMmIC0tDcuXL8fFF1/MEuvW1lZs3boV1dXVnGPhdrvhdrthsViQlZXF7tSUvUkW8tRmJGt6yq90u91cNKRMSmDQQLe+vh4OhwPXXnst8vPzR6WSlCQJb7/9Nv77v/+bt1QnIy4uDqtWrcKNN96IDRs24KWXXrqQJwVAnhjGFywWC9asWYOCggIUFRXh6aefHjHuTK/XY82aNfif//kfpKenj8q/EBi8YLxeLwoLC7Fnzx4UFhaiv78fHo8H0dHRqKyshFarxcUXX4ybb74ZU6dO5dyJcPT29qK8vBwffvghioqK4PP50NLSgszMTKSnp6O0tBTAICfAbrcjEAgwLZs6CdHR0UyMCgQC/JW8GVJSUrBkyRJkZWVhwoQJo5oQgMFi75NPPok///nPEbZsBIVCAbvdjmXLlmH16tV47bXX8Ic//OG0W7kLCPLEMN4QFRWFhQsX4rbbbsP777+PPXv2oKysDD6fb9i7mM1mwy233IK1a9eOyp0oHOSm7PV64XK5mFqcmpoKh8MxqguxqakJb7/9NiorK1FeXg6LxQKr1crMSrVajaSkJLZf83q90Ol0iIuLQ0tLC6qqqtDd3Y2UlBSOkMvIyMCsWbMwa9YsFlONFocPH8b//u//nsJmJMTGxuLyyy/HjBkzYLFYsHPnTmzfvv2bIqeWJ4bxCIVCgYKCAqxbtw4WiwWffvopdu7ciYMHD8Ln851WyCOEQGpqKlauXImbb74ZOTk5o95ifB2gusP+/ftRXFyMqqoq+Hw+qNVqZjzSV5/PxynX5DZNd/CMjAzMnDkTBQUFQ65ShkN3dzc2bdqEBx98kGsd4VAoFMjKysLKlStht9vxxhtv4LPPPrvgLdpOgjwxjGdMmDABDz/8MKZNm4aKigoUFRXhwIEDKCws5Dvs6f5uZrMZ3/rWt7BmzRpcfvnlEXF65wI9PT2orKzEli1bIghMVEyUJIlNYerq6hAbG4urrroK8+fPR3Jy8rA8hKEwMDCA48ePs0fjUIxRrVaLK6+8EosWLUIwGMTGjRvZl/IbBnliGO/QarWYOnUqbr31Vlx99dXweDxMvPniiy9QX1+PysrKiNi0cGg0GkycOBFLly7Fd7/7XUycOPGML7qvgmAwyDmdZAlXXl4OnU6HKVOmYOLEicjJyUFWVha7RJ8pWltb8fTTT+PPf/7zkLwDpVIJh8OBhQsXYvHixXjzzTfxyiuvfGP1D5AnhgsHUVFRyM/Px0033YSCggIOrG1vb8fnn3+Od999F+Xl5fB4PKe9AxqNRsyYMQPXX3895s6di6ysLPY3ONugMVG0nVqtRnx8/Ff62T6fD6+++ip+//vf49ixY6etJSxYsAALFy6ESqXCxo0bsXfv3m+cr8JJkCeGCxGJiYkoKCjAsmXLcNVVV0EIgbKyMhw5cgQvvPACCgsLOb3qdDCZTLBarbjiiiswefJk5OXl8URBhihjEeQrsW3bNvzxj3/EgQMHhuQlaLVaZGVlYdWqVbjssstQWFiIP/3pT6iqqjr3gx57kCeGCxkajQbTp0/HzTffjKVLlyI+Ph779u3Djh07UF5ejubmZhw+fBher5e9C4aCEAJarRZqtRp6vR4zZsxAYmIiVCoVCgoKkJuby3H2ZOR6rtHf34/i4mL84x//wKuvvoqqqqpT6ghCCB7jggULMGfOHJjNZrzwwgt46623vslbh5MhTwzfBAghMGHCBKxZswbXX389V/I7Ozuxfft2lJWVobGxEcXFxcNSrk/32UIIdkqi9Gir1Yr58+fDZrNh6tSpSEhIYGv6rwPkx1BaWooPP/wQr732Gg4cODDkxS2EQHR0NKZNm4brr78eJpMJkiTh0KFDeP3111FTU/O1jOkCgjwxfJMghEBmZiZWrlyJq6++Grm5uREhtbt27cJHH32Ezz//HLW1tSzH/iogD4e4uDhcdtllyMjIgN1ux2WXXYbo6GhER0fDaDQOW0ugNicldO/duxd79uzB+++/j9ra2tNaqlGA74wZM9ga/tixY9i5cyeOHDkyIvfjGwx5YvgmgpbUlAlRUFCA2bNnw2AwwOfzwe/3o6KiAh9//DEOHz6M9vZ2REdHw+/3o7a2lhWYXxZkWa/RaJCens4dBwrLNRqN8Pv9rCbt7+/H4cOHUVVVBUmSEAwGh936KBQKtsAvKCiA2WxGW1sbPv30UzbHlTEs5IlBxn8mCofDgWnTpmHhwoXIz89HMBiE3+/HiRMnEAwG0dfXx6SkI0eOoKenh81cKSOTzhNJks7p3VipVEKv18NoNGLChAmIi4uD2+1GVVVVhEmLjFFBnhhknAqlUgmz2YyLLroIs2fPxpQpU5CcnAyr1YpgMIjm5mbU1tayPbzL5UJFRQXq6urgcrmg1+sRDAZRX1+PpqYmtLa2spxakiTuEtBXOjaSAzaF1FJdIy4uDlarFXq9nmPtKisr2en6G6BpOFuQJwYZw4OyL5OTk5Gbm4uUlBSkpaVhwoQJmDp1KpuvUFGRxFU6nQ4A0NDQgMLCQgwMDLAYSq1WQ5IkdHV1sfOTz+eDy+WCSqViJ6dAIIBgMIjk5GRoNBokJycjPz+fVyPkKHXkyBF88skn2Lt3L9ra2uS6wVeHPDHI+HIgnwaz2YwpU6YgPT0dTqeTE6vdbjfy8vJgtVrZRTotLQ3Af0RZsbGxaGpqQnFxMedMmEwmAGCbe+JbGAwGDrTt7OzE3r17sX//fs7g/KpFUhkRkCcGGV8fKLZOCMHGrxRGI0kS9Ho9FAoFgsEguzypVCq0trbC7/djYGCAfRlMJhOSkpIADLpM9fX1wev1cpoU+T7KOCv4eicGIUQVgA4A/QD6JEmaIYQwAdgCwAmgCsAKSZK8YpD0/gcASwAEAPxAkqQDI3y+PDHIkHH2cVayK+dJkjQt7IPvB/C+JEnZAN4PPQeAqwBkh/79CMBfzuBnyJAhYwzgq6holgF4IfT4BQDXhh3/mzSIzwDECSGSv8LPkSFDxjnGaCcGCcAOIcQXQogfhY4lSpJE/mONABJDj1MB1IZ9b13oWASEED8SQuwXQuz/EuOWIUPGWcRoBfqXS5LkEkJYAbwrhDge/qIkSdKZ1gkkSXoWwLOAXGOQIWOsYVQrBkmSXKGvbgD/BDALQBNtEUJf3aG3uwCkhX27LXRMhgwZ4wQjTgxCiGghhJEeA1gE4CiANwGsCb1tDYA3Qo/fBPB9MYhLAbSHbTlkyJAxDjCarUQigH+GrLeiAGySJOkdIcTnAF4WQvwQQDWAFaH3b8Ngq7IMg+3KtV/7qGXIkHFWMVYITh0ASs73OEYJC4CW8z2IUWC8jBMYP2MdL+MEhh6rQ5KkhNF881hJuy4ZLfHifEMIsX88jHW8jBMYP2MdL+MEvvpYz74bqAwZMsYd5IlBhgwZp2CsTAzPnu8BnAHGy1jHyziB8TPW8TJO4CuOdUwUH2XIkDG2MFZWDDJkyBhDOO8TgxBisRCiRAhRJoS4f+TvOKtjeU4I4RZCHA07ZhJCvCuEOBH6Gh86LoQQfwyN+7AQIv8cjzVNCPGBEKJICHFMCHHnWByvEEIrhNgnhDgUGucvQ8fThRB7Q+PZIoRQh45rQs/LQq87z8U4w8arFEIUCiG2jvFxVgkhjgghDpLe6Gv925Od1vn4B0AJoBxABgA1gEMAJp3H8VwBIB/A0bBjvwZwf+jx/QCeDD1eAmA7AAHgUgB7z/FYkwHkhx4bAZQCmDTWxhv6eYbQYxWAvaGf/zKAlaHjzwD4SejxTwE8E3q8EsCWc/x7vRvAJgBbQ8/H6jirAFhOOva1/e3P2X/kNP+5ywD8O+z5AwAeOM9jcp40MZQASA49TsYg5wIA/gpg1VDvO0/jfgPAwrE8XgB6AAcAXIJB8k3UyecBgH8DuCz0OCr0PnGOxmfDoLfIfABbQxfSmBtn6GcONTF8bX/7872VGJVE+zzjK8nLzwVCy9jpGLwbj7nxhpbnBzEotHsXg6vENkmSyNAxfCw8ztDr7QDM52KcAJ4C8P8AkK21eYyOEzgLVgjhGCvMx3EBSTpzefnZhhDCAOA1AHdJkuQTYXHyY2W8kiT1A5gmhIjDoDp34vkd0akQQlwDwC1J0hdCiLnneTijwdduhRCO871iGA8S7TErLxdCqDA4KfxDkqTXQ4fH7HglSWoD8AEGl+RxQgi6MYWPhccZej0WQOs5GN5sAN8Rg/6mL2FwO/GHMThOAGffCuF8TwyfA8gOVX7VGCzivHmex3QyxqS8XAwuDTYCKJYk6XdjdbxCiITQSgFCCB0G6yDFGJwgbjzNOGn8NwLYKYU2xmcTkiQ9IEmSTZIkJwbPw52SJP3XWBsncI6sEM5VsWSYIsoSDFbUywH8/DyPZTOABgC9GNyH/RCD+8b3AZwA8B4AU+i9AsCfQ+M+AmDGOR7r5RjcZx4GcDD0b8lYGy+AKQAKQ+M8CuCh0PEMAPswKM9/BYAmdFwbel4Wej3jPJwHc/GfrsSYG2doTIdC/47RdfN1/u1l5qMMGTJOwfneSsiQIWMMQp4YZMiQcQrkiUGGDBmnQJ4YZMiQcQrkiUGGDBmnQJ4YZMiQcQrkiUGGDBmnQJ4YZMiQcQr+P/QCAexOCpe+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(n100,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7bf2cb06d8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(n20,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.7912087912088"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004086771438464067"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       ...,\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf],\n",
       "       [-inf, -inf, -inf, ..., -inf, -inf, -inf]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6227106227106227"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_loss = torch.nn.TripletMarginLoss(margin=1.0, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n100 = torch.tensor(n100)\n",
    "n80 = torch.tensor(n80)\n",
    "n60 = torch.tensor(n60)\n",
    "n40 = torch.tensor(n40)\n",
    "n20 = torch.tensor(n20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_100_80  = triplet_loss(anchor=n100.flatten(1), positive=n80.flatten(1), negative=n60.flatten(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 \n",
    "triple_100_80  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40\n",
    "triple_100_80  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60\n",
    "triple_100_80  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.diag(torch.tensor(4), torch.tensor(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = triplet_loss(anchor, positive, negative)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222.983px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
