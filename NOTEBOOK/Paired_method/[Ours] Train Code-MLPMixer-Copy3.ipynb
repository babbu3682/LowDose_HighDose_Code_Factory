{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CUDA 11.1\n",
    "# !pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE -> MAE Loss 꿀팁!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 11 08:21:04 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "| 33%   42C    P0    76W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 32%   37C    P0    62W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 33%   38C    P0    69W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 33%   38C    P0    61W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 8000     Off  | 00000000:3D:00.0 Off |                  Off |\n",
      "| 31%   30C    P0    59W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 8000     Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "| 31%   31C    P0    61W / 260W |      0MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Quadro RTX 8000     Off  | 00000000:40:00.0 Off |                  Off |\n",
      "| 37%   58C    P2   242W / 260W |  48064MiB / 48601MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Quadro RTX 8000     Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| 40%   66C    P2   277W / 260W |  48066MiB / 48601MiB |     99%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/sunggu/4.Dose_img2img/scripts study\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/sunggu/4.Dose_img2img/scripts study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 갯수 =  64\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc as container_abcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPMixer(image_size = 512, channels = 1, patch_size = 16, dim = 768, depth = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "***********************************************\n",
      "Dataset Name:  Sinogram_DCM\n",
      "---------- Model ----------\n",
      "Resume From:  \n",
      "Output To:  /workspace/sunggu/4.Dose_img2img/model/[Ours]MLPMixer_remove_denoiser\n",
      "Save   To:  /workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/\n",
      "---------- Optimizer ----------\n",
      "Learning Rate:  0.0001\n",
      "Batchsize:  40\n",
      "Loading dataset ....\n",
      "Train [Total]  number =  6899\n",
      "Valid [Total]  number =  14\n",
      "Creating criterion: Change L2 L1 Loss\n",
      "Creating model: MLPMixer\n",
      "Number of Learnable Params: 69703168\n",
      "MLPMixer(\n",
      "  (patch_embed): Sequential(\n",
      "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=16, p2=16)\n",
      "    (1): Linear(in_features=256, out_features=768, bias=True)\n",
      "  )\n",
      "  (mixer_blocks): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (8): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (0): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): PreNormResidual(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (2): Rearrange('b (h w) (p1 p2 c) -> b c (h p1) (w p2)', h=32, p1=16, p2=16)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 1000 epochs\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [  0/172]  eta: 0:33:26  lr: 0.000000  loss: 0.1806 (0.1806)  time: 11.6661  data: 6.1934  max mem: 19766\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [ 10/172]  eta: 0:07:14  lr: 0.000000  loss: 0.1793 (0.1792)  time: 2.6793  data: 0.5632  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [ 20/172]  eta: 0:05:26  lr: 0.000000  loss: 0.1792 (0.1793)  time: 1.6726  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [ 30/172]  eta: 0:04:38  lr: 0.000000  loss: 0.1789 (0.1791)  time: 1.5707  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [ 40/172]  eta: 0:04:07  lr: 0.000000  loss: 0.1783 (0.1788)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [ 50/172]  eta: 0:03:41  lr: 0.000000  loss: 0.1783 (0.1787)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [ 60/172]  eta: 0:03:19  lr: 0.000000  loss: 0.1775 (0.1785)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [ 70/172]  eta: 0:02:58  lr: 0.000000  loss: 0.1773 (0.1783)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [ 80/172]  eta: 0:02:39  lr: 0.000000  loss: 0.1764 (0.1781)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [ 90/172]  eta: 0:02:20  lr: 0.000000  loss: 0.1764 (0.1778)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [100/172]  eta: 0:02:02  lr: 0.000000  loss: 0.1761 (0.1776)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [110/172]  eta: 0:01:44  lr: 0.000000  loss: 0.1753 (0.1774)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [120/172]  eta: 0:01:27  lr: 0.000000  loss: 0.1752 (0.1773)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [130/172]  eta: 0:01:10  lr: 0.000000  loss: 0.1748 (0.1770)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [140/172]  eta: 0:00:53  lr: 0.000000  loss: 0.1738 (0.1768)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [150/172]  eta: 0:00:36  lr: 0.000000  loss: 0.1736 (0.1766)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [160/172]  eta: 0:00:19  lr: 0.000000  loss: 0.1730 (0.1763)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [170/172]  eta: 0:00:03  lr: 0.000000  loss: 0.1728 (0.1761)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:0]  [171/172]  eta: 0:00:01  lr: 0.000000  loss: 0.1728 (0.1761)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:0] Total time: 0:04:44 (1.6550 s / it)\n",
      "Averaged stats: lr: 0.000000  loss: 0.1728 (0.1761)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:0]  [ 0/14]  eta: 0:00:05  loss: 0.1740 (0.1740)  time: 0.3865  data: 0.3712  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:0]  [13/14]  eta: 0:00:00  loss: 0.1717 (0.1717)  time: 0.0430  data: 0.0279  max mem: 20571\n",
      "Valid: [epoch:0] Total time: 0:00:00 (0.0514 s / it)\n",
      "Averaged stats: loss: 0.1717 (0.1717)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_0_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.172%\n",
      "Min loss: 0.172\n",
      "Best Epoch: 0.000\n",
      "/home/sunggu/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [  0/172]  eta: 0:07:52  lr: 0.000000  loss: 0.1732 (0.1732)  time: 2.7500  data: 1.1714  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [ 10/172]  eta: 0:04:33  lr: 0.000000  loss: 0.1716 (0.1719)  time: 1.6861  data: 0.1066  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [ 20/172]  eta: 0:04:08  lr: 0.000000  loss: 0.1716 (0.1719)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [ 30/172]  eta: 0:03:49  lr: 0.000000  loss: 0.1714 (0.1717)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [ 40/172]  eta: 0:03:32  lr: 0.000000  loss: 0.1708 (0.1714)  time: 1.5840  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [ 50/172]  eta: 0:03:15  lr: 0.000000  loss: 0.1701 (0.1712)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [ 60/172]  eta: 0:02:59  lr: 0.000000  loss: 0.1701 (0.1709)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [ 70/172]  eta: 0:02:43  lr: 0.000000  loss: 0.1695 (0.1707)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [ 80/172]  eta: 0:02:26  lr: 0.000000  loss: 0.1690 (0.1705)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [ 90/172]  eta: 0:02:10  lr: 0.000000  loss: 0.1686 (0.1703)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [100/172]  eta: 0:01:54  lr: 0.000000  loss: 0.1685 (0.1701)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [110/172]  eta: 0:01:38  lr: 0.000000  loss: 0.1680 (0.1699)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [120/172]  eta: 0:01:22  lr: 0.000000  loss: 0.1675 (0.1697)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [130/172]  eta: 0:01:06  lr: 0.000000  loss: 0.1673 (0.1695)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [140/172]  eta: 0:00:50  lr: 0.000000  loss: 0.1665 (0.1693)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [150/172]  eta: 0:00:35  lr: 0.000000  loss: 0.1663 (0.1691)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [160/172]  eta: 0:00:19  lr: 0.000000  loss: 0.1658 (0.1689)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [170/172]  eta: 0:00:03  lr: 0.000000  loss: 0.1657 (0.1687)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:1]  [171/172]  eta: 0:00:01  lr: 0.000000  loss: 0.1657 (0.1687)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:1] Total time: 0:04:33 (1.5910 s / it)\n",
      "Averaged stats: lr: 0.000000  loss: 0.1657 (0.1687)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:1]  [ 0/14]  eta: 0:00:04  loss: 0.1662 (0.1662)  time: 0.3141  data: 0.2982  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:1]  [13/14]  eta: 0:00:00  loss: 0.1643 (0.1644)  time: 0.0426  data: 0.0273  max mem: 20571\n",
      "Valid: [epoch:1] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 0.1643 (0.1644)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_1_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.164%\n",
      "Min loss: 0.164\n",
      "Best Epoch: 1.000\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [  0/172]  eta: 0:07:25  lr: 0.000010  loss: 0.1646 (0.1646)  time: 2.5912  data: 1.0190  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [ 10/172]  eta: 0:04:31  lr: 0.000010  loss: 0.0534 (0.0712)  time: 1.6757  data: 0.0927  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [ 20/172]  eta: 0:04:08  lr: 0.000010  loss: 0.0324 (0.0516)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [ 30/172]  eta: 0:03:49  lr: 0.000010  loss: 0.0258 (0.0423)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [ 40/172]  eta: 0:03:32  lr: 0.000010  loss: 0.0187 (0.0361)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 0.0151 (0.0317)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [ 60/172]  eta: 0:02:59  lr: 0.000010  loss: 0.0114 (0.0282)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [ 70/172]  eta: 0:02:43  lr: 0.000010  loss: 0.0086 (0.0254)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [ 80/172]  eta: 0:02:26  lr: 0.000010  loss: 0.0075 (0.0231)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 0.0063 (0.0212)  time: 1.5839  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 0.0050 (0.0196)  time: 1.5842  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.0043 (0.0182)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 0.0040 (0.0170)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 0.0035 (0.0160)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.0029 (0.0150)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [150/172]  eta: 0:00:34  lr: 0.000010  loss: 0.0026 (0.0142)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.0023 (0.0135)  time: 1.5844  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 0.0021 (0.0128)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:2]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.0021 (0.0127)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:2] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.0021 (0.0127)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:2]  [ 0/14]  eta: 0:00:03  loss: 0.0020 (0.0020)  time: 0.2781  data: 0.2635  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:2]  [13/14]  eta: 0:00:00  loss: 0.0016 (0.0017)  time: 0.0385  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:2] Total time: 0:00:00 (0.0439 s / it)\n",
      "Averaged stats: loss: 0.0016 (0.0017)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_2_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.002%\n",
      "Min loss: 0.002\n",
      "Best Epoch: 2.000\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [  0/172]  eta: 0:07:26  lr: 0.000020  loss: 0.0019 (0.0019)  time: 2.5932  data: 1.0003  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [ 10/172]  eta: 0:04:31  lr: 0.000020  loss: 0.0017 (0.0018)  time: 1.6737  data: 0.0910  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [ 20/172]  eta: 0:04:07  lr: 0.000020  loss: 0.0016 (0.0017)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [ 30/172]  eta: 0:03:49  lr: 0.000020  loss: 0.0015 (0.0016)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [ 40/172]  eta: 0:03:32  lr: 0.000020  loss: 0.0012 (0.0015)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [ 50/172]  eta: 0:03:15  lr: 0.000020  loss: 0.0011 (0.0014)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [ 60/172]  eta: 0:02:59  lr: 0.000020  loss: 0.0010 (0.0013)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [ 70/172]  eta: 0:02:42  lr: 0.000020  loss: 0.0009 (0.0012)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.0008 (0.0012)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.0008 (0.0011)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.0007 (0.0011)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.0007 (0.0011)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.0007 (0.0010)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.0006 (0.0010)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.0006 (0.0010)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [150/172]  eta: 0:00:35  lr: 0.000020  loss: 0.0005 (0.0009)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.0005 (0.0009)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.0005 (0.0009)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:3]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.0005 (0.0009)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:3] Total time: 0:04:33 (1.5911 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.0005 (0.0009)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:3]  [ 0/14]  eta: 0:00:04  loss: 0.0004 (0.0004)  time: 0.2874  data: 0.2719  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:3]  [13/14]  eta: 0:00:00  loss: 0.0004 (0.0005)  time: 0.0386  data: 0.0235  max mem: 20571\n",
      "Valid: [epoch:3] Total time: 0:00:00 (0.0466 s / it)\n",
      "Averaged stats: loss: 0.0004 (0.0005)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_3_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 3.000\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [  0/172]  eta: 0:07:28  lr: 0.000030  loss: 0.0005 (0.0005)  time: 2.6102  data: 1.0378  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [ 10/172]  eta: 0:04:31  lr: 0.000030  loss: 0.0004 (0.0005)  time: 1.6746  data: 0.0945  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [ 20/172]  eta: 0:04:07  lr: 0.000030  loss: 0.0005 (0.0005)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [ 30/172]  eta: 0:03:49  lr: 0.000030  loss: 0.0004 (0.0005)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [ 40/172]  eta: 0:03:32  lr: 0.000030  loss: 0.0004 (0.0004)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [ 50/172]  eta: 0:03:15  lr: 0.000030  loss: 0.0004 (0.0004)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [ 60/172]  eta: 0:02:59  lr: 0.000030  loss: 0.0004 (0.0004)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [ 70/172]  eta: 0:02:43  lr: 0.000030  loss: 0.0004 (0.0004)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5842  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5846  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:4]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.0003 (0.0004)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:4] Total time: 0:04:33 (1.5904 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.0003 (0.0004)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:4]  [ 0/14]  eta: 0:00:06  loss: 0.0003 (0.0003)  time: 0.4732  data: 0.4584  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:4]  [13/14]  eta: 0:00:00  loss: 0.0003 (0.0003)  time: 0.0484  data: 0.0333  max mem: 20571\n",
      "Valid: [epoch:4] Total time: 0:00:00 (0.0542 s / it)\n",
      "Averaged stats: loss: 0.0003 (0.0003)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_4_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 4.000\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [  0/172]  eta: 0:08:01  lr: 0.000040  loss: 0.0003 (0.0003)  time: 2.7986  data: 1.2174  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [ 10/172]  eta: 0:04:33  lr: 0.000040  loss: 0.0002 (0.0003)  time: 1.6904  data: 0.1108  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [ 20/172]  eta: 0:04:09  lr: 0.000040  loss: 0.0002 (0.0003)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [ 30/172]  eta: 0:03:50  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5840  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [ 40/172]  eta: 0:03:32  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5858  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [ 50/172]  eta: 0:03:16  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [ 60/172]  eta: 0:02:59  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [ 70/172]  eta: 0:02:43  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [ 80/172]  eta: 0:02:27  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [150/172]  eta: 0:00:35  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:5]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.0002 (0.0002)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:5] Total time: 0:04:33 (1.5916 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.0002 (0.0002)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:5]  [ 0/14]  eta: 0:00:04  loss: 0.0002 (0.0002)  time: 0.3441  data: 0.3256  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:5]  [13/14]  eta: 0:00:00  loss: 0.0002 (0.0002)  time: 0.0406  data: 0.0253  max mem: 20571\n",
      "Valid: [epoch:5] Total time: 0:00:00 (0.0492 s / it)\n",
      "Averaged stats: loss: 0.0002 (0.0002)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_5_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 5.000\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [  0/172]  eta: 0:08:06  lr: 0.000050  loss: 0.0002 (0.0002)  time: 2.8279  data: 1.2605  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [ 10/172]  eta: 0:04:35  lr: 0.000050  loss: 0.0002 (0.0002)  time: 1.6992  data: 0.1147  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [ 20/172]  eta: 0:04:10  lr: 0.000050  loss: 0.0002 (0.0002)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [ 30/172]  eta: 0:03:50  lr: 0.000050  loss: 0.0002 (0.0002)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [ 40/172]  eta: 0:03:33  lr: 0.000050  loss: 0.0002 (0.0002)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [ 50/172]  eta: 0:03:16  lr: 0.000050  loss: 0.0002 (0.0002)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [ 60/172]  eta: 0:02:59  lr: 0.000050  loss: 0.0001 (0.0002)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [ 70/172]  eta: 0:02:43  lr: 0.000050  loss: 0.0001 (0.0002)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [ 80/172]  eta: 0:02:27  lr: 0.000050  loss: 0.0001 (0.0002)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.0001 (0.0002)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.0001 (0.0002)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [150/172]  eta: 0:00:35  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:6]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.0001 (0.0001)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:6] Total time: 0:04:33 (1.5909 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.0001 (0.0001)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:6]  [ 0/14]  eta: 0:00:05  loss: 0.0001 (0.0001)  time: 0.3696  data: 0.3530  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:6]  [13/14]  eta: 0:00:00  loss: 0.0001 (0.0001)  time: 0.0438  data: 0.0287  max mem: 20571\n",
      "Valid: [epoch:6] Total time: 0:00:00 (0.0509 s / it)\n",
      "Averaged stats: loss: 0.0001 (0.0001)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_6_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 6.000\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [  0/172]  eta: 0:07:39  lr: 0.000060  loss: 0.0001 (0.0001)  time: 2.6710  data: 1.0799  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [ 10/172]  eta: 0:04:31  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.6765  data: 0.0983  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [ 20/172]  eta: 0:04:07  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [ 30/172]  eta: 0:03:49  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [ 40/172]  eta: 0:03:32  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [ 60/172]  eta: 0:02:59  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5830  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [ 70/172]  eta: 0:02:42  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5825  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:7]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.0001 (0.0001)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:7] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.0001 (0.0001)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:7]  [ 0/14]  eta: 0:00:04  loss: 0.0001 (0.0001)  time: 0.3519  data: 0.3356  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:7]  [13/14]  eta: 0:00:00  loss: 0.0001 (0.0001)  time: 0.0400  data: 0.0247  max mem: 20571\n",
      "Valid: [epoch:7] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.0001 (0.0001)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_7_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 7.000\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [  0/172]  eta: 0:07:55  lr: 0.000070  loss: 0.0001 (0.0001)  time: 2.7659  data: 1.1987  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [ 10/172]  eta: 0:04:33  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.6874  data: 0.1091  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [ 20/172]  eta: 0:04:08  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [ 30/172]  eta: 0:03:49  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [ 40/172]  eta: 0:03:32  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [ 50/172]  eta: 0:03:15  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [ 70/172]  eta: 0:02:43  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [ 80/172]  eta: 0:02:26  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [ 90/172]  eta: 0:02:10  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [100/172]  eta: 0:01:54  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [110/172]  eta: 0:01:38  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [120/172]  eta: 0:01:22  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [130/172]  eta: 0:01:06  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [140/172]  eta: 0:00:50  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [150/172]  eta: 0:00:34  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:8]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.0001 (0.0001)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:8] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.0001 (0.0001)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:8]  [ 0/14]  eta: 0:00:05  loss: 0.0001 (0.0001)  time: 0.3741  data: 0.3586  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:8]  [13/14]  eta: 0:00:00  loss: 0.0001 (0.0001)  time: 0.0419  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:8] Total time: 0:00:00 (0.0505 s / it)\n",
      "Averaged stats: loss: 0.0001 (0.0001)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_8_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 8.000\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [  0/172]  eta: 0:07:37  lr: 0.000080  loss: 0.0001 (0.0001)  time: 2.6620  data: 1.0874  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [ 10/172]  eta: 0:04:31  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.6763  data: 0.0990  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [ 20/172]  eta: 0:04:07  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [ 30/172]  eta: 0:03:49  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [ 40/172]  eta: 0:03:31  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [ 60/172]  eta: 0:02:58  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:9]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.0001 (0.0001)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:9] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.0001 (0.0001)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:9]  [ 0/14]  eta: 0:00:05  loss: 0.0001 (0.0001)  time: 0.4045  data: 0.3881  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:9]  [13/14]  eta: 0:00:00  loss: 0.0001 (0.0001)  time: 0.0437  data: 0.0287  max mem: 20571\n",
      "Valid: [epoch:9] Total time: 0:00:00 (0.0494 s / it)\n",
      "Averaged stats: loss: 0.0001 (0.0001)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_9_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 9.000\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [  0/172]  eta: 0:08:05  lr: 0.000090  loss: 0.0001 (0.0001)  time: 2.8225  data: 1.2542  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [ 10/172]  eta: 0:04:34  lr: 0.000090  loss: 0.0001 (0.0001)  time: 1.6925  data: 0.1141  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [ 20/172]  eta: 0:04:09  lr: 0.000090  loss: 0.0001 (0.0001)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [ 30/172]  eta: 0:03:50  lr: 0.000090  loss: 0.0001 (0.0001)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [ 40/172]  eta: 0:03:32  lr: 0.000090  loss: 0.0001 (0.0001)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [ 50/172]  eta: 0:03:15  lr: 0.000090  loss: 0.0001 (0.0001)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [ 60/172]  eta: 0:02:59  lr: 0.000090  loss: 0.0001 (0.0001)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.0000 (0.0001)  time: 1.5790  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [ 80/172]  eta: 0:02:26  lr: 0.000090  loss: 0.0000 (0.0001)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.0000 (0.0001)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.0000 (0.0001)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.0000 (0.0001)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.0000 (0.0001)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [160/172]  eta: 0:00:19  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Train: [epoch:10]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.0000 (0.0000)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:10] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.0000 (0.0000)\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:10]  [ 0/14]  eta: 0:00:05  loss: 0.0000 (0.0000)  time: 0.4265  data: 0.4110  max mem: 20571\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Still L2 Loss...!\n",
      "Valid: [epoch:10]  [13/14]  eta: 0:00:00  loss: 0.0000 (0.0000)  time: 0.0450  data: 0.0299  max mem: 20571\n",
      "Valid: [epoch:10] Total time: 0:00:00 (0.0494 s / it)\n",
      "Averaged stats: loss: 0.0000 (0.0000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_10_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:11]  [  0/172]  eta: 0:07:37  lr: 0.000100  loss: 0.0580 (0.0580)  time: 2.6592  data: 1.0744  max mem: 20571\n",
      "Train: [epoch:11]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 1.4110 (1.5069)  time: 1.6752  data: 0.0978  max mem: 20571\n",
      "Train: [epoch:11]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 1.2829 (1.3702)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 1.0884 (1.2667)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.9427 (1.1709)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.8915 (1.1173)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.8566 (1.0691)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.8324 (1.0358)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.8220 (1.0089)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.7949 (0.9853)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.7793 (0.9639)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.7684 (0.9491)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.7684 (0.9344)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.7608 (0.9197)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.7495 (0.9082)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.7374 (0.8976)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.7301 (0.8866)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.7249 (0.8785)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.7309 (0.8777)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:11] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.7309 (0.8777)\n",
      "Valid: [epoch:11]  [ 0/14]  eta: 0:00:04  loss: 0.8482 (0.8482)  time: 0.2973  data: 0.2822  max mem: 20571\n",
      "Valid: [epoch:11]  [13/14]  eta: 0:00:00  loss: 0.7058 (0.7391)  time: 0.0439  data: 0.0288  max mem: 20571\n",
      "Valid: [epoch:11] Total time: 0:00:00 (0.0519 s / it)\n",
      "Averaged stats: loss: 0.7058 (0.7391)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_11_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.739%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:12]  [  0/172]  eta: 0:07:44  lr: 0.000100  loss: 0.8562 (0.8562)  time: 2.7031  data: 1.1359  max mem: 20571\n",
      "Train: [epoch:12]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.7713 (0.7782)  time: 1.6842  data: 0.1034  max mem: 20571\n",
      "Train: [epoch:12]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.7713 (0.7790)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.7881 (0.7849)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.7813 (0.7756)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.7705 (0.7815)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.7967 (0.7828)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.7789 (0.7803)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.7611 (0.7778)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.7523 (0.7759)  time: 1.5819  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.7387 (0.7723)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.7250 (0.7705)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.7462 (0.7697)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.7535 (0.7682)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.7264 (0.7649)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.7141 (0.7617)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.7149 (0.7587)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.7234 (0.7570)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.7234 (0.7568)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:12] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.7234 (0.7568)\n",
      "Valid: [epoch:12]  [ 0/14]  eta: 0:00:05  loss: 0.8211 (0.8211)  time: 0.3577  data: 0.3419  max mem: 20571\n",
      "Valid: [epoch:12]  [13/14]  eta: 0:00:00  loss: 0.6896 (0.7212)  time: 0.0402  data: 0.0253  max mem: 20571\n",
      "Valid: [epoch:12] Total time: 0:00:00 (0.0485 s / it)\n",
      "Averaged stats: loss: 0.6896 (0.7212)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_12_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.721%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:13]  [  0/172]  eta: 0:07:30  lr: 0.000100  loss: 0.7625 (0.7625)  time: 2.6172  data: 1.0343  max mem: 20571\n",
      "Train: [epoch:13]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.7738 (0.7626)  time: 1.6712  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:13]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.7738 (0.7646)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.7612 (0.7594)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.7356 (0.7503)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:13]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.7291 (0.7492)  time: 1.5831  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:13]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.7374 (0.7458)  time: 1.5836  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:13]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.7286 (0.7434)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.7286 (0.7405)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.6976 (0.7351)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.6892 (0.7299)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.6943 (0.7278)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.6897 (0.7249)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.6850 (0.7209)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.6563 (0.7157)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.6613 (0.7130)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.6644 (0.7089)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.6553 (0.7060)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.6553 (0.7055)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:13] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.6553 (0.7055)\n",
      "Valid: [epoch:13]  [ 0/14]  eta: 0:00:07  loss: 0.7448 (0.7448)  time: 0.5271  data: 0.5124  max mem: 20571\n",
      "Valid: [epoch:13]  [13/14]  eta: 0:00:00  loss: 0.6190 (0.6474)  time: 0.0531  data: 0.0377  max mem: 20571\n",
      "Valid: [epoch:13] Total time: 0:00:00 (0.0608 s / it)\n",
      "Averaged stats: loss: 0.6190 (0.6474)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_13_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.647%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:14]  [  0/172]  eta: 0:07:59  lr: 0.000100  loss: 0.6906 (0.6906)  time: 2.7881  data: 1.2172  max mem: 20571\n",
      "Train: [epoch:14]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.6525 (0.6643)  time: 1.6901  data: 0.1108  max mem: 20571\n",
      "Train: [epoch:14]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.6889 (0.6849)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.6889 (0.6811)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.6592 (0.6689)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.6360 (0.6651)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.6413 (0.6620)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.6263 (0.6560)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.6247 (0.6530)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.6247 (0.6505)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.5997 (0.6453)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.5924 (0.6422)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.5948 (0.6392)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.5942 (0.6339)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.5625 (0.6293)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.5580 (0.6248)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.5562 (0.6206)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.5609 (0.6173)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.5609 (0.6169)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:14] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.5609 (0.6169)\n",
      "Valid: [epoch:14]  [ 0/14]  eta: 0:00:05  loss: 0.6230 (0.6230)  time: 0.3770  data: 0.3620  max mem: 20571\n",
      "Valid: [epoch:14]  [13/14]  eta: 0:00:00  loss: 0.5323 (0.5565)  time: 0.0437  data: 0.0288  max mem: 20571\n",
      "Valid: [epoch:14] Total time: 0:00:00 (0.0524 s / it)\n",
      "Averaged stats: loss: 0.5323 (0.5565)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_14_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.556%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:15]  [  0/172]  eta: 0:07:31  lr: 0.000100  loss: 0.6027 (0.6027)  time: 2.6251  data: 1.0467  max mem: 20571\n",
      "Train: [epoch:15]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.5762 (0.5727)  time: 1.6708  data: 0.0953  max mem: 20571\n",
      "Train: [epoch:15]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.5597 (0.5663)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.5312 (0.5454)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.4667 (0.5192)  time: 1.5786  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.4107 (0.4960)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.3709 (0.4720)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.3084 (0.4459)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:15]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.2650 (0.4188)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1932 (0.3922)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1553 (0.3675)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1370 (0.3463)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1297 (0.3284)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1264 (0.3129)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1227 (0.2994)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1170 (0.2871)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1105 (0.2760)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1082 (0.2663)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1082 (0.2654)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:15] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1082 (0.2654)\n",
      "Valid: [epoch:15]  [ 0/14]  eta: 0:00:04  loss: 0.1099 (0.1099)  time: 0.3198  data: 0.3021  max mem: 20571\n",
      "Valid: [epoch:15]  [13/14]  eta: 0:00:00  loss: 0.1081 (0.1077)  time: 0.0389  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:15] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.1081 (0.1077)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_15_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.108%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:16]  [  0/172]  eta: 0:07:27  lr: 0.000100  loss: 0.1130 (0.1130)  time: 2.6026  data: 1.0360  max mem: 20571\n",
      "Train: [epoch:16]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1189 (0.1191)  time: 1.6712  data: 0.0943  max mem: 20571\n",
      "Train: [epoch:16]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1190 (0.1194)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1170 (0.1183)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1141 (0.1167)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1069 (0.1144)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1054 (0.1131)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1064 (0.1122)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1064 (0.1117)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1045 (0.1105)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1011 (0.1096)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1008 (0.1087)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1003 (0.1080)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0980 (0.1071)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0951 (0.1062)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0985 (0.1059)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0984 (0.1052)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0943 (0.1046)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0941 (0.1045)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:16] Total time: 0:04:32 (1.5848 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0941 (0.1045)\n",
      "Valid: [epoch:16]  [ 0/14]  eta: 0:00:04  loss: 0.0888 (0.0888)  time: 0.3291  data: 0.3134  max mem: 20571\n",
      "Valid: [epoch:16]  [13/14]  eta: 0:00:00  loss: 0.0881 (0.0880)  time: 0.0385  data: 0.0235  max mem: 20571\n",
      "Valid: [epoch:16] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.0881 (0.0880)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_16_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.088%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:17]  [  0/172]  eta: 0:07:27  lr: 0.000100  loss: 0.0950 (0.0950)  time: 2.6024  data: 1.0032  max mem: 20571\n",
      "Train: [epoch:17]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.0976 (0.0973)  time: 1.6684  data: 0.0913  max mem: 20571\n",
      "Train: [epoch:17]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.0990 (0.0979)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1000 (0.0991)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1025 (0.0999)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1013 (0.0999)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0986 (0.0989)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0924 (0.0981)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0951 (0.0980)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0959 (0.0977)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0938 (0.0973)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0944 (0.0970)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0940 (0.0967)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0899 (0.0961)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0867 (0.0953)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0839 (0.0945)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0821 (0.0937)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0829 (0.0932)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0833 (0.0931)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:17] Total time: 0:04:32 (1.5844 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0833 (0.0931)\n",
      "Valid: [epoch:17]  [ 0/14]  eta: 0:00:06  loss: 0.0820 (0.0820)  time: 0.4648  data: 0.4479  max mem: 20571\n",
      "Valid: [epoch:17]  [13/14]  eta: 0:00:00  loss: 0.0820 (0.0819)  time: 0.0475  data: 0.0324  max mem: 20571\n",
      "Valid: [epoch:17] Total time: 0:00:00 (0.0556 s / it)\n",
      "Averaged stats: loss: 0.0820 (0.0819)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_17_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.082%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:18]  [  0/172]  eta: 0:07:58  lr: 0.000100  loss: 0.0878 (0.0878)  time: 2.7800  data: 1.2160  max mem: 20571\n",
      "Train: [epoch:18]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0934 (0.0932)  time: 1.6864  data: 0.1107  max mem: 20571\n",
      "Train: [epoch:18]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0940 (0.0938)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:18]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0936 (0.0932)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0925 (0.0933)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0935 (0.0933)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0927 (0.0933)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0915 (0.0929)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0887 (0.0922)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0879 (0.0919)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0867 (0.0911)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0854 (0.0908)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0879 (0.0906)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0882 (0.0904)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0843 (0.0898)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0819 (0.0892)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0790 (0.0885)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0781 (0.0880)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0783 (0.0880)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:18] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0783 (0.0880)\n",
      "Valid: [epoch:18]  [ 0/14]  eta: 0:00:04  loss: 0.0820 (0.0820)  time: 0.2951  data: 0.2804  max mem: 20571\n",
      "Valid: [epoch:18]  [13/14]  eta: 0:00:00  loss: 0.0806 (0.0807)  time: 0.0481  data: 0.0332  max mem: 20571\n",
      "Valid: [epoch:18] Total time: 0:00:00 (0.0540 s / it)\n",
      "Averaged stats: loss: 0.0806 (0.0807)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_18_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.081%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:19]  [  0/172]  eta: 0:07:44  lr: 0.000100  loss: 0.0870 (0.0870)  time: 2.6992  data: 1.1286  max mem: 20571\n",
      "Train: [epoch:19]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.0870 (0.0869)  time: 1.6765  data: 0.1027  max mem: 20571\n",
      "Train: [epoch:19]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.0889 (0.0887)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.0891 (0.0880)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0849 (0.0872)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0848 (0.0868)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0876 (0.0872)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0876 (0.0869)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0824 (0.0862)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0810 (0.0858)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0819 (0.0854)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0809 (0.0848)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0774 (0.0841)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0774 (0.0837)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0803 (0.0837)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0828 (0.0835)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0788 (0.0831)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0775 (0.0829)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0777 (0.0829)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:19] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0777 (0.0829)\n",
      "Valid: [epoch:19]  [ 0/14]  eta: 0:00:03  loss: 0.0775 (0.0775)  time: 0.2818  data: 0.2658  max mem: 20571\n",
      "Valid: [epoch:19]  [13/14]  eta: 0:00:00  loss: 0.0787 (0.0788)  time: 0.0365  data: 0.0215  max mem: 20571\n",
      "Valid: [epoch:19] Total time: 0:00:00 (0.0419 s / it)\n",
      "Averaged stats: loss: 0.0787 (0.0788)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_19_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.079%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:20]  [  0/172]  eta: 0:07:33  lr: 0.000100  loss: 0.0839 (0.0839)  time: 2.6357  data: 1.0687  max mem: 20571\n",
      "Train: [epoch:20]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.0840 (0.0850)  time: 1.6748  data: 0.0973  max mem: 20571\n",
      "Train: [epoch:20]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.0823 (0.0828)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0806 (0.0822)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0834 (0.0836)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0859 (0.0840)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0845 (0.0836)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0794 (0.0830)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0782 (0.0822)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0782 (0.0818)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0817 (0.0821)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0824 (0.0820)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0800 (0.0818)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0775 (0.0813)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0739 (0.0807)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0739 (0.0804)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0745 (0.0800)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0716 (0.0794)  time: 1.5808  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0715 (0.0794)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:20] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0715 (0.0794)\n",
      "Valid: [epoch:20]  [ 0/14]  eta: 0:00:04  loss: 0.0673 (0.0673)  time: 0.2904  data: 0.2745  max mem: 20571\n",
      "Valid: [epoch:20]  [13/14]  eta: 0:00:00  loss: 0.0666 (0.0670)  time: 0.0420  data: 0.0270  max mem: 20571\n",
      "Valid: [epoch:20] Total time: 0:00:00 (0.0499 s / it)\n",
      "Averaged stats: loss: 0.0666 (0.0670)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_20_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.067%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:21]  [  0/172]  eta: 0:08:01  lr: 0.000100  loss: 0.0729 (0.0729)  time: 2.8017  data: 1.2093  max mem: 20571\n",
      "Train: [epoch:21]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0771 (0.0771)  time: 1.6883  data: 0.1101  max mem: 20571\n",
      "Train: [epoch:21]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0798 (0.0791)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0794 (0.0787)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0784 (0.0788)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0795 (0.0791)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0793 (0.0791)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0768 (0.0785)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0739 (0.0779)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0746 (0.0776)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0756 (0.0775)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0752 (0.0773)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0760 (0.0774)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0779 (0.0775)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0758 (0.0773)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0740 (0.0770)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0710 (0.0766)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0701 (0.0762)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0696 (0.0761)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:21] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0696 (0.0761)\n",
      "Valid: [epoch:21]  [ 0/14]  eta: 0:00:04  loss: 0.0639 (0.0639)  time: 0.3359  data: 0.3206  max mem: 20571\n",
      "Valid: [epoch:21]  [13/14]  eta: 0:00:00  loss: 0.0640 (0.0644)  time: 0.0385  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:21] Total time: 0:00:00 (0.0467 s / it)\n",
      "Averaged stats: loss: 0.0640 (0.0644)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_21_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.064%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:22]  [  0/172]  eta: 0:07:52  lr: 0.000100  loss: 0.0706 (0.0706)  time: 2.7475  data: 1.1652  max mem: 20571\n",
      "Train: [epoch:22]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.0743 (0.0738)  time: 1.6847  data: 0.1060  max mem: 20571\n",
      "Train: [epoch:22]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0747 (0.0750)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0804 (0.0776)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:22]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0827 (0.0788)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:22]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0807 (0.0785)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0773 (0.0781)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0774 (0.0783)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0804 (0.0785)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0787 (0.0781)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0728 (0.0776)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0708 (0.0769)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0695 (0.0764)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0748 (0.0765)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0784 (0.0767)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0774 (0.0766)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0758 (0.0766)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0759 (0.0764)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0758 (0.0764)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:22] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0758 (0.0764)\n",
      "Valid: [epoch:22]  [ 0/14]  eta: 0:00:04  loss: 0.0676 (0.0676)  time: 0.2867  data: 0.2718  max mem: 20571\n",
      "Valid: [epoch:22]  [13/14]  eta: 0:00:00  loss: 0.0656 (0.0664)  time: 0.0379  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:22] Total time: 0:00:00 (0.0459 s / it)\n",
      "Averaged stats: loss: 0.0656 (0.0664)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_22_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.066%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:23]  [  0/172]  eta: 0:07:52  lr: 0.000100  loss: 0.0712 (0.0712)  time: 2.7443  data: 1.1546  max mem: 20571\n",
      "Train: [epoch:23]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.0790 (0.0781)  time: 1.6813  data: 0.1051  max mem: 20571\n",
      "Train: [epoch:23]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.0804 (0.0800)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0802 (0.0788)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0773 (0.0790)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0785 (0.0788)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0746 (0.0777)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0736 (0.0771)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0759 (0.0776)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0770 (0.0774)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0725 (0.0767)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0706 (0.0762)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0707 (0.0758)  time: 1.5769  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:23]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0706 (0.0754)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0723 (0.0753)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0753 (0.0754)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0743 (0.0752)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0704 (0.0748)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0701 (0.0748)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:23] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0701 (0.0748)\n",
      "Valid: [epoch:23]  [ 0/14]  eta: 0:00:05  loss: 0.0638 (0.0638)  time: 0.3845  data: 0.3656  max mem: 20571\n",
      "Valid: [epoch:23]  [13/14]  eta: 0:00:00  loss: 0.0653 (0.0657)  time: 0.0422  data: 0.0267  max mem: 20571\n",
      "Valid: [epoch:23] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.0653 (0.0657)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_23_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.066%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:24]  [  0/172]  eta: 0:07:45  lr: 0.000100  loss: 0.0717 (0.0717)  time: 2.7084  data: 1.1444  max mem: 20571\n",
      "Train: [epoch:24]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.0716 (0.0714)  time: 1.6784  data: 0.1042  max mem: 20571\n",
      "Train: [epoch:24]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.0717 (0.0724)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0734 (0.0729)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0748 (0.0736)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0773 (0.0747)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0785 (0.0752)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0762 (0.0751)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0716 (0.0745)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0704 (0.0742)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0729 (0.0743)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0762 (0.0745)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0754 (0.0745)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0738 (0.0744)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0736 (0.0744)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0739 (0.0745)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0744 (0.0745)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0728 (0.0744)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0726 (0.0744)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:24] Total time: 0:04:32 (1.5850 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0726 (0.0744)\n",
      "Valid: [epoch:24]  [ 0/14]  eta: 0:00:04  loss: 0.0690 (0.0690)  time: 0.3260  data: 0.3091  max mem: 20571\n",
      "Valid: [epoch:24]  [13/14]  eta: 0:00:00  loss: 0.0690 (0.0694)  time: 0.0381  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:24] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.0690 (0.0694)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_24_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.069%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:25]  [  0/172]  eta: 0:07:15  lr: 0.000100  loss: 0.0740 (0.0740)  time: 2.5328  data: 0.9526  max mem: 20571\n",
      "Train: [epoch:25]  [ 10/172]  eta: 0:04:29  lr: 0.000100  loss: 0.0747 (0.0750)  time: 1.6632  data: 0.0867  max mem: 20571\n",
      "Train: [epoch:25]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.0746 (0.0751)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.0745 (0.0749)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0759 (0.0756)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.0773 (0.0756)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0733 (0.0752)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0733 (0.0750)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0726 (0.0746)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0716 (0.0743)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0726 (0.0743)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0754 (0.0745)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0760 (0.0746)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0746 (0.0745)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0746 (0.0746)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0783 (0.0748)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0761 (0.0749)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0763 (0.0751)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0763 (0.0752)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:25] Total time: 0:04:32 (1.5838 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0763 (0.0752)\n",
      "Valid: [epoch:25]  [ 0/14]  eta: 0:00:04  loss: 0.0747 (0.0747)  time: 0.3059  data: 0.2891  max mem: 20571\n",
      "Valid: [epoch:25]  [13/14]  eta: 0:00:00  loss: 0.0750 (0.0753)  time: 0.0365  data: 0.0215  max mem: 20571\n",
      "Valid: [epoch:25] Total time: 0:00:00 (0.0412 s / it)\n",
      "Averaged stats: loss: 0.0750 (0.0753)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_25_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.075%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:26]  [  0/172]  eta: 0:07:13  lr: 0.000100  loss: 0.0768 (0.0768)  time: 2.5204  data: 0.9533  max mem: 20571\n",
      "Train: [epoch:26]  [ 10/172]  eta: 0:04:29  lr: 0.000100  loss: 0.0824 (0.0815)  time: 1.6643  data: 0.0868  max mem: 20571\n",
      "Train: [epoch:26]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.0825 (0.0825)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.0823 (0.0823)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0822 (0.0825)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:26]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.0832 (0.0829)  time: 1.5783  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:26]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0832 (0.0825)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0774 (0.0815)  time: 1.5776  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:26]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0735 (0.0804)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0726 (0.0795)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0732 (0.0793)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0780 (0.0792)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0751 (0.0788)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:26]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0725 (0.0782)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:26]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0716 (0.0779)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0751 (0.0778)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0758 (0.0776)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0744 (0.0774)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0739 (0.0774)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:26] Total time: 0:04:32 (1.5845 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0739 (0.0774)\n",
      "Valid: [epoch:26]  [ 0/14]  eta: 0:00:04  loss: 0.0713 (0.0713)  time: 0.3282  data: 0.3128  max mem: 20571\n",
      "Valid: [epoch:26]  [13/14]  eta: 0:00:00  loss: 0.0685 (0.0693)  time: 0.0400  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:26] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.0685 (0.0693)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_26_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.069%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:27]  [  0/172]  eta: 0:07:16  lr: 0.000100  loss: 0.0734 (0.0734)  time: 2.5384  data: 0.9597  max mem: 20571\n",
      "Train: [epoch:27]  [ 10/172]  eta: 0:04:29  lr: 0.000100  loss: 0.0774 (0.0778)  time: 1.6622  data: 0.0874  max mem: 20571\n",
      "Train: [epoch:27]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.0797 (0.0794)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.0822 (0.0803)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0826 (0.0809)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.0819 (0.0809)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0737 (0.0793)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0718 (0.0784)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0733 (0.0781)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0822 (0.0787)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:27]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0816 (0.0787)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0768 (0.0784)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0746 (0.0782)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0734 (0.0776)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0721 (0.0772)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0741 (0.0771)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [160/172]  eta: 0:00:18  lr: 0.000100  loss: 0.0765 (0.0771)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0762 (0.0771)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0750 (0.0771)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:27] Total time: 0:04:32 (1.5835 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0750 (0.0771)\n",
      "Valid: [epoch:27]  [ 0/14]  eta: 0:00:03  loss: 0.0718 (0.0718)  time: 0.2710  data: 0.2558  max mem: 20571\n",
      "Valid: [epoch:27]  [13/14]  eta: 0:00:00  loss: 0.0723 (0.0731)  time: 0.0394  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:27] Total time: 0:00:00 (0.0442 s / it)\n",
      "Averaged stats: loss: 0.0723 (0.0731)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_27_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.073%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:28]  [  0/172]  eta: 0:07:15  lr: 0.000100  loss: 0.0780 (0.0780)  time: 2.5301  data: 0.9657  max mem: 20571\n",
      "Train: [epoch:28]  [ 10/172]  eta: 0:04:29  lr: 0.000100  loss: 0.0808 (0.0828)  time: 1.6657  data: 0.0879  max mem: 20571\n",
      "Train: [epoch:28]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.0838 (0.0852)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.0923 (0.0883)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0950 (0.0897)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.0900 (0.0891)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0838 (0.0879)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0812 (0.0871)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0796 (0.0858)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0764 (0.0846)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0741 (0.0834)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0731 (0.0826)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0744 (0.0819)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0723 (0.0811)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0713 (0.0803)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0711 (0.0795)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0683 (0.0789)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0711 (0.0787)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0723 (0.0787)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:28] Total time: 0:04:32 (1.5839 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0723 (0.0787)\n",
      "Valid: [epoch:28]  [ 0/14]  eta: 0:00:04  loss: 0.0721 (0.0721)  time: 0.2886  data: 0.2736  max mem: 20571\n",
      "Valid: [epoch:28]  [13/14]  eta: 0:00:00  loss: 0.0731 (0.0737)  time: 0.0480  data: 0.0330  max mem: 20571\n",
      "Valid: [epoch:28] Total time: 0:00:00 (0.0560 s / it)\n",
      "Averaged stats: loss: 0.0731 (0.0737)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_28_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.074%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:29]  [  0/172]  eta: 0:07:50  lr: 0.000100  loss: 0.0792 (0.0792)  time: 2.7328  data: 1.1572  max mem: 20571\n",
      "Train: [epoch:29]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.0792 (0.0789)  time: 1.6798  data: 0.1053  max mem: 20571\n",
      "Train: [epoch:29]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.0777 (0.0782)  time: 1.5758  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:29]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0777 (0.0781)  time: 1.5764  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:29]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0779 (0.0783)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0779 (0.0783)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0777 (0.0782)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0759 (0.0779)  time: 1.5757  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:29]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0770 (0.0780)  time: 1.5757  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:29]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0790 (0.0782)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0786 (0.0782)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0782 (0.0781)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0784 (0.0782)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0795 (0.0785)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0840 (0.0791)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0859 (0.0795)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0817 (0.0795)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0793 (0.0793)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0780 (0.0793)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:29] Total time: 0:04:32 (1.5844 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0780 (0.0793)\n",
      "Valid: [epoch:29]  [ 0/14]  eta: 0:00:04  loss: 0.0752 (0.0752)  time: 0.2937  data: 0.2788  max mem: 20571\n",
      "Valid: [epoch:29]  [13/14]  eta: 0:00:00  loss: 0.0723 (0.0729)  time: 0.0383  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:29] Total time: 0:00:00 (0.0458 s / it)\n",
      "Averaged stats: loss: 0.0723 (0.0729)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_29_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.073%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:30]  [  0/172]  eta: 0:07:59  lr: 0.000100  loss: 0.0779 (0.0779)  time: 2.7867  data: 1.2233  max mem: 20571\n",
      "Train: [epoch:30]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0767 (0.0771)  time: 1.6885  data: 0.1113  max mem: 20571\n",
      "Train: [epoch:30]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0785 (0.0794)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0820 (0.0807)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0803 (0.0798)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0761 (0.0791)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0754 (0.0786)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0760 (0.0784)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0767 (0.0784)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0766 (0.0782)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0762 (0.0780)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0753 (0.0778)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0754 (0.0778)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0777 (0.0777)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0757 (0.0776)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0762 (0.0775)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0763 (0.0774)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0763 (0.0774)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0763 (0.0774)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:30] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0763 (0.0774)\n",
      "Valid: [epoch:30]  [ 0/14]  eta: 0:00:08  loss: 0.0734 (0.0734)  time: 0.6089  data: 0.5922  max mem: 20571\n",
      "Valid: [epoch:30]  [13/14]  eta: 0:00:00  loss: 0.0708 (0.0715)  time: 0.0583  data: 0.0432  max mem: 20571\n",
      "Valid: [epoch:30] Total time: 0:00:00 (0.0637 s / it)\n",
      "Averaged stats: loss: 0.0708 (0.0715)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_30_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.072%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:31]  [  0/172]  eta: 0:07:41  lr: 0.000100  loss: 0.0756 (0.0756)  time: 2.6827  data: 1.1064  max mem: 20571\n",
      "Train: [epoch:31]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.0817 (0.0810)  time: 1.6749  data: 0.1007  max mem: 20571\n",
      "Train: [epoch:31]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.0791 (0.0797)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.0784 (0.0795)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.0791 (0.0802)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0827 (0.0807)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0830 (0.0811)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0838 (0.0818)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0839 (0.0825)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0890 (0.0832)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0903 (0.0840)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0892 (0.0842)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0843 (0.0841)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0841 (0.0842)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0841 (0.0842)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0842 (0.0845)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0879 (0.0847)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0878 (0.0848)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0879 (0.0849)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:31] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0879 (0.0849)\n",
      "Valid: [epoch:31]  [ 0/14]  eta: 0:00:05  loss: 0.0908 (0.0908)  time: 0.3658  data: 0.3495  max mem: 20571\n",
      "Valid: [epoch:31]  [13/14]  eta: 0:00:00  loss: 0.0889 (0.0897)  time: 0.0414  data: 0.0263  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:31] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.0889 (0.0897)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_31_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.090%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:32]  [  0/172]  eta: 0:07:54  lr: 0.000100  loss: 0.0950 (0.0950)  time: 2.7608  data: 1.1914  max mem: 20571\n",
      "Train: [epoch:32]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0924 (0.0921)  time: 1.6870  data: 0.1085  max mem: 20571\n",
      "Train: [epoch:32]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0889 (0.0908)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:32]  [ 30/172]  eta: 0:03:50  lr: 0.000100  loss: 0.0874 (0.0900)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0902 (0.0903)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0882 (0.0894)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0863 (0.0888)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.0880 (0.0889)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0883 (0.0886)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0864 (0.0882)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0857 (0.0879)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0871 (0.0885)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0920 (0.0887)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0900 (0.0887)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0886 (0.0888)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0890 (0.0889)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0891 (0.0889)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0888 (0.0889)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0891 (0.0889)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:32] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0891 (0.0889)\n",
      "Valid: [epoch:32]  [ 0/14]  eta: 0:00:04  loss: 0.0843 (0.0843)  time: 0.3538  data: 0.3387  max mem: 20571\n",
      "Valid: [epoch:32]  [13/14]  eta: 0:00:00  loss: 0.0819 (0.0827)  time: 0.0401  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:32] Total time: 0:00:00 (0.0451 s / it)\n",
      "Averaged stats: loss: 0.0819 (0.0827)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_32_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.083%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:33]  [  0/172]  eta: 0:07:29  lr: 0.000100  loss: 0.0860 (0.0860)  time: 2.6132  data: 1.0346  max mem: 20571\n",
      "Train: [epoch:33]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.0915 (0.0907)  time: 1.6724  data: 0.0942  max mem: 20571\n",
      "Train: [epoch:33]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.0915 (0.0916)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0943 (0.0930)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0935 (0.0927)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0877 (0.0916)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0867 (0.0910)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0868 (0.0906)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0870 (0.0901)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0857 (0.0897)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0834 (0.0888)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0817 (0.0882)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0828 (0.0879)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0827 (0.0874)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0812 (0.0871)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0831 (0.0869)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0829 (0.0866)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0836 (0.0865)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0834 (0.0865)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:33] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0834 (0.0865)\n",
      "Valid: [epoch:33]  [ 0/14]  eta: 0:00:06  loss: 0.0785 (0.0785)  time: 0.4942  data: 0.4772  max mem: 20571\n",
      "Valid: [epoch:33]  [13/14]  eta: 0:00:00  loss: 0.0813 (0.0818)  time: 0.0508  data: 0.0356  max mem: 20571\n",
      "Valid: [epoch:33] Total time: 0:00:00 (0.0559 s / it)\n",
      "Averaged stats: loss: 0.0813 (0.0818)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_33_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.082%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:34]  [  0/172]  eta: 0:07:55  lr: 0.000100  loss: 0.0860 (0.0860)  time: 2.7635  data: 1.1945  max mem: 20571\n",
      "Train: [epoch:34]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0852 (0.0855)  time: 1.6875  data: 0.1087  max mem: 20571\n",
      "Train: [epoch:34]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0876 (0.0870)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0892 (0.0885)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0943 (0.0902)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0943 (0.0905)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0909 (0.0905)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.0911 (0.0905)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0906 (0.0904)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0898 (0.0905)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0913 (0.0908)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0927 (0.0909)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0944 (0.0915)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0964 (0.0918)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0940 (0.0919)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0912 (0.0918)  time: 1.5822  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:34]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0885 (0.0916)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0878 (0.0913)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0878 (0.0913)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:34] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0878 (0.0913)\n",
      "Valid: [epoch:34]  [ 0/14]  eta: 0:00:03  loss: 0.0918 (0.0918)  time: 0.2767  data: 0.2618  max mem: 20571\n",
      "Valid: [epoch:34]  [13/14]  eta: 0:00:00  loss: 0.0895 (0.0898)  time: 0.0363  data: 0.0214  max mem: 20571\n",
      "Valid: [epoch:34] Total time: 0:00:00 (0.0420 s / it)\n",
      "Averaged stats: loss: 0.0895 (0.0898)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_34_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.090%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:35]  [  0/172]  eta: 0:07:58  lr: 0.000100  loss: 0.0930 (0.0930)  time: 2.7824  data: 1.2089  max mem: 20571\n",
      "Train: [epoch:35]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0952 (0.0934)  time: 1.6883  data: 0.1100  max mem: 20571\n",
      "Train: [epoch:35]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0954 (0.0945)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0954 (0.0947)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0943 (0.0943)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0899 (0.0932)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0884 (0.0926)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0892 (0.0923)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0899 (0.0923)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0908 (0.0922)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0912 (0.0921)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0904 (0.0919)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0898 (0.0917)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0884 (0.0915)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0883 (0.0913)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0874 (0.0911)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0882 (0.0909)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0869 (0.0905)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0869 (0.0904)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:35] Total time: 0:04:33 (1.5897 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0869 (0.0904)\n",
      "Valid: [epoch:35]  [ 0/14]  eta: 0:00:04  loss: 0.0838 (0.0838)  time: 0.3421  data: 0.3253  max mem: 20571\n",
      "Valid: [epoch:35]  [13/14]  eta: 0:00:00  loss: 0.0805 (0.0816)  time: 0.0392  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:35] Total time: 0:00:00 (0.0445 s / it)\n",
      "Averaged stats: loss: 0.0805 (0.0816)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_35_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.082%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:36]  [  0/172]  eta: 0:07:43  lr: 0.000100  loss: 0.0869 (0.0869)  time: 2.6962  data: 1.1254  max mem: 20571\n",
      "Train: [epoch:36]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.0844 (0.0857)  time: 1.6844  data: 0.1024  max mem: 20571\n",
      "Train: [epoch:36]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0839 (0.0850)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0839 (0.0846)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0840 (0.0847)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0853 (0.0848)  time: 1.5832  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:36]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0818 (0.0840)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.0824 (0.0839)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0834 (0.0838)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0847 (0.0841)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0865 (0.0846)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0896 (0.0852)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0892 (0.0856)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0876 (0.0857)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0860 (0.0857)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0866 (0.0859)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0873 (0.0860)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0873 (0.0861)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0868 (0.0861)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:36] Total time: 0:04:33 (1.5907 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0868 (0.0861)\n",
      "Valid: [epoch:36]  [ 0/14]  eta: 0:00:06  loss: 0.0876 (0.0876)  time: 0.4627  data: 0.4480  max mem: 20571\n",
      "Valid: [epoch:36]  [13/14]  eta: 0:00:00  loss: 0.0882 (0.0892)  time: 0.0483  data: 0.0333  max mem: 20571\n",
      "Valid: [epoch:36] Total time: 0:00:00 (0.0534 s / it)\n",
      "Averaged stats: loss: 0.0882 (0.0892)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_36_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.089%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:37]  [  0/172]  eta: 0:08:25  lr: 0.000100  loss: 0.0916 (0.0916)  time: 2.9379  data: 1.3557  max mem: 20571\n",
      "Train: [epoch:37]  [ 10/172]  eta: 0:04:35  lr: 0.000100  loss: 0.0916 (0.0914)  time: 1.7001  data: 0.1233  max mem: 20571\n",
      "Train: [epoch:37]  [ 20/172]  eta: 0:04:09  lr: 0.000100  loss: 0.0921 (0.0911)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [ 30/172]  eta: 0:03:50  lr: 0.000100  loss: 0.0895 (0.0902)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [ 40/172]  eta: 0:03:33  lr: 0.000100  loss: 0.0897 (0.0909)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [ 50/172]  eta: 0:03:16  lr: 0.000100  loss: 0.0913 (0.0903)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0895 (0.0905)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.0917 (0.0905)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [ 80/172]  eta: 0:02:27  lr: 0.000100  loss: 0.0919 (0.0907)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0919 (0.0908)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0913 (0.0909)  time: 1.5837  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:37]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0938 (0.0915)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0988 (0.0921)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0991 (0.0927)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0993 (0.0932)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0991 (0.0934)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0950 (0.0934)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0949 (0.0934)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0949 (0.0935)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:37] Total time: 0:04:33 (1.5901 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0949 (0.0935)\n",
      "Valid: [epoch:37]  [ 0/14]  eta: 0:00:03  loss: 0.0843 (0.0843)  time: 0.2811  data: 0.2665  max mem: 20571\n",
      "Valid: [epoch:37]  [13/14]  eta: 0:00:00  loss: 0.0843 (0.0852)  time: 0.0432  data: 0.0283  max mem: 20571\n",
      "Valid: [epoch:37] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 0.0843 (0.0852)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_37_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.085%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:38]  [  0/172]  eta: 0:07:51  lr: 0.000100  loss: 0.0858 (0.0858)  time: 2.7410  data: 1.1721  max mem: 20571\n",
      "Train: [epoch:38]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0963 (0.0975)  time: 1.6866  data: 0.1067  max mem: 20571\n",
      "Train: [epoch:38]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0980 (0.0983)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0965 (0.0974)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:38]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0968 (0.0980)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0993 (0.0983)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0968 (0.0981)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0964 (0.0978)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0958 (0.0976)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0954 (0.0972)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0935 (0.0969)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0953 (0.0970)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0992 (0.0974)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0999 (0.0975)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0979 (0.0976)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0980 (0.0978)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0979 (0.0977)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0954 (0.0976)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0964 (0.0976)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:38] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0964 (0.0976)\n",
      "Valid: [epoch:38]  [ 0/14]  eta: 0:00:06  loss: 0.0908 (0.0908)  time: 0.4286  data: 0.4122  max mem: 20571\n",
      "Valid: [epoch:38]  [13/14]  eta: 0:00:00  loss: 0.0935 (0.0945)  time: 0.0463  data: 0.0311  max mem: 20571\n",
      "Valid: [epoch:38] Total time: 0:00:00 (0.0514 s / it)\n",
      "Averaged stats: loss: 0.0935 (0.0945)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_38_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.094%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:39]  [  0/172]  eta: 0:07:46  lr: 0.000100  loss: 0.1018 (0.1018)  time: 2.7131  data: 1.1309  max mem: 20571\n",
      "Train: [epoch:39]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1011 (0.1019)  time: 1.6822  data: 0.1029  max mem: 20571\n",
      "Train: [epoch:39]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1024 (0.1029)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1031 (0.1023)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1014 (0.1018)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0991 (0.1009)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0917 (0.0992)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0907 (0.0982)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0871 (0.0965)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0868 (0.0958)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0882 (0.0950)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0879 (0.0943)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0869 (0.0936)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0845 (0.0928)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0815 (0.0921)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0813 (0.0914)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0796 (0.0907)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0781 (0.0899)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0783 (0.0898)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:39] Total time: 0:04:33 (1.5896 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0783 (0.0898)\n",
      "Valid: [epoch:39]  [ 0/14]  eta: 0:00:04  loss: 0.0823 (0.0823)  time: 0.2952  data: 0.2806  max mem: 20571\n",
      "Valid: [epoch:39]  [13/14]  eta: 0:00:00  loss: 0.0769 (0.0786)  time: 0.0368  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:39] Total time: 0:00:00 (0.0424 s / it)\n",
      "Averaged stats: loss: 0.0769 (0.0786)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_39_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.079%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:40]  [  0/172]  eta: 0:08:38  lr: 0.000100  loss: 0.0842 (0.0842)  time: 3.0164  data: 1.4329  max mem: 20571\n",
      "Train: [epoch:40]  [ 10/172]  eta: 0:04:37  lr: 0.000100  loss: 0.0788 (0.0798)  time: 1.7102  data: 0.1304  max mem: 20571\n",
      "Train: [epoch:40]  [ 20/172]  eta: 0:04:10  lr: 0.000100  loss: 0.0788 (0.0805)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [ 30/172]  eta: 0:03:51  lr: 0.000100  loss: 0.0805 (0.0801)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [ 40/172]  eta: 0:03:33  lr: 0.000100  loss: 0.0808 (0.0809)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [ 50/172]  eta: 0:03:16  lr: 0.000100  loss: 0.0808 (0.0808)  time: 1.5802  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:40]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0805 (0.0806)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.0793 (0.0805)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [ 80/172]  eta: 0:02:27  lr: 0.000100  loss: 0.0779 (0.0802)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0779 (0.0801)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0788 (0.0800)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0794 (0.0798)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0736 (0.0795)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0728 (0.0790)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0746 (0.0789)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0788 (0.0788)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0754 (0.0787)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0771 (0.0787)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0771 (0.0787)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:40] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0771 (0.0787)\n",
      "Valid: [epoch:40]  [ 0/14]  eta: 0:00:03  loss: 0.0698 (0.0698)  time: 0.2732  data: 0.2582  max mem: 20571\n",
      "Valid: [epoch:40]  [13/14]  eta: 0:00:00  loss: 0.0751 (0.0765)  time: 0.0356  data: 0.0207  max mem: 20571\n",
      "Valid: [epoch:40] Total time: 0:00:00 (0.0406 s / it)\n",
      "Averaged stats: loss: 0.0751 (0.0765)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_40_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.077%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:41]  [  0/172]  eta: 0:07:55  lr: 0.000100  loss: 0.0775 (0.0775)  time: 2.7643  data: 1.1736  max mem: 20571\n",
      "Train: [epoch:41]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.0805 (0.0806)  time: 1.6851  data: 0.1068  max mem: 20571\n",
      "Train: [epoch:41]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0803 (0.0796)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0803 (0.0795)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0785 (0.0791)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0786 (0.0791)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0786 (0.0790)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0776 (0.0789)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0776 (0.0791)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0780 (0.0790)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0780 (0.0789)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0766 (0.0789)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0765 (0.0787)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0764 (0.0786)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0771 (0.0785)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0784 (0.0784)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0784 (0.0783)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0777 (0.0783)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0771 (0.0783)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:41] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0771 (0.0783)\n",
      "Valid: [epoch:41]  [ 0/14]  eta: 0:00:04  loss: 0.0744 (0.0744)  time: 0.3225  data: 0.3055  max mem: 20571\n",
      "Valid: [epoch:41]  [13/14]  eta: 0:00:00  loss: 0.0745 (0.0759)  time: 0.0412  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:41] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.0745 (0.0759)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_41_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.076%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:42]  [  0/172]  eta: 0:08:03  lr: 0.000100  loss: 0.0753 (0.0753)  time: 2.8128  data: 1.2452  max mem: 20571\n",
      "Train: [epoch:42]  [ 10/172]  eta: 0:04:34  lr: 0.000100  loss: 0.0837 (0.0825)  time: 1.6922  data: 0.1133  max mem: 20571\n",
      "Train: [epoch:42]  [ 20/172]  eta: 0:04:09  lr: 0.000100  loss: 0.0825 (0.0812)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [ 30/172]  eta: 0:03:50  lr: 0.000100  loss: 0.0796 (0.0807)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0803 (0.0809)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [ 50/172]  eta: 0:03:16  lr: 0.000100  loss: 0.0784 (0.0803)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0784 (0.0803)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.0795 (0.0802)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0795 (0.0802)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0804 (0.0803)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0804 (0.0803)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0804 (0.0804)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0800 (0.0801)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0776 (0.0801)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0785 (0.0800)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0811 (0.0802)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0805 (0.0802)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0802 (0.0803)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0802 (0.0802)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:42] Total time: 0:04:33 (1.5900 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0802 (0.0802)\n",
      "Valid: [epoch:42]  [ 0/14]  eta: 0:00:08  loss: 0.0780 (0.0780)  time: 0.6204  data: 0.6021  max mem: 20571\n",
      "Valid: [epoch:42]  [13/14]  eta: 0:00:00  loss: 0.0703 (0.0720)  time: 0.0593  data: 0.0442  max mem: 20571\n",
      "Valid: [epoch:42] Total time: 0:00:00 (0.0662 s / it)\n",
      "Averaged stats: loss: 0.0703 (0.0720)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_42_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.072%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:43]  [  0/172]  eta: 0:07:53  lr: 0.000100  loss: 0.0716 (0.0716)  time: 2.7545  data: 1.1771  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:43]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0849 (0.0824)  time: 1.6860  data: 0.1071  max mem: 20571\n",
      "Train: [epoch:43]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0823 (0.0829)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0817 (0.0828)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0834 (0.0828)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0847 (0.0835)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0826 (0.0830)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0814 (0.0828)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0838 (0.0830)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0824 (0.0828)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0801 (0.0826)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0824 (0.0827)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0824 (0.0827)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0818 (0.0826)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0807 (0.0825)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0809 (0.0825)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0809 (0.0825)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0832 (0.0826)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0808 (0.0825)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:43] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0808 (0.0825)\n",
      "Valid: [epoch:43]  [ 0/14]  eta: 0:00:05  loss: 0.0705 (0.0705)  time: 0.3599  data: 0.3442  max mem: 20571\n",
      "Valid: [epoch:43]  [13/14]  eta: 0:00:00  loss: 0.0705 (0.0725)  time: 0.0422  data: 0.0272  max mem: 20571\n",
      "Valid: [epoch:43] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.0705 (0.0725)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_43_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.072%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:44]  [  0/172]  eta: 0:07:47  lr: 0.000100  loss: 0.0749 (0.0749)  time: 2.7209  data: 1.1513  max mem: 20571\n",
      "Train: [epoch:44]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.0847 (0.0845)  time: 1.6838  data: 0.1048  max mem: 20571\n",
      "Train: [epoch:44]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0859 (0.0854)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0856 (0.0859)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0855 (0.0855)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0864 (0.0855)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0852 (0.0854)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0826 (0.0853)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0818 (0.0851)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0816 (0.0849)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0836 (0.0850)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0851 (0.0851)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0844 (0.0850)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0838 (0.0850)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0816 (0.0848)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0825 (0.0848)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0859 (0.0848)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0837 (0.0849)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0829 (0.0848)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:44] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0829 (0.0848)\n",
      "Valid: [epoch:44]  [ 0/14]  eta: 0:00:06  loss: 0.0739 (0.0739)  time: 0.4354  data: 0.4184  max mem: 20571\n",
      "Valid: [epoch:44]  [13/14]  eta: 0:00:00  loss: 0.0803 (0.0820)  time: 0.0470  data: 0.0318  max mem: 20571\n",
      "Valid: [epoch:44] Total time: 0:00:00 (0.0530 s / it)\n",
      "Averaged stats: loss: 0.0803 (0.0820)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_44_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.082%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:45]  [  0/172]  eta: 0:08:14  lr: 0.000100  loss: 0.0794 (0.0794)  time: 2.8742  data: 1.2909  max mem: 20571\n",
      "Train: [epoch:45]  [ 10/172]  eta: 0:04:34  lr: 0.000100  loss: 0.0882 (0.0878)  time: 1.6952  data: 0.1175  max mem: 20571\n",
      "Train: [epoch:45]  [ 20/172]  eta: 0:04:09  lr: 0.000100  loss: 0.0882 (0.0880)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [ 30/172]  eta: 0:03:50  lr: 0.000100  loss: 0.0879 (0.0880)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0873 (0.0879)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [ 50/172]  eta: 0:03:16  lr: 0.000100  loss: 0.0873 (0.0880)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0865 (0.0878)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.0874 (0.0876)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [ 80/172]  eta: 0:02:27  lr: 0.000100  loss: 0.0874 (0.0876)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0868 (0.0877)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:45]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0876 (0.0876)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0872 (0.0874)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0843 (0.0874)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0855 (0.0873)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0852 (0.0872)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0846 (0.0871)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0841 (0.0870)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0855 (0.0871)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0862 (0.0871)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:45] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0862 (0.0871)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:45]  [ 0/14]  eta: 0:00:05  loss: 0.0851 (0.0851)  time: 0.3601  data: 0.3417  max mem: 20571\n",
      "Valid: [epoch:45]  [13/14]  eta: 0:00:00  loss: 0.0780 (0.0804)  time: 0.0408  data: 0.0255  max mem: 20571\n",
      "Valid: [epoch:45] Total time: 0:00:00 (0.0460 s / it)\n",
      "Averaged stats: loss: 0.0780 (0.0804)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_45_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.080%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:46]  [  0/172]  eta: 0:07:52  lr: 0.000100  loss: 0.0757 (0.0757)  time: 2.7484  data: 1.1796  max mem: 20571\n",
      "Train: [epoch:46]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0891 (0.0880)  time: 1.6871  data: 0.1073  max mem: 20571\n",
      "Train: [epoch:46]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0891 (0.0886)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0886 (0.0888)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0889 (0.0893)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0899 (0.0896)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0885 (0.0898)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.0861 (0.0894)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:46]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0880 (0.0893)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:46]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0894 (0.0895)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:46]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0872 (0.0892)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:46]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0879 (0.0894)  time: 1.5831  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:46]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0888 (0.0893)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0888 (0.0892)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0899 (0.0893)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0891 (0.0893)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0882 (0.0893)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0882 (0.0892)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0882 (0.0891)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:46] Total time: 0:04:33 (1.5897 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0882 (0.0891)\n",
      "Valid: [epoch:46]  [ 0/14]  eta: 0:00:04  loss: 0.0916 (0.0916)  time: 0.2899  data: 0.2753  max mem: 20571\n",
      "Valid: [epoch:46]  [13/14]  eta: 0:00:00  loss: 0.0858 (0.0873)  time: 0.0387  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:46] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.0858 (0.0873)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_46_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.087%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:47]  [  0/172]  eta: 0:08:01  lr: 0.000100  loss: 0.0879 (0.0879)  time: 2.8016  data: 1.2217  max mem: 20571\n",
      "Train: [epoch:47]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0931 (0.0946)  time: 1.6884  data: 0.1112  max mem: 20571\n",
      "Train: [epoch:47]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0931 (0.0935)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0915 (0.0931)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0909 (0.0930)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0949 (0.0933)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0927 (0.0929)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0884 (0.0926)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0884 (0.0921)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0879 (0.0918)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0884 (0.0917)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0884 (0.0915)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0878 (0.0914)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0893 (0.0913)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0899 (0.0913)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0902 (0.0911)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0882 (0.0910)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0877 (0.0909)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0874 (0.0909)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:47] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0874 (0.0909)\n",
      "Valid: [epoch:47]  [ 0/14]  eta: 0:00:04  loss: 0.0775 (0.0775)  time: 0.3164  data: 0.3008  max mem: 20571\n",
      "Valid: [epoch:47]  [13/14]  eta: 0:00:00  loss: 0.0776 (0.0798)  time: 0.0380  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:47] Total time: 0:00:00 (0.0429 s / it)\n",
      "Averaged stats: loss: 0.0776 (0.0798)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_47_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.080%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:48]  [  0/172]  eta: 0:07:21  lr: 0.000100  loss: 0.0911 (0.0911)  time: 2.5670  data: 0.9908  max mem: 20571\n",
      "Train: [epoch:48]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.0944 (0.0950)  time: 1.6711  data: 0.0902  max mem: 20571\n",
      "Train: [epoch:48]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.0944 (0.0949)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0934 (0.0947)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0945 (0.0948)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0946 (0.0944)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0946 (0.0944)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0925 (0.0939)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0904 (0.0940)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0957 (0.0939)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0892 (0.0936)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:48]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0913 (0.0935)  time: 1.5848  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:48]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0920 (0.0934)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0924 (0.0933)  time: 1.5820  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:48]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0895 (0.0931)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0916 (0.0932)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0921 (0.0931)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0912 (0.0931)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0912 (0.0931)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:48] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0912 (0.0931)\n",
      "Valid: [epoch:48]  [ 0/14]  eta: 0:00:04  loss: 0.1053 (0.1053)  time: 0.2957  data: 0.2810  max mem: 20571\n",
      "Valid: [epoch:48]  [13/14]  eta: 0:00:00  loss: 0.0997 (0.1011)  time: 0.0417  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:48] Total time: 0:00:00 (0.0498 s / it)\n",
      "Averaged stats: loss: 0.0997 (0.1011)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_48_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.101%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:49]  [  0/172]  eta: 0:07:46  lr: 0.000100  loss: 0.1008 (0.1008)  time: 2.7118  data: 1.1300  max mem: 20571\n",
      "Train: [epoch:49]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.0980 (0.0973)  time: 1.6815  data: 0.1028  max mem: 20571\n",
      "Train: [epoch:49]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0963 (0.0970)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.0963 (0.0970)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0960 (0.0965)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.0939 (0.0963)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0932 (0.0961)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0929 (0.0958)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0943 (0.0959)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0945 (0.0958)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0947 (0.0957)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0949 (0.0956)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0949 (0.0955)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0941 (0.0955)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0947 (0.0954)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0946 (0.0953)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0934 (0.0953)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0961 (0.0953)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0971 (0.0953)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:49] Total time: 0:04:33 (1.5900 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0971 (0.0953)\n",
      "Valid: [epoch:49]  [ 0/14]  eta: 0:00:04  loss: 0.0880 (0.0880)  time: 0.2962  data: 0.2815  max mem: 20571\n",
      "Valid: [epoch:49]  [13/14]  eta: 0:00:00  loss: 0.0789 (0.0811)  time: 0.0459  data: 0.0310  max mem: 20571\n",
      "Valid: [epoch:49] Total time: 0:00:00 (0.0509 s / it)\n",
      "Averaged stats: loss: 0.0789 (0.0811)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_49_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.081%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:50]  [  0/172]  eta: 0:07:56  lr: 0.000100  loss: 0.0832 (0.0832)  time: 2.7689  data: 1.1984  max mem: 20571\n",
      "Train: [epoch:50]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.0980 (0.0977)  time: 1.6880  data: 0.1091  max mem: 20571\n",
      "Train: [epoch:50]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.0963 (0.0973)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [ 30/172]  eta: 0:03:50  lr: 0.000100  loss: 0.0943 (0.0967)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0940 (0.0967)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [ 50/172]  eta: 0:03:16  lr: 0.000100  loss: 0.0958 (0.0972)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.0926 (0.0964)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.0930 (0.0964)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0955 (0.0967)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0962 (0.0968)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0954 (0.0967)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0942 (0.0967)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0961 (0.0968)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0959 (0.0968)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0947 (0.0967)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0938 (0.0965)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.0938 (0.0965)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0973 (0.0966)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0966 (0.0966)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:50] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0966 (0.0966)\n",
      "Valid: [epoch:50]  [ 0/14]  eta: 0:00:04  loss: 0.1121 (0.1121)  time: 0.3377  data: 0.3214  max mem: 20571\n",
      "Valid: [epoch:50]  [13/14]  eta: 0:00:00  loss: 0.1071 (0.1085)  time: 0.0393  data: 0.0242  max mem: 20571\n",
      "Valid: [epoch:50] Total time: 0:00:00 (0.0459 s / it)\n",
      "Averaged stats: loss: 0.1071 (0.1085)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_50_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.108%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:51]  [  0/172]  eta: 0:07:38  lr: 0.000100  loss: 0.1119 (0.1119)  time: 2.6654  data: 1.0978  max mem: 20571\n",
      "Train: [epoch:51]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.0988 (0.0992)  time: 1.6716  data: 0.0999  max mem: 20571\n",
      "Train: [epoch:51]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.0988 (0.0994)  time: 1.5734  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.0995 (0.1002)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1025 (0.1001)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1008 (0.0999)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.0969 (0.0996)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.0959 (0.0992)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.0959 (0.0991)  time: 1.5759  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:51]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.0967 (0.0990)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0990 (0.0991)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.0990 (0.0991)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0976 (0.0990)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0981 (0.0991)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0986 (0.0991)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0976 (0.0991)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [160/172]  eta: 0:00:18  lr: 0.000100  loss: 0.0985 (0.0991)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0973 (0.0989)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0973 (0.0990)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:51] Total time: 0:04:32 (1.5828 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0973 (0.0990)\n",
      "Valid: [epoch:51]  [ 0/14]  eta: 0:00:04  loss: 0.0927 (0.0927)  time: 0.2931  data: 0.2771  max mem: 20571\n",
      "Valid: [epoch:51]  [13/14]  eta: 0:00:00  loss: 0.0948 (0.0965)  time: 0.0389  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:51] Total time: 0:00:00 (0.0438 s / it)\n",
      "Averaged stats: loss: 0.0948 (0.0965)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_51_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.097%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:52]  [  0/172]  eta: 0:07:32  lr: 0.000100  loss: 0.1074 (0.1074)  time: 2.6335  data: 1.0679  max mem: 20571\n",
      "Train: [epoch:52]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1017 (0.1016)  time: 1.6747  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:52]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1007 (0.1022)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1005 (0.1014)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1005 (0.1012)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1006 (0.1010)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1006 (0.1010)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1000 (0.1009)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1000 (0.1009)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1022 (0.1010)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1016 (0.1010)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1005 (0.1008)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.0969 (0.1006)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.0969 (0.1004)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.0975 (0.1003)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0982 (0.1002)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1008 (0.1002)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1008 (0.1003)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1004 (0.1002)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:52] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1004 (0.1002)\n",
      "Valid: [epoch:52]  [ 0/14]  eta: 0:00:04  loss: 0.0964 (0.0964)  time: 0.3002  data: 0.2841  max mem: 20571\n",
      "Valid: [epoch:52]  [13/14]  eta: 0:00:00  loss: 0.0918 (0.0932)  time: 0.0365  data: 0.0215  max mem: 20571\n",
      "Valid: [epoch:52] Total time: 0:00:00 (0.0433 s / it)\n",
      "Averaged stats: loss: 0.0918 (0.0932)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_52_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.093%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:53]  [  0/172]  eta: 0:07:28  lr: 0.000100  loss: 0.0967 (0.0967)  time: 2.6066  data: 1.0271  max mem: 20571\n",
      "Train: [epoch:53]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1008 (0.1025)  time: 1.6674  data: 0.0935  max mem: 20571\n",
      "Train: [epoch:53]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.1027 (0.1032)  time: 1.5743  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1027 (0.1035)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1006 (0.1027)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1027 (0.1028)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1027 (0.1028)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1022 (0.1026)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1008 (0.1024)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1022 (0.1024)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.0997 (0.1024)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1003 (0.1024)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1003 (0.1021)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1002 (0.1022)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1002 (0.1021)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.0990 (0.1020)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [160/172]  eta: 0:00:18  lr: 0.000100  loss: 0.0990 (0.1019)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.0987 (0.1019)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.0987 (0.1019)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:53] Total time: 0:04:32 (1.5836 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.0987 (0.1019)\n",
      "Valid: [epoch:53]  [ 0/14]  eta: 0:00:04  loss: 0.0784 (0.0784)  time: 0.3242  data: 0.3091  max mem: 20571\n",
      "Valid: [epoch:53]  [13/14]  eta: 0:00:00  loss: 0.0879 (0.0902)  time: 0.0474  data: 0.0326  max mem: 20571\n",
      "Valid: [epoch:53] Total time: 0:00:00 (0.0552 s / it)\n",
      "Averaged stats: loss: 0.0879 (0.0902)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_53_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.090%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:54]  [  0/172]  eta: 0:07:50  lr: 0.000100  loss: 0.0879 (0.0879)  time: 2.7344  data: 1.1671  max mem: 20571\n",
      "Train: [epoch:54]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1019 (0.1016)  time: 1.6829  data: 0.1062  max mem: 20571\n",
      "Train: [epoch:54]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1019 (0.1024)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1011 (0.1027)  time: 1.5775  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:54]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.0999 (0.1027)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1013 (0.1028)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1023 (0.1029)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1014 (0.1030)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1040 (0.1034)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1040 (0.1031)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1015 (0.1034)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1028 (0.1033)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1007 (0.1033)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1021 (0.1031)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1021 (0.1031)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1026 (0.1032)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1026 (0.1033)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1018 (0.1033)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1008 (0.1032)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:54] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1008 (0.1032)\n",
      "Valid: [epoch:54]  [ 0/14]  eta: 0:00:06  loss: 0.0914 (0.0914)  time: 0.4978  data: 0.4816  max mem: 20571\n",
      "Valid: [epoch:54]  [13/14]  eta: 0:00:00  loss: 0.0927 (0.0952)  time: 0.0527  data: 0.0378  max mem: 20571\n",
      "Valid: [epoch:54] Total time: 0:00:00 (0.0584 s / it)\n",
      "Averaged stats: loss: 0.0927 (0.0952)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_54_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.095%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:55]  [  0/172]  eta: 0:07:57  lr: 0.000100  loss: 0.0921 (0.0921)  time: 2.7753  data: 1.1946  max mem: 20571\n",
      "Train: [epoch:55]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1079 (0.1073)  time: 1.6843  data: 0.1087  max mem: 20571\n",
      "Train: [epoch:55]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1075 (0.1060)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1070 (0.1058)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1077 (0.1059)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1064 (0.1059)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1031 (0.1054)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1013 (0.1054)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1053 (0.1055)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1053 (0.1056)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1044 (0.1056)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1032 (0.1053)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1047 (0.1054)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1056 (0.1052)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1048 (0.1052)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1049 (0.1052)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1055 (0.1052)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1036 (0.1051)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1030 (0.1051)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:55] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1030 (0.1051)\n",
      "Valid: [epoch:55]  [ 0/14]  eta: 0:00:05  loss: 0.0940 (0.0940)  time: 0.3832  data: 0.3680  max mem: 20571\n",
      "Valid: [epoch:55]  [13/14]  eta: 0:00:00  loss: 0.0958 (0.0985)  time: 0.0419  data: 0.0268  max mem: 20571\n",
      "Valid: [epoch:55] Total time: 0:00:00 (0.0495 s / it)\n",
      "Averaged stats: loss: 0.0958 (0.0985)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_55_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.099%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:56]  [  0/172]  eta: 0:07:57  lr: 0.000100  loss: 0.1042 (0.1042)  time: 2.7775  data: 1.2142  max mem: 20571\n",
      "Train: [epoch:56]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.1075 (0.1094)  time: 1.6867  data: 0.1105  max mem: 20571\n",
      "Train: [epoch:56]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1075 (0.1093)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1056 (0.1079)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1064 (0.1085)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1067 (0.1082)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1067 (0.1085)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1074 (0.1080)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1049 (0.1079)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1049 (0.1078)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1069 (0.1076)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1062 (0.1073)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1075 (0.1074)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1075 (0.1074)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1061 (0.1074)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1061 (0.1073)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1025 (0.1071)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1048 (0.1069)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1046 (0.1069)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:56] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1046 (0.1069)\n",
      "Valid: [epoch:56]  [ 0/14]  eta: 0:00:04  loss: 0.1069 (0.1069)  time: 0.3337  data: 0.3187  max mem: 20571\n",
      "Valid: [epoch:56]  [13/14]  eta: 0:00:00  loss: 0.0989 (0.1006)  time: 0.0395  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:56] Total time: 0:00:00 (0.0479 s / it)\n",
      "Averaged stats: loss: 0.0989 (0.1006)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_56_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.101%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:57]  [  0/172]  eta: 0:08:05  lr: 0.000100  loss: 0.1108 (0.1108)  time: 2.8213  data: 1.2381  max mem: 20571\n",
      "Train: [epoch:57]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.1108 (0.1089)  time: 1.6888  data: 0.1127  max mem: 20571\n",
      "Train: [epoch:57]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1077 (0.1095)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1101 (0.1098)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1101 (0.1099)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1115 (0.1103)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1104 (0.1100)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1073 (0.1099)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1078 (0.1096)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1084 (0.1097)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1074 (0.1098)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1056 (0.1094)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1072 (0.1094)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1088 (0.1093)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1065 (0.1091)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1065 (0.1090)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1061 (0.1088)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1053 (0.1088)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1061 (0.1088)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:57] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1061 (0.1088)\n",
      "Valid: [epoch:57]  [ 0/14]  eta: 0:00:05  loss: 0.1034 (0.1034)  time: 0.4191  data: 0.4013  max mem: 20571\n",
      "Valid: [epoch:57]  [13/14]  eta: 0:00:00  loss: 0.1038 (0.1057)  time: 0.0440  data: 0.0289  max mem: 20571\n",
      "Valid: [epoch:57] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.1038 (0.1057)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_57_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.106%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:58]  [  0/172]  eta: 0:08:07  lr: 0.000100  loss: 0.1140 (0.1140)  time: 2.8332  data: 1.2679  max mem: 20571\n",
      "Train: [epoch:58]  [ 10/172]  eta: 0:04:34  lr: 0.000100  loss: 0.1105 (0.1102)  time: 1.6916  data: 0.1154  max mem: 20571\n",
      "Train: [epoch:58]  [ 20/172]  eta: 0:04:09  lr: 0.000100  loss: 0.1086 (0.1104)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [ 30/172]  eta: 0:03:50  lr: 0.000100  loss: 0.1086 (0.1101)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1109 (0.1106)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1098 (0.1103)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1084 (0.1104)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1104 (0.1106)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1091 (0.1103)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1101 (0.1105)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1120 (0.1104)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1078 (0.1104)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1078 (0.1105)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1082 (0.1103)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1089 (0.1104)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1080 (0.1102)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1089 (0.1102)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1091 (0.1103)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1089 (0.1102)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:58] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1089 (0.1102)\n",
      "Valid: [epoch:58]  [ 0/14]  eta: 0:00:03  loss: 0.1048 (0.1048)  time: 0.2832  data: 0.2685  max mem: 20571\n",
      "Valid: [epoch:58]  [13/14]  eta: 0:00:00  loss: 0.0947 (0.0972)  time: 0.0489  data: 0.0337  max mem: 20571\n",
      "Valid: [epoch:58] Total time: 0:00:00 (0.0546 s / it)\n",
      "Averaged stats: loss: 0.0947 (0.0972)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_58_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.097%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:59]  [  0/172]  eta: 0:07:24  lr: 0.000100  loss: 0.1019 (0.1019)  time: 2.5867  data: 1.0134  max mem: 20571\n",
      "Train: [epoch:59]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1108 (0.1113)  time: 1.6668  data: 0.0922  max mem: 20571\n",
      "Train: [epoch:59]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.1109 (0.1122)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1122 (0.1137)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1148 (0.1135)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1131 (0.1136)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1130 (0.1131)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1112 (0.1131)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1132 (0.1131)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1094 (0.1131)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1126 (0.1130)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1127 (0.1128)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1083 (0.1127)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1138 (0.1126)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1128 (0.1126)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1099 (0.1125)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1103 (0.1124)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1110 (0.1124)  time: 1.5793  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:59]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1111 (0.1124)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:59] Total time: 0:04:32 (1.5836 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1111 (0.1124)\n",
      "Valid: [epoch:59]  [ 0/14]  eta: 0:00:04  loss: 0.0923 (0.0923)  time: 0.3379  data: 0.3220  max mem: 20571\n",
      "Valid: [epoch:59]  [13/14]  eta: 0:00:00  loss: 0.0989 (0.1018)  time: 0.0393  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:59] Total time: 0:00:00 (0.0442 s / it)\n",
      "Averaged stats: loss: 0.0989 (0.1018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_59_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.102%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:60]  [  0/172]  eta: 0:07:48  lr: 0.000100  loss: 0.1121 (0.1121)  time: 2.7234  data: 1.1565  max mem: 20571\n",
      "Train: [epoch:60]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1119 (0.1135)  time: 1.6811  data: 0.1052  max mem: 20571\n",
      "Train: [epoch:60]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1119 (0.1144)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1153 (0.1145)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1139 (0.1144)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1136 (0.1145)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1136 (0.1143)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1113 (0.1140)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1113 (0.1140)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1099 (0.1138)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1099 (0.1138)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1132 (0.1138)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1104 (0.1136)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1132 (0.1136)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1129 (0.1137)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1078 (0.1136)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1100 (0.1134)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1107 (0.1134)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1094 (0.1133)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:60] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1094 (0.1133)\n",
      "Valid: [epoch:60]  [ 0/14]  eta: 0:00:03  loss: 0.1053 (0.1053)  time: 0.2752  data: 0.2597  max mem: 20571\n",
      "Valid: [epoch:60]  [13/14]  eta: 0:00:00  loss: 0.0961 (0.0989)  time: 0.0347  data: 0.0197  max mem: 20571\n",
      "Valid: [epoch:60] Total time: 0:00:00 (0.0397 s / it)\n",
      "Averaged stats: loss: 0.0961 (0.0989)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_60_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.099%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:61]  [  0/172]  eta: 0:07:34  lr: 0.000100  loss: 0.0944 (0.0944)  time: 2.6449  data: 1.0691  max mem: 20571\n",
      "Train: [epoch:61]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1186 (0.1160)  time: 1.6708  data: 0.0973  max mem: 20571\n",
      "Train: [epoch:61]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1186 (0.1166)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1144 (0.1158)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1153 (0.1168)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1151 (0.1162)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1151 (0.1163)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1142 (0.1159)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1118 (0.1159)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1154 (0.1159)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1153 (0.1157)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1131 (0.1157)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1184 (0.1159)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1149 (0.1158)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1139 (0.1159)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1155 (0.1158)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1134 (0.1155)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1124 (0.1154)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1124 (0.1153)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:61] Total time: 0:04:32 (1.5842 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1124 (0.1153)\n",
      "Valid: [epoch:61]  [ 0/14]  eta: 0:00:04  loss: 0.1147 (0.1147)  time: 0.3094  data: 0.2946  max mem: 20571\n",
      "Valid: [epoch:61]  [13/14]  eta: 0:00:00  loss: 0.1045 (0.1072)  time: 0.0373  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:61] Total time: 0:00:00 (0.0423 s / it)\n",
      "Averaged stats: loss: 0.1045 (0.1072)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_61_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.107%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:62]  [  0/172]  eta: 0:07:28  lr: 0.000100  loss: 0.1040 (0.1040)  time: 2.6050  data: 1.0397  max mem: 20571\n",
      "Train: [epoch:62]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1167 (0.1178)  time: 1.6690  data: 0.0946  max mem: 20571\n",
      "Train: [epoch:62]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.1184 (0.1192)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1184 (0.1186)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1189 (0.1190)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1189 (0.1186)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1173 (0.1183)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1186 (0.1185)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1174 (0.1180)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1152 (0.1181)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1152 (0.1179)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1168 (0.1179)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1168 (0.1179)  time: 1.5772  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:62]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1145 (0.1176)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1145 (0.1176)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1146 (0.1174)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1146 (0.1173)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1157 (0.1173)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1157 (0.1174)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:62] Total time: 0:04:32 (1.5840 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1157 (0.1174)\n",
      "Valid: [epoch:62]  [ 0/14]  eta: 0:00:06  loss: 0.1033 (0.1033)  time: 0.4699  data: 0.4521  max mem: 20571\n",
      "Valid: [epoch:62]  [13/14]  eta: 0:00:00  loss: 0.1033 (0.1064)  time: 0.0477  data: 0.0325  max mem: 20571\n",
      "Valid: [epoch:62] Total time: 0:00:00 (0.0533 s / it)\n",
      "Averaged stats: loss: 0.1033 (0.1064)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_62_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.106%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:63]  [  0/172]  eta: 0:07:34  lr: 0.000100  loss: 0.1112 (0.1112)  time: 2.6452  data: 1.0722  max mem: 20571\n",
      "Train: [epoch:63]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1237 (0.1225)  time: 1.6721  data: 0.0976  max mem: 20571\n",
      "Train: [epoch:63]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1184 (0.1206)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1159 (0.1201)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1171 (0.1203)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1188 (0.1201)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1184 (0.1204)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1195 (0.1207)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1185 (0.1205)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1175 (0.1202)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1163 (0.1200)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1178 (0.1198)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1168 (0.1196)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1164 (0.1196)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1200 (0.1194)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1200 (0.1195)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1195 (0.1194)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1171 (0.1193)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1171 (0.1193)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:63] Total time: 0:04:32 (1.5854 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1171 (0.1193)\n",
      "Valid: [epoch:63]  [ 0/14]  eta: 0:00:04  loss: 0.1163 (0.1163)  time: 0.3320  data: 0.3158  max mem: 20571\n",
      "Valid: [epoch:63]  [13/14]  eta: 0:00:00  loss: 0.1066 (0.1095)  time: 0.0393  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:63] Total time: 0:00:00 (0.0447 s / it)\n",
      "Averaged stats: loss: 0.1066 (0.1095)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_63_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.110%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:64]  [  0/172]  eta: 0:07:38  lr: 0.000100  loss: 0.1153 (0.1153)  time: 2.6675  data: 1.1025  max mem: 20571\n",
      "Train: [epoch:64]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1199 (0.1213)  time: 1.6766  data: 0.1003  max mem: 20571\n",
      "Train: [epoch:64]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1191 (0.1209)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1191 (0.1217)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1201 (0.1212)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1201 (0.1217)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1223 (0.1214)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1218 (0.1217)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1190 (0.1215)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1172 (0.1215)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1190 (0.1215)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1202 (0.1215)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1205 (0.1216)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1215 (0.1214)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1193 (0.1214)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1197 (0.1214)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1192 (0.1212)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1203 (0.1213)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1203 (0.1212)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:64] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1203 (0.1212)\n",
      "Valid: [epoch:64]  [ 0/14]  eta: 0:00:04  loss: 0.1135 (0.1135)  time: 0.2961  data: 0.2811  max mem: 20571\n",
      "Valid: [epoch:64]  [13/14]  eta: 0:00:00  loss: 0.1063 (0.1092)  time: 0.0369  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:64] Total time: 0:00:00 (0.0430 s / it)\n",
      "Averaged stats: loss: 0.1063 (0.1092)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_64_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.109%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:65]  [  0/172]  eta: 0:07:46  lr: 0.000100  loss: 0.1305 (0.1305)  time: 2.7140  data: 1.1343  max mem: 20571\n",
      "Train: [epoch:65]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1305 (0.1268)  time: 1.6789  data: 0.1032  max mem: 20571\n",
      "Train: [epoch:65]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1246 (0.1247)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1220 (0.1237)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1217 (0.1232)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1203 (0.1230)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1229 (0.1235)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1271 (0.1237)  time: 1.5784  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:65]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1200 (0.1234)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1213 (0.1233)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1201 (0.1228)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1208 (0.1229)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1242 (0.1228)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1201 (0.1225)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1214 (0.1226)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1250 (0.1227)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1242 (0.1226)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1224 (0.1227)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1224 (0.1226)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:65] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1224 (0.1226)\n",
      "Valid: [epoch:65]  [ 0/14]  eta: 0:00:05  loss: 0.1073 (0.1073)  time: 0.3785  data: 0.3636  max mem: 20571\n",
      "Valid: [epoch:65]  [13/14]  eta: 0:00:00  loss: 0.1107 (0.1127)  time: 0.0416  data: 0.0265  max mem: 20571\n",
      "Valid: [epoch:65] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.1107 (0.1127)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_65_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.113%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:66]  [  0/172]  eta: 0:07:37  lr: 0.000100  loss: 0.1164 (0.1164)  time: 2.6579  data: 1.0923  max mem: 20571\n",
      "Train: [epoch:66]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1256 (0.1258)  time: 1.6761  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:66]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1265 (0.1259)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1265 (0.1256)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1240 (0.1252)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1228 (0.1249)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1262 (0.1251)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1267 (0.1254)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1242 (0.1252)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1241 (0.1253)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1250 (0.1251)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1250 (0.1252)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1253 (0.1251)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1246 (0.1250)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1210 (0.1249)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1203 (0.1248)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1203 (0.1246)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1209 (0.1245)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1207 (0.1244)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:66] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1207 (0.1244)\n",
      "Valid: [epoch:66]  [ 0/14]  eta: 0:00:04  loss: 0.1277 (0.1277)  time: 0.2943  data: 0.2796  max mem: 20571\n",
      "Valid: [epoch:66]  [13/14]  eta: 0:00:00  loss: 0.1173 (0.1198)  time: 0.0371  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:66] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.1173 (0.1198)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_66_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.120%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:67]  [  0/172]  eta: 0:07:41  lr: 0.000100  loss: 0.1249 (0.1249)  time: 2.6858  data: 1.1054  max mem: 20571\n",
      "Train: [epoch:67]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1280 (0.1273)  time: 1.6768  data: 0.1006  max mem: 20571\n",
      "Train: [epoch:67]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1235 (0.1250)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1235 (0.1256)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1280 (0.1260)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1277 (0.1260)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1258 (0.1258)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1258 (0.1259)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1245 (0.1259)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1245 (0.1260)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1251 (0.1259)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1262 (0.1259)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1236 (0.1260)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1272 (0.1261)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1284 (0.1262)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1274 (0.1260)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1218 (0.1259)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1223 (0.1258)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1223 (0.1258)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:67] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1223 (0.1258)\n",
      "Valid: [epoch:67]  [ 0/14]  eta: 0:00:04  loss: 0.1279 (0.1279)  time: 0.3042  data: 0.2894  max mem: 20571\n",
      "Valid: [epoch:67]  [13/14]  eta: 0:00:00  loss: 0.1167 (0.1200)  time: 0.0416  data: 0.0268  max mem: 20571\n",
      "Valid: [epoch:67] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.1167 (0.1200)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_67_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.120%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:68]  [  0/172]  eta: 0:07:19  lr: 0.000100  loss: 0.1316 (0.1316)  time: 2.5540  data: 0.9893  max mem: 20571\n",
      "Train: [epoch:68]  [ 10/172]  eta: 0:04:29  lr: 0.000100  loss: 0.1301 (0.1287)  time: 1.6647  data: 0.0900  max mem: 20571\n",
      "Train: [epoch:68]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.1278 (0.1293)  time: 1.5764  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:68]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1257 (0.1295)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1246 (0.1284)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1231 (0.1276)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1268 (0.1283)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1292 (0.1286)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1291 (0.1285)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1266 (0.1281)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1226 (0.1281)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1226 (0.1279)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1249 (0.1278)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1250 (0.1277)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1253 (0.1278)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1239 (0.1276)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1249 (0.1274)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1252 (0.1275)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1242 (0.1274)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:68] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1242 (0.1274)\n",
      "Valid: [epoch:68]  [ 0/14]  eta: 0:00:03  loss: 0.1312 (0.1312)  time: 0.2851  data: 0.2703  max mem: 20571\n",
      "Valid: [epoch:68]  [13/14]  eta: 0:00:00  loss: 0.1207 (0.1234)  time: 0.0366  data: 0.0215  max mem: 20571\n",
      "Valid: [epoch:68] Total time: 0:00:00 (0.0442 s / it)\n",
      "Averaged stats: loss: 0.1207 (0.1234)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_68_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.123%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:69]  [  0/172]  eta: 0:07:27  lr: 0.000100  loss: 0.1229 (0.1229)  time: 2.6024  data: 1.0229  max mem: 20571\n",
      "Train: [epoch:69]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1298 (0.1309)  time: 1.6696  data: 0.0931  max mem: 20571\n",
      "Train: [epoch:69]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1288 (0.1312)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1288 (0.1301)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1299 (0.1303)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1276 (0.1298)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1272 (0.1296)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1279 (0.1296)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1276 (0.1295)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1272 (0.1294)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1288 (0.1294)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1273 (0.1293)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1253 (0.1291)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1270 (0.1294)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1266 (0.1290)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1238 (0.1290)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1263 (0.1289)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1290 (0.1290)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1300 (0.1291)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:69] Total time: 0:04:32 (1.5846 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1300 (0.1291)\n",
      "Valid: [epoch:69]  [ 0/14]  eta: 0:00:04  loss: 0.1265 (0.1265)  time: 0.3441  data: 0.3289  max mem: 20571\n",
      "Valid: [epoch:69]  [13/14]  eta: 0:00:00  loss: 0.1202 (0.1229)  time: 0.0411  data: 0.0262  max mem: 20571\n",
      "Valid: [epoch:69] Total time: 0:00:00 (0.0494 s / it)\n",
      "Averaged stats: loss: 0.1202 (0.1229)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_69_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.123%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:70]  [  0/172]  eta: 0:08:16  lr: 0.000100  loss: 0.1307 (0.1307)  time: 2.8842  data: 1.3197  max mem: 20571\n",
      "Train: [epoch:70]  [ 10/172]  eta: 0:04:34  lr: 0.000100  loss: 0.1337 (0.1356)  time: 1.6947  data: 0.1201  max mem: 20571\n",
      "Train: [epoch:70]  [ 20/172]  eta: 0:04:09  lr: 0.000100  loss: 0.1338 (0.1356)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1354 (0.1341)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1303 (0.1338)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1298 (0.1335)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1293 (0.1331)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1289 (0.1326)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1307 (0.1328)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1327 (0.1324)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1250 (0.1318)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1313 (0.1319)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1289 (0.1317)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1271 (0.1314)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1271 (0.1314)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1265 (0.1312)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1279 (0.1311)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1300 (0.1312)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1300 (0.1312)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:70] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1300 (0.1312)\n",
      "Valid: [epoch:70]  [ 0/14]  eta: 0:00:04  loss: 0.1411 (0.1411)  time: 0.3170  data: 0.3004  max mem: 20571\n",
      "Valid: [epoch:70]  [13/14]  eta: 0:00:00  loss: 0.1324 (0.1352)  time: 0.0379  data: 0.0228  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:70] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.1324 (0.1352)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_70_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.135%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:71]  [  0/172]  eta: 0:07:55  lr: 0.000100  loss: 0.1343 (0.1343)  time: 2.7662  data: 1.1909  max mem: 20571\n",
      "Train: [epoch:71]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1371 (0.1362)  time: 1.6838  data: 0.1084  max mem: 20571\n",
      "Train: [epoch:71]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1358 (0.1338)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1285 (0.1335)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1327 (0.1333)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1315 (0.1336)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1302 (0.1333)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1316 (0.1332)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1324 (0.1330)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1302 (0.1331)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1307 (0.1329)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1316 (0.1332)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1315 (0.1331)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1307 (0.1328)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1298 (0.1326)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1305 (0.1326)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1314 (0.1325)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1307 (0.1325)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1314 (0.1325)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:71] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1314 (0.1325)\n",
      "Valid: [epoch:71]  [ 0/14]  eta: 0:00:06  loss: 0.1287 (0.1287)  time: 0.4673  data: 0.4490  max mem: 20571\n",
      "Valid: [epoch:71]  [13/14]  eta: 0:00:00  loss: 0.1179 (0.1215)  time: 0.0483  data: 0.0331  max mem: 20571\n",
      "Valid: [epoch:71] Total time: 0:00:00 (0.0533 s / it)\n",
      "Averaged stats: loss: 0.1179 (0.1215)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_71_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.122%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:72]  [  0/172]  eta: 0:07:37  lr: 0.000100  loss: 0.1227 (0.1227)  time: 2.6594  data: 1.0841  max mem: 20571\n",
      "Train: [epoch:72]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1298 (0.1317)  time: 1.6766  data: 0.0987  max mem: 20571\n",
      "Train: [epoch:72]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1306 (0.1343)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1349 (0.1348)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1349 (0.1346)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1331 (0.1349)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1354 (0.1352)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1382 (0.1351)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1362 (0.1351)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1362 (0.1352)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1379 (0.1353)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1362 (0.1355)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1314 (0.1352)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1314 (0.1351)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1321 (0.1350)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1322 (0.1349)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1318 (0.1347)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1306 (0.1345)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1306 (0.1345)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:72] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1306 (0.1345)\n",
      "Valid: [epoch:72]  [ 0/14]  eta: 0:00:05  loss: 0.1325 (0.1325)  time: 0.3619  data: 0.3470  max mem: 20571\n",
      "Valid: [epoch:72]  [13/14]  eta: 0:00:00  loss: 0.1243 (0.1276)  time: 0.0417  data: 0.0268  max mem: 20571\n",
      "Valid: [epoch:72] Total time: 0:00:00 (0.0479 s / it)\n",
      "Averaged stats: loss: 0.1243 (0.1276)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_72_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.128%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:73]  [  0/172]  eta: 0:07:46  lr: 0.000100  loss: 0.1448 (0.1448)  time: 2.7120  data: 1.1395  max mem: 20571\n",
      "Train: [epoch:73]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1368 (0.1368)  time: 1.6779  data: 0.1037  max mem: 20571\n",
      "Train: [epoch:73]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1343 (0.1366)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1331 (0.1356)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1323 (0.1361)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1346 (0.1358)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1370 (0.1359)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1359 (0.1355)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1349 (0.1359)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1358 (0.1356)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1358 (0.1354)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1366 (0.1355)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1328 (0.1353)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1328 (0.1354)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1372 (0.1357)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1372 (0.1355)  time: 1.5798  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:73]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1320 (0.1354)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1342 (0.1355)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1342 (0.1355)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:73] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1342 (0.1355)\n",
      "Valid: [epoch:73]  [ 0/14]  eta: 0:00:04  loss: 0.1264 (0.1264)  time: 0.2926  data: 0.2765  max mem: 20571\n",
      "Valid: [epoch:73]  [13/14]  eta: 0:00:00  loss: 0.1264 (0.1299)  time: 0.0476  data: 0.0327  max mem: 20571\n",
      "Valid: [epoch:73] Total time: 0:00:00 (0.0558 s / it)\n",
      "Averaged stats: loss: 0.1264 (0.1299)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_73_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.130%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:74]  [  0/172]  eta: 0:07:46  lr: 0.000100  loss: 0.1388 (0.1388)  time: 2.7107  data: 1.1426  max mem: 20571\n",
      "Train: [epoch:74]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1417 (0.1417)  time: 1.6818  data: 0.1040  max mem: 20571\n",
      "Train: [epoch:74]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1409 (0.1398)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1375 (0.1400)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1397 (0.1403)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1402 (0.1405)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1386 (0.1395)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1337 (0.1393)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1334 (0.1387)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1334 (0.1388)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1413 (0.1389)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1383 (0.1387)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1367 (0.1384)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1331 (0.1380)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1331 (0.1380)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1359 (0.1379)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1364 (0.1380)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1365 (0.1377)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1368 (0.1377)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:74] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1368 (0.1377)\n",
      "Valid: [epoch:74]  [ 0/14]  eta: 0:00:04  loss: 0.1202 (0.1202)  time: 0.3044  data: 0.2891  max mem: 20571\n",
      "Valid: [epoch:74]  [13/14]  eta: 0:00:00  loss: 0.1276 (0.1313)  time: 0.0393  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:74] Total time: 0:00:00 (0.0474 s / it)\n",
      "Averaged stats: loss: 0.1276 (0.1313)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_74_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.131%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:75]  [  0/172]  eta: 0:07:38  lr: 0.000100  loss: 0.1349 (0.1349)  time: 2.6660  data: 1.0819  max mem: 20571\n",
      "Train: [epoch:75]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1381 (0.1413)  time: 1.6791  data: 0.0985  max mem: 20571\n",
      "Train: [epoch:75]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1414 (0.1411)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:75]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1415 (0.1409)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1415 (0.1408)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1410 (0.1409)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1388 (0.1411)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1394 (0.1410)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1394 (0.1408)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1402 (0.1406)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1402 (0.1405)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1378 (0.1404)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1378 (0.1400)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:75]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1370 (0.1401)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1376 (0.1401)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1376 (0.1400)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1372 (0.1399)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1377 (0.1399)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1372 (0.1398)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:75] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1372 (0.1398)\n",
      "Valid: [epoch:75]  [ 0/14]  eta: 0:00:04  loss: 0.1423 (0.1423)  time: 0.2897  data: 0.2751  max mem: 20571\n",
      "Valid: [epoch:75]  [13/14]  eta: 0:00:00  loss: 0.1310 (0.1342)  time: 0.0386  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:75] Total time: 0:00:00 (0.0445 s / it)\n",
      "Averaged stats: loss: 0.1310 (0.1342)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_75_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.134%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:76]  [  0/172]  eta: 0:07:54  lr: 0.000100  loss: 0.1377 (0.1377)  time: 2.7614  data: 1.1789  max mem: 20571\n",
      "Train: [epoch:76]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.1419 (0.1432)  time: 1.6859  data: 0.1073  max mem: 20571\n",
      "Train: [epoch:76]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1416 (0.1425)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1400 (0.1418)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1381 (0.1411)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1387 (0.1413)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1405 (0.1417)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1422 (0.1415)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1431 (0.1420)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:76]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1393 (0.1414)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:76]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1370 (0.1414)  time: 1.5832  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:76]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1373 (0.1412)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:76]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1428 (0.1415)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1379 (0.1411)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:76]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1375 (0.1412)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:76]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1434 (0.1411)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1375 (0.1409)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1383 (0.1408)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1401 (0.1408)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:76] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1401 (0.1408)\n",
      "Valid: [epoch:76]  [ 0/14]  eta: 0:00:04  loss: 0.1173 (0.1173)  time: 0.2902  data: 0.2752  max mem: 20571\n",
      "Valid: [epoch:76]  [13/14]  eta: 0:00:00  loss: 0.1278 (0.1319)  time: 0.0360  data: 0.0210  max mem: 20571\n",
      "Valid: [epoch:76] Total time: 0:00:00 (0.0437 s / it)\n",
      "Averaged stats: loss: 0.1278 (0.1319)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_76_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.132%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:77]  [  0/172]  eta: 0:08:05  lr: 0.000100  loss: 0.1283 (0.1283)  time: 2.8239  data: 1.2340  max mem: 20571\n",
      "Train: [epoch:77]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.1425 (0.1468)  time: 1.6891  data: 0.1123  max mem: 20571\n",
      "Train: [epoch:77]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1425 (0.1454)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1456 (0.1452)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1456 (0.1453)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1439 (0.1451)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1411 (0.1447)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1404 (0.1444)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1439 (0.1442)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:77]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1439 (0.1442)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:77]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1434 (0.1439)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1437 (0.1441)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1428 (0.1438)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1407 (0.1437)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1407 (0.1435)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1394 (0.1434)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1414 (0.1433)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1413 (0.1432)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1414 (0.1432)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:77] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1414 (0.1432)\n",
      "Valid: [epoch:77]  [ 0/14]  eta: 0:00:04  loss: 0.1287 (0.1287)  time: 0.3184  data: 0.3025  max mem: 20571\n",
      "Valid: [epoch:77]  [13/14]  eta: 0:00:00  loss: 0.1287 (0.1328)  time: 0.0386  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:77] Total time: 0:00:00 (0.0436 s / it)\n",
      "Averaged stats: loss: 0.1287 (0.1328)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_77_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.133%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:78]  [  0/172]  eta: 0:07:32  lr: 0.000100  loss: 0.1377 (0.1377)  time: 2.6302  data: 1.0640  max mem: 20571\n",
      "Train: [epoch:78]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1431 (0.1431)  time: 1.6733  data: 0.0968  max mem: 20571\n",
      "Train: [epoch:78]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1434 (0.1449)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1434 (0.1451)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1445 (0.1455)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1435 (0.1452)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1435 (0.1455)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1421 (0.1451)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1402 (0.1448)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1399 (0.1446)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1416 (0.1445)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1417 (0.1444)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1444 (0.1445)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1447 (0.1445)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1390 (0.1442)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1368 (0.1439)  time: 1.5796  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:78]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1412 (0.1440)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1442 (0.1441)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1436 (0.1441)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:78] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1436 (0.1441)\n",
      "Valid: [epoch:78]  [ 0/14]  eta: 0:00:04  loss: 0.1378 (0.1378)  time: 0.3258  data: 0.3104  max mem: 20571\n",
      "Valid: [epoch:78]  [13/14]  eta: 0:00:00  loss: 0.1237 (0.1276)  time: 0.0383  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:78] Total time: 0:00:00 (0.0447 s / it)\n",
      "Averaged stats: loss: 0.1237 (0.1276)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_78_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.128%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:79]  [  0/172]  eta: 0:08:23  lr: 0.000100  loss: 0.1471 (0.1471)  time: 2.9274  data: 1.3549  max mem: 20571\n",
      "Train: [epoch:79]  [ 10/172]  eta: 0:04:34  lr: 0.000100  loss: 0.1468 (0.1469)  time: 1.6970  data: 0.1233  max mem: 20571\n",
      "Train: [epoch:79]  [ 20/172]  eta: 0:04:09  lr: 0.000100  loss: 0.1459 (0.1463)  time: 1.5762  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:79]  [ 30/172]  eta: 0:03:50  lr: 0.000100  loss: 0.1438 (0.1461)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1460 (0.1467)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1460 (0.1470)  time: 1.5790  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:79]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1436 (0.1467)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1458 (0.1468)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1484 (0.1466)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1513 (0.1466)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1487 (0.1468)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1467 (0.1464)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1446 (0.1464)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1462 (0.1463)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1437 (0.1461)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1475 (0.1463)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1468 (0.1463)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:79]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1455 (0.1465)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1510 (0.1465)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:79] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1510 (0.1465)\n",
      "Valid: [epoch:79]  [ 0/14]  eta: 0:00:04  loss: 0.1410 (0.1410)  time: 0.3258  data: 0.3106  max mem: 20571\n",
      "Valid: [epoch:79]  [13/14]  eta: 0:00:00  loss: 0.1495 (0.1523)  time: 0.0376  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:79] Total time: 0:00:00 (0.0448 s / it)\n",
      "Averaged stats: loss: 0.1495 (0.1523)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_79_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.152%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:80]  [  0/172]  eta: 0:07:46  lr: 0.000100  loss: 0.1685 (0.1685)  time: 2.7131  data: 1.1455  max mem: 20571\n",
      "Train: [epoch:80]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1512 (0.1501)  time: 1.6809  data: 0.1043  max mem: 20571\n",
      "Train: [epoch:80]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1512 (0.1500)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1475 (0.1498)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1475 (0.1493)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1477 (0.1492)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1447 (0.1482)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.1462 (0.1484)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1474 (0.1483)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1474 (0.1484)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1474 (0.1484)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1451 (0.1486)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1421 (0.1484)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1441 (0.1482)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1461 (0.1482)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1502 (0.1484)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1466 (0.1483)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1465 (0.1483)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1465 (0.1483)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:80] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1465 (0.1483)\n",
      "Valid: [epoch:80]  [ 0/14]  eta: 0:00:06  loss: 0.1326 (0.1326)  time: 0.4431  data: 0.4244  max mem: 20571\n",
      "Valid: [epoch:80]  [13/14]  eta: 0:00:00  loss: 0.1356 (0.1392)  time: 0.0467  data: 0.0315  max mem: 20571\n",
      "Valid: [epoch:80] Total time: 0:00:00 (0.0551 s / it)\n",
      "Averaged stats: loss: 0.1356 (0.1392)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_80_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.139%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:81]  [  0/172]  eta: 0:07:23  lr: 0.000100  loss: 0.1425 (0.1425)  time: 2.5794  data: 1.0061  max mem: 20571\n",
      "Train: [epoch:81]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1516 (0.1530)  time: 1.6683  data: 0.0916  max mem: 20571\n",
      "Train: [epoch:81]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1503 (0.1508)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1471 (0.1502)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1479 (0.1502)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1489 (0.1500)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1501 (0.1504)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1506 (0.1502)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1481 (0.1499)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1487 (0.1502)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1498 (0.1504)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1499 (0.1505)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1468 (0.1504)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1466 (0.1501)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1481 (0.1500)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1480 (0.1499)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1457 (0.1497)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1462 (0.1499)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1462 (0.1499)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:81] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1462 (0.1499)\n",
      "Valid: [epoch:81]  [ 0/14]  eta: 0:00:04  loss: 0.1529 (0.1529)  time: 0.3027  data: 0.2882  max mem: 20571\n",
      "Valid: [epoch:81]  [13/14]  eta: 0:00:00  loss: 0.1370 (0.1414)  time: 0.0398  data: 0.0249  max mem: 20571\n",
      "Valid: [epoch:81] Total time: 0:00:00 (0.0476 s / it)\n",
      "Averaged stats: loss: 0.1370 (0.1414)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_81_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.141%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:82]  [  0/172]  eta: 0:07:33  lr: 0.000100  loss: 0.1513 (0.1513)  time: 2.6351  data: 1.0634  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:82]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1513 (0.1522)  time: 1.6767  data: 0.0968  max mem: 20571\n",
      "Train: [epoch:82]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1507 (0.1517)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1488 (0.1522)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1501 (0.1518)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1517 (0.1517)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1525 (0.1521)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1510 (0.1517)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1520 (0.1521)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1532 (0.1521)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1514 (0.1523)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1506 (0.1518)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1480 (0.1516)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1472 (0.1515)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1429 (0.1511)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1494 (0.1513)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1494 (0.1511)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1487 (0.1511)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1510 (0.1512)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:82] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1510 (0.1512)\n",
      "Valid: [epoch:82]  [ 0/14]  eta: 0:00:04  loss: 0.1426 (0.1426)  time: 0.3381  data: 0.3232  max mem: 20571\n",
      "Valid: [epoch:82]  [13/14]  eta: 0:00:00  loss: 0.1431 (0.1460)  time: 0.0388  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:82] Total time: 0:00:00 (0.0442 s / it)\n",
      "Averaged stats: loss: 0.1431 (0.1460)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_82_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.146%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:83]  [  0/172]  eta: 0:07:41  lr: 0.000100  loss: 0.1492 (0.1492)  time: 2.6819  data: 1.1039  max mem: 20571\n",
      "Train: [epoch:83]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1500 (0.1534)  time: 1.6751  data: 0.1005  max mem: 20571\n",
      "Train: [epoch:83]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1496 (0.1527)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1490 (0.1523)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1496 (0.1534)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1536 (0.1535)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1540 (0.1535)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1583 (0.1538)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1525 (0.1536)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1513 (0.1537)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1519 (0.1535)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1519 (0.1536)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1550 (0.1537)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1536 (0.1533)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1510 (0.1533)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1528 (0.1535)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1533 (0.1536)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1551 (0.1536)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1546 (0.1536)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:83] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1546 (0.1536)\n",
      "Valid: [epoch:83]  [ 0/14]  eta: 0:00:04  loss: 0.1589 (0.1589)  time: 0.2972  data: 0.2826  max mem: 20571\n",
      "Valid: [epoch:83]  [13/14]  eta: 0:00:00  loss: 0.1455 (0.1494)  time: 0.0397  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:83] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.1455 (0.1494)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_83_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.149%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:84]  [  0/172]  eta: 0:07:36  lr: 0.000100  loss: 0.1498 (0.1498)  time: 2.6527  data: 1.0721  max mem: 20571\n",
      "Train: [epoch:84]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1523 (0.1533)  time: 1.6749  data: 0.0976  max mem: 20571\n",
      "Train: [epoch:84]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1532 (0.1544)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1528 (0.1545)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1547 (0.1556)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1567 (0.1553)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1488 (0.1555)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1488 (0.1554)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1504 (0.1551)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1543 (0.1554)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1563 (0.1555)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1559 (0.1556)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1559 (0.1555)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1549 (0.1554)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1546 (0.1552)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1562 (0.1553)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1566 (0.1554)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1559 (0.1553)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1559 (0.1552)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:84] Total time: 0:04:32 (1.5856 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1559 (0.1552)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:84]  [ 0/14]  eta: 0:00:04  loss: 0.1390 (0.1390)  time: 0.3327  data: 0.3175  max mem: 20571\n",
      "Valid: [epoch:84]  [13/14]  eta: 0:00:00  loss: 0.1390 (0.1429)  time: 0.0383  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:84] Total time: 0:00:00 (0.0434 s / it)\n",
      "Averaged stats: loss: 0.1390 (0.1429)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_84_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.143%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:85]  [  0/172]  eta: 0:07:43  lr: 0.000100  loss: 0.1312 (0.1312)  time: 2.6969  data: 1.1185  max mem: 20571\n",
      "Train: [epoch:85]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1603 (0.1579)  time: 1.6770  data: 0.1018  max mem: 20571\n",
      "Train: [epoch:85]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1559 (0.1573)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1571 (0.1581)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1599 (0.1581)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1573 (0.1584)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1568 (0.1583)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1571 (0.1582)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1563 (0.1576)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1563 (0.1575)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1540 (0.1574)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1520 (0.1572)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1542 (0.1572)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1542 (0.1571)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1508 (0.1569)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1567 (0.1570)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1576 (0.1569)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1555 (0.1570)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1540 (0.1568)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:85] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1540 (0.1568)\n",
      "Valid: [epoch:85]  [ 0/14]  eta: 0:00:05  loss: 0.1339 (0.1339)  time: 0.3668  data: 0.3491  max mem: 20571\n",
      "Valid: [epoch:85]  [13/14]  eta: 0:00:00  loss: 0.1375 (0.1419)  time: 0.0409  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:85] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.1375 (0.1419)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_85_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.142%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:86]  [  0/172]  eta: 0:07:42  lr: 0.000100  loss: 0.1487 (0.1487)  time: 2.6883  data: 1.1096  max mem: 20571\n",
      "Train: [epoch:86]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1572 (0.1596)  time: 1.6794  data: 0.1010  max mem: 20571\n",
      "Train: [epoch:86]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1593 (0.1592)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:86]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1594 (0.1595)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1582 (0.1597)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1571 (0.1596)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1556 (0.1596)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1531 (0.1591)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1532 (0.1589)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1587 (0.1592)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1599 (0.1592)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1587 (0.1592)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1573 (0.1590)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1592 (0.1590)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1603 (0.1589)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1554 (0.1589)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1578 (0.1589)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1585 (0.1590)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1585 (0.1589)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:86] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1585 (0.1589)\n",
      "Valid: [epoch:86]  [ 0/14]  eta: 0:00:06  loss: 0.1434 (0.1434)  time: 0.4601  data: 0.4447  max mem: 20571\n",
      "Valid: [epoch:86]  [13/14]  eta: 0:00:00  loss: 0.1439 (0.1479)  time: 0.0474  data: 0.0326  max mem: 20571\n",
      "Valid: [epoch:86] Total time: 0:00:00 (0.0525 s / it)\n",
      "Averaged stats: loss: 0.1439 (0.1479)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_86_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.148%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:87]  [  0/172]  eta: 0:07:35  lr: 0.000100  loss: 0.1582 (0.1582)  time: 2.6486  data: 1.0755  max mem: 20571\n",
      "Train: [epoch:87]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1642 (0.1613)  time: 1.6724  data: 0.0979  max mem: 20571\n",
      "Train: [epoch:87]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1593 (0.1608)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1575 (0.1601)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1582 (0.1614)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1594 (0.1606)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1577 (0.1600)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1590 (0.1604)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1601 (0.1602)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1563 (0.1603)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1577 (0.1604)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1630 (0.1604)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1594 (0.1604)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1593 (0.1606)  time: 1.5776  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:87]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1587 (0.1605)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1572 (0.1604)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1569 (0.1604)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1602 (0.1603)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1613 (0.1604)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:87] Total time: 0:04:32 (1.5850 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1613 (0.1604)\n",
      "Valid: [epoch:87]  [ 0/14]  eta: 0:00:03  loss: 0.1314 (0.1314)  time: 0.2762  data: 0.2600  max mem: 20571\n",
      "Valid: [epoch:87]  [13/14]  eta: 0:00:00  loss: 0.1424 (0.1463)  time: 0.0409  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:87] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.1424 (0.1463)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_87_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.146%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:88]  [  0/172]  eta: 0:07:36  lr: 0.000100  loss: 0.1460 (0.1460)  time: 2.6558  data: 1.0915  max mem: 20571\n",
      "Train: [epoch:88]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1567 (0.1608)  time: 1.6747  data: 0.0993  max mem: 20571\n",
      "Train: [epoch:88]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1634 (0.1618)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1662 (0.1630)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1618 (0.1629)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1622 (0.1635)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1619 (0.1630)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1608 (0.1628)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1631 (0.1630)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1631 (0.1631)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1593 (0.1628)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1601 (0.1627)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1606 (0.1624)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1604 (0.1624)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1551 (0.1622)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1566 (0.1620)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1592 (0.1618)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1603 (0.1619)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1603 (0.1618)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:88] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1603 (0.1618)\n",
      "Valid: [epoch:88]  [ 0/14]  eta: 0:00:03  loss: 0.1381 (0.1381)  time: 0.2714  data: 0.2550  max mem: 20571\n",
      "Valid: [epoch:88]  [13/14]  eta: 0:00:00  loss: 0.1463 (0.1501)  time: 0.0355  data: 0.0205  max mem: 20571\n",
      "Valid: [epoch:88] Total time: 0:00:00 (0.0406 s / it)\n",
      "Averaged stats: loss: 0.1463 (0.1501)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_88_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.150%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:89]  [  0/172]  eta: 0:07:37  lr: 0.000100  loss: 0.1473 (0.1473)  time: 2.6612  data: 1.0657  max mem: 20571\n",
      "Train: [epoch:89]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1701 (0.1671)  time: 1.6729  data: 0.0970  max mem: 20571\n",
      "Train: [epoch:89]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1626 (0.1643)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1639 (0.1651)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1652 (0.1652)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1652 (0.1656)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1620 (0.1652)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1608 (0.1649)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1609 (0.1644)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1609 (0.1643)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1610 (0.1642)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1623 (0.1639)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1597 (0.1638)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1605 (0.1640)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1643 (0.1637)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1592 (0.1636)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1615 (0.1636)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1648 (0.1637)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1648 (0.1636)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:89] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1648 (0.1636)\n",
      "Valid: [epoch:89]  [ 0/14]  eta: 0:00:04  loss: 0.1395 (0.1395)  time: 0.3159  data: 0.2993  max mem: 20571\n",
      "Valid: [epoch:89]  [13/14]  eta: 0:00:00  loss: 0.1500 (0.1537)  time: 0.0474  data: 0.0323  max mem: 20571\n",
      "Valid: [epoch:89] Total time: 0:00:00 (0.0551 s / it)\n",
      "Averaged stats: loss: 0.1500 (0.1537)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_89_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.154%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:90]  [  0/172]  eta: 0:07:20  lr: 0.000100  loss: 0.1665 (0.1665)  time: 2.5595  data: 0.9943  max mem: 20571\n",
      "Train: [epoch:90]  [ 10/172]  eta: 0:04:29  lr: 0.000100  loss: 0.1665 (0.1684)  time: 1.6663  data: 0.0905  max mem: 20571\n",
      "Train: [epoch:90]  [ 20/172]  eta: 0:04:06  lr: 0.000100  loss: 0.1644 (0.1678)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1653 (0.1674)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1653 (0.1670)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1667 (0.1673)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1664 (0.1667)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1636 (0.1664)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1639 (0.1664)  time: 1.5781  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:90]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1681 (0.1661)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1672 (0.1661)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1668 (0.1661)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1646 (0.1661)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1646 (0.1660)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1678 (0.1660)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1643 (0.1656)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1625 (0.1655)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1664 (0.1655)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1632 (0.1654)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:90] Total time: 0:04:32 (1.5842 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1632 (0.1654)\n",
      "Valid: [epoch:90]  [ 0/14]  eta: 0:00:04  loss: 0.1451 (0.1451)  time: 0.3149  data: 0.2993  max mem: 20571\n",
      "Valid: [epoch:90]  [13/14]  eta: 0:00:00  loss: 0.1488 (0.1531)  time: 0.0431  data: 0.0281  max mem: 20571\n",
      "Valid: [epoch:90] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.1488 (0.1531)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_90_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.153%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:91]  [  0/172]  eta: 0:07:31  lr: 0.000100  loss: 0.1442 (0.1442)  time: 2.6271  data: 1.0564  max mem: 20571\n",
      "Train: [epoch:91]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1650 (0.1674)  time: 1.6699  data: 0.0962  max mem: 20571\n",
      "Train: [epoch:91]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1648 (0.1691)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1641 (0.1682)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1621 (0.1672)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1616 (0.1671)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1638 (0.1672)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1646 (0.1672)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1642 (0.1668)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1635 (0.1670)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:91]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1684 (0.1674)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1677 (0.1675)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1640 (0.1674)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1660 (0.1673)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1687 (0.1677)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1687 (0.1676)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1657 (0.1675)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1629 (0.1674)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1636 (0.1674)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:91] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1636 (0.1674)\n",
      "Valid: [epoch:91]  [ 0/14]  eta: 0:00:04  loss: 0.1329 (0.1329)  time: 0.2889  data: 0.2741  max mem: 20571\n",
      "Valid: [epoch:91]  [13/14]  eta: 0:00:00  loss: 0.1469 (0.1512)  time: 0.0489  data: 0.0340  max mem: 20571\n",
      "Valid: [epoch:91] Total time: 0:00:00 (0.0539 s / it)\n",
      "Averaged stats: loss: 0.1469 (0.1512)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_91_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.151%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:92]  [  0/172]  eta: 0:07:50  lr: 0.000100  loss: 0.1569 (0.1569)  time: 2.7350  data: 1.1599  max mem: 20571\n",
      "Train: [epoch:92]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1664 (0.1660)  time: 1.6817  data: 0.1056  max mem: 20571\n",
      "Train: [epoch:92]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1681 (0.1691)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1702 (0.1684)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1658 (0.1681)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1690 (0.1689)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:92]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1694 (0.1693)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:92]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1708 (0.1691)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1692 (0.1690)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1657 (0.1690)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1661 (0.1690)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1676 (0.1690)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1672 (0.1689)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1671 (0.1689)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1709 (0.1689)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1706 (0.1688)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1676 (0.1687)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1630 (0.1685)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1630 (0.1686)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:92] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1630 (0.1686)\n",
      "Valid: [epoch:92]  [ 0/14]  eta: 0:00:05  loss: 0.1763 (0.1763)  time: 0.3652  data: 0.3482  max mem: 20571\n",
      "Valid: [epoch:92]  [13/14]  eta: 0:00:00  loss: 0.1671 (0.1710)  time: 0.0409  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:92] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.1671 (0.1710)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_92_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.171%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:93]  [  0/172]  eta: 0:07:33  lr: 0.000100  loss: 0.1756 (0.1756)  time: 2.6391  data: 1.0448  max mem: 20571\n",
      "Train: [epoch:93]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1727 (0.1725)  time: 1.6731  data: 0.0951  max mem: 20571\n",
      "Train: [epoch:93]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1731 (0.1724)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1731 (0.1727)  time: 1.5767  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:93]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1713 (0.1725)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [ 50/172]  eta: 0:03:14  lr: 0.000100  loss: 0.1717 (0.1722)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1717 (0.1724)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1719 (0.1726)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1682 (0.1723)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1678 (0.1721)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1700 (0.1721)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1700 (0.1717)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1714 (0.1713)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1679 (0.1713)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1674 (0.1713)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1661 (0.1710)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1640 (0.1707)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1705 (0.1708)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1682 (0.1708)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:93] Total time: 0:04:32 (1.5844 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1682 (0.1708)\n",
      "Valid: [epoch:93]  [ 0/14]  eta: 0:00:05  loss: 0.1340 (0.1340)  time: 0.3698  data: 0.3549  max mem: 20571\n",
      "Valid: [epoch:93]  [13/14]  eta: 0:00:00  loss: 0.1464 (0.1507)  time: 0.0404  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:93] Total time: 0:00:00 (0.0453 s / it)\n",
      "Averaged stats: loss: 0.1464 (0.1507)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_93_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.151%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:94]  [  0/172]  eta: 0:07:29  lr: 0.000100  loss: 0.1515 (0.1515)  time: 2.6150  data: 1.0490  max mem: 20571\n",
      "Train: [epoch:94]  [ 10/172]  eta: 0:04:30  lr: 0.000100  loss: 0.1637 (0.1690)  time: 1.6713  data: 0.0955  max mem: 20571\n",
      "Train: [epoch:94]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1689 (0.1704)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1709 (0.1710)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1747 (0.1725)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1729 (0.1726)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1679 (0.1725)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1693 (0.1725)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1680 (0.1724)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1635 (0.1720)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1707 (0.1719)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1707 (0.1717)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1703 (0.1720)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1757 (0.1722)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1757 (0.1723)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1732 (0.1722)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1683 (0.1720)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1692 (0.1721)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1692 (0.1721)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:94] Total time: 0:04:32 (1.5847 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1692 (0.1721)\n",
      "Valid: [epoch:94]  [ 0/14]  eta: 0:00:04  loss: 0.1650 (0.1650)  time: 0.2975  data: 0.2825  max mem: 20571\n",
      "Valid: [epoch:94]  [13/14]  eta: 0:00:00  loss: 0.1504 (0.1545)  time: 0.0371  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:94] Total time: 0:00:00 (0.0445 s / it)\n",
      "Averaged stats: loss: 0.1504 (0.1545)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_94_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.155%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:95]  [  0/172]  eta: 0:07:40  lr: 0.000100  loss: 0.1694 (0.1694)  time: 2.6797  data: 1.1036  max mem: 20571\n",
      "Train: [epoch:95]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1694 (0.1751)  time: 1.6762  data: 0.1004  max mem: 20571\n",
      "Train: [epoch:95]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1783 (0.1749)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [ 30/172]  eta: 0:03:48  lr: 0.000100  loss: 0.1783 (0.1742)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1776 (0.1747)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1728 (0.1745)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1711 (0.1741)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1719 (0.1739)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1738 (0.1737)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1730 (0.1736)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1756 (0.1744)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1772 (0.1742)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1725 (0.1743)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1705 (0.1743)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1727 (0.1742)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1733 (0.1742)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1730 (0.1743)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1713 (0.1743)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1710 (0.1743)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:95] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1710 (0.1743)\n",
      "Valid: [epoch:95]  [ 0/14]  eta: 0:00:04  loss: 0.1487 (0.1487)  time: 0.2936  data: 0.2776  max mem: 20571\n",
      "Valid: [epoch:95]  [13/14]  eta: 0:00:00  loss: 0.1526 (0.1570)  time: 0.0422  data: 0.0273  max mem: 20571\n",
      "Valid: [epoch:95] Total time: 0:00:00 (0.0470 s / it)\n",
      "Averaged stats: loss: 0.1526 (0.1570)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_95_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of the network on the 14 valid images: 0.157%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:96]  [  0/172]  eta: 0:07:57  lr: 0.000100  loss: 0.1605 (0.1605)  time: 2.7787  data: 1.2135  max mem: 20571\n",
      "Train: [epoch:96]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.1775 (0.1747)  time: 1.6864  data: 0.1104  max mem: 20571\n",
      "Train: [epoch:96]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1759 (0.1750)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1743 (0.1759)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1739 (0.1760)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:96]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1759 (0.1762)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:96]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1760 (0.1764)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:96]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1722 (0.1757)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:96]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1773 (0.1763)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1773 (0.1764)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1721 (0.1759)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1728 (0.1762)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1766 (0.1760)  time: 1.5768  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:96]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1761 (0.1762)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:96]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1747 (0.1760)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1755 (0.1759)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1757 (0.1758)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1729 (0.1757)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1729 (0.1757)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:96] Total time: 0:04:32 (1.5856 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1729 (0.1757)\n",
      "Valid: [epoch:96]  [ 0/14]  eta: 0:00:06  loss: 0.1837 (0.1837)  time: 0.4555  data: 0.4370  max mem: 20571\n",
      "Valid: [epoch:96]  [13/14]  eta: 0:00:00  loss: 0.1759 (0.1793)  time: 0.0475  data: 0.0323  max mem: 20571\n",
      "Valid: [epoch:96] Total time: 0:00:00 (0.0520 s / it)\n",
      "Averaged stats: loss: 0.1759 (0.1793)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_96_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.179%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:97]  [  0/172]  eta: 0:07:47  lr: 0.000100  loss: 0.1848 (0.1848)  time: 2.7182  data: 1.1396  max mem: 20571\n",
      "Train: [epoch:97]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1836 (0.1830)  time: 1.6776  data: 0.1037  max mem: 20571\n",
      "Train: [epoch:97]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1818 (0.1843)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1834 (0.1840)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1797 (0.1825)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1759 (0.1818)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1739 (0.1804)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1739 (0.1807)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1757 (0.1800)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1677 (0.1794)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1778 (0.1791)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1766 (0.1789)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1756 (0.1785)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1746 (0.1782)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1746 (0.1781)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1710 (0.1780)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:97]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1708 (0.1777)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1787 (0.1781)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1787 (0.1781)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:97] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1787 (0.1781)\n",
      "Valid: [epoch:97]  [ 0/14]  eta: 0:00:05  loss: 0.1910 (0.1910)  time: 0.3837  data: 0.3664  max mem: 20571\n",
      "Valid: [epoch:97]  [13/14]  eta: 0:00:00  loss: 0.1738 (0.1779)  time: 0.0422  data: 0.0271  max mem: 20571\n",
      "Valid: [epoch:97] Total time: 0:00:00 (0.0504 s / it)\n",
      "Averaged stats: loss: 0.1738 (0.1779)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_97_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.178%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:98]  [  0/172]  eta: 0:07:58  lr: 0.000100  loss: 0.1890 (0.1890)  time: 2.7814  data: 1.2125  max mem: 20571\n",
      "Train: [epoch:98]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.1811 (0.1810)  time: 1.6874  data: 0.1103  max mem: 20571\n",
      "Train: [epoch:98]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1801 (0.1817)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1753 (0.1802)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1760 (0.1802)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1788 (0.1800)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1830 (0.1806)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1819 (0.1803)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1752 (0.1802)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1749 (0.1802)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1769 (0.1803)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1780 (0.1801)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1780 (0.1801)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1768 (0.1800)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1810 (0.1799)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1804 (0.1796)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1781 (0.1795)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1775 (0.1794)  time: 1.5841  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:98]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1796 (0.1796)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:98] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1796 (0.1796)\n",
      "Valid: [epoch:98]  [ 0/14]  eta: 0:00:04  loss: 0.1729 (0.1729)  time: 0.3071  data: 0.2909  max mem: 20571\n",
      "Valid: [epoch:98]  [13/14]  eta: 0:00:00  loss: 0.1550 (0.1595)  time: 0.0419  data: 0.0268  max mem: 20571\n",
      "Valid: [epoch:98] Total time: 0:00:00 (0.0504 s / it)\n",
      "Averaged stats: loss: 0.1550 (0.1595)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_98_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.160%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:99]  [  0/172]  eta: 0:07:59  lr: 0.000100  loss: 0.1580 (0.1580)  time: 2.7857  data: 1.2129  max mem: 20571\n",
      "Train: [epoch:99]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.1754 (0.1754)  time: 1.6871  data: 0.1104  max mem: 20571\n",
      "Train: [epoch:99]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1754 (0.1787)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1860 (0.1802)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1843 (0.1812)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1817 (0.1817)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1810 (0.1817)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1805 (0.1811)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1778 (0.1813)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1834 (0.1820)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1821 (0.1813)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1746 (0.1812)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1772 (0.1809)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1791 (0.1808)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1827 (0.1809)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1810 (0.1807)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1797 (0.1807)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1797 (0.1804)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1800 (0.1805)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:99] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1800 (0.1805)\n",
      "Valid: [epoch:99]  [ 0/14]  eta: 0:00:04  loss: 0.1830 (0.1830)  time: 0.3017  data: 0.2849  max mem: 20571\n",
      "Valid: [epoch:99]  [13/14]  eta: 0:00:00  loss: 0.1660 (0.1704)  time: 0.0395  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:99] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.1660 (0.1704)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_99_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.170%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:100]  [  0/172]  eta: 0:07:52  lr: 0.000100  loss: 0.1766 (0.1766)  time: 2.7484  data: 1.1842  max mem: 20571\n",
      "Train: [epoch:100]  [ 10/172]  eta: 0:04:32  lr: 0.000100  loss: 0.1824 (0.1836)  time: 1.6825  data: 0.1078  max mem: 20571\n",
      "Train: [epoch:100]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1828 (0.1842)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1841 (0.1845)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1841 (0.1841)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1793 (0.1835)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1765 (0.1831)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1785 (0.1826)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1800 (0.1829)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:100]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1850 (0.1829)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:100]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1830 (0.1828)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1856 (0.1831)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1856 (0.1833)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1794 (0.1831)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1813 (0.1831)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1813 (0.1832)  time: 1.5759  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:100]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1802 (0.1833)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:100]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1808 (0.1832)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1808 (0.1832)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:100] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1808 (0.1832)\n",
      "Valid: [epoch:100]  [ 0/14]  eta: 0:00:04  loss: 0.1672 (0.1672)  time: 0.3169  data: 0.3020  max mem: 20571\n",
      "Valid: [epoch:100]  [13/14]  eta: 0:00:00  loss: 0.1714 (0.1756)  time: 0.0380  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:100] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.1714 (0.1756)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_100_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.176%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:101]  [  0/172]  eta: 0:08:11  lr: 0.000100  loss: 0.1983 (0.1983)  time: 2.8565  data: 1.2777  max mem: 20571\n",
      "Train: [epoch:101]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.1811 (0.1848)  time: 1.6911  data: 0.1163  max mem: 20571\n",
      "Train: [epoch:101]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1829 (0.1864)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1852 (0.1858)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1853 (0.1863)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1870 (0.1863)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1836 (0.1864)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1831 (0.1855)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1831 (0.1858)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1791 (0.1848)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1778 (0.1848)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1863 (0.1848)  time: 1.5799  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:101]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1826 (0.1846)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1811 (0.1843)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1811 (0.1845)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1810 (0.1843)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1798 (0.1844)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1787 (0.1842)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1787 (0.1841)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:101] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1787 (0.1841)\n",
      "Valid: [epoch:101]  [ 0/14]  eta: 0:00:04  loss: 0.1697 (0.1697)  time: 0.3411  data: 0.3236  max mem: 20571\n",
      "Valid: [epoch:101]  [13/14]  eta: 0:00:00  loss: 0.1700 (0.1741)  time: 0.0391  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:101] Total time: 0:00:00 (0.0470 s / it)\n",
      "Averaged stats: loss: 0.1700 (0.1741)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_101_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.174%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:102]  [  0/172]  eta: 0:07:57  lr: 0.000100  loss: 0.1989 (0.1989)  time: 2.7789  data: 1.2016  max mem: 20571\n",
      "Train: [epoch:102]  [ 10/172]  eta: 0:04:33  lr: 0.000100  loss: 0.1840 (0.1826)  time: 1.6877  data: 0.1094  max mem: 20571\n",
      "Train: [epoch:102]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1799 (0.1848)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1828 (0.1866)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1846 (0.1858)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1843 (0.1854)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1836 (0.1849)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1857 (0.1857)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1826 (0.1852)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1811 (0.1857)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1855 (0.1859)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1875 (0.1855)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1842 (0.1855)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1791 (0.1855)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1800 (0.1854)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1871 (0.1857)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1885 (0.1855)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1799 (0.1855)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1827 (0.1855)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:102] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1827 (0.1855)\n",
      "Valid: [epoch:102]  [ 0/14]  eta: 0:00:04  loss: 0.1593 (0.1593)  time: 0.3189  data: 0.3033  max mem: 20571\n",
      "Valid: [epoch:102]  [13/14]  eta: 0:00:00  loss: 0.1636 (0.1687)  time: 0.0414  data: 0.0262  max mem: 20571\n",
      "Valid: [epoch:102] Total time: 0:00:00 (0.0493 s / it)\n",
      "Averaged stats: loss: 0.1636 (0.1687)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_102_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.169%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:103]  [  0/172]  eta: 0:07:44  lr: 0.000100  loss: 0.1766 (0.1766)  time: 2.6977  data: 1.1176  max mem: 20571\n",
      "Train: [epoch:103]  [ 10/172]  eta: 0:04:31  lr: 0.000100  loss: 0.1817 (0.1853)  time: 1.6777  data: 0.1017  max mem: 20571\n",
      "Train: [epoch:103]  [ 20/172]  eta: 0:04:07  lr: 0.000100  loss: 0.1919 (0.1888)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1901 (0.1891)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [ 40/172]  eta: 0:03:31  lr: 0.000100  loss: 0.1849 (0.1883)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1846 (0.1881)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [ 60/172]  eta: 0:02:58  lr: 0.000100  loss: 0.1865 (0.1885)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1903 (0.1887)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1908 (0.1885)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1881 (0.1888)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1881 (0.1887)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1903 (0.1887)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1900 (0.1885)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1799 (0.1881)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1817 (0.1881)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1883 (0.1882)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1863 (0.1880)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1854 (0.1881)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1854 (0.1881)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:103] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1854 (0.1881)\n",
      "Valid: [epoch:103]  [ 0/14]  eta: 0:00:04  loss: 0.1977 (0.1977)  time: 0.3049  data: 0.2883  max mem: 20571\n",
      "Valid: [epoch:103]  [13/14]  eta: 0:00:00  loss: 0.1805 (0.1849)  time: 0.0426  data: 0.0276  max mem: 20571\n",
      "Valid: [epoch:103] Total time: 0:00:00 (0.0476 s / it)\n",
      "Averaged stats: loss: 0.1805 (0.1849)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_103_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.185%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:104]  [  0/172]  eta: 0:08:04  lr: 0.000100  loss: 0.1886 (0.1886)  time: 2.8183  data: 1.2462  max mem: 20571\n",
      "Train: [epoch:104]  [ 10/172]  eta: 0:04:34  lr: 0.000100  loss: 0.1893 (0.1889)  time: 1.6915  data: 0.1134  max mem: 20571\n",
      "Train: [epoch:104]  [ 20/172]  eta: 0:04:08  lr: 0.000100  loss: 0.1901 (0.1898)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [ 30/172]  eta: 0:03:49  lr: 0.000100  loss: 0.1902 (0.1894)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [ 40/172]  eta: 0:03:32  lr: 0.000100  loss: 0.1902 (0.1908)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [ 50/172]  eta: 0:03:15  lr: 0.000100  loss: 0.1891 (0.1906)  time: 1.5815  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:104]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1880 (0.1899)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [ 70/172]  eta: 0:02:42  lr: 0.000100  loss: 0.1914 (0.1905)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [ 80/172]  eta: 0:02:26  lr: 0.000100  loss: 0.1901 (0.1902)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1886 (0.1900)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1893 (0.1899)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1910 (0.1903)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1881 (0.1901)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:104]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1829 (0.1899)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:104]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1817 (0.1896)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1822 (0.1894)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1824 (0.1892)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1894 (0.1893)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1894 (0.1893)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:104] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1894 (0.1893)\n",
      "Valid: [epoch:104]  [ 0/14]  eta: 0:00:04  loss: 0.1626 (0.1626)  time: 0.3122  data: 0.2951  max mem: 20571\n",
      "Valid: [epoch:104]  [13/14]  eta: 0:00:00  loss: 0.1742 (0.1780)  time: 0.0377  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:104] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.1742 (0.1780)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_104_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.178%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:105]  [  0/172]  eta: 0:08:18  lr: 0.000100  loss: 0.1982 (0.1982)  time: 2.8967  data: 1.3164  max mem: 20571\n",
      "Train: [epoch:105]  [ 10/172]  eta: 0:04:35  lr: 0.000100  loss: 0.1934 (0.1926)  time: 1.6996  data: 0.1198  max mem: 20571\n",
      "Train: [epoch:105]  [ 20/172]  eta: 0:04:09  lr: 0.000100  loss: 0.1926 (0.1913)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [ 30/172]  eta: 0:03:50  lr: 0.000100  loss: 0.1855 (0.1912)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [ 40/172]  eta: 0:03:33  lr: 0.000100  loss: 0.1899 (0.1917)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [ 50/172]  eta: 0:03:16  lr: 0.000100  loss: 0.1960 (0.1922)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [ 60/172]  eta: 0:02:59  lr: 0.000100  loss: 0.1865 (0.1918)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [ 70/172]  eta: 0:02:43  lr: 0.000100  loss: 0.1873 (0.1918)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [ 80/172]  eta: 0:02:27  lr: 0.000100  loss: 0.1873 (0.1917)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [ 90/172]  eta: 0:02:10  lr: 0.000100  loss: 0.1895 (0.1915)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [100/172]  eta: 0:01:54  lr: 0.000100  loss: 0.1875 (0.1910)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [110/172]  eta: 0:01:38  lr: 0.000100  loss: 0.1856 (0.1908)  time: 1.5843  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:105]  [120/172]  eta: 0:01:22  lr: 0.000100  loss: 0.1904 (0.1908)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [130/172]  eta: 0:01:06  lr: 0.000100  loss: 0.1899 (0.1907)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [140/172]  eta: 0:00:50  lr: 0.000100  loss: 0.1908 (0.1908)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [150/172]  eta: 0:00:34  lr: 0.000100  loss: 0.1933 (0.1911)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [160/172]  eta: 0:00:19  lr: 0.000100  loss: 0.1917 (0.1909)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [170/172]  eta: 0:00:03  lr: 0.000100  loss: 0.1917 (0.1909)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105]  [171/172]  eta: 0:00:01  lr: 0.000100  loss: 0.1917 (0.1908)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:105] Total time: 0:04:33 (1.5905 s / it)\n",
      "Averaged stats: lr: 0.000100  loss: 0.1917 (0.1908)\n",
      "Valid: [epoch:105]  [ 0/14]  eta: 0:00:04  loss: 0.1549 (0.1549)  time: 0.3081  data: 0.2929  max mem: 20571\n",
      "Valid: [epoch:105]  [13/14]  eta: 0:00:00  loss: 0.1649 (0.1704)  time: 0.0489  data: 0.0339  max mem: 20571\n",
      "Valid: [epoch:105] Total time: 0:00:00 (0.0569 s / it)\n",
      "Averaged stats: loss: 0.1649 (0.1704)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_105_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.170%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:106]  [  0/172]  eta: 0:07:43  lr: 0.000099  loss: 0.1762 (0.1762)  time: 2.6928  data: 1.1160  max mem: 20571\n",
      "Train: [epoch:106]  [ 10/172]  eta: 0:04:32  lr: 0.000099  loss: 0.1847 (0.1903)  time: 1.6818  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:106]  [ 20/172]  eta: 0:04:08  lr: 0.000099  loss: 0.1952 (0.1931)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:106]  [ 30/172]  eta: 0:03:49  lr: 0.000099  loss: 0.1933 (0.1927)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [ 40/172]  eta: 0:03:32  lr: 0.000099  loss: 0.1916 (0.1932)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [ 50/172]  eta: 0:03:15  lr: 0.000099  loss: 0.1916 (0.1934)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [ 60/172]  eta: 0:02:59  lr: 0.000099  loss: 0.1915 (0.1930)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [ 70/172]  eta: 0:02:42  lr: 0.000099  loss: 0.1883 (0.1932)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [ 80/172]  eta: 0:02:26  lr: 0.000099  loss: 0.1893 (0.1934)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [ 90/172]  eta: 0:02:10  lr: 0.000099  loss: 0.1900 (0.1932)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [100/172]  eta: 0:01:54  lr: 0.000099  loss: 0.1920 (0.1932)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [110/172]  eta: 0:01:38  lr: 0.000099  loss: 0.1931 (0.1933)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [120/172]  eta: 0:01:22  lr: 0.000099  loss: 0.1898 (0.1932)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [130/172]  eta: 0:01:06  lr: 0.000099  loss: 0.1898 (0.1928)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [140/172]  eta: 0:00:50  lr: 0.000099  loss: 0.1918 (0.1928)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [150/172]  eta: 0:00:34  lr: 0.000099  loss: 0.1883 (0.1926)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [160/172]  eta: 0:00:19  lr: 0.000099  loss: 0.1899 (0.1927)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [170/172]  eta: 0:00:03  lr: 0.000099  loss: 0.1967 (0.1932)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106]  [171/172]  eta: 0:00:01  lr: 0.000099  loss: 0.1967 (0.1932)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:106] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000099  loss: 0.1967 (0.1932)\n",
      "Valid: [epoch:106]  [ 0/14]  eta: 0:00:05  loss: 0.1859 (0.1859)  time: 0.3574  data: 0.3407  max mem: 20571\n",
      "Valid: [epoch:106]  [13/14]  eta: 0:00:00  loss: 0.1674 (0.1726)  time: 0.0402  data: 0.0251  max mem: 20571\n",
      "Valid: [epoch:106] Total time: 0:00:00 (0.0447 s / it)\n",
      "Averaged stats: loss: 0.1674 (0.1726)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_106_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.173%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:107]  [  0/172]  eta: 0:07:32  lr: 0.000099  loss: 0.1744 (0.1744)  time: 2.6299  data: 1.0470  max mem: 20571\n",
      "Train: [epoch:107]  [ 10/172]  eta: 0:04:31  lr: 0.000099  loss: 0.1910 (0.1937)  time: 1.6731  data: 0.0953  max mem: 20571\n",
      "Train: [epoch:107]  [ 20/172]  eta: 0:04:07  lr: 0.000099  loss: 0.1932 (0.1926)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [ 30/172]  eta: 0:03:49  lr: 0.000099  loss: 0.1902 (0.1931)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [ 40/172]  eta: 0:03:31  lr: 0.000099  loss: 0.1888 (0.1934)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [ 50/172]  eta: 0:03:15  lr: 0.000099  loss: 0.1965 (0.1942)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [ 60/172]  eta: 0:02:58  lr: 0.000099  loss: 0.1935 (0.1938)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [ 70/172]  eta: 0:02:42  lr: 0.000099  loss: 0.1892 (0.1937)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [ 80/172]  eta: 0:02:26  lr: 0.000099  loss: 0.1892 (0.1936)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [ 90/172]  eta: 0:02:10  lr: 0.000099  loss: 0.1894 (0.1934)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [100/172]  eta: 0:01:54  lr: 0.000099  loss: 0.1892 (0.1935)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [110/172]  eta: 0:01:38  lr: 0.000099  loss: 0.1900 (0.1938)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [120/172]  eta: 0:01:22  lr: 0.000099  loss: 0.1915 (0.1936)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [130/172]  eta: 0:01:06  lr: 0.000099  loss: 0.1921 (0.1939)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:107]  [140/172]  eta: 0:00:50  lr: 0.000099  loss: 0.1903 (0.1939)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:107]  [150/172]  eta: 0:00:34  lr: 0.000099  loss: 0.1886 (0.1940)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [160/172]  eta: 0:00:19  lr: 0.000099  loss: 0.1905 (0.1940)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [170/172]  eta: 0:00:03  lr: 0.000099  loss: 0.1918 (0.1939)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107]  [171/172]  eta: 0:00:01  lr: 0.000099  loss: 0.1918 (0.1939)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:107] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000099  loss: 0.1918 (0.1939)\n",
      "Valid: [epoch:107]  [ 0/14]  eta: 0:00:04  loss: 0.1938 (0.1938)  time: 0.3084  data: 0.2912  max mem: 20571\n",
      "Valid: [epoch:107]  [13/14]  eta: 0:00:00  loss: 0.1771 (0.1817)  time: 0.0483  data: 0.0333  max mem: 20571\n",
      "Valid: [epoch:107] Total time: 0:00:00 (0.0567 s / it)\n",
      "Averaged stats: loss: 0.1771 (0.1817)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_107_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.182%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:108]  [  0/172]  eta: 0:07:44  lr: 0.000099  loss: 0.1996 (0.1996)  time: 2.6987  data: 1.1333  max mem: 20571\n",
      "Train: [epoch:108]  [ 10/172]  eta: 0:04:31  lr: 0.000099  loss: 0.1941 (0.1960)  time: 1.6789  data: 0.1031  max mem: 20571\n",
      "Train: [epoch:108]  [ 20/172]  eta: 0:04:08  lr: 0.000099  loss: 0.1941 (0.1978)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:108]  [ 30/172]  eta: 0:03:49  lr: 0.000099  loss: 0.1988 (0.1983)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:108]  [ 40/172]  eta: 0:03:32  lr: 0.000099  loss: 0.1934 (0.1967)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:108]  [ 50/172]  eta: 0:03:15  lr: 0.000099  loss: 0.1938 (0.1970)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:108]  [ 60/172]  eta: 0:02:59  lr: 0.000099  loss: 0.1951 (0.1967)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:108]  [ 70/172]  eta: 0:02:42  lr: 0.000099  loss: 0.1951 (0.1969)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:108]  [ 80/172]  eta: 0:02:26  lr: 0.000099  loss: 0.1927 (0.1969)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:108]  [ 90/172]  eta: 0:02:10  lr: 0.000099  loss: 0.1926 (0.1967)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:108]  [100/172]  eta: 0:01:54  lr: 0.000099  loss: 0.1995 (0.1970)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:108]  [110/172]  eta: 0:01:38  lr: 0.000099  loss: 0.1948 (0.1969)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:108]  [120/172]  eta: 0:01:22  lr: 0.000099  loss: 0.1929 (0.1967)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:108]  [130/172]  eta: 0:01:06  lr: 0.000099  loss: 0.1953 (0.1966)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:108]  [140/172]  eta: 0:00:50  lr: 0.000099  loss: 0.1940 (0.1961)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:108]  [150/172]  eta: 0:00:34  lr: 0.000099  loss: 0.1940 (0.1963)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:108]  [160/172]  eta: 0:00:19  lr: 0.000099  loss: 0.1906 (0.1958)  time: 1.5849  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:108]  [170/172]  eta: 0:00:03  lr: 0.000099  loss: 0.1889 (0.1957)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:108]  [171/172]  eta: 0:00:01  lr: 0.000099  loss: 0.1889 (0.1958)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:108] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000099  loss: 0.1889 (0.1958)\n",
      "Valid: [epoch:108]  [ 0/14]  eta: 0:00:04  loss: 0.1584 (0.1584)  time: 0.3303  data: 0.3144  max mem: 20571\n",
      "Valid: [epoch:108]  [13/14]  eta: 0:00:00  loss: 0.1754 (0.1805)  time: 0.0420  data: 0.0271  max mem: 20571\n",
      "Valid: [epoch:108] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.1754 (0.1805)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_108_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.181%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:109]  [  0/172]  eta: 0:08:31  lr: 0.000099  loss: 0.1851 (0.1851)  time: 2.9762  data: 1.3946  max mem: 20571\n",
      "Train: [epoch:109]  [ 10/172]  eta: 0:04:36  lr: 0.000099  loss: 0.1912 (0.1946)  time: 1.7064  data: 0.1269  max mem: 20571\n",
      "Train: [epoch:109]  [ 20/172]  eta: 0:04:10  lr: 0.000099  loss: 0.1955 (0.1948)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [ 30/172]  eta: 0:03:50  lr: 0.000099  loss: 0.1960 (0.1974)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [ 40/172]  eta: 0:03:33  lr: 0.000099  loss: 0.2030 (0.1971)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [ 50/172]  eta: 0:03:16  lr: 0.000099  loss: 0.1978 (0.1980)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [ 60/172]  eta: 0:02:59  lr: 0.000099  loss: 0.1915 (0.1962)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [ 70/172]  eta: 0:02:43  lr: 0.000099  loss: 0.1915 (0.1971)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [ 80/172]  eta: 0:02:27  lr: 0.000099  loss: 0.1952 (0.1967)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [ 90/172]  eta: 0:02:11  lr: 0.000099  loss: 0.1922 (0.1965)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [100/172]  eta: 0:01:54  lr: 0.000099  loss: 0.1929 (0.1964)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [110/172]  eta: 0:01:38  lr: 0.000099  loss: 0.1929 (0.1964)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [120/172]  eta: 0:01:22  lr: 0.000099  loss: 0.1915 (0.1965)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [130/172]  eta: 0:01:06  lr: 0.000099  loss: 0.1915 (0.1964)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [140/172]  eta: 0:00:50  lr: 0.000099  loss: 0.1966 (0.1965)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [150/172]  eta: 0:00:35  lr: 0.000099  loss: 0.1942 (0.1963)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [160/172]  eta: 0:00:19  lr: 0.000099  loss: 0.1930 (0.1963)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109]  [170/172]  eta: 0:00:03  lr: 0.000099  loss: 0.1993 (0.1967)  time: 1.5866  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:109]  [171/172]  eta: 0:00:01  lr: 0.000099  loss: 0.1974 (0.1967)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:109] Total time: 0:04:33 (1.5929 s / it)\n",
      "Averaged stats: lr: 0.000099  loss: 0.1974 (0.1967)\n",
      "Valid: [epoch:109]  [ 0/14]  eta: 0:00:04  loss: 0.2057 (0.2057)  time: 0.2909  data: 0.2748  max mem: 20571\n",
      "Valid: [epoch:109]  [13/14]  eta: 0:00:00  loss: 0.1891 (0.1950)  time: 0.0443  data: 0.0292  max mem: 20571\n",
      "Valid: [epoch:109] Total time: 0:00:00 (0.0492 s / it)\n",
      "Averaged stats: loss: 0.1891 (0.1950)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_109_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.195%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:110]  [  0/172]  eta: 0:07:55  lr: 0.000099  loss: 0.1892 (0.1892)  time: 2.7659  data: 1.1969  max mem: 20571\n",
      "Train: [epoch:110]  [ 10/172]  eta: 0:04:33  lr: 0.000099  loss: 0.1994 (0.1992)  time: 1.6871  data: 0.1089  max mem: 20571\n",
      "Train: [epoch:110]  [ 20/172]  eta: 0:04:08  lr: 0.000099  loss: 0.1994 (0.1991)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [ 30/172]  eta: 0:03:49  lr: 0.000099  loss: 0.2065 (0.2007)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [ 40/172]  eta: 0:03:32  lr: 0.000099  loss: 0.2044 (0.2010)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [ 50/172]  eta: 0:03:15  lr: 0.000099  loss: 0.1983 (0.2007)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [ 60/172]  eta: 0:02:59  lr: 0.000099  loss: 0.1983 (0.2012)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [ 70/172]  eta: 0:02:42  lr: 0.000099  loss: 0.1993 (0.2005)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [ 80/172]  eta: 0:02:26  lr: 0.000099  loss: 0.1963 (0.2007)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [ 90/172]  eta: 0:02:10  lr: 0.000099  loss: 0.2034 (0.2007)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [100/172]  eta: 0:01:54  lr: 0.000099  loss: 0.1971 (0.2002)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [110/172]  eta: 0:01:38  lr: 0.000099  loss: 0.1978 (0.2001)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [120/172]  eta: 0:01:22  lr: 0.000099  loss: 0.1978 (0.2000)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [130/172]  eta: 0:01:06  lr: 0.000099  loss: 0.1930 (0.1996)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [140/172]  eta: 0:00:50  lr: 0.000099  loss: 0.1928 (0.1994)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [150/172]  eta: 0:00:34  lr: 0.000099  loss: 0.1955 (0.1992)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [160/172]  eta: 0:00:19  lr: 0.000099  loss: 0.1969 (0.1993)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [170/172]  eta: 0:00:03  lr: 0.000099  loss: 0.1987 (0.1995)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110]  [171/172]  eta: 0:00:01  lr: 0.000099  loss: 0.1984 (0.1994)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:110] Total time: 0:04:32 (1.5865 s / it)\n",
      "Averaged stats: lr: 0.000099  loss: 0.1984 (0.1994)\n",
      "Valid: [epoch:110]  [ 0/14]  eta: 0:00:04  loss: 0.2178 (0.2178)  time: 0.3266  data: 0.3115  max mem: 20571\n",
      "Valid: [epoch:110]  [13/14]  eta: 0:00:00  loss: 0.2006 (0.2052)  time: 0.0387  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:110] Total time: 0:00:00 (0.0444 s / it)\n",
      "Averaged stats: loss: 0.2006 (0.2052)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_110_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.205%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:111]  [  0/172]  eta: 0:07:42  lr: 0.000099  loss: 0.1982 (0.1982)  time: 2.6891  data: 1.1116  max mem: 20571\n",
      "Train: [epoch:111]  [ 10/172]  eta: 0:04:31  lr: 0.000099  loss: 0.1982 (0.2025)  time: 1.6762  data: 0.1011  max mem: 20571\n",
      "Train: [epoch:111]  [ 20/172]  eta: 0:04:07  lr: 0.000099  loss: 0.1997 (0.2030)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [ 30/172]  eta: 0:03:48  lr: 0.000099  loss: 0.1994 (0.2016)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [ 40/172]  eta: 0:03:31  lr: 0.000099  loss: 0.2028 (0.2021)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [ 50/172]  eta: 0:03:14  lr: 0.000099  loss: 0.2009 (0.2021)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [ 60/172]  eta: 0:02:58  lr: 0.000099  loss: 0.1993 (0.2016)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [ 70/172]  eta: 0:02:42  lr: 0.000099  loss: 0.2000 (0.2014)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [ 80/172]  eta: 0:02:26  lr: 0.000099  loss: 0.2010 (0.2016)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [ 90/172]  eta: 0:02:10  lr: 0.000099  loss: 0.1995 (0.2016)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [100/172]  eta: 0:01:54  lr: 0.000099  loss: 0.1995 (0.2016)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [110/172]  eta: 0:01:38  lr: 0.000099  loss: 0.1993 (0.2014)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [120/172]  eta: 0:01:22  lr: 0.000099  loss: 0.1984 (0.2016)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [130/172]  eta: 0:01:06  lr: 0.000099  loss: 0.1970 (0.2012)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [140/172]  eta: 0:00:50  lr: 0.000099  loss: 0.1930 (0.2008)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [150/172]  eta: 0:00:34  lr: 0.000099  loss: 0.2015 (0.2008)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [160/172]  eta: 0:00:19  lr: 0.000099  loss: 0.1975 (0.2007)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [170/172]  eta: 0:00:03  lr: 0.000099  loss: 0.1939 (0.2007)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111]  [171/172]  eta: 0:00:01  lr: 0.000099  loss: 0.1957 (0.2007)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:111] Total time: 0:04:32 (1.5843 s / it)\n",
      "Averaged stats: lr: 0.000099  loss: 0.1957 (0.2007)\n",
      "Valid: [epoch:111]  [ 0/14]  eta: 0:00:04  loss: 0.1954 (0.1954)  time: 0.3176  data: 0.3023  max mem: 20571\n",
      "Valid: [epoch:111]  [13/14]  eta: 0:00:00  loss: 0.1954 (0.2004)  time: 0.0390  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:111] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.1954 (0.2004)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_111_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.200%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:112]  [  0/172]  eta: 0:08:40  lr: 0.000099  loss: 0.2135 (0.2135)  time: 3.0288  data: 1.4509  max mem: 20571\n",
      "Train: [epoch:112]  [ 10/172]  eta: 0:04:36  lr: 0.000099  loss: 0.1988 (0.2020)  time: 1.7080  data: 0.1320  max mem: 20571\n",
      "Train: [epoch:112]  [ 20/172]  eta: 0:04:10  lr: 0.000099  loss: 0.1988 (0.2055)  time: 1.5757  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:112]  [ 30/172]  eta: 0:03:50  lr: 0.000099  loss: 0.2059 (0.2051)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:112]  [ 40/172]  eta: 0:03:32  lr: 0.000099  loss: 0.1989 (0.2049)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [ 50/172]  eta: 0:03:15  lr: 0.000099  loss: 0.2034 (0.2050)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [ 60/172]  eta: 0:02:59  lr: 0.000099  loss: 0.1991 (0.2037)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [ 70/172]  eta: 0:02:42  lr: 0.000099  loss: 0.1979 (0.2042)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [ 80/172]  eta: 0:02:26  lr: 0.000099  loss: 0.2029 (0.2042)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [ 90/172]  eta: 0:02:10  lr: 0.000099  loss: 0.1990 (0.2035)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [100/172]  eta: 0:01:54  lr: 0.000099  loss: 0.1957 (0.2032)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:112]  [110/172]  eta: 0:01:38  lr: 0.000099  loss: 0.2003 (0.2030)  time: 1.5781  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:112]  [120/172]  eta: 0:01:22  lr: 0.000099  loss: 0.2011 (0.2029)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [130/172]  eta: 0:01:06  lr: 0.000099  loss: 0.2013 (0.2029)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [140/172]  eta: 0:00:50  lr: 0.000099  loss: 0.2013 (0.2031)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [150/172]  eta: 0:00:34  lr: 0.000099  loss: 0.1974 (0.2027)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [160/172]  eta: 0:00:19  lr: 0.000099  loss: 0.1990 (0.2028)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [170/172]  eta: 0:00:03  lr: 0.000099  loss: 0.2040 (0.2026)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112]  [171/172]  eta: 0:00:01  lr: 0.000099  loss: 0.2040 (0.2026)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:112] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000099  loss: 0.2040 (0.2026)\n",
      "Valid: [epoch:112]  [ 0/14]  eta: 0:00:04  loss: 0.1959 (0.1959)  time: 0.3243  data: 0.3082  max mem: 20571\n",
      "Valid: [epoch:112]  [13/14]  eta: 0:00:00  loss: 0.1749 (0.1807)  time: 0.0421  data: 0.0270  max mem: 20571\n",
      "Valid: [epoch:112] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.1749 (0.1807)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_112_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.181%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:113]  [  0/172]  eta: 0:07:29  lr: 0.000099  loss: 0.1936 (0.1936)  time: 2.6162  data: 1.0434  max mem: 20571\n",
      "Train: [epoch:113]  [ 10/172]  eta: 0:04:30  lr: 0.000099  loss: 0.2033 (0.2030)  time: 1.6679  data: 0.0950  max mem: 20571\n",
      "Train: [epoch:113]  [ 20/172]  eta: 0:04:06  lr: 0.000099  loss: 0.2078 (0.2050)  time: 1.5727  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:113]  [ 30/172]  eta: 0:03:48  lr: 0.000099  loss: 0.2030 (0.2037)  time: 1.5733  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [ 40/172]  eta: 0:03:31  lr: 0.000099  loss: 0.1973 (0.2031)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [ 50/172]  eta: 0:03:14  lr: 0.000099  loss: 0.1975 (0.2031)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [ 60/172]  eta: 0:02:58  lr: 0.000099  loss: 0.2044 (0.2043)  time: 1.5759  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:113]  [ 70/172]  eta: 0:02:42  lr: 0.000099  loss: 0.2035 (0.2041)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [ 80/172]  eta: 0:02:26  lr: 0.000099  loss: 0.1996 (0.2037)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [ 90/172]  eta: 0:02:10  lr: 0.000099  loss: 0.1947 (0.2033)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [100/172]  eta: 0:01:54  lr: 0.000099  loss: 0.2005 (0.2034)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [110/172]  eta: 0:01:38  lr: 0.000099  loss: 0.2063 (0.2037)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [120/172]  eta: 0:01:22  lr: 0.000099  loss: 0.2039 (0.2040)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [130/172]  eta: 0:01:06  lr: 0.000099  loss: 0.2022 (0.2038)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [140/172]  eta: 0:00:50  lr: 0.000099  loss: 0.1965 (0.2038)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [150/172]  eta: 0:00:34  lr: 0.000099  loss: 0.1992 (0.2037)  time: 1.5739  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [160/172]  eta: 0:00:18  lr: 0.000099  loss: 0.2012 (0.2036)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [170/172]  eta: 0:00:03  lr: 0.000099  loss: 0.2027 (0.2040)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113]  [171/172]  eta: 0:00:01  lr: 0.000099  loss: 0.2020 (0.2040)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:113] Total time: 0:04:32 (1.5819 s / it)\n",
      "Averaged stats: lr: 0.000099  loss: 0.2020 (0.2040)\n",
      "Valid: [epoch:113]  [ 0/14]  eta: 0:00:03  loss: 0.1879 (0.1879)  time: 0.2811  data: 0.2665  max mem: 20571\n",
      "Valid: [epoch:113]  [13/14]  eta: 0:00:00  loss: 0.1879 (0.1931)  time: 0.0360  data: 0.0212  max mem: 20571\n",
      "Valid: [epoch:113] Total time: 0:00:00 (0.0409 s / it)\n",
      "Averaged stats: loss: 0.1879 (0.1931)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_113_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.193%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:114]  [  0/172]  eta: 0:07:48  lr: 0.000099  loss: 0.1944 (0.1944)  time: 2.7262  data: 1.1535  max mem: 20571\n",
      "Train: [epoch:114]  [ 10/172]  eta: 0:04:32  lr: 0.000099  loss: 0.2151 (0.2120)  time: 1.6796  data: 0.1050  max mem: 20571\n",
      "Train: [epoch:114]  [ 20/172]  eta: 0:04:07  lr: 0.000099  loss: 0.2119 (0.2085)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [ 30/172]  eta: 0:03:48  lr: 0.000099  loss: 0.2025 (0.2075)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [ 40/172]  eta: 0:03:31  lr: 0.000099  loss: 0.2009 (0.2074)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [ 50/172]  eta: 0:03:14  lr: 0.000099  loss: 0.2051 (0.2069)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [ 60/172]  eta: 0:02:58  lr: 0.000099  loss: 0.2051 (0.2064)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [ 70/172]  eta: 0:02:42  lr: 0.000099  loss: 0.2080 (0.2066)  time: 1.5733  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [ 80/172]  eta: 0:02:26  lr: 0.000099  loss: 0.2052 (0.2064)  time: 1.5732  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [ 90/172]  eta: 0:02:10  lr: 0.000099  loss: 0.2018 (0.2058)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [100/172]  eta: 0:01:54  lr: 0.000099  loss: 0.2032 (0.2059)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [110/172]  eta: 0:01:38  lr: 0.000099  loss: 0.2045 (0.2057)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [120/172]  eta: 0:01:22  lr: 0.000099  loss: 0.2031 (0.2057)  time: 1.5743  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [130/172]  eta: 0:01:06  lr: 0.000099  loss: 0.2004 (0.2058)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [140/172]  eta: 0:00:50  lr: 0.000099  loss: 0.2040 (0.2060)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [150/172]  eta: 0:00:34  lr: 0.000099  loss: 0.2058 (0.2059)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [160/172]  eta: 0:00:18  lr: 0.000099  loss: 0.2051 (0.2057)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [170/172]  eta: 0:00:03  lr: 0.000099  loss: 0.2045 (0.2060)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114]  [171/172]  eta: 0:00:01  lr: 0.000099  loss: 0.2045 (0.2059)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:114] Total time: 0:04:32 (1.5826 s / it)\n",
      "Averaged stats: lr: 0.000099  loss: 0.2045 (0.2059)\n",
      "Valid: [epoch:114]  [ 0/14]  eta: 0:00:04  loss: 0.1864 (0.1864)  time: 0.3496  data: 0.3326  max mem: 20571\n",
      "Valid: [epoch:114]  [13/14]  eta: 0:00:00  loss: 0.2052 (0.2090)  time: 0.0391  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:114] Total time: 0:00:00 (0.0448 s / it)\n",
      "Averaged stats: loss: 0.2052 (0.2090)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_114_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.209%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:115]  [  0/172]  eta: 0:07:28  lr: 0.000098  loss: 0.2126 (0.2126)  time: 2.6067  data: 1.0265  max mem: 20571\n",
      "Train: [epoch:115]  [ 10/172]  eta: 0:04:30  lr: 0.000098  loss: 0.2073 (0.2103)  time: 1.6682  data: 0.0934  max mem: 20571\n",
      "Train: [epoch:115]  [ 20/172]  eta: 0:04:06  lr: 0.000098  loss: 0.2092 (0.2095)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [ 30/172]  eta: 0:03:48  lr: 0.000098  loss: 0.2055 (0.2064)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [ 40/172]  eta: 0:03:31  lr: 0.000098  loss: 0.2053 (0.2079)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [ 50/172]  eta: 0:03:14  lr: 0.000098  loss: 0.2062 (0.2076)  time: 1.5790  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:115]  [ 60/172]  eta: 0:02:58  lr: 0.000098  loss: 0.2066 (0.2074)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [ 70/172]  eta: 0:02:42  lr: 0.000098  loss: 0.2090 (0.2076)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [ 80/172]  eta: 0:02:26  lr: 0.000098  loss: 0.2096 (0.2082)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [ 90/172]  eta: 0:02:10  lr: 0.000098  loss: 0.2068 (0.2082)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [100/172]  eta: 0:01:54  lr: 0.000098  loss: 0.2031 (0.2078)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [110/172]  eta: 0:01:38  lr: 0.000098  loss: 0.2052 (0.2080)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [120/172]  eta: 0:01:22  lr: 0.000098  loss: 0.2084 (0.2080)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [130/172]  eta: 0:01:06  lr: 0.000098  loss: 0.2045 (0.2079)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [140/172]  eta: 0:00:50  lr: 0.000098  loss: 0.2057 (0.2078)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [150/172]  eta: 0:00:34  lr: 0.000098  loss: 0.2057 (0.2077)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [160/172]  eta: 0:00:19  lr: 0.000098  loss: 0.2048 (0.2080)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [170/172]  eta: 0:00:03  lr: 0.000098  loss: 0.2082 (0.2078)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115]  [171/172]  eta: 0:00:01  lr: 0.000098  loss: 0.2064 (0.2078)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:115] Total time: 0:04:32 (1.5848 s / it)\n",
      "Averaged stats: lr: 0.000098  loss: 0.2064 (0.2078)\n",
      "Valid: [epoch:115]  [ 0/14]  eta: 0:00:04  loss: 0.1671 (0.1671)  time: 0.2920  data: 0.2759  max mem: 20571\n",
      "Valid: [epoch:115]  [13/14]  eta: 0:00:00  loss: 0.1866 (0.1921)  time: 0.0395  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:115] Total time: 0:00:00 (0.0467 s / it)\n",
      "Averaged stats: loss: 0.1866 (0.1921)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_115_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.192%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:116]  [  0/172]  eta: 0:07:39  lr: 0.000098  loss: 0.1794 (0.1794)  time: 2.6708  data: 1.1050  max mem: 20571\n",
      "Train: [epoch:116]  [ 10/172]  eta: 0:04:31  lr: 0.000098  loss: 0.2131 (0.2089)  time: 1.6756  data: 0.1006  max mem: 20571\n",
      "Train: [epoch:116]  [ 20/172]  eta: 0:04:07  lr: 0.000098  loss: 0.2107 (0.2090)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [ 30/172]  eta: 0:03:49  lr: 0.000098  loss: 0.2070 (0.2086)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [ 40/172]  eta: 0:03:31  lr: 0.000098  loss: 0.2093 (0.2090)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [ 50/172]  eta: 0:03:15  lr: 0.000098  loss: 0.2119 (0.2097)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [ 60/172]  eta: 0:02:58  lr: 0.000098  loss: 0.2047 (0.2082)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [ 70/172]  eta: 0:02:42  lr: 0.000098  loss: 0.2047 (0.2086)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [ 80/172]  eta: 0:02:26  lr: 0.000098  loss: 0.2101 (0.2086)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [ 90/172]  eta: 0:02:10  lr: 0.000098  loss: 0.2068 (0.2082)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [100/172]  eta: 0:01:54  lr: 0.000098  loss: 0.2068 (0.2085)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [110/172]  eta: 0:01:38  lr: 0.000098  loss: 0.2119 (0.2085)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [120/172]  eta: 0:01:22  lr: 0.000098  loss: 0.2074 (0.2082)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [130/172]  eta: 0:01:06  lr: 0.000098  loss: 0.2074 (0.2085)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [140/172]  eta: 0:00:50  lr: 0.000098  loss: 0.2042 (0.2083)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [150/172]  eta: 0:00:34  lr: 0.000098  loss: 0.2060 (0.2086)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [160/172]  eta: 0:00:19  lr: 0.000098  loss: 0.2060 (0.2084)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [170/172]  eta: 0:00:03  lr: 0.000098  loss: 0.2012 (0.2083)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116]  [171/172]  eta: 0:00:01  lr: 0.000098  loss: 0.2044 (0.2083)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:116] Total time: 0:04:32 (1.5850 s / it)\n",
      "Averaged stats: lr: 0.000098  loss: 0.2044 (0.2083)\n",
      "Valid: [epoch:116]  [ 0/14]  eta: 0:00:03  loss: 0.1798 (0.1798)  time: 0.2739  data: 0.2579  max mem: 20571\n",
      "Valid: [epoch:116]  [13/14]  eta: 0:00:00  loss: 0.1900 (0.1958)  time: 0.0379  data: 0.0229  max mem: 20571\n",
      "Valid: [epoch:116] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.1900 (0.1958)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_116_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.196%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:117]  [  0/172]  eta: 0:07:53  lr: 0.000098  loss: 0.2045 (0.2045)  time: 2.7513  data: 1.1531  max mem: 20571\n",
      "Train: [epoch:117]  [ 10/172]  eta: 0:04:32  lr: 0.000098  loss: 0.2125 (0.2103)  time: 1.6833  data: 0.1049  max mem: 20571\n",
      "Train: [epoch:117]  [ 20/172]  eta: 0:04:08  lr: 0.000098  loss: 0.2125 (0.2116)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [ 30/172]  eta: 0:03:49  lr: 0.000098  loss: 0.2095 (0.2111)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [ 40/172]  eta: 0:03:32  lr: 0.000098  loss: 0.2083 (0.2107)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [ 50/172]  eta: 0:03:15  lr: 0.000098  loss: 0.2057 (0.2103)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [ 60/172]  eta: 0:02:58  lr: 0.000098  loss: 0.2060 (0.2103)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [ 70/172]  eta: 0:02:42  lr: 0.000098  loss: 0.2094 (0.2105)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [ 80/172]  eta: 0:02:26  lr: 0.000098  loss: 0.2098 (0.2106)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [ 90/172]  eta: 0:02:10  lr: 0.000098  loss: 0.2162 (0.2114)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [100/172]  eta: 0:01:54  lr: 0.000098  loss: 0.2136 (0.2112)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [110/172]  eta: 0:01:38  lr: 0.000098  loss: 0.2076 (0.2111)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [120/172]  eta: 0:01:22  lr: 0.000098  loss: 0.2082 (0.2110)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [130/172]  eta: 0:01:06  lr: 0.000098  loss: 0.2082 (0.2107)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [140/172]  eta: 0:00:50  lr: 0.000098  loss: 0.2070 (0.2105)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [150/172]  eta: 0:00:34  lr: 0.000098  loss: 0.2075 (0.2105)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [160/172]  eta: 0:00:19  lr: 0.000098  loss: 0.2084 (0.2104)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [170/172]  eta: 0:00:03  lr: 0.000098  loss: 0.2084 (0.2104)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117]  [171/172]  eta: 0:00:01  lr: 0.000098  loss: 0.2087 (0.2106)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:117] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000098  loss: 0.2087 (0.2106)\n",
      "Valid: [epoch:117]  [ 0/14]  eta: 0:00:04  loss: 0.2111 (0.2111)  time: 0.2985  data: 0.2823  max mem: 20571\n",
      "Valid: [epoch:117]  [13/14]  eta: 0:00:00  loss: 0.1901 (0.1955)  time: 0.0465  data: 0.0314  max mem: 20571\n",
      "Valid: [epoch:117] Total time: 0:00:00 (0.0520 s / it)\n",
      "Averaged stats: loss: 0.1901 (0.1955)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_117_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.196%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:118]  [  0/172]  eta: 0:07:28  lr: 0.000098  loss: 0.1976 (0.1976)  time: 2.6090  data: 1.0467  max mem: 20571\n",
      "Train: [epoch:118]  [ 10/172]  eta: 0:04:30  lr: 0.000098  loss: 0.2209 (0.2122)  time: 1.6699  data: 0.0953  max mem: 20571\n",
      "Train: [epoch:118]  [ 20/172]  eta: 0:04:07  lr: 0.000098  loss: 0.2188 (0.2124)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [ 30/172]  eta: 0:03:48  lr: 0.000098  loss: 0.2117 (0.2126)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [ 40/172]  eta: 0:03:31  lr: 0.000098  loss: 0.2115 (0.2120)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [ 50/172]  eta: 0:03:14  lr: 0.000098  loss: 0.2076 (0.2117)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [ 60/172]  eta: 0:02:58  lr: 0.000098  loss: 0.2080 (0.2120)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [ 70/172]  eta: 0:02:42  lr: 0.000098  loss: 0.2131 (0.2131)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [ 80/172]  eta: 0:02:26  lr: 0.000098  loss: 0.2131 (0.2128)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [ 90/172]  eta: 0:02:10  lr: 0.000098  loss: 0.2112 (0.2131)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [100/172]  eta: 0:01:54  lr: 0.000098  loss: 0.2112 (0.2131)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [110/172]  eta: 0:01:38  lr: 0.000098  loss: 0.2110 (0.2133)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [120/172]  eta: 0:01:22  lr: 0.000098  loss: 0.2110 (0.2135)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [130/172]  eta: 0:01:06  lr: 0.000098  loss: 0.2156 (0.2138)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [140/172]  eta: 0:00:50  lr: 0.000098  loss: 0.2150 (0.2136)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [150/172]  eta: 0:00:34  lr: 0.000098  loss: 0.2116 (0.2135)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [160/172]  eta: 0:00:18  lr: 0.000098  loss: 0.2116 (0.2134)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [170/172]  eta: 0:00:03  lr: 0.000098  loss: 0.2091 (0.2133)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118]  [171/172]  eta: 0:00:01  lr: 0.000098  loss: 0.2091 (0.2133)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:118] Total time: 0:04:32 (1.5825 s / it)\n",
      "Averaged stats: lr: 0.000098  loss: 0.2091 (0.2133)\n",
      "Valid: [epoch:118]  [ 0/14]  eta: 0:00:03  loss: 0.2149 (0.2149)  time: 0.2764  data: 0.2605  max mem: 20571\n",
      "Valid: [epoch:118]  [13/14]  eta: 0:00:00  loss: 0.2027 (0.2079)  time: 0.0355  data: 0.0207  max mem: 20571\n",
      "Valid: [epoch:118] Total time: 0:00:00 (0.0406 s / it)\n",
      "Averaged stats: loss: 0.2027 (0.2079)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_118_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.208%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:119]  [  0/172]  eta: 0:07:48  lr: 0.000098  loss: 0.2542 (0.2542)  time: 2.7267  data: 1.1558  max mem: 20571\n",
      "Train: [epoch:119]  [ 10/172]  eta: 0:04:31  lr: 0.000098  loss: 0.2142 (0.2123)  time: 1.6770  data: 0.1052  max mem: 20571\n",
      "Train: [epoch:119]  [ 20/172]  eta: 0:04:07  lr: 0.000098  loss: 0.2101 (0.2137)  time: 1.5729  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [ 30/172]  eta: 0:03:48  lr: 0.000098  loss: 0.2083 (0.2121)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [ 40/172]  eta: 0:03:31  lr: 0.000098  loss: 0.2077 (0.2120)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [ 50/172]  eta: 0:03:14  lr: 0.000098  loss: 0.2113 (0.2125)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [ 60/172]  eta: 0:02:58  lr: 0.000098  loss: 0.2130 (0.2132)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [ 70/172]  eta: 0:02:42  lr: 0.000098  loss: 0.2108 (0.2131)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [ 80/172]  eta: 0:02:26  lr: 0.000098  loss: 0.2088 (0.2125)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [ 90/172]  eta: 0:02:10  lr: 0.000098  loss: 0.2064 (0.2126)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [100/172]  eta: 0:01:54  lr: 0.000098  loss: 0.2107 (0.2128)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [110/172]  eta: 0:01:38  lr: 0.000098  loss: 0.2186 (0.2133)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [120/172]  eta: 0:01:22  lr: 0.000098  loss: 0.2182 (0.2135)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [130/172]  eta: 0:01:06  lr: 0.000098  loss: 0.2116 (0.2131)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [140/172]  eta: 0:00:50  lr: 0.000098  loss: 0.2116 (0.2134)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [150/172]  eta: 0:00:34  lr: 0.000098  loss: 0.2123 (0.2134)  time: 1.5737  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [160/172]  eta: 0:00:18  lr: 0.000098  loss: 0.2111 (0.2131)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [170/172]  eta: 0:00:03  lr: 0.000098  loss: 0.2125 (0.2133)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119]  [171/172]  eta: 0:00:01  lr: 0.000098  loss: 0.2125 (0.2133)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:119] Total time: 0:04:32 (1.5821 s / it)\n",
      "Averaged stats: lr: 0.000098  loss: 0.2125 (0.2133)\n",
      "Valid: [epoch:119]  [ 0/14]  eta: 0:00:03  loss: 0.2156 (0.2156)  time: 0.2802  data: 0.2654  max mem: 20571\n",
      "Valid: [epoch:119]  [13/14]  eta: 0:00:00  loss: 0.1935 (0.1989)  time: 0.0368  data: 0.0218  max mem: 20571\n",
      "Valid: [epoch:119] Total time: 0:00:00 (0.0445 s / it)\n",
      "Averaged stats: loss: 0.1935 (0.1989)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_119_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.199%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:120]  [  0/172]  eta: 0:07:20  lr: 0.000098  loss: 0.2221 (0.2221)  time: 2.5636  data: 1.0022  max mem: 20571\n",
      "Train: [epoch:120]  [ 10/172]  eta: 0:04:29  lr: 0.000098  loss: 0.2141 (0.2160)  time: 1.6628  data: 0.0912  max mem: 20571\n",
      "Train: [epoch:120]  [ 20/172]  eta: 0:04:06  lr: 0.000098  loss: 0.2187 (0.2170)  time: 1.5735  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [ 30/172]  eta: 0:03:47  lr: 0.000098  loss: 0.2148 (0.2154)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [ 40/172]  eta: 0:03:30  lr: 0.000098  loss: 0.2127 (0.2156)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [ 50/172]  eta: 0:03:14  lr: 0.000098  loss: 0.2160 (0.2163)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [ 60/172]  eta: 0:02:58  lr: 0.000098  loss: 0.2164 (0.2163)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [ 70/172]  eta: 0:02:41  lr: 0.000098  loss: 0.2161 (0.2165)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [ 80/172]  eta: 0:02:25  lr: 0.000098  loss: 0.2104 (0.2156)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [ 90/172]  eta: 0:02:10  lr: 0.000098  loss: 0.2104 (0.2158)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [100/172]  eta: 0:01:54  lr: 0.000098  loss: 0.2143 (0.2162)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [110/172]  eta: 0:01:38  lr: 0.000098  loss: 0.2143 (0.2163)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [120/172]  eta: 0:01:22  lr: 0.000098  loss: 0.2135 (0.2162)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [130/172]  eta: 0:01:06  lr: 0.000098  loss: 0.2114 (0.2160)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [140/172]  eta: 0:00:50  lr: 0.000098  loss: 0.2097 (0.2158)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [150/172]  eta: 0:00:34  lr: 0.000098  loss: 0.2109 (0.2160)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [160/172]  eta: 0:00:18  lr: 0.000098  loss: 0.2169 (0.2158)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120]  [170/172]  eta: 0:00:03  lr: 0.000098  loss: 0.2125 (0.2157)  time: 1.5804  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:120]  [171/172]  eta: 0:00:01  lr: 0.000098  loss: 0.2155 (0.2157)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:120] Total time: 0:04:32 (1.5828 s / it)\n",
      "Averaged stats: lr: 0.000098  loss: 0.2155 (0.2157)\n",
      "Valid: [epoch:120]  [ 0/14]  eta: 0:00:03  loss: 0.2129 (0.2129)  time: 0.2780  data: 0.2635  max mem: 20571\n",
      "Valid: [epoch:120]  [13/14]  eta: 0:00:00  loss: 0.1920 (0.1983)  time: 0.0478  data: 0.0329  max mem: 20571\n",
      "Valid: [epoch:120] Total time: 0:00:00 (0.0528 s / it)\n",
      "Averaged stats: loss: 0.1920 (0.1983)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_120_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.198%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:121]  [  0/172]  eta: 0:07:38  lr: 0.000098  loss: 0.2107 (0.2107)  time: 2.6642  data: 1.0924  max mem: 20571\n",
      "Train: [epoch:121]  [ 10/172]  eta: 0:04:31  lr: 0.000098  loss: 0.2107 (0.2165)  time: 1.6746  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:121]  [ 20/172]  eta: 0:04:07  lr: 0.000098  loss: 0.2154 (0.2181)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [ 30/172]  eta: 0:03:48  lr: 0.000098  loss: 0.2200 (0.2170)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [ 40/172]  eta: 0:03:31  lr: 0.000098  loss: 0.2162 (0.2175)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [ 50/172]  eta: 0:03:15  lr: 0.000098  loss: 0.2209 (0.2191)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [ 60/172]  eta: 0:02:58  lr: 0.000098  loss: 0.2209 (0.2192)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [ 70/172]  eta: 0:02:42  lr: 0.000098  loss: 0.2132 (0.2189)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [ 80/172]  eta: 0:02:26  lr: 0.000098  loss: 0.2110 (0.2181)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [ 90/172]  eta: 0:02:10  lr: 0.000098  loss: 0.2166 (0.2185)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [100/172]  eta: 0:01:54  lr: 0.000098  loss: 0.2189 (0.2183)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [110/172]  eta: 0:01:38  lr: 0.000098  loss: 0.2149 (0.2181)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [120/172]  eta: 0:01:22  lr: 0.000098  loss: 0.2126 (0.2176)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [130/172]  eta: 0:01:06  lr: 0.000098  loss: 0.2129 (0.2175)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:121]  [140/172]  eta: 0:00:50  lr: 0.000098  loss: 0.2170 (0.2174)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:121]  [150/172]  eta: 0:00:34  lr: 0.000098  loss: 0.2170 (0.2174)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [160/172]  eta: 0:00:19  lr: 0.000098  loss: 0.2124 (0.2173)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [170/172]  eta: 0:00:03  lr: 0.000098  loss: 0.2124 (0.2172)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121]  [171/172]  eta: 0:00:01  lr: 0.000098  loss: 0.2136 (0.2172)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:121] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000098  loss: 0.2136 (0.2172)\n",
      "Valid: [epoch:121]  [ 0/14]  eta: 0:00:04  loss: 0.2217 (0.2217)  time: 0.2967  data: 0.2820  max mem: 20571\n",
      "Valid: [epoch:121]  [13/14]  eta: 0:00:00  loss: 0.2006 (0.2061)  time: 0.0370  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:121] Total time: 0:00:00 (0.0416 s / it)\n",
      "Averaged stats: loss: 0.2006 (0.2061)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_121_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.206%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:122]  [  0/172]  eta: 0:07:42  lr: 0.000098  loss: 0.2206 (0.2206)  time: 2.6867  data: 1.1211  max mem: 20571\n",
      "Train: [epoch:122]  [ 10/172]  eta: 0:04:32  lr: 0.000098  loss: 0.2206 (0.2196)  time: 1.6793  data: 0.1021  max mem: 20571\n",
      "Train: [epoch:122]  [ 20/172]  eta: 0:04:07  lr: 0.000098  loss: 0.2141 (0.2184)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [ 30/172]  eta: 0:03:49  lr: 0.000098  loss: 0.2208 (0.2185)  time: 1.5783  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:122]  [ 40/172]  eta: 0:03:31  lr: 0.000098  loss: 0.2208 (0.2176)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:122]  [ 50/172]  eta: 0:03:15  lr: 0.000098  loss: 0.2171 (0.2183)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [ 60/172]  eta: 0:02:58  lr: 0.000098  loss: 0.2228 (0.2192)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [ 70/172]  eta: 0:02:42  lr: 0.000098  loss: 0.2220 (0.2192)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [ 80/172]  eta: 0:02:26  lr: 0.000098  loss: 0.2175 (0.2194)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [ 90/172]  eta: 0:02:10  lr: 0.000098  loss: 0.2178 (0.2194)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [100/172]  eta: 0:01:54  lr: 0.000098  loss: 0.2178 (0.2198)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [110/172]  eta: 0:01:38  lr: 0.000098  loss: 0.2208 (0.2196)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [120/172]  eta: 0:01:22  lr: 0.000098  loss: 0.2163 (0.2195)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [130/172]  eta: 0:01:06  lr: 0.000098  loss: 0.2114 (0.2193)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [140/172]  eta: 0:00:50  lr: 0.000098  loss: 0.2158 (0.2194)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [150/172]  eta: 0:00:34  lr: 0.000098  loss: 0.2191 (0.2193)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [160/172]  eta: 0:00:19  lr: 0.000098  loss: 0.2173 (0.2190)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [170/172]  eta: 0:00:03  lr: 0.000098  loss: 0.2186 (0.2190)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122]  [171/172]  eta: 0:00:01  lr: 0.000098  loss: 0.2153 (0.2189)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:122] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000098  loss: 0.2153 (0.2189)\n",
      "Valid: [epoch:122]  [ 0/14]  eta: 0:00:06  loss: 0.1912 (0.1912)  time: 0.4542  data: 0.4355  max mem: 20571\n",
      "Valid: [epoch:122]  [13/14]  eta: 0:00:00  loss: 0.1912 (0.1970)  time: 0.0468  data: 0.0316  max mem: 20571\n",
      "Valid: [epoch:122] Total time: 0:00:00 (0.0523 s / it)\n",
      "Averaged stats: loss: 0.1912 (0.1970)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_122_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.197%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:123]  [  0/172]  eta: 0:07:32  lr: 0.000098  loss: 0.2053 (0.2053)  time: 2.6336  data: 1.0600  max mem: 20571\n",
      "Train: [epoch:123]  [ 10/172]  eta: 0:04:30  lr: 0.000098  loss: 0.2125 (0.2159)  time: 1.6700  data: 0.0965  max mem: 20571\n",
      "Train: [epoch:123]  [ 20/172]  eta: 0:04:06  lr: 0.000098  loss: 0.2164 (0.2190)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [ 30/172]  eta: 0:03:48  lr: 0.000098  loss: 0.2176 (0.2189)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [ 40/172]  eta: 0:03:31  lr: 0.000098  loss: 0.2172 (0.2192)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [ 50/172]  eta: 0:03:14  lr: 0.000098  loss: 0.2181 (0.2200)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [ 60/172]  eta: 0:02:58  lr: 0.000098  loss: 0.2169 (0.2200)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [ 70/172]  eta: 0:02:42  lr: 0.000098  loss: 0.2169 (0.2202)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [ 80/172]  eta: 0:02:26  lr: 0.000098  loss: 0.2166 (0.2201)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [ 90/172]  eta: 0:02:10  lr: 0.000098  loss: 0.2199 (0.2203)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [100/172]  eta: 0:01:54  lr: 0.000098  loss: 0.2180 (0.2207)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [110/172]  eta: 0:01:38  lr: 0.000098  loss: 0.2165 (0.2206)  time: 1.5766  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:123]  [120/172]  eta: 0:01:22  lr: 0.000098  loss: 0.2206 (0.2210)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [130/172]  eta: 0:01:06  lr: 0.000098  loss: 0.2185 (0.2206)  time: 1.5758  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:123]  [140/172]  eta: 0:00:50  lr: 0.000098  loss: 0.2185 (0.2206)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:123]  [150/172]  eta: 0:00:34  lr: 0.000098  loss: 0.2189 (0.2205)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:123]  [160/172]  eta: 0:00:18  lr: 0.000098  loss: 0.2188 (0.2203)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [170/172]  eta: 0:00:03  lr: 0.000098  loss: 0.2192 (0.2203)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123]  [171/172]  eta: 0:00:01  lr: 0.000098  loss: 0.2192 (0.2203)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:123] Total time: 0:04:32 (1.5833 s / it)\n",
      "Averaged stats: lr: 0.000098  loss: 0.2192 (0.2203)\n",
      "Valid: [epoch:123]  [ 0/14]  eta: 0:00:05  loss: 0.2030 (0.2030)  time: 0.3744  data: 0.3560  max mem: 20571\n",
      "Valid: [epoch:123]  [13/14]  eta: 0:00:00  loss: 0.2036 (0.2096)  time: 0.0410  data: 0.0256  max mem: 20571\n",
      "Valid: [epoch:123] Total time: 0:00:00 (0.0466 s / it)\n",
      "Averaged stats: loss: 0.2036 (0.2096)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_123_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.210%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:124]  [  0/172]  eta: 0:08:27  lr: 0.000097  loss: 0.2221 (0.2221)  time: 2.9485  data: 1.3857  max mem: 20571\n",
      "Train: [epoch:124]  [ 10/172]  eta: 0:04:35  lr: 0.000097  loss: 0.2189 (0.2198)  time: 1.6981  data: 0.1261  max mem: 20571\n",
      "Train: [epoch:124]  [ 20/172]  eta: 0:04:09  lr: 0.000097  loss: 0.2195 (0.2248)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [ 30/172]  eta: 0:03:50  lr: 0.000097  loss: 0.2209 (0.2245)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [ 40/172]  eta: 0:03:32  lr: 0.000097  loss: 0.2217 (0.2249)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [ 50/172]  eta: 0:03:15  lr: 0.000097  loss: 0.2282 (0.2253)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [ 60/172]  eta: 0:02:59  lr: 0.000097  loss: 0.2249 (0.2249)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [ 70/172]  eta: 0:02:42  lr: 0.000097  loss: 0.2218 (0.2245)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [ 80/172]  eta: 0:02:26  lr: 0.000097  loss: 0.2218 (0.2243)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [ 90/172]  eta: 0:02:10  lr: 0.000097  loss: 0.2188 (0.2239)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [100/172]  eta: 0:01:54  lr: 0.000097  loss: 0.2223 (0.2238)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [110/172]  eta: 0:01:38  lr: 0.000097  loss: 0.2225 (0.2238)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [120/172]  eta: 0:01:22  lr: 0.000097  loss: 0.2242 (0.2239)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [130/172]  eta: 0:01:06  lr: 0.000097  loss: 0.2208 (0.2237)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [140/172]  eta: 0:00:50  lr: 0.000097  loss: 0.2216 (0.2235)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [150/172]  eta: 0:00:34  lr: 0.000097  loss: 0.2232 (0.2235)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [160/172]  eta: 0:00:19  lr: 0.000097  loss: 0.2195 (0.2235)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [170/172]  eta: 0:00:03  lr: 0.000097  loss: 0.2147 (0.2231)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124]  [171/172]  eta: 0:00:01  lr: 0.000097  loss: 0.2195 (0.2232)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:124] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000097  loss: 0.2195 (0.2232)\n",
      "Valid: [epoch:124]  [ 0/14]  eta: 0:00:06  loss: 0.2107 (0.2107)  time: 0.4381  data: 0.4190  max mem: 20571\n",
      "Valid: [epoch:124]  [13/14]  eta: 0:00:00  loss: 0.2107 (0.2165)  time: 0.0455  data: 0.0301  max mem: 20571\n",
      "Valid: [epoch:124] Total time: 0:00:00 (0.0501 s / it)\n",
      "Averaged stats: loss: 0.2107 (0.2165)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_124_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.216%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:125]  [  0/172]  eta: 0:07:35  lr: 0.000097  loss: 0.2151 (0.2151)  time: 2.6510  data: 1.0746  max mem: 20571\n",
      "Train: [epoch:125]  [ 10/172]  eta: 0:04:30  lr: 0.000097  loss: 0.2288 (0.2272)  time: 1.6724  data: 0.0978  max mem: 20571\n",
      "Train: [epoch:125]  [ 20/172]  eta: 0:04:07  lr: 0.000097  loss: 0.2296 (0.2297)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [ 30/172]  eta: 0:03:48  lr: 0.000097  loss: 0.2250 (0.2274)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [ 40/172]  eta: 0:03:31  lr: 0.000097  loss: 0.2226 (0.2261)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [ 50/172]  eta: 0:03:15  lr: 0.000097  loss: 0.2305 (0.2274)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [ 60/172]  eta: 0:02:58  lr: 0.000097  loss: 0.2292 (0.2265)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [ 70/172]  eta: 0:02:42  lr: 0.000097  loss: 0.2212 (0.2258)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [ 80/172]  eta: 0:02:26  lr: 0.000097  loss: 0.2216 (0.2257)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [ 90/172]  eta: 0:02:10  lr: 0.000097  loss: 0.2233 (0.2257)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [100/172]  eta: 0:01:54  lr: 0.000097  loss: 0.2217 (0.2251)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [110/172]  eta: 0:01:38  lr: 0.000097  loss: 0.2217 (0.2249)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [120/172]  eta: 0:01:22  lr: 0.000097  loss: 0.2278 (0.2248)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [130/172]  eta: 0:01:06  lr: 0.000097  loss: 0.2215 (0.2245)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [140/172]  eta: 0:00:50  lr: 0.000097  loss: 0.2214 (0.2244)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [150/172]  eta: 0:00:34  lr: 0.000097  loss: 0.2225 (0.2242)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [160/172]  eta: 0:00:19  lr: 0.000097  loss: 0.2225 (0.2240)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [170/172]  eta: 0:00:03  lr: 0.000097  loss: 0.2206 (0.2238)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125]  [171/172]  eta: 0:00:01  lr: 0.000097  loss: 0.2211 (0.2239)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:125] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000097  loss: 0.2211 (0.2239)\n",
      "Valid: [epoch:125]  [ 0/14]  eta: 0:00:04  loss: 0.2312 (0.2312)  time: 0.3032  data: 0.2883  max mem: 20571\n",
      "Valid: [epoch:125]  [13/14]  eta: 0:00:00  loss: 0.2140 (0.2192)  time: 0.0466  data: 0.0317  max mem: 20571\n",
      "Valid: [epoch:125] Total time: 0:00:00 (0.0552 s / it)\n",
      "Averaged stats: loss: 0.2140 (0.2192)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_125_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.219%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:126]  [  0/172]  eta: 0:08:27  lr: 0.000097  loss: 0.2381 (0.2381)  time: 2.9479  data: 1.3826  max mem: 20571\n",
      "Train: [epoch:126]  [ 10/172]  eta: 0:04:35  lr: 0.000097  loss: 0.2149 (0.2222)  time: 1.7029  data: 0.1258  max mem: 20571\n",
      "Train: [epoch:126]  [ 20/172]  eta: 0:04:09  lr: 0.000097  loss: 0.2182 (0.2245)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [ 30/172]  eta: 0:03:50  lr: 0.000097  loss: 0.2252 (0.2253)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [ 40/172]  eta: 0:03:32  lr: 0.000097  loss: 0.2271 (0.2259)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [ 50/172]  eta: 0:03:15  lr: 0.000097  loss: 0.2293 (0.2259)  time: 1.5795  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:126]  [ 60/172]  eta: 0:02:59  lr: 0.000097  loss: 0.2221 (0.2253)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [ 70/172]  eta: 0:02:42  lr: 0.000097  loss: 0.2221 (0.2252)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [ 80/172]  eta: 0:02:26  lr: 0.000097  loss: 0.2236 (0.2255)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [ 90/172]  eta: 0:02:10  lr: 0.000097  loss: 0.2228 (0.2252)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [100/172]  eta: 0:01:54  lr: 0.000097  loss: 0.2234 (0.2256)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [110/172]  eta: 0:01:38  lr: 0.000097  loss: 0.2310 (0.2257)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [120/172]  eta: 0:01:22  lr: 0.000097  loss: 0.2251 (0.2255)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [130/172]  eta: 0:01:06  lr: 0.000097  loss: 0.2229 (0.2257)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [140/172]  eta: 0:00:50  lr: 0.000097  loss: 0.2229 (0.2257)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [150/172]  eta: 0:00:34  lr: 0.000097  loss: 0.2217 (0.2256)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [160/172]  eta: 0:00:19  lr: 0.000097  loss: 0.2234 (0.2255)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [170/172]  eta: 0:00:03  lr: 0.000097  loss: 0.2209 (0.2253)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126]  [171/172]  eta: 0:00:01  lr: 0.000097  loss: 0.2209 (0.2253)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:126] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000097  loss: 0.2209 (0.2253)\n",
      "Valid: [epoch:126]  [ 0/14]  eta: 0:00:04  loss: 0.2003 (0.2003)  time: 0.3432  data: 0.3218  max mem: 20571\n",
      "Valid: [epoch:126]  [13/14]  eta: 0:00:00  loss: 0.2154 (0.2208)  time: 0.0393  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:126] Total time: 0:00:00 (0.0470 s / it)\n",
      "Averaged stats: loss: 0.2154 (0.2208)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_126_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.221%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:127]  [  0/172]  eta: 0:07:41  lr: 0.000097  loss: 0.2432 (0.2432)  time: 2.6806  data: 1.1054  max mem: 20571\n",
      "Train: [epoch:127]  [ 10/172]  eta: 0:04:31  lr: 0.000097  loss: 0.2302 (0.2257)  time: 1.6738  data: 0.1006  max mem: 20571\n",
      "Train: [epoch:127]  [ 20/172]  eta: 0:04:07  lr: 0.000097  loss: 0.2276 (0.2291)  time: 1.5737  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [ 30/172]  eta: 0:03:48  lr: 0.000097  loss: 0.2276 (0.2281)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [ 40/172]  eta: 0:03:31  lr: 0.000097  loss: 0.2252 (0.2281)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [ 50/172]  eta: 0:03:14  lr: 0.000097  loss: 0.2247 (0.2280)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:127]  [ 60/172]  eta: 0:02:58  lr: 0.000097  loss: 0.2252 (0.2287)  time: 1.5769  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:127]  [ 70/172]  eta: 0:02:42  lr: 0.000097  loss: 0.2279 (0.2288)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [ 80/172]  eta: 0:02:26  lr: 0.000097  loss: 0.2253 (0.2281)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [ 90/172]  eta: 0:02:10  lr: 0.000097  loss: 0.2253 (0.2282)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [100/172]  eta: 0:01:54  lr: 0.000097  loss: 0.2268 (0.2282)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [110/172]  eta: 0:01:38  lr: 0.000097  loss: 0.2273 (0.2280)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [120/172]  eta: 0:01:22  lr: 0.000097  loss: 0.2211 (0.2275)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [130/172]  eta: 0:01:06  lr: 0.000097  loss: 0.2230 (0.2273)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [140/172]  eta: 0:00:50  lr: 0.000097  loss: 0.2266 (0.2271)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [150/172]  eta: 0:00:34  lr: 0.000097  loss: 0.2293 (0.2271)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [160/172]  eta: 0:00:19  lr: 0.000097  loss: 0.2293 (0.2271)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [170/172]  eta: 0:00:03  lr: 0.000097  loss: 0.2238 (0.2271)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127]  [171/172]  eta: 0:00:01  lr: 0.000097  loss: 0.2197 (0.2270)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:127] Total time: 0:04:32 (1.5841 s / it)\n",
      "Averaged stats: lr: 0.000097  loss: 0.2197 (0.2270)\n",
      "Valid: [epoch:127]  [ 0/14]  eta: 0:00:04  loss: 0.1872 (0.1872)  time: 0.3352  data: 0.3186  max mem: 20571\n",
      "Valid: [epoch:127]  [13/14]  eta: 0:00:00  loss: 0.2086 (0.2142)  time: 0.0396  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:127] Total time: 0:00:00 (0.0475 s / it)\n",
      "Averaged stats: loss: 0.2086 (0.2142)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_127_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.214%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:128]  [  0/172]  eta: 0:07:51  lr: 0.000097  loss: 0.2318 (0.2318)  time: 2.7398  data: 1.1750  max mem: 20571\n",
      "Train: [epoch:128]  [ 10/172]  eta: 0:04:32  lr: 0.000097  loss: 0.2298 (0.2324)  time: 1.6812  data: 0.1069  max mem: 20571\n",
      "Train: [epoch:128]  [ 20/172]  eta: 0:04:07  lr: 0.000097  loss: 0.2293 (0.2312)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [ 30/172]  eta: 0:03:49  lr: 0.000097  loss: 0.2241 (0.2297)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [ 40/172]  eta: 0:03:31  lr: 0.000097  loss: 0.2238 (0.2293)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [ 50/172]  eta: 0:03:15  lr: 0.000097  loss: 0.2305 (0.2302)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [ 60/172]  eta: 0:02:58  lr: 0.000097  loss: 0.2263 (0.2294)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [ 70/172]  eta: 0:02:42  lr: 0.000097  loss: 0.2297 (0.2300)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [ 80/172]  eta: 0:02:26  lr: 0.000097  loss: 0.2347 (0.2296)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [ 90/172]  eta: 0:02:10  lr: 0.000097  loss: 0.2291 (0.2295)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [100/172]  eta: 0:01:54  lr: 0.000097  loss: 0.2244 (0.2292)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [110/172]  eta: 0:01:38  lr: 0.000097  loss: 0.2282 (0.2296)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [120/172]  eta: 0:01:22  lr: 0.000097  loss: 0.2326 (0.2296)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [130/172]  eta: 0:01:06  lr: 0.000097  loss: 0.2326 (0.2295)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [140/172]  eta: 0:00:50  lr: 0.000097  loss: 0.2261 (0.2294)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [150/172]  eta: 0:00:34  lr: 0.000097  loss: 0.2269 (0.2294)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [160/172]  eta: 0:00:19  lr: 0.000097  loss: 0.2264 (0.2292)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [170/172]  eta: 0:00:03  lr: 0.000097  loss: 0.2288 (0.2294)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128]  [171/172]  eta: 0:00:01  lr: 0.000097  loss: 0.2304 (0.2295)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:128] Total time: 0:04:32 (1.5842 s / it)\n",
      "Averaged stats: lr: 0.000097  loss: 0.2304 (0.2295)\n",
      "Valid: [epoch:128]  [ 0/14]  eta: 0:00:04  loss: 0.2373 (0.2373)  time: 0.3301  data: 0.3086  max mem: 20571\n",
      "Valid: [epoch:128]  [13/14]  eta: 0:00:00  loss: 0.2126 (0.2192)  time: 0.0380  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:128] Total time: 0:00:00 (0.0428 s / it)\n",
      "Averaged stats: loss: 0.2126 (0.2192)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_128_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.219%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:129]  [  0/172]  eta: 0:07:25  lr: 0.000097  loss: 0.2318 (0.2318)  time: 2.5896  data: 0.9977  max mem: 20571\n",
      "Train: [epoch:129]  [ 10/172]  eta: 0:04:30  lr: 0.000097  loss: 0.2267 (0.2284)  time: 1.6687  data: 0.0908  max mem: 20571\n",
      "Train: [epoch:129]  [ 20/172]  eta: 0:04:06  lr: 0.000097  loss: 0.2267 (0.2311)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [ 30/172]  eta: 0:03:48  lr: 0.000097  loss: 0.2311 (0.2317)  time: 1.5736  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [ 40/172]  eta: 0:03:31  lr: 0.000097  loss: 0.2373 (0.2319)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [ 50/172]  eta: 0:03:14  lr: 0.000097  loss: 0.2312 (0.2318)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [ 60/172]  eta: 0:02:58  lr: 0.000097  loss: 0.2302 (0.2318)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [ 70/172]  eta: 0:02:42  lr: 0.000097  loss: 0.2318 (0.2325)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [ 80/172]  eta: 0:02:26  lr: 0.000097  loss: 0.2302 (0.2322)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [ 90/172]  eta: 0:02:10  lr: 0.000097  loss: 0.2234 (0.2314)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [100/172]  eta: 0:01:54  lr: 0.000097  loss: 0.2234 (0.2308)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [110/172]  eta: 0:01:38  lr: 0.000097  loss: 0.2229 (0.2307)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [120/172]  eta: 0:01:22  lr: 0.000097  loss: 0.2280 (0.2307)  time: 1.5743  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [130/172]  eta: 0:01:06  lr: 0.000097  loss: 0.2277 (0.2307)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [140/172]  eta: 0:00:50  lr: 0.000097  loss: 0.2203 (0.2303)  time: 1.5738  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [150/172]  eta: 0:00:34  lr: 0.000097  loss: 0.2284 (0.2303)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [160/172]  eta: 0:00:18  lr: 0.000097  loss: 0.2321 (0.2305)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [170/172]  eta: 0:00:03  lr: 0.000097  loss: 0.2319 (0.2307)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129]  [171/172]  eta: 0:00:01  lr: 0.000097  loss: 0.2306 (0.2306)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:129] Total time: 0:04:32 (1.5817 s / it)\n",
      "Averaged stats: lr: 0.000097  loss: 0.2306 (0.2306)\n",
      "Valid: [epoch:129]  [ 0/14]  eta: 0:00:05  loss: 0.1977 (0.1977)  time: 0.4060  data: 0.3880  max mem: 20571\n",
      "Valid: [epoch:129]  [13/14]  eta: 0:00:00  loss: 0.2158 (0.2223)  time: 0.0435  data: 0.0283  max mem: 20571\n",
      "Valid: [epoch:129] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 0.2158 (0.2223)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_129_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.222%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:130]  [  0/172]  eta: 0:08:00  lr: 0.000097  loss: 0.2462 (0.2462)  time: 2.7942  data: 1.2316  max mem: 20571\n",
      "Train: [epoch:130]  [ 10/172]  eta: 0:04:33  lr: 0.000097  loss: 0.2299 (0.2302)  time: 1.6855  data: 0.1121  max mem: 20571\n",
      "Train: [epoch:130]  [ 20/172]  eta: 0:04:08  lr: 0.000097  loss: 0.2299 (0.2325)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [ 30/172]  eta: 0:03:49  lr: 0.000097  loss: 0.2333 (0.2333)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [ 40/172]  eta: 0:03:32  lr: 0.000097  loss: 0.2329 (0.2327)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [ 50/172]  eta: 0:03:15  lr: 0.000097  loss: 0.2329 (0.2334)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [ 60/172]  eta: 0:02:59  lr: 0.000097  loss: 0.2283 (0.2322)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [ 70/172]  eta: 0:02:42  lr: 0.000097  loss: 0.2263 (0.2323)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [ 80/172]  eta: 0:02:26  lr: 0.000097  loss: 0.2319 (0.2330)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [ 90/172]  eta: 0:02:10  lr: 0.000097  loss: 0.2319 (0.2329)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [100/172]  eta: 0:01:54  lr: 0.000097  loss: 0.2286 (0.2328)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [110/172]  eta: 0:01:38  lr: 0.000097  loss: 0.2349 (0.2327)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [120/172]  eta: 0:01:22  lr: 0.000097  loss: 0.2307 (0.2325)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [130/172]  eta: 0:01:06  lr: 0.000097  loss: 0.2277 (0.2325)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [140/172]  eta: 0:00:50  lr: 0.000097  loss: 0.2280 (0.2324)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [150/172]  eta: 0:00:34  lr: 0.000097  loss: 0.2324 (0.2323)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [160/172]  eta: 0:00:19  lr: 0.000097  loss: 0.2302 (0.2324)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [170/172]  eta: 0:00:03  lr: 0.000097  loss: 0.2302 (0.2326)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130]  [171/172]  eta: 0:00:01  lr: 0.000097  loss: 0.2302 (0.2326)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:130] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000097  loss: 0.2302 (0.2326)\n",
      "Valid: [epoch:130]  [ 0/14]  eta: 0:00:03  loss: 0.1987 (0.1987)  time: 0.2777  data: 0.2621  max mem: 20571\n",
      "Valid: [epoch:130]  [13/14]  eta: 0:00:00  loss: 0.2142 (0.2207)  time: 0.0440  data: 0.0290  max mem: 20571\n",
      "Valid: [epoch:130] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.2142 (0.2207)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_130_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.221%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:131]  [  0/172]  eta: 0:07:55  lr: 0.000097  loss: 0.2366 (0.2366)  time: 2.7651  data: 1.1892  max mem: 20571\n",
      "Train: [epoch:131]  [ 10/172]  eta: 0:04:33  lr: 0.000097  loss: 0.2391 (0.2362)  time: 1.6876  data: 0.1082  max mem: 20571\n",
      "Train: [epoch:131]  [ 20/172]  eta: 0:04:08  lr: 0.000097  loss: 0.2268 (0.2366)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [ 30/172]  eta: 0:03:49  lr: 0.000097  loss: 0.2268 (0.2364)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [ 40/172]  eta: 0:03:32  lr: 0.000097  loss: 0.2301 (0.2339)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [ 50/172]  eta: 0:03:15  lr: 0.000097  loss: 0.2304 (0.2344)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [ 60/172]  eta: 0:02:59  lr: 0.000097  loss: 0.2343 (0.2343)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [ 70/172]  eta: 0:02:43  lr: 0.000097  loss: 0.2322 (0.2349)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [ 80/172]  eta: 0:02:26  lr: 0.000097  loss: 0.2319 (0.2342)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [ 90/172]  eta: 0:02:10  lr: 0.000097  loss: 0.2269 (0.2342)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [100/172]  eta: 0:01:54  lr: 0.000097  loss: 0.2335 (0.2343)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [110/172]  eta: 0:01:38  lr: 0.000097  loss: 0.2384 (0.2346)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [120/172]  eta: 0:01:22  lr: 0.000097  loss: 0.2384 (0.2345)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [130/172]  eta: 0:01:06  lr: 0.000097  loss: 0.2331 (0.2344)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [140/172]  eta: 0:00:50  lr: 0.000097  loss: 0.2259 (0.2341)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [150/172]  eta: 0:00:34  lr: 0.000097  loss: 0.2263 (0.2340)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [160/172]  eta: 0:00:19  lr: 0.000097  loss: 0.2326 (0.2340)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131]  [170/172]  eta: 0:00:03  lr: 0.000097  loss: 0.2370 (0.2342)  time: 1.5833  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:131]  [171/172]  eta: 0:00:01  lr: 0.000097  loss: 0.2329 (0.2342)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:131] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000097  loss: 0.2329 (0.2342)\n",
      "Valid: [epoch:131]  [ 0/14]  eta: 0:00:04  loss: 0.2378 (0.2378)  time: 0.2863  data: 0.2706  max mem: 20571\n",
      "Valid: [epoch:131]  [13/14]  eta: 0:00:00  loss: 0.2141 (0.2210)  time: 0.0419  data: 0.0270  max mem: 20571\n",
      "Valid: [epoch:131] Total time: 0:00:00 (0.0497 s / it)\n",
      "Averaged stats: loss: 0.2141 (0.2210)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_131_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.221%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:132]  [  0/172]  eta: 0:08:14  lr: 0.000097  loss: 0.2248 (0.2248)  time: 2.8751  data: 1.3043  max mem: 20571\n",
      "Train: [epoch:132]  [ 10/172]  eta: 0:04:35  lr: 0.000097  loss: 0.2373 (0.2369)  time: 1.6986  data: 0.1187  max mem: 20571\n",
      "Train: [epoch:132]  [ 20/172]  eta: 0:04:09  lr: 0.000097  loss: 0.2406 (0.2384)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [ 30/172]  eta: 0:03:50  lr: 0.000097  loss: 0.2365 (0.2361)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [ 40/172]  eta: 0:03:33  lr: 0.000097  loss: 0.2324 (0.2361)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [ 50/172]  eta: 0:03:16  lr: 0.000097  loss: 0.2325 (0.2349)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [ 60/172]  eta: 0:02:59  lr: 0.000097  loss: 0.2325 (0.2350)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [ 70/172]  eta: 0:02:43  lr: 0.000097  loss: 0.2393 (0.2354)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [ 80/172]  eta: 0:02:27  lr: 0.000097  loss: 0.2393 (0.2354)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [ 90/172]  eta: 0:02:10  lr: 0.000097  loss: 0.2330 (0.2360)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [100/172]  eta: 0:01:54  lr: 0.000097  loss: 0.2330 (0.2360)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [110/172]  eta: 0:01:38  lr: 0.000097  loss: 0.2305 (0.2356)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [120/172]  eta: 0:01:22  lr: 0.000097  loss: 0.2352 (0.2357)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [130/172]  eta: 0:01:06  lr: 0.000097  loss: 0.2383 (0.2370)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [140/172]  eta: 0:00:50  lr: 0.000097  loss: 0.2392 (0.2364)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [150/172]  eta: 0:00:35  lr: 0.000097  loss: 0.2349 (0.2367)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [160/172]  eta: 0:00:19  lr: 0.000097  loss: 0.2358 (0.2365)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [170/172]  eta: 0:00:03  lr: 0.000097  loss: 0.2306 (0.2362)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132]  [171/172]  eta: 0:00:01  lr: 0.000097  loss: 0.2306 (0.2362)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:132] Total time: 0:04:33 (1.5912 s / it)\n",
      "Averaged stats: lr: 0.000097  loss: 0.2306 (0.2362)\n",
      "Valid: [epoch:132]  [ 0/14]  eta: 0:00:04  loss: 0.2319 (0.2319)  time: 0.3256  data: 0.3109  max mem: 20571\n",
      "Valid: [epoch:132]  [13/14]  eta: 0:00:00  loss: 0.2108 (0.2172)  time: 0.0398  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:132] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.2108 (0.2172)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_132_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.217%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:133]  [  0/172]  eta: 0:07:35  lr: 0.000096  loss: 0.2196 (0.2196)  time: 2.6509  data: 1.0719  max mem: 20571\n",
      "Train: [epoch:133]  [ 10/172]  eta: 0:04:31  lr: 0.000096  loss: 0.2263 (0.2374)  time: 1.6764  data: 0.0976  max mem: 20571\n",
      "Train: [epoch:133]  [ 20/172]  eta: 0:04:07  lr: 0.000096  loss: 0.2321 (0.2376)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:133]  [ 30/172]  eta: 0:03:49  lr: 0.000096  loss: 0.2321 (0.2377)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:133]  [ 40/172]  eta: 0:03:32  lr: 0.000096  loss: 0.2328 (0.2371)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:133]  [ 50/172]  eta: 0:03:15  lr: 0.000096  loss: 0.2348 (0.2367)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [ 60/172]  eta: 0:02:58  lr: 0.000096  loss: 0.2391 (0.2369)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [ 70/172]  eta: 0:02:42  lr: 0.000096  loss: 0.2406 (0.2375)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [ 80/172]  eta: 0:02:26  lr: 0.000096  loss: 0.2410 (0.2378)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [ 90/172]  eta: 0:02:10  lr: 0.000096  loss: 0.2410 (0.2377)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [100/172]  eta: 0:01:54  lr: 0.000096  loss: 0.2297 (0.2376)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [110/172]  eta: 0:01:38  lr: 0.000096  loss: 0.2359 (0.2377)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [120/172]  eta: 0:01:22  lr: 0.000096  loss: 0.2316 (0.2375)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [130/172]  eta: 0:01:06  lr: 0.000096  loss: 0.2297 (0.2372)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [140/172]  eta: 0:00:50  lr: 0.000096  loss: 0.2297 (0.2368)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [150/172]  eta: 0:00:34  lr: 0.000096  loss: 0.2326 (0.2369)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [160/172]  eta: 0:00:19  lr: 0.000096  loss: 0.2364 (0.2371)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [170/172]  eta: 0:00:03  lr: 0.000096  loss: 0.2382 (0.2373)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133]  [171/172]  eta: 0:00:01  lr: 0.000096  loss: 0.2382 (0.2372)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:133] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000096  loss: 0.2382 (0.2372)\n",
      "Valid: [epoch:133]  [ 0/14]  eta: 0:00:04  loss: 0.2330 (0.2330)  time: 0.3320  data: 0.3148  max mem: 20571\n",
      "Valid: [epoch:133]  [13/14]  eta: 0:00:00  loss: 0.2081 (0.2151)  time: 0.0400  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:133] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.2081 (0.2151)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_133_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.215%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:134]  [  0/172]  eta: 0:08:00  lr: 0.000096  loss: 0.2048 (0.2048)  time: 2.7928  data: 1.2202  max mem: 20571\n",
      "Train: [epoch:134]  [ 10/172]  eta: 0:04:34  lr: 0.000096  loss: 0.2372 (0.2374)  time: 1.6920  data: 0.1111  max mem: 20571\n",
      "Train: [epoch:134]  [ 20/172]  eta: 0:04:09  lr: 0.000096  loss: 0.2358 (0.2376)  time: 1.5834  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:134]  [ 30/172]  eta: 0:03:50  lr: 0.000096  loss: 0.2346 (0.2370)  time: 1.5848  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:134]  [ 40/172]  eta: 0:03:33  lr: 0.000096  loss: 0.2371 (0.2385)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [ 50/172]  eta: 0:03:16  lr: 0.000096  loss: 0.2435 (0.2399)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [ 60/172]  eta: 0:02:59  lr: 0.000096  loss: 0.2435 (0.2402)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [ 70/172]  eta: 0:02:43  lr: 0.000096  loss: 0.2361 (0.2400)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [ 80/172]  eta: 0:02:27  lr: 0.000096  loss: 0.2361 (0.2395)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [ 90/172]  eta: 0:02:10  lr: 0.000096  loss: 0.2352 (0.2393)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [100/172]  eta: 0:01:54  lr: 0.000096  loss: 0.2359 (0.2391)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [110/172]  eta: 0:01:38  lr: 0.000096  loss: 0.2374 (0.2396)  time: 1.5873  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:134]  [120/172]  eta: 0:01:22  lr: 0.000096  loss: 0.2337 (0.2392)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [130/172]  eta: 0:01:06  lr: 0.000096  loss: 0.2334 (0.2391)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [140/172]  eta: 0:00:50  lr: 0.000096  loss: 0.2422 (0.2392)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [150/172]  eta: 0:00:35  lr: 0.000096  loss: 0.2416 (0.2390)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [160/172]  eta: 0:00:19  lr: 0.000096  loss: 0.2361 (0.2390)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [170/172]  eta: 0:00:03  lr: 0.000096  loss: 0.2415 (0.2389)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134]  [171/172]  eta: 0:00:01  lr: 0.000096  loss: 0.2389 (0.2389)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:134] Total time: 0:04:33 (1.5926 s / it)\n",
      "Averaged stats: lr: 0.000096  loss: 0.2389 (0.2389)\n",
      "Valid: [epoch:134]  [ 0/14]  eta: 0:00:07  loss: 0.2281 (0.2281)  time: 0.5016  data: 0.4848  max mem: 20571\n",
      "Valid: [epoch:134]  [13/14]  eta: 0:00:00  loss: 0.2332 (0.2395)  time: 0.0520  data: 0.0368  max mem: 20571\n",
      "Valid: [epoch:134] Total time: 0:00:00 (0.0598 s / it)\n",
      "Averaged stats: loss: 0.2332 (0.2395)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_134_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.239%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:135]  [  0/172]  eta: 0:08:05  lr: 0.000096  loss: 0.2277 (0.2277)  time: 2.8220  data: 1.2403  max mem: 20571\n",
      "Train: [epoch:135]  [ 10/172]  eta: 0:04:34  lr: 0.000096  loss: 0.2420 (0.2406)  time: 1.6921  data: 0.1129  max mem: 20571\n",
      "Train: [epoch:135]  [ 20/172]  eta: 0:04:09  lr: 0.000096  loss: 0.2387 (0.2415)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [ 30/172]  eta: 0:03:50  lr: 0.000096  loss: 0.2372 (0.2419)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [ 40/172]  eta: 0:03:32  lr: 0.000096  loss: 0.2508 (0.2433)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [ 50/172]  eta: 0:03:15  lr: 0.000096  loss: 0.2508 (0.2430)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [ 60/172]  eta: 0:02:59  lr: 0.000096  loss: 0.2399 (0.2428)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [ 70/172]  eta: 0:02:43  lr: 0.000096  loss: 0.2346 (0.2420)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [ 80/172]  eta: 0:02:27  lr: 0.000096  loss: 0.2376 (0.2417)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [ 90/172]  eta: 0:02:10  lr: 0.000096  loss: 0.2376 (0.2415)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [100/172]  eta: 0:01:54  lr: 0.000096  loss: 0.2372 (0.2413)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [110/172]  eta: 0:01:38  lr: 0.000096  loss: 0.2358 (0.2407)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [120/172]  eta: 0:01:22  lr: 0.000096  loss: 0.2358 (0.2406)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [130/172]  eta: 0:01:06  lr: 0.000096  loss: 0.2376 (0.2409)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [140/172]  eta: 0:00:50  lr: 0.000096  loss: 0.2398 (0.2409)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:135]  [150/172]  eta: 0:00:35  lr: 0.000096  loss: 0.2382 (0.2411)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:135]  [160/172]  eta: 0:00:19  lr: 0.000096  loss: 0.2356 (0.2406)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [170/172]  eta: 0:00:03  lr: 0.000096  loss: 0.2399 (0.2408)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135]  [171/172]  eta: 0:00:01  lr: 0.000096  loss: 0.2399 (0.2407)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:135] Total time: 0:04:33 (1.5910 s / it)\n",
      "Averaged stats: lr: 0.000096  loss: 0.2399 (0.2407)\n",
      "Valid: [epoch:135]  [ 0/14]  eta: 0:00:03  loss: 0.2014 (0.2014)  time: 0.2836  data: 0.2672  max mem: 20571\n",
      "Valid: [epoch:135]  [13/14]  eta: 0:00:00  loss: 0.2181 (0.2244)  time: 0.0423  data: 0.0272  max mem: 20571\n",
      "Valid: [epoch:135] Total time: 0:00:00 (0.0491 s / it)\n",
      "Averaged stats: loss: 0.2181 (0.2244)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_135_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.224%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:136]  [  0/172]  eta: 0:07:54  lr: 0.000096  loss: 0.2055 (0.2055)  time: 2.7561  data: 1.1849  max mem: 20571\n",
      "Train: [epoch:136]  [ 10/172]  eta: 0:04:33  lr: 0.000096  loss: 0.2432 (0.2431)  time: 1.6882  data: 0.1078  max mem: 20571\n",
      "Train: [epoch:136]  [ 20/172]  eta: 0:04:08  lr: 0.000096  loss: 0.2432 (0.2438)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [ 30/172]  eta: 0:03:49  lr: 0.000096  loss: 0.2356 (0.2425)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [ 40/172]  eta: 0:03:32  lr: 0.000096  loss: 0.2378 (0.2420)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [ 50/172]  eta: 0:03:15  lr: 0.000096  loss: 0.2393 (0.2422)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [ 60/172]  eta: 0:02:59  lr: 0.000096  loss: 0.2393 (0.2422)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [ 70/172]  eta: 0:02:43  lr: 0.000096  loss: 0.2466 (0.2429)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [ 80/172]  eta: 0:02:26  lr: 0.000096  loss: 0.2469 (0.2431)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [ 90/172]  eta: 0:02:10  lr: 0.000096  loss: 0.2399 (0.2431)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [100/172]  eta: 0:01:54  lr: 0.000096  loss: 0.2397 (0.2430)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [110/172]  eta: 0:01:38  lr: 0.000096  loss: 0.2405 (0.2432)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [120/172]  eta: 0:01:22  lr: 0.000096  loss: 0.2406 (0.2432)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [130/172]  eta: 0:01:06  lr: 0.000096  loss: 0.2388 (0.2431)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [140/172]  eta: 0:00:50  lr: 0.000096  loss: 0.2443 (0.2429)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [150/172]  eta: 0:00:34  lr: 0.000096  loss: 0.2439 (0.2429)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [160/172]  eta: 0:00:19  lr: 0.000096  loss: 0.2378 (0.2422)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [170/172]  eta: 0:00:03  lr: 0.000096  loss: 0.2338 (0.2420)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136]  [171/172]  eta: 0:00:01  lr: 0.000096  loss: 0.2365 (0.2421)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:136] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000096  loss: 0.2365 (0.2421)\n",
      "Valid: [epoch:136]  [ 0/14]  eta: 0:00:05  loss: 0.2078 (0.2078)  time: 0.3955  data: 0.3775  max mem: 20571\n",
      "Valid: [epoch:136]  [13/14]  eta: 0:00:00  loss: 0.2132 (0.2202)  time: 0.0424  data: 0.0270  max mem: 20571\n",
      "Valid: [epoch:136] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.2132 (0.2202)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_136_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.220%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:137]  [  0/172]  eta: 0:07:45  lr: 0.000096  loss: 0.2259 (0.2259)  time: 2.7074  data: 1.1328  max mem: 20571\n",
      "Train: [epoch:137]  [ 10/172]  eta: 0:04:32  lr: 0.000096  loss: 0.2391 (0.2408)  time: 1.6795  data: 0.1031  max mem: 20571\n",
      "Train: [epoch:137]  [ 20/172]  eta: 0:04:07  lr: 0.000096  loss: 0.2415 (0.2404)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [ 30/172]  eta: 0:03:49  lr: 0.000096  loss: 0.2415 (0.2427)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [ 40/172]  eta: 0:03:32  lr: 0.000096  loss: 0.2451 (0.2429)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [ 50/172]  eta: 0:03:15  lr: 0.000096  loss: 0.2435 (0.2423)  time: 1.5817  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:137]  [ 60/172]  eta: 0:02:59  lr: 0.000096  loss: 0.2449 (0.2442)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [ 70/172]  eta: 0:02:42  lr: 0.000096  loss: 0.2439 (0.2434)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [ 80/172]  eta: 0:02:26  lr: 0.000096  loss: 0.2401 (0.2436)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [ 90/172]  eta: 0:02:10  lr: 0.000096  loss: 0.2453 (0.2439)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [100/172]  eta: 0:01:54  lr: 0.000096  loss: 0.2426 (0.2440)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [110/172]  eta: 0:01:38  lr: 0.000096  loss: 0.2393 (0.2439)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [120/172]  eta: 0:01:22  lr: 0.000096  loss: 0.2358 (0.2436)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [130/172]  eta: 0:01:06  lr: 0.000096  loss: 0.2348 (0.2436)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [140/172]  eta: 0:00:50  lr: 0.000096  loss: 0.2367 (0.2433)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [150/172]  eta: 0:00:34  lr: 0.000096  loss: 0.2437 (0.2436)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [160/172]  eta: 0:00:19  lr: 0.000096  loss: 0.2437 (0.2437)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [170/172]  eta: 0:00:03  lr: 0.000096  loss: 0.2413 (0.2435)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137]  [171/172]  eta: 0:00:01  lr: 0.000096  loss: 0.2429 (0.2435)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:137] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000096  loss: 0.2429 (0.2435)\n",
      "Valid: [epoch:137]  [ 0/14]  eta: 0:00:04  loss: 0.2378 (0.2378)  time: 0.3259  data: 0.3108  max mem: 20571\n",
      "Valid: [epoch:137]  [13/14]  eta: 0:00:00  loss: 0.2166 (0.2230)  time: 0.0402  data: 0.0253  max mem: 20571\n",
      "Valid: [epoch:137] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 0.2166 (0.2230)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_137_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.223%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:138]  [  0/172]  eta: 0:07:33  lr: 0.000096  loss: 0.2370 (0.2370)  time: 2.6384  data: 1.0651  max mem: 20571\n",
      "Train: [epoch:138]  [ 10/172]  eta: 0:04:32  lr: 0.000096  loss: 0.2370 (0.2388)  time: 1.6807  data: 0.0969  max mem: 20571\n",
      "Train: [epoch:138]  [ 20/172]  eta: 0:04:08  lr: 0.000096  loss: 0.2469 (0.2446)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [ 30/172]  eta: 0:03:50  lr: 0.000096  loss: 0.2428 (0.2434)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [ 40/172]  eta: 0:03:32  lr: 0.000096  loss: 0.2394 (0.2448)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [ 50/172]  eta: 0:03:15  lr: 0.000096  loss: 0.2457 (0.2451)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [ 60/172]  eta: 0:02:59  lr: 0.000096  loss: 0.2457 (0.2455)  time: 1.5848  data: 0.0013  max mem: 20571\n",
      "Train: [epoch:138]  [ 70/172]  eta: 0:02:43  lr: 0.000096  loss: 0.2409 (0.2455)  time: 1.5844  data: 0.0013  max mem: 20571\n",
      "Train: [epoch:138]  [ 80/172]  eta: 0:02:27  lr: 0.000096  loss: 0.2400 (0.2460)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [ 90/172]  eta: 0:02:10  lr: 0.000096  loss: 0.2433 (0.2457)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [100/172]  eta: 0:01:54  lr: 0.000096  loss: 0.2376 (0.2453)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [110/172]  eta: 0:01:38  lr: 0.000096  loss: 0.2414 (0.2457)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [120/172]  eta: 0:01:22  lr: 0.000096  loss: 0.2424 (0.2457)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [130/172]  eta: 0:01:06  lr: 0.000096  loss: 0.2414 (0.2457)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [140/172]  eta: 0:00:50  lr: 0.000096  loss: 0.2449 (0.2455)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [150/172]  eta: 0:00:35  lr: 0.000096  loss: 0.2449 (0.2455)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [160/172]  eta: 0:00:19  lr: 0.000096  loss: 0.2467 (0.2455)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [170/172]  eta: 0:00:03  lr: 0.000096  loss: 0.2476 (0.2456)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138]  [171/172]  eta: 0:00:01  lr: 0.000096  loss: 0.2476 (0.2454)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:138] Total time: 0:04:33 (1.5914 s / it)\n",
      "Averaged stats: lr: 0.000096  loss: 0.2476 (0.2454)\n",
      "Valid: [epoch:138]  [ 0/14]  eta: 0:00:04  loss: 0.2420 (0.2420)  time: 0.3008  data: 0.2848  max mem: 20571\n",
      "Valid: [epoch:138]  [13/14]  eta: 0:00:00  loss: 0.2281 (0.2340)  time: 0.0429  data: 0.0279  max mem: 20571\n",
      "Valid: [epoch:138] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.2281 (0.2340)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_138_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.234%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:139]  [  0/172]  eta: 0:07:41  lr: 0.000096  loss: 0.2268 (0.2268)  time: 2.6807  data: 1.0992  max mem: 20571\n",
      "Train: [epoch:139]  [ 10/172]  eta: 0:04:31  lr: 0.000096  loss: 0.2495 (0.2522)  time: 1.6770  data: 0.1000  max mem: 20571\n",
      "Train: [epoch:139]  [ 20/172]  eta: 0:04:07  lr: 0.000096  loss: 0.2495 (0.2487)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [ 30/172]  eta: 0:03:49  lr: 0.000096  loss: 0.2415 (0.2470)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [ 40/172]  eta: 0:03:31  lr: 0.000096  loss: 0.2447 (0.2476)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [ 50/172]  eta: 0:03:15  lr: 0.000096  loss: 0.2486 (0.2473)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [ 60/172]  eta: 0:02:58  lr: 0.000096  loss: 0.2443 (0.2473)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [ 70/172]  eta: 0:02:42  lr: 0.000096  loss: 0.2436 (0.2475)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [ 80/172]  eta: 0:02:26  lr: 0.000096  loss: 0.2464 (0.2479)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [ 90/172]  eta: 0:02:10  lr: 0.000096  loss: 0.2461 (0.2477)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [100/172]  eta: 0:01:54  lr: 0.000096  loss: 0.2419 (0.2472)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [110/172]  eta: 0:01:38  lr: 0.000096  loss: 0.2419 (0.2476)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [120/172]  eta: 0:01:22  lr: 0.000096  loss: 0.2448 (0.2475)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [130/172]  eta: 0:01:06  lr: 0.000096  loss: 0.2391 (0.2474)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [140/172]  eta: 0:00:50  lr: 0.000096  loss: 0.2384 (0.2473)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [150/172]  eta: 0:00:34  lr: 0.000096  loss: 0.2386 (0.2473)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [160/172]  eta: 0:00:19  lr: 0.000096  loss: 0.2379 (0.2471)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [170/172]  eta: 0:00:03  lr: 0.000096  loss: 0.2379 (0.2469)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139]  [171/172]  eta: 0:00:01  lr: 0.000096  loss: 0.2376 (0.2469)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:139] Total time: 0:04:32 (1.5850 s / it)\n",
      "Averaged stats: lr: 0.000096  loss: 0.2376 (0.2469)\n",
      "Valid: [epoch:139]  [ 0/14]  eta: 0:00:05  loss: 0.2200 (0.2200)  time: 0.4134  data: 0.3955  max mem: 20571\n",
      "Valid: [epoch:139]  [13/14]  eta: 0:00:00  loss: 0.2245 (0.2314)  time: 0.0451  data: 0.0300  max mem: 20571\n",
      "Valid: [epoch:139] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.2245 (0.2314)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_139_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.231%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:140]  [  0/172]  eta: 0:07:55  lr: 0.000096  loss: 0.2124 (0.2124)  time: 2.7639  data: 1.1907  max mem: 20571\n",
      "Train: [epoch:140]  [ 10/172]  eta: 0:04:32  lr: 0.000096  loss: 0.2519 (0.2478)  time: 1.6841  data: 0.1083  max mem: 20571\n",
      "Train: [epoch:140]  [ 20/172]  eta: 0:04:08  lr: 0.000096  loss: 0.2582 (0.2503)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [ 30/172]  eta: 0:03:49  lr: 0.000096  loss: 0.2568 (0.2507)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [ 40/172]  eta: 0:03:31  lr: 0.000096  loss: 0.2509 (0.2503)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [ 50/172]  eta: 0:03:15  lr: 0.000096  loss: 0.2509 (0.2501)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [ 60/172]  eta: 0:02:58  lr: 0.000096  loss: 0.2478 (0.2498)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [ 70/172]  eta: 0:02:42  lr: 0.000096  loss: 0.2472 (0.2497)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [ 80/172]  eta: 0:02:26  lr: 0.000096  loss: 0.2509 (0.2503)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [ 90/172]  eta: 0:02:10  lr: 0.000096  loss: 0.2538 (0.2504)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [100/172]  eta: 0:01:54  lr: 0.000096  loss: 0.2498 (0.2501)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [110/172]  eta: 0:01:38  lr: 0.000096  loss: 0.2504 (0.2499)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [120/172]  eta: 0:01:22  lr: 0.000096  loss: 0.2504 (0.2499)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [130/172]  eta: 0:01:06  lr: 0.000096  loss: 0.2539 (0.2501)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [140/172]  eta: 0:00:50  lr: 0.000096  loss: 0.2564 (0.2502)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [150/172]  eta: 0:00:34  lr: 0.000096  loss: 0.2403 (0.2497)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [160/172]  eta: 0:00:18  lr: 0.000096  loss: 0.2403 (0.2497)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [170/172]  eta: 0:00:03  lr: 0.000096  loss: 0.2514 (0.2501)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140]  [171/172]  eta: 0:00:01  lr: 0.000096  loss: 0.2514 (0.2499)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:140] Total time: 0:04:32 (1.5836 s / it)\n",
      "Averaged stats: lr: 0.000096  loss: 0.2514 (0.2499)\n",
      "Valid: [epoch:140]  [ 0/14]  eta: 0:00:04  loss: 0.2569 (0.2569)  time: 0.3495  data: 0.3320  max mem: 20571\n",
      "Valid: [epoch:140]  [13/14]  eta: 0:00:00  loss: 0.2323 (0.2389)  time: 0.0392  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:140] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.2323 (0.2389)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_140_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.239%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:141]  [  0/172]  eta: 0:08:27  lr: 0.000096  loss: 0.2537 (0.2537)  time: 2.9500  data: 1.3776  max mem: 20571\n",
      "Train: [epoch:141]  [ 10/172]  eta: 0:04:34  lr: 0.000096  loss: 0.2451 (0.2510)  time: 1.6974  data: 0.1253  max mem: 20571\n",
      "Train: [epoch:141]  [ 20/172]  eta: 0:04:09  lr: 0.000096  loss: 0.2451 (0.2518)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [ 30/172]  eta: 0:03:50  lr: 0.000096  loss: 0.2587 (0.2532)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [ 40/172]  eta: 0:03:32  lr: 0.000096  loss: 0.2579 (0.2529)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [ 50/172]  eta: 0:03:15  lr: 0.000096  loss: 0.2517 (0.2537)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [ 60/172]  eta: 0:02:59  lr: 0.000096  loss: 0.2465 (0.2531)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [ 70/172]  eta: 0:02:43  lr: 0.000096  loss: 0.2402 (0.2524)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [ 80/172]  eta: 0:02:26  lr: 0.000096  loss: 0.2536 (0.2521)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [ 90/172]  eta: 0:02:10  lr: 0.000096  loss: 0.2415 (0.2511)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [100/172]  eta: 0:01:54  lr: 0.000096  loss: 0.2454 (0.2515)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [110/172]  eta: 0:01:38  lr: 0.000096  loss: 0.2496 (0.2511)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [120/172]  eta: 0:01:22  lr: 0.000096  loss: 0.2434 (0.2510)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [130/172]  eta: 0:01:06  lr: 0.000096  loss: 0.2479 (0.2510)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [140/172]  eta: 0:00:50  lr: 0.000096  loss: 0.2434 (0.2506)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [150/172]  eta: 0:00:34  lr: 0.000096  loss: 0.2444 (0.2506)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [160/172]  eta: 0:00:19  lr: 0.000096  loss: 0.2470 (0.2504)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [170/172]  eta: 0:00:03  lr: 0.000096  loss: 0.2490 (0.2505)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141]  [171/172]  eta: 0:00:01  lr: 0.000096  loss: 0.2490 (0.2506)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:141] Total time: 0:04:33 (1.5909 s / it)\n",
      "Averaged stats: lr: 0.000096  loss: 0.2490 (0.2506)\n",
      "Valid: [epoch:141]  [ 0/14]  eta: 0:00:06  loss: 0.2000 (0.2000)  time: 0.4691  data: 0.4528  max mem: 20571\n",
      "Valid: [epoch:141]  [13/14]  eta: 0:00:00  loss: 0.2225 (0.2300)  time: 0.0494  data: 0.0342  max mem: 20571\n",
      "Valid: [epoch:141] Total time: 0:00:00 (0.0576 s / it)\n",
      "Averaged stats: loss: 0.2225 (0.2300)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_141_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.230%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:142]  [  0/172]  eta: 0:07:34  lr: 0.000095  loss: 0.2290 (0.2290)  time: 2.6418  data: 1.0661  max mem: 20571\n",
      "Train: [epoch:142]  [ 10/172]  eta: 0:04:31  lr: 0.000095  loss: 0.2464 (0.2547)  time: 1.6782  data: 0.0971  max mem: 20571\n",
      "Train: [epoch:142]  [ 20/172]  eta: 0:04:08  lr: 0.000095  loss: 0.2529 (0.2546)  time: 1.5841  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:142]  [ 30/172]  eta: 0:03:49  lr: 0.000095  loss: 0.2525 (0.2511)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142]  [ 40/172]  eta: 0:03:32  lr: 0.000095  loss: 0.2471 (0.2514)  time: 1.5865  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:142]  [ 50/172]  eta: 0:03:15  lr: 0.000095  loss: 0.2547 (0.2531)  time: 1.5867  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:142]  [ 60/172]  eta: 0:02:59  lr: 0.000095  loss: 0.2503 (0.2519)  time: 1.5856  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:142]  [ 70/172]  eta: 0:02:43  lr: 0.000095  loss: 0.2452 (0.2520)  time: 1.5850  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:142]  [ 80/172]  eta: 0:02:27  lr: 0.000095  loss: 0.2492 (0.2522)  time: 1.5837  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:142]  [ 90/172]  eta: 0:02:10  lr: 0.000095  loss: 0.2543 (0.2523)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142]  [100/172]  eta: 0:01:54  lr: 0.000095  loss: 0.2484 (0.2521)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142]  [110/172]  eta: 0:01:38  lr: 0.000095  loss: 0.2458 (0.2514)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142]  [120/172]  eta: 0:01:22  lr: 0.000095  loss: 0.2494 (0.2517)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142]  [130/172]  eta: 0:01:06  lr: 0.000095  loss: 0.2523 (0.2513)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142]  [140/172]  eta: 0:00:50  lr: 0.000095  loss: 0.2504 (0.2516)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142]  [150/172]  eta: 0:00:35  lr: 0.000095  loss: 0.2505 (0.2518)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142]  [160/172]  eta: 0:00:19  lr: 0.000095  loss: 0.2505 (0.2517)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142]  [170/172]  eta: 0:00:03  lr: 0.000095  loss: 0.2519 (0.2518)  time: 1.5848  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:142]  [171/172]  eta: 0:00:01  lr: 0.000095  loss: 0.2516 (0.2517)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:142] Total time: 0:04:33 (1.5918 s / it)\n",
      "Averaged stats: lr: 0.000095  loss: 0.2516 (0.2517)\n",
      "Valid: [epoch:142]  [ 0/14]  eta: 0:00:07  loss: 0.2078 (0.2078)  time: 0.5653  data: 0.5490  max mem: 20571\n",
      "Valid: [epoch:142]  [13/14]  eta: 0:00:00  loss: 0.2256 (0.2327)  time: 0.0552  data: 0.0399  max mem: 20571\n",
      "Valid: [epoch:142] Total time: 0:00:00 (0.0606 s / it)\n",
      "Averaged stats: loss: 0.2256 (0.2327)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_142_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.233%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:143]  [  0/172]  eta: 0:08:17  lr: 0.000095  loss: 0.2283 (0.2283)  time: 2.8902  data: 1.3056  max mem: 20571\n",
      "Train: [epoch:143]  [ 10/172]  eta: 0:04:35  lr: 0.000095  loss: 0.2430 (0.2560)  time: 1.6998  data: 0.1189  max mem: 20571\n",
      "Train: [epoch:143]  [ 20/172]  eta: 0:04:09  lr: 0.000095  loss: 0.2476 (0.2554)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:143]  [ 30/172]  eta: 0:03:50  lr: 0.000095  loss: 0.2471 (0.2524)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [ 40/172]  eta: 0:03:33  lr: 0.000095  loss: 0.2471 (0.2520)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [ 50/172]  eta: 0:03:16  lr: 0.000095  loss: 0.2504 (0.2524)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [ 60/172]  eta: 0:02:59  lr: 0.000095  loss: 0.2519 (0.2523)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [ 70/172]  eta: 0:02:43  lr: 0.000095  loss: 0.2519 (0.2528)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [ 80/172]  eta: 0:02:27  lr: 0.000095  loss: 0.2531 (0.2525)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [ 90/172]  eta: 0:02:10  lr: 0.000095  loss: 0.2528 (0.2526)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [100/172]  eta: 0:01:54  lr: 0.000095  loss: 0.2485 (0.2525)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [110/172]  eta: 0:01:38  lr: 0.000095  loss: 0.2487 (0.2532)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [120/172]  eta: 0:01:22  lr: 0.000095  loss: 0.2598 (0.2533)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [130/172]  eta: 0:01:06  lr: 0.000095  loss: 0.2491 (0.2529)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [140/172]  eta: 0:00:50  lr: 0.000095  loss: 0.2557 (0.2531)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [150/172]  eta: 0:00:35  lr: 0.000095  loss: 0.2557 (0.2532)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [160/172]  eta: 0:00:19  lr: 0.000095  loss: 0.2500 (0.2531)  time: 1.5836  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:143]  [170/172]  eta: 0:00:03  lr: 0.000095  loss: 0.2500 (0.2531)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143]  [171/172]  eta: 0:00:01  lr: 0.000095  loss: 0.2480 (0.2531)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:143] Total time: 0:04:33 (1.5911 s / it)\n",
      "Averaged stats: lr: 0.000095  loss: 0.2480 (0.2531)\n",
      "Valid: [epoch:143]  [ 0/14]  eta: 0:00:04  loss: 0.2510 (0.2510)  time: 0.3397  data: 0.3229  max mem: 20571\n",
      "Valid: [epoch:143]  [13/14]  eta: 0:00:00  loss: 0.2221 (0.2293)  time: 0.0385  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:143] Total time: 0:00:00 (0.0459 s / it)\n",
      "Averaged stats: loss: 0.2221 (0.2293)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_143_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.229%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:144]  [  0/172]  eta: 0:08:19  lr: 0.000095  loss: 0.2211 (0.2211)  time: 2.9057  data: 1.3232  max mem: 20571\n",
      "Train: [epoch:144]  [ 10/172]  eta: 0:04:35  lr: 0.000095  loss: 0.2548 (0.2529)  time: 1.7009  data: 0.1204  max mem: 20571\n",
      "Train: [epoch:144]  [ 20/172]  eta: 0:04:09  lr: 0.000095  loss: 0.2564 (0.2559)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:144]  [ 30/172]  eta: 0:03:50  lr: 0.000095  loss: 0.2562 (0.2557)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:144]  [ 40/172]  eta: 0:03:33  lr: 0.000095  loss: 0.2525 (0.2556)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [ 50/172]  eta: 0:03:16  lr: 0.000095  loss: 0.2485 (0.2555)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [ 60/172]  eta: 0:02:59  lr: 0.000095  loss: 0.2482 (0.2551)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [ 70/172]  eta: 0:02:43  lr: 0.000095  loss: 0.2570 (0.2556)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [ 80/172]  eta: 0:02:26  lr: 0.000095  loss: 0.2541 (0.2549)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [ 90/172]  eta: 0:02:10  lr: 0.000095  loss: 0.2464 (0.2550)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [100/172]  eta: 0:01:54  lr: 0.000095  loss: 0.2503 (0.2546)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [110/172]  eta: 0:01:38  lr: 0.000095  loss: 0.2503 (0.2552)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [120/172]  eta: 0:01:22  lr: 0.000095  loss: 0.2486 (0.2545)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [130/172]  eta: 0:01:06  lr: 0.000095  loss: 0.2486 (0.2546)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [140/172]  eta: 0:00:50  lr: 0.000095  loss: 0.2565 (0.2546)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [150/172]  eta: 0:00:34  lr: 0.000095  loss: 0.2566 (0.2547)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [160/172]  eta: 0:00:19  lr: 0.000095  loss: 0.2566 (0.2546)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [170/172]  eta: 0:00:03  lr: 0.000095  loss: 0.2553 (0.2546)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144]  [171/172]  eta: 0:00:01  lr: 0.000095  loss: 0.2553 (0.2548)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:144] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000095  loss: 0.2553 (0.2548)\n",
      "Valid: [epoch:144]  [ 0/14]  eta: 0:00:05  loss: 0.2581 (0.2581)  time: 0.3990  data: 0.3836  max mem: 20571\n",
      "Valid: [epoch:144]  [13/14]  eta: 0:00:00  loss: 0.2372 (0.2436)  time: 0.0436  data: 0.0284  max mem: 20571\n",
      "Valid: [epoch:144] Total time: 0:00:00 (0.0486 s / it)\n",
      "Averaged stats: loss: 0.2372 (0.2436)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_144_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.244%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:145]  [  0/172]  eta: 0:08:19  lr: 0.000095  loss: 0.2563 (0.2563)  time: 2.9036  data: 1.3298  max mem: 20571\n",
      "Train: [epoch:145]  [ 10/172]  eta: 0:04:35  lr: 0.000095  loss: 0.2612 (0.2587)  time: 1.6976  data: 0.1210  max mem: 20571\n",
      "Train: [epoch:145]  [ 20/172]  eta: 0:04:09  lr: 0.000095  loss: 0.2600 (0.2584)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:145]  [ 30/172]  eta: 0:03:50  lr: 0.000095  loss: 0.2541 (0.2573)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:145]  [ 40/172]  eta: 0:03:32  lr: 0.000095  loss: 0.2569 (0.2591)  time: 1.5827  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:145]  [ 50/172]  eta: 0:03:16  lr: 0.000095  loss: 0.2531 (0.2571)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [ 60/172]  eta: 0:02:59  lr: 0.000095  loss: 0.2476 (0.2564)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [ 70/172]  eta: 0:02:43  lr: 0.000095  loss: 0.2585 (0.2575)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [ 80/172]  eta: 0:02:27  lr: 0.000095  loss: 0.2575 (0.2570)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [ 90/172]  eta: 0:02:10  lr: 0.000095  loss: 0.2557 (0.2570)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [100/172]  eta: 0:01:54  lr: 0.000095  loss: 0.2559 (0.2573)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [110/172]  eta: 0:01:38  lr: 0.000095  loss: 0.2603 (0.2576)  time: 1.5863  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:145]  [120/172]  eta: 0:01:22  lr: 0.000095  loss: 0.2603 (0.2578)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [130/172]  eta: 0:01:06  lr: 0.000095  loss: 0.2582 (0.2576)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [140/172]  eta: 0:00:50  lr: 0.000095  loss: 0.2590 (0.2579)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [150/172]  eta: 0:00:35  lr: 0.000095  loss: 0.2578 (0.2579)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [160/172]  eta: 0:00:19  lr: 0.000095  loss: 0.2572 (0.2579)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [170/172]  eta: 0:00:03  lr: 0.000095  loss: 0.2573 (0.2580)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145]  [171/172]  eta: 0:00:01  lr: 0.000095  loss: 0.2572 (0.2579)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:145] Total time: 0:04:33 (1.5914 s / it)\n",
      "Averaged stats: lr: 0.000095  loss: 0.2572 (0.2579)\n",
      "Valid: [epoch:145]  [ 0/14]  eta: 0:00:05  loss: 0.2269 (0.2269)  time: 0.3647  data: 0.3477  max mem: 20571\n",
      "Valid: [epoch:145]  [13/14]  eta: 0:00:00  loss: 0.2269 (0.2341)  time: 0.0444  data: 0.0293  max mem: 20571\n",
      "Valid: [epoch:145] Total time: 0:00:00 (0.0503 s / it)\n",
      "Averaged stats: loss: 0.2269 (0.2341)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_145_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.234%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:146]  [  0/172]  eta: 0:08:05  lr: 0.000095  loss: 0.2367 (0.2367)  time: 2.8244  data: 1.2552  max mem: 20571\n",
      "Train: [epoch:146]  [ 10/172]  eta: 0:04:34  lr: 0.000095  loss: 0.2494 (0.2547)  time: 1.6965  data: 0.1142  max mem: 20571\n",
      "Train: [epoch:146]  [ 20/172]  eta: 0:04:09  lr: 0.000095  loss: 0.2545 (0.2594)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [ 30/172]  eta: 0:03:50  lr: 0.000095  loss: 0.2565 (0.2598)  time: 1.5834  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:146]  [ 40/172]  eta: 0:03:33  lr: 0.000095  loss: 0.2517 (0.2589)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [ 50/172]  eta: 0:03:16  lr: 0.000095  loss: 0.2517 (0.2614)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [ 60/172]  eta: 0:02:59  lr: 0.000095  loss: 0.2621 (0.2626)  time: 1.5831  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:146]  [ 70/172]  eta: 0:02:43  lr: 0.000095  loss: 0.2622 (0.2625)  time: 1.5838  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:146]  [ 80/172]  eta: 0:02:27  lr: 0.000095  loss: 0.2582 (0.2611)  time: 1.5843  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:146]  [ 90/172]  eta: 0:02:10  lr: 0.000095  loss: 0.2547 (0.2608)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [100/172]  eta: 0:01:54  lr: 0.000095  loss: 0.2521 (0.2603)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [110/172]  eta: 0:01:38  lr: 0.000095  loss: 0.2524 (0.2599)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [120/172]  eta: 0:01:22  lr: 0.000095  loss: 0.2568 (0.2603)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [130/172]  eta: 0:01:06  lr: 0.000095  loss: 0.2568 (0.2595)  time: 1.5830  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:146]  [140/172]  eta: 0:00:50  lr: 0.000095  loss: 0.2582 (0.2597)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [150/172]  eta: 0:00:35  lr: 0.000095  loss: 0.2608 (0.2595)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [160/172]  eta: 0:00:19  lr: 0.000095  loss: 0.2554 (0.2593)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [170/172]  eta: 0:00:03  lr: 0.000095  loss: 0.2579 (0.2596)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146]  [171/172]  eta: 0:00:01  lr: 0.000095  loss: 0.2579 (0.2599)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:146] Total time: 0:04:33 (1.5917 s / it)\n",
      "Averaged stats: lr: 0.000095  loss: 0.2579 (0.2599)\n",
      "Valid: [epoch:146]  [ 0/14]  eta: 0:00:04  loss: 0.2296 (0.2296)  time: 0.3009  data: 0.2856  max mem: 20571\n",
      "Valid: [epoch:146]  [13/14]  eta: 0:00:00  loss: 0.2364 (0.2436)  time: 0.0390  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:146] Total time: 0:00:00 (0.0470 s / it)\n",
      "Averaged stats: loss: 0.2364 (0.2436)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_146_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.244%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:147]  [  0/172]  eta: 0:07:38  lr: 0.000095  loss: 0.2357 (0.2357)  time: 2.6664  data: 1.0919  max mem: 20571\n",
      "Train: [epoch:147]  [ 10/172]  eta: 0:04:31  lr: 0.000095  loss: 0.2594 (0.2591)  time: 1.6775  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:147]  [ 20/172]  eta: 0:04:07  lr: 0.000095  loss: 0.2611 (0.2600)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:147]  [ 30/172]  eta: 0:03:49  lr: 0.000095  loss: 0.2541 (0.2580)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:147]  [ 40/172]  eta: 0:03:32  lr: 0.000095  loss: 0.2518 (0.2598)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [ 50/172]  eta: 0:03:15  lr: 0.000095  loss: 0.2618 (0.2608)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [ 60/172]  eta: 0:02:59  lr: 0.000095  loss: 0.2588 (0.2604)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [ 70/172]  eta: 0:02:42  lr: 0.000095  loss: 0.2525 (0.2604)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:147]  [ 80/172]  eta: 0:02:26  lr: 0.000095  loss: 0.2536 (0.2597)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:147]  [ 90/172]  eta: 0:02:10  lr: 0.000095  loss: 0.2565 (0.2605)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:147]  [100/172]  eta: 0:01:54  lr: 0.000095  loss: 0.2547 (0.2597)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [110/172]  eta: 0:01:38  lr: 0.000095  loss: 0.2507 (0.2600)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [120/172]  eta: 0:01:22  lr: 0.000095  loss: 0.2516 (0.2598)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [130/172]  eta: 0:01:06  lr: 0.000095  loss: 0.2548 (0.2598)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [140/172]  eta: 0:00:50  lr: 0.000095  loss: 0.2548 (0.2596)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [150/172]  eta: 0:00:34  lr: 0.000095  loss: 0.2506 (0.2591)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [160/172]  eta: 0:00:19  lr: 0.000095  loss: 0.2506 (0.2595)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [170/172]  eta: 0:00:03  lr: 0.000095  loss: 0.2630 (0.2599)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147]  [171/172]  eta: 0:00:01  lr: 0.000095  loss: 0.2630 (0.2598)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:147] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000095  loss: 0.2630 (0.2598)\n",
      "Valid: [epoch:147]  [ 0/14]  eta: 0:00:04  loss: 0.2549 (0.2549)  time: 0.3115  data: 0.2913  max mem: 20571\n",
      "Valid: [epoch:147]  [13/14]  eta: 0:00:00  loss: 0.2280 (0.2353)  time: 0.0414  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:147] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.2280 (0.2353)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_147_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.235%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:148]  [  0/172]  eta: 0:07:23  lr: 0.000095  loss: 0.2274 (0.2274)  time: 2.5769  data: 1.0084  max mem: 20571\n",
      "Train: [epoch:148]  [ 10/172]  eta: 0:04:30  lr: 0.000095  loss: 0.2587 (0.2608)  time: 1.6706  data: 0.0918  max mem: 20571\n",
      "Train: [epoch:148]  [ 20/172]  eta: 0:04:07  lr: 0.000095  loss: 0.2602 (0.2636)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:148]  [ 30/172]  eta: 0:03:49  lr: 0.000095  loss: 0.2648 (0.2641)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:148]  [ 40/172]  eta: 0:03:31  lr: 0.000095  loss: 0.2637 (0.2627)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:148]  [ 50/172]  eta: 0:03:15  lr: 0.000095  loss: 0.2608 (0.2636)  time: 1.5805  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:148]  [ 60/172]  eta: 0:02:58  lr: 0.000095  loss: 0.2611 (0.2631)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:148]  [ 70/172]  eta: 0:02:42  lr: 0.000095  loss: 0.2592 (0.2631)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:148]  [ 80/172]  eta: 0:02:26  lr: 0.000095  loss: 0.2570 (0.2628)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:148]  [ 90/172]  eta: 0:02:10  lr: 0.000095  loss: 0.2580 (0.2631)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148]  [100/172]  eta: 0:01:54  lr: 0.000095  loss: 0.2580 (0.2628)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148]  [110/172]  eta: 0:01:38  lr: 0.000095  loss: 0.2565 (0.2628)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148]  [120/172]  eta: 0:01:22  lr: 0.000095  loss: 0.2646 (0.2627)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148]  [130/172]  eta: 0:01:06  lr: 0.000095  loss: 0.2581 (0.2621)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148]  [140/172]  eta: 0:00:50  lr: 0.000095  loss: 0.2558 (0.2619)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148]  [150/172]  eta: 0:00:34  lr: 0.000095  loss: 0.2552 (0.2619)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148]  [160/172]  eta: 0:00:19  lr: 0.000095  loss: 0.2552 (0.2616)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148]  [170/172]  eta: 0:00:03  lr: 0.000095  loss: 0.2595 (0.2615)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148]  [171/172]  eta: 0:00:01  lr: 0.000095  loss: 0.2595 (0.2614)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:148] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000095  loss: 0.2595 (0.2614)\n",
      "Valid: [epoch:148]  [ 0/14]  eta: 0:00:04  loss: 0.2379 (0.2379)  time: 0.3064  data: 0.2916  max mem: 20571\n",
      "Valid: [epoch:148]  [13/14]  eta: 0:00:00  loss: 0.2384 (0.2460)  time: 0.0399  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:148] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.2384 (0.2460)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_148_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.246%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:149]  [  0/172]  eta: 0:08:14  lr: 0.000095  loss: 0.2566 (0.2566)  time: 2.8767  data: 1.3023  max mem: 20571\n",
      "Train: [epoch:149]  [ 10/172]  eta: 0:04:34  lr: 0.000095  loss: 0.2617 (0.2640)  time: 1.6929  data: 0.1185  max mem: 20571\n",
      "Train: [epoch:149]  [ 20/172]  eta: 0:04:09  lr: 0.000095  loss: 0.2654 (0.2652)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [ 30/172]  eta: 0:03:49  lr: 0.000095  loss: 0.2703 (0.2648)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [ 40/172]  eta: 0:03:32  lr: 0.000095  loss: 0.2639 (0.2640)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [ 50/172]  eta: 0:03:15  lr: 0.000095  loss: 0.2635 (0.2650)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [ 60/172]  eta: 0:02:59  lr: 0.000095  loss: 0.2635 (0.2650)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [ 70/172]  eta: 0:02:42  lr: 0.000095  loss: 0.2670 (0.2652)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [ 80/172]  eta: 0:02:26  lr: 0.000095  loss: 0.2557 (0.2649)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [ 90/172]  eta: 0:02:10  lr: 0.000095  loss: 0.2656 (0.2659)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [100/172]  eta: 0:01:54  lr: 0.000095  loss: 0.2664 (0.2655)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [110/172]  eta: 0:01:38  lr: 0.000095  loss: 0.2603 (0.2655)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [120/172]  eta: 0:01:22  lr: 0.000095  loss: 0.2606 (0.2655)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [130/172]  eta: 0:01:06  lr: 0.000095  loss: 0.2587 (0.2653)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [140/172]  eta: 0:00:50  lr: 0.000095  loss: 0.2504 (0.2643)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [150/172]  eta: 0:00:34  lr: 0.000095  loss: 0.2512 (0.2641)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [160/172]  eta: 0:00:19  lr: 0.000095  loss: 0.2611 (0.2650)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [170/172]  eta: 0:00:03  lr: 0.000095  loss: 0.2716 (0.2656)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149]  [171/172]  eta: 0:00:01  lr: 0.000095  loss: 0.2720 (0.2656)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:149] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000095  loss: 0.2720 (0.2656)\n",
      "Valid: [epoch:149]  [ 0/14]  eta: 0:00:04  loss: 0.2398 (0.2398)  time: 0.3115  data: 0.2954  max mem: 20571\n",
      "Valid: [epoch:149]  [13/14]  eta: 0:00:00  loss: 0.2465 (0.2535)  time: 0.0381  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:149] Total time: 0:00:00 (0.0448 s / it)\n",
      "Averaged stats: loss: 0.2465 (0.2535)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_149_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.254%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:150]  [  0/172]  eta: 0:07:43  lr: 0.000095  loss: 0.2647 (0.2647)  time: 2.6929  data: 1.1266  max mem: 20571\n",
      "Train: [epoch:150]  [ 10/172]  eta: 0:04:31  lr: 0.000095  loss: 0.2647 (0.2654)  time: 1.6774  data: 0.1026  max mem: 20571\n",
      "Train: [epoch:150]  [ 20/172]  eta: 0:04:07  lr: 0.000095  loss: 0.2632 (0.2630)  time: 1.5763  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:150]  [ 30/172]  eta: 0:03:49  lr: 0.000095  loss: 0.2640 (0.2657)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [ 40/172]  eta: 0:03:31  lr: 0.000095  loss: 0.2671 (0.2664)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [ 50/172]  eta: 0:03:15  lr: 0.000095  loss: 0.2671 (0.2662)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [ 60/172]  eta: 0:02:58  lr: 0.000095  loss: 0.2659 (0.2660)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [ 70/172]  eta: 0:02:42  lr: 0.000095  loss: 0.2640 (0.2656)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [ 80/172]  eta: 0:02:26  lr: 0.000095  loss: 0.2629 (0.2650)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [ 90/172]  eta: 0:02:10  lr: 0.000095  loss: 0.2643 (0.2655)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [100/172]  eta: 0:01:54  lr: 0.000095  loss: 0.2570 (0.2652)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [110/172]  eta: 0:01:38  lr: 0.000095  loss: 0.2594 (0.2655)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [120/172]  eta: 0:01:22  lr: 0.000095  loss: 0.2663 (0.2660)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [130/172]  eta: 0:01:06  lr: 0.000095  loss: 0.2632 (0.2651)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [140/172]  eta: 0:00:50  lr: 0.000095  loss: 0.2576 (0.2650)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [150/172]  eta: 0:00:34  lr: 0.000095  loss: 0.2611 (0.2647)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [160/172]  eta: 0:00:19  lr: 0.000095  loss: 0.2610 (0.2648)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [170/172]  eta: 0:00:03  lr: 0.000095  loss: 0.2610 (0.2650)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150]  [171/172]  eta: 0:00:01  lr: 0.000095  loss: 0.2608 (0.2649)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:150] Total time: 0:04:32 (1.5846 s / it)\n",
      "Averaged stats: lr: 0.000095  loss: 0.2608 (0.2649)\n",
      "Valid: [epoch:150]  [ 0/14]  eta: 0:00:04  loss: 0.2316 (0.2316)  time: 0.3406  data: 0.3231  max mem: 20571\n",
      "Valid: [epoch:150]  [13/14]  eta: 0:00:00  loss: 0.2379 (0.2455)  time: 0.0384  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:150] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.2379 (0.2455)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_150_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.246%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:151]  [  0/172]  eta: 0:08:42  lr: 0.000094  loss: 0.2435 (0.2435)  time: 3.0358  data: 1.4674  max mem: 20571\n",
      "Train: [epoch:151]  [ 10/172]  eta: 0:04:36  lr: 0.000094  loss: 0.2656 (0.2650)  time: 1.7043  data: 0.1336  max mem: 20571\n",
      "Train: [epoch:151]  [ 20/172]  eta: 0:04:09  lr: 0.000094  loss: 0.2656 (0.2698)  time: 1.5723  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [ 30/172]  eta: 0:03:50  lr: 0.000094  loss: 0.2665 (0.2695)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [ 40/172]  eta: 0:03:32  lr: 0.000094  loss: 0.2637 (0.2679)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [ 50/172]  eta: 0:03:15  lr: 0.000094  loss: 0.2602 (0.2671)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [ 60/172]  eta: 0:02:59  lr: 0.000094  loss: 0.2638 (0.2680)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [ 70/172]  eta: 0:02:42  lr: 0.000094  loss: 0.2621 (0.2677)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [ 80/172]  eta: 0:02:26  lr: 0.000094  loss: 0.2608 (0.2662)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [ 90/172]  eta: 0:02:10  lr: 0.000094  loss: 0.2535 (0.2659)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [100/172]  eta: 0:01:54  lr: 0.000094  loss: 0.2634 (0.2656)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [110/172]  eta: 0:01:38  lr: 0.000094  loss: 0.2601 (0.2655)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [120/172]  eta: 0:01:22  lr: 0.000094  loss: 0.2629 (0.2653)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [130/172]  eta: 0:01:06  lr: 0.000094  loss: 0.2634 (0.2656)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [140/172]  eta: 0:00:50  lr: 0.000094  loss: 0.2635 (0.2653)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [150/172]  eta: 0:00:34  lr: 0.000094  loss: 0.2635 (0.2652)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [160/172]  eta: 0:00:19  lr: 0.000094  loss: 0.2701 (0.2659)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [170/172]  eta: 0:00:03  lr: 0.000094  loss: 0.2667 (0.2658)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151]  [171/172]  eta: 0:00:01  lr: 0.000094  loss: 0.2634 (0.2657)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:151] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000094  loss: 0.2634 (0.2657)\n",
      "Valid: [epoch:151]  [ 0/14]  eta: 0:00:07  loss: 0.2730 (0.2730)  time: 0.5074  data: 0.4918  max mem: 20571\n",
      "Valid: [epoch:151]  [13/14]  eta: 0:00:00  loss: 0.2474 (0.2551)  time: 0.0512  data: 0.0362  max mem: 20571\n",
      "Valid: [epoch:151] Total time: 0:00:00 (0.0570 s / it)\n",
      "Averaged stats: loss: 0.2474 (0.2551)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_151_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.255%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:152]  [  0/172]  eta: 0:07:48  lr: 0.000094  loss: 0.2778 (0.2778)  time: 2.7256  data: 1.1631  max mem: 20571\n",
      "Train: [epoch:152]  [ 10/172]  eta: 0:04:32  lr: 0.000094  loss: 0.2599 (0.2653)  time: 1.6801  data: 0.1058  max mem: 20571\n",
      "Train: [epoch:152]  [ 20/172]  eta: 0:04:07  lr: 0.000094  loss: 0.2618 (0.2661)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [ 30/172]  eta: 0:03:49  lr: 0.000094  loss: 0.2665 (0.2668)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [ 40/172]  eta: 0:03:31  lr: 0.000094  loss: 0.2639 (0.2671)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [ 50/172]  eta: 0:03:15  lr: 0.000094  loss: 0.2659 (0.2671)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [ 60/172]  eta: 0:02:58  lr: 0.000094  loss: 0.2668 (0.2667)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [ 70/172]  eta: 0:02:42  lr: 0.000094  loss: 0.2716 (0.2677)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [ 80/172]  eta: 0:02:26  lr: 0.000094  loss: 0.2712 (0.2678)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [ 90/172]  eta: 0:02:10  lr: 0.000094  loss: 0.2636 (0.2683)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [100/172]  eta: 0:01:54  lr: 0.000094  loss: 0.2642 (0.2682)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [110/172]  eta: 0:01:38  lr: 0.000094  loss: 0.2675 (0.2686)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [120/172]  eta: 0:01:22  lr: 0.000094  loss: 0.2609 (0.2684)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [130/172]  eta: 0:01:06  lr: 0.000094  loss: 0.2616 (0.2684)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [140/172]  eta: 0:00:50  lr: 0.000094  loss: 0.2708 (0.2688)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [150/172]  eta: 0:00:34  lr: 0.000094  loss: 0.2661 (0.2686)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [160/172]  eta: 0:00:19  lr: 0.000094  loss: 0.2661 (0.2685)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [170/172]  eta: 0:00:03  lr: 0.000094  loss: 0.2657 (0.2687)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152]  [171/172]  eta: 0:00:01  lr: 0.000094  loss: 0.2699 (0.2687)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:152] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000094  loss: 0.2699 (0.2687)\n",
      "Valid: [epoch:152]  [ 0/14]  eta: 0:00:04  loss: 0.2628 (0.2628)  time: 0.3448  data: 0.3267  max mem: 20571\n",
      "Valid: [epoch:152]  [13/14]  eta: 0:00:00  loss: 0.2682 (0.2742)  time: 0.0395  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:152] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.2682 (0.2742)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_152_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.274%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:153]  [  0/172]  eta: 0:08:21  lr: 0.000094  loss: 0.2871 (0.2871)  time: 2.9130  data: 1.3368  max mem: 20571\n",
      "Train: [epoch:153]  [ 10/172]  eta: 0:04:35  lr: 0.000094  loss: 0.2618 (0.2669)  time: 1.6980  data: 0.1217  max mem: 20571\n",
      "Train: [epoch:153]  [ 20/172]  eta: 0:04:09  lr: 0.000094  loss: 0.2705 (0.2735)  time: 1.5757  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:153]  [ 30/172]  eta: 0:03:49  lr: 0.000094  loss: 0.2741 (0.2717)  time: 1.5758  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:153]  [ 40/172]  eta: 0:03:32  lr: 0.000094  loss: 0.2697 (0.2719)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:153]  [ 50/172]  eta: 0:03:15  lr: 0.000094  loss: 0.2732 (0.2726)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:153]  [ 60/172]  eta: 0:02:59  lr: 0.000094  loss: 0.2681 (0.2722)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:153]  [ 70/172]  eta: 0:02:42  lr: 0.000094  loss: 0.2627 (0.2732)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:153]  [ 80/172]  eta: 0:02:26  lr: 0.000094  loss: 0.2674 (0.2727)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:153]  [ 90/172]  eta: 0:02:10  lr: 0.000094  loss: 0.2661 (0.2724)  time: 1.5796  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:153]  [100/172]  eta: 0:01:54  lr: 0.000094  loss: 0.2661 (0.2713)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:153]  [110/172]  eta: 0:01:38  lr: 0.000094  loss: 0.2642 (0.2709)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:153]  [120/172]  eta: 0:01:22  lr: 0.000094  loss: 0.2642 (0.2704)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:153]  [130/172]  eta: 0:01:06  lr: 0.000094  loss: 0.2675 (0.2702)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:153]  [140/172]  eta: 0:00:50  lr: 0.000094  loss: 0.2675 (0.2702)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:153]  [150/172]  eta: 0:00:34  lr: 0.000094  loss: 0.2674 (0.2703)  time: 1.5775  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:153]  [160/172]  eta: 0:00:19  lr: 0.000094  loss: 0.2663 (0.2702)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:153]  [170/172]  eta: 0:00:03  lr: 0.000094  loss: 0.2643 (0.2700)  time: 1.5794  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:153]  [171/172]  eta: 0:00:01  lr: 0.000094  loss: 0.2643 (0.2701)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:153] Total time: 0:04:32 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000094  loss: 0.2643 (0.2701)\n",
      "Valid: [epoch:153]  [ 0/14]  eta: 0:00:05  loss: 0.2393 (0.2393)  time: 0.3642  data: 0.3493  max mem: 20571\n",
      "Valid: [epoch:153]  [13/14]  eta: 0:00:00  loss: 0.2456 (0.2527)  time: 0.0410  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:153] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.2456 (0.2527)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_153_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.253%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:154]  [  0/172]  eta: 0:07:58  lr: 0.000094  loss: 0.2587 (0.2587)  time: 2.7832  data: 1.2180  max mem: 20571\n",
      "Train: [epoch:154]  [ 10/172]  eta: 0:04:33  lr: 0.000094  loss: 0.2706 (0.2725)  time: 1.6861  data: 0.1108  max mem: 20571\n",
      "Train: [epoch:154]  [ 20/172]  eta: 0:04:08  lr: 0.000094  loss: 0.2728 (0.2723)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [ 30/172]  eta: 0:03:49  lr: 0.000094  loss: 0.2670 (0.2728)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [ 40/172]  eta: 0:03:32  lr: 0.000094  loss: 0.2648 (0.2731)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [ 50/172]  eta: 0:03:15  lr: 0.000094  loss: 0.2740 (0.2735)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [ 60/172]  eta: 0:02:58  lr: 0.000094  loss: 0.2740 (0.2734)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [ 70/172]  eta: 0:02:42  lr: 0.000094  loss: 0.2681 (0.2730)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [ 80/172]  eta: 0:02:26  lr: 0.000094  loss: 0.2627 (0.2725)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [ 90/172]  eta: 0:02:10  lr: 0.000094  loss: 0.2697 (0.2727)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [100/172]  eta: 0:01:54  lr: 0.000094  loss: 0.2651 (0.2723)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [110/172]  eta: 0:01:38  lr: 0.000094  loss: 0.2651 (0.2719)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [120/172]  eta: 0:01:22  lr: 0.000094  loss: 0.2636 (0.2715)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:154]  [130/172]  eta: 0:01:06  lr: 0.000094  loss: 0.2666 (0.2714)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:154]  [140/172]  eta: 0:00:50  lr: 0.000094  loss: 0.2676 (0.2711)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [150/172]  eta: 0:00:34  lr: 0.000094  loss: 0.2712 (0.2713)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [160/172]  eta: 0:00:19  lr: 0.000094  loss: 0.2712 (0.2711)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [170/172]  eta: 0:00:03  lr: 0.000094  loss: 0.2712 (0.2714)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154]  [171/172]  eta: 0:00:01  lr: 0.000094  loss: 0.2712 (0.2713)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:154] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000094  loss: 0.2712 (0.2713)\n",
      "Valid: [epoch:154]  [ 0/14]  eta: 0:00:04  loss: 0.2263 (0.2263)  time: 0.2896  data: 0.2743  max mem: 20571\n",
      "Valid: [epoch:154]  [13/14]  eta: 0:00:00  loss: 0.2417 (0.2488)  time: 0.0363  data: 0.0213  max mem: 20571\n",
      "Valid: [epoch:154] Total time: 0:00:00 (0.0410 s / it)\n",
      "Averaged stats: loss: 0.2417 (0.2488)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_154_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.249%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:155]  [  0/172]  eta: 0:07:56  lr: 0.000094  loss: 0.2547 (0.2547)  time: 2.7677  data: 1.1901  max mem: 20571\n",
      "Train: [epoch:155]  [ 10/172]  eta: 0:04:32  lr: 0.000094  loss: 0.2714 (0.2734)  time: 1.6830  data: 0.1083  max mem: 20571\n",
      "Train: [epoch:155]  [ 20/172]  eta: 0:04:07  lr: 0.000094  loss: 0.2714 (0.2741)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [ 30/172]  eta: 0:03:49  lr: 0.000094  loss: 0.2651 (0.2726)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [ 40/172]  eta: 0:03:31  lr: 0.000094  loss: 0.2699 (0.2729)  time: 1.5758  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:155]  [ 50/172]  eta: 0:03:15  lr: 0.000094  loss: 0.2719 (0.2724)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [ 60/172]  eta: 0:02:58  lr: 0.000094  loss: 0.2737 (0.2736)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [ 70/172]  eta: 0:02:42  lr: 0.000094  loss: 0.2733 (0.2733)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [ 80/172]  eta: 0:02:26  lr: 0.000094  loss: 0.2733 (0.2739)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [ 90/172]  eta: 0:02:10  lr: 0.000094  loss: 0.2719 (0.2739)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [100/172]  eta: 0:01:54  lr: 0.000094  loss: 0.2692 (0.2734)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [110/172]  eta: 0:01:38  lr: 0.000094  loss: 0.2691 (0.2736)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [120/172]  eta: 0:01:22  lr: 0.000094  loss: 0.2698 (0.2739)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [130/172]  eta: 0:01:06  lr: 0.000094  loss: 0.2723 (0.2742)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:155]  [140/172]  eta: 0:00:50  lr: 0.000094  loss: 0.2702 (0.2742)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:155]  [150/172]  eta: 0:00:34  lr: 0.000094  loss: 0.2707 (0.2741)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:155]  [160/172]  eta: 0:00:19  lr: 0.000094  loss: 0.2687 (0.2740)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:155]  [170/172]  eta: 0:00:03  lr: 0.000094  loss: 0.2660 (0.2739)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155]  [171/172]  eta: 0:00:01  lr: 0.000094  loss: 0.2667 (0.2740)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:155] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000094  loss: 0.2667 (0.2740)\n",
      "Valid: [epoch:155]  [ 0/14]  eta: 0:00:04  loss: 0.2675 (0.2675)  time: 0.3046  data: 0.2897  max mem: 20571\n",
      "Valid: [epoch:155]  [13/14]  eta: 0:00:00  loss: 0.2427 (0.2499)  time: 0.0379  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:155] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.2427 (0.2499)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_155_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.250%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:156]  [  0/172]  eta: 0:08:15  lr: 0.000094  loss: 0.2627 (0.2627)  time: 2.8833  data: 1.3061  max mem: 20571\n",
      "Train: [epoch:156]  [ 10/172]  eta: 0:04:34  lr: 0.000094  loss: 0.2721 (0.2732)  time: 1.6967  data: 0.1189  max mem: 20571\n",
      "Train: [epoch:156]  [ 20/172]  eta: 0:04:09  lr: 0.000094  loss: 0.2721 (0.2732)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [ 30/172]  eta: 0:03:50  lr: 0.000094  loss: 0.2704 (0.2732)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [ 40/172]  eta: 0:03:32  lr: 0.000094  loss: 0.2761 (0.2743)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [ 50/172]  eta: 0:03:15  lr: 0.000094  loss: 0.2751 (0.2746)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [ 60/172]  eta: 0:02:59  lr: 0.000094  loss: 0.2689 (0.2742)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [ 70/172]  eta: 0:02:42  lr: 0.000094  loss: 0.2661 (0.2744)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [ 80/172]  eta: 0:02:26  lr: 0.000094  loss: 0.2736 (0.2753)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [ 90/172]  eta: 0:02:10  lr: 0.000094  loss: 0.2714 (0.2747)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [100/172]  eta: 0:01:54  lr: 0.000094  loss: 0.2675 (0.2744)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [110/172]  eta: 0:01:38  lr: 0.000094  loss: 0.2682 (0.2743)  time: 1.5807  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:156]  [120/172]  eta: 0:01:22  lr: 0.000094  loss: 0.2764 (0.2745)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [130/172]  eta: 0:01:06  lr: 0.000094  loss: 0.2755 (0.2745)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [140/172]  eta: 0:00:50  lr: 0.000094  loss: 0.2649 (0.2742)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [150/172]  eta: 0:00:34  lr: 0.000094  loss: 0.2699 (0.2746)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [160/172]  eta: 0:00:19  lr: 0.000094  loss: 0.2774 (0.2745)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [170/172]  eta: 0:00:03  lr: 0.000094  loss: 0.2724 (0.2747)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156]  [171/172]  eta: 0:00:01  lr: 0.000094  loss: 0.2753 (0.2748)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:156] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000094  loss: 0.2753 (0.2748)\n",
      "Valid: [epoch:156]  [ 0/14]  eta: 0:00:04  loss: 0.2653 (0.2653)  time: 0.3162  data: 0.3003  max mem: 20571\n",
      "Valid: [epoch:156]  [13/14]  eta: 0:00:00  loss: 0.2695 (0.2759)  time: 0.0441  data: 0.0289  max mem: 20571\n",
      "Valid: [epoch:156] Total time: 0:00:00 (0.0522 s / it)\n",
      "Averaged stats: loss: 0.2695 (0.2759)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_156_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.276%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:157]  [  0/172]  eta: 0:07:46  lr: 0.000094  loss: 0.2793 (0.2793)  time: 2.7110  data: 1.1363  max mem: 20571\n",
      "Train: [epoch:157]  [ 10/172]  eta: 0:04:31  lr: 0.000094  loss: 0.2822 (0.2807)  time: 1.6777  data: 0.1034  max mem: 20571\n",
      "Train: [epoch:157]  [ 20/172]  eta: 0:04:07  lr: 0.000094  loss: 0.2808 (0.2796)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [ 30/172]  eta: 0:03:49  lr: 0.000094  loss: 0.2714 (0.2763)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [ 40/172]  eta: 0:03:31  lr: 0.000094  loss: 0.2703 (0.2761)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [ 50/172]  eta: 0:03:15  lr: 0.000094  loss: 0.2724 (0.2755)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [ 60/172]  eta: 0:02:58  lr: 0.000094  loss: 0.2736 (0.2756)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [ 70/172]  eta: 0:02:42  lr: 0.000094  loss: 0.2736 (0.2753)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [ 80/172]  eta: 0:02:26  lr: 0.000094  loss: 0.2716 (0.2757)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [ 90/172]  eta: 0:02:10  lr: 0.000094  loss: 0.2772 (0.2760)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [100/172]  eta: 0:01:54  lr: 0.000094  loss: 0.2805 (0.2768)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [110/172]  eta: 0:01:38  lr: 0.000094  loss: 0.2798 (0.2771)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [120/172]  eta: 0:01:22  lr: 0.000094  loss: 0.2725 (0.2773)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [130/172]  eta: 0:01:06  lr: 0.000094  loss: 0.2843 (0.2778)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [140/172]  eta: 0:00:50  lr: 0.000094  loss: 0.2768 (0.2775)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [150/172]  eta: 0:00:34  lr: 0.000094  loss: 0.2706 (0.2768)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [160/172]  eta: 0:00:19  lr: 0.000094  loss: 0.2731 (0.2768)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [170/172]  eta: 0:00:03  lr: 0.000094  loss: 0.2732 (0.2764)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157]  [171/172]  eta: 0:00:01  lr: 0.000094  loss: 0.2708 (0.2763)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:157] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000094  loss: 0.2708 (0.2763)\n",
      "Valid: [epoch:157]  [ 0/14]  eta: 0:00:04  loss: 0.2648 (0.2648)  time: 0.3186  data: 0.3021  max mem: 20571\n",
      "Valid: [epoch:157]  [13/14]  eta: 0:00:00  loss: 0.2648 (0.2719)  time: 0.0417  data: 0.0266  max mem: 20571\n",
      "Valid: [epoch:157] Total time: 0:00:00 (0.0473 s / it)\n",
      "Averaged stats: loss: 0.2648 (0.2719)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_157_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.272%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:158]  [  0/172]  eta: 0:08:15  lr: 0.000094  loss: 0.2495 (0.2495)  time: 2.8784  data: 1.3138  max mem: 20571\n",
      "Train: [epoch:158]  [ 10/172]  eta: 0:04:34  lr: 0.000094  loss: 0.2806 (0.2813)  time: 1.6961  data: 0.1195  max mem: 20571\n",
      "Train: [epoch:158]  [ 20/172]  eta: 0:04:09  lr: 0.000094  loss: 0.2815 (0.2803)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [ 30/172]  eta: 0:03:50  lr: 0.000094  loss: 0.2815 (0.2793)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [ 40/172]  eta: 0:03:32  lr: 0.000094  loss: 0.2746 (0.2785)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [ 50/172]  eta: 0:03:15  lr: 0.000094  loss: 0.2776 (0.2801)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [ 60/172]  eta: 0:02:59  lr: 0.000094  loss: 0.2749 (0.2793)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [ 70/172]  eta: 0:02:42  lr: 0.000094  loss: 0.2748 (0.2787)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [ 80/172]  eta: 0:02:26  lr: 0.000094  loss: 0.2749 (0.2778)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [ 90/172]  eta: 0:02:10  lr: 0.000094  loss: 0.2748 (0.2790)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [100/172]  eta: 0:01:54  lr: 0.000094  loss: 0.2748 (0.2790)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [110/172]  eta: 0:01:38  lr: 0.000094  loss: 0.2767 (0.2787)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [120/172]  eta: 0:01:22  lr: 0.000094  loss: 0.2761 (0.2783)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:158]  [130/172]  eta: 0:01:06  lr: 0.000094  loss: 0.2751 (0.2780)  time: 1.5773  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:158]  [140/172]  eta: 0:00:50  lr: 0.000094  loss: 0.2760 (0.2778)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [150/172]  eta: 0:00:34  lr: 0.000094  loss: 0.2786 (0.2781)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:158]  [160/172]  eta: 0:00:19  lr: 0.000094  loss: 0.2743 (0.2779)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:158]  [170/172]  eta: 0:00:03  lr: 0.000094  loss: 0.2744 (0.2781)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158]  [171/172]  eta: 0:00:01  lr: 0.000094  loss: 0.2744 (0.2780)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:158] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000094  loss: 0.2744 (0.2780)\n",
      "Valid: [epoch:158]  [ 0/14]  eta: 0:00:04  loss: 0.2481 (0.2481)  time: 0.3241  data: 0.3094  max mem: 20571\n",
      "Valid: [epoch:158]  [13/14]  eta: 0:00:00  loss: 0.2556 (0.2625)  time: 0.0372  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:158] Total time: 0:00:00 (0.0444 s / it)\n",
      "Averaged stats: loss: 0.2556 (0.2625)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_158_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.262%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:159]  [  0/172]  eta: 0:08:26  lr: 0.000094  loss: 0.2921 (0.2921)  time: 2.9446  data: 1.3623  max mem: 20571\n",
      "Train: [epoch:159]  [ 10/172]  eta: 0:04:35  lr: 0.000094  loss: 0.2725 (0.2806)  time: 1.6987  data: 0.1240  max mem: 20571\n",
      "Train: [epoch:159]  [ 20/172]  eta: 0:04:09  lr: 0.000094  loss: 0.2725 (0.2786)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [ 30/172]  eta: 0:03:50  lr: 0.000094  loss: 0.2752 (0.2781)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [ 40/172]  eta: 0:03:32  lr: 0.000094  loss: 0.2791 (0.2790)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [ 50/172]  eta: 0:03:15  lr: 0.000094  loss: 0.2879 (0.2802)  time: 1.5805  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:159]  [ 60/172]  eta: 0:02:59  lr: 0.000094  loss: 0.2780 (0.2794)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [ 70/172]  eta: 0:02:42  lr: 0.000094  loss: 0.2787 (0.2810)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [ 80/172]  eta: 0:02:26  lr: 0.000094  loss: 0.2831 (0.2811)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [ 90/172]  eta: 0:02:10  lr: 0.000094  loss: 0.2812 (0.2816)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [100/172]  eta: 0:01:54  lr: 0.000094  loss: 0.2823 (0.2824)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [110/172]  eta: 0:01:38  lr: 0.000094  loss: 0.2827 (0.2828)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [120/172]  eta: 0:01:22  lr: 0.000094  loss: 0.2806 (0.2828)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [130/172]  eta: 0:01:06  lr: 0.000094  loss: 0.2792 (0.2825)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [140/172]  eta: 0:00:50  lr: 0.000094  loss: 0.2827 (0.2826)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [150/172]  eta: 0:00:34  lr: 0.000094  loss: 0.2777 (0.2823)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [160/172]  eta: 0:00:19  lr: 0.000094  loss: 0.2758 (0.2818)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [170/172]  eta: 0:00:03  lr: 0.000094  loss: 0.2701 (0.2814)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159]  [171/172]  eta: 0:00:01  lr: 0.000094  loss: 0.2745 (0.2814)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:159] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000094  loss: 0.2745 (0.2814)\n",
      "Valid: [epoch:159]  [ 0/14]  eta: 0:00:06  loss: 0.2394 (0.2394)  time: 0.4597  data: 0.4450  max mem: 20571\n",
      "Valid: [epoch:159]  [13/14]  eta: 0:00:00  loss: 0.2650 (0.2726)  time: 0.0476  data: 0.0326  max mem: 20571\n",
      "Valid: [epoch:159] Total time: 0:00:00 (0.0528 s / it)\n",
      "Averaged stats: loss: 0.2650 (0.2726)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_159_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.273%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:160]  [  0/172]  eta: 0:07:43  lr: 0.000093  loss: 0.2524 (0.2524)  time: 2.6958  data: 1.1312  max mem: 20571\n",
      "Train: [epoch:160]  [ 10/172]  eta: 0:04:31  lr: 0.000093  loss: 0.2805 (0.2807)  time: 1.6787  data: 0.1029  max mem: 20571\n",
      "Train: [epoch:160]  [ 20/172]  eta: 0:04:07  lr: 0.000093  loss: 0.2835 (0.2832)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [ 30/172]  eta: 0:03:49  lr: 0.000093  loss: 0.2722 (0.2788)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [ 40/172]  eta: 0:03:32  lr: 0.000093  loss: 0.2722 (0.2793)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [ 50/172]  eta: 0:03:15  lr: 0.000093  loss: 0.2770 (0.2793)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [ 60/172]  eta: 0:02:58  lr: 0.000093  loss: 0.2772 (0.2796)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [ 70/172]  eta: 0:02:42  lr: 0.000093  loss: 0.2804 (0.2795)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [ 80/172]  eta: 0:02:26  lr: 0.000093  loss: 0.2804 (0.2788)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [ 90/172]  eta: 0:02:10  lr: 0.000093  loss: 0.2713 (0.2792)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [100/172]  eta: 0:01:54  lr: 0.000093  loss: 0.2793 (0.2794)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [110/172]  eta: 0:01:38  lr: 0.000093  loss: 0.2854 (0.2791)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [120/172]  eta: 0:01:22  lr: 0.000093  loss: 0.2733 (0.2789)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [130/172]  eta: 0:01:06  lr: 0.000093  loss: 0.2753 (0.2793)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [140/172]  eta: 0:00:50  lr: 0.000093  loss: 0.2916 (0.2800)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [150/172]  eta: 0:00:34  lr: 0.000093  loss: 0.2782 (0.2800)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [160/172]  eta: 0:00:19  lr: 0.000093  loss: 0.2758 (0.2798)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [170/172]  eta: 0:00:03  lr: 0.000093  loss: 0.2758 (0.2799)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160]  [171/172]  eta: 0:00:01  lr: 0.000093  loss: 0.2758 (0.2799)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:160] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000093  loss: 0.2758 (0.2799)\n",
      "Valid: [epoch:160]  [ 0/14]  eta: 0:00:04  loss: 0.3050 (0.3050)  time: 0.3036  data: 0.2874  max mem: 20571\n",
      "Valid: [epoch:160]  [13/14]  eta: 0:00:00  loss: 0.2821 (0.2893)  time: 0.0366  data: 0.0216  max mem: 20571\n",
      "Valid: [epoch:160] Total time: 0:00:00 (0.0440 s / it)\n",
      "Averaged stats: loss: 0.2821 (0.2893)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_160_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.289%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:161]  [  0/172]  eta: 0:08:01  lr: 0.000093  loss: 0.3418 (0.3418)  time: 2.7987  data: 1.2204  max mem: 20571\n",
      "Train: [epoch:161]  [ 10/172]  eta: 0:04:33  lr: 0.000093  loss: 0.2871 (0.2869)  time: 1.6857  data: 0.1111  max mem: 20571\n",
      "Train: [epoch:161]  [ 20/172]  eta: 0:04:08  lr: 0.000093  loss: 0.2819 (0.2861)  time: 1.5767  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:161]  [ 30/172]  eta: 0:03:49  lr: 0.000093  loss: 0.2819 (0.2861)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [ 40/172]  eta: 0:03:32  lr: 0.000093  loss: 0.2780 (0.2849)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [ 50/172]  eta: 0:03:15  lr: 0.000093  loss: 0.2815 (0.2844)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [ 60/172]  eta: 0:02:58  lr: 0.000093  loss: 0.2834 (0.2843)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [ 70/172]  eta: 0:02:42  lr: 0.000093  loss: 0.2818 (0.2836)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [ 80/172]  eta: 0:02:26  lr: 0.000093  loss: 0.2812 (0.2837)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [ 90/172]  eta: 0:02:10  lr: 0.000093  loss: 0.2791 (0.2832)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [100/172]  eta: 0:01:54  lr: 0.000093  loss: 0.2793 (0.2837)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [110/172]  eta: 0:01:38  lr: 0.000093  loss: 0.2860 (0.2835)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [120/172]  eta: 0:01:22  lr: 0.000093  loss: 0.2786 (0.2832)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [130/172]  eta: 0:01:06  lr: 0.000093  loss: 0.2835 (0.2833)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [140/172]  eta: 0:00:50  lr: 0.000093  loss: 0.2835 (0.2831)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [150/172]  eta: 0:00:34  lr: 0.000093  loss: 0.2780 (0.2827)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [160/172]  eta: 0:00:19  lr: 0.000093  loss: 0.2761 (0.2827)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [170/172]  eta: 0:00:03  lr: 0.000093  loss: 0.2821 (0.2830)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161]  [171/172]  eta: 0:00:01  lr: 0.000093  loss: 0.2835 (0.2831)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:161] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000093  loss: 0.2835 (0.2831)\n",
      "Valid: [epoch:161]  [ 0/14]  eta: 0:00:05  loss: 0.2685 (0.2685)  time: 0.3596  data: 0.3443  max mem: 20571\n",
      "Valid: [epoch:161]  [13/14]  eta: 0:00:00  loss: 0.2685 (0.2759)  time: 0.0413  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:161] Total time: 0:00:00 (0.0492 s / it)\n",
      "Averaged stats: loss: 0.2685 (0.2759)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_161_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.276%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:162]  [  0/172]  eta: 0:07:22  lr: 0.000093  loss: 0.2882 (0.2882)  time: 2.5729  data: 1.0105  max mem: 20571\n",
      "Train: [epoch:162]  [ 10/172]  eta: 0:04:29  lr: 0.000093  loss: 0.2882 (0.2915)  time: 1.6657  data: 0.0920  max mem: 20571\n",
      "Train: [epoch:162]  [ 20/172]  eta: 0:04:06  lr: 0.000093  loss: 0.2878 (0.2894)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [ 30/172]  eta: 0:03:48  lr: 0.000093  loss: 0.2816 (0.2880)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [ 40/172]  eta: 0:03:31  lr: 0.000093  loss: 0.2829 (0.2879)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [ 50/172]  eta: 0:03:14  lr: 0.000093  loss: 0.2899 (0.2881)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [ 60/172]  eta: 0:02:58  lr: 0.000093  loss: 0.2832 (0.2870)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [ 70/172]  eta: 0:02:42  lr: 0.000093  loss: 0.2811 (0.2864)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [ 80/172]  eta: 0:02:26  lr: 0.000093  loss: 0.2817 (0.2864)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [ 90/172]  eta: 0:02:10  lr: 0.000093  loss: 0.2857 (0.2864)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [100/172]  eta: 0:01:54  lr: 0.000093  loss: 0.2843 (0.2861)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [110/172]  eta: 0:01:38  lr: 0.000093  loss: 0.2755 (0.2857)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [120/172]  eta: 0:01:22  lr: 0.000093  loss: 0.2755 (0.2859)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [130/172]  eta: 0:01:06  lr: 0.000093  loss: 0.2856 (0.2855)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [140/172]  eta: 0:00:50  lr: 0.000093  loss: 0.2843 (0.2853)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [150/172]  eta: 0:00:34  lr: 0.000093  loss: 0.2817 (0.2852)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [160/172]  eta: 0:00:19  lr: 0.000093  loss: 0.2817 (0.2851)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [170/172]  eta: 0:00:03  lr: 0.000093  loss: 0.2823 (0.2851)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162]  [171/172]  eta: 0:00:01  lr: 0.000093  loss: 0.2809 (0.2850)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:162] Total time: 0:04:32 (1.5837 s / it)\n",
      "Averaged stats: lr: 0.000093  loss: 0.2809 (0.2850)\n",
      "Valid: [epoch:162]  [ 0/14]  eta: 0:00:04  loss: 0.2285 (0.2285)  time: 0.2898  data: 0.2741  max mem: 20571\n",
      "Valid: [epoch:162]  [13/14]  eta: 0:00:00  loss: 0.2564 (0.2644)  time: 0.0599  data: 0.0449  max mem: 20571\n",
      "Valid: [epoch:162] Total time: 0:00:00 (0.0653 s / it)\n",
      "Averaged stats: loss: 0.2564 (0.2644)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_162_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.264%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:163]  [  0/172]  eta: 0:07:28  lr: 0.000093  loss: 0.2593 (0.2593)  time: 2.6104  data: 1.0363  max mem: 20571\n",
      "Train: [epoch:163]  [ 10/172]  eta: 0:04:30  lr: 0.000093  loss: 0.2797 (0.2833)  time: 1.6690  data: 0.0943  max mem: 20571\n",
      "Train: [epoch:163]  [ 20/172]  eta: 0:04:06  lr: 0.000093  loss: 0.2803 (0.2842)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [ 30/172]  eta: 0:03:48  lr: 0.000093  loss: 0.2819 (0.2843)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [ 40/172]  eta: 0:03:31  lr: 0.000093  loss: 0.2864 (0.2862)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [ 50/172]  eta: 0:03:14  lr: 0.000093  loss: 0.2913 (0.2874)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [ 60/172]  eta: 0:02:58  lr: 0.000093  loss: 0.2863 (0.2866)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [ 70/172]  eta: 0:02:42  lr: 0.000093  loss: 0.2848 (0.2869)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [ 80/172]  eta: 0:02:26  lr: 0.000093  loss: 0.2848 (0.2868)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [ 90/172]  eta: 0:02:10  lr: 0.000093  loss: 0.2872 (0.2871)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [100/172]  eta: 0:01:54  lr: 0.000093  loss: 0.2877 (0.2866)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [110/172]  eta: 0:01:38  lr: 0.000093  loss: 0.2857 (0.2864)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [120/172]  eta: 0:01:22  lr: 0.000093  loss: 0.2843 (0.2862)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [130/172]  eta: 0:01:06  lr: 0.000093  loss: 0.2807 (0.2863)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [140/172]  eta: 0:00:50  lr: 0.000093  loss: 0.2807 (0.2863)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [150/172]  eta: 0:00:34  lr: 0.000093  loss: 0.2813 (0.2863)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [160/172]  eta: 0:00:19  lr: 0.000093  loss: 0.2830 (0.2865)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [170/172]  eta: 0:00:03  lr: 0.000093  loss: 0.2853 (0.2865)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163]  [171/172]  eta: 0:00:01  lr: 0.000093  loss: 0.2853 (0.2864)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:163] Total time: 0:04:32 (1.5856 s / it)\n",
      "Averaged stats: lr: 0.000093  loss: 0.2853 (0.2864)\n",
      "Valid: [epoch:163]  [ 0/14]  eta: 0:00:04  loss: 0.2782 (0.2782)  time: 0.2986  data: 0.2827  max mem: 20571\n",
      "Valid: [epoch:163]  [13/14]  eta: 0:00:00  loss: 0.2782 (0.2862)  time: 0.0390  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:163] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.2782 (0.2862)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_163_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.286%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:164]  [  0/172]  eta: 0:07:55  lr: 0.000093  loss: 0.2892 (0.2892)  time: 2.7625  data: 1.1982  max mem: 20571\n",
      "Train: [epoch:164]  [ 10/172]  eta: 0:04:33  lr: 0.000093  loss: 0.2896 (0.2859)  time: 1.6862  data: 0.1091  max mem: 20571\n",
      "Train: [epoch:164]  [ 20/172]  eta: 0:04:08  lr: 0.000093  loss: 0.2910 (0.2940)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:164]  [ 30/172]  eta: 0:03:49  lr: 0.000093  loss: 0.2966 (0.2920)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:164]  [ 40/172]  eta: 0:03:32  lr: 0.000093  loss: 0.2814 (0.2896)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:164]  [ 50/172]  eta: 0:03:15  lr: 0.000093  loss: 0.2800 (0.2894)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:164]  [ 60/172]  eta: 0:02:58  lr: 0.000093  loss: 0.2800 (0.2879)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:164]  [ 70/172]  eta: 0:02:42  lr: 0.000093  loss: 0.2787 (0.2879)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:164]  [ 80/172]  eta: 0:02:26  lr: 0.000093  loss: 0.2879 (0.2887)  time: 1.5768  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:164]  [ 90/172]  eta: 0:02:10  lr: 0.000093  loss: 0.2912 (0.2890)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:164]  [100/172]  eta: 0:01:54  lr: 0.000093  loss: 0.2919 (0.2890)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:164]  [110/172]  eta: 0:01:38  lr: 0.000093  loss: 0.2874 (0.2889)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:164]  [120/172]  eta: 0:01:22  lr: 0.000093  loss: 0.2806 (0.2885)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:164]  [130/172]  eta: 0:01:06  lr: 0.000093  loss: 0.2807 (0.2882)  time: 1.5777  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:164]  [140/172]  eta: 0:00:50  lr: 0.000093  loss: 0.2861 (0.2882)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:164]  [150/172]  eta: 0:00:34  lr: 0.000093  loss: 0.2863 (0.2884)  time: 1.5776  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:164]  [160/172]  eta: 0:00:19  lr: 0.000093  loss: 0.2900 (0.2884)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:164]  [170/172]  eta: 0:00:03  lr: 0.000093  loss: 0.2900 (0.2885)  time: 1.5782  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:164]  [171/172]  eta: 0:00:01  lr: 0.000093  loss: 0.2891 (0.2884)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:164] Total time: 0:04:32 (1.5856 s / it)\n",
      "Averaged stats: lr: 0.000093  loss: 0.2891 (0.2884)\n",
      "Valid: [epoch:164]  [ 0/14]  eta: 0:00:03  loss: 0.2564 (0.2564)  time: 0.2802  data: 0.2643  max mem: 20571\n",
      "Valid: [epoch:164]  [13/14]  eta: 0:00:00  loss: 0.2574 (0.2657)  time: 0.0460  data: 0.0310  max mem: 20571\n",
      "Valid: [epoch:164] Total time: 0:00:00 (0.0521 s / it)\n",
      "Averaged stats: loss: 0.2574 (0.2657)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_164_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.266%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:165]  [  0/172]  eta: 0:07:33  lr: 0.000093  loss: 0.2528 (0.2528)  time: 2.6392  data: 1.0680  max mem: 20571\n",
      "Train: [epoch:165]  [ 10/172]  eta: 0:04:30  lr: 0.000093  loss: 0.2904 (0.2905)  time: 1.6699  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:165]  [ 20/172]  eta: 0:04:07  lr: 0.000093  loss: 0.2904 (0.2891)  time: 1.5747  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:165]  [ 30/172]  eta: 0:03:48  lr: 0.000093  loss: 0.2854 (0.2875)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [ 40/172]  eta: 0:03:31  lr: 0.000093  loss: 0.2893 (0.2888)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [ 50/172]  eta: 0:03:14  lr: 0.000093  loss: 0.2958 (0.2893)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [ 60/172]  eta: 0:02:58  lr: 0.000093  loss: 0.2930 (0.2900)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [ 70/172]  eta: 0:02:42  lr: 0.000093  loss: 0.2948 (0.2895)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [ 80/172]  eta: 0:02:26  lr: 0.000093  loss: 0.2962 (0.2894)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [ 90/172]  eta: 0:02:10  lr: 0.000093  loss: 0.2825 (0.2889)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [100/172]  eta: 0:01:54  lr: 0.000093  loss: 0.2900 (0.2892)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [110/172]  eta: 0:01:38  lr: 0.000093  loss: 0.2920 (0.2904)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [120/172]  eta: 0:01:22  lr: 0.000093  loss: 0.3014 (0.2909)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [130/172]  eta: 0:01:06  lr: 0.000093  loss: 0.2950 (0.2903)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [140/172]  eta: 0:00:50  lr: 0.000093  loss: 0.2789 (0.2899)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [150/172]  eta: 0:00:34  lr: 0.000093  loss: 0.2847 (0.2902)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [160/172]  eta: 0:00:18  lr: 0.000093  loss: 0.2881 (0.2901)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [170/172]  eta: 0:00:03  lr: 0.000093  loss: 0.2827 (0.2901)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165]  [171/172]  eta: 0:00:01  lr: 0.000093  loss: 0.2858 (0.2901)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:165] Total time: 0:04:32 (1.5830 s / it)\n",
      "Averaged stats: lr: 0.000093  loss: 0.2858 (0.2901)\n",
      "Valid: [epoch:165]  [ 0/14]  eta: 0:00:04  loss: 0.2875 (0.2875)  time: 0.2945  data: 0.2794  max mem: 20571\n",
      "Valid: [epoch:165]  [13/14]  eta: 0:00:00  loss: 0.2613 (0.2694)  time: 0.0373  data: 0.0223  max mem: 20571\n",
      "Valid: [epoch:165] Total time: 0:00:00 (0.0442 s / it)\n",
      "Averaged stats: loss: 0.2613 (0.2694)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_165_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.269%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:166]  [  0/172]  eta: 0:07:22  lr: 0.000093  loss: 0.2774 (0.2774)  time: 2.5713  data: 1.0059  max mem: 20571\n",
      "Train: [epoch:166]  [ 10/172]  eta: 0:04:29  lr: 0.000093  loss: 0.2803 (0.2829)  time: 1.6665  data: 0.0915  max mem: 20571\n",
      "Train: [epoch:166]  [ 20/172]  eta: 0:04:06  lr: 0.000093  loss: 0.2914 (0.2915)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [ 30/172]  eta: 0:03:48  lr: 0.000093  loss: 0.2915 (0.2891)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:166]  [ 40/172]  eta: 0:03:31  lr: 0.000093  loss: 0.2874 (0.2904)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [ 50/172]  eta: 0:03:14  lr: 0.000093  loss: 0.2947 (0.2911)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [ 60/172]  eta: 0:02:58  lr: 0.000093  loss: 0.2894 (0.2907)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [ 70/172]  eta: 0:02:42  lr: 0.000093  loss: 0.2883 (0.2910)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:166]  [ 80/172]  eta: 0:02:26  lr: 0.000093  loss: 0.2869 (0.2910)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [ 90/172]  eta: 0:02:10  lr: 0.000093  loss: 0.2869 (0.2908)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [100/172]  eta: 0:01:54  lr: 0.000093  loss: 0.2852 (0.2905)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [110/172]  eta: 0:01:38  lr: 0.000093  loss: 0.2877 (0.2906)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [120/172]  eta: 0:01:22  lr: 0.000093  loss: 0.2826 (0.2904)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [130/172]  eta: 0:01:06  lr: 0.000093  loss: 0.2881 (0.2908)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [140/172]  eta: 0:00:50  lr: 0.000093  loss: 0.2892 (0.2908)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [150/172]  eta: 0:00:34  lr: 0.000093  loss: 0.2892 (0.2910)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [160/172]  eta: 0:00:19  lr: 0.000093  loss: 0.2912 (0.2910)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [170/172]  eta: 0:00:03  lr: 0.000093  loss: 0.2892 (0.2911)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166]  [171/172]  eta: 0:00:01  lr: 0.000093  loss: 0.2892 (0.2911)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:166] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000093  loss: 0.2892 (0.2911)\n",
      "Valid: [epoch:166]  [ 0/14]  eta: 0:00:06  loss: 0.2540 (0.2540)  time: 0.4467  data: 0.4318  max mem: 20571\n",
      "Valid: [epoch:166]  [13/14]  eta: 0:00:00  loss: 0.2603 (0.2685)  time: 0.0464  data: 0.0315  max mem: 20571\n",
      "Valid: [epoch:166] Total time: 0:00:00 (0.0510 s / it)\n",
      "Averaged stats: loss: 0.2603 (0.2685)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_166_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.269%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:167]  [  0/172]  eta: 0:08:02  lr: 0.000093  loss: 0.2847 (0.2847)  time: 2.8055  data: 1.2356  max mem: 20571\n",
      "Train: [epoch:167]  [ 10/172]  eta: 0:04:33  lr: 0.000093  loss: 0.2915 (0.3010)  time: 1.6868  data: 0.1124  max mem: 20571\n",
      "Train: [epoch:167]  [ 20/172]  eta: 0:04:08  lr: 0.000093  loss: 0.3012 (0.3020)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [ 30/172]  eta: 0:03:49  lr: 0.000093  loss: 0.3057 (0.3004)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [ 40/172]  eta: 0:03:32  lr: 0.000093  loss: 0.2960 (0.2990)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [ 50/172]  eta: 0:03:15  lr: 0.000093  loss: 0.2960 (0.2980)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [ 60/172]  eta: 0:02:58  lr: 0.000093  loss: 0.2990 (0.2986)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [ 70/172]  eta: 0:02:42  lr: 0.000093  loss: 0.2982 (0.2975)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [ 80/172]  eta: 0:02:26  lr: 0.000093  loss: 0.2883 (0.2967)  time: 1.5776  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:167]  [ 90/172]  eta: 0:02:10  lr: 0.000093  loss: 0.2939 (0.2977)  time: 1.5768  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:167]  [100/172]  eta: 0:01:54  lr: 0.000093  loss: 0.2928 (0.2967)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [110/172]  eta: 0:01:38  lr: 0.000093  loss: 0.2920 (0.2969)  time: 1.5785  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:167]  [120/172]  eta: 0:01:22  lr: 0.000093  loss: 0.2924 (0.2964)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [130/172]  eta: 0:01:06  lr: 0.000093  loss: 0.2887 (0.2957)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [140/172]  eta: 0:00:50  lr: 0.000093  loss: 0.2887 (0.2955)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [150/172]  eta: 0:00:34  lr: 0.000093  loss: 0.2851 (0.2948)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [160/172]  eta: 0:00:19  lr: 0.000093  loss: 0.2877 (0.2948)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [170/172]  eta: 0:00:03  lr: 0.000093  loss: 0.2916 (0.2945)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167]  [171/172]  eta: 0:00:01  lr: 0.000093  loss: 0.2912 (0.2945)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:167] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000093  loss: 0.2912 (0.2945)\n",
      "Valid: [epoch:167]  [ 0/14]  eta: 0:00:05  loss: 0.2901 (0.2901)  time: 0.4032  data: 0.3867  max mem: 20571\n",
      "Valid: [epoch:167]  [13/14]  eta: 0:00:00  loss: 0.2914 (0.2982)  time: 0.0481  data: 0.0331  max mem: 20571\n",
      "Valid: [epoch:167] Total time: 0:00:00 (0.0551 s / it)\n",
      "Averaged stats: loss: 0.2914 (0.2982)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_167_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.298%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:168]  [  0/172]  eta: 0:07:16  lr: 0.000093  loss: 0.3272 (0.3272)  time: 2.5398  data: 0.9763  max mem: 20571\n",
      "Train: [epoch:168]  [ 10/172]  eta: 0:04:29  lr: 0.000093  loss: 0.3097 (0.3037)  time: 1.6655  data: 0.0889  max mem: 20571\n",
      "Train: [epoch:168]  [ 20/172]  eta: 0:04:06  lr: 0.000093  loss: 0.2950 (0.2960)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:168]  [ 30/172]  eta: 0:03:48  lr: 0.000093  loss: 0.2865 (0.2951)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [ 40/172]  eta: 0:03:31  lr: 0.000093  loss: 0.2893 (0.2950)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [ 50/172]  eta: 0:03:14  lr: 0.000093  loss: 0.2913 (0.2956)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [ 60/172]  eta: 0:02:58  lr: 0.000093  loss: 0.2923 (0.2953)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [ 70/172]  eta: 0:02:42  lr: 0.000093  loss: 0.2933 (0.2946)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [ 80/172]  eta: 0:02:26  lr: 0.000093  loss: 0.2969 (0.2953)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [ 90/172]  eta: 0:02:10  lr: 0.000093  loss: 0.2926 (0.2944)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [100/172]  eta: 0:01:54  lr: 0.000093  loss: 0.2872 (0.2940)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [110/172]  eta: 0:01:38  lr: 0.000093  loss: 0.2864 (0.2940)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [120/172]  eta: 0:01:22  lr: 0.000093  loss: 0.2929 (0.2945)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [130/172]  eta: 0:01:06  lr: 0.000093  loss: 0.2937 (0.2943)  time: 1.5733  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:168]  [140/172]  eta: 0:00:50  lr: 0.000093  loss: 0.2934 (0.2942)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [150/172]  eta: 0:00:34  lr: 0.000093  loss: 0.2987 (0.2949)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [160/172]  eta: 0:00:18  lr: 0.000093  loss: 0.2941 (0.2944)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:168]  [170/172]  eta: 0:00:03  lr: 0.000093  loss: 0.2914 (0.2944)  time: 1.5783  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:168]  [171/172]  eta: 0:00:01  lr: 0.000093  loss: 0.2927 (0.2944)  time: 1.5783  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:168] Total time: 0:04:32 (1.5832 s / it)\n",
      "Averaged stats: lr: 0.000093  loss: 0.2927 (0.2944)\n",
      "Valid: [epoch:168]  [ 0/14]  eta: 0:00:04  loss: 0.2708 (0.2708)  time: 0.2948  data: 0.2778  max mem: 20571\n",
      "Valid: [epoch:168]  [13/14]  eta: 0:00:00  loss: 0.2770 (0.2850)  time: 0.0399  data: 0.0249  max mem: 20571\n",
      "Valid: [epoch:168] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.2770 (0.2850)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_168_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.285%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:169]  [  0/172]  eta: 0:07:24  lr: 0.000092  loss: 0.2790 (0.2790)  time: 2.5848  data: 1.0125  max mem: 20571\n",
      "Train: [epoch:169]  [ 10/172]  eta: 0:04:29  lr: 0.000092  loss: 0.2955 (0.2993)  time: 1.6654  data: 0.0922  max mem: 20571\n",
      "Train: [epoch:169]  [ 20/172]  eta: 0:04:06  lr: 0.000092  loss: 0.2946 (0.2970)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [ 30/172]  eta: 0:03:48  lr: 0.000092  loss: 0.2926 (0.2963)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [ 40/172]  eta: 0:03:31  lr: 0.000092  loss: 0.2875 (0.2956)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [ 50/172]  eta: 0:03:14  lr: 0.000092  loss: 0.2960 (0.2979)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:169]  [ 60/172]  eta: 0:02:58  lr: 0.000092  loss: 0.2960 (0.2970)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [ 70/172]  eta: 0:02:42  lr: 0.000092  loss: 0.2894 (0.2969)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [ 80/172]  eta: 0:02:26  lr: 0.000092  loss: 0.2973 (0.2969)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [ 90/172]  eta: 0:02:10  lr: 0.000092  loss: 0.2932 (0.2967)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [100/172]  eta: 0:01:54  lr: 0.000092  loss: 0.3027 (0.2973)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [110/172]  eta: 0:01:38  lr: 0.000092  loss: 0.3014 (0.2967)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [120/172]  eta: 0:01:22  lr: 0.000092  loss: 0.2873 (0.2962)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [130/172]  eta: 0:01:06  lr: 0.000092  loss: 0.2923 (0.2960)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [140/172]  eta: 0:00:50  lr: 0.000092  loss: 0.2981 (0.2965)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [150/172]  eta: 0:00:34  lr: 0.000092  loss: 0.2985 (0.2965)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [160/172]  eta: 0:00:19  lr: 0.000092  loss: 0.2985 (0.2968)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [170/172]  eta: 0:00:03  lr: 0.000092  loss: 0.2944 (0.2965)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169]  [171/172]  eta: 0:00:01  lr: 0.000092  loss: 0.2944 (0.2965)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:169] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000092  loss: 0.2944 (0.2965)\n",
      "Valid: [epoch:169]  [ 0/14]  eta: 0:00:04  loss: 0.3005 (0.3005)  time: 0.3140  data: 0.2988  max mem: 20571\n",
      "Valid: [epoch:169]  [13/14]  eta: 0:00:00  loss: 0.3012 (0.3079)  time: 0.0437  data: 0.0287  max mem: 20571\n",
      "Valid: [epoch:169] Total time: 0:00:00 (0.0515 s / it)\n",
      "Averaged stats: loss: 0.3012 (0.3079)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_169_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.308%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:170]  [  0/172]  eta: 0:07:19  lr: 0.000092  loss: 0.3172 (0.3172)  time: 2.5551  data: 0.9762  max mem: 20571\n",
      "Train: [epoch:170]  [ 10/172]  eta: 0:04:30  lr: 0.000092  loss: 0.2983 (0.3006)  time: 1.6683  data: 0.0889  max mem: 20571\n",
      "Train: [epoch:170]  [ 20/172]  eta: 0:04:07  lr: 0.000092  loss: 0.2975 (0.2961)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [ 30/172]  eta: 0:03:48  lr: 0.000092  loss: 0.2920 (0.2948)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [ 40/172]  eta: 0:03:31  lr: 0.000092  loss: 0.2953 (0.2961)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:170]  [ 50/172]  eta: 0:03:15  lr: 0.000092  loss: 0.2980 (0.2962)  time: 1.5803  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:170]  [ 60/172]  eta: 0:02:58  lr: 0.000092  loss: 0.2993 (0.2974)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:170]  [ 70/172]  eta: 0:02:42  lr: 0.000092  loss: 0.2993 (0.2971)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:170]  [ 80/172]  eta: 0:02:26  lr: 0.000092  loss: 0.2908 (0.2968)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [ 90/172]  eta: 0:02:10  lr: 0.000092  loss: 0.2855 (0.2964)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [100/172]  eta: 0:01:54  lr: 0.000092  loss: 0.2855 (0.2970)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [110/172]  eta: 0:01:38  lr: 0.000092  loss: 0.2850 (0.2974)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [120/172]  eta: 0:01:22  lr: 0.000092  loss: 0.2960 (0.2980)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [130/172]  eta: 0:01:06  lr: 0.000092  loss: 0.2979 (0.2979)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [140/172]  eta: 0:00:50  lr: 0.000092  loss: 0.2878 (0.2979)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [150/172]  eta: 0:00:34  lr: 0.000092  loss: 0.2878 (0.2979)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [160/172]  eta: 0:00:19  lr: 0.000092  loss: 0.2963 (0.2981)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [170/172]  eta: 0:00:03  lr: 0.000092  loss: 0.2960 (0.2979)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170]  [171/172]  eta: 0:00:01  lr: 0.000092  loss: 0.2983 (0.2980)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:170] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000092  loss: 0.2983 (0.2980)\n",
      "Valid: [epoch:170]  [ 0/14]  eta: 0:00:04  loss: 0.2931 (0.2931)  time: 0.3322  data: 0.3173  max mem: 20571\n",
      "Valid: [epoch:170]  [13/14]  eta: 0:00:00  loss: 0.2670 (0.2751)  time: 0.0385  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:170] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.2670 (0.2751)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_170_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.275%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:171]  [  0/172]  eta: 0:07:44  lr: 0.000092  loss: 0.2709 (0.2709)  time: 2.6985  data: 1.1219  max mem: 20571\n",
      "Train: [epoch:171]  [ 10/172]  eta: 0:04:31  lr: 0.000092  loss: 0.2878 (0.2973)  time: 1.6743  data: 0.1021  max mem: 20571\n",
      "Train: [epoch:171]  [ 20/172]  eta: 0:04:07  lr: 0.000092  loss: 0.3007 (0.2959)  time: 1.5729  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:171]  [ 30/172]  eta: 0:03:48  lr: 0.000092  loss: 0.2914 (0.2960)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171]  [ 40/172]  eta: 0:03:31  lr: 0.000092  loss: 0.2914 (0.2979)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171]  [ 50/172]  eta: 0:03:14  lr: 0.000092  loss: 0.3003 (0.2976)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:171]  [ 60/172]  eta: 0:02:58  lr: 0.000092  loss: 0.2914 (0.2973)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:171]  [ 70/172]  eta: 0:02:42  lr: 0.000092  loss: 0.2948 (0.2981)  time: 1.5745  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171]  [ 80/172]  eta: 0:02:26  lr: 0.000092  loss: 0.3002 (0.2991)  time: 1.5753  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171]  [ 90/172]  eta: 0:02:10  lr: 0.000092  loss: 0.2983 (0.2988)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:171]  [100/172]  eta: 0:01:54  lr: 0.000092  loss: 0.2960 (0.2991)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:171]  [110/172]  eta: 0:01:38  lr: 0.000092  loss: 0.3029 (0.2992)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171]  [120/172]  eta: 0:01:22  lr: 0.000092  loss: 0.2977 (0.2990)  time: 1.5759  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171]  [130/172]  eta: 0:01:06  lr: 0.000092  loss: 0.2977 (0.2996)  time: 1.5755  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171]  [140/172]  eta: 0:00:50  lr: 0.000092  loss: 0.3013 (0.3001)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:171]  [150/172]  eta: 0:00:34  lr: 0.000092  loss: 0.2966 (0.2999)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:171]  [160/172]  eta: 0:00:18  lr: 0.000092  loss: 0.2918 (0.2994)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171]  [170/172]  eta: 0:00:03  lr: 0.000092  loss: 0.2910 (0.2993)  time: 1.5763  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171]  [171/172]  eta: 0:00:01  lr: 0.000092  loss: 0.2908 (0.2992)  time: 1.5764  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:171] Total time: 0:04:32 (1.5833 s / it)\n",
      "Averaged stats: lr: 0.000092  loss: 0.2908 (0.2992)\n",
      "Valid: [epoch:171]  [ 0/14]  eta: 0:00:04  loss: 0.2963 (0.2963)  time: 0.3534  data: 0.3372  max mem: 20571\n",
      "Valid: [epoch:171]  [13/14]  eta: 0:00:00  loss: 0.2693 (0.2775)  time: 0.0396  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:171] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.2693 (0.2775)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_171_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.277%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:172]  [  0/172]  eta: 0:07:33  lr: 0.000092  loss: 0.2951 (0.2951)  time: 2.6366  data: 1.0634  max mem: 20571\n",
      "Train: [epoch:172]  [ 10/172]  eta: 0:04:30  lr: 0.000092  loss: 0.2958 (0.3037)  time: 1.6693  data: 0.0968  max mem: 20571\n",
      "Train: [epoch:172]  [ 20/172]  eta: 0:04:06  lr: 0.000092  loss: 0.3011 (0.3028)  time: 1.5736  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:172]  [ 30/172]  eta: 0:03:48  lr: 0.000092  loss: 0.3011 (0.3034)  time: 1.5745  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:172]  [ 40/172]  eta: 0:03:31  lr: 0.000092  loss: 0.3002 (0.3035)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [ 50/172]  eta: 0:03:14  lr: 0.000092  loss: 0.3047 (0.3041)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [ 60/172]  eta: 0:02:58  lr: 0.000092  loss: 0.3034 (0.3041)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [ 70/172]  eta: 0:02:42  lr: 0.000092  loss: 0.2976 (0.3031)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [ 80/172]  eta: 0:02:26  lr: 0.000092  loss: 0.2917 (0.3035)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [ 90/172]  eta: 0:02:10  lr: 0.000092  loss: 0.2954 (0.3028)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [100/172]  eta: 0:01:54  lr: 0.000092  loss: 0.2968 (0.3029)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [110/172]  eta: 0:01:38  lr: 0.000092  loss: 0.3090 (0.3031)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [120/172]  eta: 0:01:22  lr: 0.000092  loss: 0.3009 (0.3028)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [130/172]  eta: 0:01:06  lr: 0.000092  loss: 0.3009 (0.3029)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [140/172]  eta: 0:00:50  lr: 0.000092  loss: 0.2993 (0.3029)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [150/172]  eta: 0:00:34  lr: 0.000092  loss: 0.2976 (0.3025)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [160/172]  eta: 0:00:18  lr: 0.000092  loss: 0.2950 (0.3024)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [170/172]  eta: 0:00:03  lr: 0.000092  loss: 0.2919 (0.3023)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172]  [171/172]  eta: 0:00:01  lr: 0.000092  loss: 0.2910 (0.3022)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:172] Total time: 0:04:32 (1.5828 s / it)\n",
      "Averaged stats: lr: 0.000092  loss: 0.2910 (0.3022)\n",
      "Valid: [epoch:172]  [ 0/14]  eta: 0:00:04  loss: 0.2903 (0.2903)  time: 0.2975  data: 0.2825  max mem: 20571\n",
      "Valid: [epoch:172]  [13/14]  eta: 0:00:00  loss: 0.2970 (0.3047)  time: 0.0360  data: 0.0210  max mem: 20571\n",
      "Valid: [epoch:172] Total time: 0:00:00 (0.0409 s / it)\n",
      "Averaged stats: loss: 0.2970 (0.3047)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_172_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.305%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:173]  [  0/172]  eta: 0:07:48  lr: 0.000092  loss: 0.3336 (0.3336)  time: 2.7251  data: 1.1526  max mem: 20571\n",
      "Train: [epoch:173]  [ 10/172]  eta: 0:04:32  lr: 0.000092  loss: 0.3164 (0.3105)  time: 1.6801  data: 0.1049  max mem: 20571\n",
      "Train: [epoch:173]  [ 20/172]  eta: 0:04:08  lr: 0.000092  loss: 0.3119 (0.3085)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [ 30/172]  eta: 0:03:49  lr: 0.000092  loss: 0.3055 (0.3057)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [ 40/172]  eta: 0:03:31  lr: 0.000092  loss: 0.2982 (0.3039)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [ 50/172]  eta: 0:03:15  lr: 0.000092  loss: 0.3018 (0.3038)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [ 60/172]  eta: 0:02:58  lr: 0.000092  loss: 0.3064 (0.3031)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [ 70/172]  eta: 0:02:42  lr: 0.000092  loss: 0.3028 (0.3038)  time: 1.5763  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:173]  [ 80/172]  eta: 0:02:26  lr: 0.000092  loss: 0.2988 (0.3037)  time: 1.5770  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:173]  [ 90/172]  eta: 0:02:10  lr: 0.000092  loss: 0.2988 (0.3035)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [100/172]  eta: 0:01:54  lr: 0.000092  loss: 0.2991 (0.3036)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [110/172]  eta: 0:01:38  lr: 0.000092  loss: 0.2985 (0.3037)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [120/172]  eta: 0:01:22  lr: 0.000092  loss: 0.3002 (0.3035)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [130/172]  eta: 0:01:06  lr: 0.000092  loss: 0.2954 (0.3032)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [140/172]  eta: 0:00:50  lr: 0.000092  loss: 0.2954 (0.3029)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [150/172]  eta: 0:00:34  lr: 0.000092  loss: 0.3005 (0.3031)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [160/172]  eta: 0:00:19  lr: 0.000092  loss: 0.3027 (0.3031)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [170/172]  eta: 0:00:03  lr: 0.000092  loss: 0.2961 (0.3029)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173]  [171/172]  eta: 0:00:01  lr: 0.000092  loss: 0.2985 (0.3029)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:173] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000092  loss: 0.2985 (0.3029)\n",
      "Valid: [epoch:173]  [ 0/14]  eta: 0:00:04  loss: 0.3121 (0.3121)  time: 0.3386  data: 0.3206  max mem: 20571\n",
      "Valid: [epoch:173]  [13/14]  eta: 0:00:00  loss: 0.2855 (0.2937)  time: 0.0384  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:173] Total time: 0:00:00 (0.0444 s / it)\n",
      "Averaged stats: loss: 0.2855 (0.2937)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_173_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.294%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:174]  [  0/172]  eta: 0:08:05  lr: 0.000092  loss: 0.2783 (0.2783)  time: 2.8223  data: 1.2587  max mem: 20571\n",
      "Train: [epoch:174]  [ 10/172]  eta: 0:04:33  lr: 0.000092  loss: 0.3019 (0.3020)  time: 1.6906  data: 0.1146  max mem: 20571\n",
      "Train: [epoch:174]  [ 20/172]  eta: 0:04:08  lr: 0.000092  loss: 0.3019 (0.3016)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [ 30/172]  eta: 0:03:49  lr: 0.000092  loss: 0.3001 (0.3032)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [ 40/172]  eta: 0:03:32  lr: 0.000092  loss: 0.3003 (0.3040)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [ 50/172]  eta: 0:03:15  lr: 0.000092  loss: 0.3003 (0.3035)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [ 60/172]  eta: 0:02:59  lr: 0.000092  loss: 0.2907 (0.3036)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [ 70/172]  eta: 0:02:42  lr: 0.000092  loss: 0.3048 (0.3053)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [ 80/172]  eta: 0:02:26  lr: 0.000092  loss: 0.3081 (0.3045)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [ 90/172]  eta: 0:02:10  lr: 0.000092  loss: 0.3026 (0.3045)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [100/172]  eta: 0:01:54  lr: 0.000092  loss: 0.2994 (0.3040)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [110/172]  eta: 0:01:38  lr: 0.000092  loss: 0.3018 (0.3042)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [120/172]  eta: 0:01:22  lr: 0.000092  loss: 0.3018 (0.3039)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [130/172]  eta: 0:01:06  lr: 0.000092  loss: 0.2945 (0.3036)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [140/172]  eta: 0:00:50  lr: 0.000092  loss: 0.2998 (0.3044)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [150/172]  eta: 0:00:34  lr: 0.000092  loss: 0.3067 (0.3044)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [160/172]  eta: 0:00:19  lr: 0.000092  loss: 0.3042 (0.3042)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [170/172]  eta: 0:00:03  lr: 0.000092  loss: 0.3018 (0.3041)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174]  [171/172]  eta: 0:00:01  lr: 0.000092  loss: 0.2983 (0.3040)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:174] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000092  loss: 0.2983 (0.3040)\n",
      "Valid: [epoch:174]  [ 0/14]  eta: 0:00:04  loss: 0.3079 (0.3079)  time: 0.3551  data: 0.3398  max mem: 20571\n",
      "Valid: [epoch:174]  [13/14]  eta: 0:00:00  loss: 0.2764 (0.2852)  time: 0.0401  data: 0.0251  max mem: 20571\n",
      "Valid: [epoch:174] Total time: 0:00:00 (0.0479 s / it)\n",
      "Averaged stats: loss: 0.2764 (0.2852)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_174_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.285%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:175]  [  0/172]  eta: 0:08:39  lr: 0.000092  loss: 0.3046 (0.3046)  time: 3.0232  data: 1.4475  max mem: 20571\n",
      "Train: [epoch:175]  [ 10/172]  eta: 0:04:35  lr: 0.000092  loss: 0.3046 (0.3053)  time: 1.7035  data: 0.1317  max mem: 20571\n",
      "Train: [epoch:175]  [ 20/172]  eta: 0:04:09  lr: 0.000092  loss: 0.3051 (0.3084)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [ 30/172]  eta: 0:03:50  lr: 0.000092  loss: 0.3052 (0.3075)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [ 40/172]  eta: 0:03:32  lr: 0.000092  loss: 0.3098 (0.3080)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [ 50/172]  eta: 0:03:15  lr: 0.000092  loss: 0.3098 (0.3080)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [ 60/172]  eta: 0:02:59  lr: 0.000092  loss: 0.3027 (0.3076)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [ 70/172]  eta: 0:02:43  lr: 0.000092  loss: 0.3058 (0.3087)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [ 80/172]  eta: 0:02:26  lr: 0.000092  loss: 0.3147 (0.3093)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [ 90/172]  eta: 0:02:10  lr: 0.000092  loss: 0.2993 (0.3086)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [100/172]  eta: 0:01:54  lr: 0.000092  loss: 0.2971 (0.3084)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [110/172]  eta: 0:01:38  lr: 0.000092  loss: 0.3098 (0.3080)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [120/172]  eta: 0:01:22  lr: 0.000092  loss: 0.3044 (0.3075)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:175]  [130/172]  eta: 0:01:06  lr: 0.000092  loss: 0.2981 (0.3068)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:175]  [140/172]  eta: 0:00:50  lr: 0.000092  loss: 0.2966 (0.3065)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:175]  [150/172]  eta: 0:00:34  lr: 0.000092  loss: 0.3036 (0.3062)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:175]  [160/172]  eta: 0:00:19  lr: 0.000092  loss: 0.3036 (0.3060)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175]  [170/172]  eta: 0:00:03  lr: 0.000092  loss: 0.3011 (0.3060)  time: 1.5829  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:175]  [171/172]  eta: 0:00:01  lr: 0.000092  loss: 0.3029 (0.3061)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:175] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000092  loss: 0.3029 (0.3061)\n",
      "Valid: [epoch:175]  [ 0/14]  eta: 0:00:08  loss: 0.2889 (0.2889)  time: 0.5748  data: 0.5591  max mem: 20571\n",
      "Valid: [epoch:175]  [13/14]  eta: 0:00:00  loss: 0.2892 (0.2971)  time: 0.0559  data: 0.0410  max mem: 20571\n",
      "Valid: [epoch:175] Total time: 0:00:00 (0.0635 s / it)\n",
      "Averaged stats: loss: 0.2892 (0.2971)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_175_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.297%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:176]  [  0/172]  eta: 0:08:15  lr: 0.000092  loss: 0.3201 (0.3201)  time: 2.8784  data: 1.3097  max mem: 20571\n",
      "Train: [epoch:176]  [ 10/172]  eta: 0:04:35  lr: 0.000092  loss: 0.3067 (0.3062)  time: 1.6993  data: 0.1192  max mem: 20571\n",
      "Train: [epoch:176]  [ 20/172]  eta: 0:04:09  lr: 0.000092  loss: 0.3062 (0.3062)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:176]  [ 30/172]  eta: 0:03:50  lr: 0.000092  loss: 0.3053 (0.3070)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:176]  [ 40/172]  eta: 0:03:33  lr: 0.000092  loss: 0.3046 (0.3069)  time: 1.5840  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:176]  [ 50/172]  eta: 0:03:16  lr: 0.000092  loss: 0.3041 (0.3065)  time: 1.5881  data: 0.0056  max mem: 20571\n",
      "Train: [epoch:176]  [ 60/172]  eta: 0:02:59  lr: 0.000092  loss: 0.3104 (0.3077)  time: 1.5854  data: 0.0055  max mem: 20571\n",
      "Train: [epoch:176]  [ 70/172]  eta: 0:02:43  lr: 0.000092  loss: 0.3104 (0.3081)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:176]  [ 80/172]  eta: 0:02:27  lr: 0.000092  loss: 0.3045 (0.3073)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:176]  [ 90/172]  eta: 0:02:11  lr: 0.000092  loss: 0.3016 (0.3075)  time: 1.5853  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:176]  [100/172]  eta: 0:01:54  lr: 0.000092  loss: 0.3039 (0.3078)  time: 1.5853  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:176]  [110/172]  eta: 0:01:38  lr: 0.000092  loss: 0.3039 (0.3077)  time: 1.5846  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:176]  [120/172]  eta: 0:01:22  lr: 0.000092  loss: 0.3073 (0.3074)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:176]  [130/172]  eta: 0:01:06  lr: 0.000092  loss: 0.3034 (0.3074)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:176]  [140/172]  eta: 0:00:50  lr: 0.000092  loss: 0.2998 (0.3069)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:176]  [150/172]  eta: 0:00:35  lr: 0.000092  loss: 0.3055 (0.3071)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:176]  [160/172]  eta: 0:00:19  lr: 0.000092  loss: 0.3062 (0.3074)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:176]  [170/172]  eta: 0:00:03  lr: 0.000092  loss: 0.3050 (0.3073)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:176]  [171/172]  eta: 0:00:01  lr: 0.000092  loss: 0.3041 (0.3072)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:176] Total time: 0:04:33 (1.5920 s / it)\n",
      "Averaged stats: lr: 0.000092  loss: 0.3041 (0.3072)\n",
      "Valid: [epoch:176]  [ 0/14]  eta: 0:00:04  loss: 0.3070 (0.3070)  time: 0.3050  data: 0.2884  max mem: 20571\n",
      "Valid: [epoch:176]  [13/14]  eta: 0:00:00  loss: 0.2742 (0.2828)  time: 0.0384  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:176] Total time: 0:00:00 (0.0461 s / it)\n",
      "Averaged stats: loss: 0.2742 (0.2828)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_176_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.283%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:177]  [  0/172]  eta: 0:07:32  lr: 0.000092  loss: 0.2680 (0.2680)  time: 2.6306  data: 1.0495  max mem: 20571\n",
      "Train: [epoch:177]  [ 10/172]  eta: 0:04:31  lr: 0.000092  loss: 0.2985 (0.3035)  time: 1.6744  data: 0.0956  max mem: 20571\n",
      "Train: [epoch:177]  [ 20/172]  eta: 0:04:07  lr: 0.000092  loss: 0.3130 (0.3100)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [ 30/172]  eta: 0:03:49  lr: 0.000092  loss: 0.3159 (0.3098)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [ 40/172]  eta: 0:03:32  lr: 0.000092  loss: 0.3166 (0.3115)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [ 50/172]  eta: 0:03:15  lr: 0.000092  loss: 0.3162 (0.3122)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [ 60/172]  eta: 0:02:59  lr: 0.000092  loss: 0.3142 (0.3127)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [ 70/172]  eta: 0:02:42  lr: 0.000092  loss: 0.3102 (0.3118)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:177]  [ 80/172]  eta: 0:02:26  lr: 0.000092  loss: 0.3048 (0.3113)  time: 1.5827  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:177]  [ 90/172]  eta: 0:02:10  lr: 0.000092  loss: 0.3048 (0.3110)  time: 1.5832  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:177]  [100/172]  eta: 0:01:54  lr: 0.000092  loss: 0.2974 (0.3102)  time: 1.5841  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:177]  [110/172]  eta: 0:01:38  lr: 0.000092  loss: 0.3037 (0.3103)  time: 1.5850  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:177]  [120/172]  eta: 0:01:22  lr: 0.000092  loss: 0.3037 (0.3096)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [130/172]  eta: 0:01:06  lr: 0.000092  loss: 0.3093 (0.3101)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [140/172]  eta: 0:00:50  lr: 0.000092  loss: 0.3093 (0.3100)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [150/172]  eta: 0:00:34  lr: 0.000092  loss: 0.3041 (0.3098)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [160/172]  eta: 0:00:19  lr: 0.000092  loss: 0.3049 (0.3098)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [170/172]  eta: 0:00:03  lr: 0.000092  loss: 0.3040 (0.3099)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177]  [171/172]  eta: 0:00:01  lr: 0.000092  loss: 0.3040 (0.3099)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:177] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000092  loss: 0.3040 (0.3099)\n",
      "Valid: [epoch:177]  [ 0/14]  eta: 0:00:05  loss: 0.3290 (0.3290)  time: 0.4187  data: 0.4012  max mem: 20571\n",
      "Valid: [epoch:177]  [13/14]  eta: 0:00:00  loss: 0.2987 (0.3066)  time: 0.0444  data: 0.0293  max mem: 20571\n",
      "Valid: [epoch:177] Total time: 0:00:00 (0.0498 s / it)\n",
      "Averaged stats: loss: 0.2987 (0.3066)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_177_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.307%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:178]  [  0/172]  eta: 0:07:58  lr: 0.000091  loss: 0.3104 (0.3104)  time: 2.7848  data: 1.2173  max mem: 20571\n",
      "Train: [epoch:178]  [ 10/172]  eta: 0:04:33  lr: 0.000091  loss: 0.3102 (0.3086)  time: 1.6883  data: 0.1108  max mem: 20571\n",
      "Train: [epoch:178]  [ 20/172]  eta: 0:04:08  lr: 0.000091  loss: 0.3102 (0.3093)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [ 30/172]  eta: 0:03:49  lr: 0.000091  loss: 0.3093 (0.3096)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [ 40/172]  eta: 0:03:32  lr: 0.000091  loss: 0.3087 (0.3111)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [ 50/172]  eta: 0:03:15  lr: 0.000091  loss: 0.3025 (0.3111)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [ 60/172]  eta: 0:02:59  lr: 0.000091  loss: 0.3112 (0.3118)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [ 70/172]  eta: 0:02:43  lr: 0.000091  loss: 0.3123 (0.3123)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [ 80/172]  eta: 0:02:26  lr: 0.000091  loss: 0.3134 (0.3123)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [ 90/172]  eta: 0:02:10  lr: 0.000091  loss: 0.3134 (0.3126)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [100/172]  eta: 0:01:54  lr: 0.000091  loss: 0.3067 (0.3115)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [110/172]  eta: 0:01:38  lr: 0.000091  loss: 0.3028 (0.3113)  time: 1.5816  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:178]  [120/172]  eta: 0:01:22  lr: 0.000091  loss: 0.3039 (0.3110)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [130/172]  eta: 0:01:06  lr: 0.000091  loss: 0.3023 (0.3111)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [140/172]  eta: 0:00:50  lr: 0.000091  loss: 0.3034 (0.3111)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [150/172]  eta: 0:00:34  lr: 0.000091  loss: 0.3055 (0.3112)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:178]  [160/172]  eta: 0:00:19  lr: 0.000091  loss: 0.3061 (0.3106)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [170/172]  eta: 0:00:03  lr: 0.000091  loss: 0.3061 (0.3106)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178]  [171/172]  eta: 0:00:01  lr: 0.000091  loss: 0.3057 (0.3105)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:178] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000091  loss: 0.3057 (0.3105)\n",
      "Valid: [epoch:178]  [ 0/14]  eta: 0:00:05  loss: 0.3417 (0.3417)  time: 0.3628  data: 0.3451  max mem: 20571\n",
      "Valid: [epoch:178]  [13/14]  eta: 0:00:00  loss: 0.3175 (0.3255)  time: 0.0409  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:178] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.3175 (0.3255)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_178_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.325%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:179]  [  0/172]  eta: 0:07:34  lr: 0.000091  loss: 0.3373 (0.3373)  time: 2.6414  data: 1.0630  max mem: 20571\n",
      "Train: [epoch:179]  [ 10/172]  eta: 0:04:31  lr: 0.000091  loss: 0.3161 (0.3149)  time: 1.6757  data: 0.0967  max mem: 20571\n",
      "Train: [epoch:179]  [ 20/172]  eta: 0:04:07  lr: 0.000091  loss: 0.3094 (0.3113)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [ 30/172]  eta: 0:03:49  lr: 0.000091  loss: 0.3100 (0.3122)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [ 40/172]  eta: 0:03:31  lr: 0.000091  loss: 0.3100 (0.3111)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [ 50/172]  eta: 0:03:15  lr: 0.000091  loss: 0.3092 (0.3115)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [ 60/172]  eta: 0:02:58  lr: 0.000091  loss: 0.3148 (0.3118)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [ 70/172]  eta: 0:02:42  lr: 0.000091  loss: 0.3094 (0.3112)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [ 80/172]  eta: 0:02:26  lr: 0.000091  loss: 0.3087 (0.3112)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [ 90/172]  eta: 0:02:10  lr: 0.000091  loss: 0.3087 (0.3108)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [100/172]  eta: 0:01:54  lr: 0.000091  loss: 0.3136 (0.3109)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [110/172]  eta: 0:01:38  lr: 0.000091  loss: 0.3144 (0.3116)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [120/172]  eta: 0:01:22  lr: 0.000091  loss: 0.3126 (0.3115)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [130/172]  eta: 0:01:06  lr: 0.000091  loss: 0.3069 (0.3119)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [140/172]  eta: 0:00:50  lr: 0.000091  loss: 0.3083 (0.3120)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [150/172]  eta: 0:00:34  lr: 0.000091  loss: 0.3084 (0.3116)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [160/172]  eta: 0:00:19  lr: 0.000091  loss: 0.3092 (0.3117)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [170/172]  eta: 0:00:03  lr: 0.000091  loss: 0.3107 (0.3118)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179]  [171/172]  eta: 0:00:01  lr: 0.000091  loss: 0.3057 (0.3117)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:179] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000091  loss: 0.3057 (0.3117)\n",
      "Valid: [epoch:179]  [ 0/14]  eta: 0:00:04  loss: 0.3315 (0.3315)  time: 0.3038  data: 0.2878  max mem: 20571\n",
      "Valid: [epoch:179]  [13/14]  eta: 0:00:00  loss: 0.3004 (0.3084)  time: 0.0388  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:179] Total time: 0:00:00 (0.0440 s / it)\n",
      "Averaged stats: loss: 0.3004 (0.3084)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_179_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.308%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:180]  [  0/172]  eta: 0:07:47  lr: 0.000091  loss: 0.3267 (0.3267)  time: 2.7203  data: 1.1523  max mem: 20571\n",
      "Train: [epoch:180]  [ 10/172]  eta: 0:04:33  lr: 0.000091  loss: 0.3267 (0.3224)  time: 1.6870  data: 0.1049  max mem: 20571\n",
      "Train: [epoch:180]  [ 20/172]  eta: 0:04:08  lr: 0.000091  loss: 0.3200 (0.3234)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [ 30/172]  eta: 0:03:50  lr: 0.000091  loss: 0.3194 (0.3223)  time: 1.5857  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:180]  [ 40/172]  eta: 0:03:32  lr: 0.000091  loss: 0.3086 (0.3183)  time: 1.5869  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:180]  [ 50/172]  eta: 0:03:16  lr: 0.000091  loss: 0.3063 (0.3181)  time: 1.5859  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:180]  [ 60/172]  eta: 0:02:59  lr: 0.000091  loss: 0.3163 (0.3167)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [ 70/172]  eta: 0:02:43  lr: 0.000091  loss: 0.3142 (0.3168)  time: 1.5840  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:180]  [ 80/172]  eta: 0:02:27  lr: 0.000091  loss: 0.3142 (0.3167)  time: 1.5851  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:180]  [ 90/172]  eta: 0:02:10  lr: 0.000091  loss: 0.3138 (0.3168)  time: 1.5844  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:180]  [100/172]  eta: 0:01:54  lr: 0.000091  loss: 0.3138 (0.3169)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [110/172]  eta: 0:01:38  lr: 0.000091  loss: 0.3098 (0.3164)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [120/172]  eta: 0:01:22  lr: 0.000091  loss: 0.3113 (0.3164)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [130/172]  eta: 0:01:06  lr: 0.000091  loss: 0.3083 (0.3159)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [140/172]  eta: 0:00:50  lr: 0.000091  loss: 0.3002 (0.3158)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [150/172]  eta: 0:00:35  lr: 0.000091  loss: 0.3078 (0.3153)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [160/172]  eta: 0:00:19  lr: 0.000091  loss: 0.3130 (0.3156)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [170/172]  eta: 0:00:03  lr: 0.000091  loss: 0.3193 (0.3155)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180]  [171/172]  eta: 0:00:01  lr: 0.000091  loss: 0.3132 (0.3155)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:180] Total time: 0:04:33 (1.5915 s / it)\n",
      "Averaged stats: lr: 0.000091  loss: 0.3132 (0.3155)\n",
      "Valid: [epoch:180]  [ 0/14]  eta: 0:00:04  loss: 0.2898 (0.2898)  time: 0.2889  data: 0.2728  max mem: 20571\n",
      "Valid: [epoch:180]  [13/14]  eta: 0:00:00  loss: 0.2907 (0.3000)  time: 0.0426  data: 0.0276  max mem: 20571\n",
      "Valid: [epoch:180] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.2907 (0.3000)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_180_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.300%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:181]  [  0/172]  eta: 0:07:35  lr: 0.000091  loss: 0.3458 (0.3458)  time: 2.6490  data: 1.0655  max mem: 20571\n",
      "Train: [epoch:181]  [ 10/172]  eta: 0:04:31  lr: 0.000091  loss: 0.3252 (0.3177)  time: 1.6765  data: 0.0970  max mem: 20571\n",
      "Train: [epoch:181]  [ 20/172]  eta: 0:04:07  lr: 0.000091  loss: 0.3192 (0.3215)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [ 30/172]  eta: 0:03:49  lr: 0.000091  loss: 0.3122 (0.3192)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [ 40/172]  eta: 0:03:31  lr: 0.000091  loss: 0.3122 (0.3201)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [ 50/172]  eta: 0:03:15  lr: 0.000091  loss: 0.3108 (0.3190)  time: 1.5803  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:181]  [ 60/172]  eta: 0:02:58  lr: 0.000091  loss: 0.3129 (0.3186)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [ 70/172]  eta: 0:02:42  lr: 0.000091  loss: 0.3181 (0.3205)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [ 80/172]  eta: 0:02:26  lr: 0.000091  loss: 0.3205 (0.3204)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [ 90/172]  eta: 0:02:10  lr: 0.000091  loss: 0.3143 (0.3199)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [100/172]  eta: 0:01:54  lr: 0.000091  loss: 0.3155 (0.3196)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [110/172]  eta: 0:01:38  lr: 0.000091  loss: 0.3159 (0.3191)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [120/172]  eta: 0:01:22  lr: 0.000091  loss: 0.3118 (0.3183)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [130/172]  eta: 0:01:06  lr: 0.000091  loss: 0.3092 (0.3178)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [140/172]  eta: 0:00:50  lr: 0.000091  loss: 0.3082 (0.3176)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [150/172]  eta: 0:00:34  lr: 0.000091  loss: 0.3156 (0.3176)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [160/172]  eta: 0:00:19  lr: 0.000091  loss: 0.3120 (0.3170)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [170/172]  eta: 0:00:03  lr: 0.000091  loss: 0.3044 (0.3168)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181]  [171/172]  eta: 0:00:01  lr: 0.000091  loss: 0.3044 (0.3166)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:181] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000091  loss: 0.3044 (0.3166)\n",
      "Valid: [epoch:181]  [ 0/14]  eta: 0:00:04  loss: 0.3296 (0.3296)  time: 0.2869  data: 0.2718  max mem: 20571\n",
      "Valid: [epoch:181]  [13/14]  eta: 0:00:00  loss: 0.3016 (0.3098)  time: 0.0426  data: 0.0275  max mem: 20571\n",
      "Valid: [epoch:181] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.3016 (0.3098)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_181_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.310%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:182]  [  0/172]  eta: 0:07:34  lr: 0.000091  loss: 0.3178 (0.3178)  time: 2.6443  data: 1.0778  max mem: 20571\n",
      "Train: [epoch:182]  [ 10/172]  eta: 0:04:31  lr: 0.000091  loss: 0.3181 (0.3160)  time: 1.6750  data: 0.0981  max mem: 20571\n",
      "Train: [epoch:182]  [ 20/172]  eta: 0:04:07  lr: 0.000091  loss: 0.3214 (0.3226)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:182]  [ 30/172]  eta: 0:03:49  lr: 0.000091  loss: 0.3183 (0.3213)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:182]  [ 40/172]  eta: 0:03:31  lr: 0.000091  loss: 0.3072 (0.3180)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [ 50/172]  eta: 0:03:15  lr: 0.000091  loss: 0.3072 (0.3162)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [ 60/172]  eta: 0:02:58  lr: 0.000091  loss: 0.3140 (0.3176)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [ 70/172]  eta: 0:02:42  lr: 0.000091  loss: 0.3140 (0.3169)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [ 80/172]  eta: 0:02:26  lr: 0.000091  loss: 0.3100 (0.3171)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [ 90/172]  eta: 0:02:10  lr: 0.000091  loss: 0.3191 (0.3172)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [100/172]  eta: 0:01:54  lr: 0.000091  loss: 0.3086 (0.3170)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [110/172]  eta: 0:01:38  lr: 0.000091  loss: 0.3072 (0.3162)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [120/172]  eta: 0:01:22  lr: 0.000091  loss: 0.3093 (0.3164)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [130/172]  eta: 0:01:06  lr: 0.000091  loss: 0.3153 (0.3161)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [140/172]  eta: 0:00:50  lr: 0.000091  loss: 0.3160 (0.3160)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [150/172]  eta: 0:00:34  lr: 0.000091  loss: 0.3160 (0.3159)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [160/172]  eta: 0:00:19  lr: 0.000091  loss: 0.3273 (0.3168)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:182]  [170/172]  eta: 0:00:03  lr: 0.000091  loss: 0.3235 (0.3168)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182]  [171/172]  eta: 0:00:01  lr: 0.000091  loss: 0.3273 (0.3169)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:182] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000091  loss: 0.3273 (0.3169)\n",
      "Valid: [epoch:182]  [ 0/14]  eta: 0:00:05  loss: 0.3095 (0.3095)  time: 0.3992  data: 0.3818  max mem: 20571\n",
      "Valid: [epoch:182]  [13/14]  eta: 0:00:00  loss: 0.2892 (0.2982)  time: 0.0437  data: 0.0285  max mem: 20571\n",
      "Valid: [epoch:182] Total time: 0:00:00 (0.0485 s / it)\n",
      "Averaged stats: loss: 0.2892 (0.2982)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_182_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.298%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:183]  [  0/172]  eta: 0:07:42  lr: 0.000091  loss: 0.2693 (0.2693)  time: 2.6899  data: 1.1163  max mem: 20571\n",
      "Train: [epoch:183]  [ 10/172]  eta: 0:04:31  lr: 0.000091  loss: 0.3104 (0.3139)  time: 1.6763  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:183]  [ 20/172]  eta: 0:04:07  lr: 0.000091  loss: 0.3191 (0.3167)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [ 30/172]  eta: 0:03:48  lr: 0.000091  loss: 0.3182 (0.3170)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [ 40/172]  eta: 0:03:31  lr: 0.000091  loss: 0.3182 (0.3183)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [ 50/172]  eta: 0:03:14  lr: 0.000091  loss: 0.3174 (0.3189)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [ 60/172]  eta: 0:02:58  lr: 0.000091  loss: 0.3134 (0.3183)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [ 70/172]  eta: 0:02:42  lr: 0.000091  loss: 0.3185 (0.3195)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [ 80/172]  eta: 0:02:26  lr: 0.000091  loss: 0.3223 (0.3194)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [ 90/172]  eta: 0:02:10  lr: 0.000091  loss: 0.3136 (0.3193)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [100/172]  eta: 0:01:54  lr: 0.000091  loss: 0.3118 (0.3187)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [110/172]  eta: 0:01:38  lr: 0.000091  loss: 0.3123 (0.3185)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [120/172]  eta: 0:01:22  lr: 0.000091  loss: 0.3139 (0.3180)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [130/172]  eta: 0:01:06  lr: 0.000091  loss: 0.3076 (0.3180)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [140/172]  eta: 0:00:50  lr: 0.000091  loss: 0.3148 (0.3182)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [150/172]  eta: 0:00:34  lr: 0.000091  loss: 0.3234 (0.3184)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [160/172]  eta: 0:00:19  lr: 0.000091  loss: 0.3217 (0.3182)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [170/172]  eta: 0:00:03  lr: 0.000091  loss: 0.3217 (0.3184)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183]  [171/172]  eta: 0:00:01  lr: 0.000091  loss: 0.3247 (0.3186)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:183] Total time: 0:04:32 (1.5845 s / it)\n",
      "Averaged stats: lr: 0.000091  loss: 0.3247 (0.3186)\n",
      "Valid: [epoch:183]  [ 0/14]  eta: 0:00:04  loss: 0.2811 (0.2811)  time: 0.3043  data: 0.2895  max mem: 20571\n",
      "Valid: [epoch:183]  [13/14]  eta: 0:00:00  loss: 0.3092 (0.3181)  time: 0.0369  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:183] Total time: 0:00:00 (0.0438 s / it)\n",
      "Averaged stats: loss: 0.3092 (0.3181)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_183_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.318%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:184]  [  0/172]  eta: 0:07:43  lr: 0.000091  loss: 0.3491 (0.3491)  time: 2.6930  data: 1.1166  max mem: 20571\n",
      "Train: [epoch:184]  [ 10/172]  eta: 0:04:31  lr: 0.000091  loss: 0.3204 (0.3231)  time: 1.6789  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:184]  [ 20/172]  eta: 0:04:07  lr: 0.000091  loss: 0.3171 (0.3252)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [ 30/172]  eta: 0:03:49  lr: 0.000091  loss: 0.3174 (0.3243)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [ 40/172]  eta: 0:03:32  lr: 0.000091  loss: 0.3173 (0.3242)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:184]  [ 50/172]  eta: 0:03:15  lr: 0.000091  loss: 0.3173 (0.3246)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:184]  [ 60/172]  eta: 0:02:58  lr: 0.000091  loss: 0.3188 (0.3242)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [ 70/172]  eta: 0:02:42  lr: 0.000091  loss: 0.3188 (0.3245)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [ 80/172]  eta: 0:02:26  lr: 0.000091  loss: 0.3174 (0.3233)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [ 90/172]  eta: 0:02:10  lr: 0.000091  loss: 0.3151 (0.3230)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:184]  [100/172]  eta: 0:01:54  lr: 0.000091  loss: 0.3157 (0.3231)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [110/172]  eta: 0:01:38  lr: 0.000091  loss: 0.3245 (0.3234)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [120/172]  eta: 0:01:22  lr: 0.000091  loss: 0.3239 (0.3230)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [130/172]  eta: 0:01:06  lr: 0.000091  loss: 0.3171 (0.3228)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [140/172]  eta: 0:00:50  lr: 0.000091  loss: 0.3087 (0.3221)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [150/172]  eta: 0:00:34  lr: 0.000091  loss: 0.3087 (0.3220)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [160/172]  eta: 0:00:19  lr: 0.000091  loss: 0.3129 (0.3214)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [170/172]  eta: 0:00:03  lr: 0.000091  loss: 0.3081 (0.3210)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184]  [171/172]  eta: 0:00:01  lr: 0.000091  loss: 0.3081 (0.3209)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:184] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000091  loss: 0.3081 (0.3209)\n",
      "Valid: [epoch:184]  [ 0/14]  eta: 0:00:04  loss: 0.3127 (0.3127)  time: 0.3316  data: 0.3149  max mem: 20571\n",
      "Valid: [epoch:184]  [13/14]  eta: 0:00:00  loss: 0.2934 (0.3018)  time: 0.0388  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:184] Total time: 0:00:00 (0.0473 s / it)\n",
      "Averaged stats: loss: 0.2934 (0.3018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_184_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.302%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:185]  [  0/172]  eta: 0:07:28  lr: 0.000091  loss: 0.2862 (0.2862)  time: 2.6101  data: 1.0258  max mem: 20571\n",
      "Train: [epoch:185]  [ 10/172]  eta: 0:04:30  lr: 0.000091  loss: 0.3175 (0.3236)  time: 1.6687  data: 0.0934  max mem: 20571\n",
      "Train: [epoch:185]  [ 20/172]  eta: 0:04:07  lr: 0.000091  loss: 0.3177 (0.3217)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [ 30/172]  eta: 0:03:48  lr: 0.000091  loss: 0.3177 (0.3204)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [ 40/172]  eta: 0:03:31  lr: 0.000091  loss: 0.3272 (0.3223)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [ 50/172]  eta: 0:03:14  lr: 0.000091  loss: 0.3274 (0.3224)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [ 60/172]  eta: 0:02:58  lr: 0.000091  loss: 0.3139 (0.3212)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [ 70/172]  eta: 0:02:42  lr: 0.000091  loss: 0.3158 (0.3233)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [ 80/172]  eta: 0:02:26  lr: 0.000091  loss: 0.3307 (0.3240)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [ 90/172]  eta: 0:02:10  lr: 0.000091  loss: 0.3177 (0.3227)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [100/172]  eta: 0:01:54  lr: 0.000091  loss: 0.3087 (0.3221)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [110/172]  eta: 0:01:38  lr: 0.000091  loss: 0.3201 (0.3219)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [120/172]  eta: 0:01:22  lr: 0.000091  loss: 0.3201 (0.3221)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [130/172]  eta: 0:01:06  lr: 0.000091  loss: 0.3163 (0.3219)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [140/172]  eta: 0:00:50  lr: 0.000091  loss: 0.3163 (0.3220)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [150/172]  eta: 0:00:34  lr: 0.000091  loss: 0.3192 (0.3218)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [160/172]  eta: 0:00:19  lr: 0.000091  loss: 0.3203 (0.3216)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [170/172]  eta: 0:00:03  lr: 0.000091  loss: 0.3212 (0.3218)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185]  [171/172]  eta: 0:00:01  lr: 0.000091  loss: 0.3212 (0.3218)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:185] Total time: 0:04:32 (1.5840 s / it)\n",
      "Averaged stats: lr: 0.000091  loss: 0.3212 (0.3218)\n",
      "Valid: [epoch:185]  [ 0/14]  eta: 0:00:04  loss: 0.3003 (0.3003)  time: 0.3154  data: 0.3003  max mem: 20571\n",
      "Valid: [epoch:185]  [13/14]  eta: 0:00:00  loss: 0.3003 (0.3092)  time: 0.0368  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:185] Total time: 0:00:00 (0.0423 s / it)\n",
      "Averaged stats: loss: 0.3003 (0.3092)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_185_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.309%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:186]  [  0/172]  eta: 0:07:35  lr: 0.000091  loss: 0.3023 (0.3023)  time: 2.6506  data: 1.0857  max mem: 20571\n",
      "Train: [epoch:186]  [ 10/172]  eta: 0:04:31  lr: 0.000091  loss: 0.3221 (0.3285)  time: 1.6732  data: 0.0988  max mem: 20571\n",
      "Train: [epoch:186]  [ 20/172]  eta: 0:04:07  lr: 0.000091  loss: 0.3270 (0.3301)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [ 30/172]  eta: 0:03:48  lr: 0.000091  loss: 0.3255 (0.3291)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [ 40/172]  eta: 0:03:31  lr: 0.000091  loss: 0.3183 (0.3263)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [ 50/172]  eta: 0:03:14  lr: 0.000091  loss: 0.3183 (0.3252)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [ 60/172]  eta: 0:02:58  lr: 0.000091  loss: 0.3223 (0.3268)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [ 70/172]  eta: 0:02:42  lr: 0.000091  loss: 0.3198 (0.3259)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [ 80/172]  eta: 0:02:26  lr: 0.000091  loss: 0.3170 (0.3253)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [ 90/172]  eta: 0:02:10  lr: 0.000091  loss: 0.3209 (0.3253)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [100/172]  eta: 0:01:54  lr: 0.000091  loss: 0.3231 (0.3250)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [110/172]  eta: 0:01:38  lr: 0.000091  loss: 0.3234 (0.3253)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:186]  [120/172]  eta: 0:01:22  lr: 0.000091  loss: 0.3229 (0.3250)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [130/172]  eta: 0:01:06  lr: 0.000091  loss: 0.3179 (0.3249)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [140/172]  eta: 0:00:50  lr: 0.000091  loss: 0.3221 (0.3247)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [150/172]  eta: 0:00:34  lr: 0.000091  loss: 0.3233 (0.3247)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [160/172]  eta: 0:00:19  lr: 0.000091  loss: 0.3266 (0.3252)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186]  [170/172]  eta: 0:00:03  lr: 0.000091  loss: 0.3235 (0.3246)  time: 1.5773  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:186]  [171/172]  eta: 0:00:01  lr: 0.000091  loss: 0.3230 (0.3245)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:186] Total time: 0:04:32 (1.5838 s / it)\n",
      "Averaged stats: lr: 0.000091  loss: 0.3230 (0.3245)\n",
      "Valid: [epoch:186]  [ 0/14]  eta: 0:00:04  loss: 0.2938 (0.2938)  time: 0.3213  data: 0.3035  max mem: 20571\n",
      "Valid: [epoch:186]  [13/14]  eta: 0:00:00  loss: 0.2938 (0.3031)  time: 0.0382  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:186] Total time: 0:00:00 (0.0444 s / it)\n",
      "Averaged stats: loss: 0.2938 (0.3031)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_186_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.303%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:187]  [  0/172]  eta: 0:07:21  lr: 0.000090  loss: 0.2870 (0.2870)  time: 2.5650  data: 0.9886  max mem: 20571\n",
      "Train: [epoch:187]  [ 10/172]  eta: 0:04:29  lr: 0.000090  loss: 0.3156 (0.3194)  time: 1.6623  data: 0.0900  max mem: 20571\n",
      "Train: [epoch:187]  [ 20/172]  eta: 0:04:06  lr: 0.000090  loss: 0.3160 (0.3257)  time: 1.5734  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [ 30/172]  eta: 0:03:48  lr: 0.000090  loss: 0.3193 (0.3261)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [ 40/172]  eta: 0:03:30  lr: 0.000090  loss: 0.3169 (0.3255)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [ 50/172]  eta: 0:03:14  lr: 0.000090  loss: 0.3177 (0.3250)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [ 60/172]  eta: 0:02:58  lr: 0.000090  loss: 0.3243 (0.3251)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.3278 (0.3248)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [ 80/172]  eta: 0:02:25  lr: 0.000090  loss: 0.3316 (0.3252)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.3244 (0.3252)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.3244 (0.3265)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.3288 (0.3261)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.3226 (0.3255)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.3277 (0.3262)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.3266 (0.3259)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.3266 (0.3264)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [160/172]  eta: 0:00:18  lr: 0.000090  loss: 0.3263 (0.3261)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.3263 (0.3263)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.3263 (0.3263)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:187] Total time: 0:04:32 (1.5828 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.3263 (0.3263)\n",
      "Valid: [epoch:187]  [ 0/14]  eta: 0:00:04  loss: 0.2772 (0.2772)  time: 0.3186  data: 0.3037  max mem: 20571\n",
      "Valid: [epoch:187]  [13/14]  eta: 0:00:00  loss: 0.3081 (0.3173)  time: 0.0380  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:187] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.3081 (0.3173)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_187_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.317%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:188]  [  0/172]  eta: 0:07:54  lr: 0.000090  loss: 0.3324 (0.3324)  time: 2.7612  data: 1.1955  max mem: 20571\n",
      "Train: [epoch:188]  [ 10/172]  eta: 0:04:32  lr: 0.000090  loss: 0.3324 (0.3326)  time: 1.6849  data: 0.1088  max mem: 20571\n",
      "Train: [epoch:188]  [ 20/172]  eta: 0:04:08  lr: 0.000090  loss: 0.3220 (0.3282)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [ 30/172]  eta: 0:03:49  lr: 0.000090  loss: 0.3244 (0.3276)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [ 40/172]  eta: 0:03:32  lr: 0.000090  loss: 0.3209 (0.3277)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [ 50/172]  eta: 0:03:15  lr: 0.000090  loss: 0.3211 (0.3281)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:188]  [ 60/172]  eta: 0:02:58  lr: 0.000090  loss: 0.3298 (0.3286)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.3302 (0.3287)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [ 80/172]  eta: 0:02:26  lr: 0.000090  loss: 0.3302 (0.3294)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.3212 (0.3284)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.3216 (0.3284)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.3243 (0.3277)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.3199 (0.3275)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.3213 (0.3271)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.3217 (0.3271)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.3266 (0.3272)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [160/172]  eta: 0:00:19  lr: 0.000090  loss: 0.3266 (0.3275)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.3315 (0.3283)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.3315 (0.3285)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:188] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.3315 (0.3285)\n",
      "Valid: [epoch:188]  [ 0/14]  eta: 0:00:04  loss: 0.2881 (0.2881)  time: 0.2858  data: 0.2707  max mem: 20571\n",
      "Valid: [epoch:188]  [13/14]  eta: 0:00:00  loss: 0.2947 (0.3041)  time: 0.0411  data: 0.0261  max mem: 20571\n",
      "Valid: [epoch:188] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.2947 (0.3041)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_188_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.304%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:189]  [  0/172]  eta: 0:07:54  lr: 0.000090  loss: 0.3254 (0.3254)  time: 2.7602  data: 1.1839  max mem: 20571\n",
      "Train: [epoch:189]  [ 10/172]  eta: 0:04:32  lr: 0.000090  loss: 0.3240 (0.3238)  time: 1.6819  data: 0.1077  max mem: 20571\n",
      "Train: [epoch:189]  [ 20/172]  eta: 0:04:07  lr: 0.000090  loss: 0.3240 (0.3283)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [ 30/172]  eta: 0:03:49  lr: 0.000090  loss: 0.3263 (0.3278)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [ 40/172]  eta: 0:03:32  lr: 0.000090  loss: 0.3243 (0.3276)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [ 50/172]  eta: 0:03:15  lr: 0.000090  loss: 0.3303 (0.3279)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [ 60/172]  eta: 0:02:58  lr: 0.000090  loss: 0.3314 (0.3290)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.3314 (0.3289)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [ 80/172]  eta: 0:02:26  lr: 0.000090  loss: 0.3247 (0.3281)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.3198 (0.3272)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.3197 (0.3270)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.3197 (0.3274)  time: 1.5789  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:189]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.3197 (0.3275)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.3370 (0.3285)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.3349 (0.3282)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.3341 (0.3289)  time: 1.5762  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:189]  [160/172]  eta: 0:00:19  lr: 0.000090  loss: 0.3342 (0.3290)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:189]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.3258 (0.3288)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.3255 (0.3288)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:189] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.3255 (0.3288)\n",
      "Valid: [epoch:189]  [ 0/14]  eta: 0:00:04  loss: 0.3512 (0.3512)  time: 0.3555  data: 0.3395  max mem: 20571\n",
      "Valid: [epoch:189]  [13/14]  eta: 0:00:00  loss: 0.3210 (0.3291)  time: 0.0416  data: 0.0265  max mem: 20571\n",
      "Valid: [epoch:189] Total time: 0:00:00 (0.0483 s / it)\n",
      "Averaged stats: loss: 0.3210 (0.3291)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_189_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.329%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:190]  [  0/172]  eta: 0:07:54  lr: 0.000090  loss: 0.3068 (0.3068)  time: 2.7616  data: 1.1991  max mem: 20571\n",
      "Train: [epoch:190]  [ 10/172]  eta: 0:04:32  lr: 0.000090  loss: 0.3382 (0.3383)  time: 1.6844  data: 0.1091  max mem: 20571\n",
      "Train: [epoch:190]  [ 20/172]  eta: 0:04:08  lr: 0.000090  loss: 0.3365 (0.3360)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [ 30/172]  eta: 0:03:49  lr: 0.000090  loss: 0.3326 (0.3318)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [ 40/172]  eta: 0:03:31  lr: 0.000090  loss: 0.3296 (0.3316)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [ 50/172]  eta: 0:03:15  lr: 0.000090  loss: 0.3286 (0.3310)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [ 60/172]  eta: 0:02:58  lr: 0.000090  loss: 0.3273 (0.3311)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.3273 (0.3306)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [ 80/172]  eta: 0:02:26  lr: 0.000090  loss: 0.3273 (0.3304)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.3260 (0.3308)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.3244 (0.3303)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.3183 (0.3305)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.3240 (0.3299)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.3293 (0.3305)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.3293 (0.3302)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.3244 (0.3302)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [160/172]  eta: 0:00:19  lr: 0.000090  loss: 0.3279 (0.3304)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.3333 (0.3300)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.3333 (0.3300)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:190] Total time: 0:04:32 (1.5842 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.3333 (0.3300)\n",
      "Valid: [epoch:190]  [ 0/14]  eta: 0:00:04  loss: 0.3036 (0.3036)  time: 0.3348  data: 0.3175  max mem: 20571\n",
      "Valid: [epoch:190]  [13/14]  eta: 0:00:00  loss: 0.3036 (0.3124)  time: 0.0391  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:190] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.3036 (0.3124)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_190_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.312%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:191]  [  0/172]  eta: 0:07:54  lr: 0.000090  loss: 0.3060 (0.3060)  time: 2.7600  data: 1.1883  max mem: 20571\n",
      "Train: [epoch:191]  [ 10/172]  eta: 0:04:32  lr: 0.000090  loss: 0.3354 (0.3435)  time: 1.6814  data: 0.1081  max mem: 20571\n",
      "Train: [epoch:191]  [ 20/172]  eta: 0:04:07  lr: 0.000090  loss: 0.3337 (0.3367)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [ 30/172]  eta: 0:03:49  lr: 0.000090  loss: 0.3249 (0.3342)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [ 40/172]  eta: 0:03:31  lr: 0.000090  loss: 0.3255 (0.3362)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [ 50/172]  eta: 0:03:15  lr: 0.000090  loss: 0.3307 (0.3344)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [ 60/172]  eta: 0:02:58  lr: 0.000090  loss: 0.3230 (0.3325)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.3262 (0.3325)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [ 80/172]  eta: 0:02:26  lr: 0.000090  loss: 0.3290 (0.3319)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.3290 (0.3318)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.3234 (0.3310)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.3259 (0.3318)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.3397 (0.3325)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.3397 (0.3326)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.3326 (0.3324)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.3329 (0.3325)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [160/172]  eta: 0:00:19  lr: 0.000090  loss: 0.3370 (0.3325)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.3330 (0.3328)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.3348 (0.3329)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:191] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.3348 (0.3329)\n",
      "Valid: [epoch:191]  [ 0/14]  eta: 0:00:04  loss: 0.3384 (0.3384)  time: 0.3246  data: 0.3077  max mem: 20571\n",
      "Valid: [epoch:191]  [13/14]  eta: 0:00:00  loss: 0.3061 (0.3156)  time: 0.0373  data: 0.0221  max mem: 20571\n",
      "Valid: [epoch:191] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.3061 (0.3156)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_191_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.316%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:192]  [  0/172]  eta: 0:07:16  lr: 0.000090  loss: 0.3096 (0.3096)  time: 2.5371  data: 0.9524  max mem: 20571\n",
      "Train: [epoch:192]  [ 10/172]  eta: 0:04:29  lr: 0.000090  loss: 0.3466 (0.3443)  time: 1.6641  data: 0.0867  max mem: 20571\n",
      "Train: [epoch:192]  [ 20/172]  eta: 0:04:06  lr: 0.000090  loss: 0.3382 (0.3391)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [ 30/172]  eta: 0:03:48  lr: 0.000090  loss: 0.3321 (0.3374)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [ 40/172]  eta: 0:03:31  lr: 0.000090  loss: 0.3344 (0.3405)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [ 50/172]  eta: 0:03:15  lr: 0.000090  loss: 0.3344 (0.3391)  time: 1.5801  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:192]  [ 60/172]  eta: 0:02:58  lr: 0.000090  loss: 0.3259 (0.3356)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.3259 (0.3358)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [ 80/172]  eta: 0:02:26  lr: 0.000090  loss: 0.3297 (0.3367)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.3286 (0.3358)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.3213 (0.3347)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.3277 (0.3351)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.3358 (0.3347)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.3296 (0.3343)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.3314 (0.3346)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.3280 (0.3345)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [160/172]  eta: 0:00:19  lr: 0.000090  loss: 0.3235 (0.3339)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.3250 (0.3340)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.3277 (0.3340)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:192] Total time: 0:04:32 (1.5847 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.3277 (0.3340)\n",
      "Valid: [epoch:192]  [ 0/14]  eta: 0:00:05  loss: 0.3300 (0.3300)  time: 0.4055  data: 0.3890  max mem: 20571\n",
      "Valid: [epoch:192]  [13/14]  eta: 0:00:00  loss: 0.2958 (0.3053)  time: 0.0431  data: 0.0279  max mem: 20571\n",
      "Valid: [epoch:192] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.2958 (0.3053)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_192_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.305%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:193]  [  0/172]  eta: 0:07:51  lr: 0.000090  loss: 0.2917 (0.2917)  time: 2.7403  data: 1.1514  max mem: 20571\n",
      "Train: [epoch:193]  [ 10/172]  eta: 0:04:32  lr: 0.000090  loss: 0.3198 (0.3200)  time: 1.6820  data: 0.1048  max mem: 20571\n",
      "Train: [epoch:193]  [ 20/172]  eta: 0:04:08  lr: 0.000090  loss: 0.3222 (0.3253)  time: 1.5764  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:193]  [ 30/172]  eta: 0:03:49  lr: 0.000090  loss: 0.3250 (0.3278)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:193]  [ 40/172]  eta: 0:03:31  lr: 0.000090  loss: 0.3250 (0.3286)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:193]  [ 50/172]  eta: 0:03:15  lr: 0.000090  loss: 0.3327 (0.3305)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [ 60/172]  eta: 0:02:58  lr: 0.000090  loss: 0.3339 (0.3298)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.3339 (0.3320)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [ 80/172]  eta: 0:02:26  lr: 0.000090  loss: 0.3421 (0.3331)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.3421 (0.3334)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.3246 (0.3331)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.3386 (0.3339)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.3291 (0.3335)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.3222 (0.3331)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.3282 (0.3337)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.3458 (0.3344)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [160/172]  eta: 0:00:19  lr: 0.000090  loss: 0.3431 (0.3343)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.3277 (0.3349)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.3267 (0.3349)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:193] Total time: 0:04:32 (1.5843 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.3267 (0.3349)\n",
      "Valid: [epoch:193]  [ 0/14]  eta: 0:00:05  loss: 0.2838 (0.2838)  time: 0.3683  data: 0.3516  max mem: 20571\n",
      "Valid: [epoch:193]  [13/14]  eta: 0:00:00  loss: 0.3031 (0.3131)  time: 0.0423  data: 0.0272  max mem: 20571\n",
      "Valid: [epoch:193] Total time: 0:00:00 (0.0508 s / it)\n",
      "Averaged stats: loss: 0.3031 (0.3131)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_193_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.313%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:194]  [  0/172]  eta: 0:07:57  lr: 0.000090  loss: 0.3102 (0.3102)  time: 2.7742  data: 1.2116  max mem: 20571\n",
      "Train: [epoch:194]  [ 10/172]  eta: 0:04:32  lr: 0.000090  loss: 0.3440 (0.3393)  time: 1.6836  data: 0.1103  max mem: 20571\n",
      "Train: [epoch:194]  [ 20/172]  eta: 0:04:08  lr: 0.000090  loss: 0.3353 (0.3363)  time: 1.5758  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:194]  [ 30/172]  eta: 0:03:49  lr: 0.000090  loss: 0.3279 (0.3361)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [ 40/172]  eta: 0:03:32  lr: 0.000090  loss: 0.3361 (0.3371)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [ 50/172]  eta: 0:03:15  lr: 0.000090  loss: 0.3361 (0.3371)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [ 60/172]  eta: 0:02:58  lr: 0.000090  loss: 0.3359 (0.3378)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.3333 (0.3375)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [ 80/172]  eta: 0:02:26  lr: 0.000090  loss: 0.3266 (0.3372)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.3237 (0.3362)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.3281 (0.3370)  time: 1.5758  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:194]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.3352 (0.3368)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:194]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.3351 (0.3374)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.3306 (0.3366)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.3323 (0.3370)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.3365 (0.3368)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [160/172]  eta: 0:00:19  lr: 0.000090  loss: 0.3350 (0.3365)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.3360 (0.3374)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.3360 (0.3374)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:194] Total time: 0:04:32 (1.5848 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.3360 (0.3374)\n",
      "Valid: [epoch:194]  [ 0/14]  eta: 0:00:03  loss: 0.2968 (0.2968)  time: 0.2841  data: 0.2695  max mem: 20571\n",
      "Valid: [epoch:194]  [13/14]  eta: 0:00:00  loss: 0.3222 (0.3305)  time: 0.0356  data: 0.0207  max mem: 20571\n",
      "Valid: [epoch:194] Total time: 0:00:00 (0.0403 s / it)\n",
      "Averaged stats: loss: 0.3222 (0.3305)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_194_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.331%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:195]  [  0/172]  eta: 0:07:35  lr: 0.000090  loss: 0.3339 (0.3339)  time: 2.6510  data: 1.0698  max mem: 20571\n",
      "Train: [epoch:195]  [ 10/172]  eta: 0:04:30  lr: 0.000090  loss: 0.3352 (0.3368)  time: 1.6728  data: 0.0974  max mem: 20571\n",
      "Train: [epoch:195]  [ 20/172]  eta: 0:04:07  lr: 0.000090  loss: 0.3378 (0.3399)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [ 30/172]  eta: 0:03:48  lr: 0.000090  loss: 0.3424 (0.3411)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [ 40/172]  eta: 0:03:31  lr: 0.000090  loss: 0.3424 (0.3411)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [ 50/172]  eta: 0:03:14  lr: 0.000090  loss: 0.3289 (0.3394)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [ 60/172]  eta: 0:02:58  lr: 0.000090  loss: 0.3384 (0.3411)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [ 70/172]  eta: 0:02:42  lr: 0.000090  loss: 0.3515 (0.3411)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:195]  [ 80/172]  eta: 0:02:26  lr: 0.000090  loss: 0.3375 (0.3404)  time: 1.5773  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:195]  [ 90/172]  eta: 0:02:10  lr: 0.000090  loss: 0.3352 (0.3403)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [100/172]  eta: 0:01:54  lr: 0.000090  loss: 0.3323 (0.3398)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [110/172]  eta: 0:01:38  lr: 0.000090  loss: 0.3323 (0.3400)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [120/172]  eta: 0:01:22  lr: 0.000090  loss: 0.3421 (0.3400)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [130/172]  eta: 0:01:06  lr: 0.000090  loss: 0.3289 (0.3402)  time: 1.5777  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:195]  [140/172]  eta: 0:00:50  lr: 0.000090  loss: 0.3359 (0.3407)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [150/172]  eta: 0:00:34  lr: 0.000090  loss: 0.3398 (0.3406)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:195]  [160/172]  eta: 0:00:19  lr: 0.000090  loss: 0.3350 (0.3406)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:195]  [170/172]  eta: 0:00:03  lr: 0.000090  loss: 0.3296 (0.3401)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:195]  [171/172]  eta: 0:00:01  lr: 0.000090  loss: 0.3296 (0.3400)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:195] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000090  loss: 0.3296 (0.3400)\n",
      "Valid: [epoch:195]  [ 0/14]  eta: 0:00:04  loss: 0.3230 (0.3230)  time: 0.3033  data: 0.2884  max mem: 20571\n",
      "Valid: [epoch:195]  [13/14]  eta: 0:00:00  loss: 0.3238 (0.3333)  time: 0.0381  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:195] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.3238 (0.3333)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_195_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.333%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:196]  [  0/172]  eta: 0:08:06  lr: 0.000089  loss: 0.3765 (0.3765)  time: 2.8261  data: 1.2622  max mem: 20571\n",
      "Train: [epoch:196]  [ 10/172]  eta: 0:04:33  lr: 0.000089  loss: 0.3460 (0.3430)  time: 1.6906  data: 0.1149  max mem: 20571\n",
      "Train: [epoch:196]  [ 20/172]  eta: 0:04:08  lr: 0.000089  loss: 0.3460 (0.3453)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [ 30/172]  eta: 0:03:49  lr: 0.000089  loss: 0.3475 (0.3466)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [ 40/172]  eta: 0:03:32  lr: 0.000089  loss: 0.3407 (0.3456)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [ 50/172]  eta: 0:03:15  lr: 0.000089  loss: 0.3396 (0.3464)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [ 60/172]  eta: 0:02:59  lr: 0.000089  loss: 0.3623 (0.3475)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [ 70/172]  eta: 0:02:42  lr: 0.000089  loss: 0.3418 (0.3474)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [ 80/172]  eta: 0:02:26  lr: 0.000089  loss: 0.3534 (0.3483)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [ 90/172]  eta: 0:02:10  lr: 0.000089  loss: 0.3542 (0.3480)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [100/172]  eta: 0:01:54  lr: 0.000089  loss: 0.3334 (0.3467)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [110/172]  eta: 0:01:38  lr: 0.000089  loss: 0.3372 (0.3466)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [120/172]  eta: 0:01:22  lr: 0.000089  loss: 0.3391 (0.3463)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [130/172]  eta: 0:01:06  lr: 0.000089  loss: 0.3360 (0.3453)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [140/172]  eta: 0:00:50  lr: 0.000089  loss: 0.3213 (0.3441)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [150/172]  eta: 0:00:34  lr: 0.000089  loss: 0.3216 (0.3436)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [160/172]  eta: 0:00:19  lr: 0.000089  loss: 0.3290 (0.3429)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [170/172]  eta: 0:00:03  lr: 0.000089  loss: 0.3297 (0.3425)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196]  [171/172]  eta: 0:00:01  lr: 0.000089  loss: 0.3290 (0.3424)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:196] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000089  loss: 0.3290 (0.3424)\n",
      "Valid: [epoch:196]  [ 0/14]  eta: 0:00:04  loss: 0.3267 (0.3267)  time: 0.3118  data: 0.2969  max mem: 20571\n",
      "Valid: [epoch:196]  [13/14]  eta: 0:00:00  loss: 0.3047 (0.3145)  time: 0.0459  data: 0.0309  max mem: 20571\n",
      "Valid: [epoch:196] Total time: 0:00:00 (0.0525 s / it)\n",
      "Averaged stats: loss: 0.3047 (0.3145)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_196_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.315%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:197]  [  0/172]  eta: 0:07:51  lr: 0.000089  loss: 0.3040 (0.3040)  time: 2.7399  data: 1.1653  max mem: 20571\n",
      "Train: [epoch:197]  [ 10/172]  eta: 0:04:31  lr: 0.000089  loss: 0.3286 (0.3354)  time: 1.6786  data: 0.1060  max mem: 20571\n",
      "Train: [epoch:197]  [ 20/172]  eta: 0:04:07  lr: 0.000089  loss: 0.3394 (0.3367)  time: 1.5732  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [ 30/172]  eta: 0:03:48  lr: 0.000089  loss: 0.3446 (0.3396)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [ 40/172]  eta: 0:03:31  lr: 0.000089  loss: 0.3352 (0.3387)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [ 50/172]  eta: 0:03:14  lr: 0.000089  loss: 0.3417 (0.3402)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [ 60/172]  eta: 0:02:58  lr: 0.000089  loss: 0.3440 (0.3400)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [ 70/172]  eta: 0:02:42  lr: 0.000089  loss: 0.3319 (0.3391)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [ 80/172]  eta: 0:02:26  lr: 0.000089  loss: 0.3276 (0.3390)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [ 90/172]  eta: 0:02:10  lr: 0.000089  loss: 0.3354 (0.3391)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [100/172]  eta: 0:01:54  lr: 0.000089  loss: 0.3278 (0.3386)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [110/172]  eta: 0:01:38  lr: 0.000089  loss: 0.3243 (0.3384)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [120/172]  eta: 0:01:22  lr: 0.000089  loss: 0.3261 (0.3382)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [130/172]  eta: 0:01:06  lr: 0.000089  loss: 0.3386 (0.3391)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [140/172]  eta: 0:00:50  lr: 0.000089  loss: 0.3477 (0.3395)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [150/172]  eta: 0:00:34  lr: 0.000089  loss: 0.3503 (0.3399)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [160/172]  eta: 0:00:18  lr: 0.000089  loss: 0.3455 (0.3397)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197]  [170/172]  eta: 0:00:03  lr: 0.000089  loss: 0.3442 (0.3402)  time: 1.5776  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:197]  [171/172]  eta: 0:00:01  lr: 0.000089  loss: 0.3451 (0.3403)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:197] Total time: 0:04:32 (1.5836 s / it)\n",
      "Averaged stats: lr: 0.000089  loss: 0.3451 (0.3403)\n",
      "Valid: [epoch:197]  [ 0/14]  eta: 0:00:05  loss: 0.3101 (0.3101)  time: 0.3704  data: 0.3513  max mem: 20571\n",
      "Valid: [epoch:197]  [13/14]  eta: 0:00:00  loss: 0.3164 (0.3265)  time: 0.0415  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:197] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.3164 (0.3265)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_197_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.326%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:198]  [  0/172]  eta: 0:07:53  lr: 0.000089  loss: 0.3395 (0.3395)  time: 2.7524  data: 1.1865  max mem: 20571\n",
      "Train: [epoch:198]  [ 10/172]  eta: 0:04:32  lr: 0.000089  loss: 0.3313 (0.3312)  time: 1.6824  data: 0.1080  max mem: 20571\n",
      "Train: [epoch:198]  [ 20/172]  eta: 0:04:08  lr: 0.000089  loss: 0.3386 (0.3405)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:198]  [ 30/172]  eta: 0:03:49  lr: 0.000089  loss: 0.3401 (0.3419)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:198]  [ 40/172]  eta: 0:03:32  lr: 0.000089  loss: 0.3434 (0.3424)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [ 50/172]  eta: 0:03:15  lr: 0.000089  loss: 0.3458 (0.3444)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [ 60/172]  eta: 0:02:58  lr: 0.000089  loss: 0.3462 (0.3457)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [ 70/172]  eta: 0:02:42  lr: 0.000089  loss: 0.3320 (0.3435)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [ 80/172]  eta: 0:02:26  lr: 0.000089  loss: 0.3343 (0.3440)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [ 90/172]  eta: 0:02:10  lr: 0.000089  loss: 0.3439 (0.3437)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [100/172]  eta: 0:01:54  lr: 0.000089  loss: 0.3439 (0.3435)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [110/172]  eta: 0:01:38  lr: 0.000089  loss: 0.3420 (0.3433)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [120/172]  eta: 0:01:22  lr: 0.000089  loss: 0.3450 (0.3448)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [130/172]  eta: 0:01:06  lr: 0.000089  loss: 0.3451 (0.3444)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [140/172]  eta: 0:00:50  lr: 0.000089  loss: 0.3373 (0.3438)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:198]  [150/172]  eta: 0:00:34  lr: 0.000089  loss: 0.3361 (0.3438)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:198]  [160/172]  eta: 0:00:19  lr: 0.000089  loss: 0.3432 (0.3439)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:198]  [170/172]  eta: 0:00:03  lr: 0.000089  loss: 0.3514 (0.3444)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:198]  [171/172]  eta: 0:00:01  lr: 0.000089  loss: 0.3485 (0.3442)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:198] Total time: 0:04:32 (1.5858 s / it)\n",
      "Averaged stats: lr: 0.000089  loss: 0.3485 (0.3442)\n",
      "Valid: [epoch:198]  [ 0/14]  eta: 0:00:04  loss: 0.3456 (0.3456)  time: 0.3363  data: 0.3155  max mem: 20571\n",
      "Valid: [epoch:198]  [13/14]  eta: 0:00:00  loss: 0.3110 (0.3210)  time: 0.0393  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:198] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.3110 (0.3210)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_198_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.321%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:199]  [  0/172]  eta: 0:07:26  lr: 0.000089  loss: 0.3427 (0.3427)  time: 2.5984  data: 1.0090  max mem: 20571\n",
      "Train: [epoch:199]  [ 10/172]  eta: 0:04:30  lr: 0.000089  loss: 0.3427 (0.3441)  time: 1.6691  data: 0.0918  max mem: 20571\n",
      "Train: [epoch:199]  [ 20/172]  eta: 0:04:07  lr: 0.000089  loss: 0.3444 (0.3502)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [ 30/172]  eta: 0:03:48  lr: 0.000089  loss: 0.3507 (0.3491)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [ 40/172]  eta: 0:03:31  lr: 0.000089  loss: 0.3447 (0.3501)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [ 50/172]  eta: 0:03:14  lr: 0.000089  loss: 0.3475 (0.3497)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [ 60/172]  eta: 0:02:58  lr: 0.000089  loss: 0.3419 (0.3488)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [ 70/172]  eta: 0:02:42  lr: 0.000089  loss: 0.3321 (0.3465)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [ 80/172]  eta: 0:02:26  lr: 0.000089  loss: 0.3318 (0.3471)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [ 90/172]  eta: 0:02:10  lr: 0.000089  loss: 0.3466 (0.3469)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [100/172]  eta: 0:01:54  lr: 0.000089  loss: 0.3460 (0.3467)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [110/172]  eta: 0:01:38  lr: 0.000089  loss: 0.3460 (0.3470)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [120/172]  eta: 0:01:22  lr: 0.000089  loss: 0.3457 (0.3465)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [130/172]  eta: 0:01:06  lr: 0.000089  loss: 0.3453 (0.3464)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [140/172]  eta: 0:00:50  lr: 0.000089  loss: 0.3453 (0.3460)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [150/172]  eta: 0:00:34  lr: 0.000089  loss: 0.3479 (0.3461)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [160/172]  eta: 0:00:19  lr: 0.000089  loss: 0.3464 (0.3454)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [170/172]  eta: 0:00:03  lr: 0.000089  loss: 0.3443 (0.3454)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199]  [171/172]  eta: 0:00:01  lr: 0.000089  loss: 0.3420 (0.3453)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:199] Total time: 0:04:32 (1.5846 s / it)\n",
      "Averaged stats: lr: 0.000089  loss: 0.3420 (0.3453)\n",
      "Valid: [epoch:199]  [ 0/14]  eta: 0:00:04  loss: 0.3570 (0.3570)  time: 0.2908  data: 0.2746  max mem: 20571\n",
      "Valid: [epoch:199]  [13/14]  eta: 0:00:00  loss: 0.3239 (0.3333)  time: 0.0372  data: 0.0221  max mem: 20571\n",
      "Valid: [epoch:199] Total time: 0:00:00 (0.0436 s / it)\n",
      "Averaged stats: loss: 0.3239 (0.3333)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_199_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.333%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:200]  [  0/172]  eta: 0:07:37  lr: 0.000089  loss: 0.3421 (0.3421)  time: 2.6615  data: 1.0964  max mem: 20571\n",
      "Train: [epoch:200]  [ 10/172]  eta: 0:04:31  lr: 0.000089  loss: 0.3474 (0.3476)  time: 1.6784  data: 0.0998  max mem: 20571\n",
      "Train: [epoch:200]  [ 20/172]  eta: 0:04:07  lr: 0.000089  loss: 0.3474 (0.3451)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:200]  [ 30/172]  eta: 0:03:49  lr: 0.000089  loss: 0.3494 (0.3462)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:200]  [ 40/172]  eta: 0:03:31  lr: 0.000089  loss: 0.3437 (0.3462)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:200]  [ 50/172]  eta: 0:03:15  lr: 0.000089  loss: 0.3434 (0.3460)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:200]  [ 60/172]  eta: 0:02:58  lr: 0.000089  loss: 0.3493 (0.3470)  time: 1.5775  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:200]  [ 70/172]  eta: 0:02:42  lr: 0.000089  loss: 0.3536 (0.3488)  time: 1.5765  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:200]  [ 80/172]  eta: 0:02:26  lr: 0.000089  loss: 0.3513 (0.3485)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:200]  [ 90/172]  eta: 0:02:10  lr: 0.000089  loss: 0.3449 (0.3488)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:200]  [100/172]  eta: 0:01:54  lr: 0.000089  loss: 0.3449 (0.3485)  time: 1.5755  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:200]  [110/172]  eta: 0:01:38  lr: 0.000089  loss: 0.3390 (0.3481)  time: 1.5773  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:200]  [120/172]  eta: 0:01:22  lr: 0.000089  loss: 0.3463 (0.3482)  time: 1.5756  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:200]  [130/172]  eta: 0:01:06  lr: 0.000089  loss: 0.3465 (0.3481)  time: 1.5740  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:200]  [140/172]  eta: 0:00:50  lr: 0.000089  loss: 0.3444 (0.3478)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:200]  [150/172]  eta: 0:00:34  lr: 0.000089  loss: 0.3428 (0.3478)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:200]  [160/172]  eta: 0:00:19  lr: 0.000089  loss: 0.3421 (0.3471)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:200]  [170/172]  eta: 0:00:03  lr: 0.000089  loss: 0.3433 (0.3473)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:200]  [171/172]  eta: 0:00:01  lr: 0.000089  loss: 0.3421 (0.3471)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:200] Total time: 0:04:32 (1.5835 s / it)\n",
      "Averaged stats: lr: 0.000089  loss: 0.3421 (0.3471)\n",
      "Valid: [epoch:200]  [ 0/14]  eta: 0:00:04  loss: 0.3345 (0.3345)  time: 0.3329  data: 0.3168  max mem: 20571\n",
      "Valid: [epoch:200]  [13/14]  eta: 0:00:00  loss: 0.3350 (0.3443)  time: 0.0386  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:200] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.3350 (0.3443)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_200_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.344%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:201]  [  0/172]  eta: 0:07:51  lr: 0.000089  loss: 0.3380 (0.3380)  time: 2.7440  data: 1.1672  max mem: 20571\n",
      "Train: [epoch:201]  [ 10/172]  eta: 0:04:32  lr: 0.000089  loss: 0.3413 (0.3478)  time: 1.6797  data: 0.1063  max mem: 20571\n",
      "Train: [epoch:201]  [ 20/172]  eta: 0:04:07  lr: 0.000089  loss: 0.3457 (0.3530)  time: 1.5752  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:201]  [ 30/172]  eta: 0:03:49  lr: 0.000089  loss: 0.3523 (0.3524)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [ 40/172]  eta: 0:03:31  lr: 0.000089  loss: 0.3467 (0.3510)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [ 50/172]  eta: 0:03:15  lr: 0.000089  loss: 0.3519 (0.3541)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [ 60/172]  eta: 0:02:58  lr: 0.000089  loss: 0.3588 (0.3549)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [ 70/172]  eta: 0:02:42  lr: 0.000089  loss: 0.3546 (0.3538)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [ 80/172]  eta: 0:02:26  lr: 0.000089  loss: 0.3496 (0.3526)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [ 90/172]  eta: 0:02:10  lr: 0.000089  loss: 0.3443 (0.3526)  time: 1.5769  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:201]  [100/172]  eta: 0:01:54  lr: 0.000089  loss: 0.3405 (0.3517)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:201]  [110/172]  eta: 0:01:38  lr: 0.000089  loss: 0.3405 (0.3510)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [120/172]  eta: 0:01:22  lr: 0.000089  loss: 0.3476 (0.3510)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [130/172]  eta: 0:01:06  lr: 0.000089  loss: 0.3464 (0.3512)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [140/172]  eta: 0:00:50  lr: 0.000089  loss: 0.3472 (0.3513)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [150/172]  eta: 0:00:34  lr: 0.000089  loss: 0.3472 (0.3507)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [160/172]  eta: 0:00:19  lr: 0.000089  loss: 0.3391 (0.3501)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [170/172]  eta: 0:00:03  lr: 0.000089  loss: 0.3480 (0.3508)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201]  [171/172]  eta: 0:00:01  lr: 0.000089  loss: 0.3480 (0.3510)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:201] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000089  loss: 0.3480 (0.3510)\n",
      "Valid: [epoch:201]  [ 0/14]  eta: 0:00:04  loss: 0.3317 (0.3317)  time: 0.3464  data: 0.3313  max mem: 20571\n",
      "Valid: [epoch:201]  [13/14]  eta: 0:00:00  loss: 0.3094 (0.3194)  time: 0.0402  data: 0.0252  max mem: 20571\n",
      "Valid: [epoch:201] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.3094 (0.3194)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_201_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.319%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:202]  [  0/172]  eta: 0:08:10  lr: 0.000089  loss: 0.2938 (0.2938)  time: 2.8491  data: 1.2847  max mem: 20571\n",
      "Train: [epoch:202]  [ 10/172]  eta: 0:04:33  lr: 0.000089  loss: 0.3529 (0.3531)  time: 1.6903  data: 0.1169  max mem: 20571\n",
      "Train: [epoch:202]  [ 20/172]  eta: 0:04:08  lr: 0.000089  loss: 0.3409 (0.3480)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [ 30/172]  eta: 0:03:49  lr: 0.000089  loss: 0.3366 (0.3479)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [ 40/172]  eta: 0:03:32  lr: 0.000089  loss: 0.3409 (0.3464)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [ 50/172]  eta: 0:03:15  lr: 0.000089  loss: 0.3409 (0.3460)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [ 60/172]  eta: 0:02:58  lr: 0.000089  loss: 0.3493 (0.3475)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [ 70/172]  eta: 0:02:42  lr: 0.000089  loss: 0.3511 (0.3462)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [ 80/172]  eta: 0:02:26  lr: 0.000089  loss: 0.3411 (0.3473)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [ 90/172]  eta: 0:02:10  lr: 0.000089  loss: 0.3411 (0.3472)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [100/172]  eta: 0:01:54  lr: 0.000089  loss: 0.3447 (0.3473)  time: 1.5769  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:202]  [110/172]  eta: 0:01:38  lr: 0.000089  loss: 0.3542 (0.3485)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:202]  [120/172]  eta: 0:01:22  lr: 0.000089  loss: 0.3498 (0.3488)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [130/172]  eta: 0:01:06  lr: 0.000089  loss: 0.3465 (0.3484)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [140/172]  eta: 0:00:50  lr: 0.000089  loss: 0.3468 (0.3487)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [150/172]  eta: 0:00:34  lr: 0.000089  loss: 0.3483 (0.3486)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [160/172]  eta: 0:00:19  lr: 0.000089  loss: 0.3466 (0.3486)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [170/172]  eta: 0:00:03  lr: 0.000089  loss: 0.3499 (0.3491)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202]  [171/172]  eta: 0:00:01  lr: 0.000089  loss: 0.3499 (0.3491)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:202] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000089  loss: 0.3499 (0.3491)\n",
      "Valid: [epoch:202]  [ 0/14]  eta: 0:00:04  loss: 0.3378 (0.3378)  time: 0.3054  data: 0.2909  max mem: 20571\n",
      "Valid: [epoch:202]  [13/14]  eta: 0:00:00  loss: 0.3156 (0.3252)  time: 0.0387  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:202] Total time: 0:00:00 (0.0461 s / it)\n",
      "Averaged stats: loss: 0.3156 (0.3252)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_202_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.325%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:203]  [  0/172]  eta: 0:07:53  lr: 0.000089  loss: 0.3177 (0.3177)  time: 2.7549  data: 1.1825  max mem: 20571\n",
      "Train: [epoch:203]  [ 10/172]  eta: 0:04:32  lr: 0.000089  loss: 0.3506 (0.3477)  time: 1.6824  data: 0.1076  max mem: 20571\n",
      "Train: [epoch:203]  [ 20/172]  eta: 0:04:08  lr: 0.000089  loss: 0.3529 (0.3517)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [ 30/172]  eta: 0:03:49  lr: 0.000089  loss: 0.3530 (0.3536)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [ 40/172]  eta: 0:03:31  lr: 0.000089  loss: 0.3424 (0.3521)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [ 50/172]  eta: 0:03:15  lr: 0.000089  loss: 0.3474 (0.3528)  time: 1.5792  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:203]  [ 60/172]  eta: 0:02:58  lr: 0.000089  loss: 0.3502 (0.3537)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [ 70/172]  eta: 0:02:42  lr: 0.000089  loss: 0.3492 (0.3528)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:203]  [ 80/172]  eta: 0:02:26  lr: 0.000089  loss: 0.3447 (0.3519)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:203]  [ 90/172]  eta: 0:02:10  lr: 0.000089  loss: 0.3511 (0.3519)  time: 1.5762  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:203]  [100/172]  eta: 0:01:54  lr: 0.000089  loss: 0.3430 (0.3516)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [110/172]  eta: 0:01:38  lr: 0.000089  loss: 0.3404 (0.3511)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:203]  [120/172]  eta: 0:01:22  lr: 0.000089  loss: 0.3504 (0.3517)  time: 1.5761  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:203]  [130/172]  eta: 0:01:06  lr: 0.000089  loss: 0.3482 (0.3509)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [140/172]  eta: 0:00:50  lr: 0.000089  loss: 0.3413 (0.3506)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [150/172]  eta: 0:00:34  lr: 0.000089  loss: 0.3508 (0.3512)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [160/172]  eta: 0:00:19  lr: 0.000089  loss: 0.3520 (0.3520)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [170/172]  eta: 0:00:03  lr: 0.000089  loss: 0.3498 (0.3518)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203]  [171/172]  eta: 0:00:01  lr: 0.000089  loss: 0.3489 (0.3516)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:203] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000089  loss: 0.3489 (0.3516)\n",
      "Valid: [epoch:203]  [ 0/14]  eta: 0:00:04  loss: 0.3170 (0.3170)  time: 0.3015  data: 0.2836  max mem: 20571\n",
      "Valid: [epoch:203]  [13/14]  eta: 0:00:00  loss: 0.3409 (0.3505)  time: 0.0423  data: 0.0271  max mem: 20571\n",
      "Valid: [epoch:203] Total time: 0:00:00 (0.0502 s / it)\n",
      "Averaged stats: loss: 0.3409 (0.3505)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_203_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.351%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:204]  [  0/172]  eta: 0:07:25  lr: 0.000089  loss: 0.3467 (0.3467)  time: 2.5925  data: 1.0250  max mem: 20571\n",
      "Train: [epoch:204]  [ 10/172]  eta: 0:04:30  lr: 0.000089  loss: 0.3467 (0.3518)  time: 1.6686  data: 0.0933  max mem: 20571\n",
      "Train: [epoch:204]  [ 20/172]  eta: 0:04:07  lr: 0.000089  loss: 0.3558 (0.3538)  time: 1.5769  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:204]  [ 30/172]  eta: 0:03:48  lr: 0.000089  loss: 0.3593 (0.3560)  time: 1.5769  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:204]  [ 40/172]  eta: 0:03:31  lr: 0.000089  loss: 0.3555 (0.3552)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:204]  [ 50/172]  eta: 0:03:14  lr: 0.000089  loss: 0.3553 (0.3568)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:204]  [ 60/172]  eta: 0:02:58  lr: 0.000089  loss: 0.3607 (0.3575)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204]  [ 70/172]  eta: 0:02:42  lr: 0.000089  loss: 0.3553 (0.3564)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204]  [ 80/172]  eta: 0:02:26  lr: 0.000089  loss: 0.3481 (0.3559)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204]  [ 90/172]  eta: 0:02:10  lr: 0.000089  loss: 0.3481 (0.3546)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204]  [100/172]  eta: 0:01:54  lr: 0.000089  loss: 0.3496 (0.3542)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204]  [110/172]  eta: 0:01:38  lr: 0.000089  loss: 0.3527 (0.3542)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204]  [120/172]  eta: 0:01:22  lr: 0.000089  loss: 0.3611 (0.3551)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204]  [130/172]  eta: 0:01:06  lr: 0.000089  loss: 0.3504 (0.3549)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204]  [140/172]  eta: 0:00:50  lr: 0.000089  loss: 0.3622 (0.3555)  time: 1.5763  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:204]  [150/172]  eta: 0:00:34  lr: 0.000089  loss: 0.3622 (0.3553)  time: 1.5752  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:204]  [160/172]  eta: 0:00:18  lr: 0.000089  loss: 0.3473 (0.3543)  time: 1.5771  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:204]  [170/172]  eta: 0:00:03  lr: 0.000089  loss: 0.3425 (0.3543)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204]  [171/172]  eta: 0:00:01  lr: 0.000089  loss: 0.3425 (0.3543)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:204] Total time: 0:04:32 (1.5834 s / it)\n",
      "Averaged stats: lr: 0.000089  loss: 0.3425 (0.3543)\n",
      "Valid: [epoch:204]  [ 0/14]  eta: 0:00:05  loss: 0.3222 (0.3222)  time: 0.4006  data: 0.3829  max mem: 20571\n",
      "Valid: [epoch:204]  [13/14]  eta: 0:00:00  loss: 0.3222 (0.3318)  time: 0.0437  data: 0.0286  max mem: 20571\n",
      "Valid: [epoch:204] Total time: 0:00:00 (0.0489 s / it)\n",
      "Averaged stats: loss: 0.3222 (0.3318)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_204_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.332%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:205]  [  0/172]  eta: 0:07:50  lr: 0.000088  loss: 0.3185 (0.3185)  time: 2.7369  data: 1.1686  max mem: 20571\n",
      "Train: [epoch:205]  [ 10/172]  eta: 0:04:32  lr: 0.000088  loss: 0.3529 (0.3528)  time: 1.6793  data: 0.1064  max mem: 20571\n",
      "Train: [epoch:205]  [ 20/172]  eta: 0:04:07  lr: 0.000088  loss: 0.3529 (0.3542)  time: 1.5743  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:205]  [ 30/172]  eta: 0:03:49  lr: 0.000088  loss: 0.3561 (0.3558)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205]  [ 40/172]  eta: 0:03:31  lr: 0.000088  loss: 0.3504 (0.3544)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:205]  [ 50/172]  eta: 0:03:15  lr: 0.000088  loss: 0.3464 (0.3548)  time: 1.5770  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:205]  [ 60/172]  eta: 0:02:58  lr: 0.000088  loss: 0.3493 (0.3533)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205]  [ 70/172]  eta: 0:02:42  lr: 0.000088  loss: 0.3493 (0.3533)  time: 1.5775  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:205]  [ 80/172]  eta: 0:02:26  lr: 0.000088  loss: 0.3494 (0.3532)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:205]  [ 90/172]  eta: 0:02:10  lr: 0.000088  loss: 0.3537 (0.3539)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:205]  [100/172]  eta: 0:01:54  lr: 0.000088  loss: 0.3537 (0.3537)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:205]  [110/172]  eta: 0:01:38  lr: 0.000088  loss: 0.3416 (0.3533)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205]  [120/172]  eta: 0:01:22  lr: 0.000088  loss: 0.3493 (0.3535)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205]  [130/172]  eta: 0:01:06  lr: 0.000088  loss: 0.3471 (0.3525)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205]  [140/172]  eta: 0:00:50  lr: 0.000088  loss: 0.3407 (0.3528)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205]  [150/172]  eta: 0:00:34  lr: 0.000088  loss: 0.3544 (0.3530)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205]  [160/172]  eta: 0:00:19  lr: 0.000088  loss: 0.3587 (0.3541)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205]  [170/172]  eta: 0:00:03  lr: 0.000088  loss: 0.3561 (0.3540)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205]  [171/172]  eta: 0:00:01  lr: 0.000088  loss: 0.3561 (0.3541)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:205] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000088  loss: 0.3561 (0.3541)\n",
      "Valid: [epoch:205]  [ 0/14]  eta: 0:00:04  loss: 0.3197 (0.3197)  time: 0.3443  data: 0.3290  max mem: 20571\n",
      "Valid: [epoch:205]  [13/14]  eta: 0:00:00  loss: 0.3280 (0.3384)  time: 0.0385  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:205] Total time: 0:00:00 (0.0434 s / it)\n",
      "Averaged stats: loss: 0.3280 (0.3384)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_205_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.338%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:206]  [  0/172]  eta: 0:07:33  lr: 0.000088  loss: 0.3665 (0.3665)  time: 2.6394  data: 1.0694  max mem: 20571\n",
      "Train: [epoch:206]  [ 10/172]  eta: 0:04:31  lr: 0.000088  loss: 0.3571 (0.3559)  time: 1.6737  data: 0.0973  max mem: 20571\n",
      "Train: [epoch:206]  [ 20/172]  eta: 0:04:07  lr: 0.000088  loss: 0.3571 (0.3611)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:206]  [ 30/172]  eta: 0:03:49  lr: 0.000088  loss: 0.3560 (0.3578)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:206]  [ 40/172]  eta: 0:03:31  lr: 0.000088  loss: 0.3473 (0.3566)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [ 50/172]  eta: 0:03:15  lr: 0.000088  loss: 0.3470 (0.3562)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [ 60/172]  eta: 0:02:58  lr: 0.000088  loss: 0.3472 (0.3566)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [ 70/172]  eta: 0:02:42  lr: 0.000088  loss: 0.3495 (0.3564)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [ 80/172]  eta: 0:02:26  lr: 0.000088  loss: 0.3516 (0.3556)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [ 90/172]  eta: 0:02:10  lr: 0.000088  loss: 0.3516 (0.3554)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [100/172]  eta: 0:01:54  lr: 0.000088  loss: 0.3626 (0.3562)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [110/172]  eta: 0:01:38  lr: 0.000088  loss: 0.3581 (0.3568)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [120/172]  eta: 0:01:22  lr: 0.000088  loss: 0.3585 (0.3572)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [130/172]  eta: 0:01:06  lr: 0.000088  loss: 0.3497 (0.3571)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [140/172]  eta: 0:00:50  lr: 0.000088  loss: 0.3466 (0.3571)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [150/172]  eta: 0:00:34  lr: 0.000088  loss: 0.3466 (0.3570)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [160/172]  eta: 0:00:19  lr: 0.000088  loss: 0.3513 (0.3566)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:206]  [170/172]  eta: 0:00:03  lr: 0.000088  loss: 0.3558 (0.3566)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:206]  [171/172]  eta: 0:00:01  lr: 0.000088  loss: 0.3541 (0.3565)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:206] Total time: 0:04:32 (1.5854 s / it)\n",
      "Averaged stats: lr: 0.000088  loss: 0.3541 (0.3565)\n",
      "Valid: [epoch:206]  [ 0/14]  eta: 0:00:04  loss: 0.3412 (0.3412)  time: 0.2895  data: 0.2743  max mem: 20571\n",
      "Valid: [epoch:206]  [13/14]  eta: 0:00:00  loss: 0.3485 (0.3579)  time: 0.0434  data: 0.0282  max mem: 20571\n",
      "Valid: [epoch:206] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 0.3485 (0.3579)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_206_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.358%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:207]  [  0/172]  eta: 0:07:28  lr: 0.000088  loss: 0.3710 (0.3710)  time: 2.6047  data: 1.0306  max mem: 20571\n",
      "Train: [epoch:207]  [ 10/172]  eta: 0:04:29  lr: 0.000088  loss: 0.3527 (0.3517)  time: 1.6666  data: 0.0938  max mem: 20571\n",
      "Train: [epoch:207]  [ 20/172]  eta: 0:04:06  lr: 0.000088  loss: 0.3527 (0.3553)  time: 1.5736  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [ 30/172]  eta: 0:03:48  lr: 0.000088  loss: 0.3529 (0.3560)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [ 40/172]  eta: 0:03:31  lr: 0.000088  loss: 0.3548 (0.3572)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [ 50/172]  eta: 0:03:14  lr: 0.000088  loss: 0.3569 (0.3574)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [ 60/172]  eta: 0:02:58  lr: 0.000088  loss: 0.3560 (0.3569)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [ 70/172]  eta: 0:02:42  lr: 0.000088  loss: 0.3505 (0.3567)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [ 80/172]  eta: 0:02:26  lr: 0.000088  loss: 0.3559 (0.3564)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [ 90/172]  eta: 0:02:10  lr: 0.000088  loss: 0.3597 (0.3571)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [100/172]  eta: 0:01:54  lr: 0.000088  loss: 0.3524 (0.3567)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [110/172]  eta: 0:01:38  lr: 0.000088  loss: 0.3506 (0.3569)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [120/172]  eta: 0:01:22  lr: 0.000088  loss: 0.3563 (0.3567)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [130/172]  eta: 0:01:06  lr: 0.000088  loss: 0.3634 (0.3578)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [140/172]  eta: 0:00:50  lr: 0.000088  loss: 0.3691 (0.3580)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [150/172]  eta: 0:00:34  lr: 0.000088  loss: 0.3565 (0.3579)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [160/172]  eta: 0:00:18  lr: 0.000088  loss: 0.3628 (0.3588)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [170/172]  eta: 0:00:03  lr: 0.000088  loss: 0.3609 (0.3588)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207]  [171/172]  eta: 0:00:01  lr: 0.000088  loss: 0.3609 (0.3589)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:207] Total time: 0:04:32 (1.5825 s / it)\n",
      "Averaged stats: lr: 0.000088  loss: 0.3609 (0.3589)\n",
      "Valid: [epoch:207]  [ 0/14]  eta: 0:00:04  loss: 0.3485 (0.3485)  time: 0.3350  data: 0.3175  max mem: 20571\n",
      "Valid: [epoch:207]  [13/14]  eta: 0:00:00  loss: 0.3486 (0.3586)  time: 0.0387  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:207] Total time: 0:00:00 (0.0439 s / it)\n",
      "Averaged stats: loss: 0.3486 (0.3586)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_207_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.359%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:208]  [  0/172]  eta: 0:07:40  lr: 0.000088  loss: 0.3950 (0.3950)  time: 2.6765  data: 1.1148  max mem: 20571\n",
      "Train: [epoch:208]  [ 10/172]  eta: 0:04:31  lr: 0.000088  loss: 0.3418 (0.3524)  time: 1.6746  data: 0.1015  max mem: 20571\n",
      "Train: [epoch:208]  [ 20/172]  eta: 0:04:07  lr: 0.000088  loss: 0.3418 (0.3529)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [ 30/172]  eta: 0:03:48  lr: 0.000088  loss: 0.3470 (0.3543)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [ 40/172]  eta: 0:03:31  lr: 0.000088  loss: 0.3570 (0.3561)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [ 50/172]  eta: 0:03:14  lr: 0.000088  loss: 0.3578 (0.3569)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [ 60/172]  eta: 0:02:58  lr: 0.000088  loss: 0.3507 (0.3559)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [ 70/172]  eta: 0:02:42  lr: 0.000088  loss: 0.3486 (0.3563)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [ 80/172]  eta: 0:02:26  lr: 0.000088  loss: 0.3559 (0.3569)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [ 90/172]  eta: 0:02:10  lr: 0.000088  loss: 0.3611 (0.3577)  time: 1.5750  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:208]  [100/172]  eta: 0:01:54  lr: 0.000088  loss: 0.3577 (0.3580)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [110/172]  eta: 0:01:38  lr: 0.000088  loss: 0.3518 (0.3581)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [120/172]  eta: 0:01:22  lr: 0.000088  loss: 0.3736 (0.3600)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [130/172]  eta: 0:01:06  lr: 0.000088  loss: 0.3778 (0.3606)  time: 1.5757  data: 0.0003  max mem: 20571\n",
      "Train: [epoch:208]  [140/172]  eta: 0:00:50  lr: 0.000088  loss: 0.3663 (0.3608)  time: 1.5761  data: 0.0003  max mem: 20571\n",
      "Train: [epoch:208]  [150/172]  eta: 0:00:34  lr: 0.000088  loss: 0.3617 (0.3607)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [160/172]  eta: 0:00:18  lr: 0.000088  loss: 0.3513 (0.3606)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208]  [170/172]  eta: 0:00:03  lr: 0.000088  loss: 0.3472 (0.3601)  time: 1.5773  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:208]  [171/172]  eta: 0:00:01  lr: 0.000088  loss: 0.3472 (0.3601)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:208] Total time: 0:04:32 (1.5827 s / it)\n",
      "Averaged stats: lr: 0.000088  loss: 0.3472 (0.3601)\n",
      "Valid: [epoch:208]  [ 0/14]  eta: 0:00:05  loss: 0.2924 (0.2924)  time: 0.4018  data: 0.3856  max mem: 20571\n",
      "Valid: [epoch:208]  [13/14]  eta: 0:00:00  loss: 0.3270 (0.3375)  time: 0.0428  data: 0.0278  max mem: 20571\n",
      "Valid: [epoch:208] Total time: 0:00:00 (0.0480 s / it)\n",
      "Averaged stats: loss: 0.3270 (0.3375)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_208_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.338%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:209]  [  0/172]  eta: 0:07:55  lr: 0.000088  loss: 0.3445 (0.3445)  time: 2.7642  data: 1.1932  max mem: 20571\n",
      "Train: [epoch:209]  [ 10/172]  eta: 0:04:32  lr: 0.000088  loss: 0.3547 (0.3558)  time: 1.6842  data: 0.1086  max mem: 20571\n",
      "Train: [epoch:209]  [ 20/172]  eta: 0:04:08  lr: 0.000088  loss: 0.3556 (0.3578)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [ 30/172]  eta: 0:03:49  lr: 0.000088  loss: 0.3558 (0.3573)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [ 40/172]  eta: 0:03:32  lr: 0.000088  loss: 0.3574 (0.3586)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [ 50/172]  eta: 0:03:15  lr: 0.000088  loss: 0.3585 (0.3598)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [ 60/172]  eta: 0:02:58  lr: 0.000088  loss: 0.3613 (0.3603)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [ 70/172]  eta: 0:02:42  lr: 0.000088  loss: 0.3622 (0.3606)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [ 80/172]  eta: 0:02:26  lr: 0.000088  loss: 0.3648 (0.3616)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [ 90/172]  eta: 0:02:10  lr: 0.000088  loss: 0.3692 (0.3629)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [100/172]  eta: 0:01:54  lr: 0.000088  loss: 0.3668 (0.3632)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [110/172]  eta: 0:01:38  lr: 0.000088  loss: 0.3507 (0.3626)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [120/172]  eta: 0:01:22  lr: 0.000088  loss: 0.3485 (0.3622)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [130/172]  eta: 0:01:06  lr: 0.000088  loss: 0.3497 (0.3627)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [140/172]  eta: 0:00:50  lr: 0.000088  loss: 0.3642 (0.3624)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [150/172]  eta: 0:00:34  lr: 0.000088  loss: 0.3617 (0.3621)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [160/172]  eta: 0:00:19  lr: 0.000088  loss: 0.3558 (0.3620)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [170/172]  eta: 0:00:03  lr: 0.000088  loss: 0.3558 (0.3630)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209]  [171/172]  eta: 0:00:01  lr: 0.000088  loss: 0.3604 (0.3631)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:209] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000088  loss: 0.3604 (0.3631)\n",
      "Valid: [epoch:209]  [ 0/14]  eta: 0:00:05  loss: 0.3325 (0.3325)  time: 0.3576  data: 0.3420  max mem: 20571\n",
      "Valid: [epoch:209]  [13/14]  eta: 0:00:00  loss: 0.3325 (0.3424)  time: 0.0406  data: 0.0255  max mem: 20571\n",
      "Valid: [epoch:209] Total time: 0:00:00 (0.0492 s / it)\n",
      "Averaged stats: loss: 0.3325 (0.3424)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_209_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.342%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:210]  [  0/172]  eta: 0:08:14  lr: 0.000088  loss: 0.3422 (0.3422)  time: 2.8734  data: 1.3085  max mem: 20571\n",
      "Train: [epoch:210]  [ 10/172]  eta: 0:04:34  lr: 0.000088  loss: 0.3560 (0.3591)  time: 1.6935  data: 0.1191  max mem: 20571\n",
      "Train: [epoch:210]  [ 20/172]  eta: 0:04:09  lr: 0.000088  loss: 0.3560 (0.3575)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [ 30/172]  eta: 0:03:49  lr: 0.000088  loss: 0.3535 (0.3601)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [ 40/172]  eta: 0:03:32  lr: 0.000088  loss: 0.3535 (0.3598)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [ 50/172]  eta: 0:03:15  lr: 0.000088  loss: 0.3627 (0.3622)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:210]  [ 60/172]  eta: 0:02:59  lr: 0.000088  loss: 0.3681 (0.3627)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:210]  [ 70/172]  eta: 0:02:42  lr: 0.000088  loss: 0.3678 (0.3629)  time: 1.5776  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:210]  [ 80/172]  eta: 0:02:26  lr: 0.000088  loss: 0.3641 (0.3626)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [ 90/172]  eta: 0:02:10  lr: 0.000088  loss: 0.3546 (0.3622)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [100/172]  eta: 0:01:54  lr: 0.000088  loss: 0.3546 (0.3620)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [110/172]  eta: 0:01:38  lr: 0.000088  loss: 0.3610 (0.3622)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [120/172]  eta: 0:01:22  lr: 0.000088  loss: 0.3647 (0.3632)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [130/172]  eta: 0:01:06  lr: 0.000088  loss: 0.3642 (0.3630)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [140/172]  eta: 0:00:50  lr: 0.000088  loss: 0.3594 (0.3631)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [150/172]  eta: 0:00:34  lr: 0.000088  loss: 0.3594 (0.3628)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [160/172]  eta: 0:00:19  lr: 0.000088  loss: 0.3510 (0.3623)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [170/172]  eta: 0:00:03  lr: 0.000088  loss: 0.3510 (0.3621)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210]  [171/172]  eta: 0:00:01  lr: 0.000088  loss: 0.3549 (0.3621)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:210] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000088  loss: 0.3549 (0.3621)\n",
      "Valid: [epoch:210]  [ 0/14]  eta: 0:00:04  loss: 0.3445 (0.3445)  time: 0.3050  data: 0.2900  max mem: 20571\n",
      "Valid: [epoch:210]  [13/14]  eta: 0:00:00  loss: 0.3448 (0.3552)  time: 0.0457  data: 0.0306  max mem: 20571\n",
      "Valid: [epoch:210] Total time: 0:00:00 (0.0533 s / it)\n",
      "Averaged stats: loss: 0.3448 (0.3552)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_210_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.355%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:211]  [  0/172]  eta: 0:07:38  lr: 0.000088  loss: 0.3706 (0.3706)  time: 2.6652  data: 1.0931  max mem: 20571\n",
      "Train: [epoch:211]  [ 10/172]  eta: 0:04:31  lr: 0.000088  loss: 0.3641 (0.3696)  time: 1.6730  data: 0.0995  max mem: 20571\n",
      "Train: [epoch:211]  [ 20/172]  eta: 0:04:07  lr: 0.000088  loss: 0.3641 (0.3678)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [ 30/172]  eta: 0:03:48  lr: 0.000088  loss: 0.3697 (0.3661)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [ 40/172]  eta: 0:03:31  lr: 0.000088  loss: 0.3588 (0.3656)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [ 50/172]  eta: 0:03:14  lr: 0.000088  loss: 0.3589 (0.3659)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [ 60/172]  eta: 0:02:58  lr: 0.000088  loss: 0.3569 (0.3651)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [ 70/172]  eta: 0:02:42  lr: 0.000088  loss: 0.3559 (0.3648)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [ 80/172]  eta: 0:02:26  lr: 0.000088  loss: 0.3604 (0.3646)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [ 90/172]  eta: 0:02:10  lr: 0.000088  loss: 0.3604 (0.3649)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [100/172]  eta: 0:01:54  lr: 0.000088  loss: 0.3632 (0.3649)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [110/172]  eta: 0:01:38  lr: 0.000088  loss: 0.3657 (0.3646)  time: 1.5803  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:211]  [120/172]  eta: 0:01:22  lr: 0.000088  loss: 0.3615 (0.3650)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [130/172]  eta: 0:01:06  lr: 0.000088  loss: 0.3579 (0.3647)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [140/172]  eta: 0:00:50  lr: 0.000088  loss: 0.3579 (0.3647)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [150/172]  eta: 0:00:34  lr: 0.000088  loss: 0.3570 (0.3643)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [160/172]  eta: 0:00:19  lr: 0.000088  loss: 0.3582 (0.3646)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [170/172]  eta: 0:00:03  lr: 0.000088  loss: 0.3529 (0.3643)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211]  [171/172]  eta: 0:00:01  lr: 0.000088  loss: 0.3529 (0.3644)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:211] Total time: 0:04:32 (1.5840 s / it)\n",
      "Averaged stats: lr: 0.000088  loss: 0.3529 (0.3644)\n",
      "Valid: [epoch:211]  [ 0/14]  eta: 0:00:04  loss: 0.3263 (0.3263)  time: 0.2985  data: 0.2838  max mem: 20571\n",
      "Valid: [epoch:211]  [13/14]  eta: 0:00:00  loss: 0.3350 (0.3453)  time: 0.0396  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:211] Total time: 0:00:00 (0.0476 s / it)\n",
      "Averaged stats: loss: 0.3350 (0.3453)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_211_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.345%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:212]  [  0/172]  eta: 0:07:52  lr: 0.000088  loss: 0.3858 (0.3858)  time: 2.7448  data: 1.1808  max mem: 20571\n",
      "Train: [epoch:212]  [ 10/172]  eta: 0:04:32  lr: 0.000088  loss: 0.3858 (0.3750)  time: 1.6833  data: 0.1075  max mem: 20571\n",
      "Train: [epoch:212]  [ 20/172]  eta: 0:04:08  lr: 0.000088  loss: 0.3791 (0.3757)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:212]  [ 30/172]  eta: 0:03:49  lr: 0.000088  loss: 0.3642 (0.3709)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:212]  [ 40/172]  eta: 0:03:32  lr: 0.000088  loss: 0.3592 (0.3705)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:212]  [ 50/172]  eta: 0:03:15  lr: 0.000088  loss: 0.3586 (0.3700)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [ 60/172]  eta: 0:02:58  lr: 0.000088  loss: 0.3634 (0.3694)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [ 70/172]  eta: 0:02:42  lr: 0.000088  loss: 0.3576 (0.3685)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [ 80/172]  eta: 0:02:26  lr: 0.000088  loss: 0.3576 (0.3673)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [ 90/172]  eta: 0:02:10  lr: 0.000088  loss: 0.3648 (0.3673)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [100/172]  eta: 0:01:54  lr: 0.000088  loss: 0.3642 (0.3668)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [110/172]  eta: 0:01:38  lr: 0.000088  loss: 0.3618 (0.3667)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [120/172]  eta: 0:01:22  lr: 0.000088  loss: 0.3617 (0.3662)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [130/172]  eta: 0:01:06  lr: 0.000088  loss: 0.3618 (0.3658)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [140/172]  eta: 0:00:50  lr: 0.000088  loss: 0.3662 (0.3662)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [150/172]  eta: 0:00:34  lr: 0.000088  loss: 0.3671 (0.3663)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [160/172]  eta: 0:00:19  lr: 0.000088  loss: 0.3562 (0.3660)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:212]  [170/172]  eta: 0:00:03  lr: 0.000088  loss: 0.3645 (0.3662)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212]  [171/172]  eta: 0:00:01  lr: 0.000088  loss: 0.3653 (0.3664)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:212] Total time: 0:04:32 (1.5854 s / it)\n",
      "Averaged stats: lr: 0.000088  loss: 0.3653 (0.3664)\n",
      "Valid: [epoch:212]  [ 0/14]  eta: 0:00:05  loss: 0.3092 (0.3092)  time: 0.3822  data: 0.3656  max mem: 20571\n",
      "Valid: [epoch:212]  [13/14]  eta: 0:00:00  loss: 0.3368 (0.3468)  time: 0.0414  data: 0.0262  max mem: 20571\n",
      "Valid: [epoch:212] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.3368 (0.3468)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_212_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.347%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:213]  [  0/172]  eta: 0:08:04  lr: 0.000088  loss: 0.3390 (0.3390)  time: 2.8149  data: 1.2416  max mem: 20571\n",
      "Train: [epoch:213]  [ 10/172]  eta: 0:04:33  lr: 0.000088  loss: 0.3660 (0.3707)  time: 1.6852  data: 0.1130  max mem: 20571\n",
      "Train: [epoch:213]  [ 20/172]  eta: 0:04:08  lr: 0.000088  loss: 0.3632 (0.3672)  time: 1.5738  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [ 30/172]  eta: 0:03:49  lr: 0.000088  loss: 0.3619 (0.3672)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [ 40/172]  eta: 0:03:31  lr: 0.000088  loss: 0.3631 (0.3683)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [ 50/172]  eta: 0:03:15  lr: 0.000088  loss: 0.3655 (0.3684)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [ 60/172]  eta: 0:02:58  lr: 0.000088  loss: 0.3660 (0.3676)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [ 70/172]  eta: 0:02:42  lr: 0.000088  loss: 0.3685 (0.3684)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [ 80/172]  eta: 0:02:26  lr: 0.000088  loss: 0.3717 (0.3682)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [ 90/172]  eta: 0:02:10  lr: 0.000088  loss: 0.3717 (0.3684)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [100/172]  eta: 0:01:54  lr: 0.000088  loss: 0.3709 (0.3694)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [110/172]  eta: 0:01:38  lr: 0.000088  loss: 0.3716 (0.3700)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [120/172]  eta: 0:01:22  lr: 0.000088  loss: 0.3837 (0.3707)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [130/172]  eta: 0:01:06  lr: 0.000088  loss: 0.3656 (0.3692)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [140/172]  eta: 0:00:50  lr: 0.000088  loss: 0.3579 (0.3692)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [150/172]  eta: 0:00:34  lr: 0.000088  loss: 0.3624 (0.3695)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [160/172]  eta: 0:00:19  lr: 0.000088  loss: 0.3609 (0.3693)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [170/172]  eta: 0:00:03  lr: 0.000088  loss: 0.3729 (0.3696)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213]  [171/172]  eta: 0:00:01  lr: 0.000088  loss: 0.3729 (0.3698)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:213] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000088  loss: 0.3729 (0.3698)\n",
      "Valid: [epoch:213]  [ 0/14]  eta: 0:00:04  loss: 0.2981 (0.2981)  time: 0.2891  data: 0.2738  max mem: 20571\n",
      "Valid: [epoch:213]  [13/14]  eta: 0:00:00  loss: 0.3334 (0.3442)  time: 0.0379  data: 0.0228  max mem: 20571\n",
      "Valid: [epoch:213] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.3334 (0.3442)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_213_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.344%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:214]  [  0/172]  eta: 0:07:31  lr: 0.000087  loss: 0.3144 (0.3144)  time: 2.6273  data: 1.0607  max mem: 20571\n",
      "Train: [epoch:214]  [ 10/172]  eta: 0:04:30  lr: 0.000087  loss: 0.3603 (0.3703)  time: 1.6709  data: 0.0966  max mem: 20571\n",
      "Train: [epoch:214]  [ 20/172]  eta: 0:04:07  lr: 0.000087  loss: 0.3619 (0.3712)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [ 30/172]  eta: 0:03:48  lr: 0.000087  loss: 0.3751 (0.3728)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [ 40/172]  eta: 0:03:31  lr: 0.000087  loss: 0.3683 (0.3707)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:214]  [ 50/172]  eta: 0:03:14  lr: 0.000087  loss: 0.3637 (0.3711)  time: 1.5794  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:214]  [ 60/172]  eta: 0:02:58  lr: 0.000087  loss: 0.3626 (0.3707)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [ 70/172]  eta: 0:02:42  lr: 0.000087  loss: 0.3663 (0.3706)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [ 80/172]  eta: 0:02:26  lr: 0.000087  loss: 0.3697 (0.3704)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [ 90/172]  eta: 0:02:10  lr: 0.000087  loss: 0.3631 (0.3696)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [100/172]  eta: 0:01:54  lr: 0.000087  loss: 0.3630 (0.3692)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [110/172]  eta: 0:01:38  lr: 0.000087  loss: 0.3664 (0.3696)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [120/172]  eta: 0:01:22  lr: 0.000087  loss: 0.3664 (0.3704)  time: 1.5739  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [130/172]  eta: 0:01:06  lr: 0.000087  loss: 0.3745 (0.3701)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [140/172]  eta: 0:00:50  lr: 0.000087  loss: 0.3730 (0.3699)  time: 1.5738  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [150/172]  eta: 0:00:34  lr: 0.000087  loss: 0.3540 (0.3693)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [160/172]  eta: 0:00:18  lr: 0.000087  loss: 0.3613 (0.3693)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [170/172]  eta: 0:00:03  lr: 0.000087  loss: 0.3641 (0.3695)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214]  [171/172]  eta: 0:00:01  lr: 0.000087  loss: 0.3662 (0.3695)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:214] Total time: 0:04:32 (1.5824 s / it)\n",
      "Averaged stats: lr: 0.000087  loss: 0.3662 (0.3695)\n",
      "Valid: [epoch:214]  [ 0/14]  eta: 0:00:06  loss: 0.3302 (0.3302)  time: 0.4874  data: 0.4711  max mem: 20571\n",
      "Valid: [epoch:214]  [13/14]  eta: 0:00:00  loss: 0.3387 (0.3488)  time: 0.0490  data: 0.0340  max mem: 20571\n",
      "Valid: [epoch:214] Total time: 0:00:00 (0.0548 s / it)\n",
      "Averaged stats: loss: 0.3387 (0.3488)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_214_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.349%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:215]  [  0/172]  eta: 0:07:32  lr: 0.000087  loss: 0.3600 (0.3600)  time: 2.6305  data: 1.0544  max mem: 20571\n",
      "Train: [epoch:215]  [ 10/172]  eta: 0:04:30  lr: 0.000087  loss: 0.3745 (0.3697)  time: 1.6683  data: 0.0960  max mem: 20571\n",
      "Train: [epoch:215]  [ 20/172]  eta: 0:04:06  lr: 0.000087  loss: 0.3745 (0.3693)  time: 1.5732  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [ 30/172]  eta: 0:03:48  lr: 0.000087  loss: 0.3730 (0.3695)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [ 40/172]  eta: 0:03:31  lr: 0.000087  loss: 0.3727 (0.3683)  time: 1.5743  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [ 50/172]  eta: 0:03:14  lr: 0.000087  loss: 0.3628 (0.3693)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [ 60/172]  eta: 0:02:58  lr: 0.000087  loss: 0.3637 (0.3695)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [ 70/172]  eta: 0:02:42  lr: 0.000087  loss: 0.3650 (0.3693)  time: 1.5732  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [ 80/172]  eta: 0:02:25  lr: 0.000087  loss: 0.3583 (0.3693)  time: 1.5736  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [ 90/172]  eta: 0:02:10  lr: 0.000087  loss: 0.3674 (0.3701)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [100/172]  eta: 0:01:54  lr: 0.000087  loss: 0.3676 (0.3697)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [110/172]  eta: 0:01:38  lr: 0.000087  loss: 0.3627 (0.3695)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [120/172]  eta: 0:01:22  lr: 0.000087  loss: 0.3721 (0.3694)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [130/172]  eta: 0:01:06  lr: 0.000087  loss: 0.3677 (0.3692)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [140/172]  eta: 0:00:50  lr: 0.000087  loss: 0.3679 (0.3691)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [150/172]  eta: 0:00:34  lr: 0.000087  loss: 0.3659 (0.3686)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [160/172]  eta: 0:00:18  lr: 0.000087  loss: 0.3659 (0.3693)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [170/172]  eta: 0:00:03  lr: 0.000087  loss: 0.3863 (0.3696)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215]  [171/172]  eta: 0:00:01  lr: 0.000087  loss: 0.3863 (0.3698)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:215] Total time: 0:04:32 (1.5816 s / it)\n",
      "Averaged stats: lr: 0.000087  loss: 0.3863 (0.3698)\n",
      "Valid: [epoch:215]  [ 0/14]  eta: 0:00:03  loss: 0.3224 (0.3224)  time: 0.2827  data: 0.2674  max mem: 20571\n",
      "Valid: [epoch:215]  [13/14]  eta: 0:00:00  loss: 0.3322 (0.3428)  time: 0.0425  data: 0.0276  max mem: 20571\n",
      "Valid: [epoch:215] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.3322 (0.3428)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_215_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.343%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:216]  [  0/172]  eta: 0:07:21  lr: 0.000087  loss: 0.3340 (0.3340)  time: 2.5667  data: 1.0010  max mem: 20571\n",
      "Train: [epoch:216]  [ 10/172]  eta: 0:04:30  lr: 0.000087  loss: 0.3606 (0.3646)  time: 1.6688  data: 0.0911  max mem: 20571\n",
      "Train: [epoch:216]  [ 20/172]  eta: 0:04:06  lr: 0.000087  loss: 0.3679 (0.3744)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [ 30/172]  eta: 0:03:48  lr: 0.000087  loss: 0.3781 (0.3754)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [ 40/172]  eta: 0:03:31  lr: 0.000087  loss: 0.3747 (0.3755)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [ 50/172]  eta: 0:03:14  lr: 0.000087  loss: 0.3652 (0.3735)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [ 60/172]  eta: 0:02:58  lr: 0.000087  loss: 0.3670 (0.3735)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [ 70/172]  eta: 0:02:42  lr: 0.000087  loss: 0.3679 (0.3739)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [ 80/172]  eta: 0:02:26  lr: 0.000087  loss: 0.3735 (0.3738)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [ 90/172]  eta: 0:02:10  lr: 0.000087  loss: 0.3767 (0.3743)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:216]  [100/172]  eta: 0:01:54  lr: 0.000087  loss: 0.3762 (0.3745)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [110/172]  eta: 0:01:38  lr: 0.000087  loss: 0.3728 (0.3744)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [120/172]  eta: 0:01:22  lr: 0.000087  loss: 0.3655 (0.3741)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [130/172]  eta: 0:01:06  lr: 0.000087  loss: 0.3676 (0.3740)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [140/172]  eta: 0:00:50  lr: 0.000087  loss: 0.3750 (0.3741)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [150/172]  eta: 0:00:34  lr: 0.000087  loss: 0.3750 (0.3742)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [160/172]  eta: 0:00:19  lr: 0.000087  loss: 0.3791 (0.3747)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [170/172]  eta: 0:00:03  lr: 0.000087  loss: 0.3765 (0.3740)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216]  [171/172]  eta: 0:00:01  lr: 0.000087  loss: 0.3765 (0.3740)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:216] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000087  loss: 0.3765 (0.3740)\n",
      "Valid: [epoch:216]  [ 0/14]  eta: 0:00:04  loss: 0.3231 (0.3231)  time: 0.3029  data: 0.2884  max mem: 20571\n",
      "Valid: [epoch:216]  [13/14]  eta: 0:00:00  loss: 0.3451 (0.3553)  time: 0.0387  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:216] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.3451 (0.3553)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_216_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.355%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:217]  [  0/172]  eta: 0:07:29  lr: 0.000087  loss: 0.3716 (0.3716)  time: 2.6115  data: 1.0344  max mem: 20571\n",
      "Train: [epoch:217]  [ 10/172]  eta: 0:04:30  lr: 0.000087  loss: 0.3787 (0.3812)  time: 1.6684  data: 0.0942  max mem: 20571\n",
      "Train: [epoch:217]  [ 20/172]  eta: 0:04:07  lr: 0.000087  loss: 0.3753 (0.3760)  time: 1.5764  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:217]  [ 30/172]  eta: 0:03:48  lr: 0.000087  loss: 0.3650 (0.3748)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:217]  [ 40/172]  eta: 0:03:31  lr: 0.000087  loss: 0.3781 (0.3748)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [ 50/172]  eta: 0:03:14  lr: 0.000087  loss: 0.3719 (0.3751)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [ 60/172]  eta: 0:02:58  lr: 0.000087  loss: 0.3755 (0.3756)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [ 70/172]  eta: 0:02:42  lr: 0.000087  loss: 0.3775 (0.3753)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [ 80/172]  eta: 0:02:26  lr: 0.000087  loss: 0.3767 (0.3759)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [ 90/172]  eta: 0:02:10  lr: 0.000087  loss: 0.3763 (0.3754)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [100/172]  eta: 0:01:54  lr: 0.000087  loss: 0.3699 (0.3758)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [110/172]  eta: 0:01:38  lr: 0.000087  loss: 0.3749 (0.3759)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [120/172]  eta: 0:01:22  lr: 0.000087  loss: 0.3718 (0.3751)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [130/172]  eta: 0:01:06  lr: 0.000087  loss: 0.3653 (0.3749)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [140/172]  eta: 0:00:50  lr: 0.000087  loss: 0.3618 (0.3743)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [150/172]  eta: 0:00:34  lr: 0.000087  loss: 0.3646 (0.3742)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [160/172]  eta: 0:00:19  lr: 0.000087  loss: 0.3724 (0.3745)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [170/172]  eta: 0:00:03  lr: 0.000087  loss: 0.3724 (0.3744)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217]  [171/172]  eta: 0:00:01  lr: 0.000087  loss: 0.3724 (0.3744)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:217] Total time: 0:04:32 (1.5843 s / it)\n",
      "Averaged stats: lr: 0.000087  loss: 0.3724 (0.3744)\n",
      "Valid: [epoch:217]  [ 0/14]  eta: 0:00:04  loss: 0.3406 (0.3406)  time: 0.3002  data: 0.2854  max mem: 20571\n",
      "Valid: [epoch:217]  [13/14]  eta: 0:00:00  loss: 0.3411 (0.3522)  time: 0.0377  data: 0.0227  max mem: 20571\n",
      "Valid: [epoch:217] Total time: 0:00:00 (0.0445 s / it)\n",
      "Averaged stats: loss: 0.3411 (0.3522)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_217_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.352%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:218]  [  0/172]  eta: 0:08:23  lr: 0.000087  loss: 0.3478 (0.3478)  time: 2.9300  data: 1.3654  max mem: 20571\n",
      "Train: [epoch:218]  [ 10/172]  eta: 0:04:35  lr: 0.000087  loss: 0.3688 (0.3663)  time: 1.6996  data: 0.1243  max mem: 20571\n",
      "Train: [epoch:218]  [ 20/172]  eta: 0:04:09  lr: 0.000087  loss: 0.3748 (0.3728)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [ 30/172]  eta: 0:03:50  lr: 0.000087  loss: 0.3844 (0.3782)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [ 40/172]  eta: 0:03:32  lr: 0.000087  loss: 0.3871 (0.3779)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [ 50/172]  eta: 0:03:15  lr: 0.000087  loss: 0.3749 (0.3792)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [ 60/172]  eta: 0:02:59  lr: 0.000087  loss: 0.3749 (0.3776)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [ 70/172]  eta: 0:02:42  lr: 0.000087  loss: 0.3707 (0.3783)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [ 80/172]  eta: 0:02:26  lr: 0.000087  loss: 0.3720 (0.3777)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [ 90/172]  eta: 0:02:10  lr: 0.000087  loss: 0.3673 (0.3776)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [100/172]  eta: 0:01:54  lr: 0.000087  loss: 0.3654 (0.3770)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [110/172]  eta: 0:01:38  lr: 0.000087  loss: 0.3650 (0.3766)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [120/172]  eta: 0:01:22  lr: 0.000087  loss: 0.3648 (0.3765)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [130/172]  eta: 0:01:06  lr: 0.000087  loss: 0.3701 (0.3758)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [140/172]  eta: 0:00:50  lr: 0.000087  loss: 0.3662 (0.3755)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [150/172]  eta: 0:00:34  lr: 0.000087  loss: 0.3711 (0.3756)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [160/172]  eta: 0:00:19  lr: 0.000087  loss: 0.3789 (0.3762)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [170/172]  eta: 0:00:03  lr: 0.000087  loss: 0.3789 (0.3761)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218]  [171/172]  eta: 0:00:01  lr: 0.000087  loss: 0.3789 (0.3762)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:218] Total time: 0:04:32 (1.5854 s / it)\n",
      "Averaged stats: lr: 0.000087  loss: 0.3789 (0.3762)\n",
      "Valid: [epoch:218]  [ 0/14]  eta: 0:00:04  loss: 0.3908 (0.3908)  time: 0.2965  data: 0.2807  max mem: 20571\n",
      "Valid: [epoch:218]  [13/14]  eta: 0:00:00  loss: 0.3568 (0.3678)  time: 0.0427  data: 0.0276  max mem: 20571\n",
      "Valid: [epoch:218] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.3568 (0.3678)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_218_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.368%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:219]  [  0/172]  eta: 0:07:36  lr: 0.000087  loss: 0.3792 (0.3792)  time: 2.6554  data: 1.0866  max mem: 20571\n",
      "Train: [epoch:219]  [ 10/172]  eta: 0:04:30  lr: 0.000087  loss: 0.3812 (0.3812)  time: 1.6696  data: 0.0989  max mem: 20571\n",
      "Train: [epoch:219]  [ 20/172]  eta: 0:04:06  lr: 0.000087  loss: 0.3743 (0.3801)  time: 1.5724  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [ 30/172]  eta: 0:03:48  lr: 0.000087  loss: 0.3757 (0.3791)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [ 40/172]  eta: 0:03:31  lr: 0.000087  loss: 0.3764 (0.3797)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [ 50/172]  eta: 0:03:14  lr: 0.000087  loss: 0.3712 (0.3804)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [ 60/172]  eta: 0:02:58  lr: 0.000087  loss: 0.3786 (0.3799)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [ 70/172]  eta: 0:02:42  lr: 0.000087  loss: 0.3786 (0.3797)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [ 80/172]  eta: 0:02:26  lr: 0.000087  loss: 0.3802 (0.3817)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [ 90/172]  eta: 0:02:10  lr: 0.000087  loss: 0.3803 (0.3811)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [100/172]  eta: 0:01:54  lr: 0.000087  loss: 0.3693 (0.3803)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [110/172]  eta: 0:01:38  lr: 0.000087  loss: 0.3650 (0.3803)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [120/172]  eta: 0:01:22  lr: 0.000087  loss: 0.3734 (0.3800)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [130/172]  eta: 0:01:06  lr: 0.000087  loss: 0.3652 (0.3795)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [140/172]  eta: 0:00:50  lr: 0.000087  loss: 0.3751 (0.3796)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [150/172]  eta: 0:00:34  lr: 0.000087  loss: 0.3663 (0.3786)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [160/172]  eta: 0:00:18  lr: 0.000087  loss: 0.3616 (0.3788)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219]  [170/172]  eta: 0:00:03  lr: 0.000087  loss: 0.3752 (0.3788)  time: 1.5798  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:219]  [171/172]  eta: 0:00:01  lr: 0.000087  loss: 0.3700 (0.3787)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:219] Total time: 0:04:32 (1.5827 s / it)\n",
      "Averaged stats: lr: 0.000087  loss: 0.3700 (0.3787)\n",
      "Valid: [epoch:219]  [ 0/14]  eta: 0:00:04  loss: 0.3904 (0.3904)  time: 0.3086  data: 0.2936  max mem: 20571\n",
      "Valid: [epoch:219]  [13/14]  eta: 0:00:00  loss: 0.3569 (0.3668)  time: 0.0391  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:219] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.3569 (0.3668)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_219_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.367%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:220]  [  0/172]  eta: 0:07:29  lr: 0.000087  loss: 0.4284 (0.4284)  time: 2.6126  data: 1.0456  max mem: 20571\n",
      "Train: [epoch:220]  [ 10/172]  eta: 0:04:30  lr: 0.000087  loss: 0.3674 (0.3737)  time: 1.6717  data: 0.0952  max mem: 20571\n",
      "Train: [epoch:220]  [ 20/172]  eta: 0:04:07  lr: 0.000087  loss: 0.3706 (0.3788)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [ 30/172]  eta: 0:03:48  lr: 0.000087  loss: 0.3752 (0.3775)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [ 40/172]  eta: 0:03:31  lr: 0.000087  loss: 0.3728 (0.3777)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [ 50/172]  eta: 0:03:15  lr: 0.000087  loss: 0.3738 (0.3789)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [ 60/172]  eta: 0:02:58  lr: 0.000087  loss: 0.3738 (0.3773)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [ 70/172]  eta: 0:02:42  lr: 0.000087  loss: 0.3717 (0.3771)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [ 80/172]  eta: 0:02:26  lr: 0.000087  loss: 0.3787 (0.3775)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [ 90/172]  eta: 0:02:10  lr: 0.000087  loss: 0.3795 (0.3776)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [100/172]  eta: 0:01:54  lr: 0.000087  loss: 0.3855 (0.3787)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [110/172]  eta: 0:01:38  lr: 0.000087  loss: 0.3837 (0.3788)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [120/172]  eta: 0:01:22  lr: 0.000087  loss: 0.3722 (0.3786)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [130/172]  eta: 0:01:06  lr: 0.000087  loss: 0.3739 (0.3790)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [140/172]  eta: 0:00:50  lr: 0.000087  loss: 0.3742 (0.3787)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [150/172]  eta: 0:00:34  lr: 0.000087  loss: 0.3725 (0.3789)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [160/172]  eta: 0:00:19  lr: 0.000087  loss: 0.3710 (0.3783)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [170/172]  eta: 0:00:03  lr: 0.000087  loss: 0.3773 (0.3787)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220]  [171/172]  eta: 0:00:01  lr: 0.000087  loss: 0.3773 (0.3785)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:220] Total time: 0:04:32 (1.5846 s / it)\n",
      "Averaged stats: lr: 0.000087  loss: 0.3773 (0.3785)\n",
      "Valid: [epoch:220]  [ 0/14]  eta: 0:00:04  loss: 0.3771 (0.3771)  time: 0.3027  data: 0.2792  max mem: 20571\n",
      "Valid: [epoch:220]  [13/14]  eta: 0:00:00  loss: 0.3417 (0.3529)  time: 0.0429  data: 0.0272  max mem: 20571\n",
      "Valid: [epoch:220] Total time: 0:00:00 (0.0516 s / it)\n",
      "Averaged stats: loss: 0.3417 (0.3529)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_220_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.353%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:221]  [  0/172]  eta: 0:08:07  lr: 0.000087  loss: 0.3789 (0.3789)  time: 2.8357  data: 1.2617  max mem: 20571\n",
      "Train: [epoch:221]  [ 10/172]  eta: 0:04:33  lr: 0.000087  loss: 0.3766 (0.3768)  time: 1.6890  data: 0.1148  max mem: 20571\n",
      "Train: [epoch:221]  [ 20/172]  eta: 0:04:08  lr: 0.000087  loss: 0.3658 (0.3743)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [ 30/172]  eta: 0:03:49  lr: 0.000087  loss: 0.3687 (0.3773)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [ 40/172]  eta: 0:03:32  lr: 0.000087  loss: 0.3839 (0.3797)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [ 50/172]  eta: 0:03:15  lr: 0.000087  loss: 0.3761 (0.3792)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [ 60/172]  eta: 0:02:58  lr: 0.000087  loss: 0.3814 (0.3804)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [ 70/172]  eta: 0:02:42  lr: 0.000087  loss: 0.3816 (0.3807)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [ 80/172]  eta: 0:02:26  lr: 0.000087  loss: 0.3887 (0.3824)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [ 90/172]  eta: 0:02:10  lr: 0.000087  loss: 0.3813 (0.3819)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [100/172]  eta: 0:01:54  lr: 0.000087  loss: 0.3839 (0.3828)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [110/172]  eta: 0:01:38  lr: 0.000087  loss: 0.3861 (0.3828)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [120/172]  eta: 0:01:22  lr: 0.000087  loss: 0.3781 (0.3825)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [130/172]  eta: 0:01:06  lr: 0.000087  loss: 0.3760 (0.3817)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [140/172]  eta: 0:00:50  lr: 0.000087  loss: 0.3733 (0.3819)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [150/172]  eta: 0:00:34  lr: 0.000087  loss: 0.3729 (0.3818)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [160/172]  eta: 0:00:19  lr: 0.000087  loss: 0.3767 (0.3825)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [170/172]  eta: 0:00:03  lr: 0.000087  loss: 0.3793 (0.3825)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221]  [171/172]  eta: 0:00:01  lr: 0.000087  loss: 0.3817 (0.3825)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:221] Total time: 0:04:32 (1.5847 s / it)\n",
      "Averaged stats: lr: 0.000087  loss: 0.3817 (0.3825)\n",
      "Valid: [epoch:221]  [ 0/14]  eta: 0:00:04  loss: 0.3435 (0.3435)  time: 0.2945  data: 0.2797  max mem: 20571\n",
      "Valid: [epoch:221]  [13/14]  eta: 0:00:00  loss: 0.3515 (0.3626)  time: 0.0387  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:221] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.3515 (0.3626)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_221_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.363%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:222]  [  0/172]  eta: 0:07:20  lr: 0.000087  loss: 0.3681 (0.3681)  time: 2.5635  data: 0.9999  max mem: 20571\n",
      "Train: [epoch:222]  [ 10/172]  eta: 0:04:29  lr: 0.000087  loss: 0.3814 (0.3785)  time: 1.6659  data: 0.0910  max mem: 20571\n",
      "Train: [epoch:222]  [ 20/172]  eta: 0:04:06  lr: 0.000087  loss: 0.3797 (0.3788)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [ 30/172]  eta: 0:03:48  lr: 0.000087  loss: 0.3779 (0.3786)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [ 40/172]  eta: 0:03:31  lr: 0.000087  loss: 0.3779 (0.3795)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [ 50/172]  eta: 0:03:14  lr: 0.000087  loss: 0.3760 (0.3792)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [ 60/172]  eta: 0:02:58  lr: 0.000087  loss: 0.3733 (0.3790)  time: 1.5756  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:222]  [ 70/172]  eta: 0:02:42  lr: 0.000087  loss: 0.3733 (0.3792)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [ 80/172]  eta: 0:02:26  lr: 0.000087  loss: 0.3726 (0.3786)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [ 90/172]  eta: 0:02:10  lr: 0.000087  loss: 0.3789 (0.3796)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [100/172]  eta: 0:01:54  lr: 0.000087  loss: 0.3937 (0.3809)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [110/172]  eta: 0:01:38  lr: 0.000087  loss: 0.3904 (0.3810)  time: 1.5757  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:222]  [120/172]  eta: 0:01:22  lr: 0.000087  loss: 0.3800 (0.3817)  time: 1.5739  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [130/172]  eta: 0:01:06  lr: 0.000087  loss: 0.3806 (0.3816)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [140/172]  eta: 0:00:50  lr: 0.000087  loss: 0.3776 (0.3818)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [150/172]  eta: 0:00:34  lr: 0.000087  loss: 0.3762 (0.3814)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [160/172]  eta: 0:00:18  lr: 0.000087  loss: 0.3714 (0.3814)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [170/172]  eta: 0:00:03  lr: 0.000087  loss: 0.3767 (0.3823)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222]  [171/172]  eta: 0:00:01  lr: 0.000087  loss: 0.3767 (0.3828)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:222] Total time: 0:04:32 (1.5820 s / it)\n",
      "Averaged stats: lr: 0.000087  loss: 0.3767 (0.3828)\n",
      "Valid: [epoch:222]  [ 0/14]  eta: 0:00:04  loss: 0.3341 (0.3341)  time: 0.3324  data: 0.3134  max mem: 20571\n",
      "Valid: [epoch:222]  [13/14]  eta: 0:00:00  loss: 0.3418 (0.3534)  time: 0.0377  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:222] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.3418 (0.3534)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_222_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.353%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:223]  [  0/172]  eta: 0:07:32  lr: 0.000086  loss: 0.3630 (0.3630)  time: 2.6290  data: 1.0598  max mem: 20571\n",
      "Train: [epoch:223]  [ 10/172]  eta: 0:04:30  lr: 0.000086  loss: 0.3804 (0.3948)  time: 1.6682  data: 0.0964  max mem: 20571\n",
      "Train: [epoch:223]  [ 20/172]  eta: 0:04:06  lr: 0.000086  loss: 0.3872 (0.3960)  time: 1.5737  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [ 30/172]  eta: 0:03:48  lr: 0.000086  loss: 0.3888 (0.3923)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [ 40/172]  eta: 0:03:31  lr: 0.000086  loss: 0.3860 (0.3906)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [ 50/172]  eta: 0:03:14  lr: 0.000086  loss: 0.3835 (0.3892)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [ 60/172]  eta: 0:02:58  lr: 0.000086  loss: 0.3767 (0.3870)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [ 70/172]  eta: 0:02:42  lr: 0.000086  loss: 0.3754 (0.3859)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [ 80/172]  eta: 0:02:26  lr: 0.000086  loss: 0.3710 (0.3851)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [ 90/172]  eta: 0:02:10  lr: 0.000086  loss: 0.3792 (0.3851)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [100/172]  eta: 0:01:54  lr: 0.000086  loss: 0.3818 (0.3850)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [110/172]  eta: 0:01:38  lr: 0.000086  loss: 0.3819 (0.3847)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [120/172]  eta: 0:01:22  lr: 0.000086  loss: 0.3821 (0.3842)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [130/172]  eta: 0:01:06  lr: 0.000086  loss: 0.3791 (0.3841)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [140/172]  eta: 0:00:50  lr: 0.000086  loss: 0.3838 (0.3838)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [150/172]  eta: 0:00:34  lr: 0.000086  loss: 0.3820 (0.3832)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [160/172]  eta: 0:00:19  lr: 0.000086  loss: 0.3803 (0.3833)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [170/172]  eta: 0:00:03  lr: 0.000086  loss: 0.3803 (0.3833)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223]  [171/172]  eta: 0:00:01  lr: 0.000086  loss: 0.3820 (0.3833)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:223] Total time: 0:04:32 (1.5841 s / it)\n",
      "Averaged stats: lr: 0.000086  loss: 0.3820 (0.3833)\n",
      "Valid: [epoch:223]  [ 0/14]  eta: 0:00:03  loss: 0.3502 (0.3502)  time: 0.2810  data: 0.2655  max mem: 20571\n",
      "Valid: [epoch:223]  [13/14]  eta: 0:00:00  loss: 0.3502 (0.3610)  time: 0.0377  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:223] Total time: 0:00:00 (0.0424 s / it)\n",
      "Averaged stats: loss: 0.3502 (0.3610)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_223_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.361%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:224]  [  0/172]  eta: 0:07:45  lr: 0.000086  loss: 0.3707 (0.3707)  time: 2.7061  data: 1.1432  max mem: 20571\n",
      "Train: [epoch:224]  [ 10/172]  eta: 0:04:31  lr: 0.000086  loss: 0.3894 (0.3784)  time: 1.6778  data: 0.1040  max mem: 20571\n",
      "Train: [epoch:224]  [ 20/172]  eta: 0:04:07  lr: 0.000086  loss: 0.3894 (0.3825)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [ 30/172]  eta: 0:03:48  lr: 0.000086  loss: 0.3802 (0.3810)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [ 40/172]  eta: 0:03:31  lr: 0.000086  loss: 0.3762 (0.3816)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [ 50/172]  eta: 0:03:15  lr: 0.000086  loss: 0.3833 (0.3845)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [ 60/172]  eta: 0:02:58  lr: 0.000086  loss: 0.3821 (0.3832)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [ 70/172]  eta: 0:02:42  lr: 0.000086  loss: 0.3847 (0.3855)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [ 80/172]  eta: 0:02:26  lr: 0.000086  loss: 0.3931 (0.3865)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [ 90/172]  eta: 0:02:10  lr: 0.000086  loss: 0.3853 (0.3865)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [100/172]  eta: 0:01:54  lr: 0.000086  loss: 0.3715 (0.3855)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [110/172]  eta: 0:01:38  lr: 0.000086  loss: 0.3719 (0.3851)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [120/172]  eta: 0:01:22  lr: 0.000086  loss: 0.3751 (0.3848)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [130/172]  eta: 0:01:06  lr: 0.000086  loss: 0.3751 (0.3852)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [140/172]  eta: 0:00:50  lr: 0.000086  loss: 0.3781 (0.3855)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [150/172]  eta: 0:00:34  lr: 0.000086  loss: 0.3897 (0.3860)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [160/172]  eta: 0:00:19  lr: 0.000086  loss: 0.3870 (0.3856)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [170/172]  eta: 0:00:03  lr: 0.000086  loss: 0.3870 (0.3858)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224]  [171/172]  eta: 0:00:01  lr: 0.000086  loss: 0.3870 (0.3856)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:224] Total time: 0:04:32 (1.5836 s / it)\n",
      "Averaged stats: lr: 0.000086  loss: 0.3870 (0.3856)\n",
      "Valid: [epoch:224]  [ 0/14]  eta: 0:00:04  loss: 0.3714 (0.3714)  time: 0.3005  data: 0.2854  max mem: 20571\n",
      "Valid: [epoch:224]  [13/14]  eta: 0:00:00  loss: 0.3719 (0.3825)  time: 0.0395  data: 0.0247  max mem: 20571\n",
      "Valid: [epoch:224] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 0.3719 (0.3825)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_224_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.383%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:225]  [  0/172]  eta: 0:07:35  lr: 0.000086  loss: 0.3556 (0.3556)  time: 2.6503  data: 1.0554  max mem: 20571\n",
      "Train: [epoch:225]  [ 10/172]  eta: 0:04:30  lr: 0.000086  loss: 0.3932 (0.3912)  time: 1.6701  data: 0.0961  max mem: 20571\n",
      "Train: [epoch:225]  [ 20/172]  eta: 0:04:06  lr: 0.000086  loss: 0.3932 (0.3878)  time: 1.5725  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [ 30/172]  eta: 0:03:48  lr: 0.000086  loss: 0.3803 (0.3866)  time: 1.5735  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [ 40/172]  eta: 0:03:31  lr: 0.000086  loss: 0.3803 (0.3848)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [ 50/172]  eta: 0:03:14  lr: 0.000086  loss: 0.3869 (0.3877)  time: 1.5754  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:225]  [ 60/172]  eta: 0:02:58  lr: 0.000086  loss: 0.3879 (0.3870)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [ 70/172]  eta: 0:02:42  lr: 0.000086  loss: 0.3879 (0.3881)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [ 80/172]  eta: 0:02:26  lr: 0.000086  loss: 0.3896 (0.3870)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [ 90/172]  eta: 0:02:10  lr: 0.000086  loss: 0.3896 (0.3878)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [100/172]  eta: 0:01:54  lr: 0.000086  loss: 0.3932 (0.3881)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [110/172]  eta: 0:01:38  lr: 0.000086  loss: 0.3898 (0.3883)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [120/172]  eta: 0:01:22  lr: 0.000086  loss: 0.3849 (0.3877)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [130/172]  eta: 0:01:06  lr: 0.000086  loss: 0.3831 (0.3877)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [140/172]  eta: 0:00:50  lr: 0.000086  loss: 0.3816 (0.3877)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [150/172]  eta: 0:00:34  lr: 0.000086  loss: 0.3857 (0.3881)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [160/172]  eta: 0:00:18  lr: 0.000086  loss: 0.3820 (0.3880)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [170/172]  eta: 0:00:03  lr: 0.000086  loss: 0.3816 (0.3886)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225]  [171/172]  eta: 0:00:01  lr: 0.000086  loss: 0.3816 (0.3884)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:225] Total time: 0:04:32 (1.5817 s / it)\n",
      "Averaged stats: lr: 0.000086  loss: 0.3816 (0.3884)\n",
      "Valid: [epoch:225]  [ 0/14]  eta: 0:00:04  loss: 0.3600 (0.3600)  time: 0.3425  data: 0.3260  max mem: 20571\n",
      "Valid: [epoch:225]  [13/14]  eta: 0:00:00  loss: 0.3689 (0.3797)  time: 0.0445  data: 0.0297  max mem: 20571\n",
      "Valid: [epoch:225] Total time: 0:00:00 (0.0499 s / it)\n",
      "Averaged stats: loss: 0.3689 (0.3797)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_225_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.380%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:226]  [  0/172]  eta: 0:07:35  lr: 0.000086  loss: 0.3723 (0.3723)  time: 2.6487  data: 1.0800  max mem: 20571\n",
      "Train: [epoch:226]  [ 10/172]  eta: 0:04:30  lr: 0.000086  loss: 0.3816 (0.3866)  time: 1.6700  data: 0.0983  max mem: 20571\n",
      "Train: [epoch:226]  [ 20/172]  eta: 0:04:06  lr: 0.000086  loss: 0.3885 (0.3903)  time: 1.5728  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [ 30/172]  eta: 0:03:48  lr: 0.000086  loss: 0.3920 (0.3914)  time: 1.5737  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [ 40/172]  eta: 0:03:31  lr: 0.000086  loss: 0.3933 (0.3922)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [ 50/172]  eta: 0:03:14  lr: 0.000086  loss: 0.3988 (0.3925)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [ 60/172]  eta: 0:02:58  lr: 0.000086  loss: 0.3988 (0.3928)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [ 70/172]  eta: 0:02:42  lr: 0.000086  loss: 0.3882 (0.3933)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [ 80/172]  eta: 0:02:26  lr: 0.000086  loss: 0.3864 (0.3927)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [ 90/172]  eta: 0:02:10  lr: 0.000086  loss: 0.3773 (0.3916)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [100/172]  eta: 0:01:54  lr: 0.000086  loss: 0.3770 (0.3920)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [110/172]  eta: 0:01:38  lr: 0.000086  loss: 0.3929 (0.3924)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [120/172]  eta: 0:01:22  lr: 0.000086  loss: 0.3852 (0.3917)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [130/172]  eta: 0:01:06  lr: 0.000086  loss: 0.3831 (0.3916)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [140/172]  eta: 0:00:50  lr: 0.000086  loss: 0.3831 (0.3912)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [150/172]  eta: 0:00:34  lr: 0.000086  loss: 0.3744 (0.3905)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [160/172]  eta: 0:00:18  lr: 0.000086  loss: 0.3728 (0.3896)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [170/172]  eta: 0:00:03  lr: 0.000086  loss: 0.3765 (0.3896)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226]  [171/172]  eta: 0:00:01  lr: 0.000086  loss: 0.3801 (0.3896)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:226] Total time: 0:04:32 (1.5823 s / it)\n",
      "Averaged stats: lr: 0.000086  loss: 0.3801 (0.3896)\n",
      "Valid: [epoch:226]  [ 0/14]  eta: 0:00:04  loss: 0.3731 (0.3731)  time: 0.3111  data: 0.2947  max mem: 20571\n",
      "Valid: [epoch:226]  [13/14]  eta: 0:00:00  loss: 0.3482 (0.3595)  time: 0.0453  data: 0.0300  max mem: 20571\n",
      "Valid: [epoch:226] Total time: 0:00:00 (0.0529 s / it)\n",
      "Averaged stats: loss: 0.3482 (0.3595)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_226_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.359%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:227]  [  0/172]  eta: 0:07:49  lr: 0.000086  loss: 0.4123 (0.4123)  time: 2.7318  data: 1.1498  max mem: 20571\n",
      "Train: [epoch:227]  [ 10/172]  eta: 0:04:31  lr: 0.000086  loss: 0.3928 (0.3902)  time: 1.6764  data: 0.1046  max mem: 20571\n",
      "Train: [epoch:227]  [ 20/172]  eta: 0:04:07  lr: 0.000086  loss: 0.3914 (0.3895)  time: 1.5727  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:227]  [ 30/172]  eta: 0:03:48  lr: 0.000086  loss: 0.3873 (0.3886)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:227]  [ 40/172]  eta: 0:03:31  lr: 0.000086  loss: 0.3856 (0.3892)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:227]  [ 50/172]  eta: 0:03:15  lr: 0.000086  loss: 0.3868 (0.3896)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:227]  [ 60/172]  eta: 0:02:58  lr: 0.000086  loss: 0.3874 (0.3889)  time: 1.5760  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:227]  [ 70/172]  eta: 0:02:42  lr: 0.000086  loss: 0.3858 (0.3898)  time: 1.5748  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:227]  [ 80/172]  eta: 0:02:26  lr: 0.000086  loss: 0.3903 (0.3899)  time: 1.5745  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:227]  [ 90/172]  eta: 0:02:10  lr: 0.000086  loss: 0.3834 (0.3892)  time: 1.5743  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:227]  [100/172]  eta: 0:01:54  lr: 0.000086  loss: 0.3722 (0.3886)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:227]  [110/172]  eta: 0:01:38  lr: 0.000086  loss: 0.3827 (0.3887)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:227]  [120/172]  eta: 0:01:22  lr: 0.000086  loss: 0.3787 (0.3882)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:227]  [130/172]  eta: 0:01:06  lr: 0.000086  loss: 0.3787 (0.3880)  time: 1.5760  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:227]  [140/172]  eta: 0:00:50  lr: 0.000086  loss: 0.3906 (0.3886)  time: 1.5757  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:227]  [150/172]  eta: 0:00:34  lr: 0.000086  loss: 0.3915 (0.3891)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:227]  [160/172]  eta: 0:00:18  lr: 0.000086  loss: 0.3915 (0.3889)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:227]  [170/172]  eta: 0:00:03  lr: 0.000086  loss: 0.3942 (0.3896)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:227]  [171/172]  eta: 0:00:01  lr: 0.000086  loss: 0.3899 (0.3895)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:227] Total time: 0:04:32 (1.5836 s / it)\n",
      "Averaged stats: lr: 0.000086  loss: 0.3899 (0.3895)\n",
      "Valid: [epoch:227]  [ 0/14]  eta: 0:00:04  loss: 0.4011 (0.4011)  time: 0.3367  data: 0.3211  max mem: 20571\n",
      "Valid: [epoch:227]  [13/14]  eta: 0:00:00  loss: 0.3599 (0.3712)  time: 0.0424  data: 0.0274  max mem: 20571\n",
      "Valid: [epoch:227] Total time: 0:00:00 (0.0476 s / it)\n",
      "Averaged stats: loss: 0.3599 (0.3712)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_227_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.371%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:228]  [  0/172]  eta: 0:07:52  lr: 0.000086  loss: 0.3715 (0.3715)  time: 2.7463  data: 1.1836  max mem: 20571\n",
      "Train: [epoch:228]  [ 10/172]  eta: 0:04:32  lr: 0.000086  loss: 0.3900 (0.3911)  time: 1.6826  data: 0.1077  max mem: 20571\n",
      "Train: [epoch:228]  [ 20/172]  eta: 0:04:07  lr: 0.000086  loss: 0.3919 (0.3919)  time: 1.5752  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [ 30/172]  eta: 0:03:49  lr: 0.000086  loss: 0.3931 (0.3898)  time: 1.5743  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [ 40/172]  eta: 0:03:31  lr: 0.000086  loss: 0.3949 (0.3910)  time: 1.5748  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [ 50/172]  eta: 0:03:14  lr: 0.000086  loss: 0.3961 (0.3912)  time: 1.5756  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [ 60/172]  eta: 0:02:58  lr: 0.000086  loss: 0.3851 (0.3907)  time: 1.5755  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [ 70/172]  eta: 0:02:42  lr: 0.000086  loss: 0.3806 (0.3902)  time: 1.5752  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [ 80/172]  eta: 0:02:26  lr: 0.000086  loss: 0.3942 (0.3906)  time: 1.5755  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [ 90/172]  eta: 0:02:10  lr: 0.000086  loss: 0.3966 (0.3907)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:228]  [100/172]  eta: 0:01:54  lr: 0.000086  loss: 0.3941 (0.3910)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:228]  [110/172]  eta: 0:01:38  lr: 0.000086  loss: 0.3964 (0.3913)  time: 1.5769  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [120/172]  eta: 0:01:22  lr: 0.000086  loss: 0.3818 (0.3910)  time: 1.5753  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [130/172]  eta: 0:01:06  lr: 0.000086  loss: 0.3810 (0.3908)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:228]  [140/172]  eta: 0:00:50  lr: 0.000086  loss: 0.3891 (0.3910)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:228]  [150/172]  eta: 0:00:34  lr: 0.000086  loss: 0.3912 (0.3911)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:228]  [160/172]  eta: 0:00:18  lr: 0.000086  loss: 0.3917 (0.3913)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:228]  [170/172]  eta: 0:00:03  lr: 0.000086  loss: 0.3907 (0.3912)  time: 1.5760  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228]  [171/172]  eta: 0:00:01  lr: 0.000086  loss: 0.3907 (0.3918)  time: 1.5760  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:228] Total time: 0:04:32 (1.5830 s / it)\n",
      "Averaged stats: lr: 0.000086  loss: 0.3907 (0.3918)\n",
      "Valid: [epoch:228]  [ 0/14]  eta: 0:00:06  loss: 0.3986 (0.3986)  time: 0.4371  data: 0.4201  max mem: 20571\n",
      "Valid: [epoch:228]  [13/14]  eta: 0:00:00  loss: 0.3986 (0.4088)  time: 0.0453  data: 0.0301  max mem: 20571\n",
      "Valid: [epoch:228] Total time: 0:00:00 (0.0534 s / it)\n",
      "Averaged stats: loss: 0.3986 (0.4088)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_228_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.409%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:229]  [  0/172]  eta: 0:07:32  lr: 0.000086  loss: 0.4189 (0.4189)  time: 2.6294  data: 1.0608  max mem: 20571\n",
      "Train: [epoch:229]  [ 10/172]  eta: 0:04:30  lr: 0.000086  loss: 0.4022 (0.3978)  time: 1.6667  data: 0.0965  max mem: 20571\n",
      "Train: [epoch:229]  [ 20/172]  eta: 0:04:06  lr: 0.000086  loss: 0.3943 (0.3961)  time: 1.5722  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [ 30/172]  eta: 0:03:48  lr: 0.000086  loss: 0.3972 (0.3975)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [ 40/172]  eta: 0:03:31  lr: 0.000086  loss: 0.3885 (0.3942)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [ 50/172]  eta: 0:03:14  lr: 0.000086  loss: 0.3839 (0.3925)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [ 60/172]  eta: 0:02:58  lr: 0.000086  loss: 0.3797 (0.3926)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [ 70/172]  eta: 0:02:42  lr: 0.000086  loss: 0.3914 (0.3931)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [ 80/172]  eta: 0:02:26  lr: 0.000086  loss: 0.3956 (0.3938)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [ 90/172]  eta: 0:02:10  lr: 0.000086  loss: 0.3842 (0.3936)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [100/172]  eta: 0:01:54  lr: 0.000086  loss: 0.3842 (0.3947)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [110/172]  eta: 0:01:38  lr: 0.000086  loss: 0.3872 (0.3947)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [120/172]  eta: 0:01:22  lr: 0.000086  loss: 0.3864 (0.3945)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [130/172]  eta: 0:01:06  lr: 0.000086  loss: 0.3946 (0.3947)  time: 1.5743  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [140/172]  eta: 0:00:50  lr: 0.000086  loss: 0.3982 (0.3944)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [150/172]  eta: 0:00:34  lr: 0.000086  loss: 0.3858 (0.3938)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [160/172]  eta: 0:00:18  lr: 0.000086  loss: 0.3924 (0.3940)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [170/172]  eta: 0:00:03  lr: 0.000086  loss: 0.3924 (0.3945)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229]  [171/172]  eta: 0:00:01  lr: 0.000086  loss: 0.4011 (0.3945)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:229] Total time: 0:04:32 (1.5819 s / it)\n",
      "Averaged stats: lr: 0.000086  loss: 0.4011 (0.3945)\n",
      "Valid: [epoch:229]  [ 0/14]  eta: 0:00:05  loss: 0.3553 (0.3553)  time: 0.3784  data: 0.3604  max mem: 20571\n",
      "Valid: [epoch:229]  [13/14]  eta: 0:00:00  loss: 0.3776 (0.3887)  time: 0.0417  data: 0.0265  max mem: 20571\n",
      "Valid: [epoch:229] Total time: 0:00:00 (0.0493 s / it)\n",
      "Averaged stats: loss: 0.3776 (0.3887)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_229_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.389%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:230]  [  0/172]  eta: 0:07:46  lr: 0.000086  loss: 0.4112 (0.4112)  time: 2.7134  data: 1.1505  max mem: 20571\n",
      "Train: [epoch:230]  [ 10/172]  eta: 0:04:31  lr: 0.000086  loss: 0.4025 (0.3917)  time: 1.6779  data: 0.1047  max mem: 20571\n",
      "Train: [epoch:230]  [ 20/172]  eta: 0:04:07  lr: 0.000086  loss: 0.4025 (0.3989)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [ 30/172]  eta: 0:03:48  lr: 0.000086  loss: 0.3927 (0.3954)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [ 40/172]  eta: 0:03:31  lr: 0.000086  loss: 0.3873 (0.3954)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [ 50/172]  eta: 0:03:15  lr: 0.000086  loss: 0.3922 (0.3954)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [ 60/172]  eta: 0:02:58  lr: 0.000086  loss: 0.3979 (0.3944)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [ 70/172]  eta: 0:02:42  lr: 0.000086  loss: 0.3980 (0.3955)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [ 80/172]  eta: 0:02:26  lr: 0.000086  loss: 0.3996 (0.3951)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [ 90/172]  eta: 0:02:10  lr: 0.000086  loss: 0.3973 (0.3957)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [100/172]  eta: 0:01:54  lr: 0.000086  loss: 0.3945 (0.3954)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [110/172]  eta: 0:01:38  lr: 0.000086  loss: 0.3903 (0.3953)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [120/172]  eta: 0:01:22  lr: 0.000086  loss: 0.3871 (0.3955)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [130/172]  eta: 0:01:06  lr: 0.000086  loss: 0.3890 (0.3965)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [140/172]  eta: 0:00:50  lr: 0.000086  loss: 0.3942 (0.3960)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [150/172]  eta: 0:00:34  lr: 0.000086  loss: 0.3921 (0.3955)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [160/172]  eta: 0:00:19  lr: 0.000086  loss: 0.3920 (0.3956)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230]  [170/172]  eta: 0:00:03  lr: 0.000086  loss: 0.3924 (0.3957)  time: 1.5775  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:230]  [171/172]  eta: 0:00:01  lr: 0.000086  loss: 0.3924 (0.3956)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:230] Total time: 0:04:32 (1.5838 s / it)\n",
      "Averaged stats: lr: 0.000086  loss: 0.3924 (0.3956)\n",
      "Valid: [epoch:230]  [ 0/14]  eta: 0:00:08  loss: 0.4156 (0.4156)  time: 0.6327  data: 0.6160  max mem: 20571\n",
      "Valid: [epoch:230]  [13/14]  eta: 0:00:00  loss: 0.3754 (0.3858)  time: 0.0600  data: 0.0449  max mem: 20571\n",
      "Valid: [epoch:230] Total time: 0:00:00 (0.0656 s / it)\n",
      "Averaged stats: loss: 0.3754 (0.3858)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_230_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.386%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:231]  [  0/172]  eta: 0:07:41  lr: 0.000086  loss: 0.3764 (0.3764)  time: 2.6858  data: 1.1189  max mem: 20571\n",
      "Train: [epoch:231]  [ 10/172]  eta: 0:04:30  lr: 0.000086  loss: 0.4097 (0.4056)  time: 1.6725  data: 0.1018  max mem: 20571\n",
      "Train: [epoch:231]  [ 20/172]  eta: 0:04:07  lr: 0.000086  loss: 0.3948 (0.3991)  time: 1.5730  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [ 30/172]  eta: 0:03:48  lr: 0.000086  loss: 0.3882 (0.3967)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [ 40/172]  eta: 0:03:31  lr: 0.000086  loss: 0.3891 (0.3979)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [ 50/172]  eta: 0:03:14  lr: 0.000086  loss: 0.3952 (0.3980)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [ 60/172]  eta: 0:02:58  lr: 0.000086  loss: 0.3922 (0.3985)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [ 70/172]  eta: 0:02:42  lr: 0.000086  loss: 0.3922 (0.3987)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [ 80/172]  eta: 0:02:26  lr: 0.000086  loss: 0.3940 (0.3990)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [ 90/172]  eta: 0:02:10  lr: 0.000086  loss: 0.3995 (0.3984)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [100/172]  eta: 0:01:54  lr: 0.000086  loss: 0.3962 (0.3982)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [110/172]  eta: 0:01:38  lr: 0.000086  loss: 0.3894 (0.3979)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [120/172]  eta: 0:01:22  lr: 0.000086  loss: 0.3930 (0.3983)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [130/172]  eta: 0:01:06  lr: 0.000086  loss: 0.3966 (0.3977)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [140/172]  eta: 0:00:50  lr: 0.000086  loss: 0.3893 (0.3977)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [150/172]  eta: 0:00:34  lr: 0.000086  loss: 0.3935 (0.3983)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [160/172]  eta: 0:00:18  lr: 0.000086  loss: 0.4062 (0.3979)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [170/172]  eta: 0:00:03  lr: 0.000086  loss: 0.3917 (0.3972)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231]  [171/172]  eta: 0:00:01  lr: 0.000086  loss: 0.3945 (0.3975)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:231] Total time: 0:04:32 (1.5828 s / it)\n",
      "Averaged stats: lr: 0.000086  loss: 0.3945 (0.3975)\n",
      "Valid: [epoch:231]  [ 0/14]  eta: 0:00:04  loss: 0.3268 (0.3268)  time: 0.2951  data: 0.2801  max mem: 20571\n",
      "Valid: [epoch:231]  [13/14]  eta: 0:00:00  loss: 0.3647 (0.3763)  time: 0.0356  data: 0.0206  max mem: 20571\n",
      "Valid: [epoch:231] Total time: 0:00:00 (0.0423 s / it)\n",
      "Averaged stats: loss: 0.3647 (0.3763)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_231_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.376%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:232]  [  0/172]  eta: 0:07:48  lr: 0.000085  loss: 0.3649 (0.3649)  time: 2.7238  data: 1.1612  max mem: 20571\n",
      "Train: [epoch:232]  [ 10/172]  eta: 0:04:31  lr: 0.000085  loss: 0.3942 (0.3945)  time: 1.6786  data: 0.1057  max mem: 20571\n",
      "Train: [epoch:232]  [ 20/172]  eta: 0:04:07  lr: 0.000085  loss: 0.4034 (0.4030)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [ 30/172]  eta: 0:03:48  lr: 0.000085  loss: 0.4086 (0.4028)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [ 40/172]  eta: 0:03:31  lr: 0.000085  loss: 0.3946 (0.3999)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [ 50/172]  eta: 0:03:14  lr: 0.000085  loss: 0.3970 (0.3997)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [ 60/172]  eta: 0:02:58  lr: 0.000085  loss: 0.3970 (0.3997)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [ 70/172]  eta: 0:02:42  lr: 0.000085  loss: 0.3992 (0.3990)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [ 80/172]  eta: 0:02:26  lr: 0.000085  loss: 0.3973 (0.3982)  time: 1.5743  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [ 90/172]  eta: 0:02:10  lr: 0.000085  loss: 0.3897 (0.3973)  time: 1.5743  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [100/172]  eta: 0:01:54  lr: 0.000085  loss: 0.3897 (0.3982)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [110/172]  eta: 0:01:38  lr: 0.000085  loss: 0.3934 (0.3984)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [120/172]  eta: 0:01:22  lr: 0.000085  loss: 0.3934 (0.3979)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [130/172]  eta: 0:01:06  lr: 0.000085  loss: 0.3905 (0.3978)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [140/172]  eta: 0:00:50  lr: 0.000085  loss: 0.3953 (0.3979)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [150/172]  eta: 0:00:34  lr: 0.000085  loss: 0.3995 (0.3980)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [160/172]  eta: 0:00:18  lr: 0.000085  loss: 0.3995 (0.3980)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [170/172]  eta: 0:00:03  lr: 0.000085  loss: 0.3982 (0.3982)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232]  [171/172]  eta: 0:00:01  lr: 0.000085  loss: 0.3982 (0.3983)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:232] Total time: 0:04:32 (1.5824 s / it)\n",
      "Averaged stats: lr: 0.000085  loss: 0.3982 (0.3983)\n",
      "Valid: [epoch:232]  [ 0/14]  eta: 0:00:04  loss: 0.3554 (0.3554)  time: 0.3081  data: 0.2910  max mem: 20571\n",
      "Valid: [epoch:232]  [13/14]  eta: 0:00:00  loss: 0.3639 (0.3752)  time: 0.0368  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:232] Total time: 0:00:00 (0.0418 s / it)\n",
      "Averaged stats: loss: 0.3639 (0.3752)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_232_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.375%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:233]  [  0/172]  eta: 0:07:28  lr: 0.000085  loss: 0.4280 (0.4280)  time: 2.6068  data: 1.0233  max mem: 20571\n",
      "Train: [epoch:233]  [ 10/172]  eta: 0:04:29  lr: 0.000085  loss: 0.4006 (0.4001)  time: 1.6659  data: 0.0931  max mem: 20571\n",
      "Train: [epoch:233]  [ 20/172]  eta: 0:04:06  lr: 0.000085  loss: 0.3880 (0.3977)  time: 1.5726  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [ 30/172]  eta: 0:03:48  lr: 0.000085  loss: 0.3880 (0.3979)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [ 40/172]  eta: 0:03:31  lr: 0.000085  loss: 0.3924 (0.3985)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [ 50/172]  eta: 0:03:14  lr: 0.000085  loss: 0.4055 (0.3993)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [ 60/172]  eta: 0:02:58  lr: 0.000085  loss: 0.4056 (0.4003)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [ 70/172]  eta: 0:02:42  lr: 0.000085  loss: 0.3996 (0.4011)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [ 80/172]  eta: 0:02:26  lr: 0.000085  loss: 0.3960 (0.4006)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [ 90/172]  eta: 0:02:10  lr: 0.000085  loss: 0.3964 (0.4005)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [100/172]  eta: 0:01:54  lr: 0.000085  loss: 0.3965 (0.4008)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [110/172]  eta: 0:01:38  lr: 0.000085  loss: 0.3993 (0.4008)  time: 1.5767  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:233]  [120/172]  eta: 0:01:22  lr: 0.000085  loss: 0.3930 (0.4007)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [130/172]  eta: 0:01:06  lr: 0.000085  loss: 0.3978 (0.4011)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [140/172]  eta: 0:00:50  lr: 0.000085  loss: 0.3978 (0.4007)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [150/172]  eta: 0:00:34  lr: 0.000085  loss: 0.3911 (0.4002)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [160/172]  eta: 0:00:18  lr: 0.000085  loss: 0.3924 (0.4000)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [170/172]  eta: 0:00:03  lr: 0.000085  loss: 0.4038 (0.4007)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233]  [171/172]  eta: 0:00:01  lr: 0.000085  loss: 0.4066 (0.4009)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:233] Total time: 0:04:32 (1.5822 s / it)\n",
      "Averaged stats: lr: 0.000085  loss: 0.4066 (0.4009)\n",
      "Valid: [epoch:233]  [ 0/14]  eta: 0:00:04  loss: 0.3627 (0.3627)  time: 0.3515  data: 0.3339  max mem: 20571\n",
      "Valid: [epoch:233]  [13/14]  eta: 0:00:00  loss: 0.3860 (0.3963)  time: 0.0394  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:233] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.3860 (0.3963)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_233_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.396%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:234]  [  0/172]  eta: 0:07:45  lr: 0.000085  loss: 0.4074 (0.4074)  time: 2.7065  data: 1.1445  max mem: 20571\n",
      "Train: [epoch:234]  [ 10/172]  eta: 0:04:31  lr: 0.000085  loss: 0.4049 (0.3999)  time: 1.6769  data: 0.1042  max mem: 20571\n",
      "Train: [epoch:234]  [ 20/172]  eta: 0:04:07  lr: 0.000085  loss: 0.3968 (0.4001)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [ 30/172]  eta: 0:03:48  lr: 0.000085  loss: 0.3996 (0.4017)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [ 40/172]  eta: 0:03:31  lr: 0.000085  loss: 0.4093 (0.4019)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [ 50/172]  eta: 0:03:14  lr: 0.000085  loss: 0.4021 (0.4019)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [ 60/172]  eta: 0:02:58  lr: 0.000085  loss: 0.4021 (0.4018)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [ 70/172]  eta: 0:02:42  lr: 0.000085  loss: 0.4051 (0.4027)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [ 80/172]  eta: 0:02:26  lr: 0.000085  loss: 0.4079 (0.4044)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [ 90/172]  eta: 0:02:10  lr: 0.000085  loss: 0.4053 (0.4035)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [100/172]  eta: 0:01:54  lr: 0.000085  loss: 0.4069 (0.4044)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [110/172]  eta: 0:01:38  lr: 0.000085  loss: 0.4069 (0.4043)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [120/172]  eta: 0:01:22  lr: 0.000085  loss: 0.3899 (0.4039)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [130/172]  eta: 0:01:06  lr: 0.000085  loss: 0.3899 (0.4032)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [140/172]  eta: 0:00:50  lr: 0.000085  loss: 0.3884 (0.4033)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [150/172]  eta: 0:00:34  lr: 0.000085  loss: 0.4098 (0.4038)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [160/172]  eta: 0:00:18  lr: 0.000085  loss: 0.4032 (0.4032)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [170/172]  eta: 0:00:03  lr: 0.000085  loss: 0.3908 (0.4025)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234]  [171/172]  eta: 0:00:01  lr: 0.000085  loss: 0.3935 (0.4028)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:234] Total time: 0:04:32 (1.5833 s / it)\n",
      "Averaged stats: lr: 0.000085  loss: 0.3935 (0.4028)\n",
      "Valid: [epoch:234]  [ 0/14]  eta: 0:00:05  loss: 0.4137 (0.4137)  time: 0.3904  data: 0.3722  max mem: 20571\n",
      "Valid: [epoch:234]  [13/14]  eta: 0:00:00  loss: 0.3720 (0.3835)  time: 0.0428  data: 0.0276  max mem: 20571\n",
      "Valid: [epoch:234] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.3720 (0.3835)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_234_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.383%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:235]  [  0/172]  eta: 0:07:32  lr: 0.000085  loss: 0.3819 (0.3819)  time: 2.6317  data: 1.0460  max mem: 20571\n",
      "Train: [epoch:235]  [ 10/172]  eta: 0:04:30  lr: 0.000085  loss: 0.3971 (0.4014)  time: 1.6674  data: 0.0952  max mem: 20571\n",
      "Train: [epoch:235]  [ 20/172]  eta: 0:04:06  lr: 0.000085  loss: 0.3956 (0.3965)  time: 1.5722  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [ 30/172]  eta: 0:03:48  lr: 0.000085  loss: 0.3909 (0.3980)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [ 40/172]  eta: 0:03:31  lr: 0.000085  loss: 0.3915 (0.3980)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [ 50/172]  eta: 0:03:14  lr: 0.000085  loss: 0.3915 (0.4006)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [ 60/172]  eta: 0:02:58  lr: 0.000085  loss: 0.4045 (0.4005)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [ 70/172]  eta: 0:02:42  lr: 0.000085  loss: 0.4012 (0.4011)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [ 80/172]  eta: 0:02:26  lr: 0.000085  loss: 0.4039 (0.4015)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [ 90/172]  eta: 0:02:10  lr: 0.000085  loss: 0.4084 (0.4032)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [100/172]  eta: 0:01:54  lr: 0.000085  loss: 0.4082 (0.4033)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [110/172]  eta: 0:01:38  lr: 0.000085  loss: 0.3980 (0.4029)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [120/172]  eta: 0:01:22  lr: 0.000085  loss: 0.3987 (0.4029)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [130/172]  eta: 0:01:06  lr: 0.000085  loss: 0.3991 (0.4023)  time: 1.5760  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:235]  [140/172]  eta: 0:00:50  lr: 0.000085  loss: 0.3994 (0.4023)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [150/172]  eta: 0:00:34  lr: 0.000085  loss: 0.4060 (0.4022)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [160/172]  eta: 0:00:18  lr: 0.000085  loss: 0.3946 (0.4022)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [170/172]  eta: 0:00:03  lr: 0.000085  loss: 0.3976 (0.4024)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235]  [171/172]  eta: 0:00:01  lr: 0.000085  loss: 0.4063 (0.4024)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:235] Total time: 0:04:32 (1.5828 s / it)\n",
      "Averaged stats: lr: 0.000085  loss: 0.4063 (0.4024)\n",
      "Valid: [epoch:235]  [ 0/14]  eta: 0:00:04  loss: 0.3720 (0.3720)  time: 0.2929  data: 0.2781  max mem: 20571\n",
      "Valid: [epoch:235]  [13/14]  eta: 0:00:00  loss: 0.3720 (0.3833)  time: 0.0439  data: 0.0290  max mem: 20571\n",
      "Valid: [epoch:235] Total time: 0:00:00 (0.0519 s / it)\n",
      "Averaged stats: loss: 0.3720 (0.3833)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_235_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.383%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:236]  [  0/172]  eta: 0:07:34  lr: 0.000085  loss: 0.4017 (0.4017)  time: 2.6437  data: 1.0811  max mem: 20571\n",
      "Train: [epoch:236]  [ 10/172]  eta: 0:04:30  lr: 0.000085  loss: 0.4039 (0.4137)  time: 1.6703  data: 0.0984  max mem: 20571\n",
      "Train: [epoch:236]  [ 20/172]  eta: 0:04:06  lr: 0.000085  loss: 0.4074 (0.4132)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [ 30/172]  eta: 0:03:48  lr: 0.000085  loss: 0.4082 (0.4118)  time: 1.5764  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:236]  [ 40/172]  eta: 0:03:31  lr: 0.000085  loss: 0.4119 (0.4101)  time: 1.5777  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:236]  [ 50/172]  eta: 0:03:14  lr: 0.000085  loss: 0.4073 (0.4096)  time: 1.5766  data: 0.0004  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:236]  [ 60/172]  eta: 0:02:58  lr: 0.000085  loss: 0.3989 (0.4084)  time: 1.5748  data: 0.0004  max mem: 20571\n",
      "Train: [epoch:236]  [ 70/172]  eta: 0:02:42  lr: 0.000085  loss: 0.3967 (0.4076)  time: 1.5735  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [ 80/172]  eta: 0:02:26  lr: 0.000085  loss: 0.4003 (0.4072)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [ 90/172]  eta: 0:02:10  lr: 0.000085  loss: 0.4086 (0.4070)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [100/172]  eta: 0:01:54  lr: 0.000085  loss: 0.4088 (0.4075)  time: 1.5745  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:236]  [110/172]  eta: 0:01:38  lr: 0.000085  loss: 0.4088 (0.4073)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [120/172]  eta: 0:01:22  lr: 0.000085  loss: 0.4064 (0.4079)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [130/172]  eta: 0:01:06  lr: 0.000085  loss: 0.4064 (0.4078)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [140/172]  eta: 0:00:50  lr: 0.000085  loss: 0.4034 (0.4078)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [150/172]  eta: 0:00:34  lr: 0.000085  loss: 0.4019 (0.4077)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [160/172]  eta: 0:00:18  lr: 0.000085  loss: 0.4019 (0.4071)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [170/172]  eta: 0:00:03  lr: 0.000085  loss: 0.3974 (0.4068)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236]  [171/172]  eta: 0:00:01  lr: 0.000085  loss: 0.3981 (0.4068)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:236] Total time: 0:04:32 (1.5822 s / it)\n",
      "Averaged stats: lr: 0.000085  loss: 0.3981 (0.4068)\n",
      "Valid: [epoch:236]  [ 0/14]  eta: 0:00:05  loss: 0.3660 (0.3660)  time: 0.3655  data: 0.3491  max mem: 20571\n",
      "Valid: [epoch:236]  [13/14]  eta: 0:00:00  loss: 0.3660 (0.3775)  time: 0.0415  data: 0.0266  max mem: 20571\n",
      "Valid: [epoch:236] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.3660 (0.3775)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_236_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.378%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:237]  [  0/172]  eta: 0:07:30  lr: 0.000085  loss: 0.3751 (0.3751)  time: 2.6171  data: 1.0407  max mem: 20571\n",
      "Train: [epoch:237]  [ 10/172]  eta: 0:04:29  lr: 0.000085  loss: 0.3996 (0.4014)  time: 1.6663  data: 0.0947  max mem: 20571\n",
      "Train: [epoch:237]  [ 20/172]  eta: 0:04:06  lr: 0.000085  loss: 0.3996 (0.4063)  time: 1.5747  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:237]  [ 30/172]  eta: 0:03:48  lr: 0.000085  loss: 0.3973 (0.4052)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:237]  [ 40/172]  eta: 0:03:31  lr: 0.000085  loss: 0.3933 (0.4037)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [ 50/172]  eta: 0:03:14  lr: 0.000085  loss: 0.3943 (0.4034)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [ 60/172]  eta: 0:02:58  lr: 0.000085  loss: 0.4069 (0.4047)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [ 70/172]  eta: 0:02:42  lr: 0.000085  loss: 0.4079 (0.4057)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:237]  [ 80/172]  eta: 0:02:26  lr: 0.000085  loss: 0.3959 (0.4048)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:237]  [ 90/172]  eta: 0:02:10  lr: 0.000085  loss: 0.4106 (0.4065)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [100/172]  eta: 0:01:54  lr: 0.000085  loss: 0.4144 (0.4075)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [110/172]  eta: 0:01:38  lr: 0.000085  loss: 0.4035 (0.4071)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:237]  [120/172]  eta: 0:01:22  lr: 0.000085  loss: 0.4244 (0.4088)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [130/172]  eta: 0:01:06  lr: 0.000085  loss: 0.4151 (0.4088)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [140/172]  eta: 0:00:50  lr: 0.000085  loss: 0.3996 (0.4078)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [150/172]  eta: 0:00:34  lr: 0.000085  loss: 0.3906 (0.4075)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [160/172]  eta: 0:00:19  lr: 0.000085  loss: 0.3948 (0.4075)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [170/172]  eta: 0:00:03  lr: 0.000085  loss: 0.4065 (0.4080)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:237]  [171/172]  eta: 0:00:01  lr: 0.000085  loss: 0.4065 (0.4082)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:237] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000085  loss: 0.4065 (0.4082)\n",
      "Valid: [epoch:237]  [ 0/14]  eta: 0:00:04  loss: 0.3926 (0.3926)  time: 0.3414  data: 0.3242  max mem: 20571\n",
      "Valid: [epoch:237]  [13/14]  eta: 0:00:00  loss: 0.3659 (0.3778)  time: 0.0398  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:237] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.3659 (0.3778)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_237_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.378%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:238]  [  0/172]  eta: 0:08:21  lr: 0.000085  loss: 0.3764 (0.3764)  time: 2.9185  data: 1.3523  max mem: 20571\n",
      "Train: [epoch:238]  [ 10/172]  eta: 0:04:35  lr: 0.000085  loss: 0.4103 (0.4067)  time: 1.6998  data: 0.1231  max mem: 20571\n",
      "Train: [epoch:238]  [ 20/172]  eta: 0:04:09  lr: 0.000085  loss: 0.4103 (0.4085)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [ 30/172]  eta: 0:03:50  lr: 0.000085  loss: 0.4056 (0.4078)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [ 40/172]  eta: 0:03:32  lr: 0.000085  loss: 0.3969 (0.4072)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [ 50/172]  eta: 0:03:15  lr: 0.000085  loss: 0.4004 (0.4073)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [ 60/172]  eta: 0:02:59  lr: 0.000085  loss: 0.4033 (0.4071)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [ 70/172]  eta: 0:02:43  lr: 0.000085  loss: 0.4016 (0.4060)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [ 80/172]  eta: 0:02:26  lr: 0.000085  loss: 0.3951 (0.4056)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [ 90/172]  eta: 0:02:10  lr: 0.000085  loss: 0.4020 (0.4062)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [100/172]  eta: 0:01:54  lr: 0.000085  loss: 0.4024 (0.4061)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [110/172]  eta: 0:01:38  lr: 0.000085  loss: 0.4023 (0.4059)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:238]  [120/172]  eta: 0:01:22  lr: 0.000085  loss: 0.4024 (0.4062)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [130/172]  eta: 0:01:06  lr: 0.000085  loss: 0.3961 (0.4058)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [140/172]  eta: 0:00:50  lr: 0.000085  loss: 0.4050 (0.4059)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [150/172]  eta: 0:00:34  lr: 0.000085  loss: 0.4081 (0.4060)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [160/172]  eta: 0:00:19  lr: 0.000085  loss: 0.4081 (0.4062)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [170/172]  eta: 0:00:03  lr: 0.000085  loss: 0.3990 (0.4059)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238]  [171/172]  eta: 0:00:01  lr: 0.000085  loss: 0.4036 (0.4059)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:238] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000085  loss: 0.4036 (0.4059)\n",
      "Valid: [epoch:238]  [ 0/14]  eta: 0:00:04  loss: 0.3722 (0.3722)  time: 0.2903  data: 0.2750  max mem: 20571\n",
      "Valid: [epoch:238]  [13/14]  eta: 0:00:00  loss: 0.3937 (0.4047)  time: 0.0367  data: 0.0217  max mem: 20571\n",
      "Valid: [epoch:238] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.3937 (0.4047)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_238_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.405%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:239]  [  0/172]  eta: 0:07:35  lr: 0.000085  loss: 0.4677 (0.4677)  time: 2.6474  data: 1.0660  max mem: 20571\n",
      "Train: [epoch:239]  [ 10/172]  eta: 0:04:31  lr: 0.000085  loss: 0.3997 (0.4099)  time: 1.6729  data: 0.0970  max mem: 20571\n",
      "Train: [epoch:239]  [ 20/172]  eta: 0:04:07  lr: 0.000085  loss: 0.4030 (0.4123)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [ 30/172]  eta: 0:03:48  lr: 0.000085  loss: 0.4095 (0.4114)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [ 40/172]  eta: 0:03:31  lr: 0.000085  loss: 0.3986 (0.4100)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [ 50/172]  eta: 0:03:15  lr: 0.000085  loss: 0.4021 (0.4092)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [ 60/172]  eta: 0:02:58  lr: 0.000085  loss: 0.4023 (0.4087)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [ 70/172]  eta: 0:02:42  lr: 0.000085  loss: 0.4065 (0.4098)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [ 80/172]  eta: 0:02:26  lr: 0.000085  loss: 0.4126 (0.4093)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [ 90/172]  eta: 0:02:10  lr: 0.000085  loss: 0.4065 (0.4094)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [100/172]  eta: 0:01:54  lr: 0.000085  loss: 0.3991 (0.4097)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [110/172]  eta: 0:01:38  lr: 0.000085  loss: 0.4081 (0.4099)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [120/172]  eta: 0:01:22  lr: 0.000085  loss: 0.4098 (0.4107)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [130/172]  eta: 0:01:06  lr: 0.000085  loss: 0.4097 (0.4106)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [140/172]  eta: 0:00:50  lr: 0.000085  loss: 0.4088 (0.4101)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [150/172]  eta: 0:00:34  lr: 0.000085  loss: 0.4090 (0.4101)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [160/172]  eta: 0:00:19  lr: 0.000085  loss: 0.4128 (0.4103)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [170/172]  eta: 0:00:03  lr: 0.000085  loss: 0.4150 (0.4106)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239]  [171/172]  eta: 0:00:01  lr: 0.000085  loss: 0.4171 (0.4107)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:239] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000085  loss: 0.4171 (0.4107)\n",
      "Valid: [epoch:239]  [ 0/14]  eta: 0:00:03  loss: 0.4072 (0.4072)  time: 0.2826  data: 0.2682  max mem: 20571\n",
      "Valid: [epoch:239]  [13/14]  eta: 0:00:00  loss: 0.3668 (0.3788)  time: 0.0363  data: 0.0213  max mem: 20571\n",
      "Valid: [epoch:239] Total time: 0:00:00 (0.0421 s / it)\n",
      "Averaged stats: loss: 0.3668 (0.3788)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_239_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.379%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:240]  [  0/172]  eta: 0:07:40  lr: 0.000085  loss: 0.3965 (0.3965)  time: 2.6763  data: 1.0987  max mem: 20571\n",
      "Train: [epoch:240]  [ 10/172]  eta: 0:04:31  lr: 0.000085  loss: 0.4030 (0.4257)  time: 1.6770  data: 0.1000  max mem: 20571\n",
      "Train: [epoch:240]  [ 20/172]  eta: 0:04:07  lr: 0.000085  loss: 0.4204 (0.4317)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [ 30/172]  eta: 0:03:49  lr: 0.000085  loss: 0.4146 (0.4248)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [ 40/172]  eta: 0:03:31  lr: 0.000085  loss: 0.4015 (0.4188)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [ 50/172]  eta: 0:03:15  lr: 0.000085  loss: 0.4015 (0.4174)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [ 60/172]  eta: 0:02:58  lr: 0.000085  loss: 0.4097 (0.4163)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [ 70/172]  eta: 0:02:42  lr: 0.000085  loss: 0.4043 (0.4147)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [ 80/172]  eta: 0:02:26  lr: 0.000085  loss: 0.4043 (0.4138)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [ 90/172]  eta: 0:02:10  lr: 0.000085  loss: 0.4089 (0.4133)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [100/172]  eta: 0:01:54  lr: 0.000085  loss: 0.4106 (0.4134)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [110/172]  eta: 0:01:38  lr: 0.000085  loss: 0.4088 (0.4125)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [120/172]  eta: 0:01:22  lr: 0.000085  loss: 0.3999 (0.4130)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [130/172]  eta: 0:01:06  lr: 0.000085  loss: 0.4048 (0.4128)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [140/172]  eta: 0:00:50  lr: 0.000085  loss: 0.4138 (0.4132)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [150/172]  eta: 0:00:34  lr: 0.000085  loss: 0.4189 (0.4133)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [160/172]  eta: 0:00:19  lr: 0.000085  loss: 0.4093 (0.4132)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [170/172]  eta: 0:00:03  lr: 0.000085  loss: 0.4064 (0.4128)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240]  [171/172]  eta: 0:00:01  lr: 0.000085  loss: 0.4091 (0.4129)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:240] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000085  loss: 0.4091 (0.4129)\n",
      "Valid: [epoch:240]  [ 0/14]  eta: 0:00:05  loss: 0.3691 (0.3691)  time: 0.4141  data: 0.3968  max mem: 20571\n",
      "Valid: [epoch:240]  [13/14]  eta: 0:00:00  loss: 0.3797 (0.3912)  time: 0.0453  data: 0.0301  max mem: 20571\n",
      "Valid: [epoch:240] Total time: 0:00:00 (0.0531 s / it)\n",
      "Averaged stats: loss: 0.3797 (0.3912)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_240_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.391%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:241]  [  0/172]  eta: 0:08:09  lr: 0.000084  loss: 0.3759 (0.3759)  time: 2.8474  data: 1.2696  max mem: 20571\n",
      "Train: [epoch:241]  [ 10/172]  eta: 0:04:33  lr: 0.000084  loss: 0.3973 (0.4053)  time: 1.6895  data: 0.1156  max mem: 20571\n",
      "Train: [epoch:241]  [ 20/172]  eta: 0:04:08  lr: 0.000084  loss: 0.4079 (0.4114)  time: 1.5753  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:241]  [ 30/172]  eta: 0:03:49  lr: 0.000084  loss: 0.4138 (0.4122)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [ 40/172]  eta: 0:03:32  lr: 0.000084  loss: 0.4085 (0.4121)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [ 50/172]  eta: 0:03:15  lr: 0.000084  loss: 0.4093 (0.4127)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [ 60/172]  eta: 0:02:59  lr: 0.000084  loss: 0.4063 (0.4118)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [ 70/172]  eta: 0:02:42  lr: 0.000084  loss: 0.4166 (0.4136)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [ 80/172]  eta: 0:02:26  lr: 0.000084  loss: 0.4166 (0.4133)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [ 90/172]  eta: 0:02:10  lr: 0.000084  loss: 0.4019 (0.4130)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [100/172]  eta: 0:01:54  lr: 0.000084  loss: 0.4098 (0.4131)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [110/172]  eta: 0:01:38  lr: 0.000084  loss: 0.4139 (0.4126)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [120/172]  eta: 0:01:22  lr: 0.000084  loss: 0.4085 (0.4123)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [130/172]  eta: 0:01:06  lr: 0.000084  loss: 0.4052 (0.4127)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [140/172]  eta: 0:00:50  lr: 0.000084  loss: 0.4074 (0.4124)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [150/172]  eta: 0:00:34  lr: 0.000084  loss: 0.4139 (0.4128)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [160/172]  eta: 0:00:19  lr: 0.000084  loss: 0.4190 (0.4129)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241]  [170/172]  eta: 0:00:03  lr: 0.000084  loss: 0.4123 (0.4124)  time: 1.5797  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:241]  [171/172]  eta: 0:00:01  lr: 0.000084  loss: 0.4123 (0.4124)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:241] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000084  loss: 0.4123 (0.4124)\n",
      "Valid: [epoch:241]  [ 0/14]  eta: 0:00:06  loss: 0.3690 (0.3690)  time: 0.4540  data: 0.4376  max mem: 20571\n",
      "Valid: [epoch:241]  [13/14]  eta: 0:00:00  loss: 0.3990 (0.4106)  time: 0.0508  data: 0.0360  max mem: 20571\n",
      "Valid: [epoch:241] Total time: 0:00:00 (0.0580 s / it)\n",
      "Averaged stats: loss: 0.3990 (0.4106)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_241_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.411%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:242]  [  0/172]  eta: 0:07:21  lr: 0.000084  loss: 0.4065 (0.4065)  time: 2.5660  data: 1.0011  max mem: 20571\n",
      "Train: [epoch:242]  [ 10/172]  eta: 0:04:30  lr: 0.000084  loss: 0.4093 (0.4157)  time: 1.6674  data: 0.0911  max mem: 20571\n",
      "Train: [epoch:242]  [ 20/172]  eta: 0:04:07  lr: 0.000084  loss: 0.4121 (0.4185)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [ 30/172]  eta: 0:03:48  lr: 0.000084  loss: 0.4082 (0.4158)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [ 40/172]  eta: 0:03:31  lr: 0.000084  loss: 0.4108 (0.4175)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [ 50/172]  eta: 0:03:15  lr: 0.000084  loss: 0.4149 (0.4172)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [ 60/172]  eta: 0:02:58  lr: 0.000084  loss: 0.4109 (0.4167)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [ 70/172]  eta: 0:02:42  lr: 0.000084  loss: 0.4109 (0.4172)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [ 80/172]  eta: 0:02:26  lr: 0.000084  loss: 0.4117 (0.4167)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [ 90/172]  eta: 0:02:10  lr: 0.000084  loss: 0.4117 (0.4166)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [100/172]  eta: 0:01:54  lr: 0.000084  loss: 0.4110 (0.4155)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [110/172]  eta: 0:01:38  lr: 0.000084  loss: 0.4160 (0.4165)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [120/172]  eta: 0:01:22  lr: 0.000084  loss: 0.4214 (0.4164)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [130/172]  eta: 0:01:06  lr: 0.000084  loss: 0.4114 (0.4160)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [140/172]  eta: 0:00:50  lr: 0.000084  loss: 0.4114 (0.4158)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [150/172]  eta: 0:00:34  lr: 0.000084  loss: 0.4080 (0.4157)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [160/172]  eta: 0:00:19  lr: 0.000084  loss: 0.4080 (0.4155)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [170/172]  eta: 0:00:03  lr: 0.000084  loss: 0.4086 (0.4156)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242]  [171/172]  eta: 0:00:01  lr: 0.000084  loss: 0.4086 (0.4155)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:242] Total time: 0:04:32 (1.5858 s / it)\n",
      "Averaged stats: lr: 0.000084  loss: 0.4086 (0.4155)\n",
      "Valid: [epoch:242]  [ 0/14]  eta: 0:00:04  loss: 0.3891 (0.3891)  time: 0.3028  data: 0.2865  max mem: 20571\n",
      "Valid: [epoch:242]  [13/14]  eta: 0:00:00  loss: 0.3987 (0.4095)  time: 0.0426  data: 0.0275  max mem: 20571\n",
      "Valid: [epoch:242] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 0.3987 (0.4095)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_242_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.410%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:243]  [  0/172]  eta: 0:07:37  lr: 0.000084  loss: 0.4092 (0.4092)  time: 2.6626  data: 1.0801  max mem: 20571\n",
      "Train: [epoch:243]  [ 10/172]  eta: 0:04:31  lr: 0.000084  loss: 0.3961 (0.4044)  time: 1.6733  data: 0.0983  max mem: 20571\n",
      "Train: [epoch:243]  [ 20/172]  eta: 0:04:07  lr: 0.000084  loss: 0.4165 (0.4135)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [ 30/172]  eta: 0:03:48  lr: 0.000084  loss: 0.4242 (0.4181)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [ 40/172]  eta: 0:03:31  lr: 0.000084  loss: 0.4182 (0.4179)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [ 50/172]  eta: 0:03:15  lr: 0.000084  loss: 0.4127 (0.4179)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [ 60/172]  eta: 0:02:58  lr: 0.000084  loss: 0.4093 (0.4176)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [ 70/172]  eta: 0:02:42  lr: 0.000084  loss: 0.4106 (0.4181)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [ 80/172]  eta: 0:02:26  lr: 0.000084  loss: 0.4105 (0.4175)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [ 90/172]  eta: 0:02:10  lr: 0.000084  loss: 0.4115 (0.4175)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [100/172]  eta: 0:01:54  lr: 0.000084  loss: 0.4196 (0.4182)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [110/172]  eta: 0:01:38  lr: 0.000084  loss: 0.4252 (0.4193)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [120/172]  eta: 0:01:22  lr: 0.000084  loss: 0.4254 (0.4205)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [130/172]  eta: 0:01:06  lr: 0.000084  loss: 0.4146 (0.4199)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [140/172]  eta: 0:00:50  lr: 0.000084  loss: 0.4098 (0.4189)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [150/172]  eta: 0:00:34  lr: 0.000084  loss: 0.4067 (0.4183)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [160/172]  eta: 0:00:19  lr: 0.000084  loss: 0.4132 (0.4181)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [170/172]  eta: 0:00:03  lr: 0.000084  loss: 0.4156 (0.4177)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243]  [171/172]  eta: 0:00:01  lr: 0.000084  loss: 0.4132 (0.4175)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:243] Total time: 0:04:32 (1.5858 s / it)\n",
      "Averaged stats: lr: 0.000084  loss: 0.4132 (0.4175)\n",
      "Valid: [epoch:243]  [ 0/14]  eta: 0:00:04  loss: 0.4118 (0.4118)  time: 0.3220  data: 0.3054  max mem: 20571\n",
      "Valid: [epoch:243]  [13/14]  eta: 0:00:00  loss: 0.3844 (0.3965)  time: 0.0390  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:243] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.3844 (0.3965)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_243_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.397%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:244]  [  0/172]  eta: 0:07:35  lr: 0.000084  loss: 0.3805 (0.3805)  time: 2.6473  data: 1.0798  max mem: 20571\n",
      "Train: [epoch:244]  [ 10/172]  eta: 0:04:31  lr: 0.000084  loss: 0.4238 (0.4300)  time: 1.6757  data: 0.0983  max mem: 20571\n",
      "Train: [epoch:244]  [ 20/172]  eta: 0:04:07  lr: 0.000084  loss: 0.4214 (0.4235)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [ 30/172]  eta: 0:03:49  lr: 0.000084  loss: 0.4079 (0.4186)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [ 40/172]  eta: 0:03:31  lr: 0.000084  loss: 0.4074 (0.4185)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [ 50/172]  eta: 0:03:15  lr: 0.000084  loss: 0.4118 (0.4174)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [ 60/172]  eta: 0:02:58  lr: 0.000084  loss: 0.4050 (0.4166)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [ 70/172]  eta: 0:02:42  lr: 0.000084  loss: 0.4143 (0.4179)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [ 80/172]  eta: 0:02:26  lr: 0.000084  loss: 0.4172 (0.4175)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [ 90/172]  eta: 0:02:10  lr: 0.000084  loss: 0.4143 (0.4167)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [100/172]  eta: 0:01:54  lr: 0.000084  loss: 0.4125 (0.4168)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [110/172]  eta: 0:01:38  lr: 0.000084  loss: 0.4176 (0.4176)  time: 1.5801  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:244]  [120/172]  eta: 0:01:22  lr: 0.000084  loss: 0.4189 (0.4182)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [130/172]  eta: 0:01:06  lr: 0.000084  loss: 0.4166 (0.4175)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [140/172]  eta: 0:00:50  lr: 0.000084  loss: 0.4186 (0.4183)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [150/172]  eta: 0:00:34  lr: 0.000084  loss: 0.4130 (0.4172)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [160/172]  eta: 0:00:19  lr: 0.000084  loss: 0.4103 (0.4178)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [170/172]  eta: 0:00:03  lr: 0.000084  loss: 0.4207 (0.4175)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244]  [171/172]  eta: 0:00:01  lr: 0.000084  loss: 0.4122 (0.4174)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:244] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000084  loss: 0.4122 (0.4174)\n",
      "Valid: [epoch:244]  [ 0/14]  eta: 0:00:03  loss: 0.3780 (0.3780)  time: 0.2822  data: 0.2666  max mem: 20571\n",
      "Valid: [epoch:244]  [13/14]  eta: 0:00:00  loss: 0.3869 (0.3988)  time: 0.0363  data: 0.0213  max mem: 20571\n",
      "Valid: [epoch:244] Total time: 0:00:00 (0.0421 s / it)\n",
      "Averaged stats: loss: 0.3869 (0.3988)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_244_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.399%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:245]  [  0/172]  eta: 0:07:59  lr: 0.000084  loss: 0.3950 (0.3950)  time: 2.7852  data: 1.2058  max mem: 20571\n",
      "Train: [epoch:245]  [ 10/172]  eta: 0:04:33  lr: 0.000084  loss: 0.4041 (0.4094)  time: 1.6853  data: 0.1097  max mem: 20571\n",
      "Train: [epoch:245]  [ 20/172]  eta: 0:04:08  lr: 0.000084  loss: 0.4148 (0.4167)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [ 30/172]  eta: 0:03:49  lr: 0.000084  loss: 0.4164 (0.4167)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [ 40/172]  eta: 0:03:32  lr: 0.000084  loss: 0.4077 (0.4152)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [ 50/172]  eta: 0:03:15  lr: 0.000084  loss: 0.4070 (0.4153)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [ 60/172]  eta: 0:02:59  lr: 0.000084  loss: 0.4123 (0.4146)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [ 70/172]  eta: 0:02:42  lr: 0.000084  loss: 0.4149 (0.4156)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [ 80/172]  eta: 0:02:26  lr: 0.000084  loss: 0.4198 (0.4178)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [ 90/172]  eta: 0:02:10  lr: 0.000084  loss: 0.4267 (0.4182)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [100/172]  eta: 0:01:54  lr: 0.000084  loss: 0.4158 (0.4184)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [110/172]  eta: 0:01:38  lr: 0.000084  loss: 0.4150 (0.4190)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [120/172]  eta: 0:01:22  lr: 0.000084  loss: 0.4071 (0.4189)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [130/172]  eta: 0:01:06  lr: 0.000084  loss: 0.4146 (0.4187)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [140/172]  eta: 0:00:50  lr: 0.000084  loss: 0.4184 (0.4189)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [150/172]  eta: 0:00:34  lr: 0.000084  loss: 0.4252 (0.4192)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [160/172]  eta: 0:00:19  lr: 0.000084  loss: 0.4241 (0.4195)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [170/172]  eta: 0:00:03  lr: 0.000084  loss: 0.4186 (0.4197)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245]  [171/172]  eta: 0:00:01  lr: 0.000084  loss: 0.4162 (0.4197)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:245] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000084  loss: 0.4162 (0.4197)\n",
      "Valid: [epoch:245]  [ 0/14]  eta: 0:00:04  loss: 0.4257 (0.4257)  time: 0.3560  data: 0.3405  max mem: 20571\n",
      "Valid: [epoch:245]  [13/14]  eta: 0:00:00  loss: 0.3828 (0.3949)  time: 0.0415  data: 0.0267  max mem: 20571\n",
      "Valid: [epoch:245] Total time: 0:00:00 (0.0494 s / it)\n",
      "Averaged stats: loss: 0.3828 (0.3949)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_245_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.395%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:246]  [  0/172]  eta: 0:07:29  lr: 0.000084  loss: 0.4112 (0.4112)  time: 2.6134  data: 1.0462  max mem: 20571\n",
      "Train: [epoch:246]  [ 10/172]  eta: 0:04:31  lr: 0.000084  loss: 0.4132 (0.4106)  time: 1.6745  data: 0.0952  max mem: 20571\n",
      "Train: [epoch:246]  [ 20/172]  eta: 0:04:07  lr: 0.000084  loss: 0.4189 (0.4169)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:246]  [ 30/172]  eta: 0:03:49  lr: 0.000084  loss: 0.4165 (0.4158)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [ 40/172]  eta: 0:03:31  lr: 0.000084  loss: 0.4155 (0.4171)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [ 50/172]  eta: 0:03:15  lr: 0.000084  loss: 0.4194 (0.4186)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [ 60/172]  eta: 0:02:58  lr: 0.000084  loss: 0.4372 (0.4222)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [ 70/172]  eta: 0:02:42  lr: 0.000084  loss: 0.4363 (0.4213)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [ 80/172]  eta: 0:02:26  lr: 0.000084  loss: 0.4245 (0.4211)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [ 90/172]  eta: 0:02:10  lr: 0.000084  loss: 0.4255 (0.4214)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [100/172]  eta: 0:01:54  lr: 0.000084  loss: 0.4236 (0.4215)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [110/172]  eta: 0:01:38  lr: 0.000084  loss: 0.4132 (0.4208)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [120/172]  eta: 0:01:22  lr: 0.000084  loss: 0.4149 (0.4212)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:246]  [130/172]  eta: 0:01:06  lr: 0.000084  loss: 0.4240 (0.4214)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:246]  [140/172]  eta: 0:00:50  lr: 0.000084  loss: 0.4207 (0.4213)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:246]  [150/172]  eta: 0:00:34  lr: 0.000084  loss: 0.4124 (0.4211)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:246]  [160/172]  eta: 0:00:19  lr: 0.000084  loss: 0.4139 (0.4212)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:246]  [170/172]  eta: 0:00:03  lr: 0.000084  loss: 0.4195 (0.4213)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:246]  [171/172]  eta: 0:00:01  lr: 0.000084  loss: 0.4195 (0.4214)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:246] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000084  loss: 0.4195 (0.4214)\n",
      "Valid: [epoch:246]  [ 0/14]  eta: 0:00:06  loss: 0.3753 (0.3753)  time: 0.4604  data: 0.4418  max mem: 20571\n",
      "Valid: [epoch:246]  [13/14]  eta: 0:00:00  loss: 0.3867 (0.3981)  time: 0.0473  data: 0.0319  max mem: 20571\n",
      "Valid: [epoch:246] Total time: 0:00:00 (0.0561 s / it)\n",
      "Averaged stats: loss: 0.3867 (0.3981)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_246_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.398%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:247]  [  0/172]  eta: 0:07:54  lr: 0.000084  loss: 0.4258 (0.4258)  time: 2.7586  data: 1.1833  max mem: 20571\n",
      "Train: [epoch:247]  [ 10/172]  eta: 0:04:32  lr: 0.000084  loss: 0.4187 (0.4129)  time: 1.6823  data: 0.1077  max mem: 20571\n",
      "Train: [epoch:247]  [ 20/172]  eta: 0:04:08  lr: 0.000084  loss: 0.4211 (0.4214)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [ 30/172]  eta: 0:03:49  lr: 0.000084  loss: 0.4203 (0.4212)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [ 40/172]  eta: 0:03:31  lr: 0.000084  loss: 0.4160 (0.4197)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [ 50/172]  eta: 0:03:15  lr: 0.000084  loss: 0.4327 (0.4234)  time: 1.5773  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:247]  [ 60/172]  eta: 0:02:58  lr: 0.000084  loss: 0.4286 (0.4216)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [ 70/172]  eta: 0:02:42  lr: 0.000084  loss: 0.4174 (0.4215)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [ 80/172]  eta: 0:02:26  lr: 0.000084  loss: 0.4215 (0.4214)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [ 90/172]  eta: 0:02:10  lr: 0.000084  loss: 0.4227 (0.4219)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [100/172]  eta: 0:01:54  lr: 0.000084  loss: 0.4230 (0.4219)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [110/172]  eta: 0:01:38  lr: 0.000084  loss: 0.4208 (0.4220)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [120/172]  eta: 0:01:22  lr: 0.000084  loss: 0.4208 (0.4226)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [130/172]  eta: 0:01:06  lr: 0.000084  loss: 0.4096 (0.4224)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [140/172]  eta: 0:00:50  lr: 0.000084  loss: 0.4128 (0.4225)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [150/172]  eta: 0:00:34  lr: 0.000084  loss: 0.4210 (0.4230)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [160/172]  eta: 0:00:19  lr: 0.000084  loss: 0.4189 (0.4222)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [170/172]  eta: 0:00:03  lr: 0.000084  loss: 0.4202 (0.4225)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247]  [171/172]  eta: 0:00:01  lr: 0.000084  loss: 0.4202 (0.4222)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:247] Total time: 0:04:32 (1.5856 s / it)\n",
      "Averaged stats: lr: 0.000084  loss: 0.4202 (0.4222)\n",
      "Valid: [epoch:247]  [ 0/14]  eta: 0:00:05  loss: 0.3415 (0.3415)  time: 0.3574  data: 0.3425  max mem: 20571\n",
      "Valid: [epoch:247]  [13/14]  eta: 0:00:00  loss: 0.3846 (0.3966)  time: 0.0405  data: 0.0254  max mem: 20571\n",
      "Valid: [epoch:247] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.3846 (0.3966)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_247_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.397%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:248]  [  0/172]  eta: 0:07:28  lr: 0.000084  loss: 0.4097 (0.4097)  time: 2.6060  data: 1.0395  max mem: 20571\n",
      "Train: [epoch:248]  [ 10/172]  eta: 0:04:30  lr: 0.000084  loss: 0.4184 (0.4235)  time: 1.6707  data: 0.0946  max mem: 20571\n",
      "Train: [epoch:248]  [ 20/172]  eta: 0:04:07  lr: 0.000084  loss: 0.4190 (0.4257)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [ 30/172]  eta: 0:03:48  lr: 0.000084  loss: 0.4274 (0.4246)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [ 40/172]  eta: 0:03:31  lr: 0.000084  loss: 0.4203 (0.4251)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [ 50/172]  eta: 0:03:15  lr: 0.000084  loss: 0.4199 (0.4224)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [ 60/172]  eta: 0:02:58  lr: 0.000084  loss: 0.4199 (0.4244)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [ 70/172]  eta: 0:02:42  lr: 0.000084  loss: 0.4374 (0.4244)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [ 80/172]  eta: 0:02:26  lr: 0.000084  loss: 0.4265 (0.4255)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [ 90/172]  eta: 0:02:10  lr: 0.000084  loss: 0.4198 (0.4251)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [100/172]  eta: 0:01:54  lr: 0.000084  loss: 0.4190 (0.4262)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:248]  [110/172]  eta: 0:01:38  lr: 0.000084  loss: 0.4285 (0.4264)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [120/172]  eta: 0:01:22  lr: 0.000084  loss: 0.4161 (0.4263)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [130/172]  eta: 0:01:06  lr: 0.000084  loss: 0.4131 (0.4252)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [140/172]  eta: 0:00:50  lr: 0.000084  loss: 0.4104 (0.4249)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [150/172]  eta: 0:00:34  lr: 0.000084  loss: 0.4251 (0.4254)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [160/172]  eta: 0:00:19  lr: 0.000084  loss: 0.4251 (0.4247)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [170/172]  eta: 0:00:03  lr: 0.000084  loss: 0.4139 (0.4247)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248]  [171/172]  eta: 0:00:01  lr: 0.000084  loss: 0.4139 (0.4248)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:248] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000084  loss: 0.4139 (0.4248)\n",
      "Valid: [epoch:248]  [ 0/14]  eta: 0:00:04  loss: 0.4326 (0.4326)  time: 0.3551  data: 0.3368  max mem: 20571\n",
      "Valid: [epoch:248]  [13/14]  eta: 0:00:00  loss: 0.3927 (0.4043)  time: 0.0405  data: 0.0253  max mem: 20571\n",
      "Valid: [epoch:248] Total time: 0:00:00 (0.0483 s / it)\n",
      "Averaged stats: loss: 0.3927 (0.4043)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_248_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.404%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:249]  [  0/172]  eta: 0:07:57  lr: 0.000084  loss: 0.3948 (0.3948)  time: 2.7775  data: 1.2075  max mem: 20571\n",
      "Train: [epoch:249]  [ 10/172]  eta: 0:04:32  lr: 0.000084  loss: 0.4080 (0.4209)  time: 1.6831  data: 0.1099  max mem: 20571\n",
      "Train: [epoch:249]  [ 20/172]  eta: 0:04:08  lr: 0.000084  loss: 0.4094 (0.4218)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [ 30/172]  eta: 0:03:49  lr: 0.000084  loss: 0.4071 (0.4182)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [ 40/172]  eta: 0:03:32  lr: 0.000084  loss: 0.4202 (0.4198)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:249]  [ 50/172]  eta: 0:03:15  lr: 0.000084  loss: 0.4219 (0.4200)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [ 60/172]  eta: 0:02:58  lr: 0.000084  loss: 0.4219 (0.4214)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [ 70/172]  eta: 0:02:42  lr: 0.000084  loss: 0.4170 (0.4203)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [ 80/172]  eta: 0:02:26  lr: 0.000084  loss: 0.4182 (0.4216)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [ 90/172]  eta: 0:02:10  lr: 0.000084  loss: 0.4189 (0.4215)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [100/172]  eta: 0:01:54  lr: 0.000084  loss: 0.4189 (0.4224)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [110/172]  eta: 0:01:38  lr: 0.000084  loss: 0.4264 (0.4236)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [120/172]  eta: 0:01:22  lr: 0.000084  loss: 0.4311 (0.4256)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [130/172]  eta: 0:01:06  lr: 0.000084  loss: 0.4368 (0.4272)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [140/172]  eta: 0:00:50  lr: 0.000084  loss: 0.4405 (0.4278)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [150/172]  eta: 0:00:34  lr: 0.000084  loss: 0.4250 (0.4274)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [160/172]  eta: 0:00:19  lr: 0.000084  loss: 0.4111 (0.4262)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [170/172]  eta: 0:00:03  lr: 0.000084  loss: 0.4114 (0.4264)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249]  [171/172]  eta: 0:00:01  lr: 0.000084  loss: 0.4123 (0.4266)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:249] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000084  loss: 0.4123 (0.4266)\n",
      "Valid: [epoch:249]  [ 0/14]  eta: 0:00:04  loss: 0.3405 (0.3405)  time: 0.3319  data: 0.3170  max mem: 20571\n",
      "Valid: [epoch:249]  [13/14]  eta: 0:00:00  loss: 0.3839 (0.3962)  time: 0.0477  data: 0.0327  max mem: 20571\n",
      "Valid: [epoch:249] Total time: 0:00:00 (0.0526 s / it)\n",
      "Averaged stats: loss: 0.3839 (0.3962)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_249_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.396%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:250]  [  0/172]  eta: 0:07:55  lr: 0.000083  loss: 0.3963 (0.3963)  time: 2.7674  data: 1.2031  max mem: 20571\n",
      "Train: [epoch:250]  [ 10/172]  eta: 0:04:32  lr: 0.000083  loss: 0.4254 (0.4211)  time: 1.6847  data: 0.1095  max mem: 20571\n",
      "Train: [epoch:250]  [ 20/172]  eta: 0:04:08  lr: 0.000083  loss: 0.4227 (0.4181)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [ 30/172]  eta: 0:03:49  lr: 0.000083  loss: 0.4112 (0.4188)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [ 40/172]  eta: 0:03:32  lr: 0.000083  loss: 0.4251 (0.4208)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [ 50/172]  eta: 0:03:15  lr: 0.000083  loss: 0.4256 (0.4233)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [ 60/172]  eta: 0:02:58  lr: 0.000083  loss: 0.4245 (0.4239)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [ 70/172]  eta: 0:02:42  lr: 0.000083  loss: 0.4246 (0.4250)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [ 80/172]  eta: 0:02:26  lr: 0.000083  loss: 0.4168 (0.4251)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [ 90/172]  eta: 0:02:10  lr: 0.000083  loss: 0.4255 (0.4260)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [100/172]  eta: 0:01:54  lr: 0.000083  loss: 0.4255 (0.4253)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [110/172]  eta: 0:01:38  lr: 0.000083  loss: 0.4238 (0.4253)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [120/172]  eta: 0:01:22  lr: 0.000083  loss: 0.4195 (0.4249)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [130/172]  eta: 0:01:06  lr: 0.000083  loss: 0.4195 (0.4261)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [140/172]  eta: 0:00:50  lr: 0.000083  loss: 0.4272 (0.4261)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [150/172]  eta: 0:00:34  lr: 0.000083  loss: 0.4272 (0.4264)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [160/172]  eta: 0:00:19  lr: 0.000083  loss: 0.4245 (0.4261)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [170/172]  eta: 0:00:03  lr: 0.000083  loss: 0.4276 (0.4262)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250]  [171/172]  eta: 0:00:01  lr: 0.000083  loss: 0.4276 (0.4267)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:250] Total time: 0:04:32 (1.5854 s / it)\n",
      "Averaged stats: lr: 0.000083  loss: 0.4276 (0.4267)\n",
      "Valid: [epoch:250]  [ 0/14]  eta: 0:00:06  loss: 0.4440 (0.4440)  time: 0.4615  data: 0.4452  max mem: 20571\n",
      "Valid: [epoch:250]  [13/14]  eta: 0:00:00  loss: 0.3972 (0.4096)  time: 0.0495  data: 0.0344  max mem: 20571\n",
      "Valid: [epoch:250] Total time: 0:00:00 (0.0574 s / it)\n",
      "Averaged stats: loss: 0.3972 (0.4096)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_250_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.410%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:251]  [  0/172]  eta: 0:07:40  lr: 0.000083  loss: 0.4335 (0.4335)  time: 2.6789  data: 1.0890  max mem: 20571\n",
      "Train: [epoch:251]  [ 10/172]  eta: 0:04:31  lr: 0.000083  loss: 0.4335 (0.4307)  time: 1.6769  data: 0.0991  max mem: 20571\n",
      "Train: [epoch:251]  [ 20/172]  eta: 0:04:07  lr: 0.000083  loss: 0.4283 (0.4312)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [ 30/172]  eta: 0:03:49  lr: 0.000083  loss: 0.4283 (0.4301)  time: 1.5775  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:251]  [ 40/172]  eta: 0:03:31  lr: 0.000083  loss: 0.4296 (0.4303)  time: 1.5777  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:251]  [ 50/172]  eta: 0:03:15  lr: 0.000083  loss: 0.4254 (0.4286)  time: 1.5768  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:251]  [ 60/172]  eta: 0:02:58  lr: 0.000083  loss: 0.4186 (0.4317)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [ 70/172]  eta: 0:02:42  lr: 0.000083  loss: 0.4237 (0.4308)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [ 80/172]  eta: 0:02:26  lr: 0.000083  loss: 0.4237 (0.4307)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [ 90/172]  eta: 0:02:10  lr: 0.000083  loss: 0.4188 (0.4297)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [100/172]  eta: 0:01:54  lr: 0.000083  loss: 0.4118 (0.4292)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [110/172]  eta: 0:01:38  lr: 0.000083  loss: 0.4275 (0.4301)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [120/172]  eta: 0:01:22  lr: 0.000083  loss: 0.4219 (0.4295)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [130/172]  eta: 0:01:06  lr: 0.000083  loss: 0.4202 (0.4290)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [140/172]  eta: 0:00:50  lr: 0.000083  loss: 0.4214 (0.4283)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [150/172]  eta: 0:00:34  lr: 0.000083  loss: 0.4189 (0.4280)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [160/172]  eta: 0:00:19  lr: 0.000083  loss: 0.4187 (0.4282)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [170/172]  eta: 0:00:03  lr: 0.000083  loss: 0.4136 (0.4276)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251]  [171/172]  eta: 0:00:01  lr: 0.000083  loss: 0.4136 (0.4278)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:251] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000083  loss: 0.4136 (0.4278)\n",
      "Valid: [epoch:251]  [ 0/14]  eta: 0:00:05  loss: 0.3774 (0.3774)  time: 0.3633  data: 0.3463  max mem: 20571\n",
      "Valid: [epoch:251]  [13/14]  eta: 0:00:00  loss: 0.4084 (0.4209)  time: 0.0400  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:251] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.4084 (0.4209)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_251_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.421%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:252]  [  0/172]  eta: 0:07:40  lr: 0.000083  loss: 0.3861 (0.3861)  time: 2.6768  data: 1.0888  max mem: 20571\n",
      "Train: [epoch:252]  [ 10/172]  eta: 0:04:31  lr: 0.000083  loss: 0.4299 (0.4315)  time: 1.6774  data: 0.0991  max mem: 20571\n",
      "Train: [epoch:252]  [ 20/172]  eta: 0:04:07  lr: 0.000083  loss: 0.4305 (0.4395)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [ 30/172]  eta: 0:03:49  lr: 0.000083  loss: 0.4261 (0.4387)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [ 40/172]  eta: 0:03:32  lr: 0.000083  loss: 0.4223 (0.4338)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [ 50/172]  eta: 0:03:15  lr: 0.000083  loss: 0.4237 (0.4332)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [ 60/172]  eta: 0:02:58  lr: 0.000083  loss: 0.4294 (0.4330)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [ 70/172]  eta: 0:02:42  lr: 0.000083  loss: 0.4359 (0.4344)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [ 80/172]  eta: 0:02:26  lr: 0.000083  loss: 0.4377 (0.4350)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [ 90/172]  eta: 0:02:10  lr: 0.000083  loss: 0.4198 (0.4340)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [100/172]  eta: 0:01:54  lr: 0.000083  loss: 0.4267 (0.4345)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [110/172]  eta: 0:01:38  lr: 0.000083  loss: 0.4295 (0.4347)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [120/172]  eta: 0:01:22  lr: 0.000083  loss: 0.4305 (0.4350)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [130/172]  eta: 0:01:06  lr: 0.000083  loss: 0.4173 (0.4341)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [140/172]  eta: 0:00:50  lr: 0.000083  loss: 0.4147 (0.4339)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [150/172]  eta: 0:00:34  lr: 0.000083  loss: 0.4333 (0.4337)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [160/172]  eta: 0:00:19  lr: 0.000083  loss: 0.4286 (0.4333)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252]  [170/172]  eta: 0:00:03  lr: 0.000083  loss: 0.4288 (0.4346)  time: 1.5795  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:252]  [171/172]  eta: 0:00:01  lr: 0.000083  loss: 0.4288 (0.4345)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:252] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000083  loss: 0.4288 (0.4345)\n",
      "Valid: [epoch:252]  [ 0/14]  eta: 0:00:04  loss: 0.4409 (0.4409)  time: 0.3432  data: 0.3273  max mem: 20571\n",
      "Valid: [epoch:252]  [13/14]  eta: 0:00:00  loss: 0.4004 (0.4131)  time: 0.0415  data: 0.0266  max mem: 20571\n",
      "Valid: [epoch:252] Total time: 0:00:00 (0.0489 s / it)\n",
      "Averaged stats: loss: 0.4004 (0.4131)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_252_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.413%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:253]  [  0/172]  eta: 0:07:41  lr: 0.000083  loss: 0.4427 (0.4427)  time: 2.6847  data: 1.1065  max mem: 20571\n",
      "Train: [epoch:253]  [ 10/172]  eta: 0:04:31  lr: 0.000083  loss: 0.4299 (0.4264)  time: 1.6766  data: 0.1007  max mem: 20571\n",
      "Train: [epoch:253]  [ 20/172]  eta: 0:04:07  lr: 0.000083  loss: 0.4318 (0.4334)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [ 30/172]  eta: 0:03:49  lr: 0.000083  loss: 0.4360 (0.4311)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [ 40/172]  eta: 0:03:31  lr: 0.000083  loss: 0.4292 (0.4319)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [ 50/172]  eta: 0:03:15  lr: 0.000083  loss: 0.4315 (0.4327)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:253]  [ 60/172]  eta: 0:02:58  lr: 0.000083  loss: 0.4223 (0.4306)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [ 70/172]  eta: 0:02:42  lr: 0.000083  loss: 0.4223 (0.4328)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [ 80/172]  eta: 0:02:26  lr: 0.000083  loss: 0.4295 (0.4330)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [ 90/172]  eta: 0:02:10  lr: 0.000083  loss: 0.4233 (0.4318)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [100/172]  eta: 0:01:54  lr: 0.000083  loss: 0.4233 (0.4318)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [110/172]  eta: 0:01:38  lr: 0.000083  loss: 0.4272 (0.4319)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [120/172]  eta: 0:01:22  lr: 0.000083  loss: 0.4307 (0.4326)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [130/172]  eta: 0:01:06  lr: 0.000083  loss: 0.4350 (0.4326)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [140/172]  eta: 0:00:50  lr: 0.000083  loss: 0.4293 (0.4318)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [150/172]  eta: 0:00:34  lr: 0.000083  loss: 0.4277 (0.4315)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [160/172]  eta: 0:00:19  lr: 0.000083  loss: 0.4297 (0.4317)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [170/172]  eta: 0:00:03  lr: 0.000083  loss: 0.4315 (0.4318)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253]  [171/172]  eta: 0:00:01  lr: 0.000083  loss: 0.4322 (0.4319)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:253] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000083  loss: 0.4322 (0.4319)\n",
      "Valid: [epoch:253]  [ 0/14]  eta: 0:00:05  loss: 0.3924 (0.3924)  time: 0.3617  data: 0.3467  max mem: 20571\n",
      "Valid: [epoch:253]  [13/14]  eta: 0:00:00  loss: 0.3941 (0.4065)  time: 0.0409  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:253] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.3941 (0.4065)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_253_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.406%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:254]  [  0/172]  eta: 0:07:57  lr: 0.000083  loss: 0.4072 (0.4072)  time: 2.7737  data: 1.1983  max mem: 20571\n",
      "Train: [epoch:254]  [ 10/172]  eta: 0:04:32  lr: 0.000083  loss: 0.4197 (0.4253)  time: 1.6846  data: 0.1091  max mem: 20571\n",
      "Train: [epoch:254]  [ 20/172]  eta: 0:04:08  lr: 0.000083  loss: 0.4254 (0.4309)  time: 1.5773  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:254]  [ 30/172]  eta: 0:03:49  lr: 0.000083  loss: 0.4272 (0.4313)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [ 40/172]  eta: 0:03:32  lr: 0.000083  loss: 0.4274 (0.4297)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [ 50/172]  eta: 0:03:15  lr: 0.000083  loss: 0.4287 (0.4370)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [ 60/172]  eta: 0:02:58  lr: 0.000083  loss: 0.4561 (0.4390)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [ 70/172]  eta: 0:02:42  lr: 0.000083  loss: 0.4320 (0.4387)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [ 80/172]  eta: 0:02:26  lr: 0.000083  loss: 0.4299 (0.4377)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [ 90/172]  eta: 0:02:10  lr: 0.000083  loss: 0.4254 (0.4366)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [100/172]  eta: 0:01:54  lr: 0.000083  loss: 0.4173 (0.4368)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [110/172]  eta: 0:01:38  lr: 0.000083  loss: 0.4375 (0.4362)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [120/172]  eta: 0:01:22  lr: 0.000083  loss: 0.4227 (0.4357)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [130/172]  eta: 0:01:06  lr: 0.000083  loss: 0.4300 (0.4354)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [140/172]  eta: 0:00:50  lr: 0.000083  loss: 0.4300 (0.4349)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [150/172]  eta: 0:00:34  lr: 0.000083  loss: 0.4288 (0.4344)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [160/172]  eta: 0:00:19  lr: 0.000083  loss: 0.4278 (0.4343)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [170/172]  eta: 0:00:03  lr: 0.000083  loss: 0.4361 (0.4347)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254]  [171/172]  eta: 0:00:01  lr: 0.000083  loss: 0.4320 (0.4347)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:254] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000083  loss: 0.4320 (0.4347)\n",
      "Valid: [epoch:254]  [ 0/14]  eta: 0:00:04  loss: 0.4543 (0.4543)  time: 0.3102  data: 0.2952  max mem: 20571\n",
      "Valid: [epoch:254]  [13/14]  eta: 0:00:00  loss: 0.4086 (0.4212)  time: 0.0488  data: 0.0339  max mem: 20571\n",
      "Valid: [epoch:254] Total time: 0:00:00 (0.0563 s / it)\n",
      "Averaged stats: loss: 0.4086 (0.4212)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_254_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.421%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:255]  [  0/172]  eta: 0:07:37  lr: 0.000083  loss: 0.4181 (0.4181)  time: 2.6584  data: 1.0899  max mem: 20571\n",
      "Train: [epoch:255]  [ 10/172]  eta: 0:04:30  lr: 0.000083  loss: 0.4357 (0.4294)  time: 1.6721  data: 0.0992  max mem: 20571\n",
      "Train: [epoch:255]  [ 20/172]  eta: 0:04:07  lr: 0.000083  loss: 0.4418 (0.4389)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [ 30/172]  eta: 0:03:48  lr: 0.000083  loss: 0.4456 (0.4381)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [ 40/172]  eta: 0:03:31  lr: 0.000083  loss: 0.4193 (0.4359)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [ 50/172]  eta: 0:03:15  lr: 0.000083  loss: 0.4193 (0.4367)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [ 60/172]  eta: 0:02:58  lr: 0.000083  loss: 0.4289 (0.4356)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [ 70/172]  eta: 0:02:42  lr: 0.000083  loss: 0.4293 (0.4349)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [ 80/172]  eta: 0:02:26  lr: 0.000083  loss: 0.4324 (0.4360)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [ 90/172]  eta: 0:02:10  lr: 0.000083  loss: 0.4324 (0.4364)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [100/172]  eta: 0:01:54  lr: 0.000083  loss: 0.4298 (0.4356)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [110/172]  eta: 0:01:38  lr: 0.000083  loss: 0.4283 (0.4358)  time: 1.5801  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:255]  [120/172]  eta: 0:01:22  lr: 0.000083  loss: 0.4347 (0.4357)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [130/172]  eta: 0:01:06  lr: 0.000083  loss: 0.4351 (0.4357)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [140/172]  eta: 0:00:50  lr: 0.000083  loss: 0.4371 (0.4353)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [150/172]  eta: 0:00:34  lr: 0.000083  loss: 0.4311 (0.4347)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [160/172]  eta: 0:00:19  lr: 0.000083  loss: 0.4256 (0.4341)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [170/172]  eta: 0:00:03  lr: 0.000083  loss: 0.4286 (0.4337)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255]  [171/172]  eta: 0:00:01  lr: 0.000083  loss: 0.4286 (0.4340)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:255] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000083  loss: 0.4286 (0.4340)\n",
      "Valid: [epoch:255]  [ 0/14]  eta: 0:00:04  loss: 0.4446 (0.4446)  time: 0.3039  data: 0.2890  max mem: 20571\n",
      "Valid: [epoch:255]  [13/14]  eta: 0:00:00  loss: 0.3931 (0.4060)  time: 0.0394  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:255] Total time: 0:00:00 (0.0444 s / it)\n",
      "Averaged stats: loss: 0.3931 (0.4060)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_255_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.406%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:256]  [  0/172]  eta: 0:07:55  lr: 0.000083  loss: 0.4655 (0.4655)  time: 2.7656  data: 1.1996  max mem: 20571\n",
      "Train: [epoch:256]  [ 10/172]  eta: 0:04:33  lr: 0.000083  loss: 0.4295 (0.4300)  time: 1.6859  data: 0.1092  max mem: 20571\n",
      "Train: [epoch:256]  [ 20/172]  eta: 0:04:08  lr: 0.000083  loss: 0.4371 (0.4358)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [ 30/172]  eta: 0:03:49  lr: 0.000083  loss: 0.4349 (0.4354)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [ 40/172]  eta: 0:03:32  lr: 0.000083  loss: 0.4328 (0.4346)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [ 50/172]  eta: 0:03:15  lr: 0.000083  loss: 0.4369 (0.4356)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [ 60/172]  eta: 0:02:59  lr: 0.000083  loss: 0.4437 (0.4373)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [ 70/172]  eta: 0:02:42  lr: 0.000083  loss: 0.4375 (0.4359)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [ 80/172]  eta: 0:02:26  lr: 0.000083  loss: 0.4375 (0.4365)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [ 90/172]  eta: 0:02:10  lr: 0.000083  loss: 0.4345 (0.4361)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [100/172]  eta: 0:01:54  lr: 0.000083  loss: 0.4328 (0.4362)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [110/172]  eta: 0:01:38  lr: 0.000083  loss: 0.4336 (0.4358)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [120/172]  eta: 0:01:22  lr: 0.000083  loss: 0.4336 (0.4360)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [130/172]  eta: 0:01:06  lr: 0.000083  loss: 0.4329 (0.4359)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [140/172]  eta: 0:00:50  lr: 0.000083  loss: 0.4411 (0.4368)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [150/172]  eta: 0:00:34  lr: 0.000083  loss: 0.4328 (0.4370)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [160/172]  eta: 0:00:19  lr: 0.000083  loss: 0.4328 (0.4375)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [170/172]  eta: 0:00:03  lr: 0.000083  loss: 0.4411 (0.4379)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256]  [171/172]  eta: 0:00:01  lr: 0.000083  loss: 0.4425 (0.4381)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:256] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000083  loss: 0.4425 (0.4381)\n",
      "Valid: [epoch:256]  [ 0/14]  eta: 0:00:06  loss: 0.4562 (0.4562)  time: 0.4651  data: 0.4459  max mem: 20571\n",
      "Valid: [epoch:256]  [13/14]  eta: 0:00:00  loss: 0.4064 (0.4188)  time: 0.0495  data: 0.0343  max mem: 20571\n",
      "Valid: [epoch:256] Total time: 0:00:00 (0.0579 s / it)\n",
      "Averaged stats: loss: 0.4064 (0.4188)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_256_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.419%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:257]  [  0/172]  eta: 0:07:34  lr: 0.000083  loss: 0.4402 (0.4402)  time: 2.6442  data: 1.0680  max mem: 20571\n",
      "Train: [epoch:257]  [ 10/172]  eta: 0:04:30  lr: 0.000083  loss: 0.4402 (0.4390)  time: 1.6717  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:257]  [ 20/172]  eta: 0:04:07  lr: 0.000083  loss: 0.4405 (0.4456)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [ 30/172]  eta: 0:03:48  lr: 0.000083  loss: 0.4465 (0.4445)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:257]  [ 40/172]  eta: 0:03:31  lr: 0.000083  loss: 0.4433 (0.4430)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [ 50/172]  eta: 0:03:14  lr: 0.000083  loss: 0.4335 (0.4434)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [ 60/172]  eta: 0:02:58  lr: 0.000083  loss: 0.4358 (0.4429)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [ 70/172]  eta: 0:02:42  lr: 0.000083  loss: 0.4393 (0.4424)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [ 80/172]  eta: 0:02:26  lr: 0.000083  loss: 0.4386 (0.4406)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [ 90/172]  eta: 0:02:10  lr: 0.000083  loss: 0.4368 (0.4395)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [100/172]  eta: 0:01:54  lr: 0.000083  loss: 0.4368 (0.4396)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [110/172]  eta: 0:01:38  lr: 0.000083  loss: 0.4394 (0.4400)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [120/172]  eta: 0:01:22  lr: 0.000083  loss: 0.4385 (0.4395)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [130/172]  eta: 0:01:06  lr: 0.000083  loss: 0.4306 (0.4386)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:257]  [140/172]  eta: 0:00:50  lr: 0.000083  loss: 0.4261 (0.4384)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [150/172]  eta: 0:00:34  lr: 0.000083  loss: 0.4352 (0.4387)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [160/172]  eta: 0:00:19  lr: 0.000083  loss: 0.4401 (0.4385)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [170/172]  eta: 0:00:03  lr: 0.000083  loss: 0.4373 (0.4383)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257]  [171/172]  eta: 0:00:01  lr: 0.000083  loss: 0.4373 (0.4382)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:257] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000083  loss: 0.4373 (0.4382)\n",
      "Valid: [epoch:257]  [ 0/14]  eta: 0:00:04  loss: 0.4479 (0.4479)  time: 0.2949  data: 0.2783  max mem: 20571\n",
      "Valid: [epoch:257]  [13/14]  eta: 0:00:00  loss: 0.4015 (0.4141)  time: 0.0485  data: 0.0333  max mem: 20571\n",
      "Valid: [epoch:257] Total time: 0:00:00 (0.0548 s / it)\n",
      "Averaged stats: loss: 0.4015 (0.4141)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_257_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.414%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:258]  [  0/172]  eta: 0:07:57  lr: 0.000083  loss: 0.4196 (0.4196)  time: 2.7736  data: 1.2040  max mem: 20571\n",
      "Train: [epoch:258]  [ 10/172]  eta: 0:04:33  lr: 0.000083  loss: 0.4359 (0.4395)  time: 1.6873  data: 0.1096  max mem: 20571\n",
      "Train: [epoch:258]  [ 20/172]  eta: 0:04:08  lr: 0.000083  loss: 0.4437 (0.4430)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:258]  [ 30/172]  eta: 0:03:49  lr: 0.000083  loss: 0.4437 (0.4412)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:258]  [ 40/172]  eta: 0:03:32  lr: 0.000083  loss: 0.4325 (0.4397)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:258]  [ 50/172]  eta: 0:03:15  lr: 0.000083  loss: 0.4409 (0.4402)  time: 1.5791  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:258]  [ 60/172]  eta: 0:02:59  lr: 0.000083  loss: 0.4390 (0.4399)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [ 70/172]  eta: 0:02:42  lr: 0.000083  loss: 0.4280 (0.4387)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [ 80/172]  eta: 0:02:26  lr: 0.000083  loss: 0.4308 (0.4397)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [ 90/172]  eta: 0:02:10  lr: 0.000083  loss: 0.4341 (0.4402)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [100/172]  eta: 0:01:54  lr: 0.000083  loss: 0.4347 (0.4399)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [110/172]  eta: 0:01:38  lr: 0.000083  loss: 0.4366 (0.4400)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [120/172]  eta: 0:01:22  lr: 0.000083  loss: 0.4416 (0.4399)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [130/172]  eta: 0:01:06  lr: 0.000083  loss: 0.4294 (0.4393)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [140/172]  eta: 0:00:50  lr: 0.000083  loss: 0.4334 (0.4396)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [150/172]  eta: 0:00:34  lr: 0.000083  loss: 0.4413 (0.4402)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [160/172]  eta: 0:00:19  lr: 0.000083  loss: 0.4351 (0.4400)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [170/172]  eta: 0:00:03  lr: 0.000083  loss: 0.4326 (0.4406)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258]  [171/172]  eta: 0:00:01  lr: 0.000083  loss: 0.4351 (0.4405)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:258] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000083  loss: 0.4351 (0.4405)\n",
      "Valid: [epoch:258]  [ 0/14]  eta: 0:00:04  loss: 0.4711 (0.4711)  time: 0.3546  data: 0.3376  max mem: 20571\n",
      "Valid: [epoch:258]  [13/14]  eta: 0:00:00  loss: 0.4293 (0.4414)  time: 0.0402  data: 0.0249  max mem: 20571\n",
      "Valid: [epoch:258] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.4293 (0.4414)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_258_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.441%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:259]  [  0/172]  eta: 0:07:49  lr: 0.000082  loss: 0.4332 (0.4332)  time: 2.7286  data: 1.1501  max mem: 20571\n",
      "Train: [epoch:259]  [ 10/172]  eta: 0:04:32  lr: 0.000082  loss: 0.4366 (0.4383)  time: 1.6808  data: 0.1047  max mem: 20571\n",
      "Train: [epoch:259]  [ 20/172]  eta: 0:04:08  lr: 0.000082  loss: 0.4366 (0.4401)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [ 30/172]  eta: 0:03:49  lr: 0.000082  loss: 0.4329 (0.4390)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:259]  [ 40/172]  eta: 0:03:32  lr: 0.000082  loss: 0.4361 (0.4427)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:259]  [ 50/172]  eta: 0:03:15  lr: 0.000082  loss: 0.4563 (0.4428)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [ 60/172]  eta: 0:02:59  lr: 0.000082  loss: 0.4417 (0.4420)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [ 70/172]  eta: 0:02:42  lr: 0.000082  loss: 0.4342 (0.4416)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [ 80/172]  eta: 0:02:26  lr: 0.000082  loss: 0.4246 (0.4411)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [ 90/172]  eta: 0:02:10  lr: 0.000082  loss: 0.4271 (0.4412)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [100/172]  eta: 0:01:54  lr: 0.000082  loss: 0.4395 (0.4410)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [110/172]  eta: 0:01:38  lr: 0.000082  loss: 0.4395 (0.4404)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [120/172]  eta: 0:01:22  lr: 0.000082  loss: 0.4456 (0.4412)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [130/172]  eta: 0:01:06  lr: 0.000082  loss: 0.4496 (0.4412)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [140/172]  eta: 0:00:50  lr: 0.000082  loss: 0.4419 (0.4414)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [150/172]  eta: 0:00:34  lr: 0.000082  loss: 0.4386 (0.4417)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [160/172]  eta: 0:00:19  lr: 0.000082  loss: 0.4386 (0.4421)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [170/172]  eta: 0:00:03  lr: 0.000082  loss: 0.4363 (0.4417)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259]  [171/172]  eta: 0:00:01  lr: 0.000082  loss: 0.4329 (0.4416)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:259] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000082  loss: 0.4329 (0.4416)\n",
      "Valid: [epoch:259]  [ 0/14]  eta: 0:00:05  loss: 0.4601 (0.4601)  time: 0.3994  data: 0.3819  max mem: 20571\n",
      "Valid: [epoch:259]  [13/14]  eta: 0:00:00  loss: 0.4158 (0.4284)  time: 0.0429  data: 0.0277  max mem: 20571\n",
      "Valid: [epoch:259] Total time: 0:00:00 (0.0480 s / it)\n",
      "Averaged stats: loss: 0.4158 (0.4284)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_259_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.428%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:260]  [  0/172]  eta: 0:07:55  lr: 0.000082  loss: 0.4094 (0.4094)  time: 2.7618  data: 1.1875  max mem: 20571\n",
      "Train: [epoch:260]  [ 10/172]  eta: 0:04:33  lr: 0.000082  loss: 0.4481 (0.4456)  time: 1.6868  data: 0.1081  max mem: 20571\n",
      "Train: [epoch:260]  [ 20/172]  eta: 0:04:08  lr: 0.000082  loss: 0.4488 (0.4486)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [ 30/172]  eta: 0:03:49  lr: 0.000082  loss: 0.4465 (0.4478)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [ 40/172]  eta: 0:03:32  lr: 0.000082  loss: 0.4394 (0.4459)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [ 50/172]  eta: 0:03:15  lr: 0.000082  loss: 0.4350 (0.4464)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [ 60/172]  eta: 0:02:59  lr: 0.000082  loss: 0.4452 (0.4465)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [ 70/172]  eta: 0:02:42  lr: 0.000082  loss: 0.4404 (0.4457)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [ 80/172]  eta: 0:02:26  lr: 0.000082  loss: 0.4395 (0.4462)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [ 90/172]  eta: 0:02:10  lr: 0.000082  loss: 0.4450 (0.4483)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [100/172]  eta: 0:01:54  lr: 0.000082  loss: 0.4575 (0.4493)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [110/172]  eta: 0:01:38  lr: 0.000082  loss: 0.4575 (0.4501)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [120/172]  eta: 0:01:22  lr: 0.000082  loss: 0.4493 (0.4491)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [130/172]  eta: 0:01:06  lr: 0.000082  loss: 0.4392 (0.4489)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [140/172]  eta: 0:00:50  lr: 0.000082  loss: 0.4273 (0.4475)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [150/172]  eta: 0:00:34  lr: 0.000082  loss: 0.4333 (0.4478)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [160/172]  eta: 0:00:19  lr: 0.000082  loss: 0.4333 (0.4468)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [170/172]  eta: 0:00:03  lr: 0.000082  loss: 0.4313 (0.4459)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260]  [171/172]  eta: 0:00:01  lr: 0.000082  loss: 0.4315 (0.4461)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:260] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000082  loss: 0.4315 (0.4461)\n",
      "Valid: [epoch:260]  [ 0/14]  eta: 0:00:03  loss: 0.4528 (0.4528)  time: 0.2797  data: 0.2639  max mem: 20571\n",
      "Valid: [epoch:260]  [13/14]  eta: 0:00:00  loss: 0.4009 (0.4136)  time: 0.0410  data: 0.0260  max mem: 20571\n",
      "Valid: [epoch:260] Total time: 0:00:00 (0.0467 s / it)\n",
      "Averaged stats: loss: 0.4009 (0.4136)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_260_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.414%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:261]  [  0/172]  eta: 0:07:52  lr: 0.000082  loss: 0.3971 (0.3971)  time: 2.7485  data: 1.1780  max mem: 20571\n",
      "Train: [epoch:261]  [ 10/172]  eta: 0:04:32  lr: 0.000082  loss: 0.4327 (0.4340)  time: 1.6841  data: 0.1072  max mem: 20571\n",
      "Train: [epoch:261]  [ 20/172]  eta: 0:04:08  lr: 0.000082  loss: 0.4354 (0.4476)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [ 30/172]  eta: 0:03:49  lr: 0.000082  loss: 0.4420 (0.4460)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [ 40/172]  eta: 0:03:32  lr: 0.000082  loss: 0.4447 (0.4461)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [ 50/172]  eta: 0:03:15  lr: 0.000082  loss: 0.4524 (0.4470)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [ 60/172]  eta: 0:02:59  lr: 0.000082  loss: 0.4383 (0.4452)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [ 70/172]  eta: 0:02:42  lr: 0.000082  loss: 0.4341 (0.4453)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [ 80/172]  eta: 0:02:26  lr: 0.000082  loss: 0.4427 (0.4452)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [ 90/172]  eta: 0:02:10  lr: 0.000082  loss: 0.4447 (0.4461)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [100/172]  eta: 0:01:54  lr: 0.000082  loss: 0.4445 (0.4464)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [110/172]  eta: 0:01:38  lr: 0.000082  loss: 0.4520 (0.4469)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [120/172]  eta: 0:01:22  lr: 0.000082  loss: 0.4520 (0.4471)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [130/172]  eta: 0:01:06  lr: 0.000082  loss: 0.4277 (0.4458)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [140/172]  eta: 0:00:50  lr: 0.000082  loss: 0.4241 (0.4455)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [150/172]  eta: 0:00:34  lr: 0.000082  loss: 0.4374 (0.4456)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [160/172]  eta: 0:00:19  lr: 0.000082  loss: 0.4369 (0.4448)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [170/172]  eta: 0:00:03  lr: 0.000082  loss: 0.4355 (0.4452)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261]  [171/172]  eta: 0:00:01  lr: 0.000082  loss: 0.4438 (0.4452)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:261] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000082  loss: 0.4438 (0.4452)\n",
      "Valid: [epoch:261]  [ 0/14]  eta: 0:00:04  loss: 0.4507 (0.4507)  time: 0.3292  data: 0.3145  max mem: 20571\n",
      "Valid: [epoch:261]  [13/14]  eta: 0:00:00  loss: 0.4090 (0.4221)  time: 0.0384  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:261] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.4090 (0.4221)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_261_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.422%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:262]  [  0/172]  eta: 0:07:23  lr: 0.000082  loss: 0.4448 (0.4448)  time: 2.5789  data: 1.0104  max mem: 20571\n",
      "Train: [epoch:262]  [ 10/172]  eta: 0:04:30  lr: 0.000082  loss: 0.4363 (0.4432)  time: 1.6717  data: 0.0919  max mem: 20571\n",
      "Train: [epoch:262]  [ 20/172]  eta: 0:04:07  lr: 0.000082  loss: 0.4395 (0.4486)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [ 30/172]  eta: 0:03:49  lr: 0.000082  loss: 0.4562 (0.4502)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [ 40/172]  eta: 0:03:31  lr: 0.000082  loss: 0.4521 (0.4476)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [ 50/172]  eta: 0:03:15  lr: 0.000082  loss: 0.4397 (0.4475)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [ 60/172]  eta: 0:02:58  lr: 0.000082  loss: 0.4420 (0.4479)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [ 70/172]  eta: 0:02:42  lr: 0.000082  loss: 0.4420 (0.4478)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [ 80/172]  eta: 0:02:26  lr: 0.000082  loss: 0.4422 (0.4472)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [ 90/172]  eta: 0:02:10  lr: 0.000082  loss: 0.4435 (0.4476)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [100/172]  eta: 0:01:54  lr: 0.000082  loss: 0.4458 (0.4478)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [110/172]  eta: 0:01:38  lr: 0.000082  loss: 0.4395 (0.4472)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [120/172]  eta: 0:01:22  lr: 0.000082  loss: 0.4461 (0.4485)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [130/172]  eta: 0:01:06  lr: 0.000082  loss: 0.4589 (0.4492)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [140/172]  eta: 0:00:50  lr: 0.000082  loss: 0.4366 (0.4486)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [150/172]  eta: 0:00:34  lr: 0.000082  loss: 0.4416 (0.4482)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [160/172]  eta: 0:00:19  lr: 0.000082  loss: 0.4416 (0.4478)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [170/172]  eta: 0:00:03  lr: 0.000082  loss: 0.4368 (0.4476)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262]  [171/172]  eta: 0:00:01  lr: 0.000082  loss: 0.4414 (0.4477)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:262] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000082  loss: 0.4414 (0.4477)\n",
      "Valid: [epoch:262]  [ 0/14]  eta: 0:00:04  loss: 0.3861 (0.3861)  time: 0.3181  data: 0.3011  max mem: 20571\n",
      "Valid: [epoch:262]  [13/14]  eta: 0:00:00  loss: 0.4124 (0.4250)  time: 0.0376  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:262] Total time: 0:00:00 (0.0422 s / it)\n",
      "Averaged stats: loss: 0.4124 (0.4250)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_262_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.425%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:263]  [  0/172]  eta: 0:07:27  lr: 0.000082  loss: 0.4672 (0.4672)  time: 2.6040  data: 1.0195  max mem: 20571\n",
      "Train: [epoch:263]  [ 10/172]  eta: 0:04:30  lr: 0.000082  loss: 0.4352 (0.4410)  time: 1.6708  data: 0.0928  max mem: 20571\n",
      "Train: [epoch:263]  [ 20/172]  eta: 0:04:07  lr: 0.000082  loss: 0.4378 (0.4537)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [ 30/172]  eta: 0:03:48  lr: 0.000082  loss: 0.4476 (0.4502)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [ 40/172]  eta: 0:03:31  lr: 0.000082  loss: 0.4447 (0.4485)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [ 50/172]  eta: 0:03:15  lr: 0.000082  loss: 0.4458 (0.4507)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [ 60/172]  eta: 0:02:58  lr: 0.000082  loss: 0.4376 (0.4488)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [ 70/172]  eta: 0:02:42  lr: 0.000082  loss: 0.4349 (0.4488)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [ 80/172]  eta: 0:02:26  lr: 0.000082  loss: 0.4503 (0.4495)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [ 90/172]  eta: 0:02:10  lr: 0.000082  loss: 0.4469 (0.4485)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [100/172]  eta: 0:01:54  lr: 0.000082  loss: 0.4425 (0.4481)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [110/172]  eta: 0:01:38  lr: 0.000082  loss: 0.4403 (0.4475)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [120/172]  eta: 0:01:22  lr: 0.000082  loss: 0.4400 (0.4475)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [130/172]  eta: 0:01:06  lr: 0.000082  loss: 0.4476 (0.4478)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [140/172]  eta: 0:00:50  lr: 0.000082  loss: 0.4482 (0.4481)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [150/172]  eta: 0:00:34  lr: 0.000082  loss: 0.4455 (0.4483)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [160/172]  eta: 0:00:19  lr: 0.000082  loss: 0.4398 (0.4484)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263]  [170/172]  eta: 0:00:03  lr: 0.000082  loss: 0.4444 (0.4487)  time: 1.5812  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:263]  [171/172]  eta: 0:00:01  lr: 0.000082  loss: 0.4659 (0.4490)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:263] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000082  loss: 0.4659 (0.4490)\n",
      "Valid: [epoch:263]  [ 0/14]  eta: 0:00:04  loss: 0.4341 (0.4341)  time: 0.2947  data: 0.2797  max mem: 20571\n",
      "Valid: [epoch:263]  [13/14]  eta: 0:00:00  loss: 0.4048 (0.4178)  time: 0.0379  data: 0.0229  max mem: 20571\n",
      "Valid: [epoch:263] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.4048 (0.4178)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_263_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.418%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:264]  [  0/172]  eta: 0:07:33  lr: 0.000082  loss: 0.4057 (0.4057)  time: 2.6394  data: 1.0675  max mem: 20571\n",
      "Train: [epoch:264]  [ 10/172]  eta: 0:04:31  lr: 0.000082  loss: 0.4444 (0.4416)  time: 1.6760  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:264]  [ 20/172]  eta: 0:04:07  lr: 0.000082  loss: 0.4486 (0.4502)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:264]  [ 30/172]  eta: 0:03:49  lr: 0.000082  loss: 0.4470 (0.4470)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:264]  [ 40/172]  eta: 0:03:32  lr: 0.000082  loss: 0.4432 (0.4468)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [ 50/172]  eta: 0:03:15  lr: 0.000082  loss: 0.4469 (0.4488)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [ 60/172]  eta: 0:02:58  lr: 0.000082  loss: 0.4522 (0.4491)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [ 70/172]  eta: 0:02:42  lr: 0.000082  loss: 0.4522 (0.4493)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [ 80/172]  eta: 0:02:26  lr: 0.000082  loss: 0.4393 (0.4488)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [ 90/172]  eta: 0:02:10  lr: 0.000082  loss: 0.4305 (0.4472)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [100/172]  eta: 0:01:54  lr: 0.000082  loss: 0.4305 (0.4478)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [110/172]  eta: 0:01:38  lr: 0.000082  loss: 0.4428 (0.4476)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [120/172]  eta: 0:01:22  lr: 0.000082  loss: 0.4428 (0.4476)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [130/172]  eta: 0:01:06  lr: 0.000082  loss: 0.4502 (0.4482)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [140/172]  eta: 0:00:50  lr: 0.000082  loss: 0.4423 (0.4477)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [150/172]  eta: 0:00:34  lr: 0.000082  loss: 0.4376 (0.4474)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [160/172]  eta: 0:00:19  lr: 0.000082  loss: 0.4427 (0.4482)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [170/172]  eta: 0:00:03  lr: 0.000082  loss: 0.4593 (0.4483)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264]  [171/172]  eta: 0:00:01  lr: 0.000082  loss: 0.4525 (0.4481)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:264] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000082  loss: 0.4525 (0.4481)\n",
      "Valid: [epoch:264]  [ 0/14]  eta: 0:00:04  loss: 0.3831 (0.3831)  time: 0.3436  data: 0.3283  max mem: 20571\n",
      "Valid: [epoch:264]  [13/14]  eta: 0:00:00  loss: 0.4097 (0.4230)  time: 0.0389  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:264] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.4097 (0.4230)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_264_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.423%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:265]  [  0/172]  eta: 0:07:58  lr: 0.000082  loss: 0.4244 (0.4244)  time: 2.7801  data: 1.2000  max mem: 20571\n",
      "Train: [epoch:265]  [ 10/172]  eta: 0:04:33  lr: 0.000082  loss: 0.4399 (0.4434)  time: 1.6856  data: 0.1092  max mem: 20571\n",
      "Train: [epoch:265]  [ 20/172]  eta: 0:04:08  lr: 0.000082  loss: 0.4436 (0.4467)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:265]  [ 30/172]  eta: 0:03:49  lr: 0.000082  loss: 0.4357 (0.4455)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [ 40/172]  eta: 0:03:32  lr: 0.000082  loss: 0.4436 (0.4505)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [ 50/172]  eta: 0:03:15  lr: 0.000082  loss: 0.4529 (0.4511)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [ 60/172]  eta: 0:02:59  lr: 0.000082  loss: 0.4524 (0.4518)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [ 70/172]  eta: 0:02:42  lr: 0.000082  loss: 0.4553 (0.4527)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [ 80/172]  eta: 0:02:26  lr: 0.000082  loss: 0.4428 (0.4512)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [ 90/172]  eta: 0:02:10  lr: 0.000082  loss: 0.4379 (0.4504)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [100/172]  eta: 0:01:54  lr: 0.000082  loss: 0.4404 (0.4508)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [110/172]  eta: 0:01:38  lr: 0.000082  loss: 0.4479 (0.4515)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [120/172]  eta: 0:01:22  lr: 0.000082  loss: 0.4490 (0.4517)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [130/172]  eta: 0:01:06  lr: 0.000082  loss: 0.4503 (0.4515)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [140/172]  eta: 0:00:50  lr: 0.000082  loss: 0.4468 (0.4512)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [150/172]  eta: 0:00:34  lr: 0.000082  loss: 0.4446 (0.4513)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [160/172]  eta: 0:00:19  lr: 0.000082  loss: 0.4433 (0.4509)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [170/172]  eta: 0:00:03  lr: 0.000082  loss: 0.4568 (0.4523)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265]  [171/172]  eta: 0:00:01  lr: 0.000082  loss: 0.4568 (0.4520)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:265] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000082  loss: 0.4568 (0.4520)\n",
      "Valid: [epoch:265]  [ 0/14]  eta: 0:00:06  loss: 0.4572 (0.4572)  time: 0.4477  data: 0.4317  max mem: 20571\n",
      "Valid: [epoch:265]  [13/14]  eta: 0:00:00  loss: 0.4148 (0.4280)  time: 0.0470  data: 0.0320  max mem: 20571\n",
      "Valid: [epoch:265] Total time: 0:00:00 (0.0524 s / it)\n",
      "Averaged stats: loss: 0.4148 (0.4280)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_265_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.428%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:266]  [  0/172]  eta: 0:07:55  lr: 0.000082  loss: 0.4658 (0.4658)  time: 2.7625  data: 1.1948  max mem: 20571\n",
      "Train: [epoch:266]  [ 10/172]  eta: 0:04:33  lr: 0.000082  loss: 0.4566 (0.4601)  time: 1.6898  data: 0.1087  max mem: 20571\n",
      "Train: [epoch:266]  [ 20/172]  eta: 0:04:08  lr: 0.000082  loss: 0.4538 (0.4607)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [ 30/172]  eta: 0:03:50  lr: 0.000082  loss: 0.4469 (0.4573)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [ 40/172]  eta: 0:03:32  lr: 0.000082  loss: 0.4338 (0.4539)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [ 50/172]  eta: 0:03:16  lr: 0.000082  loss: 0.4430 (0.4543)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [ 60/172]  eta: 0:02:59  lr: 0.000082  loss: 0.4577 (0.4548)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [ 70/172]  eta: 0:02:43  lr: 0.000082  loss: 0.4522 (0.4545)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [ 80/172]  eta: 0:02:26  lr: 0.000082  loss: 0.4522 (0.4551)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:266]  [ 90/172]  eta: 0:02:10  lr: 0.000082  loss: 0.4571 (0.4548)  time: 1.5835  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:266]  [100/172]  eta: 0:01:54  lr: 0.000082  loss: 0.4522 (0.4543)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [110/172]  eta: 0:01:38  lr: 0.000082  loss: 0.4519 (0.4543)  time: 1.5832  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:266]  [120/172]  eta: 0:01:22  lr: 0.000082  loss: 0.4434 (0.4537)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [130/172]  eta: 0:01:06  lr: 0.000082  loss: 0.4434 (0.4537)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [140/172]  eta: 0:00:50  lr: 0.000082  loss: 0.4539 (0.4536)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [150/172]  eta: 0:00:34  lr: 0.000082  loss: 0.4440 (0.4527)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [160/172]  eta: 0:00:19  lr: 0.000082  loss: 0.4440 (0.4530)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [170/172]  eta: 0:00:03  lr: 0.000082  loss: 0.4520 (0.4534)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266]  [171/172]  eta: 0:00:01  lr: 0.000082  loss: 0.4520 (0.4535)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:266] Total time: 0:04:33 (1.5904 s / it)\n",
      "Averaged stats: lr: 0.000082  loss: 0.4520 (0.4535)\n",
      "Valid: [epoch:266]  [ 0/14]  eta: 0:00:04  loss: 0.4071 (0.4071)  time: 0.3171  data: 0.3009  max mem: 20571\n",
      "Valid: [epoch:266]  [13/14]  eta: 0:00:00  loss: 0.4086 (0.4219)  time: 0.0412  data: 0.0260  max mem: 20571\n",
      "Valid: [epoch:266] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.4086 (0.4219)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_266_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.422%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:267]  [  0/172]  eta: 0:07:50  lr: 0.000082  loss: 0.4251 (0.4251)  time: 2.7347  data: 1.1628  max mem: 20571\n",
      "Train: [epoch:267]  [ 10/172]  eta: 0:04:32  lr: 0.000082  loss: 0.4505 (0.4562)  time: 1.6809  data: 0.1058  max mem: 20571\n",
      "Train: [epoch:267]  [ 20/172]  eta: 0:04:08  lr: 0.000082  loss: 0.4524 (0.4527)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [ 30/172]  eta: 0:03:49  lr: 0.000082  loss: 0.4549 (0.4543)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:267]  [ 40/172]  eta: 0:03:32  lr: 0.000082  loss: 0.4524 (0.4536)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [ 50/172]  eta: 0:03:15  lr: 0.000082  loss: 0.4489 (0.4545)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [ 60/172]  eta: 0:02:58  lr: 0.000082  loss: 0.4497 (0.4529)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [ 70/172]  eta: 0:02:42  lr: 0.000082  loss: 0.4393 (0.4543)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [ 80/172]  eta: 0:02:26  lr: 0.000082  loss: 0.4433 (0.4539)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [ 90/172]  eta: 0:02:10  lr: 0.000082  loss: 0.4620 (0.4551)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [100/172]  eta: 0:01:54  lr: 0.000082  loss: 0.4615 (0.4554)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [110/172]  eta: 0:01:38  lr: 0.000082  loss: 0.4613 (0.4557)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [120/172]  eta: 0:01:22  lr: 0.000082  loss: 0.4561 (0.4553)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [130/172]  eta: 0:01:06  lr: 0.000082  loss: 0.4478 (0.4550)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [140/172]  eta: 0:00:50  lr: 0.000082  loss: 0.4471 (0.4550)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [150/172]  eta: 0:00:34  lr: 0.000082  loss: 0.4394 (0.4554)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [160/172]  eta: 0:00:19  lr: 0.000082  loss: 0.4393 (0.4546)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [170/172]  eta: 0:00:03  lr: 0.000082  loss: 0.4509 (0.4549)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267]  [171/172]  eta: 0:00:01  lr: 0.000082  loss: 0.4448 (0.4547)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:267] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000082  loss: 0.4448 (0.4547)\n",
      "Valid: [epoch:267]  [ 0/14]  eta: 0:00:04  loss: 0.3810 (0.3810)  time: 0.3037  data: 0.2886  max mem: 20571\n",
      "Valid: [epoch:267]  [13/14]  eta: 0:00:00  loss: 0.4154 (0.4287)  time: 0.0393  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:267] Total time: 0:00:00 (0.0461 s / it)\n",
      "Averaged stats: loss: 0.4154 (0.4287)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_267_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.429%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:268]  [  0/172]  eta: 0:07:40  lr: 0.000081  loss: 0.3727 (0.3727)  time: 2.6749  data: 1.1012  max mem: 20571\n",
      "Train: [epoch:268]  [ 10/172]  eta: 0:04:32  lr: 0.000081  loss: 0.4565 (0.4530)  time: 1.6802  data: 0.1003  max mem: 20571\n",
      "Train: [epoch:268]  [ 20/172]  eta: 0:04:08  lr: 0.000081  loss: 0.4642 (0.4587)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:268]  [ 30/172]  eta: 0:03:49  lr: 0.000081  loss: 0.4510 (0.4556)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:268]  [ 40/172]  eta: 0:03:32  lr: 0.000081  loss: 0.4448 (0.4543)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:268]  [ 50/172]  eta: 0:03:15  lr: 0.000081  loss: 0.4485 (0.4566)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:268]  [ 60/172]  eta: 0:02:59  lr: 0.000081  loss: 0.4626 (0.4590)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:268]  [ 70/172]  eta: 0:02:42  lr: 0.000081  loss: 0.4551 (0.4571)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:268]  [ 80/172]  eta: 0:02:26  lr: 0.000081  loss: 0.4459 (0.4561)  time: 1.5830  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:268]  [ 90/172]  eta: 0:02:10  lr: 0.000081  loss: 0.4626 (0.4571)  time: 1.5841  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:268]  [100/172]  eta: 0:01:54  lr: 0.000081  loss: 0.4632 (0.4566)  time: 1.5836  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:268]  [110/172]  eta: 0:01:38  lr: 0.000081  loss: 0.4533 (0.4566)  time: 1.5849  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:268]  [120/172]  eta: 0:01:22  lr: 0.000081  loss: 0.4508 (0.4557)  time: 1.5836  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:268]  [130/172]  eta: 0:01:06  lr: 0.000081  loss: 0.4508 (0.4565)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:268]  [140/172]  eta: 0:00:50  lr: 0.000081  loss: 0.4485 (0.4559)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:268]  [150/172]  eta: 0:00:34  lr: 0.000081  loss: 0.4476 (0.4563)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:268]  [160/172]  eta: 0:00:19  lr: 0.000081  loss: 0.4639 (0.4574)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:268]  [170/172]  eta: 0:00:03  lr: 0.000081  loss: 0.4619 (0.4573)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:268]  [171/172]  eta: 0:00:01  lr: 0.000081  loss: 0.4613 (0.4573)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:268] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000081  loss: 0.4613 (0.4573)\n",
      "Valid: [epoch:268]  [ 0/14]  eta: 0:00:05  loss: 0.4080 (0.4080)  time: 0.3937  data: 0.3787  max mem: 20571\n",
      "Valid: [epoch:268]  [13/14]  eta: 0:00:00  loss: 0.4177 (0.4311)  time: 0.0432  data: 0.0283  max mem: 20571\n",
      "Valid: [epoch:268] Total time: 0:00:00 (0.0489 s / it)\n",
      "Averaged stats: loss: 0.4177 (0.4311)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_268_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.431%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:269]  [  0/172]  eta: 0:07:53  lr: 0.000081  loss: 0.4391 (0.4391)  time: 2.7544  data: 1.1512  max mem: 20571\n",
      "Train: [epoch:269]  [ 10/172]  eta: 0:04:32  lr: 0.000081  loss: 0.4569 (0.4534)  time: 1.6843  data: 0.1048  max mem: 20571\n",
      "Train: [epoch:269]  [ 20/172]  eta: 0:04:08  lr: 0.000081  loss: 0.4692 (0.4637)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [ 30/172]  eta: 0:03:49  lr: 0.000081  loss: 0.4716 (0.4649)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [ 40/172]  eta: 0:03:32  lr: 0.000081  loss: 0.4677 (0.4630)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [ 50/172]  eta: 0:03:15  lr: 0.000081  loss: 0.4505 (0.4606)  time: 1.5824  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:269]  [ 60/172]  eta: 0:02:59  lr: 0.000081  loss: 0.4497 (0.4595)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [ 70/172]  eta: 0:02:42  lr: 0.000081  loss: 0.4515 (0.4601)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [ 80/172]  eta: 0:02:26  lr: 0.000081  loss: 0.4515 (0.4588)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [ 90/172]  eta: 0:02:10  lr: 0.000081  loss: 0.4514 (0.4585)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [100/172]  eta: 0:01:54  lr: 0.000081  loss: 0.4500 (0.4570)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [110/172]  eta: 0:01:38  lr: 0.000081  loss: 0.4500 (0.4578)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [120/172]  eta: 0:01:22  lr: 0.000081  loss: 0.4659 (0.4584)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [130/172]  eta: 0:01:06  lr: 0.000081  loss: 0.4632 (0.4586)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [140/172]  eta: 0:00:50  lr: 0.000081  loss: 0.4663 (0.4583)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [150/172]  eta: 0:00:34  lr: 0.000081  loss: 0.4591 (0.4582)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [160/172]  eta: 0:00:19  lr: 0.000081  loss: 0.4591 (0.4584)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [170/172]  eta: 0:00:03  lr: 0.000081  loss: 0.4810 (0.4595)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269]  [171/172]  eta: 0:00:01  lr: 0.000081  loss: 0.4797 (0.4593)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:269] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000081  loss: 0.4797 (0.4593)\n",
      "Valid: [epoch:269]  [ 0/14]  eta: 0:00:06  loss: 0.3925 (0.3925)  time: 0.4996  data: 0.4838  max mem: 20571\n",
      "Valid: [epoch:269]  [13/14]  eta: 0:00:00  loss: 0.4264 (0.4395)  time: 0.0525  data: 0.0375  max mem: 20571\n",
      "Valid: [epoch:269] Total time: 0:00:00 (0.0609 s / it)\n",
      "Averaged stats: loss: 0.4264 (0.4395)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_269_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.440%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:270]  [  0/172]  eta: 0:07:32  lr: 0.000081  loss: 0.4259 (0.4259)  time: 2.6325  data: 1.0429  max mem: 20571\n",
      "Train: [epoch:270]  [ 10/172]  eta: 0:04:31  lr: 0.000081  loss: 0.4535 (0.4546)  time: 1.6759  data: 0.0949  max mem: 20571\n",
      "Train: [epoch:270]  [ 20/172]  eta: 0:04:07  lr: 0.000081  loss: 0.4669 (0.4623)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [ 30/172]  eta: 0:03:49  lr: 0.000081  loss: 0.4729 (0.4636)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [ 40/172]  eta: 0:03:32  lr: 0.000081  loss: 0.4684 (0.4634)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [ 50/172]  eta: 0:03:15  lr: 0.000081  loss: 0.4684 (0.4651)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [ 60/172]  eta: 0:02:59  lr: 0.000081  loss: 0.4597 (0.4629)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [ 70/172]  eta: 0:02:42  lr: 0.000081  loss: 0.4471 (0.4617)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [ 80/172]  eta: 0:02:26  lr: 0.000081  loss: 0.4390 (0.4603)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [ 90/172]  eta: 0:02:10  lr: 0.000081  loss: 0.4570 (0.4609)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [100/172]  eta: 0:01:54  lr: 0.000081  loss: 0.4599 (0.4604)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [110/172]  eta: 0:01:38  lr: 0.000081  loss: 0.4599 (0.4601)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [120/172]  eta: 0:01:22  lr: 0.000081  loss: 0.4423 (0.4591)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [130/172]  eta: 0:01:06  lr: 0.000081  loss: 0.4450 (0.4585)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [140/172]  eta: 0:00:50  lr: 0.000081  loss: 0.4486 (0.4592)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [150/172]  eta: 0:00:34  lr: 0.000081  loss: 0.4609 (0.4587)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [160/172]  eta: 0:00:19  lr: 0.000081  loss: 0.4566 (0.4588)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [170/172]  eta: 0:00:03  lr: 0.000081  loss: 0.4566 (0.4585)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270]  [171/172]  eta: 0:00:01  lr: 0.000081  loss: 0.4563 (0.4584)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:270] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000081  loss: 0.4563 (0.4584)\n",
      "Valid: [epoch:270]  [ 0/14]  eta: 0:00:05  loss: 0.4355 (0.4355)  time: 0.3741  data: 0.3578  max mem: 20571\n",
      "Valid: [epoch:270]  [13/14]  eta: 0:00:00  loss: 0.4604 (0.4725)  time: 0.0442  data: 0.0290  max mem: 20571\n",
      "Valid: [epoch:270] Total time: 0:00:00 (0.0504 s / it)\n",
      "Averaged stats: loss: 0.4604 (0.4725)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_270_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.473%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:271]  [  0/172]  eta: 0:07:40  lr: 0.000081  loss: 0.4824 (0.4824)  time: 2.6752  data: 1.0932  max mem: 20571\n",
      "Train: [epoch:271]  [ 10/172]  eta: 0:04:31  lr: 0.000081  loss: 0.4599 (0.4640)  time: 1.6780  data: 0.0996  max mem: 20571\n",
      "Train: [epoch:271]  [ 20/172]  eta: 0:04:08  lr: 0.000081  loss: 0.4586 (0.4648)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:271]  [ 30/172]  eta: 0:03:49  lr: 0.000081  loss: 0.4586 (0.4631)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [ 40/172]  eta: 0:03:32  lr: 0.000081  loss: 0.4675 (0.4652)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [ 50/172]  eta: 0:03:15  lr: 0.000081  loss: 0.4675 (0.4652)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [ 60/172]  eta: 0:02:59  lr: 0.000081  loss: 0.4607 (0.4634)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [ 70/172]  eta: 0:02:42  lr: 0.000081  loss: 0.4586 (0.4632)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [ 80/172]  eta: 0:02:26  lr: 0.000081  loss: 0.4659 (0.4629)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [ 90/172]  eta: 0:02:10  lr: 0.000081  loss: 0.4630 (0.4624)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [100/172]  eta: 0:01:54  lr: 0.000081  loss: 0.4607 (0.4624)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [110/172]  eta: 0:01:38  lr: 0.000081  loss: 0.4625 (0.4632)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [120/172]  eta: 0:01:22  lr: 0.000081  loss: 0.4642 (0.4636)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [130/172]  eta: 0:01:06  lr: 0.000081  loss: 0.4553 (0.4628)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [140/172]  eta: 0:00:50  lr: 0.000081  loss: 0.4557 (0.4625)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [150/172]  eta: 0:00:34  lr: 0.000081  loss: 0.4583 (0.4625)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [160/172]  eta: 0:00:19  lr: 0.000081  loss: 0.4562 (0.4623)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [170/172]  eta: 0:00:03  lr: 0.000081  loss: 0.4562 (0.4621)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271]  [171/172]  eta: 0:00:01  lr: 0.000081  loss: 0.4562 (0.4619)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:271] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000081  loss: 0.4562 (0.4619)\n",
      "Valid: [epoch:271]  [ 0/14]  eta: 0:00:04  loss: 0.3748 (0.3748)  time: 0.3390  data: 0.3238  max mem: 20571\n",
      "Valid: [epoch:271]  [13/14]  eta: 0:00:00  loss: 0.4203 (0.4337)  time: 0.0395  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:271] Total time: 0:00:00 (0.0451 s / it)\n",
      "Averaged stats: loss: 0.4203 (0.4337)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_271_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.434%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:272]  [  0/172]  eta: 0:07:26  lr: 0.000081  loss: 0.4218 (0.4218)  time: 2.5940  data: 1.0239  max mem: 20571\n",
      "Train: [epoch:272]  [ 10/172]  eta: 0:04:31  lr: 0.000081  loss: 0.4681 (0.4577)  time: 1.6731  data: 0.0932  max mem: 20571\n",
      "Train: [epoch:272]  [ 20/172]  eta: 0:04:07  lr: 0.000081  loss: 0.4697 (0.4662)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [ 30/172]  eta: 0:03:49  lr: 0.000081  loss: 0.4709 (0.4683)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [ 40/172]  eta: 0:03:32  lr: 0.000081  loss: 0.4652 (0.4656)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [ 50/172]  eta: 0:03:15  lr: 0.000081  loss: 0.4633 (0.4663)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [ 60/172]  eta: 0:02:59  lr: 0.000081  loss: 0.4671 (0.4664)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:272]  [ 70/172]  eta: 0:02:42  lr: 0.000081  loss: 0.4592 (0.4650)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [ 80/172]  eta: 0:02:26  lr: 0.000081  loss: 0.4577 (0.4639)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [ 90/172]  eta: 0:02:10  lr: 0.000081  loss: 0.4577 (0.4629)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [100/172]  eta: 0:01:54  lr: 0.000081  loss: 0.4607 (0.4640)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [110/172]  eta: 0:01:38  lr: 0.000081  loss: 0.4732 (0.4642)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [120/172]  eta: 0:01:22  lr: 0.000081  loss: 0.4623 (0.4639)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [130/172]  eta: 0:01:06  lr: 0.000081  loss: 0.4605 (0.4632)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [140/172]  eta: 0:00:50  lr: 0.000081  loss: 0.4641 (0.4640)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [150/172]  eta: 0:00:34  lr: 0.000081  loss: 0.4486 (0.4635)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [160/172]  eta: 0:00:19  lr: 0.000081  loss: 0.4486 (0.4640)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [170/172]  eta: 0:00:03  lr: 0.000081  loss: 0.4642 (0.4647)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272]  [171/172]  eta: 0:00:01  lr: 0.000081  loss: 0.4642 (0.4645)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:272] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000081  loss: 0.4642 (0.4645)\n",
      "Valid: [epoch:272]  [ 0/14]  eta: 0:00:04  loss: 0.4983 (0.4983)  time: 0.3179  data: 0.3020  max mem: 20571\n",
      "Valid: [epoch:272]  [13/14]  eta: 0:00:00  loss: 0.4482 (0.4618)  time: 0.0419  data: 0.0270  max mem: 20571\n",
      "Valid: [epoch:272] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.4482 (0.4618)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_272_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.462%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:273]  [  0/172]  eta: 0:07:25  lr: 0.000081  loss: 0.4895 (0.4895)  time: 2.5884  data: 1.0137  max mem: 20571\n",
      "Train: [epoch:273]  [ 10/172]  eta: 0:04:30  lr: 0.000081  loss: 0.4663 (0.4635)  time: 1.6689  data: 0.0922  max mem: 20571\n",
      "Train: [epoch:273]  [ 20/172]  eta: 0:04:07  lr: 0.000081  loss: 0.4663 (0.4679)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [ 30/172]  eta: 0:03:49  lr: 0.000081  loss: 0.4693 (0.4667)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [ 40/172]  eta: 0:03:31  lr: 0.000081  loss: 0.4600 (0.4662)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [ 50/172]  eta: 0:03:15  lr: 0.000081  loss: 0.4533 (0.4644)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [ 60/172]  eta: 0:02:59  lr: 0.000081  loss: 0.4427 (0.4635)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [ 70/172]  eta: 0:02:42  lr: 0.000081  loss: 0.4546 (0.4637)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [ 80/172]  eta: 0:02:26  lr: 0.000081  loss: 0.4496 (0.4622)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [ 90/172]  eta: 0:02:10  lr: 0.000081  loss: 0.4496 (0.4629)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [100/172]  eta: 0:01:54  lr: 0.000081  loss: 0.4647 (0.4635)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [110/172]  eta: 0:01:38  lr: 0.000081  loss: 0.4661 (0.4641)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [120/172]  eta: 0:01:22  lr: 0.000081  loss: 0.4661 (0.4646)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [130/172]  eta: 0:01:06  lr: 0.000081  loss: 0.4647 (0.4641)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [140/172]  eta: 0:00:50  lr: 0.000081  loss: 0.4494 (0.4631)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [150/172]  eta: 0:00:34  lr: 0.000081  loss: 0.4494 (0.4635)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [160/172]  eta: 0:00:19  lr: 0.000081  loss: 0.4612 (0.4642)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [170/172]  eta: 0:00:03  lr: 0.000081  loss: 0.4673 (0.4641)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273]  [171/172]  eta: 0:00:01  lr: 0.000081  loss: 0.4673 (0.4640)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:273] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000081  loss: 0.4673 (0.4640)\n",
      "Valid: [epoch:273]  [ 0/14]  eta: 0:00:05  loss: 0.4264 (0.4264)  time: 0.3759  data: 0.3588  max mem: 20571\n",
      "Valid: [epoch:273]  [13/14]  eta: 0:00:00  loss: 0.4278 (0.4412)  time: 0.0418  data: 0.0266  max mem: 20571\n",
      "Valid: [epoch:273] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.4278 (0.4412)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_273_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.441%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:274]  [  0/172]  eta: 0:07:55  lr: 0.000081  loss: 0.4203 (0.4203)  time: 2.7629  data: 1.1947  max mem: 20571\n",
      "Train: [epoch:274]  [ 10/172]  eta: 0:04:33  lr: 0.000081  loss: 0.4546 (0.4548)  time: 1.6877  data: 0.1087  max mem: 20571\n",
      "Train: [epoch:274]  [ 20/172]  eta: 0:04:08  lr: 0.000081  loss: 0.4585 (0.4597)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [ 30/172]  eta: 0:03:49  lr: 0.000081  loss: 0.4611 (0.4602)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [ 40/172]  eta: 0:03:32  lr: 0.000081  loss: 0.4611 (0.4623)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [ 50/172]  eta: 0:03:15  lr: 0.000081  loss: 0.4626 (0.4663)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [ 60/172]  eta: 0:02:59  lr: 0.000081  loss: 0.4752 (0.4674)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [ 70/172]  eta: 0:02:42  lr: 0.000081  loss: 0.4705 (0.4662)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [ 80/172]  eta: 0:02:26  lr: 0.000081  loss: 0.4705 (0.4668)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [ 90/172]  eta: 0:02:10  lr: 0.000081  loss: 0.4622 (0.4666)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [100/172]  eta: 0:01:54  lr: 0.000081  loss: 0.4617 (0.4667)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [110/172]  eta: 0:01:38  lr: 0.000081  loss: 0.4723 (0.4674)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [120/172]  eta: 0:01:22  lr: 0.000081  loss: 0.4678 (0.4674)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [130/172]  eta: 0:01:06  lr: 0.000081  loss: 0.4546 (0.4663)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [140/172]  eta: 0:00:50  lr: 0.000081  loss: 0.4590 (0.4667)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [150/172]  eta: 0:00:34  lr: 0.000081  loss: 0.4591 (0.4662)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [160/172]  eta: 0:00:19  lr: 0.000081  loss: 0.4522 (0.4658)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274]  [170/172]  eta: 0:00:03  lr: 0.000081  loss: 0.4549 (0.4656)  time: 1.5824  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:274]  [171/172]  eta: 0:00:01  lr: 0.000081  loss: 0.4568 (0.4658)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:274] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000081  loss: 0.4568 (0.4658)\n",
      "Valid: [epoch:274]  [ 0/14]  eta: 0:00:04  loss: 0.3975 (0.3975)  time: 0.2893  data: 0.2733  max mem: 20571\n",
      "Valid: [epoch:274]  [13/14]  eta: 0:00:00  loss: 0.4315 (0.4454)  time: 0.0401  data: 0.0249  max mem: 20571\n",
      "Valid: [epoch:274] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.4315 (0.4454)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_274_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.445%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:275]  [  0/172]  eta: 0:07:43  lr: 0.000081  loss: 0.4534 (0.4534)  time: 2.6968  data: 1.1185  max mem: 20571\n",
      "Train: [epoch:275]  [ 10/172]  eta: 0:04:31  lr: 0.000081  loss: 0.4618 (0.4556)  time: 1.6783  data: 0.1018  max mem: 20571\n",
      "Train: [epoch:275]  [ 20/172]  eta: 0:04:07  lr: 0.000081  loss: 0.4619 (0.4650)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [ 30/172]  eta: 0:03:49  lr: 0.000081  loss: 0.4679 (0.4615)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [ 40/172]  eta: 0:03:32  lr: 0.000081  loss: 0.4735 (0.4645)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [ 50/172]  eta: 0:03:15  lr: 0.000081  loss: 0.4580 (0.4628)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [ 60/172]  eta: 0:02:59  lr: 0.000081  loss: 0.4522 (0.4621)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [ 70/172]  eta: 0:02:42  lr: 0.000081  loss: 0.4614 (0.4620)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [ 80/172]  eta: 0:02:26  lr: 0.000081  loss: 0.4698 (0.4623)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [ 90/172]  eta: 0:02:10  lr: 0.000081  loss: 0.4702 (0.4632)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [100/172]  eta: 0:01:54  lr: 0.000081  loss: 0.4698 (0.4641)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [110/172]  eta: 0:01:38  lr: 0.000081  loss: 0.4698 (0.4651)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [120/172]  eta: 0:01:22  lr: 0.000081  loss: 0.4696 (0.4654)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [130/172]  eta: 0:01:06  lr: 0.000081  loss: 0.4584 (0.4658)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [140/172]  eta: 0:00:50  lr: 0.000081  loss: 0.4567 (0.4658)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [150/172]  eta: 0:00:34  lr: 0.000081  loss: 0.4549 (0.4653)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [160/172]  eta: 0:00:19  lr: 0.000081  loss: 0.4549 (0.4652)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [170/172]  eta: 0:00:03  lr: 0.000081  loss: 0.4565 (0.4654)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275]  [171/172]  eta: 0:00:01  lr: 0.000081  loss: 0.4565 (0.4656)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:275] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000081  loss: 0.4565 (0.4656)\n",
      "Valid: [epoch:275]  [ 0/14]  eta: 0:00:04  loss: 0.4414 (0.4414)  time: 0.2903  data: 0.2755  max mem: 20571\n",
      "Valid: [epoch:275]  [13/14]  eta: 0:00:00  loss: 0.4426 (0.4564)  time: 0.0371  data: 0.0220  max mem: 20571\n",
      "Valid: [epoch:275] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.4426 (0.4564)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_275_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.456%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:276]  [  0/172]  eta: 0:07:54  lr: 0.000081  loss: 0.4460 (0.4460)  time: 2.7608  data: 1.1823  max mem: 20571\n",
      "Train: [epoch:276]  [ 10/172]  eta: 0:04:33  lr: 0.000081  loss: 0.4796 (0.4749)  time: 1.6861  data: 0.1076  max mem: 20571\n",
      "Train: [epoch:276]  [ 20/172]  eta: 0:04:08  lr: 0.000081  loss: 0.4749 (0.4698)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [ 30/172]  eta: 0:03:49  lr: 0.000081  loss: 0.4647 (0.4705)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [ 40/172]  eta: 0:03:32  lr: 0.000081  loss: 0.4554 (0.4667)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [ 50/172]  eta: 0:03:15  lr: 0.000081  loss: 0.4592 (0.4681)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [ 60/172]  eta: 0:02:59  lr: 0.000081  loss: 0.4592 (0.4679)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [ 70/172]  eta: 0:02:43  lr: 0.000081  loss: 0.4614 (0.4667)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [ 80/172]  eta: 0:02:26  lr: 0.000081  loss: 0.4614 (0.4674)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [ 90/172]  eta: 0:02:10  lr: 0.000081  loss: 0.4672 (0.4692)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [100/172]  eta: 0:01:54  lr: 0.000081  loss: 0.4672 (0.4687)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [110/172]  eta: 0:01:38  lr: 0.000081  loss: 0.4652 (0.4697)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [120/172]  eta: 0:01:22  lr: 0.000081  loss: 0.4792 (0.4706)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [130/172]  eta: 0:01:06  lr: 0.000081  loss: 0.4833 (0.4713)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [140/172]  eta: 0:00:50  lr: 0.000081  loss: 0.4827 (0.4712)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [150/172]  eta: 0:00:34  lr: 0.000081  loss: 0.4620 (0.4712)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [160/172]  eta: 0:00:19  lr: 0.000081  loss: 0.4606 (0.4706)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [170/172]  eta: 0:00:03  lr: 0.000081  loss: 0.4606 (0.4705)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276]  [171/172]  eta: 0:00:01  lr: 0.000081  loss: 0.4612 (0.4708)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:276] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000081  loss: 0.4612 (0.4708)\n",
      "Valid: [epoch:276]  [ 0/14]  eta: 0:00:06  loss: 0.4821 (0.4821)  time: 0.4650  data: 0.4495  max mem: 20571\n",
      "Valid: [epoch:276]  [13/14]  eta: 0:00:00  loss: 0.4401 (0.4531)  time: 0.0480  data: 0.0330  max mem: 20571\n",
      "Valid: [epoch:276] Total time: 0:00:00 (0.0527 s / it)\n",
      "Averaged stats: loss: 0.4401 (0.4531)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_276_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.453%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:277]  [  0/172]  eta: 0:07:38  lr: 0.000080  loss: 0.4698 (0.4698)  time: 2.6685  data: 1.0904  max mem: 20571\n",
      "Train: [epoch:277]  [ 10/172]  eta: 0:04:31  lr: 0.000080  loss: 0.4698 (0.4706)  time: 1.6755  data: 0.0992  max mem: 20571\n",
      "Train: [epoch:277]  [ 20/172]  eta: 0:04:07  lr: 0.000080  loss: 0.4640 (0.4702)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [ 30/172]  eta: 0:03:49  lr: 0.000080  loss: 0.4638 (0.4691)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [ 40/172]  eta: 0:03:32  lr: 0.000080  loss: 0.4671 (0.4697)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.4711 (0.4727)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [ 60/172]  eta: 0:02:58  lr: 0.000080  loss: 0.4724 (0.4740)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.4716 (0.4735)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:277]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.4514 (0.4716)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.4595 (0.4714)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.4646 (0.4722)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.4652 (0.4715)  time: 1.5815  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:277]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.4771 (0.4726)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.4634 (0.4714)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.4490 (0.4703)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.4601 (0.4700)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.4675 (0.4703)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.4606 (0.4695)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.4606 (0.4694)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:277] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.4606 (0.4694)\n",
      "Valid: [epoch:277]  [ 0/14]  eta: 0:00:05  loss: 0.4248 (0.4248)  time: 0.4215  data: 0.4061  max mem: 20571\n",
      "Valid: [epoch:277]  [13/14]  eta: 0:00:00  loss: 0.4347 (0.4484)  time: 0.0456  data: 0.0305  max mem: 20571\n",
      "Valid: [epoch:277] Total time: 0:00:00 (0.0545 s / it)\n",
      "Averaged stats: loss: 0.4347 (0.4484)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_277_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.448%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:278]  [  0/172]  eta: 0:07:32  lr: 0.000080  loss: 0.4234 (0.4234)  time: 2.6305  data: 1.0606  max mem: 20571\n",
      "Train: [epoch:278]  [ 10/172]  eta: 0:04:31  lr: 0.000080  loss: 0.4886 (0.4816)  time: 1.6753  data: 0.0966  max mem: 20571\n",
      "Train: [epoch:278]  [ 20/172]  eta: 0:04:07  lr: 0.000080  loss: 0.4785 (0.4843)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:278]  [ 30/172]  eta: 0:03:49  lr: 0.000080  loss: 0.4732 (0.4801)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [ 40/172]  eta: 0:03:32  lr: 0.000080  loss: 0.4680 (0.4790)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.4706 (0.4793)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [ 60/172]  eta: 0:02:58  lr: 0.000080  loss: 0.4852 (0.4795)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.4821 (0.4787)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.4630 (0.4779)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.4685 (0.4778)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.4679 (0.4766)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.4616 (0.4756)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.4607 (0.4751)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.4597 (0.4737)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.4617 (0.4738)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.4668 (0.4736)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.4665 (0.4738)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.4665 (0.4732)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.4676 (0.4732)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:278] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.4676 (0.4732)\n",
      "Valid: [epoch:278]  [ 0/14]  eta: 0:00:04  loss: 0.4830 (0.4830)  time: 0.3040  data: 0.2884  max mem: 20571\n",
      "Valid: [epoch:278]  [13/14]  eta: 0:00:00  loss: 0.4365 (0.4500)  time: 0.0499  data: 0.0348  max mem: 20571\n",
      "Valid: [epoch:278] Total time: 0:00:00 (0.0552 s / it)\n",
      "Averaged stats: loss: 0.4365 (0.4500)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_278_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.450%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:279]  [  0/172]  eta: 0:08:14  lr: 0.000080  loss: 0.4415 (0.4415)  time: 2.8775  data: 1.3048  max mem: 20571\n",
      "Train: [epoch:279]  [ 10/172]  eta: 0:04:34  lr: 0.000080  loss: 0.4694 (0.4758)  time: 1.6955  data: 0.1187  max mem: 20571\n",
      "Train: [epoch:279]  [ 20/172]  eta: 0:04:09  lr: 0.000080  loss: 0.4763 (0.4869)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [ 30/172]  eta: 0:03:50  lr: 0.000080  loss: 0.4804 (0.4876)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [ 40/172]  eta: 0:03:32  lr: 0.000080  loss: 0.4796 (0.4838)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.4699 (0.4804)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [ 60/172]  eta: 0:02:59  lr: 0.000080  loss: 0.4699 (0.4789)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.4731 (0.4771)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.4709 (0.4754)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.4728 (0.4756)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.4748 (0.4747)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.4741 (0.4733)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.4620 (0.4729)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.4666 (0.4733)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.4763 (0.4737)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.4758 (0.4743)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.4635 (0.4739)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.4688 (0.4741)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.4700 (0.4742)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:279] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.4700 (0.4742)\n",
      "Valid: [epoch:279]  [ 0/14]  eta: 0:00:04  loss: 0.4884 (0.4884)  time: 0.3395  data: 0.3214  max mem: 20571\n",
      "Valid: [epoch:279]  [13/14]  eta: 0:00:00  loss: 0.4331 (0.4471)  time: 0.0395  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:279] Total time: 0:00:00 (0.0475 s / it)\n",
      "Averaged stats: loss: 0.4331 (0.4471)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_279_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.447%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:280]  [  0/172]  eta: 0:07:25  lr: 0.000080  loss: 0.4955 (0.4955)  time: 2.5886  data: 1.0210  max mem: 20571\n",
      "Train: [epoch:280]  [ 10/172]  eta: 0:04:31  lr: 0.000080  loss: 0.4676 (0.4724)  time: 1.6729  data: 0.0929  max mem: 20571\n",
      "Train: [epoch:280]  [ 20/172]  eta: 0:04:07  lr: 0.000080  loss: 0.4637 (0.4738)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [ 30/172]  eta: 0:03:49  lr: 0.000080  loss: 0.4557 (0.4704)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [ 40/172]  eta: 0:03:31  lr: 0.000080  loss: 0.4705 (0.4737)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.4765 (0.4752)  time: 1.5803  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:280]  [ 60/172]  eta: 0:02:58  lr: 0.000080  loss: 0.4706 (0.4750)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.4729 (0.4744)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.4696 (0.4746)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.4666 (0.4744)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.4666 (0.4746)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.4731 (0.4752)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.4820 (0.4751)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.4800 (0.4760)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.4735 (0.4755)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.4771 (0.4759)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.4674 (0.4755)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.4672 (0.4755)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.4656 (0.4754)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:280] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.4656 (0.4754)\n",
      "Valid: [epoch:280]  [ 0/14]  eta: 0:00:04  loss: 0.4694 (0.4694)  time: 0.3098  data: 0.2939  max mem: 20571\n",
      "Valid: [epoch:280]  [13/14]  eta: 0:00:00  loss: 0.4390 (0.4523)  time: 0.0398  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:280] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.4390 (0.4523)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_280_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.452%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:281]  [  0/172]  eta: 0:07:40  lr: 0.000080  loss: 0.4401 (0.4401)  time: 2.6770  data: 1.0849  max mem: 20571\n",
      "Train: [epoch:281]  [ 10/172]  eta: 0:04:31  lr: 0.000080  loss: 0.4699 (0.4827)  time: 1.6774  data: 0.0987  max mem: 20571\n",
      "Train: [epoch:281]  [ 20/172]  eta: 0:04:07  lr: 0.000080  loss: 0.4686 (0.4781)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [ 30/172]  eta: 0:03:49  lr: 0.000080  loss: 0.4686 (0.4792)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [ 40/172]  eta: 0:03:31  lr: 0.000080  loss: 0.4770 (0.4779)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.4768 (0.4800)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [ 60/172]  eta: 0:02:58  lr: 0.000080  loss: 0.4768 (0.4797)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.4857 (0.4796)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.4755 (0.4800)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.4746 (0.4806)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.4774 (0.4815)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.4676 (0.4813)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.4710 (0.4811)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.4725 (0.4805)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.4635 (0.4800)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.4656 (0.4797)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.4680 (0.4791)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.4699 (0.4789)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.4699 (0.4787)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:281] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.4699 (0.4787)\n",
      "Valid: [epoch:281]  [ 0/14]  eta: 0:00:05  loss: 0.4747 (0.4747)  time: 0.3726  data: 0.3565  max mem: 20571\n",
      "Valid: [epoch:281]  [13/14]  eta: 0:00:00  loss: 0.4758 (0.4882)  time: 0.0415  data: 0.0265  max mem: 20571\n",
      "Valid: [epoch:281] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.4758 (0.4882)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_281_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.488%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:282]  [  0/172]  eta: 0:07:46  lr: 0.000080  loss: 0.5544 (0.5544)  time: 2.7138  data: 1.1427  max mem: 20571\n",
      "Train: [epoch:282]  [ 10/172]  eta: 0:04:32  lr: 0.000080  loss: 0.4687 (0.4813)  time: 1.6820  data: 0.1040  max mem: 20571\n",
      "Train: [epoch:282]  [ 20/172]  eta: 0:04:08  lr: 0.000080  loss: 0.4770 (0.4880)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [ 30/172]  eta: 0:03:49  lr: 0.000080  loss: 0.4735 (0.4812)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [ 40/172]  eta: 0:03:32  lr: 0.000080  loss: 0.4694 (0.4809)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.4775 (0.4801)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [ 60/172]  eta: 0:02:59  lr: 0.000080  loss: 0.4708 (0.4785)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.4694 (0.4777)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.4732 (0.4777)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.4646 (0.4766)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.4646 (0.4763)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.4792 (0.4764)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.4805 (0.4776)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:282]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.4905 (0.4781)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:282]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.4809 (0.4777)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.4766 (0.4780)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.4701 (0.4776)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.4710 (0.4777)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.4710 (0.4776)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:282] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.4710 (0.4776)\n",
      "Valid: [epoch:282]  [ 0/14]  eta: 0:00:04  loss: 0.4135 (0.4135)  time: 0.3282  data: 0.3127  max mem: 20571\n",
      "Valid: [epoch:282]  [13/14]  eta: 0:00:00  loss: 0.4428 (0.4563)  time: 0.0375  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:282] Total time: 0:00:00 (0.0426 s / it)\n",
      "Averaged stats: loss: 0.4428 (0.4563)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_282_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.456%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:283]  [  0/172]  eta: 0:07:50  lr: 0.000080  loss: 0.4976 (0.4976)  time: 2.7337  data: 1.1534  max mem: 20571\n",
      "Train: [epoch:283]  [ 10/172]  eta: 0:04:32  lr: 0.000080  loss: 0.4841 (0.4797)  time: 1.6816  data: 0.1050  max mem: 20571\n",
      "Train: [epoch:283]  [ 20/172]  eta: 0:04:08  lr: 0.000080  loss: 0.4841 (0.4832)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [ 30/172]  eta: 0:03:49  lr: 0.000080  loss: 0.4862 (0.4845)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [ 40/172]  eta: 0:03:32  lr: 0.000080  loss: 0.4798 (0.4831)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.4777 (0.4836)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [ 60/172]  eta: 0:02:58  lr: 0.000080  loss: 0.4777 (0.4831)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.4635 (0.4816)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.4630 (0.4795)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.4635 (0.4795)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.4761 (0.4787)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.4759 (0.4799)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.4882 (0.4813)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.4838 (0.4808)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.4718 (0.4809)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.4830 (0.4812)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.4796 (0.4803)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.4687 (0.4804)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.4712 (0.4805)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:283] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.4712 (0.4805)\n",
      "Valid: [epoch:283]  [ 0/14]  eta: 0:00:05  loss: 0.4008 (0.4008)  time: 0.4189  data: 0.4020  max mem: 20571\n",
      "Valid: [epoch:283]  [13/14]  eta: 0:00:00  loss: 0.4487 (0.4621)  time: 0.0441  data: 0.0290  max mem: 20571\n",
      "Valid: [epoch:283] Total time: 0:00:00 (0.0491 s / it)\n",
      "Averaged stats: loss: 0.4487 (0.4621)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_283_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.462%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:284]  [  0/172]  eta: 0:07:42  lr: 0.000080  loss: 0.4750 (0.4750)  time: 2.6880  data: 1.1206  max mem: 20571\n",
      "Train: [epoch:284]  [ 10/172]  eta: 0:04:32  lr: 0.000080  loss: 0.4708 (0.4746)  time: 1.6806  data: 0.1020  max mem: 20571\n",
      "Train: [epoch:284]  [ 20/172]  eta: 0:04:08  lr: 0.000080  loss: 0.4705 (0.4777)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [ 30/172]  eta: 0:03:49  lr: 0.000080  loss: 0.4705 (0.4762)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [ 40/172]  eta: 0:03:31  lr: 0.000080  loss: 0.4812 (0.4786)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.4816 (0.4799)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [ 60/172]  eta: 0:02:58  lr: 0.000080  loss: 0.4716 (0.4797)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.4732 (0.4811)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.4945 (0.4815)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.4945 (0.4831)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.4802 (0.4829)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.4735 (0.4819)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.4671 (0.4811)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.4713 (0.4814)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.4843 (0.4814)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.4761 (0.4810)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.4761 (0.4817)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.4738 (0.4810)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.4738 (0.4812)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:284] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.4738 (0.4812)\n",
      "Valid: [epoch:284]  [ 0/14]  eta: 0:00:04  loss: 0.5097 (0.5097)  time: 0.2904  data: 0.2731  max mem: 20571\n",
      "Valid: [epoch:284]  [13/14]  eta: 0:00:00  loss: 0.4544 (0.4684)  time: 0.0363  data: 0.0212  max mem: 20571\n",
      "Valid: [epoch:284] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.4544 (0.4684)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_284_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.468%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:285]  [  0/172]  eta: 0:07:29  lr: 0.000080  loss: 0.4540 (0.4540)  time: 2.6130  data: 1.0323  max mem: 20571\n",
      "Train: [epoch:285]  [ 10/172]  eta: 0:04:30  lr: 0.000080  loss: 0.4786 (0.4786)  time: 1.6719  data: 0.0940  max mem: 20571\n",
      "Train: [epoch:285]  [ 20/172]  eta: 0:04:07  lr: 0.000080  loss: 0.4848 (0.4829)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [ 30/172]  eta: 0:03:49  lr: 0.000080  loss: 0.4847 (0.4840)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [ 40/172]  eta: 0:03:31  lr: 0.000080  loss: 0.4779 (0.4849)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [ 50/172]  eta: 0:03:15  lr: 0.000080  loss: 0.4819 (0.4869)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [ 60/172]  eta: 0:02:58  lr: 0.000080  loss: 0.4819 (0.4858)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [ 70/172]  eta: 0:02:42  lr: 0.000080  loss: 0.4691 (0.4844)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [ 80/172]  eta: 0:02:26  lr: 0.000080  loss: 0.4690 (0.4837)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [ 90/172]  eta: 0:02:10  lr: 0.000080  loss: 0.4756 (0.4831)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [100/172]  eta: 0:01:54  lr: 0.000080  loss: 0.4756 (0.4832)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [110/172]  eta: 0:01:38  lr: 0.000080  loss: 0.4814 (0.4831)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [120/172]  eta: 0:01:22  lr: 0.000080  loss: 0.4721 (0.4821)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [130/172]  eta: 0:01:06  lr: 0.000080  loss: 0.4822 (0.4832)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [140/172]  eta: 0:00:50  lr: 0.000080  loss: 0.4851 (0.4837)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [150/172]  eta: 0:00:34  lr: 0.000080  loss: 0.4764 (0.4835)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [160/172]  eta: 0:00:19  lr: 0.000080  loss: 0.4764 (0.4833)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285]  [170/172]  eta: 0:00:03  lr: 0.000080  loss: 0.4963 (0.4844)  time: 1.5822  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:285]  [171/172]  eta: 0:00:01  lr: 0.000080  loss: 0.4963 (0.4844)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:285] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000080  loss: 0.4963 (0.4844)\n",
      "Valid: [epoch:285]  [ 0/14]  eta: 0:00:04  loss: 0.5270 (0.5270)  time: 0.3144  data: 0.2987  max mem: 20571\n",
      "Valid: [epoch:285]  [13/14]  eta: 0:00:00  loss: 0.4735 (0.4870)  time: 0.0429  data: 0.0279  max mem: 20571\n",
      "Valid: [epoch:285] Total time: 0:00:00 (0.0476 s / it)\n",
      "Averaged stats: loss: 0.4735 (0.4870)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_285_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.487%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:286]  [  0/172]  eta: 0:07:30  lr: 0.000079  loss: 0.4818 (0.4818)  time: 2.6216  data: 1.0429  max mem: 20571\n",
      "Train: [epoch:286]  [ 10/172]  eta: 0:04:31  lr: 0.000079  loss: 0.4818 (0.4884)  time: 1.6757  data: 0.0949  max mem: 20571\n",
      "Train: [epoch:286]  [ 20/172]  eta: 0:04:07  lr: 0.000079  loss: 0.4869 (0.4953)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [ 30/172]  eta: 0:03:49  lr: 0.000079  loss: 0.4879 (0.4925)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [ 40/172]  eta: 0:03:32  lr: 0.000079  loss: 0.4817 (0.4893)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [ 50/172]  eta: 0:03:15  lr: 0.000079  loss: 0.4664 (0.4879)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [ 60/172]  eta: 0:02:59  lr: 0.000079  loss: 0.4690 (0.4881)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [ 70/172]  eta: 0:02:42  lr: 0.000079  loss: 0.4690 (0.4862)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [ 80/172]  eta: 0:02:26  lr: 0.000079  loss: 0.4763 (0.4859)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [ 90/172]  eta: 0:02:10  lr: 0.000079  loss: 0.4890 (0.4865)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [100/172]  eta: 0:01:54  lr: 0.000079  loss: 0.4813 (0.4852)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [110/172]  eta: 0:01:38  lr: 0.000079  loss: 0.4705 (0.4848)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [120/172]  eta: 0:01:22  lr: 0.000079  loss: 0.4731 (0.4838)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [130/172]  eta: 0:01:06  lr: 0.000079  loss: 0.4738 (0.4830)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [140/172]  eta: 0:00:50  lr: 0.000079  loss: 0.4738 (0.4833)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [150/172]  eta: 0:00:34  lr: 0.000079  loss: 0.4951 (0.4852)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [160/172]  eta: 0:00:19  lr: 0.000079  loss: 0.5079 (0.4859)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [170/172]  eta: 0:00:03  lr: 0.000079  loss: 0.4819 (0.4858)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286]  [171/172]  eta: 0:00:01  lr: 0.000079  loss: 0.4819 (0.4859)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:286] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000079  loss: 0.4819 (0.4859)\n",
      "Valid: [epoch:286]  [ 0/14]  eta: 0:00:04  loss: 0.4372 (0.4372)  time: 0.2998  data: 0.2840  max mem: 20571\n",
      "Valid: [epoch:286]  [13/14]  eta: 0:00:00  loss: 0.4482 (0.4622)  time: 0.0407  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:286] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.4482 (0.4622)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_286_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.462%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:287]  [  0/172]  eta: 0:07:37  lr: 0.000079  loss: 0.4874 (0.4874)  time: 2.6627  data: 1.0835  max mem: 20571\n",
      "Train: [epoch:287]  [ 10/172]  eta: 0:04:31  lr: 0.000079  loss: 0.4735 (0.4741)  time: 1.6773  data: 0.0986  max mem: 20571\n",
      "Train: [epoch:287]  [ 20/172]  eta: 0:04:08  lr: 0.000079  loss: 0.4798 (0.4779)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [ 30/172]  eta: 0:03:49  lr: 0.000079  loss: 0.4868 (0.4845)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [ 40/172]  eta: 0:03:32  lr: 0.000079  loss: 0.4814 (0.4827)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [ 50/172]  eta: 0:03:15  lr: 0.000079  loss: 0.4748 (0.4813)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [ 60/172]  eta: 0:02:59  lr: 0.000079  loss: 0.4776 (0.4841)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [ 70/172]  eta: 0:02:42  lr: 0.000079  loss: 0.4868 (0.4836)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [ 80/172]  eta: 0:02:26  lr: 0.000079  loss: 0.4829 (0.4836)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [ 90/172]  eta: 0:02:10  lr: 0.000079  loss: 0.4829 (0.4833)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [100/172]  eta: 0:01:54  lr: 0.000079  loss: 0.4780 (0.4843)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [110/172]  eta: 0:01:38  lr: 0.000079  loss: 0.4815 (0.4845)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [120/172]  eta: 0:01:22  lr: 0.000079  loss: 0.4812 (0.4847)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [130/172]  eta: 0:01:06  lr: 0.000079  loss: 0.4792 (0.4846)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [140/172]  eta: 0:00:50  lr: 0.000079  loss: 0.4792 (0.4842)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [150/172]  eta: 0:00:34  lr: 0.000079  loss: 0.4810 (0.4846)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [160/172]  eta: 0:00:19  lr: 0.000079  loss: 0.4788 (0.4844)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [170/172]  eta: 0:00:03  lr: 0.000079  loss: 0.4783 (0.4844)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287]  [171/172]  eta: 0:00:01  lr: 0.000079  loss: 0.4783 (0.4843)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:287] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000079  loss: 0.4783 (0.4843)\n",
      "Valid: [epoch:287]  [ 0/14]  eta: 0:00:04  loss: 0.5173 (0.5173)  time: 0.3336  data: 0.3160  max mem: 20571\n",
      "Valid: [epoch:287]  [13/14]  eta: 0:00:00  loss: 0.4620 (0.4756)  time: 0.0386  data: 0.0235  max mem: 20571\n",
      "Valid: [epoch:287] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.4620 (0.4756)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_287_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.476%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:288]  [  0/172]  eta: 0:07:32  lr: 0.000079  loss: 0.4783 (0.4783)  time: 2.6333  data: 1.0455  max mem: 20571\n",
      "Train: [epoch:288]  [ 10/172]  eta: 0:04:31  lr: 0.000079  loss: 0.4858 (0.4848)  time: 1.6775  data: 0.0951  max mem: 20571\n",
      "Train: [epoch:288]  [ 20/172]  eta: 0:04:07  lr: 0.000079  loss: 0.4858 (0.4888)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [ 30/172]  eta: 0:03:49  lr: 0.000079  loss: 0.4886 (0.4886)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [ 40/172]  eta: 0:03:32  lr: 0.000079  loss: 0.4829 (0.4909)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [ 50/172]  eta: 0:03:15  lr: 0.000079  loss: 0.4753 (0.4891)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [ 60/172]  eta: 0:02:59  lr: 0.000079  loss: 0.4791 (0.4879)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [ 70/172]  eta: 0:02:42  lr: 0.000079  loss: 0.4813 (0.4873)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [ 80/172]  eta: 0:02:26  lr: 0.000079  loss: 0.4813 (0.4868)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [ 90/172]  eta: 0:02:10  lr: 0.000079  loss: 0.4770 (0.4860)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [100/172]  eta: 0:01:54  lr: 0.000079  loss: 0.4779 (0.4861)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [110/172]  eta: 0:01:38  lr: 0.000079  loss: 0.4778 (0.4855)  time: 1.5832  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:288]  [120/172]  eta: 0:01:22  lr: 0.000079  loss: 0.4778 (0.4849)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [130/172]  eta: 0:01:06  lr: 0.000079  loss: 0.4855 (0.4863)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [140/172]  eta: 0:00:50  lr: 0.000079  loss: 0.4824 (0.4854)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [150/172]  eta: 0:00:34  lr: 0.000079  loss: 0.4758 (0.4854)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [160/172]  eta: 0:00:19  lr: 0.000079  loss: 0.4865 (0.4855)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [170/172]  eta: 0:00:03  lr: 0.000079  loss: 0.4950 (0.4864)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288]  [171/172]  eta: 0:00:01  lr: 0.000079  loss: 0.4955 (0.4865)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:288] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000079  loss: 0.4955 (0.4865)\n",
      "Valid: [epoch:288]  [ 0/14]  eta: 0:00:04  loss: 0.5075 (0.5075)  time: 0.3125  data: 0.2956  max mem: 20571\n",
      "Valid: [epoch:288]  [13/14]  eta: 0:00:00  loss: 0.4512 (0.4652)  time: 0.0417  data: 0.0265  max mem: 20571\n",
      "Valid: [epoch:288] Total time: 0:00:00 (0.0486 s / it)\n",
      "Averaged stats: loss: 0.4512 (0.4652)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_288_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.465%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:289]  [  0/172]  eta: 0:07:59  lr: 0.000079  loss: 0.4702 (0.4702)  time: 2.7867  data: 1.2068  max mem: 20571\n",
      "Train: [epoch:289]  [ 10/172]  eta: 0:04:33  lr: 0.000079  loss: 0.4875 (0.4845)  time: 1.6889  data: 0.1098  max mem: 20571\n",
      "Train: [epoch:289]  [ 20/172]  eta: 0:04:08  lr: 0.000079  loss: 0.4878 (0.4953)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [ 30/172]  eta: 0:03:49  lr: 0.000079  loss: 0.5055 (0.4973)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [ 40/172]  eta: 0:03:32  lr: 0.000079  loss: 0.4955 (0.4947)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [ 50/172]  eta: 0:03:15  lr: 0.000079  loss: 0.4838 (0.4942)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [ 60/172]  eta: 0:02:59  lr: 0.000079  loss: 0.4855 (0.4950)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [ 70/172]  eta: 0:02:42  lr: 0.000079  loss: 0.4885 (0.4963)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [ 80/172]  eta: 0:02:26  lr: 0.000079  loss: 0.4776 (0.4947)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [ 90/172]  eta: 0:02:10  lr: 0.000079  loss: 0.4746 (0.4937)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [100/172]  eta: 0:01:54  lr: 0.000079  loss: 0.4779 (0.4940)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [110/172]  eta: 0:01:38  lr: 0.000079  loss: 0.4938 (0.4935)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [120/172]  eta: 0:01:22  lr: 0.000079  loss: 0.4983 (0.4938)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [130/172]  eta: 0:01:06  lr: 0.000079  loss: 0.5024 (0.4945)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [140/172]  eta: 0:00:50  lr: 0.000079  loss: 0.4877 (0.4940)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [150/172]  eta: 0:00:34  lr: 0.000079  loss: 0.4808 (0.4930)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [160/172]  eta: 0:00:19  lr: 0.000079  loss: 0.4780 (0.4918)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [170/172]  eta: 0:00:03  lr: 0.000079  loss: 0.4780 (0.4914)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289]  [171/172]  eta: 0:00:01  lr: 0.000079  loss: 0.4799 (0.4917)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:289] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000079  loss: 0.4799 (0.4917)\n",
      "Valid: [epoch:289]  [ 0/14]  eta: 0:00:04  loss: 0.4984 (0.4984)  time: 0.3178  data: 0.3021  max mem: 20571\n",
      "Valid: [epoch:289]  [13/14]  eta: 0:00:00  loss: 0.4436 (0.4581)  time: 0.0485  data: 0.0335  max mem: 20571\n",
      "Valid: [epoch:289] Total time: 0:00:00 (0.0538 s / it)\n",
      "Averaged stats: loss: 0.4436 (0.4581)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_289_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.458%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:290]  [  0/172]  eta: 0:07:25  lr: 0.000079  loss: 0.4578 (0.4578)  time: 2.5915  data: 1.0252  max mem: 20571\n",
      "Train: [epoch:290]  [ 10/172]  eta: 0:04:30  lr: 0.000079  loss: 0.4859 (0.4838)  time: 1.6720  data: 0.0933  max mem: 20571\n",
      "Train: [epoch:290]  [ 20/172]  eta: 0:04:07  lr: 0.000079  loss: 0.4859 (0.4884)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [ 30/172]  eta: 0:03:48  lr: 0.000079  loss: 0.5036 (0.4950)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [ 40/172]  eta: 0:03:31  lr: 0.000079  loss: 0.4977 (0.4926)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [ 50/172]  eta: 0:03:15  lr: 0.000079  loss: 0.4887 (0.4917)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [ 60/172]  eta: 0:02:58  lr: 0.000079  loss: 0.4888 (0.4922)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [ 70/172]  eta: 0:02:42  lr: 0.000079  loss: 0.4906 (0.4918)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [ 80/172]  eta: 0:02:26  lr: 0.000079  loss: 0.4892 (0.4917)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [ 90/172]  eta: 0:02:10  lr: 0.000079  loss: 0.5004 (0.4931)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [100/172]  eta: 0:01:54  lr: 0.000079  loss: 0.5061 (0.4941)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [110/172]  eta: 0:01:38  lr: 0.000079  loss: 0.4938 (0.4939)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [120/172]  eta: 0:01:22  lr: 0.000079  loss: 0.4898 (0.4935)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [130/172]  eta: 0:01:06  lr: 0.000079  loss: 0.4775 (0.4930)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [140/172]  eta: 0:00:50  lr: 0.000079  loss: 0.4818 (0.4925)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [150/172]  eta: 0:00:34  lr: 0.000079  loss: 0.4892 (0.4922)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [160/172]  eta: 0:00:19  lr: 0.000079  loss: 0.4966 (0.4925)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [170/172]  eta: 0:00:03  lr: 0.000079  loss: 0.4987 (0.4929)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290]  [171/172]  eta: 0:00:01  lr: 0.000079  loss: 0.4987 (0.4928)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:290] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000079  loss: 0.4987 (0.4928)\n",
      "Valid: [epoch:290]  [ 0/14]  eta: 0:00:05  loss: 0.4192 (0.4192)  time: 0.3840  data: 0.3691  max mem: 20571\n",
      "Valid: [epoch:290]  [13/14]  eta: 0:00:00  loss: 0.4668 (0.4807)  time: 0.0429  data: 0.0280  max mem: 20571\n",
      "Valid: [epoch:290] Total time: 0:00:00 (0.0512 s / it)\n",
      "Averaged stats: loss: 0.4668 (0.4807)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_290_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.481%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:291]  [  0/172]  eta: 0:07:35  lr: 0.000079  loss: 0.4781 (0.4781)  time: 2.6502  data: 1.0763  max mem: 20571\n",
      "Train: [epoch:291]  [ 10/172]  eta: 0:04:31  lr: 0.000079  loss: 0.4836 (0.4869)  time: 1.6760  data: 0.0979  max mem: 20571\n",
      "Train: [epoch:291]  [ 20/172]  eta: 0:04:07  lr: 0.000079  loss: 0.4836 (0.4839)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [ 30/172]  eta: 0:03:49  lr: 0.000079  loss: 0.4915 (0.4893)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [ 40/172]  eta: 0:03:31  lr: 0.000079  loss: 0.4768 (0.4866)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [ 50/172]  eta: 0:03:15  lr: 0.000079  loss: 0.4768 (0.4875)  time: 1.5790  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:291]  [ 60/172]  eta: 0:02:58  lr: 0.000079  loss: 0.4911 (0.4879)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [ 70/172]  eta: 0:02:42  lr: 0.000079  loss: 0.4935 (0.4909)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [ 80/172]  eta: 0:02:26  lr: 0.000079  loss: 0.4935 (0.4903)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [ 90/172]  eta: 0:02:10  lr: 0.000079  loss: 0.4764 (0.4892)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [100/172]  eta: 0:01:54  lr: 0.000079  loss: 0.4776 (0.4887)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [110/172]  eta: 0:01:38  lr: 0.000079  loss: 0.4929 (0.4902)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [120/172]  eta: 0:01:22  lr: 0.000079  loss: 0.4956 (0.4907)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [130/172]  eta: 0:01:06  lr: 0.000079  loss: 0.4992 (0.4913)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [140/172]  eta: 0:00:50  lr: 0.000079  loss: 0.4930 (0.4911)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [150/172]  eta: 0:00:34  lr: 0.000079  loss: 0.4914 (0.4911)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [160/172]  eta: 0:00:19  lr: 0.000079  loss: 0.4824 (0.4908)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [170/172]  eta: 0:00:03  lr: 0.000079  loss: 0.4755 (0.4903)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291]  [171/172]  eta: 0:00:01  lr: 0.000079  loss: 0.4720 (0.4901)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:291] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000079  loss: 0.4720 (0.4901)\n",
      "Valid: [epoch:291]  [ 0/14]  eta: 0:00:04  loss: 0.5192 (0.5192)  time: 0.3043  data: 0.2865  max mem: 20571\n",
      "Valid: [epoch:291]  [13/14]  eta: 0:00:00  loss: 0.4671 (0.4809)  time: 0.0373  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:291] Total time: 0:00:00 (0.0423 s / it)\n",
      "Averaged stats: loss: 0.4671 (0.4809)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_291_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.481%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:292]  [  0/172]  eta: 0:07:41  lr: 0.000079  loss: 0.4841 (0.4841)  time: 2.6849  data: 1.1183  max mem: 20571\n",
      "Train: [epoch:292]  [ 10/172]  eta: 0:04:32  lr: 0.000079  loss: 0.4888 (0.4936)  time: 1.6798  data: 0.1018  max mem: 20571\n",
      "Train: [epoch:292]  [ 20/172]  eta: 0:04:08  lr: 0.000079  loss: 0.4943 (0.4980)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [ 30/172]  eta: 0:03:49  lr: 0.000079  loss: 0.4937 (0.4930)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [ 40/172]  eta: 0:03:32  lr: 0.000079  loss: 0.4786 (0.4906)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [ 50/172]  eta: 0:03:15  lr: 0.000079  loss: 0.4876 (0.4915)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [ 60/172]  eta: 0:02:59  lr: 0.000079  loss: 0.4904 (0.4924)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [ 70/172]  eta: 0:02:42  lr: 0.000079  loss: 0.4904 (0.4926)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [ 80/172]  eta: 0:02:26  lr: 0.000079  loss: 0.4930 (0.4934)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [ 90/172]  eta: 0:02:10  lr: 0.000079  loss: 0.4930 (0.4931)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [100/172]  eta: 0:01:54  lr: 0.000079  loss: 0.4930 (0.4934)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [110/172]  eta: 0:01:38  lr: 0.000079  loss: 0.4880 (0.4931)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [120/172]  eta: 0:01:22  lr: 0.000079  loss: 0.4837 (0.4928)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [130/172]  eta: 0:01:06  lr: 0.000079  loss: 0.4887 (0.4927)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [140/172]  eta: 0:00:50  lr: 0.000079  loss: 0.4842 (0.4925)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [150/172]  eta: 0:00:34  lr: 0.000079  loss: 0.4875 (0.4934)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:292]  [160/172]  eta: 0:00:19  lr: 0.000079  loss: 0.4940 (0.4937)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [170/172]  eta: 0:00:03  lr: 0.000079  loss: 0.4904 (0.4934)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292]  [171/172]  eta: 0:00:01  lr: 0.000079  loss: 0.4906 (0.4935)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:292] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000079  loss: 0.4906 (0.4935)\n",
      "Valid: [epoch:292]  [ 0/14]  eta: 0:00:04  loss: 0.5077 (0.5077)  time: 0.2926  data: 0.2762  max mem: 20571\n",
      "Valid: [epoch:292]  [13/14]  eta: 0:00:00  loss: 0.4487 (0.4632)  time: 0.0363  data: 0.0212  max mem: 20571\n",
      "Valid: [epoch:292] Total time: 0:00:00 (0.0423 s / it)\n",
      "Averaged stats: loss: 0.4487 (0.4632)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_292_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.463%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:293]  [  0/172]  eta: 0:07:30  lr: 0.000079  loss: 0.4586 (0.4586)  time: 2.6205  data: 1.0326  max mem: 20571\n",
      "Train: [epoch:293]  [ 10/172]  eta: 0:04:31  lr: 0.000079  loss: 0.4739 (0.4842)  time: 1.6732  data: 0.0940  max mem: 20571\n",
      "Train: [epoch:293]  [ 20/172]  eta: 0:04:07  lr: 0.000079  loss: 0.4928 (0.4935)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [ 30/172]  eta: 0:03:49  lr: 0.000079  loss: 0.4928 (0.4926)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [ 40/172]  eta: 0:03:31  lr: 0.000079  loss: 0.4948 (0.4922)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [ 50/172]  eta: 0:03:15  lr: 0.000079  loss: 0.4969 (0.4922)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [ 60/172]  eta: 0:02:58  lr: 0.000079  loss: 0.4973 (0.4929)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [ 70/172]  eta: 0:02:42  lr: 0.000079  loss: 0.4860 (0.4923)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [ 80/172]  eta: 0:02:26  lr: 0.000079  loss: 0.4860 (0.4933)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [ 90/172]  eta: 0:02:10  lr: 0.000079  loss: 0.4877 (0.4946)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [100/172]  eta: 0:01:54  lr: 0.000079  loss: 0.4929 (0.4940)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [110/172]  eta: 0:01:38  lr: 0.000079  loss: 0.4883 (0.4944)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [120/172]  eta: 0:01:22  lr: 0.000079  loss: 0.5067 (0.4961)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [130/172]  eta: 0:01:06  lr: 0.000079  loss: 0.5044 (0.4963)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [140/172]  eta: 0:00:50  lr: 0.000079  loss: 0.4985 (0.4963)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [150/172]  eta: 0:00:34  lr: 0.000079  loss: 0.4962 (0.4960)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [160/172]  eta: 0:00:19  lr: 0.000079  loss: 0.4966 (0.4962)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [170/172]  eta: 0:00:03  lr: 0.000079  loss: 0.4990 (0.4966)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293]  [171/172]  eta: 0:00:01  lr: 0.000079  loss: 0.5022 (0.4968)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:293] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000079  loss: 0.5022 (0.4968)\n",
      "Valid: [epoch:293]  [ 0/14]  eta: 0:00:04  loss: 0.5056 (0.5056)  time: 0.2938  data: 0.2791  max mem: 20571\n",
      "Valid: [epoch:293]  [13/14]  eta: 0:00:00  loss: 0.4513 (0.4655)  time: 0.0365  data: 0.0216  max mem: 20571\n",
      "Valid: [epoch:293] Total time: 0:00:00 (0.0421 s / it)\n",
      "Averaged stats: loss: 0.4513 (0.4655)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_293_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.466%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:294]  [  0/172]  eta: 0:07:49  lr: 0.000079  loss: 0.4833 (0.4833)  time: 2.7286  data: 1.1642  max mem: 20571\n",
      "Train: [epoch:294]  [ 10/172]  eta: 0:04:32  lr: 0.000079  loss: 0.4833 (0.4946)  time: 1.6804  data: 0.1059  max mem: 20571\n",
      "Train: [epoch:294]  [ 20/172]  eta: 0:04:08  lr: 0.000079  loss: 0.4970 (0.4983)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [ 30/172]  eta: 0:03:49  lr: 0.000079  loss: 0.4970 (0.4978)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [ 40/172]  eta: 0:03:31  lr: 0.000079  loss: 0.4898 (0.4985)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [ 50/172]  eta: 0:03:15  lr: 0.000079  loss: 0.4754 (0.4971)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [ 60/172]  eta: 0:02:58  lr: 0.000079  loss: 0.4749 (0.4950)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [ 70/172]  eta: 0:02:42  lr: 0.000079  loss: 0.5022 (0.4946)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [ 80/172]  eta: 0:02:26  lr: 0.000079  loss: 0.4976 (0.4937)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [ 90/172]  eta: 0:02:10  lr: 0.000079  loss: 0.4976 (0.4941)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [100/172]  eta: 0:01:54  lr: 0.000079  loss: 0.4850 (0.4940)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [110/172]  eta: 0:01:38  lr: 0.000079  loss: 0.5046 (0.4950)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [120/172]  eta: 0:01:22  lr: 0.000079  loss: 0.5032 (0.4951)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [130/172]  eta: 0:01:06  lr: 0.000079  loss: 0.4884 (0.4938)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [140/172]  eta: 0:00:50  lr: 0.000079  loss: 0.4817 (0.4939)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [150/172]  eta: 0:00:34  lr: 0.000079  loss: 0.4957 (0.4943)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [160/172]  eta: 0:00:19  lr: 0.000079  loss: 0.5016 (0.4949)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [170/172]  eta: 0:00:03  lr: 0.000079  loss: 0.5016 (0.4945)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294]  [171/172]  eta: 0:00:01  lr: 0.000079  loss: 0.5016 (0.4945)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:294] Total time: 0:04:32 (1.5856 s / it)\n",
      "Averaged stats: lr: 0.000079  loss: 0.5016 (0.4945)\n",
      "Valid: [epoch:294]  [ 0/14]  eta: 0:00:05  loss: 0.5051 (0.5051)  time: 0.3825  data: 0.3660  max mem: 20571\n",
      "Valid: [epoch:294]  [13/14]  eta: 0:00:00  loss: 0.4586 (0.4727)  time: 0.0442  data: 0.0292  max mem: 20571\n",
      "Valid: [epoch:294] Total time: 0:00:00 (0.0529 s / it)\n",
      "Averaged stats: loss: 0.4586 (0.4727)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_294_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.473%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:295]  [  0/172]  eta: 0:07:53  lr: 0.000078  loss: 0.5095 (0.5095)  time: 2.7547  data: 1.1849  max mem: 20571\n",
      "Train: [epoch:295]  [ 10/172]  eta: 0:04:32  lr: 0.000078  loss: 0.4900 (0.4941)  time: 1.6815  data: 0.1078  max mem: 20571\n",
      "Train: [epoch:295]  [ 20/172]  eta: 0:04:07  lr: 0.000078  loss: 0.4885 (0.4935)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [ 30/172]  eta: 0:03:49  lr: 0.000078  loss: 0.4903 (0.4945)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [ 40/172]  eta: 0:03:31  lr: 0.000078  loss: 0.4873 (0.4965)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [ 50/172]  eta: 0:03:15  lr: 0.000078  loss: 0.4873 (0.4952)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [ 60/172]  eta: 0:02:58  lr: 0.000078  loss: 0.4945 (0.4967)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [ 70/172]  eta: 0:02:42  lr: 0.000078  loss: 0.4953 (0.4976)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [ 80/172]  eta: 0:02:26  lr: 0.000078  loss: 0.4849 (0.4969)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [ 90/172]  eta: 0:02:10  lr: 0.000078  loss: 0.5042 (0.4981)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [100/172]  eta: 0:01:54  lr: 0.000078  loss: 0.5136 (0.4992)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [110/172]  eta: 0:01:38  lr: 0.000078  loss: 0.5000 (0.4989)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [120/172]  eta: 0:01:22  lr: 0.000078  loss: 0.4914 (0.4987)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [130/172]  eta: 0:01:06  lr: 0.000078  loss: 0.4732 (0.4968)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [140/172]  eta: 0:00:50  lr: 0.000078  loss: 0.4926 (0.4974)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [150/172]  eta: 0:00:34  lr: 0.000078  loss: 0.5040 (0.4972)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [160/172]  eta: 0:00:19  lr: 0.000078  loss: 0.5005 (0.4975)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [170/172]  eta: 0:00:03  lr: 0.000078  loss: 0.5110 (0.4984)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295]  [171/172]  eta: 0:00:01  lr: 0.000078  loss: 0.5110 (0.4983)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:295] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000078  loss: 0.5110 (0.4983)\n",
      "Valid: [epoch:295]  [ 0/14]  eta: 0:00:04  loss: 0.5133 (0.5133)  time: 0.3035  data: 0.2890  max mem: 20571\n",
      "Valid: [epoch:295]  [13/14]  eta: 0:00:00  loss: 0.4585 (0.4730)  time: 0.0388  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:295] Total time: 0:00:00 (0.0438 s / it)\n",
      "Averaged stats: loss: 0.4585 (0.4730)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_295_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.473%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:296]  [  0/172]  eta: 0:07:36  lr: 0.000078  loss: 0.5220 (0.5220)  time: 2.6556  data: 1.0927  max mem: 20571\n",
      "Train: [epoch:296]  [ 10/172]  eta: 0:04:31  lr: 0.000078  loss: 0.5216 (0.5020)  time: 1.6739  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:296]  [ 20/172]  eta: 0:04:07  lr: 0.000078  loss: 0.4891 (0.5023)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [ 30/172]  eta: 0:03:48  lr: 0.000078  loss: 0.4837 (0.4978)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [ 40/172]  eta: 0:03:31  lr: 0.000078  loss: 0.4878 (0.4974)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [ 50/172]  eta: 0:03:15  lr: 0.000078  loss: 0.4929 (0.4965)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [ 60/172]  eta: 0:02:58  lr: 0.000078  loss: 0.4987 (0.4978)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [ 70/172]  eta: 0:02:42  lr: 0.000078  loss: 0.4987 (0.4984)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [ 80/172]  eta: 0:02:26  lr: 0.000078  loss: 0.4993 (0.4989)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [ 90/172]  eta: 0:02:10  lr: 0.000078  loss: 0.4993 (0.4992)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [100/172]  eta: 0:01:54  lr: 0.000078  loss: 0.5014 (0.4991)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [110/172]  eta: 0:01:38  lr: 0.000078  loss: 0.5054 (0.5005)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [120/172]  eta: 0:01:22  lr: 0.000078  loss: 0.5118 (0.5009)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [130/172]  eta: 0:01:06  lr: 0.000078  loss: 0.5006 (0.5012)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [140/172]  eta: 0:00:50  lr: 0.000078  loss: 0.5029 (0.5023)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [150/172]  eta: 0:00:34  lr: 0.000078  loss: 0.5025 (0.5020)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [160/172]  eta: 0:00:19  lr: 0.000078  loss: 0.4930 (0.5013)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296]  [170/172]  eta: 0:00:03  lr: 0.000078  loss: 0.4930 (0.5014)  time: 1.5804  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:296]  [171/172]  eta: 0:00:01  lr: 0.000078  loss: 0.4939 (0.5014)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:296] Total time: 0:04:32 (1.5847 s / it)\n",
      "Averaged stats: lr: 0.000078  loss: 0.4939 (0.5014)\n",
      "Valid: [epoch:296]  [ 0/14]  eta: 0:00:03  loss: 0.4551 (0.4551)  time: 0.2856  data: 0.2688  max mem: 20571\n",
      "Valid: [epoch:296]  [13/14]  eta: 0:00:00  loss: 0.4662 (0.4806)  time: 0.0359  data: 0.0208  max mem: 20571\n",
      "Valid: [epoch:296] Total time: 0:00:00 (0.0407 s / it)\n",
      "Averaged stats: loss: 0.4662 (0.4806)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_296_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.481%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:297]  [  0/172]  eta: 0:07:26  lr: 0.000078  loss: 0.4621 (0.4621)  time: 2.5942  data: 1.0196  max mem: 20571\n",
      "Train: [epoch:297]  [ 10/172]  eta: 0:04:30  lr: 0.000078  loss: 0.5063 (0.5058)  time: 1.6688  data: 0.0928  max mem: 20571\n",
      "Train: [epoch:297]  [ 20/172]  eta: 0:04:06  lr: 0.000078  loss: 0.5036 (0.5112)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [ 30/172]  eta: 0:03:48  lr: 0.000078  loss: 0.5034 (0.5087)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [ 40/172]  eta: 0:03:31  lr: 0.000078  loss: 0.4943 (0.5040)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [ 50/172]  eta: 0:03:15  lr: 0.000078  loss: 0.4970 (0.5049)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [ 60/172]  eta: 0:02:58  lr: 0.000078  loss: 0.4965 (0.5013)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [ 70/172]  eta: 0:02:42  lr: 0.000078  loss: 0.4781 (0.4992)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [ 80/172]  eta: 0:02:26  lr: 0.000078  loss: 0.4922 (0.4989)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [ 90/172]  eta: 0:02:10  lr: 0.000078  loss: 0.4955 (0.4996)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [100/172]  eta: 0:01:54  lr: 0.000078  loss: 0.4834 (0.4986)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [110/172]  eta: 0:01:38  lr: 0.000078  loss: 0.4889 (0.4990)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [120/172]  eta: 0:01:22  lr: 0.000078  loss: 0.4982 (0.4990)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [130/172]  eta: 0:01:06  lr: 0.000078  loss: 0.4948 (0.4994)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [140/172]  eta: 0:00:50  lr: 0.000078  loss: 0.5061 (0.5003)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [150/172]  eta: 0:00:34  lr: 0.000078  loss: 0.4965 (0.4994)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [160/172]  eta: 0:00:19  lr: 0.000078  loss: 0.4917 (0.4995)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [170/172]  eta: 0:00:03  lr: 0.000078  loss: 0.4917 (0.4989)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297]  [171/172]  eta: 0:00:01  lr: 0.000078  loss: 0.4885 (0.4987)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:297] Total time: 0:04:32 (1.5840 s / it)\n",
      "Averaged stats: lr: 0.000078  loss: 0.4885 (0.4987)\n",
      "Valid: [epoch:297]  [ 0/14]  eta: 0:00:04  loss: 0.5421 (0.5421)  time: 0.3218  data: 0.3067  max mem: 20571\n",
      "Valid: [epoch:297]  [13/14]  eta: 0:00:00  loss: 0.4935 (0.5070)  time: 0.0413  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:297] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.4935 (0.5070)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_297_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.507%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:298]  [  0/172]  eta: 0:07:24  lr: 0.000078  loss: 0.5096 (0.5096)  time: 2.5844  data: 1.0183  max mem: 20571\n",
      "Train: [epoch:298]  [ 10/172]  eta: 0:04:30  lr: 0.000078  loss: 0.4957 (0.4992)  time: 1.6681  data: 0.0927  max mem: 20571\n",
      "Train: [epoch:298]  [ 20/172]  eta: 0:04:07  lr: 0.000078  loss: 0.4957 (0.5016)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [ 30/172]  eta: 0:03:48  lr: 0.000078  loss: 0.5004 (0.5002)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [ 40/172]  eta: 0:03:31  lr: 0.000078  loss: 0.4919 (0.4994)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [ 50/172]  eta: 0:03:15  lr: 0.000078  loss: 0.4919 (0.5003)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [ 60/172]  eta: 0:02:58  lr: 0.000078  loss: 0.4943 (0.4994)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [ 70/172]  eta: 0:02:42  lr: 0.000078  loss: 0.5001 (0.5006)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [ 80/172]  eta: 0:02:26  lr: 0.000078  loss: 0.5042 (0.5026)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [ 90/172]  eta: 0:02:10  lr: 0.000078  loss: 0.4993 (0.5021)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [100/172]  eta: 0:01:54  lr: 0.000078  loss: 0.4959 (0.5034)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [110/172]  eta: 0:01:38  lr: 0.000078  loss: 0.4940 (0.5029)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [120/172]  eta: 0:01:22  lr: 0.000078  loss: 0.4801 (0.5021)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [130/172]  eta: 0:01:06  lr: 0.000078  loss: 0.4899 (0.5022)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [140/172]  eta: 0:00:50  lr: 0.000078  loss: 0.5014 (0.5024)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [150/172]  eta: 0:00:34  lr: 0.000078  loss: 0.4994 (0.5020)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [160/172]  eta: 0:00:19  lr: 0.000078  loss: 0.4866 (0.5025)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [170/172]  eta: 0:00:03  lr: 0.000078  loss: 0.4967 (0.5027)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298]  [171/172]  eta: 0:00:01  lr: 0.000078  loss: 0.4986 (0.5033)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:298] Total time: 0:04:33 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000078  loss: 0.4986 (0.5033)\n",
      "Valid: [epoch:298]  [ 0/14]  eta: 0:00:04  loss: 0.5098 (0.5098)  time: 0.3100  data: 0.2948  max mem: 20571\n",
      "Valid: [epoch:298]  [13/14]  eta: 0:00:00  loss: 0.4601 (0.4746)  time: 0.0395  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:298] Total time: 0:00:00 (0.0460 s / it)\n",
      "Averaged stats: loss: 0.4601 (0.4746)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_298_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.475%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:299]  [  0/172]  eta: 0:07:35  lr: 0.000078  loss: 0.5372 (0.5372)  time: 2.6481  data: 1.0507  max mem: 20571\n",
      "Train: [epoch:299]  [ 10/172]  eta: 0:04:31  lr: 0.000078  loss: 0.4769 (0.5008)  time: 1.6753  data: 0.0956  max mem: 20571\n",
      "Train: [epoch:299]  [ 20/172]  eta: 0:04:07  lr: 0.000078  loss: 0.4970 (0.5095)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [ 30/172]  eta: 0:03:49  lr: 0.000078  loss: 0.5130 (0.5111)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [ 40/172]  eta: 0:03:32  lr: 0.000078  loss: 0.5105 (0.5076)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [ 50/172]  eta: 0:03:15  lr: 0.000078  loss: 0.4960 (0.5064)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [ 60/172]  eta: 0:02:59  lr: 0.000078  loss: 0.5014 (0.5055)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [ 70/172]  eta: 0:02:42  lr: 0.000078  loss: 0.5030 (0.5059)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [ 80/172]  eta: 0:02:26  lr: 0.000078  loss: 0.4917 (0.5043)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [ 90/172]  eta: 0:02:10  lr: 0.000078  loss: 0.4944 (0.5056)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [100/172]  eta: 0:01:54  lr: 0.000078  loss: 0.5050 (0.5066)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [110/172]  eta: 0:01:38  lr: 0.000078  loss: 0.5010 (0.5057)  time: 1.5833  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:299]  [120/172]  eta: 0:01:22  lr: 0.000078  loss: 0.4981 (0.5057)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [130/172]  eta: 0:01:06  lr: 0.000078  loss: 0.5052 (0.5063)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [140/172]  eta: 0:00:50  lr: 0.000078  loss: 0.4976 (0.5056)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [150/172]  eta: 0:00:34  lr: 0.000078  loss: 0.4920 (0.5045)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [160/172]  eta: 0:00:19  lr: 0.000078  loss: 0.4890 (0.5043)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [170/172]  eta: 0:00:03  lr: 0.000078  loss: 0.4927 (0.5045)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299]  [171/172]  eta: 0:00:01  lr: 0.000078  loss: 0.4890 (0.5042)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:299] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000078  loss: 0.4890 (0.5042)\n",
      "Valid: [epoch:299]  [ 0/14]  eta: 0:00:04  loss: 0.4545 (0.4545)  time: 0.2904  data: 0.2745  max mem: 20571\n",
      "Valid: [epoch:299]  [13/14]  eta: 0:00:00  loss: 0.4651 (0.4796)  time: 0.0385  data: 0.0235  max mem: 20571\n",
      "Valid: [epoch:299] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.4651 (0.4796)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_299_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.480%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:300]  [  0/172]  eta: 0:07:38  lr: 0.000078  loss: 0.4508 (0.4508)  time: 2.6676  data: 1.0985  max mem: 20571\n",
      "Train: [epoch:300]  [ 10/172]  eta: 0:04:31  lr: 0.000078  loss: 0.5208 (0.5209)  time: 1.6782  data: 0.1000  max mem: 20571\n",
      "Train: [epoch:300]  [ 20/172]  eta: 0:04:08  lr: 0.000078  loss: 0.5025 (0.5114)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [ 30/172]  eta: 0:03:49  lr: 0.000078  loss: 0.4919 (0.5099)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [ 40/172]  eta: 0:03:32  lr: 0.000078  loss: 0.4958 (0.5046)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [ 50/172]  eta: 0:03:15  lr: 0.000078  loss: 0.5005 (0.5063)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [ 60/172]  eta: 0:02:59  lr: 0.000078  loss: 0.5064 (0.5060)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [ 70/172]  eta: 0:02:42  lr: 0.000078  loss: 0.4988 (0.5046)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [ 80/172]  eta: 0:02:26  lr: 0.000078  loss: 0.4882 (0.5040)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [ 90/172]  eta: 0:02:10  lr: 0.000078  loss: 0.4882 (0.5045)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [100/172]  eta: 0:01:54  lr: 0.000078  loss: 0.4957 (0.5047)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [110/172]  eta: 0:01:38  lr: 0.000078  loss: 0.5039 (0.5053)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [120/172]  eta: 0:01:22  lr: 0.000078  loss: 0.5149 (0.5049)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [130/172]  eta: 0:01:06  lr: 0.000078  loss: 0.5020 (0.5050)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [140/172]  eta: 0:00:50  lr: 0.000078  loss: 0.5027 (0.5053)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [150/172]  eta: 0:00:34  lr: 0.000078  loss: 0.4995 (0.5048)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [160/172]  eta: 0:00:19  lr: 0.000078  loss: 0.4922 (0.5039)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [170/172]  eta: 0:00:03  lr: 0.000078  loss: 0.4882 (0.5034)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300]  [171/172]  eta: 0:00:01  lr: 0.000078  loss: 0.4885 (0.5035)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:300] Total time: 0:04:32 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000078  loss: 0.4885 (0.5035)\n",
      "Valid: [epoch:300]  [ 0/14]  eta: 0:00:04  loss: 0.4650 (0.4650)  time: 0.3076  data: 0.2918  max mem: 20571\n",
      "Valid: [epoch:300]  [13/14]  eta: 0:00:00  loss: 0.4650 (0.4794)  time: 0.0369  data: 0.0218  max mem: 20571\n",
      "Valid: [epoch:300] Total time: 0:00:00 (0.0430 s / it)\n",
      "Averaged stats: loss: 0.4650 (0.4794)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_300_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.479%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:301]  [  0/172]  eta: 0:07:28  lr: 0.000078  loss: 0.4975 (0.4975)  time: 2.6091  data: 1.0341  max mem: 20571\n",
      "Train: [epoch:301]  [ 10/172]  eta: 0:04:30  lr: 0.000078  loss: 0.4979 (0.4994)  time: 1.6704  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:301]  [ 20/172]  eta: 0:04:07  lr: 0.000078  loss: 0.4990 (0.5080)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [ 30/172]  eta: 0:03:48  lr: 0.000078  loss: 0.5066 (0.5062)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [ 40/172]  eta: 0:03:31  lr: 0.000078  loss: 0.4893 (0.5036)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [ 50/172]  eta: 0:03:15  lr: 0.000078  loss: 0.4916 (0.5035)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [ 60/172]  eta: 0:02:58  lr: 0.000078  loss: 0.5020 (0.5043)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [ 70/172]  eta: 0:02:42  lr: 0.000078  loss: 0.5055 (0.5038)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [ 80/172]  eta: 0:02:26  lr: 0.000078  loss: 0.5148 (0.5071)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [ 90/172]  eta: 0:02:10  lr: 0.000078  loss: 0.5158 (0.5068)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [100/172]  eta: 0:01:54  lr: 0.000078  loss: 0.4989 (0.5064)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [110/172]  eta: 0:01:38  lr: 0.000078  loss: 0.4974 (0.5060)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [120/172]  eta: 0:01:22  lr: 0.000078  loss: 0.5003 (0.5065)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [130/172]  eta: 0:01:06  lr: 0.000078  loss: 0.4948 (0.5056)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [140/172]  eta: 0:00:50  lr: 0.000078  loss: 0.4956 (0.5061)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [150/172]  eta: 0:00:34  lr: 0.000078  loss: 0.5098 (0.5062)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [160/172]  eta: 0:00:19  lr: 0.000078  loss: 0.4947 (0.5062)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [170/172]  eta: 0:00:03  lr: 0.000078  loss: 0.4983 (0.5062)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301]  [171/172]  eta: 0:00:01  lr: 0.000078  loss: 0.4983 (0.5060)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:301] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000078  loss: 0.4983 (0.5060)\n",
      "Valid: [epoch:301]  [ 0/14]  eta: 0:00:03  loss: 0.4606 (0.4606)  time: 0.2793  data: 0.2643  max mem: 20571\n",
      "Valid: [epoch:301]  [13/14]  eta: 0:00:00  loss: 0.4630 (0.4777)  time: 0.0364  data: 0.0213  max mem: 20571\n",
      "Valid: [epoch:301] Total time: 0:00:00 (0.0414 s / it)\n",
      "Averaged stats: loss: 0.4630 (0.4777)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_301_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.478%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:302]  [  0/172]  eta: 0:07:16  lr: 0.000078  loss: 0.4999 (0.4999)  time: 2.5365  data: 0.9656  max mem: 20571\n",
      "Train: [epoch:302]  [ 10/172]  eta: 0:04:30  lr: 0.000078  loss: 0.4999 (0.5029)  time: 1.6668  data: 0.0879  max mem: 20571\n",
      "Train: [epoch:302]  [ 20/172]  eta: 0:04:07  lr: 0.000078  loss: 0.5068 (0.5101)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [ 30/172]  eta: 0:03:48  lr: 0.000078  loss: 0.5068 (0.5085)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [ 40/172]  eta: 0:03:31  lr: 0.000078  loss: 0.5000 (0.5068)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [ 50/172]  eta: 0:03:15  lr: 0.000078  loss: 0.4993 (0.5058)  time: 1.5827  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:302]  [ 60/172]  eta: 0:02:58  lr: 0.000078  loss: 0.4963 (0.5047)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [ 70/172]  eta: 0:02:42  lr: 0.000078  loss: 0.4877 (0.5025)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [ 80/172]  eta: 0:02:26  lr: 0.000078  loss: 0.4929 (0.5028)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [ 90/172]  eta: 0:02:10  lr: 0.000078  loss: 0.5033 (0.5031)  time: 1.5819  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:302]  [100/172]  eta: 0:01:54  lr: 0.000078  loss: 0.5086 (0.5040)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [110/172]  eta: 0:01:38  lr: 0.000078  loss: 0.5181 (0.5045)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [120/172]  eta: 0:01:22  lr: 0.000078  loss: 0.5078 (0.5052)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [130/172]  eta: 0:01:06  lr: 0.000078  loss: 0.5063 (0.5051)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [140/172]  eta: 0:00:50  lr: 0.000078  loss: 0.4998 (0.5054)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [150/172]  eta: 0:00:34  lr: 0.000078  loss: 0.5074 (0.5061)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [160/172]  eta: 0:00:19  lr: 0.000078  loss: 0.5201 (0.5068)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [170/172]  eta: 0:00:03  lr: 0.000078  loss: 0.5181 (0.5068)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302]  [171/172]  eta: 0:00:01  lr: 0.000078  loss: 0.5110 (0.5067)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:302] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000078  loss: 0.5110 (0.5067)\n",
      "Valid: [epoch:302]  [ 0/14]  eta: 0:00:04  loss: 0.4490 (0.4490)  time: 0.3248  data: 0.3095  max mem: 20571\n",
      "Valid: [epoch:302]  [13/14]  eta: 0:00:00  loss: 0.4602 (0.4749)  time: 0.0383  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:302] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.4602 (0.4749)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_302_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.475%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:303]  [  0/172]  eta: 0:07:58  lr: 0.000078  loss: 0.4495 (0.4495)  time: 2.7796  data: 1.1977  max mem: 20571\n",
      "Train: [epoch:303]  [ 10/172]  eta: 0:04:33  lr: 0.000078  loss: 0.5211 (0.5054)  time: 1.6885  data: 0.1090  max mem: 20571\n",
      "Train: [epoch:303]  [ 20/172]  eta: 0:04:08  lr: 0.000078  loss: 0.5172 (0.5124)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [ 30/172]  eta: 0:03:49  lr: 0.000078  loss: 0.5125 (0.5122)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [ 40/172]  eta: 0:03:32  lr: 0.000078  loss: 0.5185 (0.5138)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [ 50/172]  eta: 0:03:15  lr: 0.000078  loss: 0.5185 (0.5130)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [ 60/172]  eta: 0:02:59  lr: 0.000078  loss: 0.5021 (0.5126)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [ 70/172]  eta: 0:02:43  lr: 0.000078  loss: 0.5015 (0.5106)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [ 80/172]  eta: 0:02:26  lr: 0.000078  loss: 0.5104 (0.5125)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [ 90/172]  eta: 0:02:10  lr: 0.000078  loss: 0.5137 (0.5102)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [100/172]  eta: 0:01:54  lr: 0.000078  loss: 0.5004 (0.5112)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [110/172]  eta: 0:01:38  lr: 0.000078  loss: 0.5004 (0.5108)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [120/172]  eta: 0:01:22  lr: 0.000078  loss: 0.5204 (0.5125)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [130/172]  eta: 0:01:06  lr: 0.000078  loss: 0.5204 (0.5116)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [140/172]  eta: 0:00:50  lr: 0.000078  loss: 0.5045 (0.5110)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [150/172]  eta: 0:00:34  lr: 0.000078  loss: 0.5005 (0.5111)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [160/172]  eta: 0:00:19  lr: 0.000078  loss: 0.5143 (0.5117)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [170/172]  eta: 0:00:03  lr: 0.000078  loss: 0.5143 (0.5116)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303]  [171/172]  eta: 0:00:01  lr: 0.000078  loss: 0.5143 (0.5116)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:303] Total time: 0:04:33 (1.5896 s / it)\n",
      "Averaged stats: lr: 0.000078  loss: 0.5143 (0.5116)\n",
      "Valid: [epoch:303]  [ 0/14]  eta: 0:00:04  loss: 0.4613 (0.4613)  time: 0.2941  data: 0.2789  max mem: 20571\n",
      "Valid: [epoch:303]  [13/14]  eta: 0:00:00  loss: 0.4613 (0.4760)  time: 0.0421  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:303] Total time: 0:00:00 (0.0479 s / it)\n",
      "Averaged stats: loss: 0.4613 (0.4760)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_303_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.476%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:304]  [  0/172]  eta: 0:07:47  lr: 0.000077  loss: 0.4641 (0.4641)  time: 2.7160  data: 1.1498  max mem: 20571\n",
      "Train: [epoch:304]  [ 10/172]  eta: 0:04:32  lr: 0.000077  loss: 0.4965 (0.5026)  time: 1.6828  data: 0.1047  max mem: 20571\n",
      "Train: [epoch:304]  [ 20/172]  eta: 0:04:08  lr: 0.000077  loss: 0.5029 (0.5088)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [ 30/172]  eta: 0:03:49  lr: 0.000077  loss: 0.5133 (0.5121)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [ 40/172]  eta: 0:03:32  lr: 0.000077  loss: 0.5001 (0.5092)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [ 50/172]  eta: 0:03:15  lr: 0.000077  loss: 0.5063 (0.5114)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [ 60/172]  eta: 0:02:59  lr: 0.000077  loss: 0.5079 (0.5116)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [ 70/172]  eta: 0:02:42  lr: 0.000077  loss: 0.5054 (0.5129)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [ 80/172]  eta: 0:02:26  lr: 0.000077  loss: 0.5066 (0.5116)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [ 90/172]  eta: 0:02:10  lr: 0.000077  loss: 0.5066 (0.5114)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [100/172]  eta: 0:01:54  lr: 0.000077  loss: 0.5024 (0.5107)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [110/172]  eta: 0:01:38  lr: 0.000077  loss: 0.5000 (0.5097)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [120/172]  eta: 0:01:22  lr: 0.000077  loss: 0.5000 (0.5101)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [130/172]  eta: 0:01:06  lr: 0.000077  loss: 0.4873 (0.5085)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [140/172]  eta: 0:00:50  lr: 0.000077  loss: 0.4871 (0.5082)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [150/172]  eta: 0:00:34  lr: 0.000077  loss: 0.5066 (0.5085)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [160/172]  eta: 0:00:19  lr: 0.000077  loss: 0.5028 (0.5082)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [170/172]  eta: 0:00:03  lr: 0.000077  loss: 0.5023 (0.5081)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304]  [171/172]  eta: 0:00:01  lr: 0.000077  loss: 0.5050 (0.5086)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:304] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000077  loss: 0.5050 (0.5086)\n",
      "Valid: [epoch:304]  [ 0/14]  eta: 0:00:04  loss: 0.5227 (0.5227)  time: 0.3210  data: 0.3049  max mem: 20571\n",
      "Valid: [epoch:304]  [13/14]  eta: 0:00:00  loss: 0.4621 (0.4770)  time: 0.0376  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:304] Total time: 0:00:00 (0.0425 s / it)\n",
      "Averaged stats: loss: 0.4621 (0.4770)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_304_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.477%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:305]  [  0/172]  eta: 0:07:28  lr: 0.000077  loss: 0.4732 (0.4732)  time: 2.6083  data: 1.0270  max mem: 20571\n",
      "Train: [epoch:305]  [ 10/172]  eta: 0:04:31  lr: 0.000077  loss: 0.5084 (0.5145)  time: 1.6735  data: 0.0935  max mem: 20571\n",
      "Train: [epoch:305]  [ 20/172]  eta: 0:04:07  lr: 0.000077  loss: 0.5084 (0.5130)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [ 30/172]  eta: 0:03:49  lr: 0.000077  loss: 0.5004 (0.5089)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [ 40/172]  eta: 0:03:31  lr: 0.000077  loss: 0.4972 (0.5089)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [ 50/172]  eta: 0:03:15  lr: 0.000077  loss: 0.5076 (0.5089)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [ 60/172]  eta: 0:02:58  lr: 0.000077  loss: 0.5187 (0.5116)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [ 70/172]  eta: 0:02:42  lr: 0.000077  loss: 0.5210 (0.5143)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [ 80/172]  eta: 0:02:26  lr: 0.000077  loss: 0.5210 (0.5139)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [ 90/172]  eta: 0:02:10  lr: 0.000077  loss: 0.5131 (0.5145)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [100/172]  eta: 0:01:54  lr: 0.000077  loss: 0.5164 (0.5147)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [110/172]  eta: 0:01:38  lr: 0.000077  loss: 0.5164 (0.5146)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [120/172]  eta: 0:01:22  lr: 0.000077  loss: 0.5065 (0.5136)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [130/172]  eta: 0:01:06  lr: 0.000077  loss: 0.5022 (0.5135)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [140/172]  eta: 0:00:50  lr: 0.000077  loss: 0.5077 (0.5130)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [150/172]  eta: 0:00:34  lr: 0.000077  loss: 0.5081 (0.5128)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [160/172]  eta: 0:00:19  lr: 0.000077  loss: 0.5150 (0.5130)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [170/172]  eta: 0:00:03  lr: 0.000077  loss: 0.5155 (0.5124)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305]  [171/172]  eta: 0:00:01  lr: 0.000077  loss: 0.5155 (0.5122)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:305] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000077  loss: 0.5155 (0.5122)\n",
      "Valid: [epoch:305]  [ 0/14]  eta: 0:00:04  loss: 0.5293 (0.5293)  time: 0.2888  data: 0.2737  max mem: 20571\n",
      "Valid: [epoch:305]  [13/14]  eta: 0:00:00  loss: 0.4717 (0.4867)  time: 0.0360  data: 0.0213  max mem: 20571\n",
      "Valid: [epoch:305] Total time: 0:00:00 (0.0415 s / it)\n",
      "Averaged stats: loss: 0.4717 (0.4867)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_305_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.487%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:306]  [  0/172]  eta: 0:07:40  lr: 0.000077  loss: 0.4822 (0.4822)  time: 2.6796  data: 1.1081  max mem: 20571\n",
      "Train: [epoch:306]  [ 10/172]  eta: 0:04:32  lr: 0.000077  loss: 0.4898 (0.5047)  time: 1.6800  data: 0.1009  max mem: 20571\n",
      "Train: [epoch:306]  [ 20/172]  eta: 0:04:08  lr: 0.000077  loss: 0.5050 (0.5118)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:306]  [ 30/172]  eta: 0:03:49  lr: 0.000077  loss: 0.5059 (0.5125)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:306]  [ 40/172]  eta: 0:03:32  lr: 0.000077  loss: 0.5025 (0.5109)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:306]  [ 50/172]  eta: 0:03:15  lr: 0.000077  loss: 0.5087 (0.5135)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [ 60/172]  eta: 0:02:59  lr: 0.000077  loss: 0.5190 (0.5128)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [ 70/172]  eta: 0:02:42  lr: 0.000077  loss: 0.5125 (0.5124)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [ 80/172]  eta: 0:02:26  lr: 0.000077  loss: 0.5021 (0.5106)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:306]  [ 90/172]  eta: 0:02:10  lr: 0.000077  loss: 0.4970 (0.5107)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:306]  [100/172]  eta: 0:01:54  lr: 0.000077  loss: 0.4955 (0.5093)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [110/172]  eta: 0:01:38  lr: 0.000077  loss: 0.4911 (0.5094)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [120/172]  eta: 0:01:22  lr: 0.000077  loss: 0.4965 (0.5095)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [130/172]  eta: 0:01:06  lr: 0.000077  loss: 0.5096 (0.5098)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [140/172]  eta: 0:00:50  lr: 0.000077  loss: 0.5255 (0.5103)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [150/172]  eta: 0:00:34  lr: 0.000077  loss: 0.5098 (0.5105)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:306]  [160/172]  eta: 0:00:19  lr: 0.000077  loss: 0.5097 (0.5113)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [170/172]  eta: 0:00:03  lr: 0.000077  loss: 0.5134 (0.5127)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306]  [171/172]  eta: 0:00:01  lr: 0.000077  loss: 0.5134 (0.5126)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:306] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000077  loss: 0.5134 (0.5126)\n",
      "Valid: [epoch:306]  [ 0/14]  eta: 0:00:06  loss: 0.4333 (0.4333)  time: 0.4616  data: 0.4463  max mem: 20571\n",
      "Valid: [epoch:306]  [13/14]  eta: 0:00:00  loss: 0.4746 (0.4890)  time: 0.0489  data: 0.0338  max mem: 20571\n",
      "Valid: [epoch:306] Total time: 0:00:00 (0.0574 s / it)\n",
      "Averaged stats: loss: 0.4746 (0.4890)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_306_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.489%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:307]  [  0/172]  eta: 0:08:00  lr: 0.000077  loss: 0.5232 (0.5232)  time: 2.7913  data: 1.2175  max mem: 20571\n",
      "Train: [epoch:307]  [ 10/172]  eta: 0:04:33  lr: 0.000077  loss: 0.5228 (0.5179)  time: 1.6865  data: 0.1108  max mem: 20571\n",
      "Train: [epoch:307]  [ 20/172]  eta: 0:04:08  lr: 0.000077  loss: 0.5156 (0.5200)  time: 1.5783  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:307]  [ 30/172]  eta: 0:03:49  lr: 0.000077  loss: 0.5086 (0.5175)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [ 40/172]  eta: 0:03:32  lr: 0.000077  loss: 0.5083 (0.5135)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [ 50/172]  eta: 0:03:15  lr: 0.000077  loss: 0.5068 (0.5132)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [ 60/172]  eta: 0:02:59  lr: 0.000077  loss: 0.5068 (0.5135)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [ 70/172]  eta: 0:02:42  lr: 0.000077  loss: 0.5175 (0.5176)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [ 80/172]  eta: 0:02:26  lr: 0.000077  loss: 0.5362 (0.5210)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [ 90/172]  eta: 0:02:10  lr: 0.000077  loss: 0.5186 (0.5200)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [100/172]  eta: 0:01:54  lr: 0.000077  loss: 0.5114 (0.5193)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [110/172]  eta: 0:01:38  lr: 0.000077  loss: 0.5111 (0.5183)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [120/172]  eta: 0:01:22  lr: 0.000077  loss: 0.4933 (0.5161)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [130/172]  eta: 0:01:06  lr: 0.000077  loss: 0.4956 (0.5152)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [140/172]  eta: 0:00:50  lr: 0.000077  loss: 0.5055 (0.5146)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [150/172]  eta: 0:00:34  lr: 0.000077  loss: 0.5087 (0.5144)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [160/172]  eta: 0:00:19  lr: 0.000077  loss: 0.5087 (0.5139)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307]  [170/172]  eta: 0:00:03  lr: 0.000077  loss: 0.5038 (0.5133)  time: 1.5814  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:307]  [171/172]  eta: 0:00:01  lr: 0.000077  loss: 0.5038 (0.5134)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:307] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000077  loss: 0.5038 (0.5134)\n",
      "Valid: [epoch:307]  [ 0/14]  eta: 0:00:04  loss: 0.5494 (0.5494)  time: 0.2876  data: 0.2710  max mem: 20571\n",
      "Valid: [epoch:307]  [13/14]  eta: 0:00:00  loss: 0.4899 (0.5050)  time: 0.0394  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:307] Total time: 0:00:00 (0.0480 s / it)\n",
      "Averaged stats: loss: 0.4899 (0.5050)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_307_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.505%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:308]  [  0/172]  eta: 0:07:42  lr: 0.000077  loss: 0.5057 (0.5057)  time: 2.6868  data: 1.1082  max mem: 20571\n",
      "Train: [epoch:308]  [ 10/172]  eta: 0:04:31  lr: 0.000077  loss: 0.5137 (0.5111)  time: 1.6758  data: 0.1008  max mem: 20571\n",
      "Train: [epoch:308]  [ 20/172]  eta: 0:04:07  lr: 0.000077  loss: 0.5086 (0.5082)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [ 30/172]  eta: 0:03:49  lr: 0.000077  loss: 0.5086 (0.5086)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:308]  [ 40/172]  eta: 0:03:31  lr: 0.000077  loss: 0.5135 (0.5099)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [ 50/172]  eta: 0:03:15  lr: 0.000077  loss: 0.5162 (0.5099)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [ 60/172]  eta: 0:02:58  lr: 0.000077  loss: 0.5135 (0.5091)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [ 70/172]  eta: 0:02:42  lr: 0.000077  loss: 0.5088 (0.5115)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [ 80/172]  eta: 0:02:26  lr: 0.000077  loss: 0.5193 (0.5112)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [ 90/172]  eta: 0:02:10  lr: 0.000077  loss: 0.5039 (0.5111)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [100/172]  eta: 0:01:54  lr: 0.000077  loss: 0.5039 (0.5118)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [110/172]  eta: 0:01:38  lr: 0.000077  loss: 0.5113 (0.5116)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [120/172]  eta: 0:01:22  lr: 0.000077  loss: 0.5096 (0.5121)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [130/172]  eta: 0:01:06  lr: 0.000077  loss: 0.5036 (0.5117)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [140/172]  eta: 0:00:50  lr: 0.000077  loss: 0.5067 (0.5118)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [150/172]  eta: 0:00:34  lr: 0.000077  loss: 0.5185 (0.5129)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [160/172]  eta: 0:00:19  lr: 0.000077  loss: 0.5187 (0.5135)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [170/172]  eta: 0:00:03  lr: 0.000077  loss: 0.5100 (0.5131)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308]  [171/172]  eta: 0:00:01  lr: 0.000077  loss: 0.5119 (0.5133)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:308] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000077  loss: 0.5119 (0.5133)\n",
      "Valid: [epoch:308]  [ 0/14]  eta: 0:00:04  loss: 0.5495 (0.5495)  time: 0.3132  data: 0.2976  max mem: 20571\n",
      "Valid: [epoch:308]  [13/14]  eta: 0:00:00  loss: 0.4921 (0.5069)  time: 0.0378  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:308] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.4921 (0.5069)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_308_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.507%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:309]  [  0/172]  eta: 0:07:14  lr: 0.000077  loss: 0.5724 (0.5724)  time: 2.5254  data: 0.9492  max mem: 20571\n",
      "Train: [epoch:309]  [ 10/172]  eta: 0:04:29  lr: 0.000077  loss: 0.5060 (0.5133)  time: 1.6617  data: 0.0864  max mem: 20571\n",
      "Train: [epoch:309]  [ 20/172]  eta: 0:04:06  lr: 0.000077  loss: 0.5059 (0.5141)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [ 30/172]  eta: 0:03:48  lr: 0.000077  loss: 0.5071 (0.5154)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [ 40/172]  eta: 0:03:31  lr: 0.000077  loss: 0.5071 (0.5137)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [ 50/172]  eta: 0:03:14  lr: 0.000077  loss: 0.5105 (0.5141)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [ 60/172]  eta: 0:02:58  lr: 0.000077  loss: 0.5110 (0.5147)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [ 70/172]  eta: 0:02:42  lr: 0.000077  loss: 0.5264 (0.5172)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [ 80/172]  eta: 0:02:26  lr: 0.000077  loss: 0.5272 (0.5172)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [ 90/172]  eta: 0:02:10  lr: 0.000077  loss: 0.5054 (0.5160)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [100/172]  eta: 0:01:54  lr: 0.000077  loss: 0.5028 (0.5150)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [110/172]  eta: 0:01:38  lr: 0.000077  loss: 0.5028 (0.5148)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [120/172]  eta: 0:01:22  lr: 0.000077  loss: 0.5103 (0.5152)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [130/172]  eta: 0:01:06  lr: 0.000077  loss: 0.5092 (0.5143)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [140/172]  eta: 0:00:50  lr: 0.000077  loss: 0.5092 (0.5145)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [150/172]  eta: 0:00:34  lr: 0.000077  loss: 0.5084 (0.5142)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [160/172]  eta: 0:00:19  lr: 0.000077  loss: 0.5057 (0.5141)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [170/172]  eta: 0:00:03  lr: 0.000077  loss: 0.5110 (0.5145)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309]  [171/172]  eta: 0:00:01  lr: 0.000077  loss: 0.5111 (0.5149)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:309] Total time: 0:04:32 (1.5848 s / it)\n",
      "Averaged stats: lr: 0.000077  loss: 0.5111 (0.5149)\n",
      "Valid: [epoch:309]  [ 0/14]  eta: 0:00:03  loss: 0.4811 (0.4811)  time: 0.2814  data: 0.2663  max mem: 20571\n",
      "Valid: [epoch:309]  [13/14]  eta: 0:00:00  loss: 0.4921 (0.5065)  time: 0.0371  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:309] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.4921 (0.5065)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_309_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.506%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:310]  [  0/172]  eta: 0:07:41  lr: 0.000077  loss: 0.5420 (0.5420)  time: 2.6813  data: 1.1128  max mem: 20571\n",
      "Train: [epoch:310]  [ 10/172]  eta: 0:04:31  lr: 0.000077  loss: 0.5022 (0.5008)  time: 1.6782  data: 0.1013  max mem: 20571\n",
      "Train: [epoch:310]  [ 20/172]  eta: 0:04:07  lr: 0.000077  loss: 0.5096 (0.5126)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:310]  [ 30/172]  eta: 0:03:49  lr: 0.000077  loss: 0.5182 (0.5184)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:310]  [ 40/172]  eta: 0:03:31  lr: 0.000077  loss: 0.5077 (0.5178)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [ 50/172]  eta: 0:03:15  lr: 0.000077  loss: 0.5159 (0.5191)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [ 60/172]  eta: 0:02:58  lr: 0.000077  loss: 0.5159 (0.5176)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [ 70/172]  eta: 0:02:42  lr: 0.000077  loss: 0.5050 (0.5176)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [ 80/172]  eta: 0:02:26  lr: 0.000077  loss: 0.5171 (0.5173)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [ 90/172]  eta: 0:02:10  lr: 0.000077  loss: 0.5169 (0.5176)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [100/172]  eta: 0:01:54  lr: 0.000077  loss: 0.5159 (0.5188)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [110/172]  eta: 0:01:38  lr: 0.000077  loss: 0.5198 (0.5200)  time: 1.5812  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:310]  [120/172]  eta: 0:01:22  lr: 0.000077  loss: 0.5162 (0.5197)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:310]  [130/172]  eta: 0:01:06  lr: 0.000077  loss: 0.5090 (0.5188)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:310]  [140/172]  eta: 0:00:50  lr: 0.000077  loss: 0.5090 (0.5181)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:310]  [150/172]  eta: 0:00:34  lr: 0.000077  loss: 0.5078 (0.5173)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [160/172]  eta: 0:00:19  lr: 0.000077  loss: 0.5076 (0.5175)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [170/172]  eta: 0:00:03  lr: 0.000077  loss: 0.5091 (0.5175)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310]  [171/172]  eta: 0:00:01  lr: 0.000077  loss: 0.5013 (0.5173)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:310] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000077  loss: 0.5013 (0.5173)\n",
      "Valid: [epoch:310]  [ 0/14]  eta: 0:00:07  loss: 0.5340 (0.5340)  time: 0.5594  data: 0.5408  max mem: 20571\n",
      "Valid: [epoch:310]  [13/14]  eta: 0:00:00  loss: 0.4780 (0.4930)  time: 0.0545  data: 0.0392  max mem: 20571\n",
      "Valid: [epoch:310] Total time: 0:00:00 (0.0593 s / it)\n",
      "Averaged stats: loss: 0.4780 (0.4930)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_310_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.493%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:311]  [  0/172]  eta: 0:07:20  lr: 0.000077  loss: 0.4600 (0.4600)  time: 2.5605  data: 0.9873  max mem: 20571\n",
      "Train: [epoch:311]  [ 10/172]  eta: 0:04:29  lr: 0.000077  loss: 0.4921 (0.4995)  time: 1.6659  data: 0.0899  max mem: 20571\n",
      "Train: [epoch:311]  [ 20/172]  eta: 0:04:06  lr: 0.000077  loss: 0.5024 (0.5163)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [ 30/172]  eta: 0:03:48  lr: 0.000077  loss: 0.5232 (0.5173)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [ 40/172]  eta: 0:03:31  lr: 0.000077  loss: 0.5122 (0.5133)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [ 50/172]  eta: 0:03:14  lr: 0.000077  loss: 0.5074 (0.5139)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [ 60/172]  eta: 0:02:58  lr: 0.000077  loss: 0.5150 (0.5162)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [ 70/172]  eta: 0:02:42  lr: 0.000077  loss: 0.5185 (0.5160)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [ 80/172]  eta: 0:02:26  lr: 0.000077  loss: 0.5185 (0.5160)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [ 90/172]  eta: 0:02:10  lr: 0.000077  loss: 0.5041 (0.5152)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [100/172]  eta: 0:01:54  lr: 0.000077  loss: 0.5041 (0.5160)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [110/172]  eta: 0:01:38  lr: 0.000077  loss: 0.5176 (0.5152)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [120/172]  eta: 0:01:22  lr: 0.000077  loss: 0.5106 (0.5154)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [130/172]  eta: 0:01:06  lr: 0.000077  loss: 0.5106 (0.5155)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [140/172]  eta: 0:00:50  lr: 0.000077  loss: 0.4988 (0.5145)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [150/172]  eta: 0:00:34  lr: 0.000077  loss: 0.4999 (0.5142)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [160/172]  eta: 0:00:19  lr: 0.000077  loss: 0.5153 (0.5147)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [170/172]  eta: 0:00:03  lr: 0.000077  loss: 0.5148 (0.5148)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311]  [171/172]  eta: 0:00:01  lr: 0.000077  loss: 0.5148 (0.5152)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:311] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000077  loss: 0.5148 (0.5152)\n",
      "Valid: [epoch:311]  [ 0/14]  eta: 0:00:05  loss: 0.5361 (0.5361)  time: 0.3651  data: 0.3467  max mem: 20571\n",
      "Valid: [epoch:311]  [13/14]  eta: 0:00:00  loss: 0.4795 (0.4949)  time: 0.0414  data: 0.0261  max mem: 20571\n",
      "Valid: [epoch:311] Total time: 0:00:00 (0.0492 s / it)\n",
      "Averaged stats: loss: 0.4795 (0.4949)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_311_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.495%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:312]  [  0/172]  eta: 0:08:18  lr: 0.000077  loss: 0.5178 (0.5178)  time: 2.9003  data: 1.3321  max mem: 20571\n",
      "Train: [epoch:312]  [ 10/172]  eta: 0:04:35  lr: 0.000077  loss: 0.5178 (0.5214)  time: 1.6990  data: 0.1212  max mem: 20571\n",
      "Train: [epoch:312]  [ 20/172]  eta: 0:04:09  lr: 0.000077  loss: 0.5344 (0.5345)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [ 30/172]  eta: 0:03:50  lr: 0.000077  loss: 0.5414 (0.5308)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [ 40/172]  eta: 0:03:33  lr: 0.000077  loss: 0.5111 (0.5286)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [ 50/172]  eta: 0:03:16  lr: 0.000077  loss: 0.5111 (0.5257)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:312]  [ 60/172]  eta: 0:02:59  lr: 0.000077  loss: 0.5049 (0.5225)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:312]  [ 70/172]  eta: 0:02:43  lr: 0.000077  loss: 0.5130 (0.5240)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [ 80/172]  eta: 0:02:27  lr: 0.000077  loss: 0.5183 (0.5233)  time: 1.5819  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:312]  [ 90/172]  eta: 0:02:10  lr: 0.000077  loss: 0.5181 (0.5232)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:312]  [100/172]  eta: 0:01:54  lr: 0.000077  loss: 0.5110 (0.5219)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [110/172]  eta: 0:01:38  lr: 0.000077  loss: 0.5151 (0.5213)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [120/172]  eta: 0:01:22  lr: 0.000077  loss: 0.5101 (0.5204)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [130/172]  eta: 0:01:06  lr: 0.000077  loss: 0.4975 (0.5194)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:312]  [140/172]  eta: 0:00:50  lr: 0.000077  loss: 0.5069 (0.5194)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:312]  [150/172]  eta: 0:00:34  lr: 0.000077  loss: 0.5195 (0.5187)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [160/172]  eta: 0:00:19  lr: 0.000077  loss: 0.5080 (0.5186)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [170/172]  eta: 0:00:03  lr: 0.000077  loss: 0.5144 (0.5187)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312]  [171/172]  eta: 0:00:01  lr: 0.000077  loss: 0.5144 (0.5187)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:312] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000077  loss: 0.5144 (0.5187)\n",
      "Valid: [epoch:312]  [ 0/14]  eta: 0:00:04  loss: 0.4714 (0.4714)  time: 0.3123  data: 0.2948  max mem: 20571\n",
      "Valid: [epoch:312]  [13/14]  eta: 0:00:00  loss: 0.4714 (0.4872)  time: 0.0388  data: 0.0235  max mem: 20571\n",
      "Valid: [epoch:312] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.4714 (0.4872)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_312_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.487%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:313]  [  0/172]  eta: 0:07:21  lr: 0.000076  loss: 0.5608 (0.5608)  time: 2.5651  data: 0.9851  max mem: 20571\n",
      "Train: [epoch:313]  [ 10/172]  eta: 0:04:30  lr: 0.000076  loss: 0.5379 (0.5258)  time: 1.6675  data: 0.0897  max mem: 20571\n",
      "Train: [epoch:313]  [ 20/172]  eta: 0:04:07  lr: 0.000076  loss: 0.5191 (0.5256)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:313]  [ 30/172]  eta: 0:03:48  lr: 0.000076  loss: 0.5167 (0.5246)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [ 40/172]  eta: 0:03:31  lr: 0.000076  loss: 0.5109 (0.5212)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [ 50/172]  eta: 0:03:14  lr: 0.000076  loss: 0.5118 (0.5204)  time: 1.5793  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:313]  [ 60/172]  eta: 0:02:58  lr: 0.000076  loss: 0.5179 (0.5203)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [ 70/172]  eta: 0:02:42  lr: 0.000076  loss: 0.5218 (0.5198)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [ 80/172]  eta: 0:02:26  lr: 0.000076  loss: 0.5216 (0.5194)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [ 90/172]  eta: 0:02:10  lr: 0.000076  loss: 0.5140 (0.5195)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [100/172]  eta: 0:01:54  lr: 0.000076  loss: 0.5114 (0.5184)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [110/172]  eta: 0:01:38  lr: 0.000076  loss: 0.5106 (0.5184)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [120/172]  eta: 0:01:22  lr: 0.000076  loss: 0.5083 (0.5189)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [130/172]  eta: 0:01:06  lr: 0.000076  loss: 0.5204 (0.5196)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [140/172]  eta: 0:00:50  lr: 0.000076  loss: 0.5040 (0.5187)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [150/172]  eta: 0:00:34  lr: 0.000076  loss: 0.5040 (0.5179)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [160/172]  eta: 0:00:19  lr: 0.000076  loss: 0.5109 (0.5196)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [170/172]  eta: 0:00:03  lr: 0.000076  loss: 0.5222 (0.5202)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313]  [171/172]  eta: 0:00:01  lr: 0.000076  loss: 0.5222 (0.5202)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:313] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000076  loss: 0.5222 (0.5202)\n",
      "Valid: [epoch:313]  [ 0/14]  eta: 0:00:04  loss: 0.4765 (0.4765)  time: 0.3062  data: 0.2909  max mem: 20571\n",
      "Valid: [epoch:313]  [13/14]  eta: 0:00:00  loss: 0.4765 (0.4925)  time: 0.0390  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:313] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.4765 (0.4925)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_313_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.492%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:314]  [  0/172]  eta: 0:07:42  lr: 0.000076  loss: 0.5094 (0.5094)  time: 2.6892  data: 1.1220  max mem: 20571\n",
      "Train: [epoch:314]  [ 10/172]  eta: 0:04:32  lr: 0.000076  loss: 0.5094 (0.5122)  time: 1.6802  data: 0.1021  max mem: 20571\n",
      "Train: [epoch:314]  [ 20/172]  eta: 0:04:08  lr: 0.000076  loss: 0.5171 (0.5238)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [ 30/172]  eta: 0:03:49  lr: 0.000076  loss: 0.5283 (0.5246)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [ 40/172]  eta: 0:03:32  lr: 0.000076  loss: 0.5248 (0.5256)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [ 50/172]  eta: 0:03:15  lr: 0.000076  loss: 0.5250 (0.5259)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [ 60/172]  eta: 0:02:59  lr: 0.000076  loss: 0.5143 (0.5247)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [ 70/172]  eta: 0:02:42  lr: 0.000076  loss: 0.5089 (0.5237)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [ 80/172]  eta: 0:02:26  lr: 0.000076  loss: 0.5151 (0.5238)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [ 90/172]  eta: 0:02:10  lr: 0.000076  loss: 0.5232 (0.5238)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [100/172]  eta: 0:01:54  lr: 0.000076  loss: 0.5268 (0.5236)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [110/172]  eta: 0:01:38  lr: 0.000076  loss: 0.5221 (0.5232)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [120/172]  eta: 0:01:22  lr: 0.000076  loss: 0.5177 (0.5241)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [130/172]  eta: 0:01:06  lr: 0.000076  loss: 0.5191 (0.5235)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [140/172]  eta: 0:00:50  lr: 0.000076  loss: 0.5191 (0.5232)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [150/172]  eta: 0:00:34  lr: 0.000076  loss: 0.5121 (0.5228)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [160/172]  eta: 0:00:19  lr: 0.000076  loss: 0.5156 (0.5227)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [170/172]  eta: 0:00:03  lr: 0.000076  loss: 0.5092 (0.5223)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314]  [171/172]  eta: 0:00:01  lr: 0.000076  loss: 0.5156 (0.5224)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:314] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000076  loss: 0.5156 (0.5224)\n",
      "Valid: [epoch:314]  [ 0/14]  eta: 0:00:04  loss: 0.4416 (0.4416)  time: 0.3087  data: 0.2938  max mem: 20571\n",
      "Valid: [epoch:314]  [13/14]  eta: 0:00:00  loss: 0.4838 (0.4991)  time: 0.0390  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:314] Total time: 0:00:00 (0.0483 s / it)\n",
      "Averaged stats: loss: 0.4838 (0.4991)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_314_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.499%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:315]  [  0/172]  eta: 0:07:54  lr: 0.000076  loss: 0.5203 (0.5203)  time: 2.7581  data: 1.1794  max mem: 20571\n",
      "Train: [epoch:315]  [ 10/172]  eta: 0:04:32  lr: 0.000076  loss: 0.5203 (0.5304)  time: 1.6822  data: 0.1073  max mem: 20571\n",
      "Train: [epoch:315]  [ 20/172]  eta: 0:04:08  lr: 0.000076  loss: 0.5173 (0.5293)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [ 30/172]  eta: 0:03:49  lr: 0.000076  loss: 0.5087 (0.5253)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [ 40/172]  eta: 0:03:32  lr: 0.000076  loss: 0.5125 (0.5244)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [ 50/172]  eta: 0:03:15  lr: 0.000076  loss: 0.5051 (0.5201)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [ 60/172]  eta: 0:02:58  lr: 0.000076  loss: 0.5008 (0.5204)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [ 70/172]  eta: 0:02:42  lr: 0.000076  loss: 0.5145 (0.5179)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [ 80/172]  eta: 0:02:26  lr: 0.000076  loss: 0.5179 (0.5194)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [ 90/172]  eta: 0:02:10  lr: 0.000076  loss: 0.5172 (0.5184)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [100/172]  eta: 0:01:54  lr: 0.000076  loss: 0.5131 (0.5191)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [110/172]  eta: 0:01:38  lr: 0.000076  loss: 0.5128 (0.5180)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [120/172]  eta: 0:01:22  lr: 0.000076  loss: 0.5155 (0.5195)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [130/172]  eta: 0:01:06  lr: 0.000076  loss: 0.5183 (0.5183)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [140/172]  eta: 0:00:50  lr: 0.000076  loss: 0.5093 (0.5193)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [150/172]  eta: 0:00:34  lr: 0.000076  loss: 0.5177 (0.5196)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [160/172]  eta: 0:00:19  lr: 0.000076  loss: 0.5072 (0.5190)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [170/172]  eta: 0:00:03  lr: 0.000076  loss: 0.5072 (0.5189)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315]  [171/172]  eta: 0:00:01  lr: 0.000076  loss: 0.5107 (0.5193)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:315] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000076  loss: 0.5107 (0.5193)\n",
      "Valid: [epoch:315]  [ 0/14]  eta: 0:00:07  loss: 0.4678 (0.4678)  time: 0.5451  data: 0.5285  max mem: 20571\n",
      "Valid: [epoch:315]  [13/14]  eta: 0:00:00  loss: 0.4789 (0.4949)  time: 0.0539  data: 0.0389  max mem: 20571\n",
      "Valid: [epoch:315] Total time: 0:00:00 (0.0588 s / it)\n",
      "Averaged stats: loss: 0.4789 (0.4949)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_315_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.495%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:316]  [  0/172]  eta: 0:07:26  lr: 0.000076  loss: 0.4722 (0.4722)  time: 2.5935  data: 1.0261  max mem: 20571\n",
      "Train: [epoch:316]  [ 10/172]  eta: 0:04:31  lr: 0.000076  loss: 0.5054 (0.5174)  time: 1.6730  data: 0.0934  max mem: 20571\n",
      "Train: [epoch:316]  [ 20/172]  eta: 0:04:07  lr: 0.000076  loss: 0.5161 (0.5178)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [ 30/172]  eta: 0:03:49  lr: 0.000076  loss: 0.5131 (0.5155)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [ 40/172]  eta: 0:03:32  lr: 0.000076  loss: 0.5131 (0.5147)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [ 50/172]  eta: 0:03:15  lr: 0.000076  loss: 0.5151 (0.5160)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [ 60/172]  eta: 0:02:58  lr: 0.000076  loss: 0.5053 (0.5163)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [ 70/172]  eta: 0:02:42  lr: 0.000076  loss: 0.5188 (0.5173)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [ 80/172]  eta: 0:02:26  lr: 0.000076  loss: 0.5188 (0.5170)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [ 90/172]  eta: 0:02:10  lr: 0.000076  loss: 0.5031 (0.5169)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [100/172]  eta: 0:01:54  lr: 0.000076  loss: 0.5128 (0.5176)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [110/172]  eta: 0:01:38  lr: 0.000076  loss: 0.5161 (0.5172)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [120/172]  eta: 0:01:22  lr: 0.000076  loss: 0.5161 (0.5186)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [130/172]  eta: 0:01:06  lr: 0.000076  loss: 0.5211 (0.5189)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [140/172]  eta: 0:00:50  lr: 0.000076  loss: 0.5211 (0.5195)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [150/172]  eta: 0:00:34  lr: 0.000076  loss: 0.5189 (0.5194)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [160/172]  eta: 0:00:19  lr: 0.000076  loss: 0.5150 (0.5190)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [170/172]  eta: 0:00:03  lr: 0.000076  loss: 0.5222 (0.5198)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316]  [171/172]  eta: 0:00:01  lr: 0.000076  loss: 0.5224 (0.5203)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:316] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000076  loss: 0.5224 (0.5203)\n",
      "Valid: [epoch:316]  [ 0/14]  eta: 0:00:04  loss: 0.5074 (0.5074)  time: 0.3081  data: 0.2878  max mem: 20571\n",
      "Valid: [epoch:316]  [13/14]  eta: 0:00:00  loss: 0.4719 (0.4876)  time: 0.0361  data: 0.0207  max mem: 20571\n",
      "Valid: [epoch:316] Total time: 0:00:00 (0.0412 s / it)\n",
      "Averaged stats: loss: 0.4719 (0.4876)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_316_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.488%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:317]  [  0/172]  eta: 0:07:32  lr: 0.000076  loss: 0.4423 (0.4423)  time: 2.6315  data: 1.0533  max mem: 20571\n",
      "Train: [epoch:317]  [ 10/172]  eta: 0:04:31  lr: 0.000076  loss: 0.5317 (0.5172)  time: 1.6732  data: 0.0959  max mem: 20571\n",
      "Train: [epoch:317]  [ 20/172]  eta: 0:04:07  lr: 0.000076  loss: 0.5179 (0.5162)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [ 30/172]  eta: 0:03:48  lr: 0.000076  loss: 0.5120 (0.5150)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [ 40/172]  eta: 0:03:31  lr: 0.000076  loss: 0.5320 (0.5211)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [ 50/172]  eta: 0:03:15  lr: 0.000076  loss: 0.5386 (0.5257)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [ 60/172]  eta: 0:02:58  lr: 0.000076  loss: 0.5364 (0.5257)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [ 70/172]  eta: 0:02:42  lr: 0.000076  loss: 0.5292 (0.5273)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [ 80/172]  eta: 0:02:26  lr: 0.000076  loss: 0.5223 (0.5257)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [ 90/172]  eta: 0:02:10  lr: 0.000076  loss: 0.5132 (0.5261)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [100/172]  eta: 0:01:54  lr: 0.000076  loss: 0.5183 (0.5275)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [110/172]  eta: 0:01:38  lr: 0.000076  loss: 0.5208 (0.5274)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [120/172]  eta: 0:01:22  lr: 0.000076  loss: 0.5219 (0.5273)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [130/172]  eta: 0:01:06  lr: 0.000076  loss: 0.5152 (0.5261)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [140/172]  eta: 0:00:50  lr: 0.000076  loss: 0.5143 (0.5263)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [150/172]  eta: 0:00:34  lr: 0.000076  loss: 0.5190 (0.5271)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [160/172]  eta: 0:00:19  lr: 0.000076  loss: 0.5200 (0.5266)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [170/172]  eta: 0:00:03  lr: 0.000076  loss: 0.5200 (0.5273)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317]  [171/172]  eta: 0:00:01  lr: 0.000076  loss: 0.5200 (0.5270)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:317] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000076  loss: 0.5200 (0.5270)\n",
      "Valid: [epoch:317]  [ 0/14]  eta: 0:00:03  loss: 0.5447 (0.5447)  time: 0.2755  data: 0.2598  max mem: 20571\n",
      "Valid: [epoch:317]  [13/14]  eta: 0:00:00  loss: 0.4878 (0.5029)  time: 0.0389  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:317] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.4878 (0.5029)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_317_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.503%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:318]  [  0/172]  eta: 0:07:24  lr: 0.000076  loss: 0.4906 (0.4906)  time: 2.5824  data: 0.9932  max mem: 20571\n",
      "Train: [epoch:318]  [ 10/172]  eta: 0:04:31  lr: 0.000076  loss: 0.5119 (0.5193)  time: 1.6738  data: 0.0904  max mem: 20571\n",
      "Train: [epoch:318]  [ 20/172]  eta: 0:04:07  lr: 0.000076  loss: 0.5188 (0.5197)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [ 30/172]  eta: 0:03:49  lr: 0.000076  loss: 0.5188 (0.5219)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [ 40/172]  eta: 0:03:32  lr: 0.000076  loss: 0.5164 (0.5201)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [ 50/172]  eta: 0:03:15  lr: 0.000076  loss: 0.5152 (0.5192)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [ 60/172]  eta: 0:02:59  lr: 0.000076  loss: 0.5152 (0.5201)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [ 70/172]  eta: 0:02:42  lr: 0.000076  loss: 0.5163 (0.5201)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [ 80/172]  eta: 0:02:26  lr: 0.000076  loss: 0.5146 (0.5192)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [ 90/172]  eta: 0:02:10  lr: 0.000076  loss: 0.5146 (0.5207)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [100/172]  eta: 0:01:54  lr: 0.000076  loss: 0.5226 (0.5208)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [110/172]  eta: 0:01:38  lr: 0.000076  loss: 0.5334 (0.5216)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [120/172]  eta: 0:01:22  lr: 0.000076  loss: 0.5354 (0.5228)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [130/172]  eta: 0:01:06  lr: 0.000076  loss: 0.5189 (0.5230)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [140/172]  eta: 0:00:50  lr: 0.000076  loss: 0.5085 (0.5215)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [150/172]  eta: 0:00:34  lr: 0.000076  loss: 0.5086 (0.5214)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [160/172]  eta: 0:00:19  lr: 0.000076  loss: 0.5158 (0.5210)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318]  [170/172]  eta: 0:00:03  lr: 0.000076  loss: 0.5169 (0.5214)  time: 1.5819  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:318]  [171/172]  eta: 0:00:01  lr: 0.000076  loss: 0.5196 (0.5218)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:318] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000076  loss: 0.5196 (0.5218)\n",
      "Valid: [epoch:318]  [ 0/14]  eta: 0:00:04  loss: 0.5611 (0.5611)  time: 0.3232  data: 0.3074  max mem: 20571\n",
      "Valid: [epoch:318]  [13/14]  eta: 0:00:00  loss: 0.5094 (0.5249)  time: 0.0477  data: 0.0327  max mem: 20571\n",
      "Valid: [epoch:318] Total time: 0:00:00 (0.0522 s / it)\n",
      "Averaged stats: loss: 0.5094 (0.5249)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_318_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.525%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:319]  [  0/172]  eta: 0:07:30  lr: 0.000076  loss: 0.5156 (0.5156)  time: 2.6192  data: 1.0431  max mem: 20571\n",
      "Train: [epoch:319]  [ 10/172]  eta: 0:04:30  lr: 0.000076  loss: 0.5247 (0.5186)  time: 1.6724  data: 0.0949  max mem: 20571\n",
      "Train: [epoch:319]  [ 20/172]  eta: 0:04:07  lr: 0.000076  loss: 0.5110 (0.5165)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [ 30/172]  eta: 0:03:48  lr: 0.000076  loss: 0.5066 (0.5158)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [ 40/172]  eta: 0:03:31  lr: 0.000076  loss: 0.5088 (0.5149)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [ 50/172]  eta: 0:03:15  lr: 0.000076  loss: 0.5126 (0.5167)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [ 60/172]  eta: 0:02:58  lr: 0.000076  loss: 0.5232 (0.5177)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [ 70/172]  eta: 0:02:42  lr: 0.000076  loss: 0.5249 (0.5178)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [ 80/172]  eta: 0:02:26  lr: 0.000076  loss: 0.5231 (0.5174)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [ 90/172]  eta: 0:02:10  lr: 0.000076  loss: 0.5175 (0.5173)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [100/172]  eta: 0:01:54  lr: 0.000076  loss: 0.5249 (0.5192)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [110/172]  eta: 0:01:38  lr: 0.000076  loss: 0.5154 (0.5186)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [120/172]  eta: 0:01:22  lr: 0.000076  loss: 0.5148 (0.5190)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [130/172]  eta: 0:01:06  lr: 0.000076  loss: 0.5114 (0.5183)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [140/172]  eta: 0:00:50  lr: 0.000076  loss: 0.5207 (0.5189)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [150/172]  eta: 0:00:34  lr: 0.000076  loss: 0.5256 (0.5196)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [160/172]  eta: 0:00:19  lr: 0.000076  loss: 0.5349 (0.5221)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [170/172]  eta: 0:00:03  lr: 0.000076  loss: 0.5416 (0.5239)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319]  [171/172]  eta: 0:00:01  lr: 0.000076  loss: 0.5416 (0.5242)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:319] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000076  loss: 0.5416 (0.5242)\n",
      "Valid: [epoch:319]  [ 0/14]  eta: 0:00:04  loss: 0.4578 (0.4578)  time: 0.3489  data: 0.3319  max mem: 20571\n",
      "Valid: [epoch:319]  [13/14]  eta: 0:00:00  loss: 0.5096 (0.5240)  time: 0.0409  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:319] Total time: 0:00:00 (0.0486 s / it)\n",
      "Averaged stats: loss: 0.5096 (0.5240)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_319_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.524%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:320]  [  0/172]  eta: 0:07:38  lr: 0.000076  loss: 0.5629 (0.5629)  time: 2.6673  data: 1.0990  max mem: 20571\n",
      "Train: [epoch:320]  [ 10/172]  eta: 0:04:31  lr: 0.000076  loss: 0.5326 (0.5340)  time: 1.6789  data: 0.1001  max mem: 20571\n",
      "Train: [epoch:320]  [ 20/172]  eta: 0:04:08  lr: 0.000076  loss: 0.5305 (0.5274)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [ 30/172]  eta: 0:03:49  lr: 0.000076  loss: 0.5287 (0.5324)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [ 40/172]  eta: 0:03:32  lr: 0.000076  loss: 0.5195 (0.5285)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [ 50/172]  eta: 0:03:15  lr: 0.000076  loss: 0.5171 (0.5291)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [ 60/172]  eta: 0:02:59  lr: 0.000076  loss: 0.5250 (0.5272)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [ 70/172]  eta: 0:02:42  lr: 0.000076  loss: 0.5252 (0.5277)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [ 80/172]  eta: 0:02:26  lr: 0.000076  loss: 0.5189 (0.5264)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [ 90/172]  eta: 0:02:10  lr: 0.000076  loss: 0.5127 (0.5254)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [100/172]  eta: 0:01:54  lr: 0.000076  loss: 0.5105 (0.5246)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [110/172]  eta: 0:01:38  lr: 0.000076  loss: 0.5143 (0.5247)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [120/172]  eta: 0:01:22  lr: 0.000076  loss: 0.5190 (0.5240)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [130/172]  eta: 0:01:06  lr: 0.000076  loss: 0.5045 (0.5222)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [140/172]  eta: 0:00:50  lr: 0.000076  loss: 0.5084 (0.5220)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [150/172]  eta: 0:00:34  lr: 0.000076  loss: 0.5169 (0.5212)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [160/172]  eta: 0:00:19  lr: 0.000076  loss: 0.5184 (0.5219)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [170/172]  eta: 0:00:03  lr: 0.000076  loss: 0.5235 (0.5222)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320]  [171/172]  eta: 0:00:01  lr: 0.000076  loss: 0.5197 (0.5221)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:320] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000076  loss: 0.5197 (0.5221)\n",
      "Valid: [epoch:320]  [ 0/14]  eta: 0:00:04  loss: 0.5420 (0.5420)  time: 0.3476  data: 0.3298  max mem: 20571\n",
      "Valid: [epoch:320]  [13/14]  eta: 0:00:00  loss: 0.4794 (0.4950)  time: 0.0396  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:320] Total time: 0:00:00 (0.0442 s / it)\n",
      "Averaged stats: loss: 0.4794 (0.4950)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_320_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.495%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:321]  [  0/172]  eta: 0:07:17  lr: 0.000076  loss: 0.5573 (0.5573)  time: 2.5455  data: 0.9667  max mem: 20571\n",
      "Train: [epoch:321]  [ 10/172]  eta: 0:04:29  lr: 0.000076  loss: 0.5328 (0.5333)  time: 1.6654  data: 0.0880  max mem: 20571\n",
      "Train: [epoch:321]  [ 20/172]  eta: 0:04:06  lr: 0.000076  loss: 0.5295 (0.5306)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [ 30/172]  eta: 0:03:48  lr: 0.000076  loss: 0.5142 (0.5271)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [ 40/172]  eta: 0:03:31  lr: 0.000076  loss: 0.5109 (0.5249)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [ 50/172]  eta: 0:03:15  lr: 0.000076  loss: 0.5211 (0.5265)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [ 60/172]  eta: 0:02:58  lr: 0.000076  loss: 0.5315 (0.5271)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [ 70/172]  eta: 0:02:42  lr: 0.000076  loss: 0.5201 (0.5278)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [ 80/172]  eta: 0:02:26  lr: 0.000076  loss: 0.5340 (0.5296)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [ 90/172]  eta: 0:02:10  lr: 0.000076  loss: 0.5350 (0.5286)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [100/172]  eta: 0:01:54  lr: 0.000076  loss: 0.5271 (0.5290)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [110/172]  eta: 0:01:38  lr: 0.000076  loss: 0.5258 (0.5289)  time: 1.5828  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:321]  [120/172]  eta: 0:01:22  lr: 0.000076  loss: 0.5168 (0.5287)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [130/172]  eta: 0:01:06  lr: 0.000076  loss: 0.5236 (0.5283)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [140/172]  eta: 0:00:50  lr: 0.000076  loss: 0.5187 (0.5278)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [150/172]  eta: 0:00:34  lr: 0.000076  loss: 0.5203 (0.5275)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [160/172]  eta: 0:00:19  lr: 0.000076  loss: 0.5232 (0.5269)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [170/172]  eta: 0:00:03  lr: 0.000076  loss: 0.5149 (0.5261)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321]  [171/172]  eta: 0:00:01  lr: 0.000076  loss: 0.5146 (0.5260)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:321] Total time: 0:04:32 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000076  loss: 0.5146 (0.5260)\n",
      "Valid: [epoch:321]  [ 0/14]  eta: 0:00:04  loss: 0.4818 (0.4818)  time: 0.2890  data: 0.2720  max mem: 20571\n",
      "Valid: [epoch:321]  [13/14]  eta: 0:00:00  loss: 0.4818 (0.4972)  time: 0.0529  data: 0.0379  max mem: 20571\n",
      "Valid: [epoch:321] Total time: 0:00:00 (0.0613 s / it)\n",
      "Averaged stats: loss: 0.4818 (0.4972)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_321_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.497%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:322]  [  0/172]  eta: 0:08:03  lr: 0.000075  loss: 0.5229 (0.5229)  time: 2.8134  data: 1.2296  max mem: 20571\n",
      "Train: [epoch:322]  [ 10/172]  eta: 0:04:34  lr: 0.000075  loss: 0.5203 (0.5251)  time: 1.6965  data: 0.1119  max mem: 20571\n",
      "Train: [epoch:322]  [ 20/172]  eta: 0:04:09  lr: 0.000075  loss: 0.5184 (0.5249)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [ 30/172]  eta: 0:03:50  lr: 0.000075  loss: 0.5283 (0.5292)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:322]  [ 40/172]  eta: 0:03:32  lr: 0.000075  loss: 0.5356 (0.5306)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [ 50/172]  eta: 0:03:15  lr: 0.000075  loss: 0.5320 (0.5342)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [ 60/172]  eta: 0:02:59  lr: 0.000075  loss: 0.5320 (0.5343)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [ 70/172]  eta: 0:02:43  lr: 0.000075  loss: 0.5298 (0.5327)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [ 80/172]  eta: 0:02:26  lr: 0.000075  loss: 0.5119 (0.5293)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [ 90/172]  eta: 0:02:10  lr: 0.000075  loss: 0.5062 (0.5283)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [100/172]  eta: 0:01:54  lr: 0.000075  loss: 0.5191 (0.5292)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [110/172]  eta: 0:01:38  lr: 0.000075  loss: 0.5298 (0.5285)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [120/172]  eta: 0:01:22  lr: 0.000075  loss: 0.5180 (0.5274)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [130/172]  eta: 0:01:06  lr: 0.000075  loss: 0.5116 (0.5267)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [140/172]  eta: 0:00:50  lr: 0.000075  loss: 0.5148 (0.5271)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [150/172]  eta: 0:00:34  lr: 0.000075  loss: 0.5212 (0.5269)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [160/172]  eta: 0:00:19  lr: 0.000075  loss: 0.5299 (0.5269)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [170/172]  eta: 0:00:03  lr: 0.000075  loss: 0.5263 (0.5267)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322]  [171/172]  eta: 0:00:01  lr: 0.000075  loss: 0.5205 (0.5266)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:322] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000075  loss: 0.5205 (0.5266)\n",
      "Valid: [epoch:322]  [ 0/14]  eta: 0:00:04  loss: 0.5517 (0.5517)  time: 0.2900  data: 0.2755  max mem: 20571\n",
      "Valid: [epoch:322]  [13/14]  eta: 0:00:00  loss: 0.4928 (0.5087)  time: 0.0421  data: 0.0271  max mem: 20571\n",
      "Valid: [epoch:322] Total time: 0:00:00 (0.0500 s / it)\n",
      "Averaged stats: loss: 0.4928 (0.5087)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_322_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.509%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:323]  [  0/172]  eta: 0:07:24  lr: 0.000075  loss: 0.5179 (0.5179)  time: 2.5847  data: 1.0138  max mem: 20571\n",
      "Train: [epoch:323]  [ 10/172]  eta: 0:04:30  lr: 0.000075  loss: 0.5209 (0.5280)  time: 1.6681  data: 0.0923  max mem: 20571\n",
      "Train: [epoch:323]  [ 20/172]  eta: 0:04:07  lr: 0.000075  loss: 0.5244 (0.5281)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [ 30/172]  eta: 0:03:48  lr: 0.000075  loss: 0.5063 (0.5238)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:323]  [ 40/172]  eta: 0:03:31  lr: 0.000075  loss: 0.5022 (0.5235)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [ 50/172]  eta: 0:03:15  lr: 0.000075  loss: 0.5139 (0.5261)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [ 60/172]  eta: 0:02:58  lr: 0.000075  loss: 0.5375 (0.5276)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [ 70/172]  eta: 0:02:42  lr: 0.000075  loss: 0.5255 (0.5269)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [ 80/172]  eta: 0:02:26  lr: 0.000075  loss: 0.5213 (0.5266)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [ 90/172]  eta: 0:02:10  lr: 0.000075  loss: 0.5213 (0.5248)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [100/172]  eta: 0:01:54  lr: 0.000075  loss: 0.5076 (0.5236)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [110/172]  eta: 0:01:38  lr: 0.000075  loss: 0.5116 (0.5234)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [120/172]  eta: 0:01:22  lr: 0.000075  loss: 0.5242 (0.5243)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [130/172]  eta: 0:01:06  lr: 0.000075  loss: 0.5242 (0.5232)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [140/172]  eta: 0:00:50  lr: 0.000075  loss: 0.5328 (0.5241)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [150/172]  eta: 0:00:34  lr: 0.000075  loss: 0.5389 (0.5254)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [160/172]  eta: 0:00:19  lr: 0.000075  loss: 0.5326 (0.5252)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [170/172]  eta: 0:00:03  lr: 0.000075  loss: 0.5222 (0.5256)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323]  [171/172]  eta: 0:00:01  lr: 0.000075  loss: 0.5153 (0.5256)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:323] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000075  loss: 0.5153 (0.5256)\n",
      "Valid: [epoch:323]  [ 0/14]  eta: 0:00:04  loss: 0.4646 (0.4646)  time: 0.2910  data: 0.2742  max mem: 20571\n",
      "Valid: [epoch:323]  [13/14]  eta: 0:00:00  loss: 0.4814 (0.4984)  time: 0.0388  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:323] Total time: 0:00:00 (0.0439 s / it)\n",
      "Averaged stats: loss: 0.4814 (0.4984)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_323_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.498%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:324]  [  0/172]  eta: 0:07:24  lr: 0.000075  loss: 0.4684 (0.4684)  time: 2.5871  data: 1.0196  max mem: 20571\n",
      "Train: [epoch:324]  [ 10/172]  eta: 0:04:30  lr: 0.000075  loss: 0.5128 (0.5311)  time: 1.6700  data: 0.0928  max mem: 20571\n",
      "Train: [epoch:324]  [ 20/172]  eta: 0:04:07  lr: 0.000075  loss: 0.5302 (0.5365)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [ 30/172]  eta: 0:03:48  lr: 0.000075  loss: 0.5341 (0.5321)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [ 40/172]  eta: 0:03:31  lr: 0.000075  loss: 0.5216 (0.5281)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [ 50/172]  eta: 0:03:15  lr: 0.000075  loss: 0.5216 (0.5294)  time: 1.5797  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:324]  [ 60/172]  eta: 0:02:58  lr: 0.000075  loss: 0.5217 (0.5281)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:324]  [ 70/172]  eta: 0:02:42  lr: 0.000075  loss: 0.5268 (0.5294)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [ 80/172]  eta: 0:02:26  lr: 0.000075  loss: 0.5268 (0.5283)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [ 90/172]  eta: 0:02:10  lr: 0.000075  loss: 0.5116 (0.5275)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [100/172]  eta: 0:01:54  lr: 0.000075  loss: 0.5179 (0.5270)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [110/172]  eta: 0:01:38  lr: 0.000075  loss: 0.5218 (0.5271)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [120/172]  eta: 0:01:22  lr: 0.000075  loss: 0.5218 (0.5268)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [130/172]  eta: 0:01:06  lr: 0.000075  loss: 0.5274 (0.5269)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [140/172]  eta: 0:00:50  lr: 0.000075  loss: 0.5274 (0.5269)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [150/172]  eta: 0:00:34  lr: 0.000075  loss: 0.5109 (0.5270)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [160/172]  eta: 0:00:19  lr: 0.000075  loss: 0.5186 (0.5266)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [170/172]  eta: 0:00:03  lr: 0.000075  loss: 0.5186 (0.5264)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324]  [171/172]  eta: 0:00:01  lr: 0.000075  loss: 0.5186 (0.5263)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:324] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000075  loss: 0.5186 (0.5263)\n",
      "Valid: [epoch:324]  [ 0/14]  eta: 0:00:04  loss: 0.5412 (0.5412)  time: 0.2932  data: 0.2765  max mem: 20571\n",
      "Valid: [epoch:324]  [13/14]  eta: 0:00:00  loss: 0.4785 (0.4944)  time: 0.0411  data: 0.0260  max mem: 20571\n",
      "Valid: [epoch:324] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.4785 (0.4944)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_324_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.494%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:325]  [  0/172]  eta: 0:07:32  lr: 0.000075  loss: 0.5366 (0.5366)  time: 2.6301  data: 1.0532  max mem: 20571\n",
      "Train: [epoch:325]  [ 10/172]  eta: 0:04:31  lr: 0.000075  loss: 0.5330 (0.5364)  time: 1.6751  data: 0.0959  max mem: 20571\n",
      "Train: [epoch:325]  [ 20/172]  eta: 0:04:07  lr: 0.000075  loss: 0.5254 (0.5341)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [ 30/172]  eta: 0:03:48  lr: 0.000075  loss: 0.5150 (0.5322)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [ 40/172]  eta: 0:03:31  lr: 0.000075  loss: 0.5242 (0.5327)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [ 50/172]  eta: 0:03:15  lr: 0.000075  loss: 0.5242 (0.5333)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [ 60/172]  eta: 0:02:58  lr: 0.000075  loss: 0.5310 (0.5344)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [ 70/172]  eta: 0:02:42  lr: 0.000075  loss: 0.5310 (0.5322)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [ 80/172]  eta: 0:02:26  lr: 0.000075  loss: 0.5185 (0.5304)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [ 90/172]  eta: 0:02:10  lr: 0.000075  loss: 0.5300 (0.5303)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [100/172]  eta: 0:01:54  lr: 0.000075  loss: 0.5141 (0.5287)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [110/172]  eta: 0:01:38  lr: 0.000075  loss: 0.5128 (0.5288)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [120/172]  eta: 0:01:22  lr: 0.000075  loss: 0.5225 (0.5280)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [130/172]  eta: 0:01:06  lr: 0.000075  loss: 0.5268 (0.5284)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [140/172]  eta: 0:00:50  lr: 0.000075  loss: 0.5189 (0.5286)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [150/172]  eta: 0:00:34  lr: 0.000075  loss: 0.5149 (0.5280)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [160/172]  eta: 0:00:19  lr: 0.000075  loss: 0.5191 (0.5284)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [170/172]  eta: 0:00:03  lr: 0.000075  loss: 0.5205 (0.5280)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325]  [171/172]  eta: 0:00:01  lr: 0.000075  loss: 0.5232 (0.5280)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:325] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000075  loss: 0.5232 (0.5280)\n",
      "Valid: [epoch:325]  [ 0/14]  eta: 0:00:04  loss: 0.4777 (0.4777)  time: 0.3181  data: 0.3021  max mem: 20571\n",
      "Valid: [epoch:325]  [13/14]  eta: 0:00:00  loss: 0.4814 (0.4983)  time: 0.0495  data: 0.0346  max mem: 20571\n",
      "Valid: [epoch:325] Total time: 0:00:00 (0.0550 s / it)\n",
      "Averaged stats: loss: 0.4814 (0.4983)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_325_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.498%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:326]  [  0/172]  eta: 0:07:29  lr: 0.000075  loss: 0.5112 (0.5112)  time: 2.6134  data: 1.0345  max mem: 20571\n",
      "Train: [epoch:326]  [ 10/172]  eta: 0:04:31  lr: 0.000075  loss: 0.5112 (0.5136)  time: 1.6735  data: 0.0942  max mem: 20571\n",
      "Train: [epoch:326]  [ 20/172]  eta: 0:04:07  lr: 0.000075  loss: 0.5260 (0.5193)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:326]  [ 30/172]  eta: 0:03:49  lr: 0.000075  loss: 0.5281 (0.5190)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [ 40/172]  eta: 0:03:31  lr: 0.000075  loss: 0.5265 (0.5203)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [ 50/172]  eta: 0:03:15  lr: 0.000075  loss: 0.5265 (0.5206)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [ 60/172]  eta: 0:02:58  lr: 0.000075  loss: 0.5266 (0.5213)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [ 70/172]  eta: 0:02:42  lr: 0.000075  loss: 0.5265 (0.5231)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [ 80/172]  eta: 0:02:26  lr: 0.000075  loss: 0.5204 (0.5229)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [ 90/172]  eta: 0:02:10  lr: 0.000075  loss: 0.5300 (0.5228)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [100/172]  eta: 0:01:54  lr: 0.000075  loss: 0.5300 (0.5229)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [110/172]  eta: 0:01:38  lr: 0.000075  loss: 0.5066 (0.5228)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [120/172]  eta: 0:01:22  lr: 0.000075  loss: 0.5245 (0.5241)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [130/172]  eta: 0:01:06  lr: 0.000075  loss: 0.5332 (0.5249)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [140/172]  eta: 0:00:50  lr: 0.000075  loss: 0.5252 (0.5243)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [150/172]  eta: 0:00:34  lr: 0.000075  loss: 0.5240 (0.5240)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [160/172]  eta: 0:00:19  lr: 0.000075  loss: 0.5180 (0.5239)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [170/172]  eta: 0:00:03  lr: 0.000075  loss: 0.5261 (0.5250)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326]  [171/172]  eta: 0:00:01  lr: 0.000075  loss: 0.5323 (0.5251)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:326] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000075  loss: 0.5323 (0.5251)\n",
      "Valid: [epoch:326]  [ 0/14]  eta: 0:00:04  loss: 0.5443 (0.5443)  time: 0.3351  data: 0.3165  max mem: 20571\n",
      "Valid: [epoch:326]  [13/14]  eta: 0:00:00  loss: 0.4867 (0.5041)  time: 0.0380  data: 0.0227  max mem: 20571\n",
      "Valid: [epoch:326] Total time: 0:00:00 (0.0459 s / it)\n",
      "Averaged stats: loss: 0.4867 (0.5041)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_326_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.504%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:327]  [  0/172]  eta: 0:08:20  lr: 0.000075  loss: 0.4918 (0.4918)  time: 2.9086  data: 1.3266  max mem: 20571\n",
      "Train: [epoch:327]  [ 10/172]  eta: 0:04:35  lr: 0.000075  loss: 0.5318 (0.5267)  time: 1.6993  data: 0.1207  max mem: 20571\n",
      "Train: [epoch:327]  [ 20/172]  eta: 0:04:09  lr: 0.000075  loss: 0.5345 (0.5314)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:327]  [ 30/172]  eta: 0:03:50  lr: 0.000075  loss: 0.5327 (0.5289)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:327]  [ 40/172]  eta: 0:03:32  lr: 0.000075  loss: 0.5148 (0.5285)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [ 50/172]  eta: 0:03:15  lr: 0.000075  loss: 0.5148 (0.5287)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [ 60/172]  eta: 0:02:59  lr: 0.000075  loss: 0.5102 (0.5266)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [ 70/172]  eta: 0:02:43  lr: 0.000075  loss: 0.5136 (0.5261)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [ 80/172]  eta: 0:02:26  lr: 0.000075  loss: 0.5100 (0.5253)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [ 90/172]  eta: 0:02:10  lr: 0.000075  loss: 0.5128 (0.5262)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [100/172]  eta: 0:01:54  lr: 0.000075  loss: 0.5363 (0.5271)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [110/172]  eta: 0:01:38  lr: 0.000075  loss: 0.5261 (0.5270)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [120/172]  eta: 0:01:22  lr: 0.000075  loss: 0.5228 (0.5268)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [130/172]  eta: 0:01:06  lr: 0.000075  loss: 0.5456 (0.5301)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [140/172]  eta: 0:00:50  lr: 0.000075  loss: 0.5456 (0.5310)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [150/172]  eta: 0:00:34  lr: 0.000075  loss: 0.5337 (0.5315)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [160/172]  eta: 0:00:19  lr: 0.000075  loss: 0.5337 (0.5327)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [170/172]  eta: 0:00:03  lr: 0.000075  loss: 0.5299 (0.5318)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327]  [171/172]  eta: 0:00:01  lr: 0.000075  loss: 0.5299 (0.5316)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:327] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000075  loss: 0.5299 (0.5316)\n",
      "Valid: [epoch:327]  [ 0/14]  eta: 0:00:05  loss: 0.5496 (0.5496)  time: 0.3835  data: 0.3680  max mem: 20571\n",
      "Valid: [epoch:327]  [13/14]  eta: 0:00:00  loss: 0.4882 (0.5043)  time: 0.0427  data: 0.0276  max mem: 20571\n",
      "Valid: [epoch:327] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.4882 (0.5043)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_327_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.504%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:328]  [  0/172]  eta: 0:07:21  lr: 0.000075  loss: 0.5147 (0.5147)  time: 2.5671  data: 1.0003  max mem: 20571\n",
      "Train: [epoch:328]  [ 10/172]  eta: 0:04:30  lr: 0.000075  loss: 0.5147 (0.5240)  time: 1.6689  data: 0.0910  max mem: 20571\n",
      "Train: [epoch:328]  [ 20/172]  eta: 0:04:07  lr: 0.000075  loss: 0.5192 (0.5264)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [ 30/172]  eta: 0:03:48  lr: 0.000075  loss: 0.5192 (0.5234)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [ 40/172]  eta: 0:03:31  lr: 0.000075  loss: 0.5172 (0.5231)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [ 50/172]  eta: 0:03:15  lr: 0.000075  loss: 0.5172 (0.5232)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [ 60/172]  eta: 0:02:58  lr: 0.000075  loss: 0.5207 (0.5220)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [ 70/172]  eta: 0:02:42  lr: 0.000075  loss: 0.5225 (0.5234)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [ 80/172]  eta: 0:02:26  lr: 0.000075  loss: 0.5345 (0.5261)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [ 90/172]  eta: 0:02:10  lr: 0.000075  loss: 0.5334 (0.5259)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [100/172]  eta: 0:01:54  lr: 0.000075  loss: 0.5278 (0.5269)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [110/172]  eta: 0:01:38  lr: 0.000075  loss: 0.5159 (0.5257)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [120/172]  eta: 0:01:22  lr: 0.000075  loss: 0.5173 (0.5261)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [130/172]  eta: 0:01:06  lr: 0.000075  loss: 0.5187 (0.5255)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [140/172]  eta: 0:00:50  lr: 0.000075  loss: 0.5145 (0.5256)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [150/172]  eta: 0:00:34  lr: 0.000075  loss: 0.5210 (0.5253)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [160/172]  eta: 0:00:19  lr: 0.000075  loss: 0.5223 (0.5262)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [170/172]  eta: 0:00:03  lr: 0.000075  loss: 0.5216 (0.5259)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328]  [171/172]  eta: 0:00:01  lr: 0.000075  loss: 0.5243 (0.5264)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:328] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000075  loss: 0.5243 (0.5264)\n",
      "Valid: [epoch:328]  [ 0/14]  eta: 0:00:05  loss: 0.4388 (0.4388)  time: 0.4117  data: 0.3925  max mem: 20571\n",
      "Valid: [epoch:328]  [13/14]  eta: 0:00:00  loss: 0.4867 (0.5023)  time: 0.0438  data: 0.0285  max mem: 20571\n",
      "Valid: [epoch:328] Total time: 0:00:00 (0.0513 s / it)\n",
      "Averaged stats: loss: 0.4867 (0.5023)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_328_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.502%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:329]  [  0/172]  eta: 0:07:42  lr: 0.000075  loss: 0.5043 (0.5043)  time: 2.6886  data: 1.1001  max mem: 20571\n",
      "Train: [epoch:329]  [ 10/172]  eta: 0:04:31  lr: 0.000075  loss: 0.5056 (0.5149)  time: 1.6763  data: 0.1001  max mem: 20571\n",
      "Train: [epoch:329]  [ 20/172]  eta: 0:04:07  lr: 0.000075  loss: 0.5095 (0.5195)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [ 30/172]  eta: 0:03:48  lr: 0.000075  loss: 0.5217 (0.5217)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [ 40/172]  eta: 0:03:31  lr: 0.000075  loss: 0.5173 (0.5219)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [ 50/172]  eta: 0:03:15  lr: 0.000075  loss: 0.5188 (0.5249)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [ 60/172]  eta: 0:02:58  lr: 0.000075  loss: 0.5272 (0.5243)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [ 70/172]  eta: 0:02:42  lr: 0.000075  loss: 0.5252 (0.5254)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [ 80/172]  eta: 0:02:26  lr: 0.000075  loss: 0.5244 (0.5261)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [ 90/172]  eta: 0:02:10  lr: 0.000075  loss: 0.5194 (0.5255)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [100/172]  eta: 0:01:54  lr: 0.000075  loss: 0.5183 (0.5254)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [110/172]  eta: 0:01:38  lr: 0.000075  loss: 0.5269 (0.5257)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [120/172]  eta: 0:01:22  lr: 0.000075  loss: 0.5277 (0.5265)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [130/172]  eta: 0:01:06  lr: 0.000075  loss: 0.5191 (0.5262)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [140/172]  eta: 0:00:50  lr: 0.000075  loss: 0.5191 (0.5263)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [150/172]  eta: 0:00:34  lr: 0.000075  loss: 0.5242 (0.5264)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [160/172]  eta: 0:00:19  lr: 0.000075  loss: 0.5058 (0.5258)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329]  [170/172]  eta: 0:00:03  lr: 0.000075  loss: 0.5193 (0.5265)  time: 1.5809  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:329]  [171/172]  eta: 0:00:01  lr: 0.000075  loss: 0.5130 (0.5264)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:329] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000075  loss: 0.5130 (0.5264)\n",
      "Valid: [epoch:329]  [ 0/14]  eta: 0:00:08  loss: 0.5587 (0.5587)  time: 0.6075  data: 0.5906  max mem: 20571\n",
      "Valid: [epoch:329]  [13/14]  eta: 0:00:00  loss: 0.5059 (0.5202)  time: 0.0584  data: 0.0433  max mem: 20571\n",
      "Valid: [epoch:329] Total time: 0:00:00 (0.0669 s / it)\n",
      "Averaged stats: loss: 0.5059 (0.5202)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_329_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.520%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:330]  [  0/172]  eta: 0:07:45  lr: 0.000075  loss: 0.5175 (0.5175)  time: 2.7039  data: 1.1138  max mem: 20571\n",
      "Train: [epoch:330]  [ 10/172]  eta: 0:04:32  lr: 0.000075  loss: 0.5563 (0.5541)  time: 1.6827  data: 0.1014  max mem: 20571\n",
      "Train: [epoch:330]  [ 20/172]  eta: 0:04:08  lr: 0.000075  loss: 0.5447 (0.5450)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [ 30/172]  eta: 0:03:49  lr: 0.000075  loss: 0.5232 (0.5433)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [ 40/172]  eta: 0:03:32  lr: 0.000075  loss: 0.5202 (0.5401)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [ 50/172]  eta: 0:03:15  lr: 0.000075  loss: 0.5300 (0.5373)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [ 60/172]  eta: 0:02:58  lr: 0.000075  loss: 0.5130 (0.5336)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [ 70/172]  eta: 0:02:42  lr: 0.000075  loss: 0.5150 (0.5322)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [ 80/172]  eta: 0:02:26  lr: 0.000075  loss: 0.5194 (0.5310)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [ 90/172]  eta: 0:02:10  lr: 0.000075  loss: 0.5182 (0.5297)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [100/172]  eta: 0:01:54  lr: 0.000075  loss: 0.5076 (0.5277)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [110/172]  eta: 0:01:38  lr: 0.000075  loss: 0.5178 (0.5274)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [120/172]  eta: 0:01:22  lr: 0.000075  loss: 0.5178 (0.5280)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [130/172]  eta: 0:01:06  lr: 0.000075  loss: 0.5235 (0.5277)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [140/172]  eta: 0:00:50  lr: 0.000075  loss: 0.5046 (0.5279)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [150/172]  eta: 0:00:34  lr: 0.000075  loss: 0.5079 (0.5277)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [160/172]  eta: 0:00:19  lr: 0.000075  loss: 0.5266 (0.5282)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [170/172]  eta: 0:00:03  lr: 0.000075  loss: 0.5356 (0.5291)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330]  [171/172]  eta: 0:00:01  lr: 0.000075  loss: 0.5364 (0.5292)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:330] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000075  loss: 0.5364 (0.5292)\n",
      "Valid: [epoch:330]  [ 0/14]  eta: 0:00:04  loss: 0.5013 (0.5013)  time: 0.3202  data: 0.3032  max mem: 20571\n",
      "Valid: [epoch:330]  [13/14]  eta: 0:00:00  loss: 0.5049 (0.5214)  time: 0.0383  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:330] Total time: 0:00:00 (0.0436 s / it)\n",
      "Averaged stats: loss: 0.5049 (0.5214)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_330_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.521%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:331]  [  0/172]  eta: 0:07:25  lr: 0.000074  loss: 0.5325 (0.5325)  time: 2.5898  data: 1.0043  max mem: 20571\n",
      "Train: [epoch:331]  [ 10/172]  eta: 0:04:30  lr: 0.000074  loss: 0.5254 (0.5261)  time: 1.6675  data: 0.0914  max mem: 20571\n",
      "Train: [epoch:331]  [ 20/172]  eta: 0:04:07  lr: 0.000074  loss: 0.5374 (0.5339)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [ 30/172]  eta: 0:03:48  lr: 0.000074  loss: 0.5240 (0.5321)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [ 40/172]  eta: 0:03:31  lr: 0.000074  loss: 0.5240 (0.5333)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [ 50/172]  eta: 0:03:15  lr: 0.000074  loss: 0.5280 (0.5319)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [ 60/172]  eta: 0:02:58  lr: 0.000074  loss: 0.5198 (0.5307)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [ 70/172]  eta: 0:02:42  lr: 0.000074  loss: 0.5237 (0.5308)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [ 80/172]  eta: 0:02:26  lr: 0.000074  loss: 0.5237 (0.5299)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [ 90/172]  eta: 0:02:10  lr: 0.000074  loss: 0.5246 (0.5293)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [100/172]  eta: 0:01:54  lr: 0.000074  loss: 0.5130 (0.5283)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [110/172]  eta: 0:01:38  lr: 0.000074  loss: 0.5130 (0.5287)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [120/172]  eta: 0:01:22  lr: 0.000074  loss: 0.5253 (0.5279)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [130/172]  eta: 0:01:06  lr: 0.000074  loss: 0.5176 (0.5278)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [140/172]  eta: 0:00:50  lr: 0.000074  loss: 0.5117 (0.5273)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [150/172]  eta: 0:00:34  lr: 0.000074  loss: 0.5117 (0.5275)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [160/172]  eta: 0:00:19  lr: 0.000074  loss: 0.5168 (0.5275)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [170/172]  eta: 0:00:03  lr: 0.000074  loss: 0.5182 (0.5275)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331]  [171/172]  eta: 0:00:01  lr: 0.000074  loss: 0.5170 (0.5273)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:331] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000074  loss: 0.5170 (0.5273)\n",
      "Valid: [epoch:331]  [ 0/14]  eta: 0:00:04  loss: 0.4462 (0.4462)  time: 0.2928  data: 0.2765  max mem: 20571\n",
      "Valid: [epoch:331]  [13/14]  eta: 0:00:00  loss: 0.4789 (0.4962)  time: 0.0475  data: 0.0324  max mem: 20571\n",
      "Valid: [epoch:331] Total time: 0:00:00 (0.0543 s / it)\n",
      "Averaged stats: loss: 0.4789 (0.4962)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_331_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.496%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:332]  [  0/172]  eta: 0:07:45  lr: 0.000074  loss: 0.4895 (0.4895)  time: 2.7069  data: 1.1375  max mem: 20571\n",
      "Train: [epoch:332]  [ 10/172]  eta: 0:04:32  lr: 0.000074  loss: 0.5034 (0.5093)  time: 1.6847  data: 0.1035  max mem: 20571\n",
      "Train: [epoch:332]  [ 20/172]  eta: 0:04:08  lr: 0.000074  loss: 0.5034 (0.5159)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [ 30/172]  eta: 0:03:49  lr: 0.000074  loss: 0.5386 (0.5245)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [ 40/172]  eta: 0:03:32  lr: 0.000074  loss: 0.5401 (0.5268)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [ 50/172]  eta: 0:03:15  lr: 0.000074  loss: 0.5187 (0.5262)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [ 60/172]  eta: 0:02:59  lr: 0.000074  loss: 0.5187 (0.5248)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [ 70/172]  eta: 0:02:43  lr: 0.000074  loss: 0.5291 (0.5243)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [ 80/172]  eta: 0:02:26  lr: 0.000074  loss: 0.5332 (0.5275)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [ 90/172]  eta: 0:02:10  lr: 0.000074  loss: 0.5341 (0.5279)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [100/172]  eta: 0:01:54  lr: 0.000074  loss: 0.5126 (0.5271)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [110/172]  eta: 0:01:38  lr: 0.000074  loss: 0.5180 (0.5278)  time: 1.5833  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:332]  [120/172]  eta: 0:01:22  lr: 0.000074  loss: 0.5218 (0.5271)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [130/172]  eta: 0:01:06  lr: 0.000074  loss: 0.5218 (0.5267)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [140/172]  eta: 0:00:50  lr: 0.000074  loss: 0.5154 (0.5264)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [150/172]  eta: 0:00:34  lr: 0.000074  loss: 0.5154 (0.5267)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [160/172]  eta: 0:00:19  lr: 0.000074  loss: 0.5189 (0.5268)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [170/172]  eta: 0:00:03  lr: 0.000074  loss: 0.5209 (0.5273)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332]  [171/172]  eta: 0:00:01  lr: 0.000074  loss: 0.5220 (0.5275)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:332] Total time: 0:04:33 (1.5900 s / it)\n",
      "Averaged stats: lr: 0.000074  loss: 0.5220 (0.5275)\n",
      "Valid: [epoch:332]  [ 0/14]  eta: 0:00:04  loss: 0.4783 (0.4783)  time: 0.3436  data: 0.3288  max mem: 20571\n",
      "Valid: [epoch:332]  [13/14]  eta: 0:00:00  loss: 0.4783 (0.4959)  time: 0.0394  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:332] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.4783 (0.4959)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_332_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.496%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:333]  [  0/172]  eta: 0:08:10  lr: 0.000074  loss: 0.5406 (0.5406)  time: 2.8539  data: 1.2649  max mem: 20571\n",
      "Train: [epoch:333]  [ 10/172]  eta: 0:04:34  lr: 0.000074  loss: 0.5218 (0.5190)  time: 1.6943  data: 0.1151  max mem: 20571\n",
      "Train: [epoch:333]  [ 20/172]  eta: 0:04:09  lr: 0.000074  loss: 0.5218 (0.5205)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [ 30/172]  eta: 0:03:50  lr: 0.000074  loss: 0.5303 (0.5281)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [ 40/172]  eta: 0:03:32  lr: 0.000074  loss: 0.5303 (0.5260)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [ 50/172]  eta: 0:03:15  lr: 0.000074  loss: 0.5002 (0.5243)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [ 60/172]  eta: 0:02:59  lr: 0.000074  loss: 0.5135 (0.5251)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:333]  [ 70/172]  eta: 0:02:43  lr: 0.000074  loss: 0.5371 (0.5270)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:333]  [ 80/172]  eta: 0:02:26  lr: 0.000074  loss: 0.5371 (0.5287)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [ 90/172]  eta: 0:02:10  lr: 0.000074  loss: 0.5229 (0.5274)  time: 1.5830  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:333]  [100/172]  eta: 0:01:54  lr: 0.000074  loss: 0.5286 (0.5291)  time: 1.5843  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:333]  [110/172]  eta: 0:01:38  lr: 0.000074  loss: 0.5325 (0.5285)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [120/172]  eta: 0:01:22  lr: 0.000074  loss: 0.5260 (0.5284)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [130/172]  eta: 0:01:06  lr: 0.000074  loss: 0.5162 (0.5280)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [140/172]  eta: 0:00:50  lr: 0.000074  loss: 0.5137 (0.5267)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [150/172]  eta: 0:00:34  lr: 0.000074  loss: 0.5141 (0.5272)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [160/172]  eta: 0:00:19  lr: 0.000074  loss: 0.5285 (0.5274)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [170/172]  eta: 0:00:03  lr: 0.000074  loss: 0.5313 (0.5276)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333]  [171/172]  eta: 0:00:01  lr: 0.000074  loss: 0.5313 (0.5279)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:333] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000074  loss: 0.5313 (0.5279)\n",
      "Valid: [epoch:333]  [ 0/14]  eta: 0:00:05  loss: 0.4814 (0.4814)  time: 0.3997  data: 0.3831  max mem: 20571\n",
      "Valid: [epoch:333]  [13/14]  eta: 0:00:00  loss: 0.4863 (0.5023)  time: 0.0430  data: 0.0279  max mem: 20571\n",
      "Valid: [epoch:333] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.4863 (0.5023)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_333_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.502%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:334]  [  0/172]  eta: 0:07:46  lr: 0.000074  loss: 0.4873 (0.4873)  time: 2.7125  data: 1.1431  max mem: 20571\n",
      "Train: [epoch:334]  [ 10/172]  eta: 0:04:32  lr: 0.000074  loss: 0.5202 (0.5269)  time: 1.6828  data: 0.1041  max mem: 20571\n",
      "Train: [epoch:334]  [ 20/172]  eta: 0:04:08  lr: 0.000074  loss: 0.5254 (0.5357)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:334]  [ 30/172]  eta: 0:03:49  lr: 0.000074  loss: 0.5254 (0.5302)  time: 1.5819  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:334]  [ 40/172]  eta: 0:03:32  lr: 0.000074  loss: 0.5217 (0.5285)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [ 50/172]  eta: 0:03:15  lr: 0.000074  loss: 0.5142 (0.5262)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [ 60/172]  eta: 0:02:59  lr: 0.000074  loss: 0.5121 (0.5280)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [ 70/172]  eta: 0:02:42  lr: 0.000074  loss: 0.5174 (0.5266)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [ 80/172]  eta: 0:02:26  lr: 0.000074  loss: 0.5218 (0.5273)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [ 90/172]  eta: 0:02:10  lr: 0.000074  loss: 0.5240 (0.5260)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [100/172]  eta: 0:01:54  lr: 0.000074  loss: 0.5220 (0.5269)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [110/172]  eta: 0:01:38  lr: 0.000074  loss: 0.5290 (0.5270)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [120/172]  eta: 0:01:22  lr: 0.000074  loss: 0.5161 (0.5276)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [130/172]  eta: 0:01:06  lr: 0.000074  loss: 0.5174 (0.5274)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [140/172]  eta: 0:00:50  lr: 0.000074  loss: 0.5189 (0.5274)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [150/172]  eta: 0:00:34  lr: 0.000074  loss: 0.5235 (0.5273)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [160/172]  eta: 0:00:19  lr: 0.000074  loss: 0.5278 (0.5275)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [170/172]  eta: 0:00:03  lr: 0.000074  loss: 0.5318 (0.5277)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334]  [171/172]  eta: 0:00:01  lr: 0.000074  loss: 0.5328 (0.5278)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:334] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000074  loss: 0.5328 (0.5278)\n",
      "Valid: [epoch:334]  [ 0/14]  eta: 0:00:04  loss: 0.4320 (0.4320)  time: 0.3364  data: 0.3203  max mem: 20571\n",
      "Valid: [epoch:334]  [13/14]  eta: 0:00:00  loss: 0.4877 (0.5049)  time: 0.0409  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:334] Total time: 0:00:00 (0.0488 s / it)\n",
      "Averaged stats: loss: 0.4877 (0.5049)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_334_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.505%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:335]  [  0/172]  eta: 0:07:39  lr: 0.000074  loss: 0.4814 (0.4814)  time: 2.6725  data: 1.0785  max mem: 20571\n",
      "Train: [epoch:335]  [ 10/172]  eta: 0:04:31  lr: 0.000074  loss: 0.5273 (0.5343)  time: 1.6775  data: 0.0982  max mem: 20571\n",
      "Train: [epoch:335]  [ 20/172]  eta: 0:04:07  lr: 0.000074  loss: 0.5489 (0.5426)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [ 30/172]  eta: 0:03:49  lr: 0.000074  loss: 0.5348 (0.5367)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [ 40/172]  eta: 0:03:32  lr: 0.000074  loss: 0.5344 (0.5374)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [ 50/172]  eta: 0:03:15  lr: 0.000074  loss: 0.5378 (0.5345)  time: 1.5839  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:335]  [ 60/172]  eta: 0:02:59  lr: 0.000074  loss: 0.5201 (0.5315)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [ 70/172]  eta: 0:02:42  lr: 0.000074  loss: 0.5302 (0.5336)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [ 80/172]  eta: 0:02:26  lr: 0.000074  loss: 0.5446 (0.5330)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [ 90/172]  eta: 0:02:10  lr: 0.000074  loss: 0.5165 (0.5316)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [100/172]  eta: 0:01:54  lr: 0.000074  loss: 0.5083 (0.5297)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [110/172]  eta: 0:01:38  lr: 0.000074  loss: 0.5078 (0.5300)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [120/172]  eta: 0:01:22  lr: 0.000074  loss: 0.5115 (0.5300)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [130/172]  eta: 0:01:06  lr: 0.000074  loss: 0.5324 (0.5294)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [140/172]  eta: 0:00:50  lr: 0.000074  loss: 0.5180 (0.5285)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [150/172]  eta: 0:00:34  lr: 0.000074  loss: 0.5180 (0.5277)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [160/172]  eta: 0:00:19  lr: 0.000074  loss: 0.5271 (0.5280)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [170/172]  eta: 0:00:03  lr: 0.000074  loss: 0.5271 (0.5278)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335]  [171/172]  eta: 0:00:01  lr: 0.000074  loss: 0.5271 (0.5281)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:335] Total time: 0:04:33 (1.5905 s / it)\n",
      "Averaged stats: lr: 0.000074  loss: 0.5271 (0.5281)\n",
      "Valid: [epoch:335]  [ 0/14]  eta: 0:00:04  loss: 0.5364 (0.5364)  time: 0.3057  data: 0.2899  max mem: 20571\n",
      "Valid: [epoch:335]  [13/14]  eta: 0:00:00  loss: 0.4773 (0.4948)  time: 0.0400  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:335] Total time: 0:00:00 (0.0450 s / it)\n",
      "Averaged stats: loss: 0.4773 (0.4948)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_335_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.495%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:336]  [  0/172]  eta: 0:07:27  lr: 0.000074  loss: 0.4767 (0.4767)  time: 2.6018  data: 1.0213  max mem: 20571\n",
      "Train: [epoch:336]  [ 10/172]  eta: 0:04:31  lr: 0.000074  loss: 0.5200 (0.5218)  time: 1.6743  data: 0.0929  max mem: 20571\n",
      "Train: [epoch:336]  [ 20/172]  eta: 0:04:07  lr: 0.000074  loss: 0.5199 (0.5254)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [ 30/172]  eta: 0:03:49  lr: 0.000074  loss: 0.5191 (0.5233)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [ 40/172]  eta: 0:03:32  lr: 0.000074  loss: 0.5140 (0.5218)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [ 50/172]  eta: 0:03:15  lr: 0.000074  loss: 0.5330 (0.5260)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [ 60/172]  eta: 0:02:59  lr: 0.000074  loss: 0.5227 (0.5241)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [ 70/172]  eta: 0:02:42  lr: 0.000074  loss: 0.5204 (0.5269)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [ 80/172]  eta: 0:02:26  lr: 0.000074  loss: 0.5386 (0.5270)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [ 90/172]  eta: 0:02:10  lr: 0.000074  loss: 0.5231 (0.5268)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [100/172]  eta: 0:01:54  lr: 0.000074  loss: 0.5103 (0.5255)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [110/172]  eta: 0:01:38  lr: 0.000074  loss: 0.5088 (0.5251)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [120/172]  eta: 0:01:22  lr: 0.000074  loss: 0.5138 (0.5250)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [130/172]  eta: 0:01:06  lr: 0.000074  loss: 0.5282 (0.5250)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [140/172]  eta: 0:00:50  lr: 0.000074  loss: 0.5119 (0.5249)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [150/172]  eta: 0:00:34  lr: 0.000074  loss: 0.5116 (0.5255)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [160/172]  eta: 0:00:19  lr: 0.000074  loss: 0.5270 (0.5269)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [170/172]  eta: 0:00:03  lr: 0.000074  loss: 0.5346 (0.5278)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336]  [171/172]  eta: 0:00:01  lr: 0.000074  loss: 0.5346 (0.5276)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:336] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000074  loss: 0.5346 (0.5276)\n",
      "Valid: [epoch:336]  [ 0/14]  eta: 0:00:04  loss: 0.5539 (0.5539)  time: 0.3424  data: 0.3269  max mem: 20571\n",
      "Valid: [epoch:336]  [13/14]  eta: 0:00:00  loss: 0.4959 (0.5132)  time: 0.0387  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:336] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.4959 (0.5132)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_336_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.513%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:337]  [  0/172]  eta: 0:07:17  lr: 0.000074  loss: 0.5051 (0.5051)  time: 2.5462  data: 0.9576  max mem: 20571\n",
      "Train: [epoch:337]  [ 10/172]  eta: 0:04:29  lr: 0.000074  loss: 0.5197 (0.5360)  time: 1.6662  data: 0.0872  max mem: 20571\n",
      "Train: [epoch:337]  [ 20/172]  eta: 0:04:07  lr: 0.000074  loss: 0.5230 (0.5311)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [ 30/172]  eta: 0:03:48  lr: 0.000074  loss: 0.5221 (0.5299)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [ 40/172]  eta: 0:03:31  lr: 0.000074  loss: 0.5299 (0.5300)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [ 50/172]  eta: 0:03:15  lr: 0.000074  loss: 0.5318 (0.5313)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [ 60/172]  eta: 0:02:58  lr: 0.000074  loss: 0.5220 (0.5298)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [ 70/172]  eta: 0:02:42  lr: 0.000074  loss: 0.5141 (0.5274)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [ 80/172]  eta: 0:02:26  lr: 0.000074  loss: 0.5079 (0.5273)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [ 90/172]  eta: 0:02:10  lr: 0.000074  loss: 0.5342 (0.5282)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [100/172]  eta: 0:01:54  lr: 0.000074  loss: 0.5339 (0.5285)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [110/172]  eta: 0:01:38  lr: 0.000074  loss: 0.5329 (0.5288)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [120/172]  eta: 0:01:22  lr: 0.000074  loss: 0.5355 (0.5292)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [130/172]  eta: 0:01:06  lr: 0.000074  loss: 0.5340 (0.5290)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [140/172]  eta: 0:00:50  lr: 0.000074  loss: 0.5330 (0.5292)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [150/172]  eta: 0:00:34  lr: 0.000074  loss: 0.5330 (0.5293)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [160/172]  eta: 0:00:19  lr: 0.000074  loss: 0.5306 (0.5286)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [170/172]  eta: 0:00:03  lr: 0.000074  loss: 0.5165 (0.5281)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337]  [171/172]  eta: 0:00:01  lr: 0.000074  loss: 0.5165 (0.5282)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:337] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000074  loss: 0.5165 (0.5282)\n",
      "Valid: [epoch:337]  [ 0/14]  eta: 0:00:04  loss: 0.4286 (0.4286)  time: 0.3302  data: 0.3148  max mem: 20571\n",
      "Valid: [epoch:337]  [13/14]  eta: 0:00:00  loss: 0.4856 (0.5029)  time: 0.0388  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:337] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.4856 (0.5029)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_337_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.503%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:338]  [  0/172]  eta: 0:07:49  lr: 0.000074  loss: 0.5361 (0.5361)  time: 2.7310  data: 1.1635  max mem: 20571\n",
      "Train: [epoch:338]  [ 10/172]  eta: 0:04:32  lr: 0.000074  loss: 0.5269 (0.5286)  time: 1.6850  data: 0.1059  max mem: 20571\n",
      "Train: [epoch:338]  [ 20/172]  eta: 0:04:08  lr: 0.000074  loss: 0.5269 (0.5304)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [ 30/172]  eta: 0:03:49  lr: 0.000074  loss: 0.5223 (0.5295)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [ 40/172]  eta: 0:03:32  lr: 0.000074  loss: 0.5149 (0.5286)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [ 50/172]  eta: 0:03:15  lr: 0.000074  loss: 0.5345 (0.5316)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [ 60/172]  eta: 0:02:59  lr: 0.000074  loss: 0.5322 (0.5296)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [ 70/172]  eta: 0:02:42  lr: 0.000074  loss: 0.5254 (0.5317)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [ 80/172]  eta: 0:02:26  lr: 0.000074  loss: 0.5381 (0.5328)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [ 90/172]  eta: 0:02:10  lr: 0.000074  loss: 0.5388 (0.5326)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [100/172]  eta: 0:01:54  lr: 0.000074  loss: 0.5427 (0.5341)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [110/172]  eta: 0:01:38  lr: 0.000074  loss: 0.5248 (0.5328)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [120/172]  eta: 0:01:22  lr: 0.000074  loss: 0.5142 (0.5322)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [130/172]  eta: 0:01:06  lr: 0.000074  loss: 0.5143 (0.5310)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [140/172]  eta: 0:00:50  lr: 0.000074  loss: 0.5173 (0.5304)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [150/172]  eta: 0:00:34  lr: 0.000074  loss: 0.5042 (0.5295)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [160/172]  eta: 0:00:19  lr: 0.000074  loss: 0.5221 (0.5300)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [170/172]  eta: 0:00:03  lr: 0.000074  loss: 0.5291 (0.5297)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338]  [171/172]  eta: 0:00:01  lr: 0.000074  loss: 0.5206 (0.5296)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:338] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000074  loss: 0.5206 (0.5296)\n",
      "Valid: [epoch:338]  [ 0/14]  eta: 0:00:03  loss: 0.5702 (0.5702)  time: 0.2775  data: 0.2625  max mem: 20571\n",
      "Valid: [epoch:338]  [13/14]  eta: 0:00:00  loss: 0.5105 (0.5281)  time: 0.0364  data: 0.0211  max mem: 20571\n",
      "Valid: [epoch:338] Total time: 0:00:00 (0.0440 s / it)\n",
      "Averaged stats: loss: 0.5105 (0.5281)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_338_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.528%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:339]  [  0/172]  eta: 0:07:22  lr: 0.000074  loss: 0.5293 (0.5293)  time: 2.5739  data: 0.9953  max mem: 20571\n",
      "Train: [epoch:339]  [ 10/172]  eta: 0:04:30  lr: 0.000074  loss: 0.5293 (0.5312)  time: 1.6681  data: 0.0906  max mem: 20571\n",
      "Train: [epoch:339]  [ 20/172]  eta: 0:04:07  lr: 0.000074  loss: 0.5313 (0.5368)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [ 30/172]  eta: 0:03:48  lr: 0.000074  loss: 0.5254 (0.5288)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [ 40/172]  eta: 0:03:31  lr: 0.000074  loss: 0.5118 (0.5286)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [ 50/172]  eta: 0:03:15  lr: 0.000074  loss: 0.5297 (0.5326)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [ 60/172]  eta: 0:02:58  lr: 0.000074  loss: 0.5260 (0.5310)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [ 70/172]  eta: 0:02:42  lr: 0.000074  loss: 0.5140 (0.5296)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [ 80/172]  eta: 0:02:26  lr: 0.000074  loss: 0.5148 (0.5282)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [ 90/172]  eta: 0:02:10  lr: 0.000074  loss: 0.5278 (0.5286)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [100/172]  eta: 0:01:54  lr: 0.000074  loss: 0.5278 (0.5292)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [110/172]  eta: 0:01:38  lr: 0.000074  loss: 0.5180 (0.5287)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [120/172]  eta: 0:01:22  lr: 0.000074  loss: 0.5180 (0.5276)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [130/172]  eta: 0:01:06  lr: 0.000074  loss: 0.5189 (0.5276)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [140/172]  eta: 0:00:50  lr: 0.000074  loss: 0.5277 (0.5282)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [150/172]  eta: 0:00:34  lr: 0.000074  loss: 0.5272 (0.5279)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [160/172]  eta: 0:00:19  lr: 0.000074  loss: 0.5267 (0.5278)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [170/172]  eta: 0:00:03  lr: 0.000074  loss: 0.5284 (0.5287)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339]  [171/172]  eta: 0:00:01  lr: 0.000074  loss: 0.5306 (0.5288)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:339] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000074  loss: 0.5306 (0.5288)\n",
      "Valid: [epoch:339]  [ 0/14]  eta: 0:00:04  loss: 0.5678 (0.5678)  time: 0.3267  data: 0.3117  max mem: 20571\n",
      "Valid: [epoch:339]  [13/14]  eta: 0:00:00  loss: 0.5075 (0.5224)  time: 0.0376  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:339] Total time: 0:00:00 (0.0434 s / it)\n",
      "Averaged stats: loss: 0.5075 (0.5224)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_339_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.522%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:340]  [  0/172]  eta: 0:07:09  lr: 0.000073  loss: 0.5008 (0.5008)  time: 2.4977  data: 0.9277  max mem: 20571\n",
      "Train: [epoch:340]  [ 10/172]  eta: 0:04:29  lr: 0.000073  loss: 0.5485 (0.5363)  time: 1.6648  data: 0.0844  max mem: 20571\n",
      "Train: [epoch:340]  [ 20/172]  eta: 0:04:07  lr: 0.000073  loss: 0.5485 (0.5362)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [ 30/172]  eta: 0:03:48  lr: 0.000073  loss: 0.5294 (0.5317)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [ 40/172]  eta: 0:03:31  lr: 0.000073  loss: 0.5207 (0.5269)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [ 50/172]  eta: 0:03:15  lr: 0.000073  loss: 0.5168 (0.5270)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [ 60/172]  eta: 0:02:58  lr: 0.000073  loss: 0.5236 (0.5261)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [ 70/172]  eta: 0:02:42  lr: 0.000073  loss: 0.5217 (0.5253)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [ 80/172]  eta: 0:02:26  lr: 0.000073  loss: 0.5183 (0.5252)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [ 90/172]  eta: 0:02:10  lr: 0.000073  loss: 0.5165 (0.5237)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [100/172]  eta: 0:01:54  lr: 0.000073  loss: 0.5161 (0.5226)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [110/172]  eta: 0:01:38  lr: 0.000073  loss: 0.5218 (0.5248)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [120/172]  eta: 0:01:22  lr: 0.000073  loss: 0.5452 (0.5261)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [130/172]  eta: 0:01:06  lr: 0.000073  loss: 0.5277 (0.5257)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [140/172]  eta: 0:00:50  lr: 0.000073  loss: 0.5159 (0.5248)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [150/172]  eta: 0:00:34  lr: 0.000073  loss: 0.5246 (0.5257)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [160/172]  eta: 0:00:19  lr: 0.000073  loss: 0.5246 (0.5249)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340]  [170/172]  eta: 0:00:03  lr: 0.000073  loss: 0.5136 (0.5254)  time: 1.5831  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:340]  [171/172]  eta: 0:00:01  lr: 0.000073  loss: 0.5136 (0.5252)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:340] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000073  loss: 0.5136 (0.5252)\n",
      "Valid: [epoch:340]  [ 0/14]  eta: 0:00:04  loss: 0.4249 (0.4249)  time: 0.3153  data: 0.2982  max mem: 20571\n",
      "Valid: [epoch:340]  [13/14]  eta: 0:00:00  loss: 0.4821 (0.4990)  time: 0.0382  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:340] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.4821 (0.4990)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_340_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.499%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:341]  [  0/172]  eta: 0:07:38  lr: 0.000073  loss: 0.4945 (0.4945)  time: 2.6636  data: 1.0825  max mem: 20571\n",
      "Train: [epoch:341]  [ 10/172]  eta: 0:04:31  lr: 0.000073  loss: 0.5269 (0.5123)  time: 1.6764  data: 0.0985  max mem: 20571\n",
      "Train: [epoch:341]  [ 20/172]  eta: 0:04:07  lr: 0.000073  loss: 0.5125 (0.5156)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [ 30/172]  eta: 0:03:49  lr: 0.000073  loss: 0.5179 (0.5226)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [ 40/172]  eta: 0:03:32  lr: 0.000073  loss: 0.5318 (0.5234)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [ 50/172]  eta: 0:03:15  lr: 0.000073  loss: 0.5273 (0.5256)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [ 60/172]  eta: 0:02:58  lr: 0.000073  loss: 0.5193 (0.5252)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [ 70/172]  eta: 0:02:42  lr: 0.000073  loss: 0.5215 (0.5267)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [ 80/172]  eta: 0:02:26  lr: 0.000073  loss: 0.5317 (0.5272)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [ 90/172]  eta: 0:02:10  lr: 0.000073  loss: 0.5217 (0.5265)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [100/172]  eta: 0:01:54  lr: 0.000073  loss: 0.5185 (0.5263)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [110/172]  eta: 0:01:38  lr: 0.000073  loss: 0.5205 (0.5262)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [120/172]  eta: 0:01:22  lr: 0.000073  loss: 0.5300 (0.5271)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [130/172]  eta: 0:01:06  lr: 0.000073  loss: 0.5232 (0.5265)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [140/172]  eta: 0:00:50  lr: 0.000073  loss: 0.5178 (0.5259)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [150/172]  eta: 0:00:34  lr: 0.000073  loss: 0.5168 (0.5262)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [160/172]  eta: 0:00:19  lr: 0.000073  loss: 0.5102 (0.5257)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [170/172]  eta: 0:00:03  lr: 0.000073  loss: 0.5104 (0.5259)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341]  [171/172]  eta: 0:00:01  lr: 0.000073  loss: 0.5104 (0.5259)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:341] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000073  loss: 0.5104 (0.5259)\n",
      "Valid: [epoch:341]  [ 0/14]  eta: 0:00:03  loss: 0.4927 (0.4927)  time: 0.2775  data: 0.2618  max mem: 20571\n",
      "Valid: [epoch:341]  [13/14]  eta: 0:00:00  loss: 0.4927 (0.5100)  time: 0.0427  data: 0.0277  max mem: 20571\n",
      "Valid: [epoch:341] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.4927 (0.5100)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_341_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.510%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:342]  [  0/172]  eta: 0:07:37  lr: 0.000073  loss: 0.5619 (0.5619)  time: 2.6612  data: 1.0928  max mem: 20571\n",
      "Train: [epoch:342]  [ 10/172]  eta: 0:04:31  lr: 0.000073  loss: 0.5433 (0.5395)  time: 1.6771  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:342]  [ 20/172]  eta: 0:04:08  lr: 0.000073  loss: 0.5287 (0.5384)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [ 30/172]  eta: 0:03:49  lr: 0.000073  loss: 0.5287 (0.5327)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [ 40/172]  eta: 0:03:32  lr: 0.000073  loss: 0.5225 (0.5306)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [ 50/172]  eta: 0:03:15  lr: 0.000073  loss: 0.5184 (0.5293)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [ 60/172]  eta: 0:02:59  lr: 0.000073  loss: 0.5165 (0.5280)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [ 70/172]  eta: 0:02:42  lr: 0.000073  loss: 0.5197 (0.5300)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [ 80/172]  eta: 0:02:26  lr: 0.000073  loss: 0.5444 (0.5310)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [ 90/172]  eta: 0:02:10  lr: 0.000073  loss: 0.5348 (0.5314)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [100/172]  eta: 0:01:54  lr: 0.000073  loss: 0.5289 (0.5318)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [110/172]  eta: 0:01:38  lr: 0.000073  loss: 0.5245 (0.5311)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [120/172]  eta: 0:01:22  lr: 0.000073  loss: 0.5215 (0.5307)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [130/172]  eta: 0:01:06  lr: 0.000073  loss: 0.5116 (0.5296)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [140/172]  eta: 0:00:50  lr: 0.000073  loss: 0.5071 (0.5296)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [150/172]  eta: 0:00:34  lr: 0.000073  loss: 0.5314 (0.5299)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [160/172]  eta: 0:00:19  lr: 0.000073  loss: 0.5314 (0.5298)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [170/172]  eta: 0:00:03  lr: 0.000073  loss: 0.5316 (0.5303)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342]  [171/172]  eta: 0:00:01  lr: 0.000073  loss: 0.5316 (0.5306)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:342] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000073  loss: 0.5316 (0.5306)\n",
      "Valid: [epoch:342]  [ 0/14]  eta: 0:00:06  loss: 0.5605 (0.5605)  time: 0.4342  data: 0.4192  max mem: 20571\n",
      "Valid: [epoch:342]  [13/14]  eta: 0:00:00  loss: 0.5018 (0.5162)  time: 0.0460  data: 0.0312  max mem: 20571\n",
      "Valid: [epoch:342] Total time: 0:00:00 (0.0513 s / it)\n",
      "Averaged stats: loss: 0.5018 (0.5162)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_342_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.516%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:343]  [  0/172]  eta: 0:07:19  lr: 0.000073  loss: 0.5014 (0.5014)  time: 2.5573  data: 0.9805  max mem: 20571\n",
      "Train: [epoch:343]  [ 10/172]  eta: 0:04:30  lr: 0.000073  loss: 0.5309 (0.5352)  time: 1.6673  data: 0.0893  max mem: 20571\n",
      "Train: [epoch:343]  [ 20/172]  eta: 0:04:07  lr: 0.000073  loss: 0.5309 (0.5389)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [ 30/172]  eta: 0:03:48  lr: 0.000073  loss: 0.5236 (0.5309)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [ 40/172]  eta: 0:03:31  lr: 0.000073  loss: 0.5113 (0.5267)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [ 50/172]  eta: 0:03:15  lr: 0.000073  loss: 0.5146 (0.5270)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [ 60/172]  eta: 0:02:58  lr: 0.000073  loss: 0.5141 (0.5254)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [ 70/172]  eta: 0:02:42  lr: 0.000073  loss: 0.5410 (0.5286)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [ 80/172]  eta: 0:02:26  lr: 0.000073  loss: 0.5384 (0.5282)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [ 90/172]  eta: 0:02:10  lr: 0.000073  loss: 0.5215 (0.5291)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [100/172]  eta: 0:01:54  lr: 0.000073  loss: 0.5311 (0.5310)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [110/172]  eta: 0:01:38  lr: 0.000073  loss: 0.5272 (0.5292)  time: 1.5814  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:343]  [120/172]  eta: 0:01:22  lr: 0.000073  loss: 0.5081 (0.5280)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [130/172]  eta: 0:01:06  lr: 0.000073  loss: 0.5142 (0.5275)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [140/172]  eta: 0:00:50  lr: 0.000073  loss: 0.5264 (0.5274)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [150/172]  eta: 0:00:34  lr: 0.000073  loss: 0.5285 (0.5283)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [160/172]  eta: 0:00:19  lr: 0.000073  loss: 0.5285 (0.5287)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [170/172]  eta: 0:00:03  lr: 0.000073  loss: 0.5215 (0.5278)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343]  [171/172]  eta: 0:00:01  lr: 0.000073  loss: 0.5215 (0.5279)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:343] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000073  loss: 0.5215 (0.5279)\n",
      "Valid: [epoch:343]  [ 0/14]  eta: 0:00:04  loss: 0.5346 (0.5346)  time: 0.3290  data: 0.3141  max mem: 20571\n",
      "Valid: [epoch:343]  [13/14]  eta: 0:00:00  loss: 0.4971 (0.5158)  time: 0.0376  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:343] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.4971 (0.5158)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_343_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.516%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:344]  [  0/172]  eta: 0:07:21  lr: 0.000073  loss: 0.5363 (0.5363)  time: 2.5682  data: 0.9984  max mem: 20571\n",
      "Train: [epoch:344]  [ 10/172]  eta: 0:04:30  lr: 0.000073  loss: 0.5218 (0.5260)  time: 1.6713  data: 0.0909  max mem: 20571\n",
      "Train: [epoch:344]  [ 20/172]  eta: 0:04:07  lr: 0.000073  loss: 0.5207 (0.5242)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [ 30/172]  eta: 0:03:49  lr: 0.000073  loss: 0.5177 (0.5275)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [ 40/172]  eta: 0:03:32  lr: 0.000073  loss: 0.5246 (0.5278)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [ 50/172]  eta: 0:03:15  lr: 0.000073  loss: 0.5277 (0.5275)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [ 60/172]  eta: 0:02:59  lr: 0.000073  loss: 0.5274 (0.5294)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [ 70/172]  eta: 0:02:42  lr: 0.000073  loss: 0.5268 (0.5285)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [ 80/172]  eta: 0:02:26  lr: 0.000073  loss: 0.5377 (0.5288)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [ 90/172]  eta: 0:02:10  lr: 0.000073  loss: 0.5307 (0.5280)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [100/172]  eta: 0:01:54  lr: 0.000073  loss: 0.5196 (0.5279)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [110/172]  eta: 0:01:38  lr: 0.000073  loss: 0.5180 (0.5271)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [120/172]  eta: 0:01:22  lr: 0.000073  loss: 0.5184 (0.5270)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [130/172]  eta: 0:01:06  lr: 0.000073  loss: 0.5338 (0.5273)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [140/172]  eta: 0:00:50  lr: 0.000073  loss: 0.5326 (0.5268)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [150/172]  eta: 0:00:34  lr: 0.000073  loss: 0.5182 (0.5260)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [160/172]  eta: 0:00:19  lr: 0.000073  loss: 0.5183 (0.5258)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [170/172]  eta: 0:00:03  lr: 0.000073  loss: 0.5254 (0.5262)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344]  [171/172]  eta: 0:00:01  lr: 0.000073  loss: 0.5254 (0.5261)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:344] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000073  loss: 0.5254 (0.5261)\n",
      "Valid: [epoch:344]  [ 0/14]  eta: 0:00:04  loss: 0.4682 (0.4682)  time: 0.3153  data: 0.2980  max mem: 20571\n",
      "Valid: [epoch:344]  [13/14]  eta: 0:00:00  loss: 0.4816 (0.4991)  time: 0.0411  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:344] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.4816 (0.4991)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_344_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.499%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:345]  [  0/172]  eta: 0:07:27  lr: 0.000073  loss: 0.4886 (0.4886)  time: 2.6017  data: 1.0212  max mem: 20571\n",
      "Train: [epoch:345]  [ 10/172]  eta: 0:04:30  lr: 0.000073  loss: 0.5171 (0.5166)  time: 1.6688  data: 0.0929  max mem: 20571\n",
      "Train: [epoch:345]  [ 20/172]  eta: 0:04:07  lr: 0.000073  loss: 0.5171 (0.5217)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [ 30/172]  eta: 0:03:48  lr: 0.000073  loss: 0.5158 (0.5255)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [ 40/172]  eta: 0:03:31  lr: 0.000073  loss: 0.5165 (0.5249)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:345]  [ 50/172]  eta: 0:03:15  lr: 0.000073  loss: 0.5269 (0.5255)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:345]  [ 60/172]  eta: 0:02:58  lr: 0.000073  loss: 0.5153 (0.5242)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:345]  [ 70/172]  eta: 0:02:42  lr: 0.000073  loss: 0.5130 (0.5247)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [ 80/172]  eta: 0:02:26  lr: 0.000073  loss: 0.5302 (0.5265)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [ 90/172]  eta: 0:02:10  lr: 0.000073  loss: 0.5294 (0.5267)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [100/172]  eta: 0:01:54  lr: 0.000073  loss: 0.5259 (0.5269)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [110/172]  eta: 0:01:38  lr: 0.000073  loss: 0.5211 (0.5269)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [120/172]  eta: 0:01:22  lr: 0.000073  loss: 0.5232 (0.5284)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [130/172]  eta: 0:01:06  lr: 0.000073  loss: 0.5456 (0.5294)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [140/172]  eta: 0:00:50  lr: 0.000073  loss: 0.5372 (0.5292)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [150/172]  eta: 0:00:34  lr: 0.000073  loss: 0.5199 (0.5298)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [160/172]  eta: 0:00:19  lr: 0.000073  loss: 0.5176 (0.5287)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [170/172]  eta: 0:00:03  lr: 0.000073  loss: 0.5035 (0.5280)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345]  [171/172]  eta: 0:00:01  lr: 0.000073  loss: 0.5073 (0.5286)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:345] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000073  loss: 0.5073 (0.5286)\n",
      "Valid: [epoch:345]  [ 0/14]  eta: 0:00:06  loss: 0.5442 (0.5442)  time: 0.4338  data: 0.4187  max mem: 20571\n",
      "Valid: [epoch:345]  [13/14]  eta: 0:00:00  loss: 0.4855 (0.5037)  time: 0.0462  data: 0.0313  max mem: 20571\n",
      "Valid: [epoch:345] Total time: 0:00:00 (0.0516 s / it)\n",
      "Averaged stats: loss: 0.4855 (0.5037)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_345_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.504%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:346]  [  0/172]  eta: 0:08:08  lr: 0.000073  loss: 0.5140 (0.5140)  time: 2.8414  data: 1.2743  max mem: 20571\n",
      "Train: [epoch:346]  [ 10/172]  eta: 0:04:34  lr: 0.000073  loss: 0.5241 (0.5272)  time: 1.6939  data: 0.1160  max mem: 20571\n",
      "Train: [epoch:346]  [ 20/172]  eta: 0:04:09  lr: 0.000073  loss: 0.5241 (0.5248)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [ 30/172]  eta: 0:03:50  lr: 0.000073  loss: 0.5194 (0.5249)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [ 40/172]  eta: 0:03:32  lr: 0.000073  loss: 0.5121 (0.5243)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [ 50/172]  eta: 0:03:15  lr: 0.000073  loss: 0.5188 (0.5268)  time: 1.5814  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:346]  [ 60/172]  eta: 0:02:59  lr: 0.000073  loss: 0.5350 (0.5294)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [ 70/172]  eta: 0:02:43  lr: 0.000073  loss: 0.5401 (0.5319)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:346]  [ 80/172]  eta: 0:02:26  lr: 0.000073  loss: 0.5343 (0.5315)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:346]  [ 90/172]  eta: 0:02:10  lr: 0.000073  loss: 0.5303 (0.5317)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [100/172]  eta: 0:01:54  lr: 0.000073  loss: 0.5195 (0.5314)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [110/172]  eta: 0:01:38  lr: 0.000073  loss: 0.5105 (0.5304)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [120/172]  eta: 0:01:22  lr: 0.000073  loss: 0.5105 (0.5293)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [130/172]  eta: 0:01:06  lr: 0.000073  loss: 0.5059 (0.5286)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [140/172]  eta: 0:00:50  lr: 0.000073  loss: 0.5157 (0.5292)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [150/172]  eta: 0:00:34  lr: 0.000073  loss: 0.5236 (0.5278)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [160/172]  eta: 0:00:19  lr: 0.000073  loss: 0.5151 (0.5283)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [170/172]  eta: 0:00:03  lr: 0.000073  loss: 0.5155 (0.5280)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346]  [171/172]  eta: 0:00:01  lr: 0.000073  loss: 0.5155 (0.5281)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:346] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000073  loss: 0.5155 (0.5281)\n",
      "Valid: [epoch:346]  [ 0/14]  eta: 0:00:03  loss: 0.5423 (0.5423)  time: 0.2797  data: 0.2650  max mem: 20571\n",
      "Valid: [epoch:346]  [13/14]  eta: 0:00:00  loss: 0.4862 (0.5026)  time: 0.0357  data: 0.0207  max mem: 20571\n",
      "Valid: [epoch:346] Total time: 0:00:00 (0.0405 s / it)\n",
      "Averaged stats: loss: 0.4862 (0.5026)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_346_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.503%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:347]  [  0/172]  eta: 0:07:28  lr: 0.000073  loss: 0.5213 (0.5213)  time: 2.6073  data: 1.0284  max mem: 20571\n",
      "Train: [epoch:347]  [ 10/172]  eta: 0:04:30  lr: 0.000073  loss: 0.5213 (0.5294)  time: 1.6707  data: 0.0936  max mem: 20571\n",
      "Train: [epoch:347]  [ 20/172]  eta: 0:04:07  lr: 0.000073  loss: 0.5284 (0.5292)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [ 30/172]  eta: 0:03:48  lr: 0.000073  loss: 0.5284 (0.5285)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [ 40/172]  eta: 0:03:31  lr: 0.000073  loss: 0.5055 (0.5230)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [ 50/172]  eta: 0:03:15  lr: 0.000073  loss: 0.5225 (0.5280)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [ 60/172]  eta: 0:02:58  lr: 0.000073  loss: 0.5278 (0.5259)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [ 70/172]  eta: 0:02:42  lr: 0.000073  loss: 0.5118 (0.5260)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [ 80/172]  eta: 0:02:26  lr: 0.000073  loss: 0.5122 (0.5248)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [ 90/172]  eta: 0:02:10  lr: 0.000073  loss: 0.5193 (0.5261)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [100/172]  eta: 0:01:54  lr: 0.000073  loss: 0.5223 (0.5257)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [110/172]  eta: 0:01:38  lr: 0.000073  loss: 0.5223 (0.5260)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [120/172]  eta: 0:01:22  lr: 0.000073  loss: 0.5211 (0.5267)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [130/172]  eta: 0:01:06  lr: 0.000073  loss: 0.5293 (0.5264)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [140/172]  eta: 0:00:50  lr: 0.000073  loss: 0.5293 (0.5264)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [150/172]  eta: 0:00:34  lr: 0.000073  loss: 0.5211 (0.5267)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:347]  [160/172]  eta: 0:00:19  lr: 0.000073  loss: 0.5283 (0.5275)  time: 1.5837  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:347]  [170/172]  eta: 0:00:03  lr: 0.000073  loss: 0.5330 (0.5275)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347]  [171/172]  eta: 0:00:01  lr: 0.000073  loss: 0.5330 (0.5276)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:347] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000073  loss: 0.5330 (0.5276)\n",
      "Valid: [epoch:347]  [ 0/14]  eta: 0:00:04  loss: 0.4664 (0.4664)  time: 0.2880  data: 0.2729  max mem: 20571\n",
      "Valid: [epoch:347]  [13/14]  eta: 0:00:00  loss: 0.4800 (0.4975)  time: 0.0360  data: 0.0212  max mem: 20571\n",
      "Valid: [epoch:347] Total time: 0:00:00 (0.0440 s / it)\n",
      "Averaged stats: loss: 0.4800 (0.4975)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_347_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.497%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:348]  [  0/172]  eta: 0:08:00  lr: 0.000073  loss: 0.5056 (0.5056)  time: 2.7916  data: 1.2213  max mem: 20571\n",
      "Train: [epoch:348]  [ 10/172]  eta: 0:04:34  lr: 0.000073  loss: 0.5209 (0.5251)  time: 1.6914  data: 0.1112  max mem: 20571\n",
      "Train: [epoch:348]  [ 20/172]  eta: 0:04:09  lr: 0.000073  loss: 0.5335 (0.5322)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [ 30/172]  eta: 0:03:50  lr: 0.000073  loss: 0.5321 (0.5333)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [ 40/172]  eta: 0:03:32  lr: 0.000073  loss: 0.5315 (0.5329)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [ 50/172]  eta: 0:03:15  lr: 0.000073  loss: 0.5201 (0.5305)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [ 60/172]  eta: 0:02:59  lr: 0.000073  loss: 0.5184 (0.5302)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [ 70/172]  eta: 0:02:43  lr: 0.000073  loss: 0.5263 (0.5299)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [ 80/172]  eta: 0:02:26  lr: 0.000073  loss: 0.5314 (0.5314)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [ 90/172]  eta: 0:02:10  lr: 0.000073  loss: 0.5294 (0.5316)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [100/172]  eta: 0:01:54  lr: 0.000073  loss: 0.5203 (0.5294)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [110/172]  eta: 0:01:38  lr: 0.000073  loss: 0.5039 (0.5288)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [120/172]  eta: 0:01:22  lr: 0.000073  loss: 0.5142 (0.5282)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [130/172]  eta: 0:01:06  lr: 0.000073  loss: 0.5170 (0.5271)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [140/172]  eta: 0:00:50  lr: 0.000073  loss: 0.5115 (0.5264)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [150/172]  eta: 0:00:34  lr: 0.000073  loss: 0.5204 (0.5278)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [160/172]  eta: 0:00:19  lr: 0.000073  loss: 0.5396 (0.5287)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [170/172]  eta: 0:00:03  lr: 0.000073  loss: 0.5344 (0.5298)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348]  [171/172]  eta: 0:00:01  lr: 0.000073  loss: 0.5362 (0.5299)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:348] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000073  loss: 0.5362 (0.5299)\n",
      "Valid: [epoch:348]  [ 0/14]  eta: 0:00:04  loss: 0.4927 (0.4927)  time: 0.3153  data: 0.3001  max mem: 20571\n",
      "Valid: [epoch:348]  [13/14]  eta: 0:00:00  loss: 0.4927 (0.5095)  time: 0.0451  data: 0.0301  max mem: 20571\n",
      "Valid: [epoch:348] Total time: 0:00:00 (0.0528 s / it)\n",
      "Averaged stats: loss: 0.4927 (0.5095)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_348_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.509%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:349]  [  0/172]  eta: 0:07:47  lr: 0.000072  loss: 0.5788 (0.5788)  time: 2.7164  data: 1.1361  max mem: 20571\n",
      "Train: [epoch:349]  [ 10/172]  eta: 0:04:32  lr: 0.000072  loss: 0.5482 (0.5463)  time: 1.6801  data: 0.1034  max mem: 20571\n",
      "Train: [epoch:349]  [ 20/172]  eta: 0:04:07  lr: 0.000072  loss: 0.5304 (0.5346)  time: 1.5773  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:349]  [ 30/172]  eta: 0:03:49  lr: 0.000072  loss: 0.5197 (0.5318)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:349]  [ 40/172]  eta: 0:03:32  lr: 0.000072  loss: 0.5169 (0.5281)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [ 50/172]  eta: 0:03:15  lr: 0.000072  loss: 0.5194 (0.5300)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [ 60/172]  eta: 0:02:58  lr: 0.000072  loss: 0.5322 (0.5294)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [ 70/172]  eta: 0:02:42  lr: 0.000072  loss: 0.5310 (0.5303)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [ 80/172]  eta: 0:02:26  lr: 0.000072  loss: 0.5261 (0.5299)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [ 90/172]  eta: 0:02:10  lr: 0.000072  loss: 0.5261 (0.5287)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [100/172]  eta: 0:01:54  lr: 0.000072  loss: 0.5154 (0.5292)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [110/172]  eta: 0:01:38  lr: 0.000072  loss: 0.5110 (0.5284)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [120/172]  eta: 0:01:22  lr: 0.000072  loss: 0.5096 (0.5283)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [130/172]  eta: 0:01:06  lr: 0.000072  loss: 0.5173 (0.5275)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [140/172]  eta: 0:00:50  lr: 0.000072  loss: 0.5247 (0.5278)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [150/172]  eta: 0:00:34  lr: 0.000072  loss: 0.5290 (0.5284)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [160/172]  eta: 0:00:19  lr: 0.000072  loss: 0.5171 (0.5277)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [170/172]  eta: 0:00:03  lr: 0.000072  loss: 0.5183 (0.5278)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:349]  [171/172]  eta: 0:00:01  lr: 0.000072  loss: 0.5194 (0.5277)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:349] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000072  loss: 0.5194 (0.5277)\n",
      "Valid: [epoch:349]  [ 0/14]  eta: 0:00:06  loss: 0.5430 (0.5430)  time: 0.4413  data: 0.4236  max mem: 20571\n",
      "Valid: [epoch:349]  [13/14]  eta: 0:00:00  loss: 0.4856 (0.5020)  time: 0.0466  data: 0.0315  max mem: 20571\n",
      "Valid: [epoch:349] Total time: 0:00:00 (0.0547 s / it)\n",
      "Averaged stats: loss: 0.4856 (0.5020)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_349_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.502%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:350]  [  0/172]  eta: 0:07:40  lr: 0.000072  loss: 0.5050 (0.5050)  time: 2.6787  data: 1.0885  max mem: 20571\n",
      "Train: [epoch:350]  [ 10/172]  eta: 0:04:32  lr: 0.000072  loss: 0.5193 (0.5285)  time: 1.6824  data: 0.0991  max mem: 20571\n",
      "Train: [epoch:350]  [ 20/172]  eta: 0:04:08  lr: 0.000072  loss: 0.5256 (0.5370)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:350]  [ 30/172]  eta: 0:03:49  lr: 0.000072  loss: 0.5256 (0.5338)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:350]  [ 40/172]  eta: 0:03:32  lr: 0.000072  loss: 0.5079 (0.5316)  time: 1.5838  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:350]  [ 50/172]  eta: 0:03:15  lr: 0.000072  loss: 0.5171 (0.5322)  time: 1.5836  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:350]  [ 60/172]  eta: 0:02:59  lr: 0.000072  loss: 0.5219 (0.5296)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:350]  [ 70/172]  eta: 0:02:42  lr: 0.000072  loss: 0.5132 (0.5291)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [ 80/172]  eta: 0:02:26  lr: 0.000072  loss: 0.5189 (0.5307)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [ 90/172]  eta: 0:02:10  lr: 0.000072  loss: 0.5261 (0.5304)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [100/172]  eta: 0:01:54  lr: 0.000072  loss: 0.5080 (0.5293)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [110/172]  eta: 0:01:38  lr: 0.000072  loss: 0.5180 (0.5300)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [120/172]  eta: 0:01:22  lr: 0.000072  loss: 0.5243 (0.5300)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [130/172]  eta: 0:01:06  lr: 0.000072  loss: 0.5211 (0.5300)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [140/172]  eta: 0:00:50  lr: 0.000072  loss: 0.5211 (0.5292)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [150/172]  eta: 0:00:34  lr: 0.000072  loss: 0.5267 (0.5291)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:350]  [160/172]  eta: 0:00:19  lr: 0.000072  loss: 0.5330 (0.5291)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [170/172]  eta: 0:00:03  lr: 0.000072  loss: 0.5243 (0.5292)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350]  [171/172]  eta: 0:00:01  lr: 0.000072  loss: 0.5151 (0.5291)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:350] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000072  loss: 0.5151 (0.5291)\n",
      "Valid: [epoch:350]  [ 0/14]  eta: 0:00:04  loss: 0.5480 (0.5480)  time: 0.2954  data: 0.2797  max mem: 20571\n",
      "Valid: [epoch:350]  [13/14]  eta: 0:00:00  loss: 0.4849 (0.5013)  time: 0.0391  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:350] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.4849 (0.5013)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_350_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.501%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:351]  [  0/172]  eta: 0:08:08  lr: 0.000072  loss: 0.5681 (0.5681)  time: 2.8422  data: 1.2629  max mem: 20571\n",
      "Train: [epoch:351]  [ 10/172]  eta: 0:04:34  lr: 0.000072  loss: 0.5404 (0.5416)  time: 1.6928  data: 0.1149  max mem: 20571\n",
      "Train: [epoch:351]  [ 20/172]  eta: 0:04:09  lr: 0.000072  loss: 0.5382 (0.5392)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:351]  [ 30/172]  eta: 0:03:49  lr: 0.000072  loss: 0.5347 (0.5375)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:351]  [ 40/172]  eta: 0:03:32  lr: 0.000072  loss: 0.5123 (0.5319)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:351]  [ 50/172]  eta: 0:03:15  lr: 0.000072  loss: 0.5229 (0.5359)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:351]  [ 60/172]  eta: 0:02:59  lr: 0.000072  loss: 0.5336 (0.5333)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:351]  [ 70/172]  eta: 0:02:42  lr: 0.000072  loss: 0.5187 (0.5341)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:351]  [ 80/172]  eta: 0:02:26  lr: 0.000072  loss: 0.5472 (0.5361)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:351]  [ 90/172]  eta: 0:02:10  lr: 0.000072  loss: 0.5379 (0.5362)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:351]  [100/172]  eta: 0:01:54  lr: 0.000072  loss: 0.5235 (0.5343)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:351]  [110/172]  eta: 0:01:38  lr: 0.000072  loss: 0.5212 (0.5339)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:351]  [120/172]  eta: 0:01:22  lr: 0.000072  loss: 0.5250 (0.5339)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:351]  [130/172]  eta: 0:01:06  lr: 0.000072  loss: 0.5201 (0.5327)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:351]  [140/172]  eta: 0:00:50  lr: 0.000072  loss: 0.5184 (0.5321)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:351]  [150/172]  eta: 0:00:34  lr: 0.000072  loss: 0.5182 (0.5310)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:351]  [160/172]  eta: 0:00:19  lr: 0.000072  loss: 0.5062 (0.5297)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:351]  [170/172]  eta: 0:00:03  lr: 0.000072  loss: 0.5234 (0.5303)  time: 1.5824  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:351]  [171/172]  eta: 0:00:01  lr: 0.000072  loss: 0.5234 (0.5301)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:351] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000072  loss: 0.5234 (0.5301)\n",
      "Valid: [epoch:351]  [ 0/14]  eta: 0:00:05  loss: 0.5175 (0.5175)  time: 0.3964  data: 0.3812  max mem: 20571\n",
      "Valid: [epoch:351]  [13/14]  eta: 0:00:00  loss: 0.4783 (0.4956)  time: 0.0426  data: 0.0274  max mem: 20571\n",
      "Valid: [epoch:351] Total time: 0:00:00 (0.0483 s / it)\n",
      "Averaged stats: loss: 0.4783 (0.4956)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_351_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.496%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:352]  [  0/172]  eta: 0:08:40  lr: 0.000072  loss: 0.6378 (0.6378)  time: 3.0290  data: 1.4456  max mem: 20571\n",
      "Train: [epoch:352]  [ 10/172]  eta: 0:04:37  lr: 0.000072  loss: 0.5123 (0.5111)  time: 1.7108  data: 0.1315  max mem: 20571\n",
      "Train: [epoch:352]  [ 20/172]  eta: 0:04:10  lr: 0.000072  loss: 0.5172 (0.5262)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [ 30/172]  eta: 0:03:50  lr: 0.000072  loss: 0.5183 (0.5263)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [ 40/172]  eta: 0:03:33  lr: 0.000072  loss: 0.5064 (0.5272)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [ 50/172]  eta: 0:03:16  lr: 0.000072  loss: 0.5164 (0.5247)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [ 60/172]  eta: 0:02:59  lr: 0.000072  loss: 0.5289 (0.5277)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:352]  [ 70/172]  eta: 0:02:43  lr: 0.000072  loss: 0.5213 (0.5262)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:352]  [ 80/172]  eta: 0:02:27  lr: 0.000072  loss: 0.5171 (0.5275)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [ 90/172]  eta: 0:02:10  lr: 0.000072  loss: 0.5340 (0.5289)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [100/172]  eta: 0:01:54  lr: 0.000072  loss: 0.5274 (0.5292)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [110/172]  eta: 0:01:38  lr: 0.000072  loss: 0.5458 (0.5312)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [120/172]  eta: 0:01:22  lr: 0.000072  loss: 0.5458 (0.5320)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [130/172]  eta: 0:01:06  lr: 0.000072  loss: 0.5199 (0.5309)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [140/172]  eta: 0:00:50  lr: 0.000072  loss: 0.5102 (0.5304)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:352]  [150/172]  eta: 0:00:34  lr: 0.000072  loss: 0.5102 (0.5293)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [160/172]  eta: 0:00:19  lr: 0.000072  loss: 0.5249 (0.5293)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [170/172]  eta: 0:00:03  lr: 0.000072  loss: 0.5277 (0.5292)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352]  [171/172]  eta: 0:00:01  lr: 0.000072  loss: 0.5279 (0.5296)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:352] Total time: 0:04:33 (1.5905 s / it)\n",
      "Averaged stats: lr: 0.000072  loss: 0.5279 (0.5296)\n",
      "Valid: [epoch:352]  [ 0/14]  eta: 0:00:06  loss: 0.4792 (0.4792)  time: 0.4480  data: 0.4313  max mem: 20571\n",
      "Valid: [epoch:352]  [13/14]  eta: 0:00:00  loss: 0.4932 (0.5090)  time: 0.0461  data: 0.0309  max mem: 20571\n",
      "Valid: [epoch:352] Total time: 0:00:00 (0.0544 s / it)\n",
      "Averaged stats: loss: 0.4932 (0.5090)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_352_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.509%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:353]  [  0/172]  eta: 0:08:31  lr: 0.000072  loss: 0.5093 (0.5093)  time: 2.9736  data: 1.3950  max mem: 20571\n",
      "Train: [epoch:353]  [ 10/172]  eta: 0:04:36  lr: 0.000072  loss: 0.5152 (0.5156)  time: 1.7064  data: 0.1269  max mem: 20571\n",
      "Train: [epoch:353]  [ 20/172]  eta: 0:04:10  lr: 0.000072  loss: 0.5290 (0.5355)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:353]  [ 30/172]  eta: 0:03:50  lr: 0.000072  loss: 0.5267 (0.5311)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [ 40/172]  eta: 0:03:33  lr: 0.000072  loss: 0.5245 (0.5293)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [ 50/172]  eta: 0:03:16  lr: 0.000072  loss: 0.5245 (0.5289)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [ 60/172]  eta: 0:02:59  lr: 0.000072  loss: 0.5287 (0.5286)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [ 70/172]  eta: 0:02:43  lr: 0.000072  loss: 0.5235 (0.5273)  time: 1.5831  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [ 80/172]  eta: 0:02:27  lr: 0.000072  loss: 0.5177 (0.5269)  time: 1.5845  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [ 90/172]  eta: 0:02:10  lr: 0.000072  loss: 0.5220 (0.5265)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [100/172]  eta: 0:01:54  lr: 0.000072  loss: 0.5234 (0.5265)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [110/172]  eta: 0:01:38  lr: 0.000072  loss: 0.5234 (0.5268)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [120/172]  eta: 0:01:22  lr: 0.000072  loss: 0.5266 (0.5275)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:353]  [130/172]  eta: 0:01:06  lr: 0.000072  loss: 0.5267 (0.5280)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:353]  [140/172]  eta: 0:00:50  lr: 0.000072  loss: 0.5266 (0.5278)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:353]  [150/172]  eta: 0:00:35  lr: 0.000072  loss: 0.5235 (0.5270)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:353]  [160/172]  eta: 0:00:19  lr: 0.000072  loss: 0.5293 (0.5274)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:353]  [170/172]  eta: 0:00:03  lr: 0.000072  loss: 0.5352 (0.5282)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:353]  [171/172]  eta: 0:00:01  lr: 0.000072  loss: 0.5402 (0.5283)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:353] Total time: 0:04:33 (1.5909 s / it)\n",
      "Averaged stats: lr: 0.000072  loss: 0.5402 (0.5283)\n",
      "Valid: [epoch:353]  [ 0/14]  eta: 0:00:06  loss: 0.4675 (0.4675)  time: 0.4648  data: 0.4470  max mem: 20571\n",
      "Valid: [epoch:353]  [13/14]  eta: 0:00:00  loss: 0.4821 (0.4985)  time: 0.0485  data: 0.0332  max mem: 20571\n",
      "Valid: [epoch:353] Total time: 0:00:00 (0.0568 s / it)\n",
      "Averaged stats: loss: 0.4821 (0.4985)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_353_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.499%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:354]  [  0/172]  eta: 0:08:05  lr: 0.000072  loss: 0.5051 (0.5051)  time: 2.8256  data: 1.2465  max mem: 20571\n",
      "Train: [epoch:354]  [ 10/172]  eta: 0:04:34  lr: 0.000072  loss: 0.5366 (0.5243)  time: 1.6936  data: 0.1135  max mem: 20571\n",
      "Train: [epoch:354]  [ 20/172]  eta: 0:04:09  lr: 0.000072  loss: 0.5366 (0.5320)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:354]  [ 30/172]  eta: 0:03:50  lr: 0.000072  loss: 0.5332 (0.5328)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [ 40/172]  eta: 0:03:32  lr: 0.000072  loss: 0.5116 (0.5259)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [ 50/172]  eta: 0:03:15  lr: 0.000072  loss: 0.4987 (0.5258)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [ 60/172]  eta: 0:02:59  lr: 0.000072  loss: 0.5204 (0.5289)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [ 70/172]  eta: 0:02:43  lr: 0.000072  loss: 0.5180 (0.5273)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [ 80/172]  eta: 0:02:26  lr: 0.000072  loss: 0.5135 (0.5266)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [ 90/172]  eta: 0:02:10  lr: 0.000072  loss: 0.5141 (0.5269)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:354]  [100/172]  eta: 0:01:54  lr: 0.000072  loss: 0.5239 (0.5276)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:354]  [110/172]  eta: 0:01:38  lr: 0.000072  loss: 0.5471 (0.5286)  time: 1.5817  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:354]  [120/172]  eta: 0:01:22  lr: 0.000072  loss: 0.5307 (0.5289)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [130/172]  eta: 0:01:06  lr: 0.000072  loss: 0.5292 (0.5292)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [140/172]  eta: 0:00:50  lr: 0.000072  loss: 0.5278 (0.5287)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [150/172]  eta: 0:00:34  lr: 0.000072  loss: 0.5206 (0.5282)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [160/172]  eta: 0:00:19  lr: 0.000072  loss: 0.5258 (0.5285)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [170/172]  eta: 0:00:03  lr: 0.000072  loss: 0.5288 (0.5286)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354]  [171/172]  eta: 0:00:01  lr: 0.000072  loss: 0.5299 (0.5288)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:354] Total time: 0:04:33 (1.5901 s / it)\n",
      "Averaged stats: lr: 0.000072  loss: 0.5299 (0.5288)\n",
      "Valid: [epoch:354]  [ 0/14]  eta: 0:00:04  loss: 0.4210 (0.4210)  time: 0.3315  data: 0.3089  max mem: 20571\n",
      "Valid: [epoch:354]  [13/14]  eta: 0:00:00  loss: 0.4807 (0.4978)  time: 0.0411  data: 0.0253  max mem: 20571\n",
      "Valid: [epoch:354] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.4807 (0.4978)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_354_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.498%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:355]  [  0/172]  eta: 0:07:46  lr: 0.000072  loss: 0.5285 (0.5285)  time: 2.7121  data: 1.1333  max mem: 20571\n",
      "Train: [epoch:355]  [ 10/172]  eta: 0:04:32  lr: 0.000072  loss: 0.5266 (0.5256)  time: 1.6801  data: 0.1032  max mem: 20571\n",
      "Train: [epoch:355]  [ 20/172]  eta: 0:04:08  lr: 0.000072  loss: 0.5266 (0.5295)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [ 30/172]  eta: 0:03:49  lr: 0.000072  loss: 0.5291 (0.5284)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [ 40/172]  eta: 0:03:32  lr: 0.000072  loss: 0.5304 (0.5306)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:355]  [ 50/172]  eta: 0:03:15  lr: 0.000072  loss: 0.5193 (0.5303)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [ 60/172]  eta: 0:02:59  lr: 0.000072  loss: 0.5170 (0.5298)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [ 70/172]  eta: 0:02:42  lr: 0.000072  loss: 0.5339 (0.5331)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [ 80/172]  eta: 0:02:26  lr: 0.000072  loss: 0.5339 (0.5311)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [ 90/172]  eta: 0:02:10  lr: 0.000072  loss: 0.5275 (0.5317)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [100/172]  eta: 0:01:54  lr: 0.000072  loss: 0.5283 (0.5320)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [110/172]  eta: 0:01:38  lr: 0.000072  loss: 0.5253 (0.5311)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [120/172]  eta: 0:01:22  lr: 0.000072  loss: 0.5216 (0.5311)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [130/172]  eta: 0:01:06  lr: 0.000072  loss: 0.5293 (0.5312)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [140/172]  eta: 0:00:50  lr: 0.000072  loss: 0.5293 (0.5313)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [150/172]  eta: 0:00:34  lr: 0.000072  loss: 0.5246 (0.5313)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [160/172]  eta: 0:00:19  lr: 0.000072  loss: 0.5246 (0.5314)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [170/172]  eta: 0:00:03  lr: 0.000072  loss: 0.5219 (0.5322)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355]  [171/172]  eta: 0:00:01  lr: 0.000072  loss: 0.5226 (0.5321)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:355] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000072  loss: 0.5226 (0.5321)\n",
      "Valid: [epoch:355]  [ 0/14]  eta: 0:00:04  loss: 0.5484 (0.5484)  time: 0.3018  data: 0.2862  max mem: 20571\n",
      "Valid: [epoch:355]  [13/14]  eta: 0:00:00  loss: 0.4798 (0.4977)  time: 0.0376  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:355] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.4798 (0.4977)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_355_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.498%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:356]  [  0/172]  eta: 0:07:33  lr: 0.000072  loss: 0.5230 (0.5230)  time: 2.6382  data: 1.0698  max mem: 20571\n",
      "Train: [epoch:356]  [ 10/172]  eta: 0:04:31  lr: 0.000072  loss: 0.5230 (0.5255)  time: 1.6756  data: 0.0974  max mem: 20571\n",
      "Train: [epoch:356]  [ 20/172]  eta: 0:04:07  lr: 0.000072  loss: 0.5163 (0.5215)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [ 30/172]  eta: 0:03:49  lr: 0.000072  loss: 0.5230 (0.5271)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [ 40/172]  eta: 0:03:31  lr: 0.000072  loss: 0.5384 (0.5262)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [ 50/172]  eta: 0:03:15  lr: 0.000072  loss: 0.5257 (0.5298)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [ 60/172]  eta: 0:02:58  lr: 0.000072  loss: 0.5188 (0.5303)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [ 70/172]  eta: 0:02:42  lr: 0.000072  loss: 0.5346 (0.5304)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:356]  [ 80/172]  eta: 0:02:26  lr: 0.000072  loss: 0.5341 (0.5303)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [ 90/172]  eta: 0:02:10  lr: 0.000072  loss: 0.5136 (0.5299)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:356]  [100/172]  eta: 0:01:54  lr: 0.000072  loss: 0.5557 (0.5331)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:356]  [110/172]  eta: 0:01:38  lr: 0.000072  loss: 0.5607 (0.5331)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [120/172]  eta: 0:01:22  lr: 0.000072  loss: 0.5360 (0.5337)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [130/172]  eta: 0:01:06  lr: 0.000072  loss: 0.5449 (0.5352)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [140/172]  eta: 0:00:50  lr: 0.000072  loss: 0.5203 (0.5346)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:356]  [150/172]  eta: 0:00:34  lr: 0.000072  loss: 0.5116 (0.5341)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:356]  [160/172]  eta: 0:00:19  lr: 0.000072  loss: 0.5144 (0.5336)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:356]  [170/172]  eta: 0:00:03  lr: 0.000072  loss: 0.5205 (0.5334)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:356]  [171/172]  eta: 0:00:01  lr: 0.000072  loss: 0.5151 (0.5332)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:356] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000072  loss: 0.5151 (0.5332)\n",
      "Valid: [epoch:356]  [ 0/14]  eta: 0:00:09  loss: 0.4310 (0.4310)  time: 0.6923  data: 0.6769  max mem: 20571\n",
      "Valid: [epoch:356]  [13/14]  eta: 0:00:00  loss: 0.4809 (0.4989)  time: 0.0638  data: 0.0485  max mem: 20571\n",
      "Valid: [epoch:356] Total time: 0:00:01 (0.0719 s / it)\n",
      "Averaged stats: loss: 0.4809 (0.4989)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_356_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.499%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:357]  [  0/172]  eta: 0:07:33  lr: 0.000072  loss: 0.5531 (0.5531)  time: 2.6338  data: 1.0552  max mem: 20571\n",
      "Train: [epoch:357]  [ 10/172]  eta: 0:04:31  lr: 0.000072  loss: 0.5190 (0.5192)  time: 1.6736  data: 0.0960  max mem: 20571\n",
      "Train: [epoch:357]  [ 20/172]  eta: 0:04:07  lr: 0.000072  loss: 0.5190 (0.5243)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357]  [ 30/172]  eta: 0:03:49  lr: 0.000072  loss: 0.5239 (0.5252)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357]  [ 40/172]  eta: 0:03:31  lr: 0.000072  loss: 0.5239 (0.5269)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357]  [ 50/172]  eta: 0:03:15  lr: 0.000072  loss: 0.5217 (0.5272)  time: 1.5800  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:357]  [ 60/172]  eta: 0:02:58  lr: 0.000072  loss: 0.5271 (0.5286)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357]  [ 70/172]  eta: 0:02:42  lr: 0.000072  loss: 0.5365 (0.5289)  time: 1.5796  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:357]  [ 80/172]  eta: 0:02:26  lr: 0.000072  loss: 0.5200 (0.5283)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:357]  [ 90/172]  eta: 0:02:10  lr: 0.000072  loss: 0.5246 (0.5281)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:357]  [100/172]  eta: 0:01:54  lr: 0.000072  loss: 0.5330 (0.5296)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:357]  [110/172]  eta: 0:01:38  lr: 0.000072  loss: 0.5330 (0.5292)  time: 1.5832  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:357]  [120/172]  eta: 0:01:22  lr: 0.000072  loss: 0.5239 (0.5292)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:357]  [130/172]  eta: 0:01:06  lr: 0.000072  loss: 0.5154 (0.5298)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357]  [140/172]  eta: 0:00:50  lr: 0.000072  loss: 0.5151 (0.5285)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357]  [150/172]  eta: 0:00:34  lr: 0.000072  loss: 0.5096 (0.5277)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357]  [160/172]  eta: 0:00:19  lr: 0.000072  loss: 0.5155 (0.5278)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357]  [170/172]  eta: 0:00:03  lr: 0.000072  loss: 0.5444 (0.5292)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357]  [171/172]  eta: 0:00:01  lr: 0.000072  loss: 0.5444 (0.5293)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:357] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000072  loss: 0.5444 (0.5293)\n",
      "Valid: [epoch:357]  [ 0/14]  eta: 0:00:07  loss: 0.5491 (0.5491)  time: 0.5624  data: 0.5444  max mem: 20571\n",
      "Valid: [epoch:357]  [13/14]  eta: 0:00:00  loss: 0.4811 (0.4983)  time: 0.0555  data: 0.0402  max mem: 20571\n",
      "Valid: [epoch:357] Total time: 0:00:00 (0.0635 s / it)\n",
      "Averaged stats: loss: 0.4811 (0.4983)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_357_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.498%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:358]  [  0/172]  eta: 0:07:38  lr: 0.000071  loss: 0.4754 (0.4754)  time: 2.6656  data: 1.0959  max mem: 20571\n",
      "Train: [epoch:358]  [ 10/172]  eta: 0:04:32  lr: 0.000071  loss: 0.5277 (0.5382)  time: 1.6811  data: 0.0998  max mem: 20571\n",
      "Train: [epoch:358]  [ 20/172]  eta: 0:04:08  lr: 0.000071  loss: 0.5277 (0.5348)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:358]  [ 30/172]  eta: 0:03:49  lr: 0.000071  loss: 0.5231 (0.5307)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [ 40/172]  eta: 0:03:32  lr: 0.000071  loss: 0.5329 (0.5316)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [ 50/172]  eta: 0:03:15  lr: 0.000071  loss: 0.5339 (0.5314)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [ 60/172]  eta: 0:02:59  lr: 0.000071  loss: 0.5304 (0.5320)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [ 70/172]  eta: 0:02:42  lr: 0.000071  loss: 0.5268 (0.5304)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [ 80/172]  eta: 0:02:26  lr: 0.000071  loss: 0.5048 (0.5302)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [ 90/172]  eta: 0:02:10  lr: 0.000071  loss: 0.5266 (0.5303)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [100/172]  eta: 0:01:54  lr: 0.000071  loss: 0.5264 (0.5309)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [110/172]  eta: 0:01:38  lr: 0.000071  loss: 0.5370 (0.5313)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [120/172]  eta: 0:01:22  lr: 0.000071  loss: 0.5400 (0.5323)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [130/172]  eta: 0:01:06  lr: 0.000071  loss: 0.5298 (0.5318)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [140/172]  eta: 0:00:50  lr: 0.000071  loss: 0.5288 (0.5321)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [150/172]  eta: 0:00:34  lr: 0.000071  loss: 0.5194 (0.5315)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [160/172]  eta: 0:00:19  lr: 0.000071  loss: 0.5194 (0.5316)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [170/172]  eta: 0:00:03  lr: 0.000071  loss: 0.5375 (0.5310)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358]  [171/172]  eta: 0:00:01  lr: 0.000071  loss: 0.5375 (0.5308)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:358] Total time: 0:04:33 (1.5904 s / it)\n",
      "Averaged stats: lr: 0.000071  loss: 0.5375 (0.5308)\n",
      "Valid: [epoch:358]  [ 0/14]  eta: 0:00:05  loss: 0.5471 (0.5471)  time: 0.3996  data: 0.3848  max mem: 20571\n",
      "Valid: [epoch:358]  [13/14]  eta: 0:00:00  loss: 0.4891 (0.5059)  time: 0.0551  data: 0.0402  max mem: 20571\n",
      "Valid: [epoch:358] Total time: 0:00:00 (0.0631 s / it)\n",
      "Averaged stats: loss: 0.4891 (0.5059)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_358_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.506%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:359]  [  0/172]  eta: 0:07:38  lr: 0.000071  loss: 0.5152 (0.5152)  time: 2.6654  data: 1.0742  max mem: 20571\n",
      "Train: [epoch:359]  [ 10/172]  eta: 0:04:31  lr: 0.000071  loss: 0.5251 (0.5326)  time: 1.6775  data: 0.0978  max mem: 20571\n",
      "Train: [epoch:359]  [ 20/172]  eta: 0:04:07  lr: 0.000071  loss: 0.5315 (0.5349)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:359]  [ 30/172]  eta: 0:03:49  lr: 0.000071  loss: 0.5180 (0.5340)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [ 40/172]  eta: 0:03:32  lr: 0.000071  loss: 0.5174 (0.5295)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [ 50/172]  eta: 0:03:15  lr: 0.000071  loss: 0.5071 (0.5263)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [ 60/172]  eta: 0:02:59  lr: 0.000071  loss: 0.5233 (0.5269)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [ 70/172]  eta: 0:02:43  lr: 0.000071  loss: 0.5315 (0.5279)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [ 80/172]  eta: 0:02:26  lr: 0.000071  loss: 0.5410 (0.5301)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [ 90/172]  eta: 0:02:10  lr: 0.000071  loss: 0.5177 (0.5294)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [100/172]  eta: 0:01:54  lr: 0.000071  loss: 0.5249 (0.5297)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [110/172]  eta: 0:01:38  lr: 0.000071  loss: 0.5239 (0.5293)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [120/172]  eta: 0:01:22  lr: 0.000071  loss: 0.5161 (0.5287)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [130/172]  eta: 0:01:06  lr: 0.000071  loss: 0.5320 (0.5304)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [140/172]  eta: 0:00:50  lr: 0.000071  loss: 0.5335 (0.5306)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [150/172]  eta: 0:00:34  lr: 0.000071  loss: 0.5254 (0.5309)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [160/172]  eta: 0:00:19  lr: 0.000071  loss: 0.5208 (0.5309)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359]  [170/172]  eta: 0:00:03  lr: 0.000071  loss: 0.5241 (0.5309)  time: 1.5837  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:359]  [171/172]  eta: 0:00:01  lr: 0.000071  loss: 0.5241 (0.5306)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:359] Total time: 0:04:33 (1.5907 s / it)\n",
      "Averaged stats: lr: 0.000071  loss: 0.5241 (0.5306)\n",
      "Valid: [epoch:359]  [ 0/14]  eta: 0:00:06  loss: 0.5488 (0.5488)  time: 0.4654  data: 0.4503  max mem: 20571\n",
      "Valid: [epoch:359]  [13/14]  eta: 0:00:00  loss: 0.4861 (0.5036)  time: 0.0479  data: 0.0328  max mem: 20571\n",
      "Valid: [epoch:359] Total time: 0:00:00 (0.0526 s / it)\n",
      "Averaged stats: loss: 0.4861 (0.5036)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_359_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.504%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:360]  [  0/172]  eta: 0:07:37  lr: 0.000071  loss: 0.5074 (0.5074)  time: 2.6590  data: 1.0877  max mem: 20571\n",
      "Train: [epoch:360]  [ 10/172]  eta: 0:04:32  lr: 0.000071  loss: 0.5386 (0.5382)  time: 1.6806  data: 0.0990  max mem: 20571\n",
      "Train: [epoch:360]  [ 20/172]  eta: 0:04:08  lr: 0.000071  loss: 0.5374 (0.5351)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [ 30/172]  eta: 0:03:49  lr: 0.000071  loss: 0.5287 (0.5326)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [ 40/172]  eta: 0:03:32  lr: 0.000071  loss: 0.5284 (0.5331)  time: 1.5839  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:360]  [ 50/172]  eta: 0:03:15  lr: 0.000071  loss: 0.5294 (0.5361)  time: 1.5835  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:360]  [ 60/172]  eta: 0:02:59  lr: 0.000071  loss: 0.5259 (0.5347)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [ 70/172]  eta: 0:02:43  lr: 0.000071  loss: 0.5220 (0.5335)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [ 80/172]  eta: 0:02:26  lr: 0.000071  loss: 0.5275 (0.5326)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [ 90/172]  eta: 0:02:10  lr: 0.000071  loss: 0.5396 (0.5337)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [100/172]  eta: 0:01:54  lr: 0.000071  loss: 0.5437 (0.5343)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [110/172]  eta: 0:01:38  lr: 0.000071  loss: 0.5247 (0.5341)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [120/172]  eta: 0:01:22  lr: 0.000071  loss: 0.5228 (0.5338)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:360]  [130/172]  eta: 0:01:06  lr: 0.000071  loss: 0.5228 (0.5326)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [140/172]  eta: 0:00:50  lr: 0.000071  loss: 0.5246 (0.5327)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [150/172]  eta: 0:00:34  lr: 0.000071  loss: 0.5225 (0.5317)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [160/172]  eta: 0:00:19  lr: 0.000071  loss: 0.5204 (0.5317)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [170/172]  eta: 0:00:03  lr: 0.000071  loss: 0.5251 (0.5319)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360]  [171/172]  eta: 0:00:01  lr: 0.000071  loss: 0.5251 (0.5319)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:360] Total time: 0:04:33 (1.5902 s / it)\n",
      "Averaged stats: lr: 0.000071  loss: 0.5251 (0.5319)\n",
      "Valid: [epoch:360]  [ 0/14]  eta: 0:00:05  loss: 0.5612 (0.5612)  time: 0.3823  data: 0.3669  max mem: 20571\n",
      "Valid: [epoch:360]  [13/14]  eta: 0:00:00  loss: 0.4947 (0.5129)  time: 0.0428  data: 0.0277  max mem: 20571\n",
      "Valid: [epoch:360] Total time: 0:00:00 (0.0502 s / it)\n",
      "Averaged stats: loss: 0.4947 (0.5129)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_360_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.513%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:361]  [  0/172]  eta: 0:08:21  lr: 0.000071  loss: 0.4978 (0.4978)  time: 2.9185  data: 1.3448  max mem: 20571\n",
      "Train: [epoch:361]  [ 10/172]  eta: 0:04:34  lr: 0.000071  loss: 0.5142 (0.5185)  time: 1.6975  data: 0.1224  max mem: 20571\n",
      "Train: [epoch:361]  [ 20/172]  eta: 0:04:09  lr: 0.000071  loss: 0.5277 (0.5290)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:361]  [ 30/172]  eta: 0:03:50  lr: 0.000071  loss: 0.5425 (0.5326)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [ 40/172]  eta: 0:03:32  lr: 0.000071  loss: 0.5394 (0.5312)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [ 50/172]  eta: 0:03:15  lr: 0.000071  loss: 0.5301 (0.5321)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [ 60/172]  eta: 0:02:59  lr: 0.000071  loss: 0.5256 (0.5305)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [ 70/172]  eta: 0:02:42  lr: 0.000071  loss: 0.5303 (0.5319)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [ 80/172]  eta: 0:02:26  lr: 0.000071  loss: 0.5413 (0.5331)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [ 90/172]  eta: 0:02:10  lr: 0.000071  loss: 0.5455 (0.5330)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [100/172]  eta: 0:01:54  lr: 0.000071  loss: 0.5375 (0.5328)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [110/172]  eta: 0:01:38  lr: 0.000071  loss: 0.5379 (0.5334)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [120/172]  eta: 0:01:22  lr: 0.000071  loss: 0.5351 (0.5333)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [130/172]  eta: 0:01:06  lr: 0.000071  loss: 0.5255 (0.5334)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [140/172]  eta: 0:00:50  lr: 0.000071  loss: 0.5234 (0.5329)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [150/172]  eta: 0:00:34  lr: 0.000071  loss: 0.5214 (0.5329)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [160/172]  eta: 0:00:19  lr: 0.000071  loss: 0.5180 (0.5328)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [170/172]  eta: 0:00:03  lr: 0.000071  loss: 0.5320 (0.5332)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361]  [171/172]  eta: 0:00:01  lr: 0.000071  loss: 0.5391 (0.5333)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:361] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000071  loss: 0.5391 (0.5333)\n",
      "Valid: [epoch:361]  [ 0/14]  eta: 0:00:06  loss: 0.5020 (0.5020)  time: 0.4365  data: 0.4184  max mem: 20571\n",
      "Valid: [epoch:361]  [13/14]  eta: 0:00:00  loss: 0.5195 (0.5352)  time: 0.0461  data: 0.0309  max mem: 20571\n",
      "Valid: [epoch:361] Total time: 0:00:00 (0.0518 s / it)\n",
      "Averaged stats: loss: 0.5195 (0.5352)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_361_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.535%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:362]  [  0/172]  eta: 0:08:17  lr: 0.000071  loss: 0.6328 (0.6328)  time: 2.8919  data: 1.3245  max mem: 20571\n",
      "Train: [epoch:362]  [ 10/172]  eta: 0:04:35  lr: 0.000071  loss: 0.5349 (0.5410)  time: 1.7008  data: 0.1205  max mem: 20571\n",
      "Train: [epoch:362]  [ 20/172]  eta: 0:04:09  lr: 0.000071  loss: 0.5288 (0.5377)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [ 30/172]  eta: 0:03:50  lr: 0.000071  loss: 0.5367 (0.5380)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [ 40/172]  eta: 0:03:33  lr: 0.000071  loss: 0.5232 (0.5356)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [ 50/172]  eta: 0:03:16  lr: 0.000071  loss: 0.5199 (0.5371)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [ 60/172]  eta: 0:02:59  lr: 0.000071  loss: 0.5287 (0.5361)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [ 70/172]  eta: 0:02:43  lr: 0.000071  loss: 0.5244 (0.5355)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [ 80/172]  eta: 0:02:27  lr: 0.000071  loss: 0.5244 (0.5349)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [ 90/172]  eta: 0:02:10  lr: 0.000071  loss: 0.5179 (0.5335)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [100/172]  eta: 0:01:54  lr: 0.000071  loss: 0.5236 (0.5344)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [110/172]  eta: 0:01:38  lr: 0.000071  loss: 0.5236 (0.5345)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [120/172]  eta: 0:01:22  lr: 0.000071  loss: 0.5214 (0.5338)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [130/172]  eta: 0:01:06  lr: 0.000071  loss: 0.5178 (0.5332)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [140/172]  eta: 0:00:50  lr: 0.000071  loss: 0.5211 (0.5329)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [150/172]  eta: 0:00:35  lr: 0.000071  loss: 0.5284 (0.5328)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [160/172]  eta: 0:00:19  lr: 0.000071  loss: 0.5272 (0.5328)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362]  [170/172]  eta: 0:00:03  lr: 0.000071  loss: 0.5330 (0.5333)  time: 1.5853  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:362]  [171/172]  eta: 0:00:01  lr: 0.000071  loss: 0.5384 (0.5336)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:362] Total time: 0:04:33 (1.5912 s / it)\n",
      "Averaged stats: lr: 0.000071  loss: 0.5384 (0.5336)\n",
      "Valid: [epoch:362]  [ 0/14]  eta: 0:00:04  loss: 0.5551 (0.5551)  time: 0.2932  data: 0.2777  max mem: 20571\n",
      "Valid: [epoch:362]  [13/14]  eta: 0:00:00  loss: 0.4948 (0.5119)  time: 0.0415  data: 0.0264  max mem: 20571\n",
      "Valid: [epoch:362] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.4948 (0.5119)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_362_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.512%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:363]  [  0/172]  eta: 0:07:47  lr: 0.000071  loss: 0.5220 (0.5220)  time: 2.7157  data: 1.1413  max mem: 20571\n",
      "Train: [epoch:363]  [ 10/172]  eta: 0:04:32  lr: 0.000071  loss: 0.5220 (0.5214)  time: 1.6829  data: 0.1039  max mem: 20571\n",
      "Train: [epoch:363]  [ 20/172]  eta: 0:04:08  lr: 0.000071  loss: 0.5287 (0.5306)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:363]  [ 30/172]  eta: 0:03:49  lr: 0.000071  loss: 0.5272 (0.5310)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [ 40/172]  eta: 0:03:32  lr: 0.000071  loss: 0.5223 (0.5311)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [ 50/172]  eta: 0:03:15  lr: 0.000071  loss: 0.5312 (0.5334)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [ 60/172]  eta: 0:02:59  lr: 0.000071  loss: 0.5346 (0.5333)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [ 70/172]  eta: 0:02:43  lr: 0.000071  loss: 0.5385 (0.5339)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [ 80/172]  eta: 0:02:26  lr: 0.000071  loss: 0.5409 (0.5348)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [ 90/172]  eta: 0:02:10  lr: 0.000071  loss: 0.5340 (0.5346)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [100/172]  eta: 0:01:54  lr: 0.000071  loss: 0.5299 (0.5339)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [110/172]  eta: 0:01:38  lr: 0.000071  loss: 0.5208 (0.5335)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [120/172]  eta: 0:01:22  lr: 0.000071  loss: 0.5208 (0.5329)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [130/172]  eta: 0:01:06  lr: 0.000071  loss: 0.5227 (0.5332)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [140/172]  eta: 0:00:50  lr: 0.000071  loss: 0.5364 (0.5327)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [150/172]  eta: 0:00:34  lr: 0.000071  loss: 0.5292 (0.5329)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [160/172]  eta: 0:00:19  lr: 0.000071  loss: 0.5295 (0.5326)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [170/172]  eta: 0:00:03  lr: 0.000071  loss: 0.5359 (0.5329)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363]  [171/172]  eta: 0:00:01  lr: 0.000071  loss: 0.5359 (0.5329)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:363] Total time: 0:04:33 (1.5907 s / it)\n",
      "Averaged stats: lr: 0.000071  loss: 0.5359 (0.5329)\n",
      "Valid: [epoch:363]  [ 0/14]  eta: 0:00:03  loss: 0.5537 (0.5537)  time: 0.2857  data: 0.2708  max mem: 20571\n",
      "Valid: [epoch:363]  [13/14]  eta: 0:00:00  loss: 0.4903 (0.5076)  time: 0.0389  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:363] Total time: 0:00:00 (0.0473 s / it)\n",
      "Averaged stats: loss: 0.4903 (0.5076)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_363_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.508%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:364]  [  0/172]  eta: 0:08:07  lr: 0.000071  loss: 0.5332 (0.5332)  time: 2.8355  data: 1.2631  max mem: 20571\n",
      "Train: [epoch:364]  [ 10/172]  eta: 0:04:34  lr: 0.000071  loss: 0.5332 (0.5337)  time: 1.6959  data: 0.1150  max mem: 20571\n",
      "Train: [epoch:364]  [ 20/172]  eta: 0:04:09  lr: 0.000071  loss: 0.5361 (0.5412)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [ 30/172]  eta: 0:03:50  lr: 0.000071  loss: 0.5369 (0.5390)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [ 40/172]  eta: 0:03:32  lr: 0.000071  loss: 0.5356 (0.5395)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [ 50/172]  eta: 0:03:16  lr: 0.000071  loss: 0.5373 (0.5384)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [ 60/172]  eta: 0:02:59  lr: 0.000071  loss: 0.5293 (0.5384)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [ 70/172]  eta: 0:02:43  lr: 0.000071  loss: 0.5293 (0.5373)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [ 80/172]  eta: 0:02:27  lr: 0.000071  loss: 0.5359 (0.5371)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [ 90/172]  eta: 0:02:10  lr: 0.000071  loss: 0.5401 (0.5379)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [100/172]  eta: 0:01:54  lr: 0.000071  loss: 0.5431 (0.5382)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [110/172]  eta: 0:01:38  lr: 0.000071  loss: 0.5344 (0.5373)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [120/172]  eta: 0:01:22  lr: 0.000071  loss: 0.5251 (0.5372)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [130/172]  eta: 0:01:06  lr: 0.000071  loss: 0.5274 (0.5367)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [140/172]  eta: 0:00:50  lr: 0.000071  loss: 0.5252 (0.5361)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [150/172]  eta: 0:00:35  lr: 0.000071  loss: 0.5361 (0.5359)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [160/172]  eta: 0:00:19  lr: 0.000071  loss: 0.5366 (0.5355)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [170/172]  eta: 0:00:03  lr: 0.000071  loss: 0.5280 (0.5355)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364]  [171/172]  eta: 0:00:01  lr: 0.000071  loss: 0.5280 (0.5354)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:364] Total time: 0:04:33 (1.5911 s / it)\n",
      "Averaged stats: lr: 0.000071  loss: 0.5280 (0.5354)\n",
      "Valid: [epoch:364]  [ 0/14]  eta: 0:00:05  loss: 0.4579 (0.4579)  time: 0.3898  data: 0.3744  max mem: 20571\n",
      "Valid: [epoch:364]  [13/14]  eta: 0:00:00  loss: 0.5044 (0.5224)  time: 0.0431  data: 0.0280  max mem: 20571\n",
      "Valid: [epoch:364] Total time: 0:00:00 (0.0505 s / it)\n",
      "Averaged stats: loss: 0.5044 (0.5224)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_364_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.522%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:365]  [  0/172]  eta: 0:07:46  lr: 0.000071  loss: 0.5432 (0.5432)  time: 2.7143  data: 1.1378  max mem: 20571\n",
      "Train: [epoch:365]  [ 10/172]  eta: 0:04:32  lr: 0.000071  loss: 0.5124 (0.5327)  time: 1.6839  data: 0.1035  max mem: 20571\n",
      "Train: [epoch:365]  [ 20/172]  eta: 0:04:08  lr: 0.000071  loss: 0.5337 (0.5340)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [ 30/172]  eta: 0:03:49  lr: 0.000071  loss: 0.5351 (0.5321)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [ 40/172]  eta: 0:03:32  lr: 0.000071  loss: 0.5255 (0.5316)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [ 50/172]  eta: 0:03:15  lr: 0.000071  loss: 0.5336 (0.5343)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [ 60/172]  eta: 0:02:59  lr: 0.000071  loss: 0.5394 (0.5332)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [ 70/172]  eta: 0:02:43  lr: 0.000071  loss: 0.5390 (0.5344)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [ 80/172]  eta: 0:02:26  lr: 0.000071  loss: 0.5390 (0.5351)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [ 90/172]  eta: 0:02:10  lr: 0.000071  loss: 0.5337 (0.5336)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [100/172]  eta: 0:01:54  lr: 0.000071  loss: 0.5252 (0.5339)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [110/172]  eta: 0:01:38  lr: 0.000071  loss: 0.5300 (0.5327)  time: 1.5864  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:365]  [120/172]  eta: 0:01:22  lr: 0.000071  loss: 0.5300 (0.5337)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [130/172]  eta: 0:01:06  lr: 0.000071  loss: 0.5338 (0.5336)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [140/172]  eta: 0:00:50  lr: 0.000071  loss: 0.5338 (0.5341)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [150/172]  eta: 0:00:35  lr: 0.000071  loss: 0.5266 (0.5336)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [160/172]  eta: 0:00:19  lr: 0.000071  loss: 0.5290 (0.5346)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [170/172]  eta: 0:00:03  lr: 0.000071  loss: 0.5429 (0.5345)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365]  [171/172]  eta: 0:00:01  lr: 0.000071  loss: 0.5429 (0.5346)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:365] Total time: 0:04:33 (1.5914 s / it)\n",
      "Averaged stats: lr: 0.000071  loss: 0.5429 (0.5346)\n",
      "Valid: [epoch:365]  [ 0/14]  eta: 0:00:06  loss: 0.5603 (0.5603)  time: 0.4383  data: 0.4218  max mem: 20571\n",
      "Valid: [epoch:365]  [13/14]  eta: 0:00:00  loss: 0.5189 (0.5371)  time: 0.0456  data: 0.0305  max mem: 20571\n",
      "Valid: [epoch:365] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.5189 (0.5371)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_365_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.537%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:366]  [  0/172]  eta: 0:07:41  lr: 0.000071  loss: 0.5816 (0.5816)  time: 2.6821  data: 1.1044  max mem: 20571\n",
      "Train: [epoch:366]  [ 10/172]  eta: 0:04:32  lr: 0.000071  loss: 0.5164 (0.5258)  time: 1.6838  data: 0.1005  max mem: 20571\n",
      "Train: [epoch:366]  [ 20/172]  eta: 0:04:08  lr: 0.000071  loss: 0.5257 (0.5343)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [ 30/172]  eta: 0:03:49  lr: 0.000071  loss: 0.5363 (0.5346)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [ 40/172]  eta: 0:03:32  lr: 0.000071  loss: 0.5252 (0.5325)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [ 50/172]  eta: 0:03:15  lr: 0.000071  loss: 0.5430 (0.5349)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [ 60/172]  eta: 0:02:59  lr: 0.000071  loss: 0.5461 (0.5360)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [ 70/172]  eta: 0:02:43  lr: 0.000071  loss: 0.5276 (0.5342)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [ 80/172]  eta: 0:02:26  lr: 0.000071  loss: 0.5148 (0.5336)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [ 90/172]  eta: 0:02:10  lr: 0.000071  loss: 0.5278 (0.5343)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [100/172]  eta: 0:01:54  lr: 0.000071  loss: 0.5272 (0.5343)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [110/172]  eta: 0:01:38  lr: 0.000071  loss: 0.5451 (0.5358)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [120/172]  eta: 0:01:22  lr: 0.000071  loss: 0.5600 (0.5374)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [130/172]  eta: 0:01:06  lr: 0.000071  loss: 0.5266 (0.5366)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [140/172]  eta: 0:00:50  lr: 0.000071  loss: 0.5211 (0.5361)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [150/172]  eta: 0:00:35  lr: 0.000071  loss: 0.5358 (0.5374)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [160/172]  eta: 0:00:19  lr: 0.000071  loss: 0.5399 (0.5381)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [170/172]  eta: 0:00:03  lr: 0.000071  loss: 0.5274 (0.5375)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366]  [171/172]  eta: 0:00:01  lr: 0.000071  loss: 0.5274 (0.5375)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:366] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000071  loss: 0.5274 (0.5375)\n",
      "Valid: [epoch:366]  [ 0/14]  eta: 0:00:04  loss: 0.5689 (0.5689)  time: 0.3298  data: 0.3142  max mem: 20571\n",
      "Valid: [epoch:366]  [13/14]  eta: 0:00:00  loss: 0.5008 (0.5185)  time: 0.0465  data: 0.0313  max mem: 20571\n",
      "Valid: [epoch:366] Total time: 0:00:00 (0.0547 s / it)\n",
      "Averaged stats: loss: 0.5008 (0.5185)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_366_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.518%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:367]  [  0/172]  eta: 0:07:47  lr: 0.000070  loss: 0.5681 (0.5681)  time: 2.7196  data: 1.1461  max mem: 20571\n",
      "Train: [epoch:367]  [ 10/172]  eta: 0:04:32  lr: 0.000070  loss: 0.5245 (0.5364)  time: 1.6814  data: 0.1043  max mem: 20571\n",
      "Train: [epoch:367]  [ 20/172]  eta: 0:04:08  lr: 0.000070  loss: 0.5198 (0.5285)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [ 30/172]  eta: 0:03:49  lr: 0.000070  loss: 0.5169 (0.5278)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [ 40/172]  eta: 0:03:32  lr: 0.000070  loss: 0.5248 (0.5281)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [ 50/172]  eta: 0:03:15  lr: 0.000070  loss: 0.5300 (0.5288)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.5310 (0.5311)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [ 70/172]  eta: 0:02:42  lr: 0.000070  loss: 0.5357 (0.5334)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [ 80/172]  eta: 0:02:26  lr: 0.000070  loss: 0.5357 (0.5347)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [ 90/172]  eta: 0:02:10  lr: 0.000070  loss: 0.5344 (0.5337)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [100/172]  eta: 0:01:54  lr: 0.000070  loss: 0.5263 (0.5342)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [110/172]  eta: 0:01:38  lr: 0.000070  loss: 0.5345 (0.5342)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [120/172]  eta: 0:01:22  lr: 0.000070  loss: 0.5394 (0.5345)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [130/172]  eta: 0:01:06  lr: 0.000070  loss: 0.5253 (0.5342)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [140/172]  eta: 0:00:50  lr: 0.000070  loss: 0.5199 (0.5342)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [150/172]  eta: 0:00:34  lr: 0.000070  loss: 0.5196 (0.5336)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.5197 (0.5335)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.5302 (0.5340)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.5377 (0.5341)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:367] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.5377 (0.5341)\n",
      "Valid: [epoch:367]  [ 0/14]  eta: 0:00:04  loss: 0.5714 (0.5714)  time: 0.2861  data: 0.2697  max mem: 20571\n",
      "Valid: [epoch:367]  [13/14]  eta: 0:00:00  loss: 0.5055 (0.5231)  time: 0.0380  data: 0.0228  max mem: 20571\n",
      "Valid: [epoch:367] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.5055 (0.5231)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_367_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.523%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:368]  [  0/172]  eta: 0:07:19  lr: 0.000070  loss: 0.4985 (0.4985)  time: 2.5528  data: 0.9850  max mem: 20571\n",
      "Train: [epoch:368]  [ 10/172]  eta: 0:04:30  lr: 0.000070  loss: 0.5448 (0.5496)  time: 1.6685  data: 0.0896  max mem: 20571\n",
      "Train: [epoch:368]  [ 20/172]  eta: 0:04:07  lr: 0.000070  loss: 0.5448 (0.5454)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [ 30/172]  eta: 0:03:49  lr: 0.000070  loss: 0.5306 (0.5413)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [ 40/172]  eta: 0:03:32  lr: 0.000070  loss: 0.5302 (0.5428)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [ 50/172]  eta: 0:03:15  lr: 0.000070  loss: 0.5304 (0.5420)  time: 1.5834  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:368]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.5315 (0.5421)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [ 70/172]  eta: 0:02:42  lr: 0.000070  loss: 0.5334 (0.5415)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [ 80/172]  eta: 0:02:26  lr: 0.000070  loss: 0.5304 (0.5385)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [ 90/172]  eta: 0:02:10  lr: 0.000070  loss: 0.5184 (0.5369)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [100/172]  eta: 0:01:54  lr: 0.000070  loss: 0.5259 (0.5369)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [110/172]  eta: 0:01:38  lr: 0.000070  loss: 0.5259 (0.5372)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [120/172]  eta: 0:01:22  lr: 0.000070  loss: 0.5358 (0.5375)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [130/172]  eta: 0:01:06  lr: 0.000070  loss: 0.5304 (0.5371)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [140/172]  eta: 0:00:50  lr: 0.000070  loss: 0.5304 (0.5372)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [150/172]  eta: 0:00:34  lr: 0.000070  loss: 0.5342 (0.5371)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.5389 (0.5377)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.5445 (0.5374)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.5445 (0.5377)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:368] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.5445 (0.5377)\n",
      "Valid: [epoch:368]  [ 0/14]  eta: 0:00:05  loss: 0.5585 (0.5585)  time: 0.4074  data: 0.3927  max mem: 20571\n",
      "Valid: [epoch:368]  [13/14]  eta: 0:00:00  loss: 0.4891 (0.5074)  time: 0.0433  data: 0.0281  max mem: 20571\n",
      "Valid: [epoch:368] Total time: 0:00:00 (0.0517 s / it)\n",
      "Averaged stats: loss: 0.4891 (0.5074)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_368_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.507%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:369]  [  0/172]  eta: 0:08:24  lr: 0.000070  loss: 0.5312 (0.5312)  time: 2.9306  data: 1.3531  max mem: 20571\n",
      "Train: [epoch:369]  [ 10/172]  eta: 0:04:36  lr: 0.000070  loss: 0.5292 (0.5212)  time: 1.7038  data: 0.1232  max mem: 20571\n",
      "Train: [epoch:369]  [ 20/172]  eta: 0:04:10  lr: 0.000070  loss: 0.5396 (0.5329)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:369]  [ 30/172]  eta: 0:03:50  lr: 0.000070  loss: 0.5438 (0.5309)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [ 40/172]  eta: 0:03:33  lr: 0.000070  loss: 0.5347 (0.5309)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [ 50/172]  eta: 0:03:16  lr: 0.000070  loss: 0.5328 (0.5336)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.5369 (0.5339)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [ 70/172]  eta: 0:02:43  lr: 0.000070  loss: 0.5348 (0.5341)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [ 80/172]  eta: 0:02:27  lr: 0.000070  loss: 0.5418 (0.5372)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [ 90/172]  eta: 0:02:10  lr: 0.000070  loss: 0.5392 (0.5354)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [100/172]  eta: 0:01:54  lr: 0.000070  loss: 0.5376 (0.5366)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [110/172]  eta: 0:01:38  lr: 0.000070  loss: 0.5557 (0.5371)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [120/172]  eta: 0:01:22  lr: 0.000070  loss: 0.5319 (0.5377)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [130/172]  eta: 0:01:06  lr: 0.000070  loss: 0.5281 (0.5380)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [140/172]  eta: 0:00:50  lr: 0.000070  loss: 0.5318 (0.5375)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [150/172]  eta: 0:00:35  lr: 0.000070  loss: 0.5269 (0.5373)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.5274 (0.5379)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.5393 (0.5391)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.5385 (0.5391)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:369] Total time: 0:04:33 (1.5919 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.5385 (0.5391)\n",
      "Valid: [epoch:369]  [ 0/14]  eta: 0:00:04  loss: 0.4624 (0.4624)  time: 0.3249  data: 0.3064  max mem: 20571\n",
      "Valid: [epoch:369]  [13/14]  eta: 0:00:00  loss: 0.5146 (0.5313)  time: 0.0373  data: 0.0220  max mem: 20571\n",
      "Valid: [epoch:369] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.5146 (0.5313)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_369_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.531%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:370]  [  0/172]  eta: 0:08:18  lr: 0.000070  loss: 0.5301 (0.5301)  time: 2.9005  data: 1.3308  max mem: 20571\n",
      "Train: [epoch:370]  [ 10/172]  eta: 0:04:35  lr: 0.000070  loss: 0.5301 (0.5394)  time: 1.7006  data: 0.1211  max mem: 20571\n",
      "Train: [epoch:370]  [ 20/172]  eta: 0:04:09  lr: 0.000070  loss: 0.5483 (0.5406)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [ 30/172]  eta: 0:03:50  lr: 0.000070  loss: 0.5311 (0.5366)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [ 40/172]  eta: 0:03:33  lr: 0.000070  loss: 0.5384 (0.5397)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [ 50/172]  eta: 0:03:16  lr: 0.000070  loss: 0.5428 (0.5377)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.5362 (0.5378)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [ 70/172]  eta: 0:02:43  lr: 0.000070  loss: 0.5416 (0.5382)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [ 80/172]  eta: 0:02:27  lr: 0.000070  loss: 0.5388 (0.5385)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [ 90/172]  eta: 0:02:11  lr: 0.000070  loss: 0.5383 (0.5394)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [100/172]  eta: 0:01:54  lr: 0.000070  loss: 0.5150 (0.5381)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [110/172]  eta: 0:01:38  lr: 0.000070  loss: 0.5253 (0.5387)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [120/172]  eta: 0:01:22  lr: 0.000070  loss: 0.5417 (0.5385)  time: 1.5819  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:370]  [130/172]  eta: 0:01:06  lr: 0.000070  loss: 0.5386 (0.5378)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:370]  [140/172]  eta: 0:00:50  lr: 0.000070  loss: 0.5314 (0.5380)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [150/172]  eta: 0:00:35  lr: 0.000070  loss: 0.5305 (0.5377)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.5271 (0.5372)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.5274 (0.5370)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.5274 (0.5373)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:370] Total time: 0:04:33 (1.5914 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.5274 (0.5373)\n",
      "Valid: [epoch:370]  [ 0/14]  eta: 0:00:06  loss: 0.4755 (0.4755)  time: 0.4361  data: 0.4194  max mem: 20571\n",
      "Valid: [epoch:370]  [13/14]  eta: 0:00:00  loss: 0.4904 (0.5077)  time: 0.0471  data: 0.0320  max mem: 20571\n",
      "Valid: [epoch:370] Total time: 0:00:00 (0.0522 s / it)\n",
      "Averaged stats: loss: 0.4904 (0.5077)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_370_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.508%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:371]  [  0/172]  eta: 0:07:53  lr: 0.000070  loss: 0.4791 (0.4791)  time: 2.7544  data: 1.1786  max mem: 20571\n",
      "Train: [epoch:371]  [ 10/172]  eta: 0:04:32  lr: 0.000070  loss: 0.5298 (0.5257)  time: 1.6850  data: 0.1073  max mem: 20571\n",
      "Train: [epoch:371]  [ 20/172]  eta: 0:04:08  lr: 0.000070  loss: 0.5298 (0.5333)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [ 30/172]  eta: 0:03:49  lr: 0.000070  loss: 0.5331 (0.5360)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [ 40/172]  eta: 0:03:32  lr: 0.000070  loss: 0.5388 (0.5362)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [ 50/172]  eta: 0:03:15  lr: 0.000070  loss: 0.5365 (0.5374)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.5315 (0.5388)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [ 70/172]  eta: 0:02:43  lr: 0.000070  loss: 0.5355 (0.5391)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [ 80/172]  eta: 0:02:26  lr: 0.000070  loss: 0.5296 (0.5377)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [ 90/172]  eta: 0:02:10  lr: 0.000070  loss: 0.5282 (0.5378)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [100/172]  eta: 0:01:54  lr: 0.000070  loss: 0.5254 (0.5370)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [110/172]  eta: 0:01:38  lr: 0.000070  loss: 0.5233 (0.5376)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [120/172]  eta: 0:01:22  lr: 0.000070  loss: 0.5329 (0.5374)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [130/172]  eta: 0:01:06  lr: 0.000070  loss: 0.5333 (0.5374)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [140/172]  eta: 0:00:50  lr: 0.000070  loss: 0.5373 (0.5377)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [150/172]  eta: 0:00:35  lr: 0.000070  loss: 0.5380 (0.5383)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.5335 (0.5383)  time: 1.5880  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.5331 (0.5383)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.5335 (0.5388)  time: 1.5894  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:371] Total time: 0:04:33 (1.5918 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.5335 (0.5388)\n",
      "Valid: [epoch:371]  [ 0/14]  eta: 0:00:04  loss: 0.5563 (0.5563)  time: 0.3020  data: 0.2856  max mem: 20571\n",
      "Valid: [epoch:371]  [13/14]  eta: 0:00:00  loss: 0.4961 (0.5132)  time: 0.0529  data: 0.0376  max mem: 20571\n",
      "Valid: [epoch:371] Total time: 0:00:00 (0.0601 s / it)\n",
      "Averaged stats: loss: 0.4961 (0.5132)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_371_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.513%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:372]  [  0/172]  eta: 0:08:10  lr: 0.000070  loss: 0.4741 (0.4741)  time: 2.8522  data: 1.2790  max mem: 20571\n",
      "Train: [epoch:372]  [ 10/172]  eta: 0:04:35  lr: 0.000070  loss: 0.5233 (0.5253)  time: 1.6998  data: 0.1164  max mem: 20571\n",
      "Train: [epoch:372]  [ 20/172]  eta: 0:04:10  lr: 0.000070  loss: 0.5266 (0.5304)  time: 1.5847  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:372]  [ 30/172]  eta: 0:03:50  lr: 0.000070  loss: 0.5448 (0.5372)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [ 40/172]  eta: 0:03:33  lr: 0.000070  loss: 0.5491 (0.5386)  time: 1.5895  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [ 50/172]  eta: 0:03:16  lr: 0.000070  loss: 0.5352 (0.5381)  time: 1.5883  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:372]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.5370 (0.5391)  time: 1.5848  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:372]  [ 70/172]  eta: 0:02:43  lr: 0.000070  loss: 0.5370 (0.5385)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [ 80/172]  eta: 0:02:27  lr: 0.000070  loss: 0.5251 (0.5379)  time: 1.5849  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:372]  [ 90/172]  eta: 0:02:11  lr: 0.000070  loss: 0.5405 (0.5392)  time: 1.5853  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:372]  [100/172]  eta: 0:01:55  lr: 0.000070  loss: 0.5421 (0.5387)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [110/172]  eta: 0:01:39  lr: 0.000070  loss: 0.5321 (0.5391)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [120/172]  eta: 0:01:22  lr: 0.000070  loss: 0.5457 (0.5400)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [130/172]  eta: 0:01:07  lr: 0.000070  loss: 0.5457 (0.5403)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [140/172]  eta: 0:00:51  lr: 0.000070  loss: 0.5249 (0.5394)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [150/172]  eta: 0:00:35  lr: 0.000070  loss: 0.5301 (0.5392)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.5358 (0.5390)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.5391 (0.5401)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.5391 (0.5402)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:372] Total time: 0:04:34 (1.5937 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.5391 (0.5402)\n",
      "Valid: [epoch:372]  [ 0/14]  eta: 0:00:04  loss: 0.5670 (0.5670)  time: 0.2937  data: 0.2788  max mem: 20571\n",
      "Valid: [epoch:372]  [13/14]  eta: 0:00:00  loss: 0.5037 (0.5209)  time: 0.0405  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:372] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.5037 (0.5209)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_372_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.521%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:373]  [  0/172]  eta: 0:07:58  lr: 0.000070  loss: 0.5145 (0.5145)  time: 2.7811  data: 1.1982  max mem: 20571\n",
      "Train: [epoch:373]  [ 10/172]  eta: 0:04:33  lr: 0.000070  loss: 0.5294 (0.5289)  time: 1.6891  data: 0.1091  max mem: 20571\n",
      "Train: [epoch:373]  [ 20/172]  eta: 0:04:09  lr: 0.000070  loss: 0.5294 (0.5370)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:373]  [ 30/172]  eta: 0:03:50  lr: 0.000070  loss: 0.5282 (0.5337)  time: 1.5849  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:373]  [ 40/172]  eta: 0:03:32  lr: 0.000070  loss: 0.5347 (0.5344)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [ 50/172]  eta: 0:03:16  lr: 0.000070  loss: 0.5262 (0.5340)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.5298 (0.5355)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [ 70/172]  eta: 0:02:43  lr: 0.000070  loss: 0.5426 (0.5358)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [ 80/172]  eta: 0:02:27  lr: 0.000070  loss: 0.5491 (0.5367)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [ 90/172]  eta: 0:02:11  lr: 0.000070  loss: 0.5387 (0.5374)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [100/172]  eta: 0:01:54  lr: 0.000070  loss: 0.5343 (0.5374)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [110/172]  eta: 0:01:38  lr: 0.000070  loss: 0.5504 (0.5390)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [120/172]  eta: 0:01:22  lr: 0.000070  loss: 0.5460 (0.5392)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [130/172]  eta: 0:01:06  lr: 0.000070  loss: 0.5385 (0.5396)  time: 1.5846  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:373]  [140/172]  eta: 0:00:50  lr: 0.000070  loss: 0.5413 (0.5393)  time: 1.5851  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:373]  [150/172]  eta: 0:00:35  lr: 0.000070  loss: 0.5459 (0.5396)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.5337 (0.5395)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.5266 (0.5392)  time: 1.5868  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:373]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.5310 (0.5392)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:373] Total time: 0:04:33 (1.5927 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.5310 (0.5392)\n",
      "Valid: [epoch:373]  [ 0/14]  eta: 0:00:04  loss: 0.4942 (0.4942)  time: 0.2974  data: 0.2814  max mem: 20571\n",
      "Valid: [epoch:373]  [13/14]  eta: 0:00:00  loss: 0.5121 (0.5288)  time: 0.0377  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:373] Total time: 0:00:00 (0.0429 s / it)\n",
      "Averaged stats: loss: 0.5121 (0.5288)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_373_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.529%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:374]  [  0/172]  eta: 0:07:55  lr: 0.000070  loss: 0.5395 (0.5395)  time: 2.7627  data: 1.1882  max mem: 20571\n",
      "Train: [epoch:374]  [ 10/172]  eta: 0:04:33  lr: 0.000070  loss: 0.5267 (0.5331)  time: 1.6898  data: 0.1081  max mem: 20571\n",
      "Train: [epoch:374]  [ 20/172]  eta: 0:04:09  lr: 0.000070  loss: 0.5308 (0.5328)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [ 30/172]  eta: 0:03:50  lr: 0.000070  loss: 0.5335 (0.5356)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [ 40/172]  eta: 0:03:32  lr: 0.000070  loss: 0.5524 (0.5413)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [ 50/172]  eta: 0:03:16  lr: 0.000070  loss: 0.5447 (0.5393)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.5362 (0.5403)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [ 70/172]  eta: 0:02:43  lr: 0.000070  loss: 0.5530 (0.5423)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [ 80/172]  eta: 0:02:27  lr: 0.000070  loss: 0.5396 (0.5425)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [ 90/172]  eta: 0:02:10  lr: 0.000070  loss: 0.5297 (0.5419)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [100/172]  eta: 0:01:54  lr: 0.000070  loss: 0.5459 (0.5410)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [110/172]  eta: 0:01:38  lr: 0.000070  loss: 0.5264 (0.5399)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [120/172]  eta: 0:01:22  lr: 0.000070  loss: 0.5264 (0.5400)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [130/172]  eta: 0:01:06  lr: 0.000070  loss: 0.5312 (0.5395)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [140/172]  eta: 0:00:50  lr: 0.000070  loss: 0.5236 (0.5389)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [150/172]  eta: 0:00:35  lr: 0.000070  loss: 0.5310 (0.5393)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.5382 (0.5391)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.5473 (0.5401)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.5429 (0.5401)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:374] Total time: 0:04:33 (1.5912 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.5429 (0.5401)\n",
      "Valid: [epoch:374]  [ 0/14]  eta: 0:00:05  loss: 0.5802 (0.5802)  time: 0.3680  data: 0.3525  max mem: 20571\n",
      "Valid: [epoch:374]  [13/14]  eta: 0:00:00  loss: 0.5194 (0.5358)  time: 0.0410  data: 0.0260  max mem: 20571\n",
      "Valid: [epoch:374] Total time: 0:00:00 (0.0496 s / it)\n",
      "Averaged stats: loss: 0.5194 (0.5358)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_374_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.536%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:375]  [  0/172]  eta: 0:08:00  lr: 0.000070  loss: 0.5048 (0.5048)  time: 2.7913  data: 1.2122  max mem: 20571\n",
      "Train: [epoch:375]  [ 10/172]  eta: 0:04:34  lr: 0.000070  loss: 0.5577 (0.5481)  time: 1.6914  data: 0.1103  max mem: 20571\n",
      "Train: [epoch:375]  [ 20/172]  eta: 0:04:09  lr: 0.000070  loss: 0.5419 (0.5410)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [ 30/172]  eta: 0:03:50  lr: 0.000070  loss: 0.5217 (0.5378)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [ 40/172]  eta: 0:03:32  lr: 0.000070  loss: 0.5217 (0.5372)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [ 50/172]  eta: 0:03:16  lr: 0.000070  loss: 0.5410 (0.5384)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [ 60/172]  eta: 0:02:59  lr: 0.000070  loss: 0.5420 (0.5387)  time: 1.5859  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:375]  [ 70/172]  eta: 0:02:43  lr: 0.000070  loss: 0.5438 (0.5400)  time: 1.5893  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:375]  [ 80/172]  eta: 0:02:27  lr: 0.000070  loss: 0.5435 (0.5402)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [ 90/172]  eta: 0:02:11  lr: 0.000070  loss: 0.5369 (0.5410)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [100/172]  eta: 0:01:55  lr: 0.000070  loss: 0.5479 (0.5424)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [110/172]  eta: 0:01:39  lr: 0.000070  loss: 0.5428 (0.5425)  time: 1.5906  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [120/172]  eta: 0:01:23  lr: 0.000070  loss: 0.5360 (0.5429)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [130/172]  eta: 0:01:07  lr: 0.000070  loss: 0.5296 (0.5424)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [140/172]  eta: 0:00:51  lr: 0.000070  loss: 0.5369 (0.5429)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [150/172]  eta: 0:00:35  lr: 0.000070  loss: 0.5335 (0.5421)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [160/172]  eta: 0:00:19  lr: 0.000070  loss: 0.5311 (0.5418)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [170/172]  eta: 0:00:03  lr: 0.000070  loss: 0.5472 (0.5423)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375]  [171/172]  eta: 0:00:01  lr: 0.000070  loss: 0.5472 (0.5424)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:375] Total time: 0:04:34 (1.5944 s / it)\n",
      "Averaged stats: lr: 0.000070  loss: 0.5472 (0.5424)\n",
      "Valid: [epoch:375]  [ 0/14]  eta: 0:00:04  loss: 0.5650 (0.5650)  time: 0.3310  data: 0.3162  max mem: 20571\n",
      "Valid: [epoch:375]  [13/14]  eta: 0:00:00  loss: 0.4949 (0.5119)  time: 0.0378  data: 0.0229  max mem: 20571\n",
      "Valid: [epoch:375] Total time: 0:00:00 (0.0438 s / it)\n",
      "Averaged stats: loss: 0.4949 (0.5119)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_375_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.512%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:376]  [  0/172]  eta: 0:07:43  lr: 0.000069  loss: 0.5426 (0.5426)  time: 2.6968  data: 1.1114  max mem: 20571\n",
      "Train: [epoch:376]  [ 10/172]  eta: 0:04:33  lr: 0.000069  loss: 0.5374 (0.5439)  time: 1.6874  data: 0.1011  max mem: 20571\n",
      "Train: [epoch:376]  [ 20/172]  eta: 0:04:08  lr: 0.000069  loss: 0.5369 (0.5432)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [ 30/172]  eta: 0:03:50  lr: 0.000069  loss: 0.5257 (0.5403)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [ 40/172]  eta: 0:03:32  lr: 0.000069  loss: 0.5291 (0.5393)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [ 50/172]  eta: 0:03:16  lr: 0.000069  loss: 0.5415 (0.5428)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [ 60/172]  eta: 0:02:59  lr: 0.000069  loss: 0.5289 (0.5416)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [ 70/172]  eta: 0:02:43  lr: 0.000069  loss: 0.5241 (0.5407)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [ 80/172]  eta: 0:02:27  lr: 0.000069  loss: 0.5300 (0.5413)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [ 90/172]  eta: 0:02:10  lr: 0.000069  loss: 0.5405 (0.5419)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [100/172]  eta: 0:01:54  lr: 0.000069  loss: 0.5396 (0.5418)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [110/172]  eta: 0:01:38  lr: 0.000069  loss: 0.5403 (0.5412)  time: 1.5846  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:376]  [120/172]  eta: 0:01:22  lr: 0.000069  loss: 0.5355 (0.5407)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [130/172]  eta: 0:01:06  lr: 0.000069  loss: 0.5355 (0.5409)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [140/172]  eta: 0:00:50  lr: 0.000069  loss: 0.5323 (0.5417)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [150/172]  eta: 0:00:35  lr: 0.000069  loss: 0.5220 (0.5416)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [160/172]  eta: 0:00:19  lr: 0.000069  loss: 0.5226 (0.5421)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [170/172]  eta: 0:00:03  lr: 0.000069  loss: 0.5234 (0.5415)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376]  [171/172]  eta: 0:00:01  lr: 0.000069  loss: 0.5234 (0.5415)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:376] Total time: 0:04:33 (1.5920 s / it)\n",
      "Averaged stats: lr: 0.000069  loss: 0.5234 (0.5415)\n",
      "Valid: [epoch:376]  [ 0/14]  eta: 0:00:05  loss: 0.5665 (0.5665)  time: 0.4113  data: 0.3930  max mem: 20571\n",
      "Valid: [epoch:376]  [13/14]  eta: 0:00:00  loss: 0.5024 (0.5201)  time: 0.0446  data: 0.0293  max mem: 20571\n",
      "Valid: [epoch:376] Total time: 0:00:00 (0.0524 s / it)\n",
      "Averaged stats: loss: 0.5024 (0.5201)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_376_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.520%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:377]  [  0/172]  eta: 0:07:37  lr: 0.000069  loss: 0.5088 (0.5088)  time: 2.6573  data: 1.0819  max mem: 20571\n",
      "Train: [epoch:377]  [ 10/172]  eta: 0:04:32  lr: 0.000069  loss: 0.5522 (0.5519)  time: 1.6791  data: 0.0985  max mem: 20571\n",
      "Train: [epoch:377]  [ 20/172]  eta: 0:04:08  lr: 0.000069  loss: 0.5522 (0.5500)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [ 30/172]  eta: 0:03:49  lr: 0.000069  loss: 0.5387 (0.5476)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [ 40/172]  eta: 0:03:32  lr: 0.000069  loss: 0.5371 (0.5458)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [ 50/172]  eta: 0:03:15  lr: 0.000069  loss: 0.5447 (0.5493)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [ 60/172]  eta: 0:02:59  lr: 0.000069  loss: 0.5632 (0.5522)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [ 70/172]  eta: 0:02:43  lr: 0.000069  loss: 0.5576 (0.5518)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [ 80/172]  eta: 0:02:26  lr: 0.000069  loss: 0.5321 (0.5489)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [ 90/172]  eta: 0:02:10  lr: 0.000069  loss: 0.5321 (0.5484)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [100/172]  eta: 0:01:54  lr: 0.000069  loss: 0.5468 (0.5476)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [110/172]  eta: 0:01:38  lr: 0.000069  loss: 0.5454 (0.5487)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [120/172]  eta: 0:01:22  lr: 0.000069  loss: 0.5379 (0.5481)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [130/172]  eta: 0:01:06  lr: 0.000069  loss: 0.5370 (0.5473)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [140/172]  eta: 0:00:50  lr: 0.000069  loss: 0.5257 (0.5459)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [150/172]  eta: 0:00:34  lr: 0.000069  loss: 0.5212 (0.5446)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [160/172]  eta: 0:00:19  lr: 0.000069  loss: 0.5227 (0.5440)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [170/172]  eta: 0:00:03  lr: 0.000069  loss: 0.5280 (0.5435)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377]  [171/172]  eta: 0:00:01  lr: 0.000069  loss: 0.5288 (0.5435)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:377] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000069  loss: 0.5288 (0.5435)\n",
      "Valid: [epoch:377]  [ 0/14]  eta: 0:00:04  loss: 0.4899 (0.4899)  time: 0.2922  data: 0.2772  max mem: 20571\n",
      "Valid: [epoch:377]  [13/14]  eta: 0:00:00  loss: 0.5053 (0.5223)  time: 0.0375  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:377] Total time: 0:00:00 (0.0425 s / it)\n",
      "Averaged stats: loss: 0.5053 (0.5223)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_377_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.522%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:378]  [  0/172]  eta: 0:07:31  lr: 0.000069  loss: 0.5725 (0.5725)  time: 2.6222  data: 1.0508  max mem: 20571\n",
      "Train: [epoch:378]  [ 10/172]  eta: 0:04:32  lr: 0.000069  loss: 0.5368 (0.5333)  time: 1.6793  data: 0.0956  max mem: 20571\n",
      "Train: [epoch:378]  [ 20/172]  eta: 0:04:08  lr: 0.000069  loss: 0.5336 (0.5332)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [ 30/172]  eta: 0:03:49  lr: 0.000069  loss: 0.5409 (0.5382)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [ 40/172]  eta: 0:03:32  lr: 0.000069  loss: 0.5409 (0.5376)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [ 50/172]  eta: 0:03:15  lr: 0.000069  loss: 0.5363 (0.5389)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [ 60/172]  eta: 0:02:59  lr: 0.000069  loss: 0.5423 (0.5407)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [ 70/172]  eta: 0:02:43  lr: 0.000069  loss: 0.5356 (0.5400)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [ 80/172]  eta: 0:02:27  lr: 0.000069  loss: 0.5291 (0.5408)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [ 90/172]  eta: 0:02:10  lr: 0.000069  loss: 0.5358 (0.5406)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [100/172]  eta: 0:01:54  lr: 0.000069  loss: 0.5433 (0.5412)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [110/172]  eta: 0:01:38  lr: 0.000069  loss: 0.5437 (0.5414)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [120/172]  eta: 0:01:22  lr: 0.000069  loss: 0.5424 (0.5417)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [130/172]  eta: 0:01:06  lr: 0.000069  loss: 0.5370 (0.5415)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [140/172]  eta: 0:00:50  lr: 0.000069  loss: 0.5433 (0.5421)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [150/172]  eta: 0:00:35  lr: 0.000069  loss: 0.5433 (0.5415)  time: 1.5865  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:378]  [160/172]  eta: 0:00:19  lr: 0.000069  loss: 0.5419 (0.5420)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [170/172]  eta: 0:00:03  lr: 0.000069  loss: 0.5316 (0.5421)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378]  [171/172]  eta: 0:00:01  lr: 0.000069  loss: 0.5316 (0.5422)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:378] Total time: 0:04:33 (1.5923 s / it)\n",
      "Averaged stats: lr: 0.000069  loss: 0.5316 (0.5422)\n",
      "Valid: [epoch:378]  [ 0/14]  eta: 0:00:05  loss: 0.5787 (0.5787)  time: 0.3776  data: 0.3611  max mem: 20571\n",
      "Valid: [epoch:378]  [13/14]  eta: 0:00:00  loss: 0.5154 (0.5340)  time: 0.0427  data: 0.0274  max mem: 20571\n",
      "Valid: [epoch:378] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.5154 (0.5340)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_378_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.534%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:379]  [  0/172]  eta: 0:07:58  lr: 0.000069  loss: 0.5430 (0.5430)  time: 2.7826  data: 1.2079  max mem: 20571\n",
      "Train: [epoch:379]  [ 10/172]  eta: 0:04:33  lr: 0.000069  loss: 0.5297 (0.5316)  time: 1.6883  data: 0.1099  max mem: 20571\n",
      "Train: [epoch:379]  [ 20/172]  eta: 0:04:08  lr: 0.000069  loss: 0.5252 (0.5382)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [ 30/172]  eta: 0:03:49  lr: 0.000069  loss: 0.5255 (0.5359)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [ 40/172]  eta: 0:03:32  lr: 0.000069  loss: 0.5413 (0.5355)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [ 50/172]  eta: 0:03:15  lr: 0.000069  loss: 0.5413 (0.5392)  time: 1.5831  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:379]  [ 60/172]  eta: 0:02:59  lr: 0.000069  loss: 0.5464 (0.5404)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [ 70/172]  eta: 0:02:43  lr: 0.000069  loss: 0.5457 (0.5409)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [ 80/172]  eta: 0:02:26  lr: 0.000069  loss: 0.5452 (0.5424)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [ 90/172]  eta: 0:02:10  lr: 0.000069  loss: 0.5184 (0.5398)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [100/172]  eta: 0:01:54  lr: 0.000069  loss: 0.5183 (0.5404)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [110/172]  eta: 0:01:38  lr: 0.000069  loss: 0.5506 (0.5418)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [120/172]  eta: 0:01:22  lr: 0.000069  loss: 0.5618 (0.5435)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [130/172]  eta: 0:01:06  lr: 0.000069  loss: 0.5487 (0.5442)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [140/172]  eta: 0:00:50  lr: 0.000069  loss: 0.5480 (0.5444)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [150/172]  eta: 0:00:34  lr: 0.000069  loss: 0.5422 (0.5443)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [160/172]  eta: 0:00:19  lr: 0.000069  loss: 0.5421 (0.5443)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [170/172]  eta: 0:00:03  lr: 0.000069  loss: 0.5362 (0.5447)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379]  [171/172]  eta: 0:00:01  lr: 0.000069  loss: 0.5376 (0.5449)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:379] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000069  loss: 0.5376 (0.5449)\n",
      "Valid: [epoch:379]  [ 0/14]  eta: 0:00:05  loss: 0.4749 (0.4749)  time: 0.3650  data: 0.3470  max mem: 20571\n",
      "Valid: [epoch:379]  [13/14]  eta: 0:00:00  loss: 0.5322 (0.5485)  time: 0.0464  data: 0.0311  max mem: 20571\n",
      "Valid: [epoch:379] Total time: 0:00:00 (0.0549 s / it)\n",
      "Averaged stats: loss: 0.5322 (0.5485)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_379_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.548%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:380]  [  0/172]  eta: 0:08:02  lr: 0.000069  loss: 0.5123 (0.5123)  time: 2.8052  data: 1.2377  max mem: 20571\n",
      "Train: [epoch:380]  [ 10/172]  eta: 0:04:34  lr: 0.000069  loss: 0.5445 (0.5498)  time: 1.6934  data: 0.1126  max mem: 20571\n",
      "Train: [epoch:380]  [ 20/172]  eta: 0:04:09  lr: 0.000069  loss: 0.5552 (0.5523)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [ 30/172]  eta: 0:03:50  lr: 0.000069  loss: 0.5619 (0.5517)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [ 40/172]  eta: 0:03:32  lr: 0.000069  loss: 0.5274 (0.5477)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [ 50/172]  eta: 0:03:15  lr: 0.000069  loss: 0.5323 (0.5476)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [ 60/172]  eta: 0:02:59  lr: 0.000069  loss: 0.5406 (0.5476)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [ 70/172]  eta: 0:02:43  lr: 0.000069  loss: 0.5451 (0.5469)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:380]  [ 80/172]  eta: 0:02:26  lr: 0.000069  loss: 0.5451 (0.5471)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:380]  [ 90/172]  eta: 0:02:10  lr: 0.000069  loss: 0.5310 (0.5456)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [100/172]  eta: 0:01:54  lr: 0.000069  loss: 0.5291 (0.5452)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [110/172]  eta: 0:01:38  lr: 0.000069  loss: 0.5429 (0.5450)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [120/172]  eta: 0:01:22  lr: 0.000069  loss: 0.5429 (0.5437)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:380]  [130/172]  eta: 0:01:06  lr: 0.000069  loss: 0.5406 (0.5434)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [140/172]  eta: 0:00:50  lr: 0.000069  loss: 0.5348 (0.5434)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [150/172]  eta: 0:00:34  lr: 0.000069  loss: 0.5347 (0.5439)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [160/172]  eta: 0:00:19  lr: 0.000069  loss: 0.5477 (0.5438)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [170/172]  eta: 0:00:03  lr: 0.000069  loss: 0.5519 (0.5444)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380]  [171/172]  eta: 0:00:01  lr: 0.000069  loss: 0.5519 (0.5444)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:380] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000069  loss: 0.5519 (0.5444)\n",
      "Valid: [epoch:380]  [ 0/14]  eta: 0:00:04  loss: 0.4543 (0.4543)  time: 0.3176  data: 0.3022  max mem: 20571\n",
      "Valid: [epoch:380]  [13/14]  eta: 0:00:00  loss: 0.5063 (0.5236)  time: 0.0428  data: 0.0278  max mem: 20571\n",
      "Valid: [epoch:380] Total time: 0:00:00 (0.0511 s / it)\n",
      "Averaged stats: loss: 0.5063 (0.5236)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_380_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.524%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:381]  [  0/172]  eta: 0:07:28  lr: 0.000069  loss: 0.5249 (0.5249)  time: 2.6090  data: 1.0285  max mem: 20571\n",
      "Train: [epoch:381]  [ 10/172]  eta: 0:04:30  lr: 0.000069  loss: 0.5394 (0.5368)  time: 1.6711  data: 0.0937  max mem: 20571\n",
      "Train: [epoch:381]  [ 20/172]  eta: 0:04:07  lr: 0.000069  loss: 0.5431 (0.5504)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:381]  [ 30/172]  eta: 0:03:48  lr: 0.000069  loss: 0.5476 (0.5493)  time: 1.5770  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:381]  [ 40/172]  eta: 0:03:31  lr: 0.000069  loss: 0.5474 (0.5475)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [ 50/172]  eta: 0:03:15  lr: 0.000069  loss: 0.5465 (0.5466)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [ 60/172]  eta: 0:02:58  lr: 0.000069  loss: 0.5485 (0.5478)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [ 70/172]  eta: 0:02:42  lr: 0.000069  loss: 0.5355 (0.5459)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [ 80/172]  eta: 0:02:26  lr: 0.000069  loss: 0.5326 (0.5464)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [ 90/172]  eta: 0:02:10  lr: 0.000069  loss: 0.5561 (0.5465)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [100/172]  eta: 0:01:54  lr: 0.000069  loss: 0.5264 (0.5454)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [110/172]  eta: 0:01:38  lr: 0.000069  loss: 0.5417 (0.5463)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [120/172]  eta: 0:01:22  lr: 0.000069  loss: 0.5330 (0.5446)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [130/172]  eta: 0:01:06  lr: 0.000069  loss: 0.5365 (0.5464)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [140/172]  eta: 0:00:50  lr: 0.000069  loss: 0.5563 (0.5477)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [150/172]  eta: 0:00:34  lr: 0.000069  loss: 0.5385 (0.5472)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [160/172]  eta: 0:00:19  lr: 0.000069  loss: 0.5300 (0.5465)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [170/172]  eta: 0:00:03  lr: 0.000069  loss: 0.5324 (0.5463)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381]  [171/172]  eta: 0:00:01  lr: 0.000069  loss: 0.5324 (0.5467)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:381] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000069  loss: 0.5324 (0.5467)\n",
      "Valid: [epoch:381]  [ 0/14]  eta: 0:00:05  loss: 0.5678 (0.5678)  time: 0.3668  data: 0.3513  max mem: 20571\n",
      "Valid: [epoch:381]  [13/14]  eta: 0:00:00  loss: 0.4973 (0.5142)  time: 0.0409  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:381] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.4973 (0.5142)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_381_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.514%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:382]  [  0/172]  eta: 0:07:44  lr: 0.000069  loss: 0.5276 (0.5276)  time: 2.6984  data: 1.1262  max mem: 20571\n",
      "Train: [epoch:382]  [ 10/172]  eta: 0:04:32  lr: 0.000069  loss: 0.5281 (0.5401)  time: 1.6834  data: 0.1025  max mem: 20571\n",
      "Train: [epoch:382]  [ 20/172]  eta: 0:04:08  lr: 0.000069  loss: 0.5452 (0.5474)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [ 30/172]  eta: 0:03:49  lr: 0.000069  loss: 0.5462 (0.5458)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [ 40/172]  eta: 0:03:32  lr: 0.000069  loss: 0.5368 (0.5459)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [ 50/172]  eta: 0:03:15  lr: 0.000069  loss: 0.5486 (0.5478)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [ 60/172]  eta: 0:02:59  lr: 0.000069  loss: 0.5387 (0.5480)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [ 70/172]  eta: 0:02:43  lr: 0.000069  loss: 0.5350 (0.5462)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [ 80/172]  eta: 0:02:26  lr: 0.000069  loss: 0.5294 (0.5450)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [ 90/172]  eta: 0:02:10  lr: 0.000069  loss: 0.5353 (0.5437)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [100/172]  eta: 0:01:54  lr: 0.000069  loss: 0.5353 (0.5440)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [110/172]  eta: 0:01:38  lr: 0.000069  loss: 0.5566 (0.5453)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [120/172]  eta: 0:01:22  lr: 0.000069  loss: 0.5383 (0.5453)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [130/172]  eta: 0:01:06  lr: 0.000069  loss: 0.5308 (0.5446)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [140/172]  eta: 0:00:50  lr: 0.000069  loss: 0.5303 (0.5439)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [150/172]  eta: 0:00:34  lr: 0.000069  loss: 0.5301 (0.5441)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [160/172]  eta: 0:00:19  lr: 0.000069  loss: 0.5391 (0.5437)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [170/172]  eta: 0:00:03  lr: 0.000069  loss: 0.5293 (0.5433)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382]  [171/172]  eta: 0:00:01  lr: 0.000069  loss: 0.5349 (0.5437)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:382] Total time: 0:04:33 (1.5902 s / it)\n",
      "Averaged stats: lr: 0.000069  loss: 0.5349 (0.5437)\n",
      "Valid: [epoch:382]  [ 0/14]  eta: 0:00:04  loss: 0.5210 (0.5210)  time: 0.3182  data: 0.3015  max mem: 20571\n",
      "Valid: [epoch:382]  [13/14]  eta: 0:00:00  loss: 0.5210 (0.5378)  time: 0.0374  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:382] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.5210 (0.5378)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_382_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.538%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:383]  [  0/172]  eta: 0:07:40  lr: 0.000069  loss: 0.5664 (0.5664)  time: 2.6763  data: 1.0979  max mem: 20571\n",
      "Train: [epoch:383]  [ 10/172]  eta: 0:04:31  lr: 0.000069  loss: 0.5466 (0.5488)  time: 1.6784  data: 0.0999  max mem: 20571\n",
      "Train: [epoch:383]  [ 20/172]  eta: 0:04:08  lr: 0.000069  loss: 0.5406 (0.5391)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [ 30/172]  eta: 0:03:49  lr: 0.000069  loss: 0.5337 (0.5405)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [ 40/172]  eta: 0:03:32  lr: 0.000069  loss: 0.5405 (0.5430)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [ 50/172]  eta: 0:03:15  lr: 0.000069  loss: 0.5421 (0.5431)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [ 60/172]  eta: 0:02:59  lr: 0.000069  loss: 0.5400 (0.5436)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [ 70/172]  eta: 0:02:43  lr: 0.000069  loss: 0.5409 (0.5438)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [ 80/172]  eta: 0:02:26  lr: 0.000069  loss: 0.5409 (0.5453)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [ 90/172]  eta: 0:02:10  lr: 0.000069  loss: 0.5513 (0.5456)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [100/172]  eta: 0:01:54  lr: 0.000069  loss: 0.5477 (0.5453)  time: 1.5866  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:383]  [110/172]  eta: 0:01:38  lr: 0.000069  loss: 0.5477 (0.5470)  time: 1.5865  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:383]  [120/172]  eta: 0:01:22  lr: 0.000069  loss: 0.5646 (0.5473)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:383]  [130/172]  eta: 0:01:06  lr: 0.000069  loss: 0.5689 (0.5489)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [140/172]  eta: 0:00:50  lr: 0.000069  loss: 0.5376 (0.5472)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [150/172]  eta: 0:00:35  lr: 0.000069  loss: 0.5335 (0.5473)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [160/172]  eta: 0:00:19  lr: 0.000069  loss: 0.5257 (0.5463)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [170/172]  eta: 0:00:03  lr: 0.000069  loss: 0.5255 (0.5459)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383]  [171/172]  eta: 0:00:01  lr: 0.000069  loss: 0.5213 (0.5457)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:383] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000069  loss: 0.5213 (0.5457)\n",
      "Valid: [epoch:383]  [ 0/14]  eta: 0:00:04  loss: 0.5544 (0.5544)  time: 0.3532  data: 0.3366  max mem: 20571\n",
      "Valid: [epoch:383]  [13/14]  eta: 0:00:00  loss: 0.5109 (0.5288)  time: 0.0403  data: 0.0251  max mem: 20571\n",
      "Valid: [epoch:383] Total time: 0:00:00 (0.0453 s / it)\n",
      "Averaged stats: loss: 0.5109 (0.5288)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_383_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.529%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:384]  [  0/172]  eta: 0:07:27  lr: 0.000069  loss: 0.5219 (0.5219)  time: 2.6028  data: 1.0341  max mem: 20571\n",
      "Train: [epoch:384]  [ 10/172]  eta: 0:04:31  lr: 0.000069  loss: 0.5495 (0.5512)  time: 1.6745  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:384]  [ 20/172]  eta: 0:04:07  lr: 0.000069  loss: 0.5383 (0.5418)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [ 30/172]  eta: 0:03:49  lr: 0.000069  loss: 0.5259 (0.5405)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [ 40/172]  eta: 0:03:32  lr: 0.000069  loss: 0.5456 (0.5414)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [ 50/172]  eta: 0:03:15  lr: 0.000069  loss: 0.5483 (0.5423)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [ 60/172]  eta: 0:02:59  lr: 0.000069  loss: 0.5428 (0.5433)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [ 70/172]  eta: 0:02:42  lr: 0.000069  loss: 0.5379 (0.5443)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [ 80/172]  eta: 0:02:26  lr: 0.000069  loss: 0.5450 (0.5454)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [ 90/172]  eta: 0:02:10  lr: 0.000069  loss: 0.5407 (0.5460)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [100/172]  eta: 0:01:54  lr: 0.000069  loss: 0.5407 (0.5463)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [110/172]  eta: 0:01:38  lr: 0.000069  loss: 0.5598 (0.5471)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [120/172]  eta: 0:01:22  lr: 0.000069  loss: 0.5366 (0.5470)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [130/172]  eta: 0:01:06  lr: 0.000069  loss: 0.5393 (0.5472)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [140/172]  eta: 0:00:50  lr: 0.000069  loss: 0.5393 (0.5468)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [150/172]  eta: 0:00:34  lr: 0.000069  loss: 0.5458 (0.5480)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [160/172]  eta: 0:00:19  lr: 0.000069  loss: 0.5553 (0.5486)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384]  [170/172]  eta: 0:00:03  lr: 0.000069  loss: 0.5533 (0.5488)  time: 1.5814  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:384]  [171/172]  eta: 0:00:01  lr: 0.000069  loss: 0.5553 (0.5490)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:384] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000069  loss: 0.5553 (0.5490)\n",
      "Valid: [epoch:384]  [ 0/14]  eta: 0:00:04  loss: 0.4617 (0.4617)  time: 0.3440  data: 0.3277  max mem: 20571\n",
      "Valid: [epoch:384]  [13/14]  eta: 0:00:00  loss: 0.4996 (0.5170)  time: 0.0406  data: 0.0255  max mem: 20571\n",
      "Valid: [epoch:384] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.4996 (0.5170)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_384_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.517%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:385]  [  0/172]  eta: 0:07:25  lr: 0.000068  loss: 0.5112 (0.5112)  time: 2.5890  data: 1.0117  max mem: 20571\n",
      "Train: [epoch:385]  [ 10/172]  eta: 0:04:30  lr: 0.000068  loss: 0.5505 (0.5440)  time: 1.6700  data: 0.0921  max mem: 20571\n",
      "Train: [epoch:385]  [ 20/172]  eta: 0:04:07  lr: 0.000068  loss: 0.5461 (0.5436)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [ 30/172]  eta: 0:03:48  lr: 0.000068  loss: 0.5411 (0.5455)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [ 40/172]  eta: 0:03:31  lr: 0.000068  loss: 0.5378 (0.5440)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [ 50/172]  eta: 0:03:15  lr: 0.000068  loss: 0.5373 (0.5463)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [ 60/172]  eta: 0:02:58  lr: 0.000068  loss: 0.5366 (0.5449)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [ 70/172]  eta: 0:02:42  lr: 0.000068  loss: 0.5358 (0.5453)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [ 80/172]  eta: 0:02:26  lr: 0.000068  loss: 0.5401 (0.5447)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [ 90/172]  eta: 0:02:10  lr: 0.000068  loss: 0.5401 (0.5445)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [100/172]  eta: 0:01:54  lr: 0.000068  loss: 0.5487 (0.5460)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [110/172]  eta: 0:01:38  lr: 0.000068  loss: 0.5487 (0.5475)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [120/172]  eta: 0:01:22  lr: 0.000068  loss: 0.5355 (0.5470)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [130/172]  eta: 0:01:06  lr: 0.000068  loss: 0.5358 (0.5470)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [140/172]  eta: 0:00:50  lr: 0.000068  loss: 0.5397 (0.5472)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [150/172]  eta: 0:00:34  lr: 0.000068  loss: 0.5282 (0.5466)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [160/172]  eta: 0:00:19  lr: 0.000068  loss: 0.5374 (0.5464)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [170/172]  eta: 0:00:03  lr: 0.000068  loss: 0.5378 (0.5462)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385]  [171/172]  eta: 0:00:01  lr: 0.000068  loss: 0.5378 (0.5464)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:385] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000068  loss: 0.5378 (0.5464)\n",
      "Valid: [epoch:385]  [ 0/14]  eta: 0:00:04  loss: 0.5811 (0.5811)  time: 0.2980  data: 0.2818  max mem: 20571\n",
      "Valid: [epoch:385]  [13/14]  eta: 0:00:00  loss: 0.5125 (0.5283)  time: 0.0415  data: 0.0264  max mem: 20571\n",
      "Valid: [epoch:385] Total time: 0:00:00 (0.0497 s / it)\n",
      "Averaged stats: loss: 0.5125 (0.5283)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_385_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.528%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:386]  [  0/172]  eta: 0:08:43  lr: 0.000068  loss: 0.5168 (0.5168)  time: 3.0421  data: 1.4575  max mem: 20571\n",
      "Train: [epoch:386]  [ 10/172]  eta: 0:04:37  lr: 0.000068  loss: 0.5388 (0.5396)  time: 1.7158  data: 0.1326  max mem: 20571\n",
      "Train: [epoch:386]  [ 20/172]  eta: 0:04:11  lr: 0.000068  loss: 0.5517 (0.5524)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [ 30/172]  eta: 0:03:51  lr: 0.000068  loss: 0.5638 (0.5537)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [ 40/172]  eta: 0:03:33  lr: 0.000068  loss: 0.5421 (0.5502)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [ 50/172]  eta: 0:03:16  lr: 0.000068  loss: 0.5398 (0.5500)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [ 60/172]  eta: 0:03:00  lr: 0.000068  loss: 0.5403 (0.5498)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [ 70/172]  eta: 0:02:43  lr: 0.000068  loss: 0.5488 (0.5502)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [ 80/172]  eta: 0:02:27  lr: 0.000068  loss: 0.5488 (0.5503)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [ 90/172]  eta: 0:02:11  lr: 0.000068  loss: 0.5438 (0.5483)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [100/172]  eta: 0:01:55  lr: 0.000068  loss: 0.5438 (0.5492)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [110/172]  eta: 0:01:39  lr: 0.000068  loss: 0.5478 (0.5492)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [120/172]  eta: 0:01:22  lr: 0.000068  loss: 0.5380 (0.5491)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [130/172]  eta: 0:01:06  lr: 0.000068  loss: 0.5349 (0.5489)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [140/172]  eta: 0:00:51  lr: 0.000068  loss: 0.5372 (0.5481)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [150/172]  eta: 0:00:35  lr: 0.000068  loss: 0.5338 (0.5469)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [160/172]  eta: 0:00:19  lr: 0.000068  loss: 0.5315 (0.5464)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [170/172]  eta: 0:00:03  lr: 0.000068  loss: 0.5400 (0.5468)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386]  [171/172]  eta: 0:00:01  lr: 0.000068  loss: 0.5370 (0.5465)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:386] Total time: 0:04:34 (1.5931 s / it)\n",
      "Averaged stats: lr: 0.000068  loss: 0.5370 (0.5465)\n",
      "Valid: [epoch:386]  [ 0/14]  eta: 0:00:05  loss: 0.5178 (0.5178)  time: 0.4078  data: 0.3929  max mem: 20571\n",
      "Valid: [epoch:386]  [13/14]  eta: 0:00:00  loss: 0.5178 (0.5348)  time: 0.0437  data: 0.0287  max mem: 20571\n",
      "Valid: [epoch:386] Total time: 0:00:00 (0.0510 s / it)\n",
      "Averaged stats: loss: 0.5178 (0.5348)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_386_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.535%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:387]  [  0/172]  eta: 0:07:36  lr: 0.000068  loss: 0.5817 (0.5817)  time: 2.6567  data: 1.0712  max mem: 20571\n",
      "Train: [epoch:387]  [ 10/172]  eta: 0:04:31  lr: 0.000068  loss: 0.5468 (0.5554)  time: 1.6778  data: 0.0975  max mem: 20571\n",
      "Train: [epoch:387]  [ 20/172]  eta: 0:04:08  lr: 0.000068  loss: 0.5468 (0.5615)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [ 30/172]  eta: 0:03:49  lr: 0.000068  loss: 0.5469 (0.5594)  time: 1.5859  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:387]  [ 40/172]  eta: 0:03:32  lr: 0.000068  loss: 0.5415 (0.5521)  time: 1.5865  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:387]  [ 50/172]  eta: 0:03:15  lr: 0.000068  loss: 0.5422 (0.5520)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [ 60/172]  eta: 0:02:59  lr: 0.000068  loss: 0.5482 (0.5507)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [ 70/172]  eta: 0:02:43  lr: 0.000068  loss: 0.5348 (0.5498)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [ 80/172]  eta: 0:02:26  lr: 0.000068  loss: 0.5559 (0.5527)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [ 90/172]  eta: 0:02:10  lr: 0.000068  loss: 0.5674 (0.5514)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [100/172]  eta: 0:01:54  lr: 0.000068  loss: 0.5514 (0.5513)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [110/172]  eta: 0:01:38  lr: 0.000068  loss: 0.5562 (0.5514)  time: 1.5841  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:387]  [120/172]  eta: 0:01:22  lr: 0.000068  loss: 0.5745 (0.5517)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [130/172]  eta: 0:01:06  lr: 0.000068  loss: 0.5411 (0.5515)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [140/172]  eta: 0:00:50  lr: 0.000068  loss: 0.5379 (0.5514)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [150/172]  eta: 0:00:35  lr: 0.000068  loss: 0.5331 (0.5508)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [160/172]  eta: 0:00:19  lr: 0.000068  loss: 0.5331 (0.5507)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [170/172]  eta: 0:00:03  lr: 0.000068  loss: 0.5387 (0.5508)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387]  [171/172]  eta: 0:00:01  lr: 0.000068  loss: 0.5387 (0.5506)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:387] Total time: 0:04:33 (1.5910 s / it)\n",
      "Averaged stats: lr: 0.000068  loss: 0.5387 (0.5506)\n",
      "Valid: [epoch:387]  [ 0/14]  eta: 0:00:04  loss: 0.4651 (0.4651)  time: 0.3570  data: 0.3416  max mem: 20571\n",
      "Valid: [epoch:387]  [13/14]  eta: 0:00:00  loss: 0.5131 (0.5308)  time: 0.0403  data: 0.0252  max mem: 20571\n",
      "Valid: [epoch:387] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.5131 (0.5308)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_387_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.531%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:388]  [  0/172]  eta: 0:07:49  lr: 0.000068  loss: 0.5804 (0.5804)  time: 2.7316  data: 1.1614  max mem: 20571\n",
      "Train: [epoch:388]  [ 10/172]  eta: 0:04:32  lr: 0.000068  loss: 0.5504 (0.5521)  time: 1.6847  data: 0.1057  max mem: 20571\n",
      "Train: [epoch:388]  [ 20/172]  eta: 0:04:08  lr: 0.000068  loss: 0.5383 (0.5467)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [ 30/172]  eta: 0:03:49  lr: 0.000068  loss: 0.5472 (0.5483)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [ 40/172]  eta: 0:03:32  lr: 0.000068  loss: 0.5472 (0.5481)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [ 50/172]  eta: 0:03:15  lr: 0.000068  loss: 0.5345 (0.5478)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [ 60/172]  eta: 0:02:59  lr: 0.000068  loss: 0.5423 (0.5468)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [ 70/172]  eta: 0:02:42  lr: 0.000068  loss: 0.5379 (0.5464)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [ 80/172]  eta: 0:02:26  lr: 0.000068  loss: 0.5373 (0.5463)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [ 90/172]  eta: 0:02:10  lr: 0.000068  loss: 0.5334 (0.5457)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [100/172]  eta: 0:01:54  lr: 0.000068  loss: 0.5358 (0.5445)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [110/172]  eta: 0:01:38  lr: 0.000068  loss: 0.5467 (0.5447)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [120/172]  eta: 0:01:22  lr: 0.000068  loss: 0.5421 (0.5444)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [130/172]  eta: 0:01:06  lr: 0.000068  loss: 0.5370 (0.5442)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [140/172]  eta: 0:00:50  lr: 0.000068  loss: 0.5494 (0.5443)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [150/172]  eta: 0:00:34  lr: 0.000068  loss: 0.5445 (0.5439)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [160/172]  eta: 0:00:19  lr: 0.000068  loss: 0.5387 (0.5437)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [170/172]  eta: 0:00:03  lr: 0.000068  loss: 0.5617 (0.5457)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388]  [171/172]  eta: 0:00:01  lr: 0.000068  loss: 0.5617 (0.5457)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:388] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000068  loss: 0.5617 (0.5457)\n",
      "Valid: [epoch:388]  [ 0/14]  eta: 0:00:03  loss: 0.6240 (0.6240)  time: 0.2842  data: 0.2683  max mem: 20571\n",
      "Valid: [epoch:388]  [13/14]  eta: 0:00:00  loss: 0.5636 (0.5787)  time: 0.0429  data: 0.0276  max mem: 20571\n",
      "Valid: [epoch:388] Total time: 0:00:00 (0.0479 s / it)\n",
      "Averaged stats: loss: 0.5636 (0.5787)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_388_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.579%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:389]  [  0/172]  eta: 0:07:47  lr: 0.000068  loss: 0.5465 (0.5465)  time: 2.7209  data: 1.1387  max mem: 20571\n",
      "Train: [epoch:389]  [ 10/172]  eta: 0:04:32  lr: 0.000068  loss: 0.5465 (0.5488)  time: 1.6821  data: 0.1036  max mem: 20571\n",
      "Train: [epoch:389]  [ 20/172]  eta: 0:04:08  lr: 0.000068  loss: 0.5479 (0.5526)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [ 30/172]  eta: 0:03:49  lr: 0.000068  loss: 0.5611 (0.5542)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [ 40/172]  eta: 0:03:32  lr: 0.000068  loss: 0.5689 (0.5548)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [ 50/172]  eta: 0:03:15  lr: 0.000068  loss: 0.5580 (0.5552)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [ 60/172]  eta: 0:02:59  lr: 0.000068  loss: 0.5421 (0.5511)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [ 70/172]  eta: 0:02:42  lr: 0.000068  loss: 0.5384 (0.5517)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [ 80/172]  eta: 0:02:26  lr: 0.000068  loss: 0.5465 (0.5512)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [ 90/172]  eta: 0:02:10  lr: 0.000068  loss: 0.5369 (0.5498)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [100/172]  eta: 0:01:54  lr: 0.000068  loss: 0.5478 (0.5507)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [110/172]  eta: 0:01:38  lr: 0.000068  loss: 0.5559 (0.5505)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [120/172]  eta: 0:01:22  lr: 0.000068  loss: 0.5489 (0.5501)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [130/172]  eta: 0:01:06  lr: 0.000068  loss: 0.5369 (0.5494)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [140/172]  eta: 0:00:50  lr: 0.000068  loss: 0.5381 (0.5493)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [150/172]  eta: 0:00:34  lr: 0.000068  loss: 0.5380 (0.5497)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [160/172]  eta: 0:00:19  lr: 0.000068  loss: 0.5380 (0.5497)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [170/172]  eta: 0:00:03  lr: 0.000068  loss: 0.5432 (0.5495)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389]  [171/172]  eta: 0:00:01  lr: 0.000068  loss: 0.5409 (0.5494)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:389] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000068  loss: 0.5409 (0.5494)\n",
      "Valid: [epoch:389]  [ 0/14]  eta: 0:00:04  loss: 0.4578 (0.4578)  time: 0.3289  data: 0.3115  max mem: 20571\n",
      "Valid: [epoch:389]  [13/14]  eta: 0:00:00  loss: 0.5138 (0.5298)  time: 0.0378  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:389] Total time: 0:00:00 (0.0424 s / it)\n",
      "Averaged stats: loss: 0.5138 (0.5298)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_389_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.530%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:390]  [  0/172]  eta: 0:07:37  lr: 0.000068  loss: 0.5547 (0.5547)  time: 2.6609  data: 1.0928  max mem: 20571\n",
      "Train: [epoch:390]  [ 10/172]  eta: 0:04:31  lr: 0.000068  loss: 0.5400 (0.5441)  time: 1.6771  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:390]  [ 20/172]  eta: 0:04:07  lr: 0.000068  loss: 0.5400 (0.5503)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [ 30/172]  eta: 0:03:49  lr: 0.000068  loss: 0.5397 (0.5443)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [ 40/172]  eta: 0:03:31  lr: 0.000068  loss: 0.5281 (0.5447)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [ 50/172]  eta: 0:03:15  lr: 0.000068  loss: 0.5346 (0.5443)  time: 1.5794  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:390]  [ 60/172]  eta: 0:02:58  lr: 0.000068  loss: 0.5533 (0.5517)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [ 70/172]  eta: 0:02:42  lr: 0.000068  loss: 0.5584 (0.5508)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [ 80/172]  eta: 0:02:26  lr: 0.000068  loss: 0.5359 (0.5504)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [ 90/172]  eta: 0:02:10  lr: 0.000068  loss: 0.5520 (0.5501)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [100/172]  eta: 0:01:54  lr: 0.000068  loss: 0.5520 (0.5503)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [110/172]  eta: 0:01:38  lr: 0.000068  loss: 0.5458 (0.5506)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [120/172]  eta: 0:01:22  lr: 0.000068  loss: 0.5390 (0.5500)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [130/172]  eta: 0:01:06  lr: 0.000068  loss: 0.5390 (0.5493)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [140/172]  eta: 0:00:50  lr: 0.000068  loss: 0.5471 (0.5497)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [150/172]  eta: 0:00:34  lr: 0.000068  loss: 0.5524 (0.5496)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [160/172]  eta: 0:00:19  lr: 0.000068  loss: 0.5426 (0.5496)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [170/172]  eta: 0:00:03  lr: 0.000068  loss: 0.5569 (0.5503)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390]  [171/172]  eta: 0:00:01  lr: 0.000068  loss: 0.5569 (0.5501)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:390] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000068  loss: 0.5569 (0.5501)\n",
      "Valid: [epoch:390]  [ 0/14]  eta: 0:00:04  loss: 0.4739 (0.4739)  time: 0.3465  data: 0.3280  max mem: 20571\n",
      "Valid: [epoch:390]  [13/14]  eta: 0:00:00  loss: 0.5105 (0.5255)  time: 0.0397  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:390] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.5105 (0.5255)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_390_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.525%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:391]  [  0/172]  eta: 0:07:41  lr: 0.000068  loss: 0.5476 (0.5476)  time: 2.6843  data: 1.1097  max mem: 20571\n",
      "Train: [epoch:391]  [ 10/172]  eta: 0:04:31  lr: 0.000068  loss: 0.5495 (0.5493)  time: 1.6755  data: 0.1010  max mem: 20571\n",
      "Train: [epoch:391]  [ 20/172]  eta: 0:04:07  lr: 0.000068  loss: 0.5421 (0.5429)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [ 30/172]  eta: 0:03:48  lr: 0.000068  loss: 0.5435 (0.5468)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [ 40/172]  eta: 0:03:31  lr: 0.000068  loss: 0.5310 (0.5425)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [ 50/172]  eta: 0:03:15  lr: 0.000068  loss: 0.5214 (0.5414)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [ 60/172]  eta: 0:02:58  lr: 0.000068  loss: 0.5355 (0.5441)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [ 70/172]  eta: 0:02:42  lr: 0.000068  loss: 0.5380 (0.5444)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [ 80/172]  eta: 0:02:26  lr: 0.000068  loss: 0.5409 (0.5451)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [ 90/172]  eta: 0:02:10  lr: 0.000068  loss: 0.5409 (0.5448)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [100/172]  eta: 0:01:54  lr: 0.000068  loss: 0.5449 (0.5455)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [110/172]  eta: 0:01:38  lr: 0.000068  loss: 0.5449 (0.5464)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [120/172]  eta: 0:01:22  lr: 0.000068  loss: 0.5389 (0.5464)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [130/172]  eta: 0:01:06  lr: 0.000068  loss: 0.5389 (0.5472)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [140/172]  eta: 0:00:50  lr: 0.000068  loss: 0.5424 (0.5468)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [150/172]  eta: 0:00:34  lr: 0.000068  loss: 0.5424 (0.5466)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [160/172]  eta: 0:00:19  lr: 0.000068  loss: 0.5615 (0.5474)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [170/172]  eta: 0:00:03  lr: 0.000068  loss: 0.5432 (0.5472)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391]  [171/172]  eta: 0:00:01  lr: 0.000068  loss: 0.5432 (0.5473)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:391] Total time: 0:04:32 (1.5848 s / it)\n",
      "Averaged stats: lr: 0.000068  loss: 0.5432 (0.5473)\n",
      "Valid: [epoch:391]  [ 0/14]  eta: 0:00:04  loss: 0.5645 (0.5645)  time: 0.3386  data: 0.3224  max mem: 20571\n",
      "Valid: [epoch:391]  [13/14]  eta: 0:00:00  loss: 0.5021 (0.5171)  time: 0.0384  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:391] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.5021 (0.5171)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_391_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.517%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:392]  [  0/172]  eta: 0:07:40  lr: 0.000068  loss: 0.5410 (0.5410)  time: 2.6771  data: 1.0980  max mem: 20571\n",
      "Train: [epoch:392]  [ 10/172]  eta: 0:04:32  lr: 0.000068  loss: 0.5480 (0.5569)  time: 1.6811  data: 0.0999  max mem: 20571\n",
      "Train: [epoch:392]  [ 20/172]  eta: 0:04:08  lr: 0.000068  loss: 0.5480 (0.5569)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [ 30/172]  eta: 0:03:49  lr: 0.000068  loss: 0.5423 (0.5491)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [ 40/172]  eta: 0:03:31  lr: 0.000068  loss: 0.5408 (0.5504)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [ 50/172]  eta: 0:03:15  lr: 0.000068  loss: 0.5454 (0.5494)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [ 60/172]  eta: 0:02:58  lr: 0.000068  loss: 0.5496 (0.5492)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [ 70/172]  eta: 0:02:42  lr: 0.000068  loss: 0.5558 (0.5504)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [ 80/172]  eta: 0:02:26  lr: 0.000068  loss: 0.5554 (0.5497)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [ 90/172]  eta: 0:02:10  lr: 0.000068  loss: 0.5383 (0.5489)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [100/172]  eta: 0:01:54  lr: 0.000068  loss: 0.5344 (0.5492)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [110/172]  eta: 0:01:38  lr: 0.000068  loss: 0.5492 (0.5497)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [120/172]  eta: 0:01:22  lr: 0.000068  loss: 0.5529 (0.5501)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [130/172]  eta: 0:01:06  lr: 0.000068  loss: 0.5427 (0.5492)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [140/172]  eta: 0:00:50  lr: 0.000068  loss: 0.5376 (0.5491)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [150/172]  eta: 0:00:34  lr: 0.000068  loss: 0.5376 (0.5487)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [160/172]  eta: 0:00:19  lr: 0.000068  loss: 0.5475 (0.5487)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [170/172]  eta: 0:00:03  lr: 0.000068  loss: 0.5343 (0.5485)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392]  [171/172]  eta: 0:00:01  lr: 0.000068  loss: 0.5351 (0.5488)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:392] Total time: 0:04:32 (1.5844 s / it)\n",
      "Averaged stats: lr: 0.000068  loss: 0.5351 (0.5488)\n",
      "Valid: [epoch:392]  [ 0/14]  eta: 0:00:05  loss: 0.5076 (0.5076)  time: 0.3738  data: 0.3570  max mem: 20571\n",
      "Valid: [epoch:392]  [13/14]  eta: 0:00:00  loss: 0.5224 (0.5373)  time: 0.0409  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:392] Total time: 0:00:00 (0.0466 s / it)\n",
      "Averaged stats: loss: 0.5224 (0.5373)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_392_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.537%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:393]  [  0/172]  eta: 0:07:39  lr: 0.000068  loss: 0.5885 (0.5885)  time: 2.6710  data: 1.0992  max mem: 20571\n",
      "Train: [epoch:393]  [ 10/172]  eta: 0:04:31  lr: 0.000068  loss: 0.5484 (0.5492)  time: 1.6741  data: 0.1000  max mem: 20571\n",
      "Train: [epoch:393]  [ 20/172]  eta: 0:04:07  lr: 0.000068  loss: 0.5436 (0.5502)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [ 30/172]  eta: 0:03:48  lr: 0.000068  loss: 0.5546 (0.5636)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [ 40/172]  eta: 0:03:31  lr: 0.000068  loss: 0.5565 (0.5594)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [ 50/172]  eta: 0:03:15  lr: 0.000068  loss: 0.5565 (0.5581)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [ 60/172]  eta: 0:02:58  lr: 0.000068  loss: 0.5617 (0.5588)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [ 70/172]  eta: 0:02:42  lr: 0.000068  loss: 0.5521 (0.5571)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [ 80/172]  eta: 0:02:26  lr: 0.000068  loss: 0.5410 (0.5563)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [ 90/172]  eta: 0:02:10  lr: 0.000068  loss: 0.5485 (0.5558)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [100/172]  eta: 0:01:54  lr: 0.000068  loss: 0.5485 (0.5557)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [110/172]  eta: 0:01:38  lr: 0.000068  loss: 0.5323 (0.5548)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [120/172]  eta: 0:01:22  lr: 0.000068  loss: 0.5475 (0.5546)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [130/172]  eta: 0:01:06  lr: 0.000068  loss: 0.5475 (0.5534)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [140/172]  eta: 0:00:50  lr: 0.000068  loss: 0.5476 (0.5534)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [150/172]  eta: 0:00:34  lr: 0.000068  loss: 0.5442 (0.5524)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [160/172]  eta: 0:00:19  lr: 0.000068  loss: 0.5329 (0.5511)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [170/172]  eta: 0:00:03  lr: 0.000068  loss: 0.5343 (0.5509)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393]  [171/172]  eta: 0:00:01  lr: 0.000068  loss: 0.5361 (0.5511)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:393] Total time: 0:04:32 (1.5856 s / it)\n",
      "Averaged stats: lr: 0.000068  loss: 0.5361 (0.5511)\n",
      "Valid: [epoch:393]  [ 0/14]  eta: 0:00:04  loss: 0.4969 (0.4969)  time: 0.2870  data: 0.2720  max mem: 20571\n",
      "Valid: [epoch:393]  [13/14]  eta: 0:00:00  loss: 0.4969 (0.5117)  time: 0.0395  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:393] Total time: 0:00:00 (0.0475 s / it)\n",
      "Averaged stats: loss: 0.4969 (0.5117)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_393_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.512%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:394]  [  0/172]  eta: 0:07:49  lr: 0.000067  loss: 0.6025 (0.6025)  time: 2.7300  data: 1.1501  max mem: 20571\n",
      "Train: [epoch:394]  [ 10/172]  eta: 0:04:32  lr: 0.000067  loss: 0.5360 (0.5412)  time: 1.6833  data: 0.1047  max mem: 20571\n",
      "Train: [epoch:394]  [ 20/172]  eta: 0:04:08  lr: 0.000067  loss: 0.5394 (0.5487)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:394]  [ 30/172]  eta: 0:03:49  lr: 0.000067  loss: 0.5442 (0.5481)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:394]  [ 40/172]  eta: 0:03:32  lr: 0.000067  loss: 0.5358 (0.5449)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [ 50/172]  eta: 0:03:15  lr: 0.000067  loss: 0.5366 (0.5465)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [ 60/172]  eta: 0:02:58  lr: 0.000067  loss: 0.5603 (0.5504)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:394]  [ 70/172]  eta: 0:02:42  lr: 0.000067  loss: 0.5580 (0.5510)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [ 80/172]  eta: 0:02:26  lr: 0.000067  loss: 0.5511 (0.5511)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [ 90/172]  eta: 0:02:10  lr: 0.000067  loss: 0.5442 (0.5508)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [100/172]  eta: 0:01:54  lr: 0.000067  loss: 0.5402 (0.5489)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [110/172]  eta: 0:01:38  lr: 0.000067  loss: 0.5390 (0.5492)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [120/172]  eta: 0:01:22  lr: 0.000067  loss: 0.5527 (0.5504)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [130/172]  eta: 0:01:06  lr: 0.000067  loss: 0.5401 (0.5489)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [140/172]  eta: 0:00:50  lr: 0.000067  loss: 0.5261 (0.5484)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [150/172]  eta: 0:00:34  lr: 0.000067  loss: 0.5416 (0.5477)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [160/172]  eta: 0:00:19  lr: 0.000067  loss: 0.5467 (0.5480)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [170/172]  eta: 0:00:03  lr: 0.000067  loss: 0.5429 (0.5481)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394]  [171/172]  eta: 0:00:01  lr: 0.000067  loss: 0.5429 (0.5484)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:394] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000067  loss: 0.5429 (0.5484)\n",
      "Valid: [epoch:394]  [ 0/14]  eta: 0:00:04  loss: 0.4832 (0.4832)  time: 0.3135  data: 0.2978  max mem: 20571\n",
      "Valid: [epoch:394]  [13/14]  eta: 0:00:00  loss: 0.5009 (0.5160)  time: 0.0367  data: 0.0216  max mem: 20571\n",
      "Valid: [epoch:394] Total time: 0:00:00 (0.0450 s / it)\n",
      "Averaged stats: loss: 0.5009 (0.5160)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_394_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.516%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:395]  [  0/172]  eta: 0:07:30  lr: 0.000067  loss: 0.4936 (0.4936)  time: 2.6195  data: 1.0405  max mem: 20571\n",
      "Train: [epoch:395]  [ 10/172]  eta: 0:04:30  lr: 0.000067  loss: 0.5402 (0.5373)  time: 1.6698  data: 0.0947  max mem: 20571\n",
      "Train: [epoch:395]  [ 20/172]  eta: 0:04:06  lr: 0.000067  loss: 0.5423 (0.5495)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [ 30/172]  eta: 0:03:48  lr: 0.000067  loss: 0.5690 (0.5481)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [ 40/172]  eta: 0:03:31  lr: 0.000067  loss: 0.5445 (0.5484)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [ 50/172]  eta: 0:03:14  lr: 0.000067  loss: 0.5495 (0.5509)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [ 60/172]  eta: 0:02:58  lr: 0.000067  loss: 0.5495 (0.5493)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [ 70/172]  eta: 0:02:42  lr: 0.000067  loss: 0.5421 (0.5495)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [ 80/172]  eta: 0:02:26  lr: 0.000067  loss: 0.5407 (0.5503)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [ 90/172]  eta: 0:02:10  lr: 0.000067  loss: 0.5568 (0.5511)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [100/172]  eta: 0:01:54  lr: 0.000067  loss: 0.5518 (0.5500)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [110/172]  eta: 0:01:38  lr: 0.000067  loss: 0.5510 (0.5501)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [120/172]  eta: 0:01:22  lr: 0.000067  loss: 0.5595 (0.5501)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [130/172]  eta: 0:01:06  lr: 0.000067  loss: 0.5462 (0.5496)  time: 1.5761  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:395]  [140/172]  eta: 0:00:50  lr: 0.000067  loss: 0.5412 (0.5492)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [150/172]  eta: 0:00:34  lr: 0.000067  loss: 0.5330 (0.5486)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [160/172]  eta: 0:00:18  lr: 0.000067  loss: 0.5330 (0.5476)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395]  [170/172]  eta: 0:00:03  lr: 0.000067  loss: 0.5338 (0.5470)  time: 1.5776  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:395]  [171/172]  eta: 0:00:01  lr: 0.000067  loss: 0.5365 (0.5470)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:395] Total time: 0:04:32 (1.5832 s / it)\n",
      "Averaged stats: lr: 0.000067  loss: 0.5365 (0.5470)\n",
      "Valid: [epoch:395]  [ 0/14]  eta: 0:00:04  loss: 0.5569 (0.5569)  time: 0.3294  data: 0.3137  max mem: 20571\n",
      "Valid: [epoch:395]  [13/14]  eta: 0:00:00  loss: 0.5008 (0.5162)  time: 0.0384  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:395] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.5008 (0.5162)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_395_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.516%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:396]  [  0/172]  eta: 0:07:33  lr: 0.000067  loss: 0.5018 (0.5018)  time: 2.6377  data: 1.0682  max mem: 20571\n",
      "Train: [epoch:396]  [ 10/172]  eta: 0:04:30  lr: 0.000067  loss: 0.5351 (0.5403)  time: 1.6709  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:396]  [ 20/172]  eta: 0:04:07  lr: 0.000067  loss: 0.5486 (0.5451)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [ 30/172]  eta: 0:03:48  lr: 0.000067  loss: 0.5540 (0.5484)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [ 40/172]  eta: 0:03:31  lr: 0.000067  loss: 0.5468 (0.5455)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [ 50/172]  eta: 0:03:14  lr: 0.000067  loss: 0.5372 (0.5470)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [ 60/172]  eta: 0:02:58  lr: 0.000067  loss: 0.5502 (0.5476)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [ 70/172]  eta: 0:02:42  lr: 0.000067  loss: 0.5418 (0.5474)  time: 1.5768  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:396]  [ 80/172]  eta: 0:02:26  lr: 0.000067  loss: 0.5349 (0.5475)  time: 1.5771  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:396]  [ 90/172]  eta: 0:02:10  lr: 0.000067  loss: 0.5444 (0.5479)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [100/172]  eta: 0:01:54  lr: 0.000067  loss: 0.5296 (0.5463)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [110/172]  eta: 0:01:38  lr: 0.000067  loss: 0.5234 (0.5460)  time: 1.5783  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:396]  [120/172]  eta: 0:01:22  lr: 0.000067  loss: 0.5497 (0.5465)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:396]  [130/172]  eta: 0:01:06  lr: 0.000067  loss: 0.5432 (0.5460)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [140/172]  eta: 0:00:50  lr: 0.000067  loss: 0.5411 (0.5459)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [150/172]  eta: 0:00:34  lr: 0.000067  loss: 0.5488 (0.5463)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [160/172]  eta: 0:00:19  lr: 0.000067  loss: 0.5488 (0.5466)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [170/172]  eta: 0:00:03  lr: 0.000067  loss: 0.5419 (0.5467)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396]  [171/172]  eta: 0:00:01  lr: 0.000067  loss: 0.5419 (0.5466)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:396] Total time: 0:04:32 (1.5850 s / it)\n",
      "Averaged stats: lr: 0.000067  loss: 0.5419 (0.5466)\n",
      "Valid: [epoch:396]  [ 0/14]  eta: 0:00:04  loss: 0.5697 (0.5697)  time: 0.3307  data: 0.3158  max mem: 20571\n",
      "Valid: [epoch:396]  [13/14]  eta: 0:00:00  loss: 0.5070 (0.5240)  time: 0.0408  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:396] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.5070 (0.5240)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_396_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.524%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:397]  [  0/172]  eta: 0:07:25  lr: 0.000067  loss: 0.5566 (0.5566)  time: 2.5885  data: 1.0105  max mem: 20571\n",
      "Train: [epoch:397]  [ 10/172]  eta: 0:04:30  lr: 0.000067  loss: 0.5292 (0.5387)  time: 1.6698  data: 0.0920  max mem: 20571\n",
      "Train: [epoch:397]  [ 20/172]  eta: 0:04:07  lr: 0.000067  loss: 0.5401 (0.5500)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [ 30/172]  eta: 0:03:48  lr: 0.000067  loss: 0.5586 (0.5509)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [ 40/172]  eta: 0:03:31  lr: 0.000067  loss: 0.5359 (0.5486)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [ 50/172]  eta: 0:03:15  lr: 0.000067  loss: 0.5342 (0.5467)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [ 60/172]  eta: 0:02:58  lr: 0.000067  loss: 0.5379 (0.5479)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [ 70/172]  eta: 0:02:42  lr: 0.000067  loss: 0.5478 (0.5475)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [ 80/172]  eta: 0:02:26  lr: 0.000067  loss: 0.5586 (0.5491)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [ 90/172]  eta: 0:02:10  lr: 0.000067  loss: 0.5504 (0.5493)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [100/172]  eta: 0:01:54  lr: 0.000067  loss: 0.5404 (0.5479)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [110/172]  eta: 0:01:38  lr: 0.000067  loss: 0.5357 (0.5474)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [120/172]  eta: 0:01:22  lr: 0.000067  loss: 0.5392 (0.5469)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [130/172]  eta: 0:01:06  lr: 0.000067  loss: 0.5462 (0.5479)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [140/172]  eta: 0:00:50  lr: 0.000067  loss: 0.5428 (0.5476)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [150/172]  eta: 0:00:34  lr: 0.000067  loss: 0.5460 (0.5476)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [160/172]  eta: 0:00:19  lr: 0.000067  loss: 0.5569 (0.5478)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [170/172]  eta: 0:00:03  lr: 0.000067  loss: 0.5323 (0.5480)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397]  [171/172]  eta: 0:00:01  lr: 0.000067  loss: 0.5323 (0.5482)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:397] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000067  loss: 0.5323 (0.5482)\n",
      "Valid: [epoch:397]  [ 0/14]  eta: 0:00:04  loss: 0.4938 (0.4938)  time: 0.3098  data: 0.2949  max mem: 20571\n",
      "Valid: [epoch:397]  [13/14]  eta: 0:00:00  loss: 0.5070 (0.5200)  time: 0.0368  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:397] Total time: 0:00:00 (0.0425 s / it)\n",
      "Averaged stats: loss: 0.5070 (0.5200)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_397_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.520%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:398]  [  0/172]  eta: 0:07:35  lr: 0.000067  loss: 0.5894 (0.5894)  time: 2.6481  data: 1.0731  max mem: 20571\n",
      "Train: [epoch:398]  [ 10/172]  eta: 0:04:31  lr: 0.000067  loss: 0.5401 (0.5446)  time: 1.6765  data: 0.0976  max mem: 20571\n",
      "Train: [epoch:398]  [ 20/172]  eta: 0:04:07  lr: 0.000067  loss: 0.5373 (0.5455)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [ 30/172]  eta: 0:03:49  lr: 0.000067  loss: 0.5420 (0.5483)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [ 40/172]  eta: 0:03:32  lr: 0.000067  loss: 0.5467 (0.5472)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [ 50/172]  eta: 0:03:15  lr: 0.000067  loss: 0.5412 (0.5464)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [ 60/172]  eta: 0:02:58  lr: 0.000067  loss: 0.5504 (0.5487)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [ 70/172]  eta: 0:02:42  lr: 0.000067  loss: 0.5532 (0.5482)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [ 80/172]  eta: 0:02:26  lr: 0.000067  loss: 0.5483 (0.5485)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [ 90/172]  eta: 0:02:10  lr: 0.000067  loss: 0.5481 (0.5486)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [100/172]  eta: 0:01:54  lr: 0.000067  loss: 0.5423 (0.5484)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [110/172]  eta: 0:01:38  lr: 0.000067  loss: 0.5401 (0.5476)  time: 1.5801  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:398]  [120/172]  eta: 0:01:22  lr: 0.000067  loss: 0.5421 (0.5476)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [130/172]  eta: 0:01:06  lr: 0.000067  loss: 0.5410 (0.5468)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [140/172]  eta: 0:00:50  lr: 0.000067  loss: 0.5378 (0.5461)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [150/172]  eta: 0:00:34  lr: 0.000067  loss: 0.5441 (0.5466)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [160/172]  eta: 0:00:19  lr: 0.000067  loss: 0.5441 (0.5459)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [170/172]  eta: 0:00:03  lr: 0.000067  loss: 0.5369 (0.5461)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398]  [171/172]  eta: 0:00:01  lr: 0.000067  loss: 0.5393 (0.5463)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:398] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000067  loss: 0.5393 (0.5463)\n",
      "Valid: [epoch:398]  [ 0/14]  eta: 0:00:04  loss: 0.5089 (0.5089)  time: 0.2963  data: 0.2797  max mem: 20571\n",
      "Valid: [epoch:398]  [13/14]  eta: 0:00:00  loss: 0.5125 (0.5270)  time: 0.0362  data: 0.0211  max mem: 20571\n",
      "Valid: [epoch:398] Total time: 0:00:00 (0.0410 s / it)\n",
      "Averaged stats: loss: 0.5125 (0.5270)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_398_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.527%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:399]  [  0/172]  eta: 0:07:33  lr: 0.000067  loss: 0.5579 (0.5579)  time: 2.6358  data: 1.0613  max mem: 20571\n",
      "Train: [epoch:399]  [ 10/172]  eta: 0:04:30  lr: 0.000067  loss: 0.5594 (0.5687)  time: 1.6727  data: 0.0966  max mem: 20571\n",
      "Train: [epoch:399]  [ 20/172]  eta: 0:04:07  lr: 0.000067  loss: 0.5553 (0.5580)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [ 30/172]  eta: 0:03:48  lr: 0.000067  loss: 0.5553 (0.5591)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [ 40/172]  eta: 0:03:31  lr: 0.000067  loss: 0.5494 (0.5539)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [ 50/172]  eta: 0:03:14  lr: 0.000067  loss: 0.5437 (0.5553)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [ 60/172]  eta: 0:02:58  lr: 0.000067  loss: 0.5474 (0.5524)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [ 70/172]  eta: 0:02:42  lr: 0.000067  loss: 0.5433 (0.5509)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [ 80/172]  eta: 0:02:26  lr: 0.000067  loss: 0.5328 (0.5481)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [ 90/172]  eta: 0:02:10  lr: 0.000067  loss: 0.5213 (0.5475)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [100/172]  eta: 0:01:54  lr: 0.000067  loss: 0.5363 (0.5472)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [110/172]  eta: 0:01:38  lr: 0.000067  loss: 0.5445 (0.5475)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [120/172]  eta: 0:01:22  lr: 0.000067  loss: 0.5449 (0.5477)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [130/172]  eta: 0:01:06  lr: 0.000067  loss: 0.5449 (0.5473)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [140/172]  eta: 0:00:50  lr: 0.000067  loss: 0.5523 (0.5482)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [150/172]  eta: 0:00:34  lr: 0.000067  loss: 0.5482 (0.5475)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [160/172]  eta: 0:00:19  lr: 0.000067  loss: 0.5352 (0.5474)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [170/172]  eta: 0:00:03  lr: 0.000067  loss: 0.5353 (0.5469)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399]  [171/172]  eta: 0:00:01  lr: 0.000067  loss: 0.5353 (0.5472)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:399] Total time: 0:04:32 (1.5843 s / it)\n",
      "Averaged stats: lr: 0.000067  loss: 0.5353 (0.5472)\n",
      "Valid: [epoch:399]  [ 0/14]  eta: 0:00:03  loss: 0.5625 (0.5625)  time: 0.2728  data: 0.2582  max mem: 20571\n",
      "Valid: [epoch:399]  [13/14]  eta: 0:00:00  loss: 0.5032 (0.5189)  time: 0.0344  data: 0.0195  max mem: 20571\n",
      "Valid: [epoch:399] Total time: 0:00:00 (0.0390 s / it)\n",
      "Averaged stats: loss: 0.5032 (0.5189)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_399_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.519%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:400]  [  0/172]  eta: 0:07:35  lr: 0.000067  loss: 0.5450 (0.5450)  time: 2.6512  data: 1.0855  max mem: 20571\n",
      "Train: [epoch:400]  [ 10/172]  eta: 0:04:31  lr: 0.000067  loss: 0.5469 (0.5507)  time: 1.6739  data: 0.0988  max mem: 20571\n",
      "Train: [epoch:400]  [ 20/172]  eta: 0:04:07  lr: 0.000067  loss: 0.5472 (0.5523)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [ 30/172]  eta: 0:03:48  lr: 0.000067  loss: 0.5480 (0.5498)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [ 40/172]  eta: 0:03:31  lr: 0.000067  loss: 0.5446 (0.5485)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [ 50/172]  eta: 0:03:15  lr: 0.000067  loss: 0.5291 (0.5453)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [ 60/172]  eta: 0:02:58  lr: 0.000067  loss: 0.5289 (0.5450)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [ 70/172]  eta: 0:02:42  lr: 0.000067  loss: 0.5497 (0.5477)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [ 80/172]  eta: 0:02:26  lr: 0.000067  loss: 0.5488 (0.5472)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [ 90/172]  eta: 0:02:10  lr: 0.000067  loss: 0.5488 (0.5485)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [100/172]  eta: 0:01:54  lr: 0.000067  loss: 0.5521 (0.5473)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [110/172]  eta: 0:01:38  lr: 0.000067  loss: 0.5339 (0.5472)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [120/172]  eta: 0:01:22  lr: 0.000067  loss: 0.5362 (0.5480)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [130/172]  eta: 0:01:06  lr: 0.000067  loss: 0.5370 (0.5468)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [140/172]  eta: 0:00:50  lr: 0.000067  loss: 0.5167 (0.5460)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [150/172]  eta: 0:00:34  lr: 0.000067  loss: 0.5248 (0.5454)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [160/172]  eta: 0:00:19  lr: 0.000067  loss: 0.5487 (0.5471)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [170/172]  eta: 0:00:03  lr: 0.000067  loss: 0.5607 (0.5476)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400]  [171/172]  eta: 0:00:01  lr: 0.000067  loss: 0.5607 (0.5477)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:400] Total time: 0:04:32 (1.5865 s / it)\n",
      "Averaged stats: lr: 0.000067  loss: 0.5607 (0.5477)\n",
      "Valid: [epoch:400]  [ 0/14]  eta: 0:00:04  loss: 0.5011 (0.5011)  time: 0.2900  data: 0.2750  max mem: 20571\n",
      "Valid: [epoch:400]  [13/14]  eta: 0:00:00  loss: 0.5011 (0.5144)  time: 0.0539  data: 0.0389  max mem: 20571\n",
      "Valid: [epoch:400] Total time: 0:00:00 (0.0620 s / it)\n",
      "Averaged stats: loss: 0.5011 (0.5144)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_400_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.514%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:401]  [  0/172]  eta: 0:07:17  lr: 0.000067  loss: 0.5434 (0.5434)  time: 2.5458  data: 0.9447  max mem: 20571\n",
      "Train: [epoch:401]  [ 10/172]  eta: 0:04:29  lr: 0.000067  loss: 0.5513 (0.5564)  time: 1.6642  data: 0.0860  max mem: 20571\n",
      "Train: [epoch:401]  [ 20/172]  eta: 0:04:06  lr: 0.000067  loss: 0.5478 (0.5548)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [ 30/172]  eta: 0:03:48  lr: 0.000067  loss: 0.5449 (0.5597)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [ 40/172]  eta: 0:03:31  lr: 0.000067  loss: 0.5432 (0.5561)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [ 50/172]  eta: 0:03:14  lr: 0.000067  loss: 0.5630 (0.5599)  time: 1.5808  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:401]  [ 60/172]  eta: 0:02:58  lr: 0.000067  loss: 0.5674 (0.5584)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [ 70/172]  eta: 0:02:42  lr: 0.000067  loss: 0.5381 (0.5562)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [ 80/172]  eta: 0:02:26  lr: 0.000067  loss: 0.5365 (0.5546)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [ 90/172]  eta: 0:02:10  lr: 0.000067  loss: 0.5401 (0.5534)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [100/172]  eta: 0:01:54  lr: 0.000067  loss: 0.5364 (0.5517)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [110/172]  eta: 0:01:38  lr: 0.000067  loss: 0.5448 (0.5520)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [120/172]  eta: 0:01:22  lr: 0.000067  loss: 0.5439 (0.5512)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [130/172]  eta: 0:01:06  lr: 0.000067  loss: 0.5371 (0.5506)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [140/172]  eta: 0:00:50  lr: 0.000067  loss: 0.5509 (0.5512)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [150/172]  eta: 0:00:34  lr: 0.000067  loss: 0.5374 (0.5510)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [160/172]  eta: 0:00:19  lr: 0.000067  loss: 0.5365 (0.5507)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [170/172]  eta: 0:00:03  lr: 0.000067  loss: 0.5383 (0.5497)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401]  [171/172]  eta: 0:00:01  lr: 0.000067  loss: 0.5405 (0.5497)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:401] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000067  loss: 0.5405 (0.5497)\n",
      "Valid: [epoch:401]  [ 0/14]  eta: 0:00:04  loss: 0.4967 (0.4967)  time: 0.3079  data: 0.2923  max mem: 20571\n",
      "Valid: [epoch:401]  [13/14]  eta: 0:00:00  loss: 0.5074 (0.5235)  time: 0.0382  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:401] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.5074 (0.5235)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_401_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.524%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:402]  [  0/172]  eta: 0:07:36  lr: 0.000067  loss: 0.5416 (0.5416)  time: 2.6520  data: 1.0662  max mem: 20571\n",
      "Train: [epoch:402]  [ 10/172]  eta: 0:04:31  lr: 0.000067  loss: 0.5474 (0.5522)  time: 1.6758  data: 0.0970  max mem: 20571\n",
      "Train: [epoch:402]  [ 20/172]  eta: 0:04:07  lr: 0.000067  loss: 0.5463 (0.5482)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [ 30/172]  eta: 0:03:49  lr: 0.000067  loss: 0.5436 (0.5468)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [ 40/172]  eta: 0:03:31  lr: 0.000067  loss: 0.5637 (0.5480)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [ 50/172]  eta: 0:03:15  lr: 0.000067  loss: 0.5524 (0.5465)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [ 60/172]  eta: 0:02:58  lr: 0.000067  loss: 0.5322 (0.5444)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [ 70/172]  eta: 0:02:42  lr: 0.000067  loss: 0.5320 (0.5453)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [ 80/172]  eta: 0:02:26  lr: 0.000067  loss: 0.5334 (0.5453)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [ 90/172]  eta: 0:02:10  lr: 0.000067  loss: 0.5439 (0.5457)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [100/172]  eta: 0:01:54  lr: 0.000067  loss: 0.5439 (0.5452)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [110/172]  eta: 0:01:38  lr: 0.000067  loss: 0.5451 (0.5453)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [120/172]  eta: 0:01:22  lr: 0.000067  loss: 0.5480 (0.5458)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [130/172]  eta: 0:01:06  lr: 0.000067  loss: 0.5462 (0.5458)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [140/172]  eta: 0:00:50  lr: 0.000067  loss: 0.5355 (0.5460)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [150/172]  eta: 0:00:34  lr: 0.000067  loss: 0.5338 (0.5457)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [160/172]  eta: 0:00:19  lr: 0.000067  loss: 0.5379 (0.5456)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [170/172]  eta: 0:00:03  lr: 0.000067  loss: 0.5407 (0.5463)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402]  [171/172]  eta: 0:00:01  lr: 0.000067  loss: 0.5407 (0.5461)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:402] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000067  loss: 0.5407 (0.5461)\n",
      "Valid: [epoch:402]  [ 0/14]  eta: 0:00:06  loss: 0.4598 (0.4598)  time: 0.4476  data: 0.4328  max mem: 20571\n",
      "Valid: [epoch:402]  [13/14]  eta: 0:00:00  loss: 0.5111 (0.5215)  time: 0.0466  data: 0.0317  max mem: 20571\n",
      "Valid: [epoch:402] Total time: 0:00:00 (0.0521 s / it)\n",
      "Averaged stats: loss: 0.5111 (0.5215)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_402_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.522%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:403]  [  0/172]  eta: 0:07:51  lr: 0.000066  loss: 0.5890 (0.5890)  time: 2.7421  data: 1.1644  max mem: 20571\n",
      "Train: [epoch:403]  [ 10/172]  eta: 0:04:32  lr: 0.000066  loss: 0.5419 (0.5524)  time: 1.6829  data: 0.1060  max mem: 20571\n",
      "Train: [epoch:403]  [ 20/172]  eta: 0:04:08  lr: 0.000066  loss: 0.5419 (0.5539)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [ 30/172]  eta: 0:03:49  lr: 0.000066  loss: 0.5439 (0.5528)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [ 40/172]  eta: 0:03:32  lr: 0.000066  loss: 0.5416 (0.5482)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [ 50/172]  eta: 0:03:15  lr: 0.000066  loss: 0.5416 (0.5476)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [ 60/172]  eta: 0:02:58  lr: 0.000066  loss: 0.5546 (0.5480)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [ 70/172]  eta: 0:02:42  lr: 0.000066  loss: 0.5529 (0.5486)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [ 80/172]  eta: 0:02:26  lr: 0.000066  loss: 0.5472 (0.5481)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [ 90/172]  eta: 0:02:10  lr: 0.000066  loss: 0.5421 (0.5490)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [100/172]  eta: 0:01:54  lr: 0.000066  loss: 0.5529 (0.5517)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [110/172]  eta: 0:01:38  lr: 0.000066  loss: 0.5533 (0.5518)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [120/172]  eta: 0:01:22  lr: 0.000066  loss: 0.5482 (0.5522)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [130/172]  eta: 0:01:06  lr: 0.000066  loss: 0.5499 (0.5526)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [140/172]  eta: 0:00:50  lr: 0.000066  loss: 0.5538 (0.5519)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [150/172]  eta: 0:00:34  lr: 0.000066  loss: 0.5346 (0.5509)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [160/172]  eta: 0:00:19  lr: 0.000066  loss: 0.5342 (0.5503)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [170/172]  eta: 0:00:03  lr: 0.000066  loss: 0.5381 (0.5504)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403]  [171/172]  eta: 0:00:01  lr: 0.000066  loss: 0.5482 (0.5504)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:403] Total time: 0:04:32 (1.5858 s / it)\n",
      "Averaged stats: lr: 0.000066  loss: 0.5482 (0.5504)\n",
      "Valid: [epoch:403]  [ 0/14]  eta: 0:00:04  loss: 0.5508 (0.5508)  time: 0.3459  data: 0.3300  max mem: 20571\n",
      "Valid: [epoch:403]  [13/14]  eta: 0:00:00  loss: 0.5037 (0.5163)  time: 0.0395  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:403] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.5037 (0.5163)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_403_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.516%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:404]  [  0/172]  eta: 0:07:28  lr: 0.000066  loss: 0.5109 (0.5109)  time: 2.6100  data: 1.0460  max mem: 20571\n",
      "Train: [epoch:404]  [ 10/172]  eta: 0:04:30  lr: 0.000066  loss: 0.5359 (0.5387)  time: 1.6721  data: 0.0952  max mem: 20571\n",
      "Train: [epoch:404]  [ 20/172]  eta: 0:04:07  lr: 0.000066  loss: 0.5379 (0.5505)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [ 30/172]  eta: 0:03:48  lr: 0.000066  loss: 0.5552 (0.5531)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [ 40/172]  eta: 0:03:31  lr: 0.000066  loss: 0.5547 (0.5531)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [ 50/172]  eta: 0:03:15  lr: 0.000066  loss: 0.5490 (0.5531)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [ 60/172]  eta: 0:02:58  lr: 0.000066  loss: 0.5466 (0.5530)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [ 70/172]  eta: 0:02:42  lr: 0.000066  loss: 0.5548 (0.5520)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [ 80/172]  eta: 0:02:26  lr: 0.000066  loss: 0.5356 (0.5507)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [ 90/172]  eta: 0:02:10  lr: 0.000066  loss: 0.5340 (0.5498)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [100/172]  eta: 0:01:54  lr: 0.000066  loss: 0.5393 (0.5501)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [110/172]  eta: 0:01:38  lr: 0.000066  loss: 0.5511 (0.5486)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [120/172]  eta: 0:01:22  lr: 0.000066  loss: 0.5525 (0.5495)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [130/172]  eta: 0:01:06  lr: 0.000066  loss: 0.5463 (0.5480)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [140/172]  eta: 0:00:50  lr: 0.000066  loss: 0.5463 (0.5481)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [150/172]  eta: 0:00:34  lr: 0.000066  loss: 0.5460 (0.5476)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [160/172]  eta: 0:00:19  lr: 0.000066  loss: 0.5425 (0.5474)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [170/172]  eta: 0:00:03  lr: 0.000066  loss: 0.5387 (0.5475)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404]  [171/172]  eta: 0:00:01  lr: 0.000066  loss: 0.5364 (0.5474)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:404] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000066  loss: 0.5364 (0.5474)\n",
      "Valid: [epoch:404]  [ 0/14]  eta: 0:00:04  loss: 0.5521 (0.5521)  time: 0.3093  data: 0.2946  max mem: 20571\n",
      "Valid: [epoch:404]  [13/14]  eta: 0:00:00  loss: 0.5089 (0.5197)  time: 0.0361  data: 0.0211  max mem: 20571\n",
      "Valid: [epoch:404] Total time: 0:00:00 (0.0417 s / it)\n",
      "Averaged stats: loss: 0.5089 (0.5197)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_404_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.520%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:405]  [  0/172]  eta: 0:07:59  lr: 0.000066  loss: 0.5558 (0.5558)  time: 2.7899  data: 1.2108  max mem: 20571\n",
      "Train: [epoch:405]  [ 10/172]  eta: 0:04:33  lr: 0.000066  loss: 0.5538 (0.5463)  time: 1.6857  data: 0.1102  max mem: 20571\n",
      "Train: [epoch:405]  [ 20/172]  eta: 0:04:08  lr: 0.000066  loss: 0.5538 (0.5470)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [ 30/172]  eta: 0:03:49  lr: 0.000066  loss: 0.5485 (0.5495)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [ 40/172]  eta: 0:03:32  lr: 0.000066  loss: 0.5330 (0.5455)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [ 50/172]  eta: 0:03:15  lr: 0.000066  loss: 0.5298 (0.5443)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [ 60/172]  eta: 0:02:59  lr: 0.000066  loss: 0.5421 (0.5434)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [ 70/172]  eta: 0:02:42  lr: 0.000066  loss: 0.5421 (0.5440)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [ 80/172]  eta: 0:02:26  lr: 0.000066  loss: 0.5379 (0.5438)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [ 90/172]  eta: 0:02:10  lr: 0.000066  loss: 0.5537 (0.5453)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [100/172]  eta: 0:01:54  lr: 0.000066  loss: 0.5509 (0.5445)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [110/172]  eta: 0:01:38  lr: 0.000066  loss: 0.5382 (0.5446)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [120/172]  eta: 0:01:22  lr: 0.000066  loss: 0.5453 (0.5447)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [130/172]  eta: 0:01:06  lr: 0.000066  loss: 0.5398 (0.5447)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [140/172]  eta: 0:00:50  lr: 0.000066  loss: 0.5398 (0.5451)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [150/172]  eta: 0:00:34  lr: 0.000066  loss: 0.5577 (0.5462)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [160/172]  eta: 0:00:19  lr: 0.000066  loss: 0.5365 (0.5461)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [170/172]  eta: 0:00:03  lr: 0.000066  loss: 0.5413 (0.5459)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405]  [171/172]  eta: 0:00:01  lr: 0.000066  loss: 0.5437 (0.5459)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:405] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000066  loss: 0.5437 (0.5459)\n",
      "Valid: [epoch:405]  [ 0/14]  eta: 0:00:04  loss: 0.4963 (0.4963)  time: 0.3531  data: 0.3340  max mem: 20571\n",
      "Valid: [epoch:405]  [13/14]  eta: 0:00:00  loss: 0.5171 (0.5261)  time: 0.0406  data: 0.0254  max mem: 20571\n",
      "Valid: [epoch:405] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.5171 (0.5261)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_405_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.526%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:406]  [  0/172]  eta: 0:07:31  lr: 0.000066  loss: 0.5292 (0.5292)  time: 2.6233  data: 1.0560  max mem: 20571\n",
      "Train: [epoch:406]  [ 10/172]  eta: 0:04:30  lr: 0.000066  loss: 0.5413 (0.5633)  time: 1.6720  data: 0.0961  max mem: 20571\n",
      "Train: [epoch:406]  [ 20/172]  eta: 0:04:07  lr: 0.000066  loss: 0.5413 (0.5570)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [ 30/172]  eta: 0:03:48  lr: 0.000066  loss: 0.5469 (0.5548)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [ 40/172]  eta: 0:03:31  lr: 0.000066  loss: 0.5469 (0.5527)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [ 50/172]  eta: 0:03:15  lr: 0.000066  loss: 0.5479 (0.5530)  time: 1.5786  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:406]  [ 60/172]  eta: 0:02:58  lr: 0.000066  loss: 0.5456 (0.5529)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [ 70/172]  eta: 0:02:42  lr: 0.000066  loss: 0.5343 (0.5518)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [ 80/172]  eta: 0:02:26  lr: 0.000066  loss: 0.5400 (0.5512)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [ 90/172]  eta: 0:02:10  lr: 0.000066  loss: 0.5413 (0.5499)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [100/172]  eta: 0:01:54  lr: 0.000066  loss: 0.5452 (0.5502)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [110/172]  eta: 0:01:38  lr: 0.000066  loss: 0.5590 (0.5506)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [120/172]  eta: 0:01:22  lr: 0.000066  loss: 0.5628 (0.5507)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [130/172]  eta: 0:01:06  lr: 0.000066  loss: 0.5452 (0.5503)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [140/172]  eta: 0:00:50  lr: 0.000066  loss: 0.5356 (0.5500)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [150/172]  eta: 0:00:34  lr: 0.000066  loss: 0.5407 (0.5497)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [160/172]  eta: 0:00:19  lr: 0.000066  loss: 0.5407 (0.5492)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406]  [170/172]  eta: 0:00:03  lr: 0.000066  loss: 0.5451 (0.5494)  time: 1.5772  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:406]  [171/172]  eta: 0:00:01  lr: 0.000066  loss: 0.5451 (0.5493)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:406] Total time: 0:04:32 (1.5838 s / it)\n",
      "Averaged stats: lr: 0.000066  loss: 0.5451 (0.5493)\n",
      "Valid: [epoch:406]  [ 0/14]  eta: 0:00:04  loss: 0.5609 (0.5609)  time: 0.2952  data: 0.2791  max mem: 20571\n",
      "Valid: [epoch:406]  [13/14]  eta: 0:00:00  loss: 0.5103 (0.5205)  time: 0.0466  data: 0.0315  max mem: 20571\n",
      "Valid: [epoch:406] Total time: 0:00:00 (0.0512 s / it)\n",
      "Averaged stats: loss: 0.5103 (0.5205)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_406_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.521%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:407]  [  0/172]  eta: 0:07:29  lr: 0.000066  loss: 0.5806 (0.5806)  time: 2.6148  data: 1.0465  max mem: 20571\n",
      "Train: [epoch:407]  [ 10/172]  eta: 0:04:30  lr: 0.000066  loss: 0.5525 (0.5481)  time: 1.6677  data: 0.0952  max mem: 20571\n",
      "Train: [epoch:407]  [ 20/172]  eta: 0:04:06  lr: 0.000066  loss: 0.5480 (0.5520)  time: 1.5738  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [ 30/172]  eta: 0:03:48  lr: 0.000066  loss: 0.5473 (0.5498)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [ 40/172]  eta: 0:03:31  lr: 0.000066  loss: 0.5473 (0.5501)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [ 50/172]  eta: 0:03:14  lr: 0.000066  loss: 0.5596 (0.5517)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [ 60/172]  eta: 0:02:58  lr: 0.000066  loss: 0.5339 (0.5499)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [ 70/172]  eta: 0:02:42  lr: 0.000066  loss: 0.5307 (0.5478)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [ 80/172]  eta: 0:02:26  lr: 0.000066  loss: 0.5451 (0.5488)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [ 90/172]  eta: 0:02:10  lr: 0.000066  loss: 0.5554 (0.5497)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [100/172]  eta: 0:01:54  lr: 0.000066  loss: 0.5562 (0.5502)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [110/172]  eta: 0:01:38  lr: 0.000066  loss: 0.5344 (0.5487)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [120/172]  eta: 0:01:22  lr: 0.000066  loss: 0.5327 (0.5479)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [130/172]  eta: 0:01:06  lr: 0.000066  loss: 0.5497 (0.5490)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [140/172]  eta: 0:00:50  lr: 0.000066  loss: 0.5345 (0.5476)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [150/172]  eta: 0:00:34  lr: 0.000066  loss: 0.5210 (0.5467)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [160/172]  eta: 0:00:18  lr: 0.000066  loss: 0.5487 (0.5473)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [170/172]  eta: 0:00:03  lr: 0.000066  loss: 0.5537 (0.5471)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407]  [171/172]  eta: 0:00:01  lr: 0.000066  loss: 0.5537 (0.5470)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:407] Total time: 0:04:32 (1.5829 s / it)\n",
      "Averaged stats: lr: 0.000066  loss: 0.5537 (0.5470)\n",
      "Valid: [epoch:407]  [ 0/14]  eta: 0:00:04  loss: 0.4462 (0.4462)  time: 0.3201  data: 0.3031  max mem: 20571\n",
      "Valid: [epoch:407]  [13/14]  eta: 0:00:00  loss: 0.5050 (0.5165)  time: 0.0369  data: 0.0217  max mem: 20571\n",
      "Valid: [epoch:407] Total time: 0:00:00 (0.0418 s / it)\n",
      "Averaged stats: loss: 0.5050 (0.5165)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_407_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.516%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:408]  [  0/172]  eta: 0:07:26  lr: 0.000066  loss: 0.4618 (0.4618)  time: 2.5944  data: 1.0278  max mem: 20571\n",
      "Train: [epoch:408]  [ 10/172]  eta: 0:04:30  lr: 0.000066  loss: 0.5522 (0.5411)  time: 1.6684  data: 0.0935  max mem: 20571\n",
      "Train: [epoch:408]  [ 20/172]  eta: 0:04:06  lr: 0.000066  loss: 0.5437 (0.5421)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [ 30/172]  eta: 0:03:48  lr: 0.000066  loss: 0.5361 (0.5455)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [ 40/172]  eta: 0:03:31  lr: 0.000066  loss: 0.5448 (0.5492)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [ 50/172]  eta: 0:03:14  lr: 0.000066  loss: 0.5622 (0.5526)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [ 60/172]  eta: 0:02:58  lr: 0.000066  loss: 0.5611 (0.5518)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [ 70/172]  eta: 0:02:42  lr: 0.000066  loss: 0.5402 (0.5515)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [ 80/172]  eta: 0:02:26  lr: 0.000066  loss: 0.5423 (0.5515)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [ 90/172]  eta: 0:02:10  lr: 0.000066  loss: 0.5429 (0.5509)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [100/172]  eta: 0:01:54  lr: 0.000066  loss: 0.5417 (0.5501)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [110/172]  eta: 0:01:38  lr: 0.000066  loss: 0.5425 (0.5500)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [120/172]  eta: 0:01:22  lr: 0.000066  loss: 0.5452 (0.5502)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [130/172]  eta: 0:01:06  lr: 0.000066  loss: 0.5401 (0.5495)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [140/172]  eta: 0:00:50  lr: 0.000066  loss: 0.5401 (0.5493)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [150/172]  eta: 0:00:34  lr: 0.000066  loss: 0.5421 (0.5489)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [160/172]  eta: 0:00:19  lr: 0.000066  loss: 0.5374 (0.5486)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [170/172]  eta: 0:00:03  lr: 0.000066  loss: 0.5453 (0.5478)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408]  [171/172]  eta: 0:00:01  lr: 0.000066  loss: 0.5453 (0.5477)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:408] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000066  loss: 0.5453 (0.5477)\n",
      "Valid: [epoch:408]  [ 0/14]  eta: 0:00:04  loss: 0.5614 (0.5614)  time: 0.3082  data: 0.2933  max mem: 20571\n",
      "Valid: [epoch:408]  [13/14]  eta: 0:00:00  loss: 0.5079 (0.5215)  time: 0.0382  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:408] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.5079 (0.5215)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_408_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.522%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:409]  [  0/172]  eta: 0:08:01  lr: 0.000066  loss: 0.5399 (0.5399)  time: 2.8014  data: 1.2263  max mem: 20571\n",
      "Train: [epoch:409]  [ 10/172]  eta: 0:04:33  lr: 0.000066  loss: 0.5424 (0.5459)  time: 1.6901  data: 0.1116  max mem: 20571\n",
      "Train: [epoch:409]  [ 20/172]  eta: 0:04:09  lr: 0.000066  loss: 0.5434 (0.5489)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [ 30/172]  eta: 0:03:50  lr: 0.000066  loss: 0.5434 (0.5476)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [ 40/172]  eta: 0:03:32  lr: 0.000066  loss: 0.5378 (0.5460)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [ 50/172]  eta: 0:03:15  lr: 0.000066  loss: 0.5448 (0.5466)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [ 60/172]  eta: 0:02:59  lr: 0.000066  loss: 0.5482 (0.5479)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [ 70/172]  eta: 0:02:43  lr: 0.000066  loss: 0.5445 (0.5489)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [ 80/172]  eta: 0:02:26  lr: 0.000066  loss: 0.5445 (0.5484)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [ 90/172]  eta: 0:02:10  lr: 0.000066  loss: 0.5414 (0.5482)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [100/172]  eta: 0:01:54  lr: 0.000066  loss: 0.5403 (0.5482)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [110/172]  eta: 0:01:38  lr: 0.000066  loss: 0.5425 (0.5479)  time: 1.5855  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:409]  [120/172]  eta: 0:01:22  lr: 0.000066  loss: 0.5397 (0.5475)  time: 1.5836  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:409]  [130/172]  eta: 0:01:06  lr: 0.000066  loss: 0.5417 (0.5477)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [140/172]  eta: 0:00:50  lr: 0.000066  loss: 0.5525 (0.5491)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [150/172]  eta: 0:00:34  lr: 0.000066  loss: 0.5543 (0.5496)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [160/172]  eta: 0:00:19  lr: 0.000066  loss: 0.5421 (0.5486)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [170/172]  eta: 0:00:03  lr: 0.000066  loss: 0.5344 (0.5483)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409]  [171/172]  eta: 0:00:01  lr: 0.000066  loss: 0.5344 (0.5483)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:409] Total time: 0:04:33 (1.5904 s / it)\n",
      "Averaged stats: lr: 0.000066  loss: 0.5344 (0.5483)\n",
      "Valid: [epoch:409]  [ 0/14]  eta: 0:00:03  loss: 0.4579 (0.4579)  time: 0.2838  data: 0.2690  max mem: 20571\n",
      "Valid: [epoch:409]  [13/14]  eta: 0:00:00  loss: 0.5184 (0.5264)  time: 0.0454  data: 0.0304  max mem: 20571\n",
      "Valid: [epoch:409] Total time: 0:00:00 (0.0531 s / it)\n",
      "Averaged stats: loss: 0.5184 (0.5264)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_409_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.526%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:410]  [  0/172]  eta: 0:07:40  lr: 0.000066  loss: 0.5522 (0.5522)  time: 2.6770  data: 1.1077  max mem: 20571\n",
      "Train: [epoch:410]  [ 10/172]  eta: 0:04:32  lr: 0.000066  loss: 0.5522 (0.5467)  time: 1.6804  data: 0.1009  max mem: 20571\n",
      "Train: [epoch:410]  [ 20/172]  eta: 0:04:08  lr: 0.000066  loss: 0.5584 (0.5552)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:410]  [ 30/172]  eta: 0:03:49  lr: 0.000066  loss: 0.5483 (0.5489)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [ 40/172]  eta: 0:03:32  lr: 0.000066  loss: 0.5402 (0.5499)  time: 1.5844  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:410]  [ 50/172]  eta: 0:03:15  lr: 0.000066  loss: 0.5402 (0.5480)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [ 60/172]  eta: 0:02:59  lr: 0.000066  loss: 0.5353 (0.5476)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:410]  [ 70/172]  eta: 0:02:42  lr: 0.000066  loss: 0.5353 (0.5459)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:410]  [ 80/172]  eta: 0:02:26  lr: 0.000066  loss: 0.5376 (0.5460)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [ 90/172]  eta: 0:02:10  lr: 0.000066  loss: 0.5502 (0.5470)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [100/172]  eta: 0:01:54  lr: 0.000066  loss: 0.5618 (0.5472)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [110/172]  eta: 0:01:38  lr: 0.000066  loss: 0.5299 (0.5459)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [120/172]  eta: 0:01:22  lr: 0.000066  loss: 0.5601 (0.5490)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [130/172]  eta: 0:01:06  lr: 0.000066  loss: 0.5467 (0.5487)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [140/172]  eta: 0:00:50  lr: 0.000066  loss: 0.5398 (0.5485)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:410]  [150/172]  eta: 0:00:34  lr: 0.000066  loss: 0.5512 (0.5490)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [160/172]  eta: 0:00:19  lr: 0.000066  loss: 0.5473 (0.5483)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [170/172]  eta: 0:00:03  lr: 0.000066  loss: 0.5371 (0.5486)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410]  [171/172]  eta: 0:00:01  lr: 0.000066  loss: 0.5473 (0.5488)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:410] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000066  loss: 0.5473 (0.5488)\n",
      "Valid: [epoch:410]  [ 0/14]  eta: 0:00:04  loss: 0.5611 (0.5611)  time: 0.3003  data: 0.2837  max mem: 20571\n",
      "Valid: [epoch:410]  [13/14]  eta: 0:00:00  loss: 0.5105 (0.5221)  time: 0.0367  data: 0.0215  max mem: 20571\n",
      "Valid: [epoch:410] Total time: 0:00:00 (0.0414 s / it)\n",
      "Averaged stats: loss: 0.5105 (0.5221)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_410_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.522%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:411]  [  0/172]  eta: 0:07:43  lr: 0.000066  loss: 0.5074 (0.5074)  time: 2.6963  data: 1.1226  max mem: 20571\n",
      "Train: [epoch:411]  [ 10/172]  eta: 0:04:31  lr: 0.000066  loss: 0.5166 (0.5301)  time: 1.6779  data: 0.1022  max mem: 20571\n",
      "Train: [epoch:411]  [ 20/172]  eta: 0:04:07  lr: 0.000066  loss: 0.5333 (0.5409)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [ 30/172]  eta: 0:03:49  lr: 0.000066  loss: 0.5376 (0.5446)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [ 40/172]  eta: 0:03:31  lr: 0.000066  loss: 0.5444 (0.5489)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [ 50/172]  eta: 0:03:15  lr: 0.000066  loss: 0.5554 (0.5491)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [ 60/172]  eta: 0:02:58  lr: 0.000066  loss: 0.5397 (0.5503)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [ 70/172]  eta: 0:02:42  lr: 0.000066  loss: 0.5470 (0.5513)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [ 80/172]  eta: 0:02:26  lr: 0.000066  loss: 0.5484 (0.5517)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [ 90/172]  eta: 0:02:10  lr: 0.000066  loss: 0.5484 (0.5512)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [100/172]  eta: 0:01:54  lr: 0.000066  loss: 0.5455 (0.5506)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [110/172]  eta: 0:01:38  lr: 0.000066  loss: 0.5489 (0.5515)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [120/172]  eta: 0:01:22  lr: 0.000066  loss: 0.5506 (0.5510)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [130/172]  eta: 0:01:06  lr: 0.000066  loss: 0.5501 (0.5514)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [140/172]  eta: 0:00:50  lr: 0.000066  loss: 0.5389 (0.5504)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [150/172]  eta: 0:00:34  lr: 0.000066  loss: 0.5389 (0.5507)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [160/172]  eta: 0:00:19  lr: 0.000066  loss: 0.5480 (0.5506)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [170/172]  eta: 0:00:03  lr: 0.000066  loss: 0.5372 (0.5507)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411]  [171/172]  eta: 0:00:01  lr: 0.000066  loss: 0.5372 (0.5506)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:411] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000066  loss: 0.5372 (0.5506)\n",
      "Valid: [epoch:411]  [ 0/14]  eta: 0:00:05  loss: 0.4702 (0.4702)  time: 0.4261  data: 0.4097  max mem: 20571\n",
      "Valid: [epoch:411]  [13/14]  eta: 0:00:00  loss: 0.5028 (0.5133)  time: 0.0455  data: 0.0305  max mem: 20571\n",
      "Valid: [epoch:411] Total time: 0:00:00 (0.0538 s / it)\n",
      "Averaged stats: loss: 0.5028 (0.5133)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_411_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.513%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:412]  [  0/172]  eta: 0:07:40  lr: 0.000065  loss: 0.5722 (0.5722)  time: 2.6788  data: 1.1159  max mem: 20571\n",
      "Train: [epoch:412]  [ 10/172]  eta: 0:04:31  lr: 0.000065  loss: 0.5579 (0.5519)  time: 1.6779  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:412]  [ 20/172]  eta: 0:04:07  lr: 0.000065  loss: 0.5436 (0.5493)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412]  [ 30/172]  eta: 0:03:49  lr: 0.000065  loss: 0.5436 (0.5479)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412]  [ 40/172]  eta: 0:03:31  lr: 0.000065  loss: 0.5368 (0.5471)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412]  [ 50/172]  eta: 0:03:15  lr: 0.000065  loss: 0.5276 (0.5443)  time: 1.5761  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:412]  [ 60/172]  eta: 0:02:58  lr: 0.000065  loss: 0.5379 (0.5453)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:412]  [ 70/172]  eta: 0:02:42  lr: 0.000065  loss: 0.5554 (0.5456)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:412]  [ 80/172]  eta: 0:02:26  lr: 0.000065  loss: 0.5493 (0.5461)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:412]  [ 90/172]  eta: 0:02:10  lr: 0.000065  loss: 0.5457 (0.5476)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412]  [100/172]  eta: 0:01:54  lr: 0.000065  loss: 0.5457 (0.5462)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412]  [110/172]  eta: 0:01:38  lr: 0.000065  loss: 0.5378 (0.5462)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:412]  [120/172]  eta: 0:01:22  lr: 0.000065  loss: 0.5399 (0.5472)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:412]  [130/172]  eta: 0:01:06  lr: 0.000065  loss: 0.5399 (0.5471)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:412]  [140/172]  eta: 0:00:50  lr: 0.000065  loss: 0.5378 (0.5472)  time: 1.5777  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412]  [150/172]  eta: 0:00:34  lr: 0.000065  loss: 0.5458 (0.5478)  time: 1.5786  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412]  [160/172]  eta: 0:00:19  lr: 0.000065  loss: 0.5597 (0.5475)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412]  [170/172]  eta: 0:00:03  lr: 0.000065  loss: 0.5423 (0.5482)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412]  [171/172]  eta: 0:00:01  lr: 0.000065  loss: 0.5534 (0.5486)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:412] Total time: 0:04:32 (1.5854 s / it)\n",
      "Averaged stats: lr: 0.000065  loss: 0.5534 (0.5486)\n",
      "Valid: [epoch:412]  [ 0/14]  eta: 0:00:05  loss: 0.5531 (0.5531)  time: 0.4227  data: 0.4050  max mem: 20571\n",
      "Valid: [epoch:412]  [13/14]  eta: 0:00:00  loss: 0.5089 (0.5193)  time: 0.0454  data: 0.0301  max mem: 20571\n",
      "Valid: [epoch:412] Total time: 0:00:00 (0.0505 s / it)\n",
      "Averaged stats: loss: 0.5089 (0.5193)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_412_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.519%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:413]  [  0/172]  eta: 0:08:02  lr: 0.000065  loss: 0.5366 (0.5366)  time: 2.8038  data: 1.2307  max mem: 20571\n",
      "Train: [epoch:413]  [ 10/172]  eta: 0:04:33  lr: 0.000065  loss: 0.5357 (0.5459)  time: 1.6873  data: 0.1120  max mem: 20571\n",
      "Train: [epoch:413]  [ 20/172]  eta: 0:04:08  lr: 0.000065  loss: 0.5412 (0.5476)  time: 1.5767  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:413]  [ 30/172]  eta: 0:03:49  lr: 0.000065  loss: 0.5412 (0.5485)  time: 1.5789  data: 0.0003  max mem: 20571\n",
      "Train: [epoch:413]  [ 40/172]  eta: 0:03:32  lr: 0.000065  loss: 0.5396 (0.5484)  time: 1.5806  data: 0.0003  max mem: 20571\n",
      "Train: [epoch:413]  [ 50/172]  eta: 0:03:15  lr: 0.000065  loss: 0.5519 (0.5515)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:413]  [ 60/172]  eta: 0:02:59  lr: 0.000065  loss: 0.5591 (0.5532)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:413]  [ 70/172]  eta: 0:02:42  lr: 0.000065  loss: 0.5574 (0.5527)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:413]  [ 80/172]  eta: 0:02:26  lr: 0.000065  loss: 0.5460 (0.5527)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:413]  [ 90/172]  eta: 0:02:10  lr: 0.000065  loss: 0.5428 (0.5531)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:413]  [100/172]  eta: 0:01:54  lr: 0.000065  loss: 0.5561 (0.5541)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:413]  [110/172]  eta: 0:01:38  lr: 0.000065  loss: 0.5539 (0.5532)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:413]  [120/172]  eta: 0:01:22  lr: 0.000065  loss: 0.5419 (0.5527)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:413]  [130/172]  eta: 0:01:06  lr: 0.000065  loss: 0.5419 (0.5526)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:413]  [140/172]  eta: 0:00:50  lr: 0.000065  loss: 0.5383 (0.5517)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:413]  [150/172]  eta: 0:00:34  lr: 0.000065  loss: 0.5392 (0.5513)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:413]  [160/172]  eta: 0:00:19  lr: 0.000065  loss: 0.5475 (0.5510)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:413]  [170/172]  eta: 0:00:03  lr: 0.000065  loss: 0.5494 (0.5505)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:413]  [171/172]  eta: 0:00:01  lr: 0.000065  loss: 0.5494 (0.5508)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:413] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000065  loss: 0.5494 (0.5508)\n",
      "Valid: [epoch:413]  [ 0/14]  eta: 0:00:04  loss: 0.5712 (0.5712)  time: 0.2960  data: 0.2811  max mem: 20571\n",
      "Valid: [epoch:413]  [13/14]  eta: 0:00:00  loss: 0.5293 (0.5440)  time: 0.0382  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:413] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.5293 (0.5440)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_413_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.544%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:414]  [  0/172]  eta: 0:08:03  lr: 0.000065  loss: 0.5281 (0.5281)  time: 2.8093  data: 1.2399  max mem: 20571\n",
      "Train: [epoch:414]  [ 10/172]  eta: 0:04:34  lr: 0.000065  loss: 0.5496 (0.5525)  time: 1.6920  data: 0.1128  max mem: 20571\n",
      "Train: [epoch:414]  [ 20/172]  eta: 0:04:09  lr: 0.000065  loss: 0.5525 (0.5531)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [ 30/172]  eta: 0:03:50  lr: 0.000065  loss: 0.5502 (0.5538)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:414]  [ 40/172]  eta: 0:03:32  lr: 0.000065  loss: 0.5316 (0.5474)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:414]  [ 50/172]  eta: 0:03:15  lr: 0.000065  loss: 0.5420 (0.5522)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [ 60/172]  eta: 0:02:59  lr: 0.000065  loss: 0.5559 (0.5523)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:414]  [ 70/172]  eta: 0:02:43  lr: 0.000065  loss: 0.5489 (0.5520)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [ 80/172]  eta: 0:02:26  lr: 0.000065  loss: 0.5371 (0.5516)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [ 90/172]  eta: 0:02:10  lr: 0.000065  loss: 0.5351 (0.5509)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [100/172]  eta: 0:01:54  lr: 0.000065  loss: 0.5337 (0.5496)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [110/172]  eta: 0:01:38  lr: 0.000065  loss: 0.5331 (0.5488)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:414]  [120/172]  eta: 0:01:22  lr: 0.000065  loss: 0.5369 (0.5488)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:414]  [130/172]  eta: 0:01:06  lr: 0.000065  loss: 0.5416 (0.5485)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:414]  [140/172]  eta: 0:00:50  lr: 0.000065  loss: 0.5518 (0.5484)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [150/172]  eta: 0:00:34  lr: 0.000065  loss: 0.5544 (0.5491)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [160/172]  eta: 0:00:19  lr: 0.000065  loss: 0.5550 (0.5497)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [170/172]  eta: 0:00:03  lr: 0.000065  loss: 0.5485 (0.5501)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414]  [171/172]  eta: 0:00:01  lr: 0.000065  loss: 0.5627 (0.5502)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:414] Total time: 0:04:33 (1.5897 s / it)\n",
      "Averaged stats: lr: 0.000065  loss: 0.5627 (0.5502)\n",
      "Valid: [epoch:414]  [ 0/14]  eta: 0:00:05  loss: 0.5671 (0.5671)  time: 0.3616  data: 0.3468  max mem: 20571\n",
      "Valid: [epoch:414]  [13/14]  eta: 0:00:00  loss: 0.5265 (0.5330)  time: 0.0413  data: 0.0264  max mem: 20571\n",
      "Valid: [epoch:414] Total time: 0:00:00 (0.0461 s / it)\n",
      "Averaged stats: loss: 0.5265 (0.5330)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_414_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.533%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:415]  [  0/172]  eta: 0:07:51  lr: 0.000065  loss: 0.5533 (0.5533)  time: 2.7403  data: 1.1616  max mem: 20571\n",
      "Train: [epoch:415]  [ 10/172]  eta: 0:04:32  lr: 0.000065  loss: 0.5533 (0.5414)  time: 1.6811  data: 0.1057  max mem: 20571\n",
      "Train: [epoch:415]  [ 20/172]  eta: 0:04:07  lr: 0.000065  loss: 0.5403 (0.5415)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [ 30/172]  eta: 0:03:49  lr: 0.000065  loss: 0.5400 (0.5446)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [ 40/172]  eta: 0:03:31  lr: 0.000065  loss: 0.5512 (0.5446)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [ 50/172]  eta: 0:03:15  lr: 0.000065  loss: 0.5518 (0.5462)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [ 60/172]  eta: 0:02:58  lr: 0.000065  loss: 0.5567 (0.5474)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [ 70/172]  eta: 0:02:42  lr: 0.000065  loss: 0.5516 (0.5471)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [ 80/172]  eta: 0:02:26  lr: 0.000065  loss: 0.5419 (0.5459)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [ 90/172]  eta: 0:02:10  lr: 0.000065  loss: 0.5420 (0.5472)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [100/172]  eta: 0:01:54  lr: 0.000065  loss: 0.5468 (0.5467)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [110/172]  eta: 0:01:38  lr: 0.000065  loss: 0.5477 (0.5461)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [120/172]  eta: 0:01:22  lr: 0.000065  loss: 0.5477 (0.5467)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [130/172]  eta: 0:01:06  lr: 0.000065  loss: 0.5479 (0.5470)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [140/172]  eta: 0:00:50  lr: 0.000065  loss: 0.5444 (0.5478)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [150/172]  eta: 0:00:34  lr: 0.000065  loss: 0.5428 (0.5476)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [160/172]  eta: 0:00:19  lr: 0.000065  loss: 0.5435 (0.5485)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [170/172]  eta: 0:00:03  lr: 0.000065  loss: 0.5570 (0.5487)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415]  [171/172]  eta: 0:00:01  lr: 0.000065  loss: 0.5570 (0.5487)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:415] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000065  loss: 0.5570 (0.5487)\n",
      "Valid: [epoch:415]  [ 0/14]  eta: 0:00:04  loss: 0.5479 (0.5479)  time: 0.3380  data: 0.3224  max mem: 20571\n",
      "Valid: [epoch:415]  [13/14]  eta: 0:00:00  loss: 0.5093 (0.5210)  time: 0.0443  data: 0.0294  max mem: 20571\n",
      "Valid: [epoch:415] Total time: 0:00:00 (0.0526 s / it)\n",
      "Averaged stats: loss: 0.5093 (0.5210)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_415_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.521%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:416]  [  0/172]  eta: 0:07:54  lr: 0.000065  loss: 0.5808 (0.5808)  time: 2.7607  data: 1.1957  max mem: 20571\n",
      "Train: [epoch:416]  [ 10/172]  eta: 0:04:33  lr: 0.000065  loss: 0.5630 (0.5520)  time: 1.6863  data: 0.1088  max mem: 20571\n",
      "Train: [epoch:416]  [ 20/172]  eta: 0:04:08  lr: 0.000065  loss: 0.5570 (0.5501)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [ 30/172]  eta: 0:03:49  lr: 0.000065  loss: 0.5393 (0.5523)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [ 40/172]  eta: 0:03:32  lr: 0.000065  loss: 0.5366 (0.5529)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [ 50/172]  eta: 0:03:15  lr: 0.000065  loss: 0.5504 (0.5523)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [ 60/172]  eta: 0:02:59  lr: 0.000065  loss: 0.5504 (0.5515)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [ 70/172]  eta: 0:02:43  lr: 0.000065  loss: 0.5409 (0.5504)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [ 80/172]  eta: 0:02:26  lr: 0.000065  loss: 0.5409 (0.5501)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [ 90/172]  eta: 0:02:10  lr: 0.000065  loss: 0.5417 (0.5500)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [100/172]  eta: 0:01:54  lr: 0.000065  loss: 0.5419 (0.5494)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [110/172]  eta: 0:01:38  lr: 0.000065  loss: 0.5495 (0.5500)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [120/172]  eta: 0:01:22  lr: 0.000065  loss: 0.5497 (0.5515)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [130/172]  eta: 0:01:06  lr: 0.000065  loss: 0.5502 (0.5514)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:416]  [140/172]  eta: 0:00:50  lr: 0.000065  loss: 0.5392 (0.5508)  time: 1.5860  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:416]  [150/172]  eta: 0:00:35  lr: 0.000065  loss: 0.5392 (0.5511)  time: 1.5864  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:416]  [160/172]  eta: 0:00:19  lr: 0.000065  loss: 0.5529 (0.5516)  time: 1.5879  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:416]  [170/172]  eta: 0:00:03  lr: 0.000065  loss: 0.5589 (0.5520)  time: 1.5891  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:416]  [171/172]  eta: 0:00:01  lr: 0.000065  loss: 0.5589 (0.5519)  time: 1.5890  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:416] Total time: 0:04:33 (1.5929 s / it)\n",
      "Averaged stats: lr: 0.000065  loss: 0.5589 (0.5519)\n",
      "Valid: [epoch:416]  [ 0/14]  eta: 0:00:04  loss: 0.4832 (0.4832)  time: 0.3203  data: 0.3042  max mem: 20571\n",
      "Valid: [epoch:416]  [13/14]  eta: 0:00:00  loss: 0.5369 (0.5481)  time: 0.0414  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:416] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.5369 (0.5481)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_416_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.548%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:417]  [  0/172]  eta: 0:08:24  lr: 0.000065  loss: 0.5337 (0.5337)  time: 2.9344  data: 1.3534  max mem: 20571\n",
      "Train: [epoch:417]  [ 10/172]  eta: 0:04:36  lr: 0.000065  loss: 0.5370 (0.5474)  time: 1.7049  data: 0.1232  max mem: 20571\n",
      "Train: [epoch:417]  [ 20/172]  eta: 0:04:10  lr: 0.000065  loss: 0.5369 (0.5422)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [ 30/172]  eta: 0:03:51  lr: 0.000065  loss: 0.5369 (0.5439)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [ 40/172]  eta: 0:03:33  lr: 0.000065  loss: 0.5283 (0.5399)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [ 50/172]  eta: 0:03:16  lr: 0.000065  loss: 0.5455 (0.5429)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [ 60/172]  eta: 0:03:00  lr: 0.000065  loss: 0.5468 (0.5442)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [ 70/172]  eta: 0:02:43  lr: 0.000065  loss: 0.5448 (0.5425)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [ 80/172]  eta: 0:02:27  lr: 0.000065  loss: 0.5293 (0.5439)  time: 1.5872  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:417]  [ 90/172]  eta: 0:02:11  lr: 0.000065  loss: 0.5575 (0.5463)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [100/172]  eta: 0:01:55  lr: 0.000065  loss: 0.5492 (0.5466)  time: 1.5892  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [110/172]  eta: 0:01:39  lr: 0.000065  loss: 0.5492 (0.5491)  time: 1.5891  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [120/172]  eta: 0:01:23  lr: 0.000065  loss: 0.5598 (0.5503)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [130/172]  eta: 0:01:07  lr: 0.000065  loss: 0.5598 (0.5505)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [140/172]  eta: 0:00:51  lr: 0.000065  loss: 0.5433 (0.5507)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [150/172]  eta: 0:00:35  lr: 0.000065  loss: 0.5482 (0.5508)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [160/172]  eta: 0:00:19  lr: 0.000065  loss: 0.5540 (0.5516)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417]  [170/172]  eta: 0:00:03  lr: 0.000065  loss: 0.5586 (0.5520)  time: 1.5897  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:417]  [171/172]  eta: 0:00:01  lr: 0.000065  loss: 0.5586 (0.5520)  time: 1.5897  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:417] Total time: 0:04:34 (1.5958 s / it)\n",
      "Averaged stats: lr: 0.000065  loss: 0.5586 (0.5520)\n",
      "Valid: [epoch:417]  [ 0/14]  eta: 0:00:05  loss: 0.4894 (0.4894)  time: 0.3861  data: 0.3676  max mem: 20571\n",
      "Valid: [epoch:417]  [13/14]  eta: 0:00:00  loss: 0.5245 (0.5360)  time: 0.0424  data: 0.0272  max mem: 20571\n",
      "Valid: [epoch:417] Total time: 0:00:00 (0.0511 s / it)\n",
      "Averaged stats: loss: 0.5245 (0.5360)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_417_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.536%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:418]  [  0/172]  eta: 0:08:15  lr: 0.000065  loss: 0.5564 (0.5564)  time: 2.8834  data: 1.1829  max mem: 20571\n",
      "Train: [epoch:418]  [ 10/172]  eta: 0:04:35  lr: 0.000065  loss: 0.5512 (0.5522)  time: 1.7036  data: 0.1077  max mem: 20571\n",
      "Train: [epoch:418]  [ 20/172]  eta: 0:04:10  lr: 0.000065  loss: 0.5512 (0.5538)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [ 30/172]  eta: 0:03:51  lr: 0.000065  loss: 0.5609 (0.5555)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [ 40/172]  eta: 0:03:33  lr: 0.000065  loss: 0.5517 (0.5536)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [ 50/172]  eta: 0:03:16  lr: 0.000065  loss: 0.5507 (0.5506)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [ 60/172]  eta: 0:02:59  lr: 0.000065  loss: 0.5530 (0.5516)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [ 70/172]  eta: 0:02:43  lr: 0.000065  loss: 0.5526 (0.5509)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [ 80/172]  eta: 0:02:27  lr: 0.000065  loss: 0.5482 (0.5512)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [ 90/172]  eta: 0:02:11  lr: 0.000065  loss: 0.5411 (0.5507)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [100/172]  eta: 0:01:55  lr: 0.000065  loss: 0.5309 (0.5510)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [110/172]  eta: 0:01:38  lr: 0.000065  loss: 0.5524 (0.5517)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [120/172]  eta: 0:01:22  lr: 0.000065  loss: 0.5579 (0.5518)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [130/172]  eta: 0:01:06  lr: 0.000065  loss: 0.5432 (0.5510)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [140/172]  eta: 0:00:50  lr: 0.000065  loss: 0.5341 (0.5508)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [150/172]  eta: 0:00:35  lr: 0.000065  loss: 0.5487 (0.5516)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [160/172]  eta: 0:00:19  lr: 0.000065  loss: 0.5491 (0.5509)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [170/172]  eta: 0:00:03  lr: 0.000065  loss: 0.5416 (0.5508)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418]  [171/172]  eta: 0:00:01  lr: 0.000065  loss: 0.5416 (0.5510)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:418] Total time: 0:04:33 (1.5925 s / it)\n",
      "Averaged stats: lr: 0.000065  loss: 0.5416 (0.5510)\n",
      "Valid: [epoch:418]  [ 0/14]  eta: 0:00:05  loss: 0.5678 (0.5678)  time: 0.3980  data: 0.3819  max mem: 20571\n",
      "Valid: [epoch:418]  [13/14]  eta: 0:00:00  loss: 0.5256 (0.5355)  time: 0.0438  data: 0.0287  max mem: 20571\n",
      "Valid: [epoch:418] Total time: 0:00:00 (0.0488 s / it)\n",
      "Averaged stats: loss: 0.5256 (0.5355)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_418_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.536%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:419]  [  0/172]  eta: 0:07:44  lr: 0.000065  loss: 0.5682 (0.5682)  time: 2.6994  data: 1.1112  max mem: 20571\n",
      "Train: [epoch:419]  [ 10/172]  eta: 0:04:32  lr: 0.000065  loss: 0.5458 (0.5360)  time: 1.6809  data: 0.1011  max mem: 20571\n",
      "Train: [epoch:419]  [ 20/172]  eta: 0:04:08  lr: 0.000065  loss: 0.5458 (0.5454)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [ 30/172]  eta: 0:03:49  lr: 0.000065  loss: 0.5524 (0.5469)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [ 40/172]  eta: 0:03:32  lr: 0.000065  loss: 0.5592 (0.5498)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [ 50/172]  eta: 0:03:15  lr: 0.000065  loss: 0.5581 (0.5498)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [ 60/172]  eta: 0:02:59  lr: 0.000065  loss: 0.5526 (0.5504)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [ 70/172]  eta: 0:02:42  lr: 0.000065  loss: 0.5594 (0.5510)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [ 80/172]  eta: 0:02:26  lr: 0.000065  loss: 0.5618 (0.5515)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [ 90/172]  eta: 0:02:10  lr: 0.000065  loss: 0.5489 (0.5509)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [100/172]  eta: 0:01:54  lr: 0.000065  loss: 0.5312 (0.5505)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [110/172]  eta: 0:01:38  lr: 0.000065  loss: 0.5501 (0.5530)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [120/172]  eta: 0:01:22  lr: 0.000065  loss: 0.5620 (0.5534)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [130/172]  eta: 0:01:06  lr: 0.000065  loss: 0.5621 (0.5543)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [140/172]  eta: 0:00:50  lr: 0.000065  loss: 0.5611 (0.5535)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [150/172]  eta: 0:00:34  lr: 0.000065  loss: 0.5289 (0.5525)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [160/172]  eta: 0:00:19  lr: 0.000065  loss: 0.5421 (0.5522)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [170/172]  eta: 0:00:03  lr: 0.000065  loss: 0.5532 (0.5526)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419]  [171/172]  eta: 0:00:01  lr: 0.000065  loss: 0.5532 (0.5529)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:419] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000065  loss: 0.5532 (0.5529)\n",
      "Valid: [epoch:419]  [ 0/14]  eta: 0:00:06  loss: 0.5507 (0.5507)  time: 0.4612  data: 0.4429  max mem: 20571\n",
      "Valid: [epoch:419]  [13/14]  eta: 0:00:00  loss: 0.5055 (0.5158)  time: 0.0472  data: 0.0320  max mem: 20571\n",
      "Valid: [epoch:419] Total time: 0:00:00 (0.0556 s / it)\n",
      "Averaged stats: loss: 0.5055 (0.5158)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_419_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.516%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:420]  [  0/172]  eta: 0:07:35  lr: 0.000065  loss: 0.5432 (0.5432)  time: 2.6467  data: 1.0751  max mem: 20571\n",
      "Train: [epoch:420]  [ 10/172]  eta: 0:04:31  lr: 0.000065  loss: 0.5462 (0.5484)  time: 1.6789  data: 0.0979  max mem: 20571\n",
      "Train: [epoch:420]  [ 20/172]  eta: 0:04:08  lr: 0.000065  loss: 0.5485 (0.5539)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:420]  [ 30/172]  eta: 0:03:49  lr: 0.000065  loss: 0.5511 (0.5552)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [ 40/172]  eta: 0:03:32  lr: 0.000065  loss: 0.5445 (0.5520)  time: 1.5865  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:420]  [ 50/172]  eta: 0:03:15  lr: 0.000065  loss: 0.5325 (0.5500)  time: 1.5867  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:420]  [ 60/172]  eta: 0:02:59  lr: 0.000065  loss: 0.5474 (0.5529)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [ 70/172]  eta: 0:02:43  lr: 0.000065  loss: 0.5557 (0.5528)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [ 80/172]  eta: 0:02:27  lr: 0.000065  loss: 0.5345 (0.5520)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [ 90/172]  eta: 0:02:10  lr: 0.000065  loss: 0.5529 (0.5525)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [100/172]  eta: 0:01:54  lr: 0.000065  loss: 0.5529 (0.5525)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [110/172]  eta: 0:01:38  lr: 0.000065  loss: 0.5530 (0.5530)  time: 1.5875  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:420]  [120/172]  eta: 0:01:22  lr: 0.000065  loss: 0.5416 (0.5523)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [130/172]  eta: 0:01:06  lr: 0.000065  loss: 0.5406 (0.5517)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [140/172]  eta: 0:00:50  lr: 0.000065  loss: 0.5523 (0.5525)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [150/172]  eta: 0:00:35  lr: 0.000065  loss: 0.5553 (0.5526)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [160/172]  eta: 0:00:19  lr: 0.000065  loss: 0.5572 (0.5532)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [170/172]  eta: 0:00:03  lr: 0.000065  loss: 0.5657 (0.5533)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420]  [171/172]  eta: 0:00:01  lr: 0.000065  loss: 0.5594 (0.5533)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:420] Total time: 0:04:33 (1.5924 s / it)\n",
      "Averaged stats: lr: 0.000065  loss: 0.5594 (0.5533)\n",
      "Valid: [epoch:420]  [ 0/14]  eta: 0:00:03  loss: 0.5930 (0.5930)  time: 0.2841  data: 0.2692  max mem: 20571\n",
      "Valid: [epoch:420]  [13/14]  eta: 0:00:00  loss: 0.5546 (0.5657)  time: 0.0368  data: 0.0216  max mem: 20571\n",
      "Valid: [epoch:420] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.5546 (0.5657)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_420_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.566%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:421]  [  0/172]  eta: 0:07:44  lr: 0.000064  loss: 0.5688 (0.5688)  time: 2.6981  data: 1.1199  max mem: 20571\n",
      "Train: [epoch:421]  [ 10/172]  eta: 0:04:32  lr: 0.000064  loss: 0.5650 (0.5538)  time: 1.6828  data: 0.1019  max mem: 20571\n",
      "Train: [epoch:421]  [ 20/172]  eta: 0:04:08  lr: 0.000064  loss: 0.5399 (0.5530)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [ 30/172]  eta: 0:03:49  lr: 0.000064  loss: 0.5399 (0.5517)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [ 40/172]  eta: 0:03:32  lr: 0.000064  loss: 0.5464 (0.5513)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [ 50/172]  eta: 0:03:15  lr: 0.000064  loss: 0.5573 (0.5563)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [ 60/172]  eta: 0:02:59  lr: 0.000064  loss: 0.5522 (0.5553)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [ 70/172]  eta: 0:02:43  lr: 0.000064  loss: 0.5382 (0.5548)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [ 80/172]  eta: 0:02:27  lr: 0.000064  loss: 0.5327 (0.5539)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [ 90/172]  eta: 0:02:10  lr: 0.000064  loss: 0.5390 (0.5530)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [100/172]  eta: 0:01:54  lr: 0.000064  loss: 0.5458 (0.5537)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [110/172]  eta: 0:01:38  lr: 0.000064  loss: 0.5506 (0.5533)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [120/172]  eta: 0:01:22  lr: 0.000064  loss: 0.5525 (0.5531)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [130/172]  eta: 0:01:06  lr: 0.000064  loss: 0.5400 (0.5522)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [140/172]  eta: 0:00:50  lr: 0.000064  loss: 0.5400 (0.5520)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [150/172]  eta: 0:00:35  lr: 0.000064  loss: 0.5365 (0.5515)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [160/172]  eta: 0:00:19  lr: 0.000064  loss: 0.5318 (0.5510)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [170/172]  eta: 0:00:03  lr: 0.000064  loss: 0.5490 (0.5512)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421]  [171/172]  eta: 0:00:01  lr: 0.000064  loss: 0.5498 (0.5512)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:421] Total time: 0:04:33 (1.5923 s / it)\n",
      "Averaged stats: lr: 0.000064  loss: 0.5498 (0.5512)\n",
      "Valid: [epoch:421]  [ 0/14]  eta: 0:00:04  loss: 0.4945 (0.4945)  time: 0.3175  data: 0.3022  max mem: 20571\n",
      "Valid: [epoch:421]  [13/14]  eta: 0:00:00  loss: 0.5116 (0.5200)  time: 0.0368  data: 0.0217  max mem: 20571\n",
      "Valid: [epoch:421] Total time: 0:00:00 (0.0430 s / it)\n",
      "Averaged stats: loss: 0.5116 (0.5200)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_421_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.520%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:422]  [  0/172]  eta: 0:07:16  lr: 0.000064  loss: 0.5254 (0.5254)  time: 2.5382  data: 0.9531  max mem: 20571\n",
      "Train: [epoch:422]  [ 10/172]  eta: 0:04:30  lr: 0.000064  loss: 0.5376 (0.5555)  time: 1.6710  data: 0.0868  max mem: 20571\n",
      "Train: [epoch:422]  [ 20/172]  eta: 0:04:07  lr: 0.000064  loss: 0.5392 (0.5577)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [ 30/172]  eta: 0:03:49  lr: 0.000064  loss: 0.5453 (0.5537)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [ 40/172]  eta: 0:03:32  lr: 0.000064  loss: 0.5389 (0.5521)  time: 1.5860  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:422]  [ 50/172]  eta: 0:03:15  lr: 0.000064  loss: 0.5389 (0.5528)  time: 1.5865  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:422]  [ 60/172]  eta: 0:02:59  lr: 0.000064  loss: 0.5561 (0.5541)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [ 70/172]  eta: 0:02:43  lr: 0.000064  loss: 0.5561 (0.5554)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [ 80/172]  eta: 0:02:26  lr: 0.000064  loss: 0.5553 (0.5579)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [ 90/172]  eta: 0:02:10  lr: 0.000064  loss: 0.5488 (0.5580)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [100/172]  eta: 0:01:54  lr: 0.000064  loss: 0.5659 (0.5601)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [110/172]  eta: 0:01:38  lr: 0.000064  loss: 0.5694 (0.5600)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [120/172]  eta: 0:01:22  lr: 0.000064  loss: 0.5581 (0.5602)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [130/172]  eta: 0:01:06  lr: 0.000064  loss: 0.5495 (0.5589)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [140/172]  eta: 0:00:50  lr: 0.000064  loss: 0.5450 (0.5576)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [150/172]  eta: 0:00:35  lr: 0.000064  loss: 0.5400 (0.5569)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [160/172]  eta: 0:00:19  lr: 0.000064  loss: 0.5444 (0.5567)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [170/172]  eta: 0:00:03  lr: 0.000064  loss: 0.5444 (0.5561)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422]  [171/172]  eta: 0:00:01  lr: 0.000064  loss: 0.5451 (0.5561)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:422] Total time: 0:04:33 (1.5911 s / it)\n",
      "Averaged stats: lr: 0.000064  loss: 0.5451 (0.5561)\n",
      "Valid: [epoch:422]  [ 0/14]  eta: 0:00:04  loss: 0.5969 (0.5969)  time: 0.3060  data: 0.2911  max mem: 20571\n",
      "Valid: [epoch:422]  [13/14]  eta: 0:00:00  loss: 0.5606 (0.5655)  time: 0.0379  data: 0.0229  max mem: 20571\n",
      "Valid: [epoch:422] Total time: 0:00:00 (0.0428 s / it)\n",
      "Averaged stats: loss: 0.5606 (0.5655)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_422_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.566%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:423]  [  0/172]  eta: 0:07:39  lr: 0.000064  loss: 0.5854 (0.5854)  time: 2.6693  data: 1.0714  max mem: 20571\n",
      "Train: [epoch:423]  [ 10/172]  eta: 0:04:32  lr: 0.000064  loss: 0.5271 (0.5387)  time: 1.6820  data: 0.0976  max mem: 20571\n",
      "Train: [epoch:423]  [ 20/172]  eta: 0:04:08  lr: 0.000064  loss: 0.5387 (0.5477)  time: 1.5830  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:423]  [ 30/172]  eta: 0:03:49  lr: 0.000064  loss: 0.5527 (0.5505)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [ 40/172]  eta: 0:03:32  lr: 0.000064  loss: 0.5501 (0.5521)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [ 50/172]  eta: 0:03:15  lr: 0.000064  loss: 0.5483 (0.5523)  time: 1.5848  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:423]  [ 60/172]  eta: 0:02:59  lr: 0.000064  loss: 0.5516 (0.5536)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [ 70/172]  eta: 0:02:43  lr: 0.000064  loss: 0.5484 (0.5543)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [ 80/172]  eta: 0:02:26  lr: 0.000064  loss: 0.5471 (0.5536)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [ 90/172]  eta: 0:02:10  lr: 0.000064  loss: 0.5473 (0.5532)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [100/172]  eta: 0:01:54  lr: 0.000064  loss: 0.5593 (0.5544)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [110/172]  eta: 0:01:38  lr: 0.000064  loss: 0.5549 (0.5548)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [120/172]  eta: 0:01:22  lr: 0.000064  loss: 0.5470 (0.5544)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [130/172]  eta: 0:01:06  lr: 0.000064  loss: 0.5468 (0.5535)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [140/172]  eta: 0:00:50  lr: 0.000064  loss: 0.5468 (0.5538)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [150/172]  eta: 0:00:35  lr: 0.000064  loss: 0.5621 (0.5533)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [160/172]  eta: 0:00:19  lr: 0.000064  loss: 0.5515 (0.5537)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [170/172]  eta: 0:00:03  lr: 0.000064  loss: 0.5474 (0.5530)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423]  [171/172]  eta: 0:00:01  lr: 0.000064  loss: 0.5462 (0.5528)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:423] Total time: 0:04:33 (1.5911 s / it)\n",
      "Averaged stats: lr: 0.000064  loss: 0.5462 (0.5528)\n",
      "Valid: [epoch:423]  [ 0/14]  eta: 0:00:05  loss: 0.5266 (0.5266)  time: 0.4142  data: 0.3975  max mem: 20571\n",
      "Valid: [epoch:423]  [13/14]  eta: 0:00:00  loss: 0.5432 (0.5471)  time: 0.0446  data: 0.0293  max mem: 20571\n",
      "Valid: [epoch:423] Total time: 0:00:00 (0.0502 s / it)\n",
      "Averaged stats: loss: 0.5432 (0.5471)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_423_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.547%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:424]  [  0/172]  eta: 0:07:19  lr: 0.000064  loss: 0.6679 (0.6679)  time: 2.5578  data: 0.9878  max mem: 20571\n",
      "Train: [epoch:424]  [ 10/172]  eta: 0:04:30  lr: 0.000064  loss: 0.5440 (0.5629)  time: 1.6720  data: 0.0899  max mem: 20571\n",
      "Train: [epoch:424]  [ 20/172]  eta: 0:04:07  lr: 0.000064  loss: 0.5440 (0.5622)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [ 30/172]  eta: 0:03:49  lr: 0.000064  loss: 0.5526 (0.5592)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [ 40/172]  eta: 0:03:32  lr: 0.000064  loss: 0.5367 (0.5529)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [ 50/172]  eta: 0:03:15  lr: 0.000064  loss: 0.5347 (0.5532)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [ 60/172]  eta: 0:02:59  lr: 0.000064  loss: 0.5518 (0.5539)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [ 70/172]  eta: 0:02:43  lr: 0.000064  loss: 0.5520 (0.5544)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [ 80/172]  eta: 0:02:26  lr: 0.000064  loss: 0.5514 (0.5535)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [ 90/172]  eta: 0:02:10  lr: 0.000064  loss: 0.5548 (0.5537)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [100/172]  eta: 0:01:54  lr: 0.000064  loss: 0.5647 (0.5549)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [110/172]  eta: 0:01:38  lr: 0.000064  loss: 0.5650 (0.5551)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [120/172]  eta: 0:01:22  lr: 0.000064  loss: 0.5601 (0.5564)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [130/172]  eta: 0:01:06  lr: 0.000064  loss: 0.5601 (0.5567)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [140/172]  eta: 0:00:50  lr: 0.000064  loss: 0.5456 (0.5563)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [150/172]  eta: 0:00:35  lr: 0.000064  loss: 0.5456 (0.5565)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [160/172]  eta: 0:00:19  lr: 0.000064  loss: 0.5409 (0.5564)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [170/172]  eta: 0:00:03  lr: 0.000064  loss: 0.5529 (0.5572)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424]  [171/172]  eta: 0:00:01  lr: 0.000064  loss: 0.5529 (0.5569)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:424] Total time: 0:04:33 (1.5915 s / it)\n",
      "Averaged stats: lr: 0.000064  loss: 0.5529 (0.5569)\n",
      "Valid: [epoch:424]  [ 0/14]  eta: 0:00:04  loss: 0.5684 (0.5684)  time: 0.3305  data: 0.3138  max mem: 20571\n",
      "Valid: [epoch:424]  [13/14]  eta: 0:00:00  loss: 0.5255 (0.5335)  time: 0.0395  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:424] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.5255 (0.5335)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_424_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.533%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:425]  [  0/172]  eta: 0:07:16  lr: 0.000064  loss: 0.6254 (0.6254)  time: 2.5397  data: 0.9587  max mem: 20571\n",
      "Train: [epoch:425]  [ 10/172]  eta: 0:04:29  lr: 0.000064  loss: 0.5615 (0.5733)  time: 1.6666  data: 0.0873  max mem: 20571\n",
      "Train: [epoch:425]  [ 20/172]  eta: 0:04:07  lr: 0.000064  loss: 0.5493 (0.5631)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [ 30/172]  eta: 0:03:49  lr: 0.000064  loss: 0.5493 (0.5635)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [ 40/172]  eta: 0:03:32  lr: 0.000064  loss: 0.5422 (0.5565)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [ 50/172]  eta: 0:03:15  lr: 0.000064  loss: 0.5423 (0.5577)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [ 60/172]  eta: 0:02:59  lr: 0.000064  loss: 0.5507 (0.5558)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [ 70/172]  eta: 0:02:42  lr: 0.000064  loss: 0.5399 (0.5551)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [ 80/172]  eta: 0:02:26  lr: 0.000064  loss: 0.5357 (0.5530)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [ 90/172]  eta: 0:02:10  lr: 0.000064  loss: 0.5486 (0.5535)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [100/172]  eta: 0:01:54  lr: 0.000064  loss: 0.5488 (0.5536)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [110/172]  eta: 0:01:38  lr: 0.000064  loss: 0.5634 (0.5554)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [120/172]  eta: 0:01:22  lr: 0.000064  loss: 0.5586 (0.5552)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [130/172]  eta: 0:01:06  lr: 0.000064  loss: 0.5506 (0.5551)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [140/172]  eta: 0:00:50  lr: 0.000064  loss: 0.5506 (0.5547)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [150/172]  eta: 0:00:34  lr: 0.000064  loss: 0.5409 (0.5539)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [160/172]  eta: 0:00:19  lr: 0.000064  loss: 0.5484 (0.5537)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [170/172]  eta: 0:00:03  lr: 0.000064  loss: 0.5593 (0.5539)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425]  [171/172]  eta: 0:00:01  lr: 0.000064  loss: 0.5593 (0.5537)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:425] Total time: 0:04:33 (1.5900 s / it)\n",
      "Averaged stats: lr: 0.000064  loss: 0.5593 (0.5537)\n",
      "Valid: [epoch:425]  [ 0/14]  eta: 0:00:05  loss: 0.4857 (0.4857)  time: 0.3926  data: 0.3763  max mem: 20571\n",
      "Valid: [epoch:425]  [13/14]  eta: 0:00:00  loss: 0.5156 (0.5237)  time: 0.0455  data: 0.0298  max mem: 20571\n",
      "Valid: [epoch:425] Total time: 0:00:00 (0.0534 s / it)\n",
      "Averaged stats: loss: 0.5156 (0.5237)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_425_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.524%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:426]  [  0/172]  eta: 0:07:45  lr: 0.000064  loss: 0.5032 (0.5032)  time: 2.7070  data: 1.1369  max mem: 20571\n",
      "Train: [epoch:426]  [ 10/172]  eta: 0:04:32  lr: 0.000064  loss: 0.5437 (0.5517)  time: 1.6844  data: 0.1035  max mem: 20571\n",
      "Train: [epoch:426]  [ 20/172]  eta: 0:04:08  lr: 0.000064  loss: 0.5416 (0.5505)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [ 30/172]  eta: 0:03:50  lr: 0.000064  loss: 0.5427 (0.5488)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [ 40/172]  eta: 0:03:32  lr: 0.000064  loss: 0.5447 (0.5487)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [ 50/172]  eta: 0:03:15  lr: 0.000064  loss: 0.5405 (0.5502)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [ 60/172]  eta: 0:02:59  lr: 0.000064  loss: 0.5363 (0.5477)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [ 70/172]  eta: 0:02:43  lr: 0.000064  loss: 0.5435 (0.5495)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [ 80/172]  eta: 0:02:26  lr: 0.000064  loss: 0.5545 (0.5502)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [ 90/172]  eta: 0:02:10  lr: 0.000064  loss: 0.5453 (0.5510)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [100/172]  eta: 0:01:54  lr: 0.000064  loss: 0.5519 (0.5522)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [110/172]  eta: 0:01:38  lr: 0.000064  loss: 0.5519 (0.5526)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [120/172]  eta: 0:01:22  lr: 0.000064  loss: 0.5533 (0.5525)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [130/172]  eta: 0:01:06  lr: 0.000064  loss: 0.5567 (0.5524)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [140/172]  eta: 0:00:50  lr: 0.000064  loss: 0.5426 (0.5518)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [150/172]  eta: 0:00:34  lr: 0.000064  loss: 0.5534 (0.5531)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [160/172]  eta: 0:00:19  lr: 0.000064  loss: 0.5487 (0.5527)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [170/172]  eta: 0:00:03  lr: 0.000064  loss: 0.5487 (0.5536)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426]  [171/172]  eta: 0:00:01  lr: 0.000064  loss: 0.5490 (0.5540)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:426] Total time: 0:04:33 (1.5908 s / it)\n",
      "Averaged stats: lr: 0.000064  loss: 0.5490 (0.5540)\n",
      "Valid: [epoch:426]  [ 0/14]  eta: 0:00:05  loss: 0.5696 (0.5696)  time: 0.3734  data: 0.3575  max mem: 20571\n",
      "Valid: [epoch:426]  [13/14]  eta: 0:00:00  loss: 0.5216 (0.5314)  time: 0.0411  data: 0.0260  max mem: 20571\n",
      "Valid: [epoch:426] Total time: 0:00:00 (0.0466 s / it)\n",
      "Averaged stats: loss: 0.5216 (0.5314)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_426_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.531%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:427]  [  0/172]  eta: 0:07:35  lr: 0.000064  loss: 0.4845 (0.4845)  time: 2.6464  data: 1.0681  max mem: 20571\n",
      "Train: [epoch:427]  [ 10/172]  eta: 0:04:31  lr: 0.000064  loss: 0.5548 (0.5500)  time: 1.6772  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:427]  [ 20/172]  eta: 0:04:08  lr: 0.000064  loss: 0.5712 (0.5653)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [ 30/172]  eta: 0:03:49  lr: 0.000064  loss: 0.5689 (0.5633)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [ 40/172]  eta: 0:03:32  lr: 0.000064  loss: 0.5493 (0.5616)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [ 50/172]  eta: 0:03:15  lr: 0.000064  loss: 0.5485 (0.5576)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [ 60/172]  eta: 0:02:59  lr: 0.000064  loss: 0.5506 (0.5575)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [ 70/172]  eta: 0:02:42  lr: 0.000064  loss: 0.5567 (0.5569)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [ 80/172]  eta: 0:02:26  lr: 0.000064  loss: 0.5516 (0.5569)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [ 90/172]  eta: 0:02:10  lr: 0.000064  loss: 0.5641 (0.5583)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [100/172]  eta: 0:01:54  lr: 0.000064  loss: 0.5604 (0.5579)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [110/172]  eta: 0:01:38  lr: 0.000064  loss: 0.5756 (0.5641)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [120/172]  eta: 0:01:22  lr: 0.000064  loss: 0.6299 (0.5693)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [130/172]  eta: 0:01:06  lr: 0.000064  loss: 0.6001 (0.5711)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [140/172]  eta: 0:00:50  lr: 0.000064  loss: 0.5909 (0.5731)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [150/172]  eta: 0:00:35  lr: 0.000064  loss: 0.5954 (0.5753)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [160/172]  eta: 0:00:19  lr: 0.000064  loss: 0.5983 (0.5772)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [170/172]  eta: 0:00:03  lr: 0.000064  loss: 0.5801 (0.5770)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427]  [171/172]  eta: 0:00:01  lr: 0.000064  loss: 0.5801 (0.5771)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:427] Total time: 0:04:33 (1.5913 s / it)\n",
      "Averaged stats: lr: 0.000064  loss: 0.5801 (0.5771)\n",
      "Valid: [epoch:427]  [ 0/14]  eta: 0:00:04  loss: 0.6144 (0.6144)  time: 0.3162  data: 0.3007  max mem: 20571\n",
      "Valid: [epoch:427]  [13/14]  eta: 0:00:00  loss: 0.5495 (0.5673)  time: 0.0380  data: 0.0229  max mem: 20571\n",
      "Valid: [epoch:427] Total time: 0:00:00 (0.0426 s / it)\n",
      "Averaged stats: loss: 0.5495 (0.5673)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_427_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.567%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:428]  [  0/172]  eta: 0:07:30  lr: 0.000064  loss: 0.5578 (0.5578)  time: 2.6165  data: 1.0415  max mem: 20571\n",
      "Train: [epoch:428]  [ 10/172]  eta: 0:04:31  lr: 0.000064  loss: 0.5641 (0.5818)  time: 1.6769  data: 0.0948  max mem: 20571\n",
      "Train: [epoch:428]  [ 20/172]  eta: 0:04:08  lr: 0.000064  loss: 0.5666 (0.5762)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [ 30/172]  eta: 0:03:49  lr: 0.000064  loss: 0.5746 (0.5772)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [ 40/172]  eta: 0:03:32  lr: 0.000064  loss: 0.5731 (0.5752)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [ 50/172]  eta: 0:03:15  lr: 0.000064  loss: 0.5674 (0.5723)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [ 60/172]  eta: 0:02:59  lr: 0.000064  loss: 0.5566 (0.5703)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [ 70/172]  eta: 0:02:43  lr: 0.000064  loss: 0.5560 (0.5697)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [ 80/172]  eta: 0:02:26  lr: 0.000064  loss: 0.5560 (0.5680)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [ 90/172]  eta: 0:02:10  lr: 0.000064  loss: 0.5503 (0.5678)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [100/172]  eta: 0:01:54  lr: 0.000064  loss: 0.5520 (0.5672)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [110/172]  eta: 0:01:38  lr: 0.000064  loss: 0.5517 (0.5657)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [120/172]  eta: 0:01:22  lr: 0.000064  loss: 0.5579 (0.5661)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [130/172]  eta: 0:01:06  lr: 0.000064  loss: 0.5522 (0.5645)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [140/172]  eta: 0:00:50  lr: 0.000064  loss: 0.5522 (0.5644)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [150/172]  eta: 0:00:35  lr: 0.000064  loss: 0.5635 (0.5639)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [160/172]  eta: 0:00:19  lr: 0.000064  loss: 0.5420 (0.5623)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428]  [170/172]  eta: 0:00:03  lr: 0.000064  loss: 0.5405 (0.5629)  time: 1.5878  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:428]  [171/172]  eta: 0:00:01  lr: 0.000064  loss: 0.5405 (0.5627)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:428] Total time: 0:04:33 (1.5915 s / it)\n",
      "Averaged stats: lr: 0.000064  loss: 0.5405 (0.5627)\n",
      "Valid: [epoch:428]  [ 0/14]  eta: 0:00:06  loss: 0.5093 (0.5093)  time: 0.4573  data: 0.4423  max mem: 20571\n",
      "Valid: [epoch:428]  [13/14]  eta: 0:00:00  loss: 0.5160 (0.5227)  time: 0.0468  data: 0.0318  max mem: 20571\n",
      "Valid: [epoch:428] Total time: 0:00:00 (0.0513 s / it)\n",
      "Averaged stats: loss: 0.5160 (0.5227)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_428_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.523%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:429]  [  0/172]  eta: 0:07:34  lr: 0.000064  loss: 0.5263 (0.5263)  time: 2.6452  data: 1.0439  max mem: 20571\n",
      "Train: [epoch:429]  [ 10/172]  eta: 0:04:31  lr: 0.000064  loss: 0.5468 (0.5579)  time: 1.6760  data: 0.0950  max mem: 20571\n",
      "Train: [epoch:429]  [ 20/172]  eta: 0:04:07  lr: 0.000064  loss: 0.5468 (0.5556)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [ 30/172]  eta: 0:03:49  lr: 0.000064  loss: 0.5622 (0.5560)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [ 40/172]  eta: 0:03:32  lr: 0.000064  loss: 0.5383 (0.5523)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [ 50/172]  eta: 0:03:15  lr: 0.000064  loss: 0.5447 (0.5544)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [ 60/172]  eta: 0:02:59  lr: 0.000064  loss: 0.5592 (0.5553)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [ 70/172]  eta: 0:02:43  lr: 0.000064  loss: 0.5467 (0.5537)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [ 80/172]  eta: 0:02:26  lr: 0.000064  loss: 0.5424 (0.5540)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [ 90/172]  eta: 0:02:10  lr: 0.000064  loss: 0.5577 (0.5549)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [100/172]  eta: 0:01:54  lr: 0.000064  loss: 0.5645 (0.5550)  time: 1.5853  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:429]  [110/172]  eta: 0:01:38  lr: 0.000064  loss: 0.5516 (0.5561)  time: 1.5869  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:429]  [120/172]  eta: 0:01:22  lr: 0.000064  loss: 0.5516 (0.5558)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [130/172]  eta: 0:01:06  lr: 0.000064  loss: 0.5577 (0.5564)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [140/172]  eta: 0:00:50  lr: 0.000064  loss: 0.5576 (0.5557)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [150/172]  eta: 0:00:34  lr: 0.000064  loss: 0.5414 (0.5559)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [160/172]  eta: 0:00:19  lr: 0.000064  loss: 0.5458 (0.5561)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [170/172]  eta: 0:00:03  lr: 0.000064  loss: 0.5594 (0.5563)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429]  [171/172]  eta: 0:00:01  lr: 0.000064  loss: 0.5594 (0.5560)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:429] Total time: 0:04:33 (1.5908 s / it)\n",
      "Averaged stats: lr: 0.000064  loss: 0.5594 (0.5560)\n",
      "Valid: [epoch:429]  [ 0/14]  eta: 0:00:05  loss: 0.5156 (0.5156)  time: 0.4227  data: 0.4073  max mem: 20571\n",
      "Valid: [epoch:429]  [13/14]  eta: 0:00:00  loss: 0.5271 (0.5346)  time: 0.0451  data: 0.0300  max mem: 20571\n",
      "Valid: [epoch:429] Total time: 0:00:00 (0.0532 s / it)\n",
      "Averaged stats: loss: 0.5271 (0.5346)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_429_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.535%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:430]  [  0/172]  eta: 0:07:30  lr: 0.000063  loss: 0.5735 (0.5735)  time: 2.6197  data: 1.0463  max mem: 20571\n",
      "Train: [epoch:430]  [ 10/172]  eta: 0:04:31  lr: 0.000063  loss: 0.5570 (0.5590)  time: 1.6774  data: 0.0952  max mem: 20571\n",
      "Train: [epoch:430]  [ 20/172]  eta: 0:04:08  lr: 0.000063  loss: 0.5679 (0.5678)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [ 30/172]  eta: 0:03:49  lr: 0.000063  loss: 0.5645 (0.5628)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [ 40/172]  eta: 0:03:32  lr: 0.000063  loss: 0.5570 (0.5628)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [ 50/172]  eta: 0:03:15  lr: 0.000063  loss: 0.5755 (0.5649)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [ 60/172]  eta: 0:02:59  lr: 0.000063  loss: 0.5582 (0.5635)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [ 70/172]  eta: 0:02:42  lr: 0.000063  loss: 0.5366 (0.5612)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [ 80/172]  eta: 0:02:26  lr: 0.000063  loss: 0.5449 (0.5606)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [ 90/172]  eta: 0:02:10  lr: 0.000063  loss: 0.5453 (0.5608)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [100/172]  eta: 0:01:54  lr: 0.000063  loss: 0.5506 (0.5606)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [110/172]  eta: 0:01:38  lr: 0.000063  loss: 0.5496 (0.5604)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [120/172]  eta: 0:01:22  lr: 0.000063  loss: 0.5481 (0.5611)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [130/172]  eta: 0:01:06  lr: 0.000063  loss: 0.5586 (0.5608)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [140/172]  eta: 0:00:50  lr: 0.000063  loss: 0.5586 (0.5605)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [150/172]  eta: 0:00:34  lr: 0.000063  loss: 0.5491 (0.5600)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [160/172]  eta: 0:00:19  lr: 0.000063  loss: 0.5427 (0.5592)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [170/172]  eta: 0:00:03  lr: 0.000063  loss: 0.5443 (0.5590)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430]  [171/172]  eta: 0:00:01  lr: 0.000063  loss: 0.5427 (0.5588)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:430] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000063  loss: 0.5427 (0.5588)\n",
      "Valid: [epoch:430]  [ 0/14]  eta: 0:00:04  loss: 0.5627 (0.5627)  time: 0.3054  data: 0.2899  max mem: 20571\n",
      "Valid: [epoch:430]  [13/14]  eta: 0:00:00  loss: 0.5296 (0.5388)  time: 0.0567  data: 0.0417  max mem: 20571\n",
      "Valid: [epoch:430] Total time: 0:00:00 (0.0628 s / it)\n",
      "Averaged stats: loss: 0.5296 (0.5388)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_430_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.539%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:431]  [  0/172]  eta: 0:07:47  lr: 0.000063  loss: 0.5455 (0.5455)  time: 2.7157  data: 1.1330  max mem: 20571\n",
      "Train: [epoch:431]  [ 10/172]  eta: 0:04:32  lr: 0.000063  loss: 0.5455 (0.5557)  time: 1.6833  data: 0.1031  max mem: 20571\n",
      "Train: [epoch:431]  [ 20/172]  eta: 0:04:08  lr: 0.000063  loss: 0.5580 (0.5605)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [ 30/172]  eta: 0:03:49  lr: 0.000063  loss: 0.5580 (0.5584)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [ 40/172]  eta: 0:03:32  lr: 0.000063  loss: 0.5573 (0.5569)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [ 50/172]  eta: 0:03:15  lr: 0.000063  loss: 0.5668 (0.5572)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [ 60/172]  eta: 0:02:59  lr: 0.000063  loss: 0.5557 (0.5570)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [ 70/172]  eta: 0:02:43  lr: 0.000063  loss: 0.5607 (0.5569)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [ 80/172]  eta: 0:02:27  lr: 0.000063  loss: 0.5613 (0.5566)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [ 90/172]  eta: 0:02:10  lr: 0.000063  loss: 0.5637 (0.5588)  time: 1.5858  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:431]  [100/172]  eta: 0:01:54  lr: 0.000063  loss: 0.5612 (0.5585)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [110/172]  eta: 0:01:38  lr: 0.000063  loss: 0.5612 (0.5584)  time: 1.5885  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:431]  [120/172]  eta: 0:01:22  lr: 0.000063  loss: 0.5590 (0.5580)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [130/172]  eta: 0:01:06  lr: 0.000063  loss: 0.5575 (0.5580)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [140/172]  eta: 0:00:50  lr: 0.000063  loss: 0.5588 (0.5583)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [150/172]  eta: 0:00:35  lr: 0.000063  loss: 0.5717 (0.5585)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [160/172]  eta: 0:00:19  lr: 0.000063  loss: 0.5500 (0.5580)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [170/172]  eta: 0:00:03  lr: 0.000063  loss: 0.5467 (0.5583)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431]  [171/172]  eta: 0:00:01  lr: 0.000063  loss: 0.5500 (0.5584)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:431] Total time: 0:04:34 (1.5932 s / it)\n",
      "Averaged stats: lr: 0.000063  loss: 0.5500 (0.5584)\n",
      "Valid: [epoch:431]  [ 0/14]  eta: 0:00:06  loss: 0.5672 (0.5672)  time: 0.4851  data: 0.4658  max mem: 20571\n",
      "Valid: [epoch:431]  [13/14]  eta: 0:00:00  loss: 0.5219 (0.5309)  time: 0.0499  data: 0.0343  max mem: 20571\n",
      "Valid: [epoch:431] Total time: 0:00:00 (0.0563 s / it)\n",
      "Averaged stats: loss: 0.5219 (0.5309)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_431_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.531%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:432]  [  0/172]  eta: 0:07:52  lr: 0.000063  loss: 0.5470 (0.5470)  time: 2.7497  data: 1.1707  max mem: 20571\n",
      "Train: [epoch:432]  [ 10/172]  eta: 0:04:34  lr: 0.000063  loss: 0.5470 (0.5496)  time: 1.6922  data: 0.1066  max mem: 20571\n",
      "Train: [epoch:432]  [ 20/172]  eta: 0:04:09  lr: 0.000063  loss: 0.5532 (0.5587)  time: 1.5880  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:432]  [ 30/172]  eta: 0:03:50  lr: 0.000063  loss: 0.5563 (0.5573)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [ 40/172]  eta: 0:03:33  lr: 0.000063  loss: 0.5563 (0.5577)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [ 50/172]  eta: 0:03:16  lr: 0.000063  loss: 0.5517 (0.5569)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [ 60/172]  eta: 0:02:59  lr: 0.000063  loss: 0.5438 (0.5539)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [ 70/172]  eta: 0:02:43  lr: 0.000063  loss: 0.5368 (0.5540)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [ 80/172]  eta: 0:02:27  lr: 0.000063  loss: 0.5456 (0.5544)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [ 90/172]  eta: 0:02:11  lr: 0.000063  loss: 0.5521 (0.5551)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [100/172]  eta: 0:01:55  lr: 0.000063  loss: 0.5595 (0.5555)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [110/172]  eta: 0:01:39  lr: 0.000063  loss: 0.5480 (0.5559)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [120/172]  eta: 0:01:22  lr: 0.000063  loss: 0.5499 (0.5568)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [130/172]  eta: 0:01:06  lr: 0.000063  loss: 0.5552 (0.5573)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [140/172]  eta: 0:00:51  lr: 0.000063  loss: 0.5638 (0.5581)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [150/172]  eta: 0:00:35  lr: 0.000063  loss: 0.5638 (0.5577)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [160/172]  eta: 0:00:19  lr: 0.000063  loss: 0.5573 (0.5584)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [170/172]  eta: 0:00:03  lr: 0.000063  loss: 0.5520 (0.5585)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432]  [171/172]  eta: 0:00:01  lr: 0.000063  loss: 0.5573 (0.5585)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:432] Total time: 0:04:34 (1.5938 s / it)\n",
      "Averaged stats: lr: 0.000063  loss: 0.5573 (0.5585)\n",
      "Valid: [epoch:432]  [ 0/14]  eta: 0:00:04  loss: 0.4882 (0.4882)  time: 0.3516  data: 0.3342  max mem: 20571\n",
      "Valid: [epoch:432]  [13/14]  eta: 0:00:00  loss: 0.5327 (0.5387)  time: 0.0394  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:432] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.5327 (0.5387)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_432_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.539%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:433]  [  0/172]  eta: 0:07:32  lr: 0.000063  loss: 0.5858 (0.5858)  time: 2.6283  data: 1.0470  max mem: 20571\n",
      "Train: [epoch:433]  [ 10/172]  eta: 0:04:31  lr: 0.000063  loss: 0.5374 (0.5591)  time: 1.6748  data: 0.0953  max mem: 20571\n",
      "Train: [epoch:433]  [ 20/172]  eta: 0:04:07  lr: 0.000063  loss: 0.5510 (0.5658)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [ 30/172]  eta: 0:03:49  lr: 0.000063  loss: 0.5554 (0.5603)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [ 40/172]  eta: 0:03:32  lr: 0.000063  loss: 0.5496 (0.5601)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [ 50/172]  eta: 0:03:15  lr: 0.000063  loss: 0.5465 (0.5581)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [ 60/172]  eta: 0:02:59  lr: 0.000063  loss: 0.5465 (0.5577)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [ 70/172]  eta: 0:02:43  lr: 0.000063  loss: 0.5593 (0.5589)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [ 80/172]  eta: 0:02:26  lr: 0.000063  loss: 0.5593 (0.5597)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [ 90/172]  eta: 0:02:10  lr: 0.000063  loss: 0.5512 (0.5599)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [100/172]  eta: 0:01:54  lr: 0.000063  loss: 0.5407 (0.5581)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [110/172]  eta: 0:01:38  lr: 0.000063  loss: 0.5552 (0.5586)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [120/172]  eta: 0:01:22  lr: 0.000063  loss: 0.5621 (0.5577)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [130/172]  eta: 0:01:06  lr: 0.000063  loss: 0.5433 (0.5572)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [140/172]  eta: 0:00:50  lr: 0.000063  loss: 0.5422 (0.5572)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [150/172]  eta: 0:00:34  lr: 0.000063  loss: 0.5422 (0.5580)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [160/172]  eta: 0:00:19  lr: 0.000063  loss: 0.5536 (0.5587)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [170/172]  eta: 0:00:03  lr: 0.000063  loss: 0.5573 (0.5595)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433]  [171/172]  eta: 0:00:01  lr: 0.000063  loss: 0.5536 (0.5594)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:433] Total time: 0:04:33 (1.5908 s / it)\n",
      "Averaged stats: lr: 0.000063  loss: 0.5536 (0.5594)\n",
      "Valid: [epoch:433]  [ 0/14]  eta: 0:00:04  loss: 0.5187 (0.5187)  time: 0.2942  data: 0.2792  max mem: 20571\n",
      "Valid: [epoch:433]  [13/14]  eta: 0:00:00  loss: 0.5241 (0.5304)  time: 0.0392  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:433] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.5241 (0.5304)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_433_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.530%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:434]  [  0/172]  eta: 0:07:50  lr: 0.000063  loss: 0.5882 (0.5882)  time: 2.7367  data: 1.1664  max mem: 20571\n",
      "Train: [epoch:434]  [ 10/172]  eta: 0:04:33  lr: 0.000063  loss: 0.5715 (0.5615)  time: 1.6858  data: 0.1061  max mem: 20571\n",
      "Train: [epoch:434]  [ 20/172]  eta: 0:04:08  lr: 0.000063  loss: 0.5412 (0.5522)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [ 30/172]  eta: 0:03:49  lr: 0.000063  loss: 0.5412 (0.5542)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [ 40/172]  eta: 0:03:32  lr: 0.000063  loss: 0.5494 (0.5533)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [ 50/172]  eta: 0:03:15  lr: 0.000063  loss: 0.5505 (0.5565)  time: 1.5826  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:434]  [ 60/172]  eta: 0:02:59  lr: 0.000063  loss: 0.5607 (0.5581)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [ 70/172]  eta: 0:02:43  lr: 0.000063  loss: 0.5571 (0.5597)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [ 80/172]  eta: 0:02:26  lr: 0.000063  loss: 0.5571 (0.5598)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [ 90/172]  eta: 0:02:10  lr: 0.000063  loss: 0.5573 (0.5607)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [100/172]  eta: 0:01:54  lr: 0.000063  loss: 0.5699 (0.5614)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [110/172]  eta: 0:01:38  lr: 0.000063  loss: 0.5587 (0.5601)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [120/172]  eta: 0:01:22  lr: 0.000063  loss: 0.5592 (0.5607)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [130/172]  eta: 0:01:06  lr: 0.000063  loss: 0.5671 (0.5608)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [140/172]  eta: 0:00:50  lr: 0.000063  loss: 0.5630 (0.5604)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [150/172]  eta: 0:00:34  lr: 0.000063  loss: 0.5466 (0.5590)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [160/172]  eta: 0:00:19  lr: 0.000063  loss: 0.5460 (0.5592)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [170/172]  eta: 0:00:03  lr: 0.000063  loss: 0.5540 (0.5594)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434]  [171/172]  eta: 0:00:01  lr: 0.000063  loss: 0.5554 (0.5596)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:434] Total time: 0:04:33 (1.5900 s / it)\n",
      "Averaged stats: lr: 0.000063  loss: 0.5554 (0.5596)\n",
      "Valid: [epoch:434]  [ 0/14]  eta: 0:00:04  loss: 0.5331 (0.5331)  time: 0.3331  data: 0.3148  max mem: 20571\n",
      "Valid: [epoch:434]  [13/14]  eta: 0:00:00  loss: 0.5418 (0.5514)  time: 0.0390  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:434] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.5418 (0.5514)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_434_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.551%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:435]  [  0/172]  eta: 0:08:14  lr: 0.000063  loss: 0.5176 (0.5176)  time: 2.8732  data: 1.2950  max mem: 20571\n",
      "Train: [epoch:435]  [ 10/172]  eta: 0:04:34  lr: 0.000063  loss: 0.5334 (0.5630)  time: 1.6973  data: 0.1178  max mem: 20571\n",
      "Train: [epoch:435]  [ 20/172]  eta: 0:04:09  lr: 0.000063  loss: 0.5527 (0.5645)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [ 30/172]  eta: 0:03:50  lr: 0.000063  loss: 0.5586 (0.5664)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [ 40/172]  eta: 0:03:33  lr: 0.000063  loss: 0.5586 (0.5689)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [ 50/172]  eta: 0:03:16  lr: 0.000063  loss: 0.5843 (0.5705)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [ 60/172]  eta: 0:02:59  lr: 0.000063  loss: 0.5744 (0.5688)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [ 70/172]  eta: 0:02:43  lr: 0.000063  loss: 0.5498 (0.5673)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [ 80/172]  eta: 0:02:27  lr: 0.000063  loss: 0.5571 (0.5673)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [ 90/172]  eta: 0:02:11  lr: 0.000063  loss: 0.5585 (0.5667)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [100/172]  eta: 0:01:55  lr: 0.000063  loss: 0.5526 (0.5656)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [110/172]  eta: 0:01:38  lr: 0.000063  loss: 0.5643 (0.5672)  time: 1.5866  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:435]  [120/172]  eta: 0:01:22  lr: 0.000063  loss: 0.5626 (0.5665)  time: 1.5847  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:435]  [130/172]  eta: 0:01:06  lr: 0.000063  loss: 0.5531 (0.5664)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [140/172]  eta: 0:00:51  lr: 0.000063  loss: 0.5489 (0.5655)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [150/172]  eta: 0:00:35  lr: 0.000063  loss: 0.5515 (0.5655)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [160/172]  eta: 0:00:19  lr: 0.000063  loss: 0.5485 (0.5646)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [170/172]  eta: 0:00:03  lr: 0.000063  loss: 0.5588 (0.5646)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435]  [171/172]  eta: 0:00:01  lr: 0.000063  loss: 0.5588 (0.5642)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:435] Total time: 0:04:34 (1.5934 s / it)\n",
      "Averaged stats: lr: 0.000063  loss: 0.5588 (0.5642)\n",
      "Valid: [epoch:435]  [ 0/14]  eta: 0:00:04  loss: 0.5810 (0.5810)  time: 0.2884  data: 0.2725  max mem: 20571\n",
      "Valid: [epoch:435]  [13/14]  eta: 0:00:00  loss: 0.5419 (0.5486)  time: 0.0413  data: 0.0262  max mem: 20571\n",
      "Valid: [epoch:435] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.5419 (0.5486)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_435_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.549%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:436]  [  0/172]  eta: 0:07:29  lr: 0.000063  loss: 0.5786 (0.5786)  time: 2.6147  data: 1.0412  max mem: 20571\n",
      "Train: [epoch:436]  [ 10/172]  eta: 0:04:31  lr: 0.000063  loss: 0.5698 (0.5601)  time: 1.6772  data: 0.0948  max mem: 20571\n",
      "Train: [epoch:436]  [ 20/172]  eta: 0:04:08  lr: 0.000063  loss: 0.5698 (0.5683)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [ 30/172]  eta: 0:03:49  lr: 0.000063  loss: 0.5734 (0.5661)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [ 40/172]  eta: 0:03:32  lr: 0.000063  loss: 0.5389 (0.5598)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [ 50/172]  eta: 0:03:15  lr: 0.000063  loss: 0.5389 (0.5595)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [ 60/172]  eta: 0:02:59  lr: 0.000063  loss: 0.5457 (0.5570)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [ 70/172]  eta: 0:02:43  lr: 0.000063  loss: 0.5443 (0.5572)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [ 80/172]  eta: 0:02:26  lr: 0.000063  loss: 0.5639 (0.5584)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [ 90/172]  eta: 0:02:10  lr: 0.000063  loss: 0.5531 (0.5576)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [100/172]  eta: 0:01:54  lr: 0.000063  loss: 0.5586 (0.5584)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [110/172]  eta: 0:01:38  lr: 0.000063  loss: 0.5586 (0.5592)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [120/172]  eta: 0:01:22  lr: 0.000063  loss: 0.5541 (0.5607)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [130/172]  eta: 0:01:06  lr: 0.000063  loss: 0.5541 (0.5606)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [140/172]  eta: 0:00:50  lr: 0.000063  loss: 0.5724 (0.5628)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [150/172]  eta: 0:00:35  lr: 0.000063  loss: 0.5658 (0.5625)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [160/172]  eta: 0:00:19  lr: 0.000063  loss: 0.5658 (0.5634)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [170/172]  eta: 0:00:03  lr: 0.000063  loss: 0.5632 (0.5636)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436]  [171/172]  eta: 0:00:01  lr: 0.000063  loss: 0.5597 (0.5634)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:436] Total time: 0:04:33 (1.5916 s / it)\n",
      "Averaged stats: lr: 0.000063  loss: 0.5597 (0.5634)\n",
      "Valid: [epoch:436]  [ 0/14]  eta: 0:00:04  loss: 0.5836 (0.5836)  time: 0.3201  data: 0.3044  max mem: 20571\n",
      "Valid: [epoch:436]  [13/14]  eta: 0:00:00  loss: 0.5511 (0.5600)  time: 0.0391  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:436] Total time: 0:00:00 (0.0467 s / it)\n",
      "Averaged stats: loss: 0.5511 (0.5600)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_436_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.560%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:437]  [  0/172]  eta: 0:07:19  lr: 0.000063  loss: 0.5330 (0.5330)  time: 2.5546  data: 0.9681  max mem: 20571\n",
      "Train: [epoch:437]  [ 10/172]  eta: 0:04:30  lr: 0.000063  loss: 0.5505 (0.5633)  time: 1.6697  data: 0.0881  max mem: 20571\n",
      "Train: [epoch:437]  [ 20/172]  eta: 0:04:07  lr: 0.000063  loss: 0.5505 (0.5625)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [ 30/172]  eta: 0:03:49  lr: 0.000063  loss: 0.5432 (0.5623)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [ 40/172]  eta: 0:03:32  lr: 0.000063  loss: 0.5456 (0.5605)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [ 50/172]  eta: 0:03:15  lr: 0.000063  loss: 0.5549 (0.5612)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [ 60/172]  eta: 0:02:59  lr: 0.000063  loss: 0.5605 (0.5614)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [ 70/172]  eta: 0:02:42  lr: 0.000063  loss: 0.5734 (0.5621)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [ 80/172]  eta: 0:02:26  lr: 0.000063  loss: 0.5734 (0.5633)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [ 90/172]  eta: 0:02:10  lr: 0.000063  loss: 0.5703 (0.5642)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [100/172]  eta: 0:01:54  lr: 0.000063  loss: 0.5570 (0.5629)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [110/172]  eta: 0:01:38  lr: 0.000063  loss: 0.5622 (0.5646)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [120/172]  eta: 0:01:22  lr: 0.000063  loss: 0.5882 (0.5676)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [130/172]  eta: 0:01:06  lr: 0.000063  loss: 0.5737 (0.5675)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [140/172]  eta: 0:00:50  lr: 0.000063  loss: 0.5587 (0.5672)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [150/172]  eta: 0:00:34  lr: 0.000063  loss: 0.5573 (0.5673)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [160/172]  eta: 0:00:19  lr: 0.000063  loss: 0.5505 (0.5667)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [170/172]  eta: 0:00:03  lr: 0.000063  loss: 0.5569 (0.5671)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437]  [171/172]  eta: 0:00:01  lr: 0.000063  loss: 0.5604 (0.5671)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:437] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000063  loss: 0.5604 (0.5671)\n",
      "Valid: [epoch:437]  [ 0/14]  eta: 0:00:04  loss: 0.5579 (0.5579)  time: 0.3437  data: 0.3276  max mem: 20571\n",
      "Valid: [epoch:437]  [13/14]  eta: 0:00:00  loss: 0.5175 (0.5250)  time: 0.0396  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:437] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.5175 (0.5250)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_437_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.525%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:438]  [  0/172]  eta: 0:07:38  lr: 0.000063  loss: 0.5278 (0.5278)  time: 2.6664  data: 1.0954  max mem: 20571\n",
      "Train: [epoch:438]  [ 10/172]  eta: 0:04:31  lr: 0.000063  loss: 0.5322 (0.5455)  time: 1.6790  data: 0.0997  max mem: 20571\n",
      "Train: [epoch:438]  [ 20/172]  eta: 0:04:08  lr: 0.000063  loss: 0.5390 (0.5538)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [ 30/172]  eta: 0:03:49  lr: 0.000063  loss: 0.5512 (0.5536)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [ 40/172]  eta: 0:03:32  lr: 0.000063  loss: 0.5594 (0.5543)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [ 50/172]  eta: 0:03:15  lr: 0.000063  loss: 0.5574 (0.5553)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [ 60/172]  eta: 0:02:58  lr: 0.000063  loss: 0.5554 (0.5556)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [ 70/172]  eta: 0:02:42  lr: 0.000063  loss: 0.5546 (0.5570)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [ 80/172]  eta: 0:02:26  lr: 0.000063  loss: 0.5631 (0.5573)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [ 90/172]  eta: 0:02:10  lr: 0.000063  loss: 0.5634 (0.5595)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [100/172]  eta: 0:01:54  lr: 0.000063  loss: 0.5634 (0.5589)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [110/172]  eta: 0:01:38  lr: 0.000063  loss: 0.5498 (0.5601)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [120/172]  eta: 0:01:22  lr: 0.000063  loss: 0.5793 (0.5613)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [130/172]  eta: 0:01:06  lr: 0.000063  loss: 0.5767 (0.5623)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [140/172]  eta: 0:00:50  lr: 0.000063  loss: 0.5606 (0.5616)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [150/172]  eta: 0:00:34  lr: 0.000063  loss: 0.5572 (0.5612)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [160/172]  eta: 0:00:19  lr: 0.000063  loss: 0.5626 (0.5619)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [170/172]  eta: 0:00:03  lr: 0.000063  loss: 0.5657 (0.5628)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438]  [171/172]  eta: 0:00:01  lr: 0.000063  loss: 0.5628 (0.5627)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:438] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000063  loss: 0.5628 (0.5627)\n",
      "Valid: [epoch:438]  [ 0/14]  eta: 0:00:05  loss: 0.4908 (0.4908)  time: 0.3822  data: 0.3653  max mem: 20571\n",
      "Valid: [epoch:438]  [13/14]  eta: 0:00:00  loss: 0.5216 (0.5273)  time: 0.0428  data: 0.0275  max mem: 20571\n",
      "Valid: [epoch:438] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.5216 (0.5273)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_438_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.527%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:439]  [  0/172]  eta: 0:07:41  lr: 0.000062  loss: 0.5244 (0.5244)  time: 2.6853  data: 1.1013  max mem: 20571\n",
      "Train: [epoch:439]  [ 10/172]  eta: 0:04:31  lr: 0.000062  loss: 0.5589 (0.5554)  time: 1.6779  data: 0.1002  max mem: 20571\n",
      "Train: [epoch:439]  [ 20/172]  eta: 0:04:07  lr: 0.000062  loss: 0.5589 (0.5606)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [ 30/172]  eta: 0:03:49  lr: 0.000062  loss: 0.5508 (0.5577)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [ 40/172]  eta: 0:03:32  lr: 0.000062  loss: 0.5548 (0.5588)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [ 50/172]  eta: 0:03:15  lr: 0.000062  loss: 0.5610 (0.5606)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [ 60/172]  eta: 0:02:58  lr: 0.000062  loss: 0.5539 (0.5594)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [ 70/172]  eta: 0:02:42  lr: 0.000062  loss: 0.5431 (0.5591)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [ 80/172]  eta: 0:02:26  lr: 0.000062  loss: 0.5568 (0.5619)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [ 90/172]  eta: 0:02:10  lr: 0.000062  loss: 0.5568 (0.5628)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [100/172]  eta: 0:01:54  lr: 0.000062  loss: 0.5567 (0.5635)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [110/172]  eta: 0:01:38  lr: 0.000062  loss: 0.5618 (0.5637)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [120/172]  eta: 0:01:22  lr: 0.000062  loss: 0.5461 (0.5632)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [130/172]  eta: 0:01:06  lr: 0.000062  loss: 0.5609 (0.5640)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [140/172]  eta: 0:00:50  lr: 0.000062  loss: 0.5591 (0.5633)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [150/172]  eta: 0:00:34  lr: 0.000062  loss: 0.5541 (0.5638)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [160/172]  eta: 0:00:19  lr: 0.000062  loss: 0.5653 (0.5636)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439]  [170/172]  eta: 0:00:03  lr: 0.000062  loss: 0.5613 (0.5630)  time: 1.5796  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:439]  [171/172]  eta: 0:00:01  lr: 0.000062  loss: 0.5613 (0.5631)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:439] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000062  loss: 0.5613 (0.5631)\n",
      "Valid: [epoch:439]  [ 0/14]  eta: 0:00:04  loss: 0.5690 (0.5690)  time: 0.3565  data: 0.3392  max mem: 20571\n",
      "Valid: [epoch:439]  [13/14]  eta: 0:00:00  loss: 0.5384 (0.5450)  time: 0.0399  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:439] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 0.5384 (0.5450)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_439_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.545%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:440]  [  0/172]  eta: 0:08:00  lr: 0.000062  loss: 0.5545 (0.5545)  time: 2.7939  data: 1.2258  max mem: 20571\n",
      "Train: [epoch:440]  [ 10/172]  eta: 0:04:33  lr: 0.000062  loss: 0.5629 (0.5581)  time: 1.6888  data: 0.1115  max mem: 20571\n",
      "Train: [epoch:440]  [ 20/172]  eta: 0:04:08  lr: 0.000062  loss: 0.5545 (0.5589)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:440]  [ 30/172]  eta: 0:03:49  lr: 0.000062  loss: 0.5542 (0.5583)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:440]  [ 40/172]  eta: 0:03:32  lr: 0.000062  loss: 0.5586 (0.5595)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:440]  [ 50/172]  eta: 0:03:15  lr: 0.000062  loss: 0.5658 (0.5625)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:440]  [ 60/172]  eta: 0:02:59  lr: 0.000062  loss: 0.5684 (0.5635)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:440]  [ 70/172]  eta: 0:02:42  lr: 0.000062  loss: 0.5578 (0.5627)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:440]  [ 80/172]  eta: 0:02:26  lr: 0.000062  loss: 0.5604 (0.5624)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:440]  [ 90/172]  eta: 0:02:10  lr: 0.000062  loss: 0.5606 (0.5619)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:440]  [100/172]  eta: 0:01:54  lr: 0.000062  loss: 0.5566 (0.5626)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:440]  [110/172]  eta: 0:01:38  lr: 0.000062  loss: 0.5514 (0.5626)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:440]  [120/172]  eta: 0:01:22  lr: 0.000062  loss: 0.5502 (0.5630)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:440]  [130/172]  eta: 0:01:06  lr: 0.000062  loss: 0.5881 (0.5646)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:440]  [140/172]  eta: 0:00:50  lr: 0.000062  loss: 0.5679 (0.5643)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:440]  [150/172]  eta: 0:00:34  lr: 0.000062  loss: 0.5631 (0.5655)  time: 1.5773  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:440]  [160/172]  eta: 0:00:19  lr: 0.000062  loss: 0.5592 (0.5651)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:440]  [170/172]  eta: 0:00:03  lr: 0.000062  loss: 0.5533 (0.5650)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:440]  [171/172]  eta: 0:00:01  lr: 0.000062  loss: 0.5533 (0.5651)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:440] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000062  loss: 0.5533 (0.5651)\n",
      "Valid: [epoch:440]  [ 0/14]  eta: 0:00:04  loss: 0.5087 (0.5087)  time: 0.2910  data: 0.2762  max mem: 20571\n",
      "Valid: [epoch:440]  [13/14]  eta: 0:00:00  loss: 0.5208 (0.5289)  time: 0.0500  data: 0.0350  max mem: 20571\n",
      "Valid: [epoch:440] Total time: 0:00:00 (0.0548 s / it)\n",
      "Averaged stats: loss: 0.5208 (0.5289)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_440_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.529%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:441]  [  0/172]  eta: 0:07:12  lr: 0.000062  loss: 0.6190 (0.6190)  time: 2.5166  data: 0.9414  max mem: 20571\n",
      "Train: [epoch:441]  [ 10/172]  eta: 0:04:28  lr: 0.000062  loss: 0.5696 (0.5739)  time: 1.6597  data: 0.0857  max mem: 20571\n",
      "Train: [epoch:441]  [ 20/172]  eta: 0:04:06  lr: 0.000062  loss: 0.5694 (0.5749)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [ 30/172]  eta: 0:03:48  lr: 0.000062  loss: 0.5622 (0.5731)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [ 40/172]  eta: 0:03:31  lr: 0.000062  loss: 0.5551 (0.5721)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [ 50/172]  eta: 0:03:14  lr: 0.000062  loss: 0.5551 (0.5702)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [ 60/172]  eta: 0:02:58  lr: 0.000062  loss: 0.5623 (0.5691)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:441]  [ 70/172]  eta: 0:02:42  lr: 0.000062  loss: 0.5604 (0.5689)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:441]  [ 80/172]  eta: 0:02:26  lr: 0.000062  loss: 0.5578 (0.5694)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:441]  [ 90/172]  eta: 0:02:10  lr: 0.000062  loss: 0.5579 (0.5665)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [100/172]  eta: 0:01:54  lr: 0.000062  loss: 0.5606 (0.5681)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [110/172]  eta: 0:01:38  lr: 0.000062  loss: 0.5582 (0.5675)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [120/172]  eta: 0:01:22  lr: 0.000062  loss: 0.5547 (0.5655)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [130/172]  eta: 0:01:06  lr: 0.000062  loss: 0.5596 (0.5647)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [140/172]  eta: 0:00:50  lr: 0.000062  loss: 0.5588 (0.5641)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [150/172]  eta: 0:00:34  lr: 0.000062  loss: 0.5515 (0.5638)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [160/172]  eta: 0:00:19  lr: 0.000062  loss: 0.5636 (0.5642)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [170/172]  eta: 0:00:03  lr: 0.000062  loss: 0.5629 (0.5641)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441]  [171/172]  eta: 0:00:01  lr: 0.000062  loss: 0.5605 (0.5641)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:441] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000062  loss: 0.5605 (0.5641)\n",
      "Valid: [epoch:441]  [ 0/14]  eta: 0:00:04  loss: 0.5623 (0.5623)  time: 0.3177  data: 0.3011  max mem: 20571\n",
      "Valid: [epoch:441]  [13/14]  eta: 0:00:00  loss: 0.5314 (0.5387)  time: 0.0368  data: 0.0216  max mem: 20571\n",
      "Valid: [epoch:441] Total time: 0:00:00 (0.0417 s / it)\n",
      "Averaged stats: loss: 0.5314 (0.5387)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_441_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.539%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:442]  [  0/172]  eta: 0:07:38  lr: 0.000062  loss: 0.5781 (0.5781)  time: 2.6646  data: 1.0957  max mem: 20571\n",
      "Train: [epoch:442]  [ 10/172]  eta: 0:04:31  lr: 0.000062  loss: 0.5654 (0.5602)  time: 1.6783  data: 0.0997  max mem: 20571\n",
      "Train: [epoch:442]  [ 20/172]  eta: 0:04:08  lr: 0.000062  loss: 0.5632 (0.5621)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [ 30/172]  eta: 0:03:49  lr: 0.000062  loss: 0.5569 (0.5642)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [ 40/172]  eta: 0:03:32  lr: 0.000062  loss: 0.5641 (0.5658)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [ 50/172]  eta: 0:03:15  lr: 0.000062  loss: 0.5740 (0.5680)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [ 60/172]  eta: 0:02:59  lr: 0.000062  loss: 0.5561 (0.5665)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [ 70/172]  eta: 0:02:42  lr: 0.000062  loss: 0.5512 (0.5668)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [ 80/172]  eta: 0:02:26  lr: 0.000062  loss: 0.5650 (0.5665)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [ 90/172]  eta: 0:02:10  lr: 0.000062  loss: 0.5697 (0.5667)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [100/172]  eta: 0:01:54  lr: 0.000062  loss: 0.5656 (0.5669)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [110/172]  eta: 0:01:38  lr: 0.000062  loss: 0.5635 (0.5674)  time: 1.5819  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:442]  [120/172]  eta: 0:01:22  lr: 0.000062  loss: 0.5563 (0.5665)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [130/172]  eta: 0:01:06  lr: 0.000062  loss: 0.5546 (0.5660)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [140/172]  eta: 0:00:50  lr: 0.000062  loss: 0.5551 (0.5652)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [150/172]  eta: 0:00:34  lr: 0.000062  loss: 0.5646 (0.5656)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [160/172]  eta: 0:00:19  lr: 0.000062  loss: 0.5664 (0.5656)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [170/172]  eta: 0:00:03  lr: 0.000062  loss: 0.5727 (0.5656)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442]  [171/172]  eta: 0:00:01  lr: 0.000062  loss: 0.5702 (0.5655)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:442] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000062  loss: 0.5702 (0.5655)\n",
      "Valid: [epoch:442]  [ 0/14]  eta: 0:00:04  loss: 0.5736 (0.5736)  time: 0.2915  data: 0.2750  max mem: 20571\n",
      "Valid: [epoch:442]  [13/14]  eta: 0:00:00  loss: 0.5417 (0.5501)  time: 0.0383  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:442] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.5417 (0.5501)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_442_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.550%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:443]  [  0/172]  eta: 0:07:40  lr: 0.000062  loss: 0.5899 (0.5899)  time: 2.6797  data: 1.1035  max mem: 20571\n",
      "Train: [epoch:443]  [ 10/172]  eta: 0:04:31  lr: 0.000062  loss: 0.5569 (0.5645)  time: 1.6771  data: 0.1004  max mem: 20571\n",
      "Train: [epoch:443]  [ 20/172]  eta: 0:04:07  lr: 0.000062  loss: 0.5709 (0.5725)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [ 30/172]  eta: 0:03:49  lr: 0.000062  loss: 0.5709 (0.5719)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [ 40/172]  eta: 0:03:31  lr: 0.000062  loss: 0.5675 (0.5700)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [ 50/172]  eta: 0:03:15  lr: 0.000062  loss: 0.5675 (0.5664)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [ 60/172]  eta: 0:02:58  lr: 0.000062  loss: 0.5569 (0.5664)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [ 70/172]  eta: 0:02:42  lr: 0.000062  loss: 0.5629 (0.5673)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [ 80/172]  eta: 0:02:26  lr: 0.000062  loss: 0.5675 (0.5672)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [ 90/172]  eta: 0:02:10  lr: 0.000062  loss: 0.5675 (0.5678)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [100/172]  eta: 0:01:54  lr: 0.000062  loss: 0.5704 (0.5685)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [110/172]  eta: 0:01:38  lr: 0.000062  loss: 0.5646 (0.5673)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [120/172]  eta: 0:01:22  lr: 0.000062  loss: 0.5669 (0.5689)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [130/172]  eta: 0:01:06  lr: 0.000062  loss: 0.5697 (0.5684)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [140/172]  eta: 0:00:50  lr: 0.000062  loss: 0.5647 (0.5678)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [150/172]  eta: 0:00:34  lr: 0.000062  loss: 0.5669 (0.5690)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [160/172]  eta: 0:00:19  lr: 0.000062  loss: 0.5856 (0.5691)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [170/172]  eta: 0:00:03  lr: 0.000062  loss: 0.5565 (0.5681)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443]  [171/172]  eta: 0:00:01  lr: 0.000062  loss: 0.5619 (0.5686)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:443] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000062  loss: 0.5619 (0.5686)\n",
      "Valid: [epoch:443]  [ 0/14]  eta: 0:00:04  loss: 0.5619 (0.5619)  time: 0.2857  data: 0.2703  max mem: 20571\n",
      "Valid: [epoch:443]  [13/14]  eta: 0:00:00  loss: 0.5319 (0.5386)  time: 0.0376  data: 0.0223  max mem: 20571\n",
      "Valid: [epoch:443] Total time: 0:00:00 (0.0461 s / it)\n",
      "Averaged stats: loss: 0.5319 (0.5386)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_443_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.539%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:444]  [  0/172]  eta: 0:07:29  lr: 0.000062  loss: 0.5765 (0.5765)  time: 2.6120  data: 1.0441  max mem: 20571\n",
      "Train: [epoch:444]  [ 10/172]  eta: 0:04:30  lr: 0.000062  loss: 0.5698 (0.5702)  time: 1.6711  data: 0.0951  max mem: 20571\n",
      "Train: [epoch:444]  [ 20/172]  eta: 0:04:07  lr: 0.000062  loss: 0.5698 (0.5724)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [ 30/172]  eta: 0:03:48  lr: 0.000062  loss: 0.5755 (0.5712)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [ 40/172]  eta: 0:03:31  lr: 0.000062  loss: 0.5565 (0.5681)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [ 50/172]  eta: 0:03:14  lr: 0.000062  loss: 0.5563 (0.5706)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [ 60/172]  eta: 0:02:58  lr: 0.000062  loss: 0.5552 (0.5685)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [ 70/172]  eta: 0:02:42  lr: 0.000062  loss: 0.5476 (0.5669)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [ 80/172]  eta: 0:02:26  lr: 0.000062  loss: 0.5609 (0.5681)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [ 90/172]  eta: 0:02:10  lr: 0.000062  loss: 0.5651 (0.5688)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [100/172]  eta: 0:01:54  lr: 0.000062  loss: 0.5651 (0.5694)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [110/172]  eta: 0:01:38  lr: 0.000062  loss: 0.5725 (0.5713)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [120/172]  eta: 0:01:22  lr: 0.000062  loss: 0.5860 (0.5721)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [130/172]  eta: 0:01:06  lr: 0.000062  loss: 0.5928 (0.5741)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [140/172]  eta: 0:00:50  lr: 0.000062  loss: 0.5814 (0.5730)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [150/172]  eta: 0:00:34  lr: 0.000062  loss: 0.5683 (0.5731)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [160/172]  eta: 0:00:19  lr: 0.000062  loss: 0.5556 (0.5720)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [170/172]  eta: 0:00:03  lr: 0.000062  loss: 0.5446 (0.5714)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444]  [171/172]  eta: 0:00:01  lr: 0.000062  loss: 0.5505 (0.5715)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:444] Total time: 0:04:32 (1.5838 s / it)\n",
      "Averaged stats: lr: 0.000062  loss: 0.5505 (0.5715)\n",
      "Valid: [epoch:444]  [ 0/14]  eta: 0:00:04  loss: 0.5118 (0.5118)  time: 0.2935  data: 0.2765  max mem: 20571\n",
      "Valid: [epoch:444]  [13/14]  eta: 0:00:00  loss: 0.5256 (0.5321)  time: 0.0555  data: 0.0403  max mem: 20571\n",
      "Valid: [epoch:444] Total time: 0:00:00 (0.0601 s / it)\n",
      "Averaged stats: loss: 0.5256 (0.5321)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_444_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.532%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:445]  [  0/172]  eta: 0:07:47  lr: 0.000062  loss: 0.4927 (0.4927)  time: 2.7182  data: 1.1422  max mem: 20571\n",
      "Train: [epoch:445]  [ 10/172]  eta: 0:04:32  lr: 0.000062  loss: 0.5625 (0.5591)  time: 1.6795  data: 0.1039  max mem: 20571\n",
      "Train: [epoch:445]  [ 20/172]  eta: 0:04:07  lr: 0.000062  loss: 0.5732 (0.5627)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [ 30/172]  eta: 0:03:49  lr: 0.000062  loss: 0.5747 (0.5659)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [ 40/172]  eta: 0:03:31  lr: 0.000062  loss: 0.5702 (0.5650)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [ 50/172]  eta: 0:03:15  lr: 0.000062  loss: 0.5657 (0.5637)  time: 1.5808  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:445]  [ 60/172]  eta: 0:02:58  lr: 0.000062  loss: 0.5594 (0.5636)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [ 70/172]  eta: 0:02:42  lr: 0.000062  loss: 0.5580 (0.5638)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [ 80/172]  eta: 0:02:26  lr: 0.000062  loss: 0.5602 (0.5632)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [ 90/172]  eta: 0:02:10  lr: 0.000062  loss: 0.5602 (0.5650)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [100/172]  eta: 0:01:54  lr: 0.000062  loss: 0.5735 (0.5656)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [110/172]  eta: 0:01:38  lr: 0.000062  loss: 0.5735 (0.5664)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [120/172]  eta: 0:01:22  lr: 0.000062  loss: 0.5715 (0.5669)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [130/172]  eta: 0:01:06  lr: 0.000062  loss: 0.5738 (0.5683)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [140/172]  eta: 0:00:50  lr: 0.000062  loss: 0.5738 (0.5681)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [150/172]  eta: 0:00:34  lr: 0.000062  loss: 0.5676 (0.5676)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [160/172]  eta: 0:00:19  lr: 0.000062  loss: 0.5676 (0.5695)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [170/172]  eta: 0:00:03  lr: 0.000062  loss: 0.5680 (0.5697)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445]  [171/172]  eta: 0:00:01  lr: 0.000062  loss: 0.5680 (0.5695)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:445] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000062  loss: 0.5680 (0.5695)\n",
      "Valid: [epoch:445]  [ 0/14]  eta: 0:00:03  loss: 0.5095 (0.5095)  time: 0.2815  data: 0.2668  max mem: 20571\n",
      "Valid: [epoch:445]  [13/14]  eta: 0:00:00  loss: 0.5241 (0.5303)  time: 0.0395  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:445] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.5241 (0.5303)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_445_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.530%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:446]  [  0/172]  eta: 0:07:17  lr: 0.000062  loss: 0.5607 (0.5607)  time: 2.5424  data: 0.9739  max mem: 20571\n",
      "Train: [epoch:446]  [ 10/172]  eta: 0:04:29  lr: 0.000062  loss: 0.5761 (0.5733)  time: 1.6658  data: 0.0887  max mem: 20571\n",
      "Train: [epoch:446]  [ 20/172]  eta: 0:04:07  lr: 0.000062  loss: 0.5761 (0.5733)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [ 30/172]  eta: 0:03:48  lr: 0.000062  loss: 0.5520 (0.5682)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [ 40/172]  eta: 0:03:31  lr: 0.000062  loss: 0.5504 (0.5726)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [ 50/172]  eta: 0:03:15  lr: 0.000062  loss: 0.5697 (0.5733)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [ 60/172]  eta: 0:02:58  lr: 0.000062  loss: 0.5603 (0.5720)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [ 70/172]  eta: 0:02:42  lr: 0.000062  loss: 0.5576 (0.5708)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [ 80/172]  eta: 0:02:26  lr: 0.000062  loss: 0.5664 (0.5712)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [ 90/172]  eta: 0:02:10  lr: 0.000062  loss: 0.5664 (0.5702)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [100/172]  eta: 0:01:54  lr: 0.000062  loss: 0.5588 (0.5691)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [110/172]  eta: 0:01:38  lr: 0.000062  loss: 0.5608 (0.5702)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [120/172]  eta: 0:01:22  lr: 0.000062  loss: 0.5789 (0.5710)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [130/172]  eta: 0:01:06  lr: 0.000062  loss: 0.5612 (0.5700)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [140/172]  eta: 0:00:50  lr: 0.000062  loss: 0.5613 (0.5694)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [150/172]  eta: 0:00:34  lr: 0.000062  loss: 0.5673 (0.5694)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [160/172]  eta: 0:00:19  lr: 0.000062  loss: 0.5580 (0.5690)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [170/172]  eta: 0:00:03  lr: 0.000062  loss: 0.5580 (0.5684)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446]  [171/172]  eta: 0:00:01  lr: 0.000062  loss: 0.5580 (0.5682)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:446] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000062  loss: 0.5580 (0.5682)\n",
      "Valid: [epoch:446]  [ 0/14]  eta: 0:00:04  loss: 0.5852 (0.5852)  time: 0.3162  data: 0.2993  max mem: 20571\n",
      "Valid: [epoch:446]  [13/14]  eta: 0:00:00  loss: 0.5429 (0.5492)  time: 0.0374  data: 0.0223  max mem: 20571\n",
      "Valid: [epoch:446] Total time: 0:00:00 (0.0424 s / it)\n",
      "Averaged stats: loss: 0.5429 (0.5492)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_446_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.549%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:447]  [  0/172]  eta: 0:07:45  lr: 0.000062  loss: 0.5759 (0.5759)  time: 2.7084  data: 1.1336  max mem: 20571\n",
      "Train: [epoch:447]  [ 10/172]  eta: 0:04:31  lr: 0.000062  loss: 0.5759 (0.5713)  time: 1.6775  data: 0.1031  max mem: 20571\n",
      "Train: [epoch:447]  [ 20/172]  eta: 0:04:07  lr: 0.000062  loss: 0.5518 (0.5665)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [ 30/172]  eta: 0:03:49  lr: 0.000062  loss: 0.5540 (0.5669)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [ 40/172]  eta: 0:03:31  lr: 0.000062  loss: 0.5643 (0.5683)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [ 50/172]  eta: 0:03:15  lr: 0.000062  loss: 0.5626 (0.5691)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [ 60/172]  eta: 0:02:58  lr: 0.000062  loss: 0.5535 (0.5685)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [ 70/172]  eta: 0:02:42  lr: 0.000062  loss: 0.5641 (0.5691)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [ 80/172]  eta: 0:02:26  lr: 0.000062  loss: 0.5706 (0.5691)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [ 90/172]  eta: 0:02:10  lr: 0.000062  loss: 0.5649 (0.5684)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [100/172]  eta: 0:01:54  lr: 0.000062  loss: 0.5624 (0.5682)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [110/172]  eta: 0:01:38  lr: 0.000062  loss: 0.5569 (0.5678)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [120/172]  eta: 0:01:22  lr: 0.000062  loss: 0.5732 (0.5686)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [130/172]  eta: 0:01:06  lr: 0.000062  loss: 0.5756 (0.5696)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [140/172]  eta: 0:00:50  lr: 0.000062  loss: 0.5631 (0.5686)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [150/172]  eta: 0:00:34  lr: 0.000062  loss: 0.5631 (0.5697)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [160/172]  eta: 0:00:19  lr: 0.000062  loss: 0.5717 (0.5691)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [170/172]  eta: 0:00:03  lr: 0.000062  loss: 0.5715 (0.5689)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447]  [171/172]  eta: 0:00:01  lr: 0.000062  loss: 0.5717 (0.5689)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:447] Total time: 0:04:32 (1.5856 s / it)\n",
      "Averaged stats: lr: 0.000062  loss: 0.5717 (0.5689)\n",
      "Valid: [epoch:447]  [ 0/14]  eta: 0:00:04  loss: 0.5825 (0.5825)  time: 0.3183  data: 0.3000  max mem: 20571\n",
      "Valid: [epoch:447]  [13/14]  eta: 0:00:00  loss: 0.5441 (0.5509)  time: 0.0375  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:447] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.5441 (0.5509)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_447_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.551%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:448]  [  0/172]  eta: 0:08:09  lr: 0.000061  loss: 0.5058 (0.5058)  time: 2.8445  data: 1.2800  max mem: 20571\n",
      "Train: [epoch:448]  [ 10/172]  eta: 0:04:33  lr: 0.000061  loss: 0.5464 (0.5540)  time: 1.6905  data: 0.1165  max mem: 20571\n",
      "Train: [epoch:448]  [ 20/172]  eta: 0:04:08  lr: 0.000061  loss: 0.5734 (0.5727)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [ 30/172]  eta: 0:03:49  lr: 0.000061  loss: 0.5789 (0.5713)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [ 40/172]  eta: 0:03:32  lr: 0.000061  loss: 0.5789 (0.5742)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [ 50/172]  eta: 0:03:15  lr: 0.000061  loss: 0.5682 (0.5691)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [ 60/172]  eta: 0:02:58  lr: 0.000061  loss: 0.5646 (0.5734)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [ 70/172]  eta: 0:02:42  lr: 0.000061  loss: 0.5821 (0.5742)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [ 80/172]  eta: 0:02:26  lr: 0.000061  loss: 0.5818 (0.5743)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [ 90/172]  eta: 0:02:10  lr: 0.000061  loss: 0.5704 (0.5732)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [100/172]  eta: 0:01:54  lr: 0.000061  loss: 0.5681 (0.5724)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [110/172]  eta: 0:01:38  lr: 0.000061  loss: 0.5649 (0.5722)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [120/172]  eta: 0:01:22  lr: 0.000061  loss: 0.5649 (0.5722)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [130/172]  eta: 0:01:06  lr: 0.000061  loss: 0.5655 (0.5727)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [140/172]  eta: 0:00:50  lr: 0.000061  loss: 0.5754 (0.5728)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [150/172]  eta: 0:00:34  lr: 0.000061  loss: 0.5754 (0.5735)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [160/172]  eta: 0:00:19  lr: 0.000061  loss: 0.5635 (0.5717)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [170/172]  eta: 0:00:03  lr: 0.000061  loss: 0.5447 (0.5710)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448]  [171/172]  eta: 0:00:01  lr: 0.000061  loss: 0.5447 (0.5712)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:448] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000061  loss: 0.5447 (0.5712)\n",
      "Valid: [epoch:448]  [ 0/14]  eta: 0:00:04  loss: 0.5159 (0.5159)  time: 0.3342  data: 0.3175  max mem: 20571\n",
      "Valid: [epoch:448]  [13/14]  eta: 0:00:00  loss: 0.5284 (0.5352)  time: 0.0392  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:448] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.5284 (0.5352)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_448_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.535%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:449]  [  0/172]  eta: 0:07:45  lr: 0.000061  loss: 0.5365 (0.5365)  time: 2.7074  data: 1.1274  max mem: 20571\n",
      "Train: [epoch:449]  [ 10/172]  eta: 0:04:31  lr: 0.000061  loss: 0.5510 (0.5711)  time: 1.6783  data: 0.1026  max mem: 20571\n",
      "Train: [epoch:449]  [ 20/172]  eta: 0:04:07  lr: 0.000061  loss: 0.5667 (0.5674)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [ 30/172]  eta: 0:03:49  lr: 0.000061  loss: 0.5667 (0.5689)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [ 40/172]  eta: 0:03:31  lr: 0.000061  loss: 0.5641 (0.5685)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [ 50/172]  eta: 0:03:15  lr: 0.000061  loss: 0.5641 (0.5678)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [ 60/172]  eta: 0:02:58  lr: 0.000061  loss: 0.5628 (0.5673)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [ 70/172]  eta: 0:02:42  lr: 0.000061  loss: 0.5556 (0.5660)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [ 80/172]  eta: 0:02:26  lr: 0.000061  loss: 0.5502 (0.5646)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [ 90/172]  eta: 0:02:10  lr: 0.000061  loss: 0.5661 (0.5666)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [100/172]  eta: 0:01:54  lr: 0.000061  loss: 0.5684 (0.5670)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [110/172]  eta: 0:01:38  lr: 0.000061  loss: 0.5684 (0.5672)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [120/172]  eta: 0:01:22  lr: 0.000061  loss: 0.5697 (0.5680)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [130/172]  eta: 0:01:06  lr: 0.000061  loss: 0.5683 (0.5675)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [140/172]  eta: 0:00:50  lr: 0.000061  loss: 0.5513 (0.5663)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [150/172]  eta: 0:00:34  lr: 0.000061  loss: 0.5631 (0.5687)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [160/172]  eta: 0:00:19  lr: 0.000061  loss: 0.5810 (0.5685)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [170/172]  eta: 0:00:03  lr: 0.000061  loss: 0.5810 (0.5698)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449]  [171/172]  eta: 0:00:01  lr: 0.000061  loss: 0.5714 (0.5696)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:449] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000061  loss: 0.5714 (0.5696)\n",
      "Valid: [epoch:449]  [ 0/14]  eta: 0:00:04  loss: 0.5193 (0.5193)  time: 0.2872  data: 0.2709  max mem: 20571\n",
      "Valid: [epoch:449]  [13/14]  eta: 0:00:00  loss: 0.5494 (0.5537)  time: 0.0384  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:449] Total time: 0:00:00 (0.0470 s / it)\n",
      "Averaged stats: loss: 0.5494 (0.5537)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_449_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.554%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:450]  [  0/172]  eta: 0:07:46  lr: 0.000061  loss: 0.5330 (0.5330)  time: 2.7100  data: 1.1432  max mem: 20571\n",
      "Train: [epoch:450]  [ 10/172]  eta: 0:04:32  lr: 0.000061  loss: 0.5552 (0.5590)  time: 1.6804  data: 0.1040  max mem: 20571\n",
      "Train: [epoch:450]  [ 20/172]  eta: 0:04:08  lr: 0.000061  loss: 0.5552 (0.5558)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [ 30/172]  eta: 0:03:49  lr: 0.000061  loss: 0.5661 (0.5612)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [ 40/172]  eta: 0:03:32  lr: 0.000061  loss: 0.5678 (0.5602)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [ 50/172]  eta: 0:03:15  lr: 0.000061  loss: 0.5679 (0.5643)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [ 60/172]  eta: 0:02:59  lr: 0.000061  loss: 0.5684 (0.5641)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [ 70/172]  eta: 0:02:42  lr: 0.000061  loss: 0.5584 (0.5640)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [ 80/172]  eta: 0:02:26  lr: 0.000061  loss: 0.5703 (0.5653)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [ 90/172]  eta: 0:02:10  lr: 0.000061  loss: 0.5656 (0.5650)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [100/172]  eta: 0:01:54  lr: 0.000061  loss: 0.5667 (0.5648)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [110/172]  eta: 0:01:38  lr: 0.000061  loss: 0.5675 (0.5659)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [120/172]  eta: 0:01:22  lr: 0.000061  loss: 0.5807 (0.5685)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [130/172]  eta: 0:01:06  lr: 0.000061  loss: 0.5920 (0.5691)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [140/172]  eta: 0:00:50  lr: 0.000061  loss: 0.5724 (0.5691)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [150/172]  eta: 0:00:34  lr: 0.000061  loss: 0.5756 (0.5699)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [160/172]  eta: 0:00:19  lr: 0.000061  loss: 0.5831 (0.5697)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450]  [170/172]  eta: 0:00:03  lr: 0.000061  loss: 0.5758 (0.5699)  time: 1.5836  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:450]  [171/172]  eta: 0:00:01  lr: 0.000061  loss: 0.5758 (0.5699)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:450] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000061  loss: 0.5758 (0.5699)\n",
      "Valid: [epoch:450]  [ 0/14]  eta: 0:00:04  loss: 0.5280 (0.5280)  time: 0.3329  data: 0.3182  max mem: 20571\n",
      "Valid: [epoch:450]  [13/14]  eta: 0:00:00  loss: 0.5336 (0.5408)  time: 0.0398  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:450] Total time: 0:00:00 (0.0448 s / it)\n",
      "Averaged stats: loss: 0.5336 (0.5408)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_450_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.541%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:451]  [  0/172]  eta: 0:07:15  lr: 0.000061  loss: 0.5879 (0.5879)  time: 2.5319  data: 0.9513  max mem: 20571\n",
      "Train: [epoch:451]  [ 10/172]  eta: 0:04:29  lr: 0.000061  loss: 0.5758 (0.5642)  time: 1.6658  data: 0.0866  max mem: 20571\n",
      "Train: [epoch:451]  [ 20/172]  eta: 0:04:07  lr: 0.000061  loss: 0.5723 (0.5700)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [ 30/172]  eta: 0:03:48  lr: 0.000061  loss: 0.5723 (0.5710)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [ 40/172]  eta: 0:03:31  lr: 0.000061  loss: 0.5673 (0.5723)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [ 50/172]  eta: 0:03:15  lr: 0.000061  loss: 0.5673 (0.5694)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [ 60/172]  eta: 0:02:58  lr: 0.000061  loss: 0.5690 (0.5697)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [ 70/172]  eta: 0:02:42  lr: 0.000061  loss: 0.5660 (0.5700)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [ 80/172]  eta: 0:02:26  lr: 0.000061  loss: 0.5658 (0.5693)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [ 90/172]  eta: 0:02:10  lr: 0.000061  loss: 0.5658 (0.5693)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [100/172]  eta: 0:01:54  lr: 0.000061  loss: 0.5592 (0.5690)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [110/172]  eta: 0:01:38  lr: 0.000061  loss: 0.5552 (0.5681)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [120/172]  eta: 0:01:22  lr: 0.000061  loss: 0.5653 (0.5692)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [130/172]  eta: 0:01:06  lr: 0.000061  loss: 0.5697 (0.5692)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [140/172]  eta: 0:00:50  lr: 0.000061  loss: 0.5673 (0.5693)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [150/172]  eta: 0:00:34  lr: 0.000061  loss: 0.5674 (0.5693)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [160/172]  eta: 0:00:19  lr: 0.000061  loss: 0.5743 (0.5705)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [170/172]  eta: 0:00:03  lr: 0.000061  loss: 0.5551 (0.5697)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451]  [171/172]  eta: 0:00:01  lr: 0.000061  loss: 0.5551 (0.5697)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:451] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000061  loss: 0.5551 (0.5697)\n",
      "Valid: [epoch:451]  [ 0/14]  eta: 0:00:04  loss: 0.5883 (0.5883)  time: 0.3137  data: 0.2988  max mem: 20571\n",
      "Valid: [epoch:451]  [13/14]  eta: 0:00:00  loss: 0.5560 (0.5613)  time: 0.0379  data: 0.0229  max mem: 20571\n",
      "Valid: [epoch:451] Total time: 0:00:00 (0.0432 s / it)\n",
      "Averaged stats: loss: 0.5560 (0.5613)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_451_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.561%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:452]  [  0/172]  eta: 0:07:21  lr: 0.000061  loss: 0.6260 (0.6260)  time: 2.5679  data: 0.9998  max mem: 20571\n",
      "Train: [epoch:452]  [ 10/172]  eta: 0:04:30  lr: 0.000061  loss: 0.5629 (0.5693)  time: 1.6721  data: 0.0910  max mem: 20571\n",
      "Train: [epoch:452]  [ 20/172]  eta: 0:04:07  lr: 0.000061  loss: 0.5629 (0.5704)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [ 30/172]  eta: 0:03:49  lr: 0.000061  loss: 0.5675 (0.5695)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [ 40/172]  eta: 0:03:32  lr: 0.000061  loss: 0.5630 (0.5666)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [ 50/172]  eta: 0:03:15  lr: 0.000061  loss: 0.5578 (0.5660)  time: 1.5856  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:452]  [ 60/172]  eta: 0:02:59  lr: 0.000061  loss: 0.5720 (0.5673)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [ 70/172]  eta: 0:02:43  lr: 0.000061  loss: 0.5779 (0.5688)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [ 80/172]  eta: 0:02:26  lr: 0.000061  loss: 0.5798 (0.5706)  time: 1.5849  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:452]  [ 90/172]  eta: 0:02:10  lr: 0.000061  loss: 0.5702 (0.5714)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [100/172]  eta: 0:01:54  lr: 0.000061  loss: 0.5715 (0.5720)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [110/172]  eta: 0:01:38  lr: 0.000061  loss: 0.5635 (0.5713)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [120/172]  eta: 0:01:22  lr: 0.000061  loss: 0.5607 (0.5716)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [130/172]  eta: 0:01:06  lr: 0.000061  loss: 0.5790 (0.5720)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [140/172]  eta: 0:00:50  lr: 0.000061  loss: 0.5772 (0.5722)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [150/172]  eta: 0:00:34  lr: 0.000061  loss: 0.5745 (0.5718)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [160/172]  eta: 0:00:19  lr: 0.000061  loss: 0.5637 (0.5718)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [170/172]  eta: 0:00:03  lr: 0.000061  loss: 0.5772 (0.5722)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452]  [171/172]  eta: 0:00:01  lr: 0.000061  loss: 0.5772 (0.5721)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:452] Total time: 0:04:33 (1.5908 s / it)\n",
      "Averaged stats: lr: 0.000061  loss: 0.5772 (0.5721)\n",
      "Valid: [epoch:452]  [ 0/14]  eta: 0:00:05  loss: 0.5689 (0.5689)  time: 0.3579  data: 0.3393  max mem: 20571\n",
      "Valid: [epoch:452]  [13/14]  eta: 0:00:00  loss: 0.5332 (0.5386)  time: 0.0406  data: 0.0254  max mem: 20571\n",
      "Valid: [epoch:452] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.5332 (0.5386)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_452_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.539%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:453]  [  0/172]  eta: 0:07:29  lr: 0.000061  loss: 0.5246 (0.5246)  time: 2.6105  data: 1.0337  max mem: 20571\n",
      "Train: [epoch:453]  [ 10/172]  eta: 0:04:31  lr: 0.000061  loss: 0.5473 (0.5606)  time: 1.6734  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:453]  [ 20/172]  eta: 0:04:07  lr: 0.000061  loss: 0.5800 (0.5740)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [ 30/172]  eta: 0:03:49  lr: 0.000061  loss: 0.5846 (0.5766)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [ 40/172]  eta: 0:03:32  lr: 0.000061  loss: 0.5835 (0.5790)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [ 50/172]  eta: 0:03:15  lr: 0.000061  loss: 0.5835 (0.5799)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [ 60/172]  eta: 0:02:59  lr: 0.000061  loss: 0.5763 (0.5780)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [ 70/172]  eta: 0:02:42  lr: 0.000061  loss: 0.5734 (0.5775)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [ 80/172]  eta: 0:02:26  lr: 0.000061  loss: 0.5834 (0.5791)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [ 90/172]  eta: 0:02:10  lr: 0.000061  loss: 0.5782 (0.5781)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [100/172]  eta: 0:01:54  lr: 0.000061  loss: 0.5614 (0.5775)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [110/172]  eta: 0:01:38  lr: 0.000061  loss: 0.5654 (0.5767)  time: 1.5846  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:453]  [120/172]  eta: 0:01:22  lr: 0.000061  loss: 0.5651 (0.5757)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [130/172]  eta: 0:01:06  lr: 0.000061  loss: 0.5595 (0.5747)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [140/172]  eta: 0:00:50  lr: 0.000061  loss: 0.5649 (0.5744)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [150/172]  eta: 0:00:34  lr: 0.000061  loss: 0.5653 (0.5737)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [160/172]  eta: 0:00:19  lr: 0.000061  loss: 0.5517 (0.5727)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [170/172]  eta: 0:00:03  lr: 0.000061  loss: 0.5557 (0.5732)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453]  [171/172]  eta: 0:00:01  lr: 0.000061  loss: 0.5679 (0.5733)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:453] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000061  loss: 0.5679 (0.5733)\n",
      "Valid: [epoch:453]  [ 0/14]  eta: 0:00:06  loss: 0.5782 (0.5782)  time: 0.4418  data: 0.4269  max mem: 20571\n",
      "Valid: [epoch:453]  [13/14]  eta: 0:00:00  loss: 0.5440 (0.5492)  time: 0.0468  data: 0.0320  max mem: 20571\n",
      "Valid: [epoch:453] Total time: 0:00:00 (0.0527 s / it)\n",
      "Averaged stats: loss: 0.5440 (0.5492)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_453_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.549%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:454]  [  0/172]  eta: 0:07:50  lr: 0.000061  loss: 0.5688 (0.5688)  time: 2.7379  data: 1.1657  max mem: 20571\n",
      "Train: [epoch:454]  [ 10/172]  eta: 0:04:33  lr: 0.000061  loss: 0.5688 (0.5643)  time: 1.6853  data: 0.1061  max mem: 20571\n",
      "Train: [epoch:454]  [ 20/172]  eta: 0:04:08  lr: 0.000061  loss: 0.5615 (0.5651)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [ 30/172]  eta: 0:03:49  lr: 0.000061  loss: 0.5572 (0.5652)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [ 40/172]  eta: 0:03:32  lr: 0.000061  loss: 0.5576 (0.5626)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [ 50/172]  eta: 0:03:15  lr: 0.000061  loss: 0.5663 (0.5677)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [ 60/172]  eta: 0:02:59  lr: 0.000061  loss: 0.5778 (0.5684)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [ 70/172]  eta: 0:02:42  lr: 0.000061  loss: 0.5773 (0.5706)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [ 80/172]  eta: 0:02:26  lr: 0.000061  loss: 0.5720 (0.5715)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [ 90/172]  eta: 0:02:10  lr: 0.000061  loss: 0.5678 (0.5712)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [100/172]  eta: 0:01:54  lr: 0.000061  loss: 0.5723 (0.5722)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [110/172]  eta: 0:01:38  lr: 0.000061  loss: 0.5730 (0.5720)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [120/172]  eta: 0:01:22  lr: 0.000061  loss: 0.5733 (0.5722)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [130/172]  eta: 0:01:06  lr: 0.000061  loss: 0.5675 (0.5718)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [140/172]  eta: 0:00:50  lr: 0.000061  loss: 0.5597 (0.5719)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [150/172]  eta: 0:00:34  lr: 0.000061  loss: 0.5597 (0.5720)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [160/172]  eta: 0:00:19  lr: 0.000061  loss: 0.5790 (0.5725)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [170/172]  eta: 0:00:03  lr: 0.000061  loss: 0.5739 (0.5727)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454]  [171/172]  eta: 0:00:01  lr: 0.000061  loss: 0.5739 (0.5726)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:454] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000061  loss: 0.5739 (0.5726)\n",
      "Valid: [epoch:454]  [ 0/14]  eta: 0:00:03  loss: 0.4926 (0.4926)  time: 0.2791  data: 0.2639  max mem: 20571\n",
      "Valid: [epoch:454]  [13/14]  eta: 0:00:00  loss: 0.5370 (0.5412)  time: 0.0546  data: 0.0399  max mem: 20571\n",
      "Valid: [epoch:454] Total time: 0:00:00 (0.0602 s / it)\n",
      "Averaged stats: loss: 0.5370 (0.5412)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_454_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.541%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:455]  [  0/172]  eta: 0:07:31  lr: 0.000061  loss: 0.5700 (0.5700)  time: 2.6231  data: 1.0472  max mem: 20571\n",
      "Train: [epoch:455]  [ 10/172]  eta: 0:04:30  lr: 0.000061  loss: 0.5651 (0.5636)  time: 1.6719  data: 0.0953  max mem: 20571\n",
      "Train: [epoch:455]  [ 20/172]  eta: 0:04:07  lr: 0.000061  loss: 0.5586 (0.5685)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [ 30/172]  eta: 0:03:48  lr: 0.000061  loss: 0.5860 (0.5705)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [ 40/172]  eta: 0:03:31  lr: 0.000061  loss: 0.5586 (0.5687)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [ 50/172]  eta: 0:03:15  lr: 0.000061  loss: 0.5586 (0.5701)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [ 60/172]  eta: 0:02:58  lr: 0.000061  loss: 0.5710 (0.5705)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [ 70/172]  eta: 0:02:42  lr: 0.000061  loss: 0.5710 (0.5706)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [ 80/172]  eta: 0:02:26  lr: 0.000061  loss: 0.5611 (0.5714)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [ 90/172]  eta: 0:02:10  lr: 0.000061  loss: 0.5579 (0.5713)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [100/172]  eta: 0:01:54  lr: 0.000061  loss: 0.5618 (0.5718)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [110/172]  eta: 0:01:38  lr: 0.000061  loss: 0.5686 (0.5714)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [120/172]  eta: 0:01:22  lr: 0.000061  loss: 0.5866 (0.5730)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [130/172]  eta: 0:01:06  lr: 0.000061  loss: 0.5897 (0.5738)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [140/172]  eta: 0:00:50  lr: 0.000061  loss: 0.5670 (0.5740)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [150/172]  eta: 0:00:34  lr: 0.000061  loss: 0.5670 (0.5745)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [160/172]  eta: 0:00:19  lr: 0.000061  loss: 0.5886 (0.5742)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:455]  [170/172]  eta: 0:00:03  lr: 0.000061  loss: 0.5877 (0.5747)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:455]  [171/172]  eta: 0:00:01  lr: 0.000061  loss: 0.5877 (0.5746)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:455] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000061  loss: 0.5877 (0.5746)\n",
      "Valid: [epoch:455]  [ 0/14]  eta: 0:00:04  loss: 0.5756 (0.5756)  time: 0.3060  data: 0.2887  max mem: 20571\n",
      "Valid: [epoch:455]  [13/14]  eta: 0:00:00  loss: 0.5428 (0.5467)  time: 0.0409  data: 0.0256  max mem: 20571\n",
      "Valid: [epoch:455] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.5428 (0.5467)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_455_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.547%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:456]  [  0/172]  eta: 0:07:39  lr: 0.000061  loss: 0.5548 (0.5548)  time: 2.6698  data: 1.1006  max mem: 20571\n",
      "Train: [epoch:456]  [ 10/172]  eta: 0:04:32  lr: 0.000061  loss: 0.5643 (0.5642)  time: 1.6798  data: 0.1002  max mem: 20571\n",
      "Train: [epoch:456]  [ 20/172]  eta: 0:04:08  lr: 0.000061  loss: 0.5674 (0.5736)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [ 30/172]  eta: 0:03:49  lr: 0.000061  loss: 0.5716 (0.5693)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [ 40/172]  eta: 0:03:32  lr: 0.000061  loss: 0.5711 (0.5720)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [ 50/172]  eta: 0:03:15  lr: 0.000061  loss: 0.5731 (0.5723)  time: 1.5821  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:456]  [ 60/172]  eta: 0:02:59  lr: 0.000061  loss: 0.5821 (0.5753)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [ 70/172]  eta: 0:02:42  lr: 0.000061  loss: 0.5821 (0.5740)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [ 80/172]  eta: 0:02:26  lr: 0.000061  loss: 0.5624 (0.5734)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [ 90/172]  eta: 0:02:10  lr: 0.000061  loss: 0.5621 (0.5727)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [100/172]  eta: 0:01:54  lr: 0.000061  loss: 0.5711 (0.5726)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [110/172]  eta: 0:01:38  lr: 0.000061  loss: 0.5767 (0.5733)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [120/172]  eta: 0:01:22  lr: 0.000061  loss: 0.5808 (0.5760)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [130/172]  eta: 0:01:06  lr: 0.000061  loss: 0.5820 (0.5764)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [140/172]  eta: 0:00:50  lr: 0.000061  loss: 0.5808 (0.5767)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [150/172]  eta: 0:00:34  lr: 0.000061  loss: 0.5684 (0.5759)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [160/172]  eta: 0:00:19  lr: 0.000061  loss: 0.5547 (0.5753)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [170/172]  eta: 0:00:03  lr: 0.000061  loss: 0.5718 (0.5754)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456]  [171/172]  eta: 0:00:01  lr: 0.000061  loss: 0.5698 (0.5751)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:456] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000061  loss: 0.5698 (0.5751)\n",
      "Valid: [epoch:456]  [ 0/14]  eta: 0:00:04  loss: 0.4996 (0.4996)  time: 0.3057  data: 0.2906  max mem: 20571\n",
      "Valid: [epoch:456]  [13/14]  eta: 0:00:00  loss: 0.5445 (0.5488)  time: 0.0379  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:456] Total time: 0:00:00 (0.0459 s / it)\n",
      "Averaged stats: loss: 0.5445 (0.5488)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_456_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.549%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:457]  [  0/172]  eta: 0:07:42  lr: 0.000060  loss: 0.6140 (0.6140)  time: 2.6907  data: 1.1131  max mem: 20571\n",
      "Train: [epoch:457]  [ 10/172]  eta: 0:04:32  lr: 0.000060  loss: 0.5680 (0.5654)  time: 1.6792  data: 0.1013  max mem: 20571\n",
      "Train: [epoch:457]  [ 20/172]  eta: 0:04:08  lr: 0.000060  loss: 0.5680 (0.5707)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [ 30/172]  eta: 0:03:49  lr: 0.000060  loss: 0.5649 (0.5632)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [ 40/172]  eta: 0:03:32  lr: 0.000060  loss: 0.5617 (0.5655)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.5772 (0.5699)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [ 60/172]  eta: 0:02:59  lr: 0.000060  loss: 0.5764 (0.5703)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [ 70/172]  eta: 0:02:42  lr: 0.000060  loss: 0.5723 (0.5722)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.5738 (0.5729)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.5738 (0.5732)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.5990 (0.5749)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.5990 (0.5748)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.5839 (0.5754)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.5791 (0.5742)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.5500 (0.5739)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.5751 (0.5737)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.5759 (0.5742)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.5862 (0.5749)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.5893 (0.5751)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:457] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.5893 (0.5751)\n",
      "Valid: [epoch:457]  [ 0/14]  eta: 0:00:05  loss: 0.5323 (0.5323)  time: 0.3725  data: 0.3571  max mem: 20571\n",
      "Valid: [epoch:457]  [13/14]  eta: 0:00:00  loss: 0.5323 (0.5374)  time: 0.0420  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:457] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.5323 (0.5374)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_457_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.537%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:458]  [  0/172]  eta: 0:07:39  lr: 0.000060  loss: 0.5507 (0.5507)  time: 2.6711  data: 1.1051  max mem: 20571\n",
      "Train: [epoch:458]  [ 10/172]  eta: 0:04:32  lr: 0.000060  loss: 0.5720 (0.5721)  time: 1.6803  data: 0.1005  max mem: 20571\n",
      "Train: [epoch:458]  [ 20/172]  eta: 0:04:08  lr: 0.000060  loss: 0.5653 (0.5707)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [ 30/172]  eta: 0:03:49  lr: 0.000060  loss: 0.5605 (0.5740)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [ 40/172]  eta: 0:03:32  lr: 0.000060  loss: 0.5672 (0.5732)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.5834 (0.5764)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [ 60/172]  eta: 0:02:58  lr: 0.000060  loss: 0.5886 (0.5775)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [ 70/172]  eta: 0:02:42  lr: 0.000060  loss: 0.5801 (0.5776)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.5815 (0.5793)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.5815 (0.5784)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.5784 (0.5792)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.5704 (0.5778)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.5562 (0.5767)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.5653 (0.5771)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.5770 (0.5765)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.5584 (0.5766)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.5611 (0.5765)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.5635 (0.5767)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.5635 (0.5764)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:458] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.5635 (0.5764)\n",
      "Valid: [epoch:458]  [ 0/14]  eta: 0:00:06  loss: 0.5259 (0.5259)  time: 0.4755  data: 0.4574  max mem: 20571\n",
      "Valid: [epoch:458]  [13/14]  eta: 0:00:00  loss: 0.5577 (0.5600)  time: 0.0489  data: 0.0338  max mem: 20571\n",
      "Valid: [epoch:458] Total time: 0:00:00 (0.0536 s / it)\n",
      "Averaged stats: loss: 0.5577 (0.5600)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_458_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.560%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:459]  [  0/172]  eta: 0:07:34  lr: 0.000060  loss: 0.5910 (0.5910)  time: 2.6443  data: 1.0571  max mem: 20571\n",
      "Train: [epoch:459]  [ 10/172]  eta: 0:04:31  lr: 0.000060  loss: 0.5826 (0.5798)  time: 1.6755  data: 0.0962  max mem: 20571\n",
      "Train: [epoch:459]  [ 20/172]  eta: 0:04:07  lr: 0.000060  loss: 0.5907 (0.5862)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [ 30/172]  eta: 0:03:49  lr: 0.000060  loss: 0.5792 (0.5807)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [ 40/172]  eta: 0:03:32  lr: 0.000060  loss: 0.5793 (0.5810)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.5821 (0.5788)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [ 60/172]  eta: 0:02:59  lr: 0.000060  loss: 0.5773 (0.5797)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [ 70/172]  eta: 0:02:42  lr: 0.000060  loss: 0.5772 (0.5802)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.5766 (0.5797)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.5652 (0.5790)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.5555 (0.5779)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.5641 (0.5779)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.5739 (0.5782)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.5806 (0.5793)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.5616 (0.5779)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.5616 (0.5776)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.5600 (0.5770)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.5655 (0.5768)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.5655 (0.5768)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:459] Total time: 0:04:33 (1.5900 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.5655 (0.5768)\n",
      "Valid: [epoch:459]  [ 0/14]  eta: 0:00:04  loss: 0.5744 (0.5744)  time: 0.2953  data: 0.2801  max mem: 20571\n",
      "Valid: [epoch:459]  [13/14]  eta: 0:00:00  loss: 0.5479 (0.5528)  time: 0.0362  data: 0.0210  max mem: 20571\n",
      "Valid: [epoch:459] Total time: 0:00:00 (0.0436 s / it)\n",
      "Averaged stats: loss: 0.5479 (0.5528)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_459_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.553%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:460]  [  0/172]  eta: 0:07:25  lr: 0.000060  loss: 0.5185 (0.5185)  time: 2.5894  data: 1.0205  max mem: 20571\n",
      "Train: [epoch:460]  [ 10/172]  eta: 0:04:31  lr: 0.000060  loss: 0.5679 (0.5661)  time: 1.6730  data: 0.0929  max mem: 20571\n",
      "Train: [epoch:460]  [ 20/172]  eta: 0:04:07  lr: 0.000060  loss: 0.5679 (0.5678)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [ 30/172]  eta: 0:03:49  lr: 0.000060  loss: 0.5757 (0.5759)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [ 40/172]  eta: 0:03:32  lr: 0.000060  loss: 0.5694 (0.5708)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.5596 (0.5731)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [ 60/172]  eta: 0:02:59  lr: 0.000060  loss: 0.5701 (0.5728)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [ 70/172]  eta: 0:02:42  lr: 0.000060  loss: 0.5849 (0.5745)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.5873 (0.5732)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.5696 (0.5738)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.5753 (0.5744)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.5808 (0.5754)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.5757 (0.5755)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.5649 (0.5759)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.5780 (0.5754)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.5795 (0.5765)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.5769 (0.5763)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.5629 (0.5759)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.5694 (0.5763)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:460] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.5694 (0.5763)\n",
      "Valid: [epoch:460]  [ 0/14]  eta: 0:00:04  loss: 0.5220 (0.5220)  time: 0.3062  data: 0.2905  max mem: 20571\n",
      "Valid: [epoch:460]  [13/14]  eta: 0:00:00  loss: 0.5368 (0.5417)  time: 0.0448  data: 0.0295  max mem: 20571\n",
      "Valid: [epoch:460] Total time: 0:00:00 (0.0513 s / it)\n",
      "Averaged stats: loss: 0.5368 (0.5417)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_460_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.542%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:461]  [  0/172]  eta: 0:07:33  lr: 0.000060  loss: 0.5918 (0.5918)  time: 2.6370  data: 1.0625  max mem: 20571\n",
      "Train: [epoch:461]  [ 10/172]  eta: 0:04:31  lr: 0.000060  loss: 0.5698 (0.5702)  time: 1.6731  data: 0.0967  max mem: 20571\n",
      "Train: [epoch:461]  [ 20/172]  eta: 0:04:07  lr: 0.000060  loss: 0.5715 (0.5747)  time: 1.5783  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:461]  [ 30/172]  eta: 0:03:48  lr: 0.000060  loss: 0.5715 (0.5735)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [ 40/172]  eta: 0:03:31  lr: 0.000060  loss: 0.5761 (0.5780)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.5792 (0.5788)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [ 60/172]  eta: 0:02:58  lr: 0.000060  loss: 0.5681 (0.5775)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [ 70/172]  eta: 0:02:42  lr: 0.000060  loss: 0.5744 (0.5787)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.5744 (0.5787)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.5806 (0.5780)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.5765 (0.5770)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.5765 (0.5773)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.5657 (0.5768)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.5657 (0.5767)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.5746 (0.5773)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.5681 (0.5771)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.5726 (0.5778)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.5777 (0.5786)  time: 1.5830  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:461]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.5777 (0.5785)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:461] Total time: 0:04:33 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.5777 (0.5785)\n",
      "Valid: [epoch:461]  [ 0/14]  eta: 0:00:04  loss: 0.5082 (0.5082)  time: 0.2869  data: 0.2721  max mem: 20571\n",
      "Valid: [epoch:461]  [13/14]  eta: 0:00:00  loss: 0.5394 (0.5439)  time: 0.0355  data: 0.0207  max mem: 20571\n",
      "Valid: [epoch:461] Total time: 0:00:00 (0.0438 s / it)\n",
      "Averaged stats: loss: 0.5394 (0.5439)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_461_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.544%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:462]  [  0/172]  eta: 0:07:47  lr: 0.000060  loss: 0.5510 (0.5510)  time: 2.7201  data: 1.1398  max mem: 20571\n",
      "Train: [epoch:462]  [ 10/172]  eta: 0:04:32  lr: 0.000060  loss: 0.5469 (0.5564)  time: 1.6833  data: 0.1037  max mem: 20571\n",
      "Train: [epoch:462]  [ 20/172]  eta: 0:04:08  lr: 0.000060  loss: 0.5667 (0.5669)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [ 30/172]  eta: 0:03:49  lr: 0.000060  loss: 0.5814 (0.5722)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:462]  [ 40/172]  eta: 0:03:32  lr: 0.000060  loss: 0.5746 (0.5782)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.5976 (0.5812)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [ 60/172]  eta: 0:02:59  lr: 0.000060  loss: 0.5810 (0.5785)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [ 70/172]  eta: 0:02:43  lr: 0.000060  loss: 0.5716 (0.5811)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.5815 (0.5805)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.5673 (0.5797)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.5778 (0.5800)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.5838 (0.5807)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.5761 (0.5799)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.5677 (0.5793)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.5644 (0.5796)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.5694 (0.5799)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.5878 (0.5795)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.5668 (0.5789)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.5587 (0.5787)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:462] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.5587 (0.5787)\n",
      "Valid: [epoch:462]  [ 0/14]  eta: 0:00:04  loss: 0.5094 (0.5094)  time: 0.2907  data: 0.2751  max mem: 20571\n",
      "Valid: [epoch:462]  [13/14]  eta: 0:00:00  loss: 0.5409 (0.5466)  time: 0.0374  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:462] Total time: 0:00:00 (0.0424 s / it)\n",
      "Averaged stats: loss: 0.5409 (0.5466)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_462_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.547%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:463]  [  0/172]  eta: 0:07:27  lr: 0.000060  loss: 0.5531 (0.5531)  time: 2.5992  data: 1.0251  max mem: 20571\n",
      "Train: [epoch:463]  [ 10/172]  eta: 0:04:30  lr: 0.000060  loss: 0.5590 (0.5717)  time: 1.6708  data: 0.0933  max mem: 20571\n",
      "Train: [epoch:463]  [ 20/172]  eta: 0:04:07  lr: 0.000060  loss: 0.5734 (0.5730)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [ 30/172]  eta: 0:03:48  lr: 0.000060  loss: 0.5758 (0.5765)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [ 40/172]  eta: 0:03:31  lr: 0.000060  loss: 0.5857 (0.5802)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.5855 (0.5791)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [ 60/172]  eta: 0:02:58  lr: 0.000060  loss: 0.5772 (0.5803)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [ 70/172]  eta: 0:02:42  lr: 0.000060  loss: 0.5831 (0.5802)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.5801 (0.5809)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.5734 (0.5803)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.5613 (0.5785)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.5743 (0.5794)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.5830 (0.5796)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.5853 (0.5802)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.5709 (0.5796)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.5759 (0.5803)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.5811 (0.5805)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.5671 (0.5797)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.5671 (0.5800)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:463] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.5671 (0.5800)\n",
      "Valid: [epoch:463]  [ 0/14]  eta: 0:00:08  loss: 0.4809 (0.4809)  time: 0.5897  data: 0.5719  max mem: 20571\n",
      "Valid: [epoch:463]  [13/14]  eta: 0:00:00  loss: 0.5379 (0.5435)  time: 0.0568  data: 0.0417  max mem: 20571\n",
      "Valid: [epoch:463] Total time: 0:00:00 (0.0612 s / it)\n",
      "Averaged stats: loss: 0.5379 (0.5435)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_463_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.544%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:464]  [  0/172]  eta: 0:07:26  lr: 0.000060  loss: 0.5359 (0.5359)  time: 2.5955  data: 1.0273  max mem: 20571\n",
      "Train: [epoch:464]  [ 10/172]  eta: 0:04:30  lr: 0.000060  loss: 0.5683 (0.5714)  time: 1.6725  data: 0.0935  max mem: 20571\n",
      "Train: [epoch:464]  [ 20/172]  eta: 0:04:07  lr: 0.000060  loss: 0.5587 (0.5747)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [ 30/172]  eta: 0:03:49  lr: 0.000060  loss: 0.5634 (0.5741)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [ 40/172]  eta: 0:03:31  lr: 0.000060  loss: 0.5710 (0.5718)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.5800 (0.5739)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [ 60/172]  eta: 0:02:58  lr: 0.000060  loss: 0.5880 (0.5752)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [ 70/172]  eta: 0:02:42  lr: 0.000060  loss: 0.5804 (0.5758)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.5819 (0.5767)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.5822 (0.5778)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.5869 (0.5789)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.5669 (0.5793)  time: 1.5809  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:464]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.5669 (0.5795)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.5779 (0.5787)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.5810 (0.5787)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.5753 (0.5779)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.5650 (0.5779)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.5716 (0.5785)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.5798 (0.5787)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:464] Total time: 0:04:33 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.5798 (0.5787)\n",
      "Valid: [epoch:464]  [ 0/14]  eta: 0:00:04  loss: 0.5794 (0.5794)  time: 0.3091  data: 0.2928  max mem: 20571\n",
      "Valid: [epoch:464]  [13/14]  eta: 0:00:00  loss: 0.5442 (0.5479)  time: 0.0384  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:464] Total time: 0:00:00 (0.0467 s / it)\n",
      "Averaged stats: loss: 0.5442 (0.5479)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_464_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.548%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:465]  [  0/172]  eta: 0:07:40  lr: 0.000060  loss: 0.5570 (0.5570)  time: 2.6766  data: 1.1020  max mem: 20571\n",
      "Train: [epoch:465]  [ 10/172]  eta: 0:04:31  lr: 0.000060  loss: 0.5570 (0.5722)  time: 1.6778  data: 0.1003  max mem: 20571\n",
      "Train: [epoch:465]  [ 20/172]  eta: 0:04:07  lr: 0.000060  loss: 0.5874 (0.5875)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [ 30/172]  eta: 0:03:49  lr: 0.000060  loss: 0.5933 (0.5865)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [ 40/172]  eta: 0:03:32  lr: 0.000060  loss: 0.5815 (0.5825)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [ 50/172]  eta: 0:03:15  lr: 0.000060  loss: 0.5641 (0.5789)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [ 60/172]  eta: 0:02:59  lr: 0.000060  loss: 0.5651 (0.5811)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [ 70/172]  eta: 0:02:42  lr: 0.000060  loss: 0.5914 (0.5825)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [ 80/172]  eta: 0:02:26  lr: 0.000060  loss: 0.5675 (0.5808)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [ 90/172]  eta: 0:02:10  lr: 0.000060  loss: 0.5845 (0.5823)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [100/172]  eta: 0:01:54  lr: 0.000060  loss: 0.5681 (0.5806)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [110/172]  eta: 0:01:38  lr: 0.000060  loss: 0.5710 (0.5814)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [120/172]  eta: 0:01:22  lr: 0.000060  loss: 0.5752 (0.5809)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [130/172]  eta: 0:01:06  lr: 0.000060  loss: 0.5879 (0.5831)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [140/172]  eta: 0:00:50  lr: 0.000060  loss: 0.5946 (0.5829)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [150/172]  eta: 0:00:34  lr: 0.000060  loss: 0.5604 (0.5810)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [160/172]  eta: 0:00:19  lr: 0.000060  loss: 0.5522 (0.5803)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [170/172]  eta: 0:00:03  lr: 0.000060  loss: 0.5781 (0.5808)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465]  [171/172]  eta: 0:00:01  lr: 0.000060  loss: 0.5781 (0.5808)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:465] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000060  loss: 0.5781 (0.5808)\n",
      "Valid: [epoch:465]  [ 0/14]  eta: 0:00:03  loss: 0.5698 (0.5698)  time: 0.2756  data: 0.2594  max mem: 20571\n",
      "Valid: [epoch:465]  [13/14]  eta: 0:00:00  loss: 0.5410 (0.5454)  time: 0.0395  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:465] Total time: 0:00:00 (0.0444 s / it)\n",
      "Averaged stats: loss: 0.5410 (0.5454)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_465_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.545%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:466]  [  0/172]  eta: 0:07:16  lr: 0.000059  loss: 0.5299 (0.5299)  time: 2.5355  data: 0.9648  max mem: 20571\n",
      "Train: [epoch:466]  [ 10/172]  eta: 0:04:30  lr: 0.000059  loss: 0.5757 (0.5785)  time: 1.6699  data: 0.0878  max mem: 20571\n",
      "Train: [epoch:466]  [ 20/172]  eta: 0:04:07  lr: 0.000059  loss: 0.5812 (0.5829)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [ 30/172]  eta: 0:03:49  lr: 0.000059  loss: 0.5834 (0.5805)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [ 40/172]  eta: 0:03:31  lr: 0.000059  loss: 0.5765 (0.5756)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [ 50/172]  eta: 0:03:15  lr: 0.000059  loss: 0.5779 (0.5793)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [ 60/172]  eta: 0:02:58  lr: 0.000059  loss: 0.5813 (0.5772)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:466]  [ 70/172]  eta: 0:02:42  lr: 0.000059  loss: 0.5707 (0.5789)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:466]  [ 80/172]  eta: 0:02:26  lr: 0.000059  loss: 0.5715 (0.5792)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [ 90/172]  eta: 0:02:10  lr: 0.000059  loss: 0.5787 (0.5795)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [100/172]  eta: 0:01:54  lr: 0.000059  loss: 0.5894 (0.5804)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [110/172]  eta: 0:01:38  lr: 0.000059  loss: 0.5699 (0.5787)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [120/172]  eta: 0:01:22  lr: 0.000059  loss: 0.5699 (0.5800)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [130/172]  eta: 0:01:06  lr: 0.000059  loss: 0.5699 (0.5790)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [140/172]  eta: 0:00:50  lr: 0.000059  loss: 0.5618 (0.5793)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [150/172]  eta: 0:00:34  lr: 0.000059  loss: 0.5824 (0.5802)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [160/172]  eta: 0:00:19  lr: 0.000059  loss: 0.5981 (0.5810)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [170/172]  eta: 0:00:03  lr: 0.000059  loss: 0.5906 (0.5812)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466]  [171/172]  eta: 0:00:01  lr: 0.000059  loss: 0.5928 (0.5813)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:466] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000059  loss: 0.5928 (0.5813)\n",
      "Valid: [epoch:466]  [ 0/14]  eta: 0:00:06  loss: 0.5700 (0.5700)  time: 0.4805  data: 0.4653  max mem: 20571\n",
      "Valid: [epoch:466]  [13/14]  eta: 0:00:00  loss: 0.5413 (0.5453)  time: 0.0495  data: 0.0346  max mem: 20571\n",
      "Valid: [epoch:466] Total time: 0:00:00 (0.0579 s / it)\n",
      "Averaged stats: loss: 0.5413 (0.5453)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_466_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.545%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:467]  [  0/172]  eta: 0:07:49  lr: 0.000059  loss: 0.5565 (0.5565)  time: 2.7317  data: 1.1389  max mem: 20571\n",
      "Train: [epoch:467]  [ 10/172]  eta: 0:04:32  lr: 0.000059  loss: 0.5698 (0.5747)  time: 1.6818  data: 0.1036  max mem: 20571\n",
      "Train: [epoch:467]  [ 20/172]  eta: 0:04:08  lr: 0.000059  loss: 0.5827 (0.5866)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [ 30/172]  eta: 0:03:49  lr: 0.000059  loss: 0.5827 (0.5844)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [ 40/172]  eta: 0:03:32  lr: 0.000059  loss: 0.5775 (0.5832)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [ 50/172]  eta: 0:03:15  lr: 0.000059  loss: 0.5774 (0.5834)  time: 1.5811  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:467]  [ 60/172]  eta: 0:02:59  lr: 0.000059  loss: 0.5889 (0.5844)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [ 70/172]  eta: 0:02:42  lr: 0.000059  loss: 0.5991 (0.5862)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [ 80/172]  eta: 0:02:26  lr: 0.000059  loss: 0.5946 (0.5876)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [ 90/172]  eta: 0:02:10  lr: 0.000059  loss: 0.5923 (0.5870)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [100/172]  eta: 0:01:54  lr: 0.000059  loss: 0.5799 (0.5863)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [110/172]  eta: 0:01:38  lr: 0.000059  loss: 0.5705 (0.5857)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [120/172]  eta: 0:01:22  lr: 0.000059  loss: 0.5698 (0.5850)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [130/172]  eta: 0:01:06  lr: 0.000059  loss: 0.5696 (0.5849)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [140/172]  eta: 0:00:50  lr: 0.000059  loss: 0.5722 (0.5837)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [150/172]  eta: 0:00:34  lr: 0.000059  loss: 0.5749 (0.5839)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [160/172]  eta: 0:00:19  lr: 0.000059  loss: 0.5938 (0.5847)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [170/172]  eta: 0:00:03  lr: 0.000059  loss: 0.5846 (0.5842)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467]  [171/172]  eta: 0:00:01  lr: 0.000059  loss: 0.5899 (0.5843)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:467] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000059  loss: 0.5899 (0.5843)\n",
      "Valid: [epoch:467]  [ 0/14]  eta: 0:00:03  loss: 0.5481 (0.5481)  time: 0.2803  data: 0.2654  max mem: 20571\n",
      "Valid: [epoch:467]  [13/14]  eta: 0:00:00  loss: 0.5646 (0.5686)  time: 0.0440  data: 0.0290  max mem: 20571\n",
      "Valid: [epoch:467] Total time: 0:00:00 (0.0517 s / it)\n",
      "Averaged stats: loss: 0.5646 (0.5686)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_467_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.569%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:468]  [  0/172]  eta: 0:07:47  lr: 0.000059  loss: 0.5410 (0.5410)  time: 2.7203  data: 1.1520  max mem: 20571\n",
      "Train: [epoch:468]  [ 10/172]  eta: 0:04:32  lr: 0.000059  loss: 0.5703 (0.5717)  time: 1.6839  data: 0.1048  max mem: 20571\n",
      "Train: [epoch:468]  [ 20/172]  eta: 0:04:08  lr: 0.000059  loss: 0.5778 (0.5795)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [ 30/172]  eta: 0:03:49  lr: 0.000059  loss: 0.5742 (0.5748)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [ 40/172]  eta: 0:03:32  lr: 0.000059  loss: 0.5725 (0.5786)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [ 50/172]  eta: 0:03:15  lr: 0.000059  loss: 0.5878 (0.5817)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [ 60/172]  eta: 0:02:59  lr: 0.000059  loss: 0.6026 (0.5822)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [ 70/172]  eta: 0:02:43  lr: 0.000059  loss: 0.5801 (0.5823)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [ 80/172]  eta: 0:02:26  lr: 0.000059  loss: 0.5691 (0.5801)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [ 90/172]  eta: 0:02:10  lr: 0.000059  loss: 0.5696 (0.5813)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [100/172]  eta: 0:01:54  lr: 0.000059  loss: 0.5927 (0.5830)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [110/172]  eta: 0:01:38  lr: 0.000059  loss: 0.5822 (0.5837)  time: 1.5865  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:468]  [120/172]  eta: 0:01:22  lr: 0.000059  loss: 0.5851 (0.5842)  time: 1.5843  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:468]  [130/172]  eta: 0:01:06  lr: 0.000059  loss: 0.5783 (0.5830)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [140/172]  eta: 0:00:50  lr: 0.000059  loss: 0.5768 (0.5836)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [150/172]  eta: 0:00:35  lr: 0.000059  loss: 0.5788 (0.5835)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:468]  [160/172]  eta: 0:00:19  lr: 0.000059  loss: 0.5790 (0.5838)  time: 1.5864  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:468]  [170/172]  eta: 0:00:03  lr: 0.000059  loss: 0.5790 (0.5836)  time: 1.5857  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:468]  [171/172]  eta: 0:00:01  lr: 0.000059  loss: 0.5790 (0.5837)  time: 1.5857  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:468] Total time: 0:04:33 (1.5911 s / it)\n",
      "Averaged stats: lr: 0.000059  loss: 0.5790 (0.5837)\n",
      "Valid: [epoch:468]  [ 0/14]  eta: 0:00:06  loss: 0.5627 (0.5627)  time: 0.4364  data: 0.4208  max mem: 20571\n",
      "Valid: [epoch:468]  [13/14]  eta: 0:00:00  loss: 0.5686 (0.5727)  time: 0.0460  data: 0.0309  max mem: 20571\n",
      "Valid: [epoch:468] Total time: 0:00:00 (0.0546 s / it)\n",
      "Averaged stats: loss: 0.5686 (0.5727)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_468_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.573%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:469]  [  0/172]  eta: 0:08:35  lr: 0.000059  loss: 0.5334 (0.5334)  time: 2.9964  data: 1.4170  max mem: 20571\n",
      "Train: [epoch:469]  [ 10/172]  eta: 0:04:36  lr: 0.000059  loss: 0.5606 (0.5708)  time: 1.7089  data: 0.1290  max mem: 20571\n",
      "Train: [epoch:469]  [ 20/172]  eta: 0:04:10  lr: 0.000059  loss: 0.5857 (0.5827)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:469]  [ 30/172]  eta: 0:03:51  lr: 0.000059  loss: 0.5857 (0.5864)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:469]  [ 40/172]  eta: 0:03:33  lr: 0.000059  loss: 0.5775 (0.5854)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [ 50/172]  eta: 0:03:16  lr: 0.000059  loss: 0.5800 (0.5866)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [ 60/172]  eta: 0:02:59  lr: 0.000059  loss: 0.5800 (0.5853)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [ 70/172]  eta: 0:02:43  lr: 0.000059  loss: 0.5691 (0.5865)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [ 80/172]  eta: 0:02:27  lr: 0.000059  loss: 0.5906 (0.5863)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [ 90/172]  eta: 0:02:11  lr: 0.000059  loss: 0.5822 (0.5856)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [100/172]  eta: 0:01:55  lr: 0.000059  loss: 0.5822 (0.5868)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [110/172]  eta: 0:01:38  lr: 0.000059  loss: 0.5900 (0.5858)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [120/172]  eta: 0:01:22  lr: 0.000059  loss: 0.5841 (0.5862)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [130/172]  eta: 0:01:06  lr: 0.000059  loss: 0.5773 (0.5852)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [140/172]  eta: 0:00:50  lr: 0.000059  loss: 0.5665 (0.5843)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [150/172]  eta: 0:00:35  lr: 0.000059  loss: 0.5768 (0.5838)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [160/172]  eta: 0:00:19  lr: 0.000059  loss: 0.5807 (0.5841)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [170/172]  eta: 0:00:03  lr: 0.000059  loss: 0.5807 (0.5838)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469]  [171/172]  eta: 0:00:01  lr: 0.000059  loss: 0.5807 (0.5838)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:469] Total time: 0:04:33 (1.5925 s / it)\n",
      "Averaged stats: lr: 0.000059  loss: 0.5807 (0.5838)\n",
      "Valid: [epoch:469]  [ 0/14]  eta: 0:00:05  loss: 0.5269 (0.5269)  time: 0.4090  data: 0.3920  max mem: 20571\n",
      "Valid: [epoch:469]  [13/14]  eta: 0:00:00  loss: 0.5410 (0.5459)  time: 0.0433  data: 0.0281  max mem: 20571\n",
      "Valid: [epoch:469] Total time: 0:00:00 (0.0516 s / it)\n",
      "Averaged stats: loss: 0.5410 (0.5459)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_469_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.546%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:470]  [  0/172]  eta: 0:08:09  lr: 0.000059  loss: 0.5899 (0.5899)  time: 2.8442  data: 1.2755  max mem: 20571\n",
      "Train: [epoch:470]  [ 10/172]  eta: 0:04:34  lr: 0.000059  loss: 0.5781 (0.5837)  time: 1.6956  data: 0.1161  max mem: 20571\n",
      "Train: [epoch:470]  [ 20/172]  eta: 0:04:09  lr: 0.000059  loss: 0.5762 (0.5843)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [ 30/172]  eta: 0:03:50  lr: 0.000059  loss: 0.5728 (0.5812)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [ 40/172]  eta: 0:03:32  lr: 0.000059  loss: 0.5698 (0.5807)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [ 50/172]  eta: 0:03:16  lr: 0.000059  loss: 0.5735 (0.5853)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [ 60/172]  eta: 0:02:59  lr: 0.000059  loss: 0.5984 (0.5872)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [ 70/172]  eta: 0:02:43  lr: 0.000059  loss: 0.5914 (0.5875)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [ 80/172]  eta: 0:02:27  lr: 0.000059  loss: 0.5795 (0.5857)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [ 90/172]  eta: 0:02:10  lr: 0.000059  loss: 0.5804 (0.5856)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [100/172]  eta: 0:01:54  lr: 0.000059  loss: 0.5857 (0.5852)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [110/172]  eta: 0:01:38  lr: 0.000059  loss: 0.5722 (0.5849)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [120/172]  eta: 0:01:22  lr: 0.000059  loss: 0.5858 (0.5863)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [130/172]  eta: 0:01:06  lr: 0.000059  loss: 0.5927 (0.5858)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [140/172]  eta: 0:00:50  lr: 0.000059  loss: 0.5693 (0.5849)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [150/172]  eta: 0:00:34  lr: 0.000059  loss: 0.5688 (0.5846)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [160/172]  eta: 0:00:19  lr: 0.000059  loss: 0.5899 (0.5854)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [170/172]  eta: 0:00:03  lr: 0.000059  loss: 0.5938 (0.5856)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470]  [171/172]  eta: 0:00:01  lr: 0.000059  loss: 0.5938 (0.5855)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:470] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000059  loss: 0.5938 (0.5855)\n",
      "Valid: [epoch:470]  [ 0/14]  eta: 0:00:05  loss: 0.5417 (0.5417)  time: 0.3678  data: 0.3500  max mem: 20571\n",
      "Valid: [epoch:470]  [13/14]  eta: 0:00:00  loss: 0.5417 (0.5467)  time: 0.0412  data: 0.0261  max mem: 20571\n",
      "Valid: [epoch:470] Total time: 0:00:00 (0.0460 s / it)\n",
      "Averaged stats: loss: 0.5417 (0.5467)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_470_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.547%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:471]  [  0/172]  eta: 0:08:15  lr: 0.000059  loss: 0.5574 (0.5574)  time: 2.8806  data: 1.3046  max mem: 20571\n",
      "Train: [epoch:471]  [ 10/172]  eta: 0:04:34  lr: 0.000059  loss: 0.5717 (0.5791)  time: 1.6960  data: 0.1187  max mem: 20571\n",
      "Train: [epoch:471]  [ 20/172]  eta: 0:04:09  lr: 0.000059  loss: 0.5675 (0.5809)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [ 30/172]  eta: 0:03:50  lr: 0.000059  loss: 0.5670 (0.5779)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [ 40/172]  eta: 0:03:32  lr: 0.000059  loss: 0.5648 (0.5766)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [ 50/172]  eta: 0:03:15  lr: 0.000059  loss: 0.5787 (0.5782)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [ 60/172]  eta: 0:02:59  lr: 0.000059  loss: 0.5787 (0.5781)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [ 70/172]  eta: 0:02:43  lr: 0.000059  loss: 0.5768 (0.5809)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [ 80/172]  eta: 0:02:26  lr: 0.000059  loss: 0.6111 (0.5836)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [ 90/172]  eta: 0:02:10  lr: 0.000059  loss: 0.5876 (0.5831)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [100/172]  eta: 0:01:54  lr: 0.000059  loss: 0.5822 (0.5836)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [110/172]  eta: 0:01:38  lr: 0.000059  loss: 0.5718 (0.5844)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [120/172]  eta: 0:01:22  lr: 0.000059  loss: 0.5839 (0.5857)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [130/172]  eta: 0:01:06  lr: 0.000059  loss: 0.5874 (0.5860)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [140/172]  eta: 0:00:50  lr: 0.000059  loss: 0.5772 (0.5856)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [150/172]  eta: 0:00:34  lr: 0.000059  loss: 0.5702 (0.5847)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [160/172]  eta: 0:00:19  lr: 0.000059  loss: 0.5685 (0.5848)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [170/172]  eta: 0:00:03  lr: 0.000059  loss: 0.5775 (0.5857)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471]  [171/172]  eta: 0:00:01  lr: 0.000059  loss: 0.5775 (0.5856)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:471] Total time: 0:04:33 (1.5901 s / it)\n",
      "Averaged stats: lr: 0.000059  loss: 0.5775 (0.5856)\n",
      "Valid: [epoch:471]  [ 0/14]  eta: 0:00:04  loss: 0.5101 (0.5101)  time: 0.3213  data: 0.3053  max mem: 20571\n",
      "Valid: [epoch:471]  [13/14]  eta: 0:00:00  loss: 0.5542 (0.5603)  time: 0.0387  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:471] Total time: 0:00:00 (0.0434 s / it)\n",
      "Averaged stats: loss: 0.5542 (0.5603)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_471_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.560%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:472]  [  0/172]  eta: 0:07:51  lr: 0.000059  loss: 0.5619 (0.5619)  time: 2.7386  data: 1.1550  max mem: 20571\n",
      "Train: [epoch:472]  [ 10/172]  eta: 0:04:32  lr: 0.000059  loss: 0.5674 (0.5728)  time: 1.6841  data: 0.1051  max mem: 20571\n",
      "Train: [epoch:472]  [ 20/172]  eta: 0:04:08  lr: 0.000059  loss: 0.5873 (0.5866)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [ 30/172]  eta: 0:03:49  lr: 0.000059  loss: 0.5873 (0.5859)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [ 40/172]  eta: 0:03:32  lr: 0.000059  loss: 0.5769 (0.5840)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [ 50/172]  eta: 0:03:15  lr: 0.000059  loss: 0.5799 (0.5909)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [ 60/172]  eta: 0:02:59  lr: 0.000059  loss: 0.5856 (0.5881)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [ 70/172]  eta: 0:02:42  lr: 0.000059  loss: 0.5734 (0.5858)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [ 80/172]  eta: 0:02:26  lr: 0.000059  loss: 0.5508 (0.5844)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [ 90/172]  eta: 0:02:10  lr: 0.000059  loss: 0.5826 (0.5851)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [100/172]  eta: 0:01:54  lr: 0.000059  loss: 0.5826 (0.5852)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [110/172]  eta: 0:01:38  lr: 0.000059  loss: 0.5784 (0.5854)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [120/172]  eta: 0:01:22  lr: 0.000059  loss: 0.5870 (0.5859)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [130/172]  eta: 0:01:06  lr: 0.000059  loss: 0.5843 (0.5858)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [140/172]  eta: 0:00:50  lr: 0.000059  loss: 0.5849 (0.5858)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [150/172]  eta: 0:00:34  lr: 0.000059  loss: 0.5849 (0.5857)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [160/172]  eta: 0:00:19  lr: 0.000059  loss: 0.5803 (0.5858)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472]  [170/172]  eta: 0:00:03  lr: 0.000059  loss: 0.5803 (0.5860)  time: 1.5817  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:472]  [171/172]  eta: 0:00:01  lr: 0.000059  loss: 0.5782 (0.5859)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:472] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000059  loss: 0.5782 (0.5859)\n",
      "Valid: [epoch:472]  [ 0/14]  eta: 0:00:06  loss: 0.5898 (0.5898)  time: 0.4318  data: 0.4156  max mem: 20571\n",
      "Valid: [epoch:472]  [13/14]  eta: 0:00:00  loss: 0.5638 (0.5698)  time: 0.0462  data: 0.0312  max mem: 20571\n",
      "Valid: [epoch:472] Total time: 0:00:00 (0.0518 s / it)\n",
      "Averaged stats: loss: 0.5638 (0.5698)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_472_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.570%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:473]  [  0/172]  eta: 0:08:04  lr: 0.000059  loss: 0.6162 (0.6162)  time: 2.8177  data: 1.2450  max mem: 20571\n",
      "Train: [epoch:473]  [ 10/172]  eta: 0:04:33  lr: 0.000059  loss: 0.5835 (0.5868)  time: 1.6892  data: 0.1133  max mem: 20571\n",
      "Train: [epoch:473]  [ 20/172]  eta: 0:04:09  lr: 0.000059  loss: 0.5825 (0.5878)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [ 30/172]  eta: 0:03:50  lr: 0.000059  loss: 0.5776 (0.5858)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [ 40/172]  eta: 0:03:32  lr: 0.000059  loss: 0.5687 (0.5822)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [ 50/172]  eta: 0:03:15  lr: 0.000059  loss: 0.5742 (0.5860)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [ 60/172]  eta: 0:02:59  lr: 0.000059  loss: 0.5949 (0.5881)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [ 70/172]  eta: 0:02:43  lr: 0.000059  loss: 0.5949 (0.5874)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [ 80/172]  eta: 0:02:26  lr: 0.000059  loss: 0.5801 (0.5873)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [ 90/172]  eta: 0:02:10  lr: 0.000059  loss: 0.5847 (0.5877)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [100/172]  eta: 0:01:54  lr: 0.000059  loss: 0.5865 (0.5874)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [110/172]  eta: 0:01:38  lr: 0.000059  loss: 0.5950 (0.5886)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [120/172]  eta: 0:01:22  lr: 0.000059  loss: 0.5950 (0.5880)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [130/172]  eta: 0:01:06  lr: 0.000059  loss: 0.5781 (0.5872)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [140/172]  eta: 0:00:50  lr: 0.000059  loss: 0.5749 (0.5868)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [150/172]  eta: 0:00:34  lr: 0.000059  loss: 0.5785 (0.5869)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [160/172]  eta: 0:00:19  lr: 0.000059  loss: 0.5809 (0.5865)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [170/172]  eta: 0:00:03  lr: 0.000059  loss: 0.5966 (0.5869)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473]  [171/172]  eta: 0:00:01  lr: 0.000059  loss: 0.5966 (0.5868)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:473] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000059  loss: 0.5966 (0.5868)\n",
      "Valid: [epoch:473]  [ 0/14]  eta: 0:00:04  loss: 0.5379 (0.5379)  time: 0.3366  data: 0.3200  max mem: 20571\n",
      "Valid: [epoch:473]  [13/14]  eta: 0:00:00  loss: 0.5530 (0.5569)  time: 0.0391  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:473] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.5530 (0.5569)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_473_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.557%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:474]  [  0/172]  eta: 0:07:54  lr: 0.000059  loss: 0.6250 (0.6250)  time: 2.7610  data: 1.1952  max mem: 20571\n",
      "Train: [epoch:474]  [ 10/172]  eta: 0:04:33  lr: 0.000059  loss: 0.5907 (0.5912)  time: 1.6852  data: 0.1088  max mem: 20571\n",
      "Train: [epoch:474]  [ 20/172]  eta: 0:04:08  lr: 0.000059  loss: 0.5814 (0.5903)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [ 30/172]  eta: 0:03:49  lr: 0.000059  loss: 0.5814 (0.5868)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [ 40/172]  eta: 0:03:32  lr: 0.000059  loss: 0.5761 (0.5846)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [ 50/172]  eta: 0:03:15  lr: 0.000059  loss: 0.5778 (0.5846)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [ 60/172]  eta: 0:02:59  lr: 0.000059  loss: 0.5845 (0.5850)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [ 70/172]  eta: 0:02:42  lr: 0.000059  loss: 0.5845 (0.5886)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [ 80/172]  eta: 0:02:26  lr: 0.000059  loss: 0.5957 (0.5893)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [ 90/172]  eta: 0:02:10  lr: 0.000059  loss: 0.5932 (0.5886)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [100/172]  eta: 0:01:54  lr: 0.000059  loss: 0.5916 (0.5900)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [110/172]  eta: 0:01:38  lr: 0.000059  loss: 0.5916 (0.5895)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:474]  [120/172]  eta: 0:01:22  lr: 0.000059  loss: 0.5769 (0.5890)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:474]  [130/172]  eta: 0:01:06  lr: 0.000059  loss: 0.5741 (0.5875)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [140/172]  eta: 0:00:50  lr: 0.000059  loss: 0.5733 (0.5869)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [150/172]  eta: 0:00:34  lr: 0.000059  loss: 0.5727 (0.5865)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [160/172]  eta: 0:00:19  lr: 0.000059  loss: 0.5762 (0.5873)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [170/172]  eta: 0:00:03  lr: 0.000059  loss: 0.6006 (0.5876)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474]  [171/172]  eta: 0:00:01  lr: 0.000059  loss: 0.6006 (0.5873)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:474] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000059  loss: 0.6006 (0.5873)\n",
      "Valid: [epoch:474]  [ 0/14]  eta: 0:00:04  loss: 0.5803 (0.5803)  time: 0.3237  data: 0.3070  max mem: 20571\n",
      "Valid: [epoch:474]  [13/14]  eta: 0:00:00  loss: 0.5537 (0.5578)  time: 0.0399  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:474] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.5537 (0.5578)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_474_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.558%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:475]  [  0/172]  eta: 0:07:31  lr: 0.000058  loss: 0.6005 (0.6005)  time: 2.6232  data: 1.0404  max mem: 20571\n",
      "Train: [epoch:475]  [ 10/172]  eta: 0:04:30  lr: 0.000058  loss: 0.5951 (0.5935)  time: 1.6725  data: 0.0947  max mem: 20571\n",
      "Train: [epoch:475]  [ 20/172]  eta: 0:04:07  lr: 0.000058  loss: 0.5912 (0.5955)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:475]  [ 30/172]  eta: 0:03:49  lr: 0.000058  loss: 0.5865 (0.5926)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [ 40/172]  eta: 0:03:31  lr: 0.000058  loss: 0.5768 (0.5882)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [ 50/172]  eta: 0:03:15  lr: 0.000058  loss: 0.5803 (0.5905)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [ 60/172]  eta: 0:02:58  lr: 0.000058  loss: 0.5917 (0.5881)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [ 70/172]  eta: 0:02:42  lr: 0.000058  loss: 0.5943 (0.5909)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [ 80/172]  eta: 0:02:26  lr: 0.000058  loss: 0.5999 (0.5918)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [ 90/172]  eta: 0:02:10  lr: 0.000058  loss: 0.5888 (0.5906)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [100/172]  eta: 0:01:54  lr: 0.000058  loss: 0.5888 (0.5911)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [110/172]  eta: 0:01:38  lr: 0.000058  loss: 0.5795 (0.5904)  time: 1.5840  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:475]  [120/172]  eta: 0:01:22  lr: 0.000058  loss: 0.5795 (0.5896)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [130/172]  eta: 0:01:06  lr: 0.000058  loss: 0.5781 (0.5880)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [140/172]  eta: 0:00:50  lr: 0.000058  loss: 0.5724 (0.5883)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [150/172]  eta: 0:00:34  lr: 0.000058  loss: 0.5724 (0.5872)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [160/172]  eta: 0:00:19  lr: 0.000058  loss: 0.5819 (0.5876)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [170/172]  eta: 0:00:03  lr: 0.000058  loss: 0.5905 (0.5885)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475]  [171/172]  eta: 0:00:01  lr: 0.000058  loss: 0.5870 (0.5884)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:475] Total time: 0:04:33 (1.5897 s / it)\n",
      "Averaged stats: lr: 0.000058  loss: 0.5870 (0.5884)\n",
      "Valid: [epoch:475]  [ 0/14]  eta: 0:00:04  loss: 0.5541 (0.5541)  time: 0.3308  data: 0.3158  max mem: 20571\n",
      "Valid: [epoch:475]  [13/14]  eta: 0:00:00  loss: 0.5541 (0.5595)  time: 0.0384  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:475] Total time: 0:00:00 (0.0434 s / it)\n",
      "Averaged stats: loss: 0.5541 (0.5595)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_475_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.559%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:476]  [  0/172]  eta: 0:08:34  lr: 0.000058  loss: 0.5395 (0.5395)  time: 2.9907  data: 1.4224  max mem: 20571\n",
      "Train: [epoch:476]  [ 10/172]  eta: 0:04:36  lr: 0.000058  loss: 0.5815 (0.5847)  time: 1.7094  data: 0.1295  max mem: 20571\n",
      "Train: [epoch:476]  [ 20/172]  eta: 0:04:10  lr: 0.000058  loss: 0.5832 (0.5928)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [ 30/172]  eta: 0:03:51  lr: 0.000058  loss: 0.5832 (0.5898)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [ 40/172]  eta: 0:03:33  lr: 0.000058  loss: 0.5859 (0.5915)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [ 50/172]  eta: 0:03:16  lr: 0.000058  loss: 0.5971 (0.5927)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [ 60/172]  eta: 0:02:59  lr: 0.000058  loss: 0.5905 (0.5910)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [ 70/172]  eta: 0:02:43  lr: 0.000058  loss: 0.5802 (0.5910)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [ 80/172]  eta: 0:02:27  lr: 0.000058  loss: 0.5752 (0.5896)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [ 90/172]  eta: 0:02:11  lr: 0.000058  loss: 0.5816 (0.5888)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [100/172]  eta: 0:01:54  lr: 0.000058  loss: 0.5769 (0.5873)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [110/172]  eta: 0:01:38  lr: 0.000058  loss: 0.5761 (0.5861)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [120/172]  eta: 0:01:22  lr: 0.000058  loss: 0.5786 (0.5863)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [130/172]  eta: 0:01:06  lr: 0.000058  loss: 0.5825 (0.5865)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [140/172]  eta: 0:00:50  lr: 0.000058  loss: 0.5830 (0.5868)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:476]  [150/172]  eta: 0:00:35  lr: 0.000058  loss: 0.5930 (0.5877)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [160/172]  eta: 0:00:19  lr: 0.000058  loss: 0.5918 (0.5879)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [170/172]  eta: 0:00:03  lr: 0.000058  loss: 0.5928 (0.5886)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476]  [171/172]  eta: 0:00:01  lr: 0.000058  loss: 0.5928 (0.5886)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:476] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000058  loss: 0.5928 (0.5886)\n",
      "Valid: [epoch:476]  [ 0/14]  eta: 0:00:04  loss: 0.5934 (0.5934)  time: 0.3092  data: 0.2942  max mem: 20571\n",
      "Valid: [epoch:476]  [13/14]  eta: 0:00:00  loss: 0.5571 (0.5619)  time: 0.0394  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:476] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.5571 (0.5619)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_476_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.562%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:477]  [  0/172]  eta: 0:07:51  lr: 0.000058  loss: 0.5636 (0.5636)  time: 2.7428  data: 1.1658  max mem: 20571\n",
      "Train: [epoch:477]  [ 10/172]  eta: 0:04:32  lr: 0.000058  loss: 0.5707 (0.5802)  time: 1.6815  data: 0.1061  max mem: 20571\n",
      "Train: [epoch:477]  [ 20/172]  eta: 0:04:08  lr: 0.000058  loss: 0.5875 (0.5881)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [ 30/172]  eta: 0:03:49  lr: 0.000058  loss: 0.5808 (0.5847)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [ 40/172]  eta: 0:03:32  lr: 0.000058  loss: 0.5818 (0.5859)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [ 50/172]  eta: 0:03:15  lr: 0.000058  loss: 0.6014 (0.5902)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [ 60/172]  eta: 0:02:59  lr: 0.000058  loss: 0.5922 (0.5892)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [ 70/172]  eta: 0:02:42  lr: 0.000058  loss: 0.5835 (0.5893)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [ 80/172]  eta: 0:02:26  lr: 0.000058  loss: 0.5951 (0.5905)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [ 90/172]  eta: 0:02:10  lr: 0.000058  loss: 0.5919 (0.5911)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [100/172]  eta: 0:01:54  lr: 0.000058  loss: 0.5919 (0.5909)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [110/172]  eta: 0:01:38  lr: 0.000058  loss: 0.5697 (0.5889)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [120/172]  eta: 0:01:22  lr: 0.000058  loss: 0.5899 (0.5899)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [130/172]  eta: 0:01:06  lr: 0.000058  loss: 0.6063 (0.5917)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [140/172]  eta: 0:00:50  lr: 0.000058  loss: 0.6074 (0.5930)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [150/172]  eta: 0:00:34  lr: 0.000058  loss: 0.5906 (0.5928)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [160/172]  eta: 0:00:19  lr: 0.000058  loss: 0.5832 (0.5924)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [170/172]  eta: 0:00:03  lr: 0.000058  loss: 0.5832 (0.5921)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477]  [171/172]  eta: 0:00:01  lr: 0.000058  loss: 0.5842 (0.5921)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:477] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000058  loss: 0.5842 (0.5921)\n",
      "Valid: [epoch:477]  [ 0/14]  eta: 0:00:07  loss: 0.5301 (0.5301)  time: 0.5479  data: 0.5297  max mem: 20571\n",
      "Valid: [epoch:477]  [13/14]  eta: 0:00:00  loss: 0.5453 (0.5501)  time: 0.0549  data: 0.0397  max mem: 20571\n",
      "Valid: [epoch:477] Total time: 0:00:00 (0.0635 s / it)\n",
      "Averaged stats: loss: 0.5453 (0.5501)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_477_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.550%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:478]  [  0/172]  eta: 0:07:31  lr: 0.000058  loss: 0.4981 (0.4981)  time: 2.6262  data: 1.0557  max mem: 20571\n",
      "Train: [epoch:478]  [ 10/172]  eta: 0:04:32  lr: 0.000058  loss: 0.6084 (0.5875)  time: 1.6811  data: 0.0962  max mem: 20571\n",
      "Train: [epoch:478]  [ 20/172]  eta: 0:04:08  lr: 0.000058  loss: 0.6084 (0.5966)  time: 1.5859  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:478]  [ 30/172]  eta: 0:03:49  lr: 0.000058  loss: 0.6012 (0.5956)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [ 40/172]  eta: 0:03:32  lr: 0.000058  loss: 0.5789 (0.5872)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [ 50/172]  eta: 0:03:15  lr: 0.000058  loss: 0.5744 (0.5900)  time: 1.5847  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:478]  [ 60/172]  eta: 0:02:59  lr: 0.000058  loss: 0.5990 (0.5916)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [ 70/172]  eta: 0:02:43  lr: 0.000058  loss: 0.5982 (0.5920)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [ 80/172]  eta: 0:02:27  lr: 0.000058  loss: 0.5782 (0.5901)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [ 90/172]  eta: 0:02:10  lr: 0.000058  loss: 0.5770 (0.5900)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [100/172]  eta: 0:01:54  lr: 0.000058  loss: 0.5700 (0.5887)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [110/172]  eta: 0:01:38  lr: 0.000058  loss: 0.5700 (0.5880)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [120/172]  eta: 0:01:22  lr: 0.000058  loss: 0.5834 (0.5876)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [130/172]  eta: 0:01:06  lr: 0.000058  loss: 0.5911 (0.5890)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [140/172]  eta: 0:00:50  lr: 0.000058  loss: 0.5895 (0.5890)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [150/172]  eta: 0:00:35  lr: 0.000058  loss: 0.5811 (0.5881)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [160/172]  eta: 0:00:19  lr: 0.000058  loss: 0.5857 (0.5883)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [170/172]  eta: 0:00:03  lr: 0.000058  loss: 0.5881 (0.5878)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478]  [171/172]  eta: 0:00:01  lr: 0.000058  loss: 0.5881 (0.5877)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:478] Total time: 0:04:33 (1.5911 s / it)\n",
      "Averaged stats: lr: 0.000058  loss: 0.5881 (0.5877)\n",
      "Valid: [epoch:478]  [ 0/14]  eta: 0:00:04  loss: 0.5828 (0.5828)  time: 0.2942  data: 0.2787  max mem: 20571\n",
      "Valid: [epoch:478]  [13/14]  eta: 0:00:00  loss: 0.5573 (0.5611)  time: 0.0374  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:478] Total time: 0:00:00 (0.0423 s / it)\n",
      "Averaged stats: loss: 0.5573 (0.5611)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_478_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.561%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:479]  [  0/172]  eta: 0:07:49  lr: 0.000058  loss: 0.6311 (0.6311)  time: 2.7277  data: 1.1467  max mem: 20571\n",
      "Train: [epoch:479]  [ 10/172]  eta: 0:04:32  lr: 0.000058  loss: 0.5899 (0.5937)  time: 1.6817  data: 0.1044  max mem: 20571\n",
      "Train: [epoch:479]  [ 20/172]  eta: 0:04:08  lr: 0.000058  loss: 0.5800 (0.6004)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:479]  [ 30/172]  eta: 0:03:49  lr: 0.000058  loss: 0.5800 (0.5964)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:479]  [ 40/172]  eta: 0:03:32  lr: 0.000058  loss: 0.5758 (0.5916)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:479]  [ 50/172]  eta: 0:03:15  lr: 0.000058  loss: 0.5924 (0.5924)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [ 60/172]  eta: 0:02:59  lr: 0.000058  loss: 0.6065 (0.5963)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [ 70/172]  eta: 0:02:42  lr: 0.000058  loss: 0.5990 (0.5959)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [ 80/172]  eta: 0:02:26  lr: 0.000058  loss: 0.5912 (0.5946)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [ 90/172]  eta: 0:02:10  lr: 0.000058  loss: 0.5784 (0.5943)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:479]  [100/172]  eta: 0:01:54  lr: 0.000058  loss: 0.5781 (0.5940)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:479]  [110/172]  eta: 0:01:38  lr: 0.000058  loss: 0.5891 (0.5939)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [120/172]  eta: 0:01:22  lr: 0.000058  loss: 0.5952 (0.5933)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [130/172]  eta: 0:01:06  lr: 0.000058  loss: 0.5936 (0.5933)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [140/172]  eta: 0:00:50  lr: 0.000058  loss: 0.5891 (0.5925)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [150/172]  eta: 0:00:34  lr: 0.000058  loss: 0.5872 (0.5924)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [160/172]  eta: 0:00:19  lr: 0.000058  loss: 0.5845 (0.5921)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [170/172]  eta: 0:00:03  lr: 0.000058  loss: 0.5805 (0.5918)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479]  [171/172]  eta: 0:00:01  lr: 0.000058  loss: 0.5805 (0.5917)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:479] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000058  loss: 0.5805 (0.5917)\n",
      "Valid: [epoch:479]  [ 0/14]  eta: 0:00:05  loss: 0.5422 (0.5422)  time: 0.3778  data: 0.3629  max mem: 20571\n",
      "Valid: [epoch:479]  [13/14]  eta: 0:00:00  loss: 0.5556 (0.5605)  time: 0.0426  data: 0.0277  max mem: 20571\n",
      "Valid: [epoch:479] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.5556 (0.5605)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_479_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.561%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:480]  [  0/172]  eta: 0:08:19  lr: 0.000058  loss: 0.6387 (0.6387)  time: 2.9065  data: 1.3391  max mem: 20571\n",
      "Train: [epoch:480]  [ 10/172]  eta: 0:04:35  lr: 0.000058  loss: 0.6044 (0.5971)  time: 1.6995  data: 0.1218  max mem: 20571\n",
      "Train: [epoch:480]  [ 20/172]  eta: 0:04:09  lr: 0.000058  loss: 0.6044 (0.6017)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [ 30/172]  eta: 0:03:50  lr: 0.000058  loss: 0.6182 (0.6053)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [ 40/172]  eta: 0:03:32  lr: 0.000058  loss: 0.5889 (0.6002)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [ 50/172]  eta: 0:03:15  lr: 0.000058  loss: 0.5728 (0.5962)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [ 60/172]  eta: 0:02:59  lr: 0.000058  loss: 0.5880 (0.5972)  time: 1.5786  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:480]  [ 70/172]  eta: 0:02:42  lr: 0.000058  loss: 0.5886 (0.5953)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:480]  [ 80/172]  eta: 0:02:26  lr: 0.000058  loss: 0.5886 (0.5963)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [ 90/172]  eta: 0:02:10  lr: 0.000058  loss: 0.6014 (0.5954)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [100/172]  eta: 0:01:54  lr: 0.000058  loss: 0.5818 (0.5942)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [110/172]  eta: 0:01:38  lr: 0.000058  loss: 0.5801 (0.5935)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [120/172]  eta: 0:01:22  lr: 0.000058  loss: 0.5846 (0.5938)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [130/172]  eta: 0:01:06  lr: 0.000058  loss: 0.6079 (0.5939)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [140/172]  eta: 0:00:50  lr: 0.000058  loss: 0.5638 (0.5931)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [150/172]  eta: 0:00:34  lr: 0.000058  loss: 0.5795 (0.5933)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [160/172]  eta: 0:00:19  lr: 0.000058  loss: 0.5795 (0.5926)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [170/172]  eta: 0:00:03  lr: 0.000058  loss: 0.5751 (0.5924)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480]  [171/172]  eta: 0:00:01  lr: 0.000058  loss: 0.5751 (0.5925)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:480] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000058  loss: 0.5751 (0.5925)\n",
      "Valid: [epoch:480]  [ 0/14]  eta: 0:00:04  loss: 0.4963 (0.4963)  time: 0.3249  data: 0.3074  max mem: 20571\n",
      "Valid: [epoch:480]  [13/14]  eta: 0:00:00  loss: 0.5526 (0.5575)  time: 0.0460  data: 0.0307  max mem: 20571\n",
      "Valid: [epoch:480] Total time: 0:00:00 (0.0538 s / it)\n",
      "Averaged stats: loss: 0.5526 (0.5575)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_480_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.557%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:481]  [  0/172]  eta: 0:08:13  lr: 0.000058  loss: 0.6099 (0.6099)  time: 2.8673  data: 1.2933  max mem: 20571\n",
      "Train: [epoch:481]  [ 10/172]  eta: 0:04:35  lr: 0.000058  loss: 0.5907 (0.5900)  time: 1.6988  data: 0.1177  max mem: 20571\n",
      "Train: [epoch:481]  [ 20/172]  eta: 0:04:09  lr: 0.000058  loss: 0.5908 (0.5960)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:481]  [ 30/172]  eta: 0:03:50  lr: 0.000058  loss: 0.5743 (0.5919)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [ 40/172]  eta: 0:03:33  lr: 0.000058  loss: 0.5743 (0.5913)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [ 50/172]  eta: 0:03:16  lr: 0.000058  loss: 0.5890 (0.5909)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [ 60/172]  eta: 0:02:59  lr: 0.000058  loss: 0.5911 (0.5900)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [ 70/172]  eta: 0:02:43  lr: 0.000058  loss: 0.5930 (0.5903)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [ 80/172]  eta: 0:02:27  lr: 0.000058  loss: 0.5930 (0.5908)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [ 90/172]  eta: 0:02:10  lr: 0.000058  loss: 0.5870 (0.5921)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [100/172]  eta: 0:01:54  lr: 0.000058  loss: 0.5929 (0.5933)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [110/172]  eta: 0:01:38  lr: 0.000058  loss: 0.5929 (0.5943)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [120/172]  eta: 0:01:22  lr: 0.000058  loss: 0.5835 (0.5932)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [130/172]  eta: 0:01:06  lr: 0.000058  loss: 0.5835 (0.5933)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [140/172]  eta: 0:00:50  lr: 0.000058  loss: 0.5895 (0.5930)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [150/172]  eta: 0:00:35  lr: 0.000058  loss: 0.5866 (0.5926)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [160/172]  eta: 0:00:19  lr: 0.000058  loss: 0.5866 (0.5929)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [170/172]  eta: 0:00:03  lr: 0.000058  loss: 0.5859 (0.5925)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481]  [171/172]  eta: 0:00:01  lr: 0.000058  loss: 0.5859 (0.5923)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:481] Total time: 0:04:33 (1.5916 s / it)\n",
      "Averaged stats: lr: 0.000058  loss: 0.5859 (0.5923)\n",
      "Valid: [epoch:481]  [ 0/14]  eta: 0:00:07  loss: 0.5889 (0.5889)  time: 0.5173  data: 0.4985  max mem: 20571\n",
      "Valid: [epoch:481]  [13/14]  eta: 0:00:00  loss: 0.5586 (0.5641)  time: 0.0527  data: 0.0374  max mem: 20571\n",
      "Valid: [epoch:481] Total time: 0:00:00 (0.0600 s / it)\n",
      "Averaged stats: loss: 0.5586 (0.5641)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_481_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.564%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:482]  [  0/172]  eta: 0:07:30  lr: 0.000058  loss: 0.6048 (0.6048)  time: 2.6209  data: 1.0500  max mem: 20571\n",
      "Train: [epoch:482]  [ 10/172]  eta: 0:04:32  lr: 0.000058  loss: 0.5697 (0.5767)  time: 1.6798  data: 0.0956  max mem: 20571\n",
      "Train: [epoch:482]  [ 20/172]  eta: 0:04:08  lr: 0.000058  loss: 0.5801 (0.5876)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [ 30/172]  eta: 0:03:49  lr: 0.000058  loss: 0.5990 (0.5929)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [ 40/172]  eta: 0:03:32  lr: 0.000058  loss: 0.5892 (0.5962)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [ 50/172]  eta: 0:03:15  lr: 0.000058  loss: 0.5981 (0.5948)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [ 60/172]  eta: 0:02:59  lr: 0.000058  loss: 0.5911 (0.5953)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [ 70/172]  eta: 0:02:42  lr: 0.000058  loss: 0.5858 (0.5930)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [ 80/172]  eta: 0:02:26  lr: 0.000058  loss: 0.5882 (0.5931)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [ 90/172]  eta: 0:02:10  lr: 0.000058  loss: 0.5945 (0.5936)  time: 1.5838  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:482]  [100/172]  eta: 0:01:54  lr: 0.000058  loss: 0.5863 (0.5932)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [110/172]  eta: 0:01:38  lr: 0.000058  loss: 0.5885 (0.5931)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [120/172]  eta: 0:01:22  lr: 0.000058  loss: 0.5828 (0.5922)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [130/172]  eta: 0:01:06  lr: 0.000058  loss: 0.5821 (0.5917)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [140/172]  eta: 0:00:50  lr: 0.000058  loss: 0.5751 (0.5913)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [150/172]  eta: 0:00:34  lr: 0.000058  loss: 0.5986 (0.5923)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [160/172]  eta: 0:00:19  lr: 0.000058  loss: 0.6059 (0.5933)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [170/172]  eta: 0:00:03  lr: 0.000058  loss: 0.5986 (0.5940)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482]  [171/172]  eta: 0:00:01  lr: 0.000058  loss: 0.5976 (0.5937)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:482] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000058  loss: 0.5976 (0.5937)\n",
      "Valid: [epoch:482]  [ 0/14]  eta: 0:00:05  loss: 0.5739 (0.5739)  time: 0.3666  data: 0.3518  max mem: 20571\n",
      "Valid: [epoch:482]  [13/14]  eta: 0:00:00  loss: 0.6211 (0.6273)  time: 0.0425  data: 0.0273  max mem: 20571\n",
      "Valid: [epoch:482] Total time: 0:00:00 (0.0508 s / it)\n",
      "Averaged stats: loss: 0.6211 (0.6273)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_482_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.627%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:483]  [  0/172]  eta: 0:07:49  lr: 0.000058  loss: 0.6683 (0.6683)  time: 2.7287  data: 1.1564  max mem: 20571\n",
      "Train: [epoch:483]  [ 10/172]  eta: 0:04:32  lr: 0.000058  loss: 0.5910 (0.5959)  time: 1.6808  data: 0.1052  max mem: 20571\n",
      "Train: [epoch:483]  [ 20/172]  eta: 0:04:08  lr: 0.000058  loss: 0.5796 (0.5984)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [ 30/172]  eta: 0:03:49  lr: 0.000058  loss: 0.6289 (0.6024)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [ 40/172]  eta: 0:03:32  lr: 0.000058  loss: 0.5901 (0.5970)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [ 50/172]  eta: 0:03:15  lr: 0.000058  loss: 0.5901 (0.5982)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [ 60/172]  eta: 0:02:58  lr: 0.000058  loss: 0.5950 (0.5971)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [ 70/172]  eta: 0:02:42  lr: 0.000058  loss: 0.5765 (0.5941)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [ 80/172]  eta: 0:02:26  lr: 0.000058  loss: 0.5810 (0.5935)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [ 90/172]  eta: 0:02:10  lr: 0.000058  loss: 0.6013 (0.5935)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [100/172]  eta: 0:01:54  lr: 0.000058  loss: 0.6005 (0.5922)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [110/172]  eta: 0:01:38  lr: 0.000058  loss: 0.5872 (0.5932)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [120/172]  eta: 0:01:22  lr: 0.000058  loss: 0.6046 (0.5946)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [130/172]  eta: 0:01:06  lr: 0.000058  loss: 0.5811 (0.5935)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [140/172]  eta: 0:00:50  lr: 0.000058  loss: 0.5811 (0.5932)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [150/172]  eta: 0:00:34  lr: 0.000058  loss: 0.5896 (0.5945)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [160/172]  eta: 0:00:19  lr: 0.000058  loss: 0.5760 (0.5931)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483]  [170/172]  eta: 0:00:03  lr: 0.000058  loss: 0.5706 (0.5934)  time: 1.5862  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:483]  [171/172]  eta: 0:00:01  lr: 0.000058  loss: 0.5834 (0.5934)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:483] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000058  loss: 0.5834 (0.5934)\n",
      "Valid: [epoch:483]  [ 0/14]  eta: 0:00:04  loss: 0.5784 (0.5784)  time: 0.2964  data: 0.2780  max mem: 20571\n",
      "Valid: [epoch:483]  [13/14]  eta: 0:00:00  loss: 0.5490 (0.5540)  time: 0.0370  data: 0.0217  max mem: 20571\n",
      "Valid: [epoch:483] Total time: 0:00:00 (0.0447 s / it)\n",
      "Averaged stats: loss: 0.5490 (0.5540)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_483_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.554%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:484]  [  0/172]  eta: 0:08:14  lr: 0.000057  loss: 0.5540 (0.5540)  time: 2.8760  data: 1.3052  max mem: 20571\n",
      "Train: [epoch:484]  [ 10/172]  eta: 0:04:35  lr: 0.000057  loss: 0.5721 (0.5824)  time: 1.6994  data: 0.1188  max mem: 20571\n",
      "Train: [epoch:484]  [ 20/172]  eta: 0:04:10  lr: 0.000057  loss: 0.5823 (0.5934)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [ 30/172]  eta: 0:03:50  lr: 0.000057  loss: 0.6016 (0.5928)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [ 40/172]  eta: 0:03:33  lr: 0.000057  loss: 0.5935 (0.5945)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [ 50/172]  eta: 0:03:16  lr: 0.000057  loss: 0.5875 (0.5942)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [ 60/172]  eta: 0:02:59  lr: 0.000057  loss: 0.5803 (0.5943)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [ 70/172]  eta: 0:02:43  lr: 0.000057  loss: 0.5746 (0.5919)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [ 80/172]  eta: 0:02:27  lr: 0.000057  loss: 0.5796 (0.5912)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [ 90/172]  eta: 0:02:11  lr: 0.000057  loss: 0.5903 (0.5919)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [100/172]  eta: 0:01:55  lr: 0.000057  loss: 0.5954 (0.5919)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [110/172]  eta: 0:01:38  lr: 0.000057  loss: 0.5940 (0.5916)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [120/172]  eta: 0:01:22  lr: 0.000057  loss: 0.5918 (0.5923)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [130/172]  eta: 0:01:06  lr: 0.000057  loss: 0.6065 (0.5925)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [140/172]  eta: 0:00:50  lr: 0.000057  loss: 0.6044 (0.5925)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [150/172]  eta: 0:00:35  lr: 0.000057  loss: 0.6088 (0.5946)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [160/172]  eta: 0:00:19  lr: 0.000057  loss: 0.6135 (0.5950)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [170/172]  eta: 0:00:03  lr: 0.000057  loss: 0.5830 (0.5946)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484]  [171/172]  eta: 0:00:01  lr: 0.000057  loss: 0.5840 (0.5950)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:484] Total time: 0:04:33 (1.5926 s / it)\n",
      "Averaged stats: lr: 0.000057  loss: 0.5840 (0.5950)\n",
      "Valid: [epoch:484]  [ 0/14]  eta: 0:00:05  loss: 0.5849 (0.5849)  time: 0.4144  data: 0.3990  max mem: 20571\n",
      "Valid: [epoch:484]  [13/14]  eta: 0:00:00  loss: 0.5556 (0.5609)  time: 0.0438  data: 0.0288  max mem: 20571\n",
      "Valid: [epoch:484] Total time: 0:00:00 (0.0493 s / it)\n",
      "Averaged stats: loss: 0.5556 (0.5609)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_484_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.561%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:485]  [  0/172]  eta: 0:07:36  lr: 0.000057  loss: 0.5368 (0.5368)  time: 2.6562  data: 1.0727  max mem: 20571\n",
      "Train: [epoch:485]  [ 10/172]  eta: 0:04:31  lr: 0.000057  loss: 0.6108 (0.6013)  time: 1.6762  data: 0.0976  max mem: 20571\n",
      "Train: [epoch:485]  [ 20/172]  eta: 0:04:07  lr: 0.000057  loss: 0.5929 (0.5928)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [ 30/172]  eta: 0:03:49  lr: 0.000057  loss: 0.5922 (0.5939)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [ 40/172]  eta: 0:03:31  lr: 0.000057  loss: 0.5945 (0.5956)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [ 50/172]  eta: 0:03:15  lr: 0.000057  loss: 0.6227 (0.6016)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [ 60/172]  eta: 0:02:58  lr: 0.000057  loss: 0.6087 (0.6008)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [ 70/172]  eta: 0:02:42  lr: 0.000057  loss: 0.5925 (0.5986)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [ 80/172]  eta: 0:02:26  lr: 0.000057  loss: 0.5750 (0.5967)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [ 90/172]  eta: 0:02:10  lr: 0.000057  loss: 0.5860 (0.5964)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [100/172]  eta: 0:01:54  lr: 0.000057  loss: 0.6017 (0.5967)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [110/172]  eta: 0:01:38  lr: 0.000057  loss: 0.6022 (0.5962)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [120/172]  eta: 0:01:22  lr: 0.000057  loss: 0.6001 (0.5968)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [130/172]  eta: 0:01:06  lr: 0.000057  loss: 0.5927 (0.5960)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [140/172]  eta: 0:00:50  lr: 0.000057  loss: 0.5843 (0.5955)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [150/172]  eta: 0:00:34  lr: 0.000057  loss: 0.5935 (0.5959)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [160/172]  eta: 0:00:19  lr: 0.000057  loss: 0.5935 (0.5957)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [170/172]  eta: 0:00:03  lr: 0.000057  loss: 0.5912 (0.5967)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485]  [171/172]  eta: 0:00:01  lr: 0.000057  loss: 0.6005 (0.5969)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:485] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000057  loss: 0.6005 (0.5969)\n",
      "Valid: [epoch:485]  [ 0/14]  eta: 0:00:04  loss: 0.6074 (0.6074)  time: 0.2877  data: 0.2710  max mem: 20571\n",
      "Valid: [epoch:485]  [13/14]  eta: 0:00:00  loss: 0.5727 (0.5774)  time: 0.0393  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:485] Total time: 0:00:00 (0.0479 s / it)\n",
      "Averaged stats: loss: 0.5727 (0.5774)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_485_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.577%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:486]  [  0/172]  eta: 0:08:19  lr: 0.000057  loss: 0.5827 (0.5827)  time: 2.9033  data: 1.3346  max mem: 20571\n",
      "Train: [epoch:486]  [ 10/172]  eta: 0:04:35  lr: 0.000057  loss: 0.5827 (0.5900)  time: 1.7004  data: 0.1215  max mem: 20571\n",
      "Train: [epoch:486]  [ 20/172]  eta: 0:04:09  lr: 0.000057  loss: 0.5839 (0.5980)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:486]  [ 30/172]  eta: 0:03:50  lr: 0.000057  loss: 0.5927 (0.5948)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:486]  [ 40/172]  eta: 0:03:33  lr: 0.000057  loss: 0.5811 (0.5929)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [ 50/172]  eta: 0:03:16  lr: 0.000057  loss: 0.5981 (0.5963)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [ 60/172]  eta: 0:02:59  lr: 0.000057  loss: 0.5981 (0.5948)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [ 70/172]  eta: 0:02:43  lr: 0.000057  loss: 0.5941 (0.5960)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [ 80/172]  eta: 0:02:27  lr: 0.000057  loss: 0.5945 (0.5973)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [ 90/172]  eta: 0:02:10  lr: 0.000057  loss: 0.5866 (0.5966)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [100/172]  eta: 0:01:54  lr: 0.000057  loss: 0.5778 (0.5961)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [110/172]  eta: 0:01:38  lr: 0.000057  loss: 0.5757 (0.5950)  time: 1.5850  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:486]  [120/172]  eta: 0:01:22  lr: 0.000057  loss: 0.5765 (0.5957)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [130/172]  eta: 0:01:06  lr: 0.000057  loss: 0.5911 (0.5964)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [140/172]  eta: 0:00:50  lr: 0.000057  loss: 0.5911 (0.5960)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [150/172]  eta: 0:00:34  lr: 0.000057  loss: 0.5882 (0.5968)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [160/172]  eta: 0:00:19  lr: 0.000057  loss: 0.5882 (0.5967)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [170/172]  eta: 0:00:03  lr: 0.000057  loss: 0.5954 (0.5965)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486]  [171/172]  eta: 0:00:01  lr: 0.000057  loss: 0.5954 (0.5967)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:486] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000057  loss: 0.5954 (0.5967)\n",
      "Valid: [epoch:486]  [ 0/14]  eta: 0:00:05  loss: 0.5381 (0.5381)  time: 0.3912  data: 0.3760  max mem: 20571\n",
      "Valid: [epoch:486]  [13/14]  eta: 0:00:00  loss: 0.5518 (0.5564)  time: 0.0438  data: 0.0287  max mem: 20571\n",
      "Valid: [epoch:486] Total time: 0:00:00 (0.0517 s / it)\n",
      "Averaged stats: loss: 0.5518 (0.5564)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_486_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.556%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:487]  [  0/172]  eta: 0:07:31  lr: 0.000057  loss: 0.5599 (0.5599)  time: 2.6263  data: 1.0315  max mem: 20571\n",
      "Train: [epoch:487]  [ 10/172]  eta: 0:04:30  lr: 0.000057  loss: 0.5687 (0.5843)  time: 1.6719  data: 0.0939  max mem: 20571\n",
      "Train: [epoch:487]  [ 20/172]  eta: 0:04:07  lr: 0.000057  loss: 0.5852 (0.5913)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [ 30/172]  eta: 0:03:48  lr: 0.000057  loss: 0.5916 (0.5967)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [ 40/172]  eta: 0:03:31  lr: 0.000057  loss: 0.5916 (0.5953)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [ 50/172]  eta: 0:03:15  lr: 0.000057  loss: 0.5800 (0.5961)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [ 60/172]  eta: 0:02:58  lr: 0.000057  loss: 0.5881 (0.5968)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [ 70/172]  eta: 0:02:42  lr: 0.000057  loss: 0.5929 (0.5970)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [ 80/172]  eta: 0:02:26  lr: 0.000057  loss: 0.5953 (0.5964)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [ 90/172]  eta: 0:02:10  lr: 0.000057  loss: 0.5910 (0.5969)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [100/172]  eta: 0:01:54  lr: 0.000057  loss: 0.5875 (0.5956)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [110/172]  eta: 0:01:38  lr: 0.000057  loss: 0.6085 (0.5987)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [120/172]  eta: 0:01:22  lr: 0.000057  loss: 0.6142 (0.5994)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [130/172]  eta: 0:01:06  lr: 0.000057  loss: 0.5910 (0.5984)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [140/172]  eta: 0:00:50  lr: 0.000057  loss: 0.5906 (0.5986)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [150/172]  eta: 0:00:34  lr: 0.000057  loss: 0.5833 (0.5974)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [160/172]  eta: 0:00:19  lr: 0.000057  loss: 0.5833 (0.5976)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [170/172]  eta: 0:00:03  lr: 0.000057  loss: 0.5899 (0.5977)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487]  [171/172]  eta: 0:00:01  lr: 0.000057  loss: 0.5868 (0.5976)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:487] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000057  loss: 0.5868 (0.5976)\n",
      "Valid: [epoch:487]  [ 0/14]  eta: 0:00:04  loss: 0.4988 (0.4988)  time: 0.2959  data: 0.2813  max mem: 20571\n",
      "Valid: [epoch:487]  [13/14]  eta: 0:00:00  loss: 0.5565 (0.5620)  time: 0.0391  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:487] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.5565 (0.5620)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_487_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.562%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:488]  [  0/172]  eta: 0:07:59  lr: 0.000057  loss: 0.5704 (0.5704)  time: 2.7903  data: 1.2079  max mem: 20571\n",
      "Train: [epoch:488]  [ 10/172]  eta: 0:04:33  lr: 0.000057  loss: 0.5951 (0.6018)  time: 1.6896  data: 0.1099  max mem: 20571\n",
      "Train: [epoch:488]  [ 20/172]  eta: 0:04:08  lr: 0.000057  loss: 0.5951 (0.6011)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [ 30/172]  eta: 0:03:49  lr: 0.000057  loss: 0.5935 (0.5994)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [ 40/172]  eta: 0:03:32  lr: 0.000057  loss: 0.5930 (0.5977)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [ 50/172]  eta: 0:03:15  lr: 0.000057  loss: 0.5930 (0.5989)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [ 60/172]  eta: 0:02:59  lr: 0.000057  loss: 0.6018 (0.5993)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:488]  [ 70/172]  eta: 0:02:42  lr: 0.000057  loss: 0.5853 (0.5968)  time: 1.5776  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:488]  [ 80/172]  eta: 0:02:26  lr: 0.000057  loss: 0.5841 (0.5980)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [ 90/172]  eta: 0:02:10  lr: 0.000057  loss: 0.5926 (0.5980)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [100/172]  eta: 0:01:54  lr: 0.000057  loss: 0.5841 (0.5967)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [110/172]  eta: 0:01:38  lr: 0.000057  loss: 0.5841 (0.5969)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [120/172]  eta: 0:01:22  lr: 0.000057  loss: 0.6171 (0.5998)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [130/172]  eta: 0:01:06  lr: 0.000057  loss: 0.5853 (0.5985)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [140/172]  eta: 0:00:50  lr: 0.000057  loss: 0.5838 (0.5991)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [150/172]  eta: 0:00:34  lr: 0.000057  loss: 0.6020 (0.5996)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [160/172]  eta: 0:00:19  lr: 0.000057  loss: 0.5871 (0.5988)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [170/172]  eta: 0:00:03  lr: 0.000057  loss: 0.5834 (0.5986)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488]  [171/172]  eta: 0:00:01  lr: 0.000057  loss: 0.5834 (0.5989)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:488] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000057  loss: 0.5834 (0.5989)\n",
      "Valid: [epoch:488]  [ 0/14]  eta: 0:00:05  loss: 0.5938 (0.5938)  time: 0.4156  data: 0.3982  max mem: 20571\n",
      "Valid: [epoch:488]  [13/14]  eta: 0:00:00  loss: 0.5582 (0.5636)  time: 0.0437  data: 0.0285  max mem: 20571\n",
      "Valid: [epoch:488] Total time: 0:00:00 (0.0526 s / it)\n",
      "Averaged stats: loss: 0.5582 (0.5636)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_488_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.564%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:489]  [  0/172]  eta: 0:07:27  lr: 0.000057  loss: 0.5650 (0.5650)  time: 2.6032  data: 1.0221  max mem: 20571\n",
      "Train: [epoch:489]  [ 10/172]  eta: 0:04:30  lr: 0.000057  loss: 0.5902 (0.5972)  time: 1.6690  data: 0.0930  max mem: 20571\n",
      "Train: [epoch:489]  [ 20/172]  eta: 0:04:06  lr: 0.000057  loss: 0.6103 (0.6015)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [ 30/172]  eta: 0:03:48  lr: 0.000057  loss: 0.6008 (0.5994)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [ 40/172]  eta: 0:03:31  lr: 0.000057  loss: 0.5995 (0.5998)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [ 50/172]  eta: 0:03:14  lr: 0.000057  loss: 0.6024 (0.6037)  time: 1.5777  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:489]  [ 60/172]  eta: 0:02:58  lr: 0.000057  loss: 0.6018 (0.6029)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [ 70/172]  eta: 0:02:42  lr: 0.000057  loss: 0.5971 (0.6026)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [ 80/172]  eta: 0:02:26  lr: 0.000057  loss: 0.5997 (0.6020)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [ 90/172]  eta: 0:02:10  lr: 0.000057  loss: 0.5896 (0.6010)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [100/172]  eta: 0:01:54  lr: 0.000057  loss: 0.5887 (0.6001)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [110/172]  eta: 0:01:38  lr: 0.000057  loss: 0.5846 (0.5990)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [120/172]  eta: 0:01:22  lr: 0.000057  loss: 0.5815 (0.5981)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [130/172]  eta: 0:01:06  lr: 0.000057  loss: 0.5852 (0.5968)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [140/172]  eta: 0:00:50  lr: 0.000057  loss: 0.5867 (0.5971)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [150/172]  eta: 0:00:34  lr: 0.000057  loss: 0.5953 (0.5977)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [160/172]  eta: 0:00:19  lr: 0.000057  loss: 0.6044 (0.5984)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [170/172]  eta: 0:00:03  lr: 0.000057  loss: 0.5878 (0.5978)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489]  [171/172]  eta: 0:00:01  lr: 0.000057  loss: 0.5878 (0.5982)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:489] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000057  loss: 0.5878 (0.5982)\n",
      "Valid: [epoch:489]  [ 0/14]  eta: 0:00:07  loss: 0.5274 (0.5274)  time: 0.5221  data: 0.5050  max mem: 20571\n",
      "Valid: [epoch:489]  [13/14]  eta: 0:00:00  loss: 0.5698 (0.5751)  time: 0.0522  data: 0.0370  max mem: 20571\n",
      "Valid: [epoch:489] Total time: 0:00:00 (0.0573 s / it)\n",
      "Averaged stats: loss: 0.5698 (0.5751)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_489_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.575%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:490]  [  0/172]  eta: 0:08:00  lr: 0.000057  loss: 0.6198 (0.6198)  time: 2.7919  data: 1.2227  max mem: 20571\n",
      "Train: [epoch:490]  [ 10/172]  eta: 0:04:33  lr: 0.000057  loss: 0.6057 (0.6066)  time: 1.6908  data: 0.1113  max mem: 20571\n",
      "Train: [epoch:490]  [ 20/172]  eta: 0:04:09  lr: 0.000057  loss: 0.5941 (0.6005)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [ 30/172]  eta: 0:03:50  lr: 0.000057  loss: 0.5908 (0.5971)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [ 40/172]  eta: 0:03:32  lr: 0.000057  loss: 0.5897 (0.5950)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [ 50/172]  eta: 0:03:16  lr: 0.000057  loss: 0.5897 (0.5971)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [ 60/172]  eta: 0:02:59  lr: 0.000057  loss: 0.5922 (0.5965)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [ 70/172]  eta: 0:02:43  lr: 0.000057  loss: 0.5827 (0.5977)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [ 80/172]  eta: 0:02:26  lr: 0.000057  loss: 0.6016 (0.5995)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [ 90/172]  eta: 0:02:10  lr: 0.000057  loss: 0.6016 (0.5984)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [100/172]  eta: 0:01:54  lr: 0.000057  loss: 0.5832 (0.5972)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [110/172]  eta: 0:01:38  lr: 0.000057  loss: 0.5870 (0.5977)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [120/172]  eta: 0:01:22  lr: 0.000057  loss: 0.5953 (0.5982)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [130/172]  eta: 0:01:06  lr: 0.000057  loss: 0.5949 (0.5987)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [140/172]  eta: 0:00:50  lr: 0.000057  loss: 0.5947 (0.5984)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [150/172]  eta: 0:00:34  lr: 0.000057  loss: 0.6010 (0.5986)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [160/172]  eta: 0:00:19  lr: 0.000057  loss: 0.6022 (0.5984)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [170/172]  eta: 0:00:03  lr: 0.000057  loss: 0.5867 (0.5983)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490]  [171/172]  eta: 0:00:01  lr: 0.000057  loss: 0.5867 (0.5985)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:490] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000057  loss: 0.5867 (0.5985)\n",
      "Valid: [epoch:490]  [ 0/14]  eta: 0:00:04  loss: 0.6074 (0.6074)  time: 0.2871  data: 0.2719  max mem: 20571\n",
      "Valid: [epoch:490]  [13/14]  eta: 0:00:00  loss: 0.5615 (0.5657)  time: 0.0389  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:490] Total time: 0:00:00 (0.0436 s / it)\n",
      "Averaged stats: loss: 0.5615 (0.5657)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_490_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.566%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:491]  [  0/172]  eta: 0:08:02  lr: 0.000057  loss: 0.6883 (0.6883)  time: 2.8063  data: 1.2317  max mem: 20571\n",
      "Train: [epoch:491]  [ 10/172]  eta: 0:04:33  lr: 0.000057  loss: 0.6008 (0.6106)  time: 1.6890  data: 0.1121  max mem: 20571\n",
      "Train: [epoch:491]  [ 20/172]  eta: 0:04:08  lr: 0.000057  loss: 0.5997 (0.6095)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [ 30/172]  eta: 0:03:49  lr: 0.000057  loss: 0.5936 (0.6050)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [ 40/172]  eta: 0:03:32  lr: 0.000057  loss: 0.5928 (0.6027)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [ 50/172]  eta: 0:03:15  lr: 0.000057  loss: 0.5887 (0.5989)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [ 60/172]  eta: 0:02:59  lr: 0.000057  loss: 0.5804 (0.5965)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [ 70/172]  eta: 0:02:42  lr: 0.000057  loss: 0.5919 (0.5990)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [ 80/172]  eta: 0:02:26  lr: 0.000057  loss: 0.5919 (0.5979)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [ 90/172]  eta: 0:02:10  lr: 0.000057  loss: 0.5932 (0.5983)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [100/172]  eta: 0:01:54  lr: 0.000057  loss: 0.6113 (0.5999)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [110/172]  eta: 0:01:38  lr: 0.000057  loss: 0.6113 (0.5992)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [120/172]  eta: 0:01:22  lr: 0.000057  loss: 0.6054 (0.5990)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [130/172]  eta: 0:01:06  lr: 0.000057  loss: 0.6044 (0.5993)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [140/172]  eta: 0:00:50  lr: 0.000057  loss: 0.5988 (0.5995)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [150/172]  eta: 0:00:34  lr: 0.000057  loss: 0.5944 (0.5990)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [160/172]  eta: 0:00:19  lr: 0.000057  loss: 0.5939 (0.5999)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [170/172]  eta: 0:00:03  lr: 0.000057  loss: 0.5981 (0.5999)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491]  [171/172]  eta: 0:00:01  lr: 0.000057  loss: 0.5981 (0.6001)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:491] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000057  loss: 0.5981 (0.6001)\n",
      "Valid: [epoch:491]  [ 0/14]  eta: 0:00:03  loss: 0.5563 (0.5563)  time: 0.2731  data: 0.2584  max mem: 20571\n",
      "Valid: [epoch:491]  [13/14]  eta: 0:00:00  loss: 0.5705 (0.5742)  time: 0.0346  data: 0.0195  max mem: 20571\n",
      "Valid: [epoch:491] Total time: 0:00:00 (0.0428 s / it)\n",
      "Averaged stats: loss: 0.5705 (0.5742)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_491_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.574%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:492]  [  0/172]  eta: 0:07:31  lr: 0.000057  loss: 0.6248 (0.6248)  time: 2.6261  data: 1.0404  max mem: 20571\n",
      "Train: [epoch:492]  [ 10/172]  eta: 0:04:31  lr: 0.000057  loss: 0.6096 (0.6110)  time: 1.6777  data: 0.0947  max mem: 20571\n",
      "Train: [epoch:492]  [ 20/172]  eta: 0:04:08  lr: 0.000057  loss: 0.5950 (0.6057)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [ 30/172]  eta: 0:03:49  lr: 0.000057  loss: 0.5905 (0.6082)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [ 40/172]  eta: 0:03:32  lr: 0.000057  loss: 0.5929 (0.6047)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [ 50/172]  eta: 0:03:15  lr: 0.000057  loss: 0.5929 (0.6037)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [ 60/172]  eta: 0:02:59  lr: 0.000057  loss: 0.5913 (0.6014)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [ 70/172]  eta: 0:02:42  lr: 0.000057  loss: 0.5913 (0.6027)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [ 80/172]  eta: 0:02:26  lr: 0.000057  loss: 0.5965 (0.6028)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [ 90/172]  eta: 0:02:10  lr: 0.000057  loss: 0.5960 (0.6016)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [100/172]  eta: 0:01:54  lr: 0.000057  loss: 0.6029 (0.6037)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [110/172]  eta: 0:01:38  lr: 0.000057  loss: 0.6044 (0.6043)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [120/172]  eta: 0:01:22  lr: 0.000057  loss: 0.5974 (0.6046)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [130/172]  eta: 0:01:06  lr: 0.000057  loss: 0.5875 (0.6030)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [140/172]  eta: 0:00:50  lr: 0.000057  loss: 0.5908 (0.6032)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [150/172]  eta: 0:00:34  lr: 0.000057  loss: 0.6036 (0.6021)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [160/172]  eta: 0:00:19  lr: 0.000057  loss: 0.6022 (0.6028)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [170/172]  eta: 0:00:03  lr: 0.000057  loss: 0.6080 (0.6022)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492]  [171/172]  eta: 0:00:01  lr: 0.000057  loss: 0.6083 (0.6023)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:492] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000057  loss: 0.6083 (0.6023)\n",
      "Valid: [epoch:492]  [ 0/14]  eta: 0:00:04  loss: 0.5472 (0.5472)  time: 0.3198  data: 0.3042  max mem: 20571\n",
      "Valid: [epoch:492]  [13/14]  eta: 0:00:00  loss: 0.5604 (0.5647)  time: 0.0377  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:492] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.5604 (0.5647)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_492_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.565%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:493]  [  0/172]  eta: 0:07:30  lr: 0.000056  loss: 0.5143 (0.5143)  time: 2.6206  data: 1.0341  max mem: 20571\n",
      "Train: [epoch:493]  [ 10/172]  eta: 0:04:31  lr: 0.000056  loss: 0.5938 (0.5874)  time: 1.6766  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:493]  [ 20/172]  eta: 0:04:08  lr: 0.000056  loss: 0.6030 (0.5932)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [ 30/172]  eta: 0:03:49  lr: 0.000056  loss: 0.6115 (0.5987)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [ 40/172]  eta: 0:03:32  lr: 0.000056  loss: 0.5809 (0.5979)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [ 50/172]  eta: 0:03:15  lr: 0.000056  loss: 0.5928 (0.5987)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [ 60/172]  eta: 0:02:59  lr: 0.000056  loss: 0.5950 (0.5978)  time: 1.5842  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:493]  [ 70/172]  eta: 0:02:43  lr: 0.000056  loss: 0.5941 (0.5968)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:493]  [ 80/172]  eta: 0:02:26  lr: 0.000056  loss: 0.5999 (0.5983)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [ 90/172]  eta: 0:02:10  lr: 0.000056  loss: 0.6070 (0.5992)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [100/172]  eta: 0:01:54  lr: 0.000056  loss: 0.6076 (0.5988)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [110/172]  eta: 0:01:38  lr: 0.000056  loss: 0.6078 (0.5995)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [120/172]  eta: 0:01:22  lr: 0.000056  loss: 0.6086 (0.6000)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [130/172]  eta: 0:01:06  lr: 0.000056  loss: 0.6037 (0.6010)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [140/172]  eta: 0:00:50  lr: 0.000056  loss: 0.5888 (0.5998)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [150/172]  eta: 0:00:35  lr: 0.000056  loss: 0.5882 (0.5998)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [160/172]  eta: 0:00:19  lr: 0.000056  loss: 0.6009 (0.6003)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [170/172]  eta: 0:00:03  lr: 0.000056  loss: 0.5992 (0.6003)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493]  [171/172]  eta: 0:00:01  lr: 0.000056  loss: 0.5920 (0.6002)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:493] Total time: 0:04:33 (1.5912 s / it)\n",
      "Averaged stats: lr: 0.000056  loss: 0.5920 (0.6002)\n",
      "Valid: [epoch:493]  [ 0/14]  eta: 0:00:04  loss: 0.5312 (0.5312)  time: 0.2930  data: 0.2781  max mem: 20571\n",
      "Valid: [epoch:493]  [13/14]  eta: 0:00:00  loss: 0.5614 (0.5663)  time: 0.0381  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:493] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.5614 (0.5663)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_493_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.566%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:494]  [  0/172]  eta: 0:08:26  lr: 0.000056  loss: 0.5705 (0.5705)  time: 2.9473  data: 1.3788  max mem: 20571\n",
      "Train: [epoch:494]  [ 10/172]  eta: 0:04:36  lr: 0.000056  loss: 0.5851 (0.5984)  time: 1.7052  data: 0.1255  max mem: 20571\n",
      "Train: [epoch:494]  [ 20/172]  eta: 0:04:10  lr: 0.000056  loss: 0.5946 (0.5990)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [ 30/172]  eta: 0:03:50  lr: 0.000056  loss: 0.5968 (0.6025)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [ 40/172]  eta: 0:03:33  lr: 0.000056  loss: 0.6000 (0.6032)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [ 50/172]  eta: 0:03:16  lr: 0.000056  loss: 0.5970 (0.6034)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [ 60/172]  eta: 0:02:59  lr: 0.000056  loss: 0.6081 (0.6051)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [ 70/172]  eta: 0:02:43  lr: 0.000056  loss: 0.6002 (0.6038)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [ 80/172]  eta: 0:02:27  lr: 0.000056  loss: 0.5870 (0.6010)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [ 90/172]  eta: 0:02:10  lr: 0.000056  loss: 0.6040 (0.6036)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [100/172]  eta: 0:01:54  lr: 0.000056  loss: 0.6103 (0.6032)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [110/172]  eta: 0:01:38  lr: 0.000056  loss: 0.6071 (0.6034)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [120/172]  eta: 0:01:22  lr: 0.000056  loss: 0.6102 (0.6043)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [130/172]  eta: 0:01:06  lr: 0.000056  loss: 0.6039 (0.6038)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [140/172]  eta: 0:00:50  lr: 0.000056  loss: 0.5891 (0.6027)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [150/172]  eta: 0:00:34  lr: 0.000056  loss: 0.6040 (0.6026)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [160/172]  eta: 0:00:19  lr: 0.000056  loss: 0.6044 (0.6021)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494]  [170/172]  eta: 0:00:03  lr: 0.000056  loss: 0.5982 (0.6021)  time: 1.5805  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:494]  [171/172]  eta: 0:00:01  lr: 0.000056  loss: 0.5982 (0.6021)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:494] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000056  loss: 0.5982 (0.6021)\n",
      "Valid: [epoch:494]  [ 0/14]  eta: 0:00:03  loss: 0.5445 (0.5445)  time: 0.2757  data: 0.2603  max mem: 20571\n",
      "Valid: [epoch:494]  [13/14]  eta: 0:00:00  loss: 0.5749 (0.5799)  time: 0.0395  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:494] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.5749 (0.5799)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_494_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.580%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:495]  [  0/172]  eta: 0:08:00  lr: 0.000056  loss: 0.6303 (0.6303)  time: 2.7928  data: 1.2151  max mem: 20571\n",
      "Train: [epoch:495]  [ 10/172]  eta: 0:04:33  lr: 0.000056  loss: 0.5955 (0.6049)  time: 1.6865  data: 0.1106  max mem: 20571\n",
      "Train: [epoch:495]  [ 20/172]  eta: 0:04:08  lr: 0.000056  loss: 0.5974 (0.6085)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [ 30/172]  eta: 0:03:49  lr: 0.000056  loss: 0.6000 (0.6087)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [ 40/172]  eta: 0:03:32  lr: 0.000056  loss: 0.5956 (0.6077)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [ 50/172]  eta: 0:03:15  lr: 0.000056  loss: 0.5932 (0.6065)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [ 60/172]  eta: 0:02:59  lr: 0.000056  loss: 0.5920 (0.6056)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [ 70/172]  eta: 0:02:42  lr: 0.000056  loss: 0.5826 (0.6053)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [ 80/172]  eta: 0:02:26  lr: 0.000056  loss: 0.6066 (0.6053)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [ 90/172]  eta: 0:02:10  lr: 0.000056  loss: 0.6000 (0.6035)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [100/172]  eta: 0:01:54  lr: 0.000056  loss: 0.5959 (0.6034)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [110/172]  eta: 0:01:38  lr: 0.000056  loss: 0.6046 (0.6030)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [120/172]  eta: 0:01:22  lr: 0.000056  loss: 0.5966 (0.6023)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [130/172]  eta: 0:01:06  lr: 0.000056  loss: 0.5962 (0.6027)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [140/172]  eta: 0:00:50  lr: 0.000056  loss: 0.5955 (0.6026)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [150/172]  eta: 0:00:34  lr: 0.000056  loss: 0.5966 (0.6021)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [160/172]  eta: 0:00:19  lr: 0.000056  loss: 0.5911 (0.6013)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [170/172]  eta: 0:00:03  lr: 0.000056  loss: 0.5998 (0.6019)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495]  [171/172]  eta: 0:00:01  lr: 0.000056  loss: 0.5998 (0.6018)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:495] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000056  loss: 0.5998 (0.6018)\n",
      "Valid: [epoch:495]  [ 0/14]  eta: 0:00:04  loss: 0.6095 (0.6095)  time: 0.2885  data: 0.2716  max mem: 20571\n",
      "Valid: [epoch:495]  [13/14]  eta: 0:00:00  loss: 0.5741 (0.5797)  time: 0.0365  data: 0.0213  max mem: 20571\n",
      "Valid: [epoch:495] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.5741 (0.5797)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_495_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.580%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:496]  [  0/172]  eta: 0:07:24  lr: 0.000056  loss: 0.6057 (0.6057)  time: 2.5818  data: 1.0138  max mem: 20571\n",
      "Train: [epoch:496]  [ 10/172]  eta: 0:04:31  lr: 0.000056  loss: 0.5997 (0.5998)  time: 1.6732  data: 0.0923  max mem: 20571\n",
      "Train: [epoch:496]  [ 20/172]  eta: 0:04:07  lr: 0.000056  loss: 0.5997 (0.6055)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [ 30/172]  eta: 0:03:49  lr: 0.000056  loss: 0.5999 (0.6032)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [ 40/172]  eta: 0:03:32  lr: 0.000056  loss: 0.5823 (0.6020)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [ 50/172]  eta: 0:03:15  lr: 0.000056  loss: 0.5989 (0.6068)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [ 60/172]  eta: 0:02:59  lr: 0.000056  loss: 0.6070 (0.6062)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [ 70/172]  eta: 0:02:42  lr: 0.000056  loss: 0.6001 (0.6070)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [ 80/172]  eta: 0:02:26  lr: 0.000056  loss: 0.5943 (0.6071)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [ 90/172]  eta: 0:02:10  lr: 0.000056  loss: 0.5913 (0.6070)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [100/172]  eta: 0:01:54  lr: 0.000056  loss: 0.5796 (0.6062)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [110/172]  eta: 0:01:38  lr: 0.000056  loss: 0.6030 (0.6071)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [120/172]  eta: 0:01:22  lr: 0.000056  loss: 0.5954 (0.6061)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [130/172]  eta: 0:01:06  lr: 0.000056  loss: 0.5899 (0.6050)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [140/172]  eta: 0:00:50  lr: 0.000056  loss: 0.6044 (0.6062)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [150/172]  eta: 0:00:34  lr: 0.000056  loss: 0.6047 (0.6061)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [160/172]  eta: 0:00:19  lr: 0.000056  loss: 0.5927 (0.6057)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [170/172]  eta: 0:00:03  lr: 0.000056  loss: 0.5927 (0.6052)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496]  [171/172]  eta: 0:00:01  lr: 0.000056  loss: 0.5987 (0.6054)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:496] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000056  loss: 0.5987 (0.6054)\n",
      "Valid: [epoch:496]  [ 0/14]  eta: 0:00:04  loss: 0.6029 (0.6029)  time: 0.3108  data: 0.2935  max mem: 20571\n",
      "Valid: [epoch:496]  [13/14]  eta: 0:00:00  loss: 0.5675 (0.5717)  time: 0.0370  data: 0.0217  max mem: 20571\n",
      "Valid: [epoch:496] Total time: 0:00:00 (0.0418 s / it)\n",
      "Averaged stats: loss: 0.5675 (0.5717)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_496_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.572%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:497]  [  0/172]  eta: 0:07:39  lr: 0.000056  loss: 0.6064 (0.6064)  time: 2.6704  data: 1.0969  max mem: 20571\n",
      "Train: [epoch:497]  [ 10/172]  eta: 0:04:31  lr: 0.000056  loss: 0.6075 (0.6077)  time: 1.6770  data: 0.0998  max mem: 20571\n",
      "Train: [epoch:497]  [ 20/172]  eta: 0:04:07  lr: 0.000056  loss: 0.6075 (0.6107)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [ 30/172]  eta: 0:03:49  lr: 0.000056  loss: 0.6024 (0.6057)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [ 40/172]  eta: 0:03:32  lr: 0.000056  loss: 0.5893 (0.6043)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [ 50/172]  eta: 0:03:15  lr: 0.000056  loss: 0.5867 (0.6026)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [ 60/172]  eta: 0:02:59  lr: 0.000056  loss: 0.5957 (0.6034)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [ 70/172]  eta: 0:02:42  lr: 0.000056  loss: 0.5949 (0.6025)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [ 80/172]  eta: 0:02:26  lr: 0.000056  loss: 0.5949 (0.6034)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [ 90/172]  eta: 0:02:10  lr: 0.000056  loss: 0.6132 (0.6044)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [100/172]  eta: 0:01:54  lr: 0.000056  loss: 0.5972 (0.6042)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [110/172]  eta: 0:01:38  lr: 0.000056  loss: 0.5989 (0.6051)  time: 1.5842  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:497]  [120/172]  eta: 0:01:22  lr: 0.000056  loss: 0.6116 (0.6049)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [130/172]  eta: 0:01:06  lr: 0.000056  loss: 0.5996 (0.6051)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [140/172]  eta: 0:00:50  lr: 0.000056  loss: 0.5948 (0.6039)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:497]  [150/172]  eta: 0:00:34  lr: 0.000056  loss: 0.5974 (0.6041)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:497]  [160/172]  eta: 0:00:19  lr: 0.000056  loss: 0.6019 (0.6036)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:497]  [170/172]  eta: 0:00:03  lr: 0.000056  loss: 0.5992 (0.6037)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497]  [171/172]  eta: 0:00:01  lr: 0.000056  loss: 0.5992 (0.6039)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:497] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000056  loss: 0.5992 (0.6039)\n",
      "Valid: [epoch:497]  [ 0/14]  eta: 0:00:04  loss: 0.5295 (0.5295)  time: 0.3149  data: 0.2973  max mem: 20571\n",
      "Valid: [epoch:497]  [13/14]  eta: 0:00:00  loss: 0.5756 (0.5810)  time: 0.0423  data: 0.0271  max mem: 20571\n",
      "Valid: [epoch:497] Total time: 0:00:00 (0.0507 s / it)\n",
      "Averaged stats: loss: 0.5756 (0.5810)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_497_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.581%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:498]  [  0/172]  eta: 0:08:15  lr: 0.000056  loss: 0.5988 (0.5988)  time: 2.8816  data: 1.2951  max mem: 20571\n",
      "Train: [epoch:498]  [ 10/172]  eta: 0:04:34  lr: 0.000056  loss: 0.6037 (0.6018)  time: 1.6967  data: 0.1179  max mem: 20571\n",
      "Train: [epoch:498]  [ 20/172]  eta: 0:04:09  lr: 0.000056  loss: 0.6062 (0.6117)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [ 30/172]  eta: 0:03:50  lr: 0.000056  loss: 0.6004 (0.6030)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [ 40/172]  eta: 0:03:32  lr: 0.000056  loss: 0.5999 (0.6022)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [ 50/172]  eta: 0:03:15  lr: 0.000056  loss: 0.6011 (0.6022)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [ 60/172]  eta: 0:02:59  lr: 0.000056  loss: 0.6035 (0.6051)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [ 70/172]  eta: 0:02:43  lr: 0.000056  loss: 0.6043 (0.6053)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [ 80/172]  eta: 0:02:26  lr: 0.000056  loss: 0.6005 (0.6045)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [ 90/172]  eta: 0:02:10  lr: 0.000056  loss: 0.5947 (0.6045)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [100/172]  eta: 0:01:54  lr: 0.000056  loss: 0.5988 (0.6043)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [110/172]  eta: 0:01:38  lr: 0.000056  loss: 0.6160 (0.6060)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [120/172]  eta: 0:01:22  lr: 0.000056  loss: 0.6148 (0.6061)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [130/172]  eta: 0:01:06  lr: 0.000056  loss: 0.6018 (0.6061)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [140/172]  eta: 0:00:50  lr: 0.000056  loss: 0.6053 (0.6067)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [150/172]  eta: 0:00:34  lr: 0.000056  loss: 0.5999 (0.6057)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [160/172]  eta: 0:00:19  lr: 0.000056  loss: 0.5999 (0.6058)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [170/172]  eta: 0:00:03  lr: 0.000056  loss: 0.6077 (0.6055)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498]  [171/172]  eta: 0:00:01  lr: 0.000056  loss: 0.6077 (0.6056)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:498] Total time: 0:04:33 (1.5905 s / it)\n",
      "Averaged stats: lr: 0.000056  loss: 0.6077 (0.6056)\n",
      "Valid: [epoch:498]  [ 0/14]  eta: 0:00:04  loss: 0.5429 (0.5429)  time: 0.2943  data: 0.2795  max mem: 20571\n",
      "Valid: [epoch:498]  [13/14]  eta: 0:00:00  loss: 0.5714 (0.5771)  time: 0.0366  data: 0.0216  max mem: 20571\n",
      "Valid: [epoch:498] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.5714 (0.5771)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_498_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.577%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:499]  [  0/172]  eta: 0:07:59  lr: 0.000056  loss: 0.6000 (0.6000)  time: 2.7870  data: 1.2075  max mem: 20571\n",
      "Train: [epoch:499]  [ 10/172]  eta: 0:04:33  lr: 0.000056  loss: 0.6232 (0.6048)  time: 1.6885  data: 0.1099  max mem: 20571\n",
      "Train: [epoch:499]  [ 20/172]  eta: 0:04:09  lr: 0.000056  loss: 0.6008 (0.6007)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [ 30/172]  eta: 0:03:50  lr: 0.000056  loss: 0.5951 (0.6010)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [ 40/172]  eta: 0:03:32  lr: 0.000056  loss: 0.5951 (0.5994)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [ 50/172]  eta: 0:03:16  lr: 0.000056  loss: 0.5960 (0.5990)  time: 1.5855  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:499]  [ 60/172]  eta: 0:02:59  lr: 0.000056  loss: 0.6005 (0.6015)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [ 70/172]  eta: 0:02:43  lr: 0.000056  loss: 0.6008 (0.6027)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [ 80/172]  eta: 0:02:27  lr: 0.000056  loss: 0.5965 (0.6043)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [ 90/172]  eta: 0:02:10  lr: 0.000056  loss: 0.5957 (0.6046)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [100/172]  eta: 0:01:54  lr: 0.000056  loss: 0.5996 (0.6039)  time: 1.5834  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:499]  [110/172]  eta: 0:01:38  lr: 0.000056  loss: 0.6047 (0.6045)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [120/172]  eta: 0:01:22  lr: 0.000056  loss: 0.6047 (0.6066)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [130/172]  eta: 0:01:06  lr: 0.000056  loss: 0.6135 (0.6072)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [140/172]  eta: 0:00:50  lr: 0.000056  loss: 0.6002 (0.6062)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [150/172]  eta: 0:00:35  lr: 0.000056  loss: 0.5934 (0.6058)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [160/172]  eta: 0:00:19  lr: 0.000056  loss: 0.5984 (0.6069)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [170/172]  eta: 0:00:03  lr: 0.000056  loss: 0.6109 (0.6069)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499]  [171/172]  eta: 0:00:01  lr: 0.000056  loss: 0.6109 (0.6073)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:499] Total time: 0:04:33 (1.5911 s / it)\n",
      "Averaged stats: lr: 0.000056  loss: 0.6109 (0.6073)\n",
      "Valid: [epoch:499]  [ 0/14]  eta: 0:00:04  loss: 0.5751 (0.5751)  time: 0.3508  data: 0.3355  max mem: 20571\n",
      "Valid: [epoch:499]  [13/14]  eta: 0:00:00  loss: 0.5751 (0.5809)  time: 0.0392  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:499] Total time: 0:00:00 (0.0440 s / it)\n",
      "Averaged stats: loss: 0.5751 (0.5809)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_499_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.581%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:500]  [  0/172]  eta: 0:08:47  lr: 0.000056  loss: 0.5738 (0.5738)  time: 3.0691  data: 1.4874  max mem: 20571\n",
      "Train: [epoch:500]  [ 10/172]  eta: 0:04:38  lr: 0.000056  loss: 0.6129 (0.6142)  time: 1.7175  data: 0.1353  max mem: 20571\n",
      "Train: [epoch:500]  [ 20/172]  eta: 0:04:11  lr: 0.000056  loss: 0.6107 (0.6131)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [ 30/172]  eta: 0:03:51  lr: 0.000056  loss: 0.6038 (0.6073)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [ 40/172]  eta: 0:03:33  lr: 0.000056  loss: 0.5913 (0.6045)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [ 50/172]  eta: 0:03:16  lr: 0.000056  loss: 0.6012 (0.6075)  time: 1.5840  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:500]  [ 60/172]  eta: 0:02:59  lr: 0.000056  loss: 0.6099 (0.6071)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [ 70/172]  eta: 0:02:43  lr: 0.000056  loss: 0.6065 (0.6073)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [ 80/172]  eta: 0:02:27  lr: 0.000056  loss: 0.6003 (0.6060)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [ 90/172]  eta: 0:02:11  lr: 0.000056  loss: 0.5968 (0.6058)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [100/172]  eta: 0:01:54  lr: 0.000056  loss: 0.5984 (0.6050)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [110/172]  eta: 0:01:38  lr: 0.000056  loss: 0.6044 (0.6053)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [120/172]  eta: 0:01:22  lr: 0.000056  loss: 0.6051 (0.6053)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [130/172]  eta: 0:01:06  lr: 0.000056  loss: 0.6004 (0.6039)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [140/172]  eta: 0:00:50  lr: 0.000056  loss: 0.5971 (0.6043)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [150/172]  eta: 0:00:35  lr: 0.000056  loss: 0.6032 (0.6051)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [160/172]  eta: 0:00:19  lr: 0.000056  loss: 0.6056 (0.6053)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [170/172]  eta: 0:00:03  lr: 0.000056  loss: 0.6056 (0.6061)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500]  [171/172]  eta: 0:00:01  lr: 0.000056  loss: 0.6056 (0.6064)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:500] Total time: 0:04:33 (1.5907 s / it)\n",
      "Averaged stats: lr: 0.000056  loss: 0.6056 (0.6064)\n",
      "Valid: [epoch:500]  [ 0/14]  eta: 0:00:04  loss: 0.5086 (0.5086)  time: 0.3000  data: 0.2833  max mem: 20571\n",
      "Valid: [epoch:500]  [13/14]  eta: 0:00:00  loss: 0.5696 (0.5747)  time: 0.0460  data: 0.0310  max mem: 20571\n",
      "Valid: [epoch:500] Total time: 0:00:00 (0.0545 s / it)\n",
      "Averaged stats: loss: 0.5696 (0.5747)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_500_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.575%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:501]  [  0/172]  eta: 0:07:57  lr: 0.000056  loss: 0.5949 (0.5949)  time: 2.7761  data: 1.2028  max mem: 20571\n",
      "Train: [epoch:501]  [ 10/172]  eta: 0:04:32  lr: 0.000056  loss: 0.6143 (0.6235)  time: 1.6825  data: 0.1095  max mem: 20571\n",
      "Train: [epoch:501]  [ 20/172]  eta: 0:04:08  lr: 0.000056  loss: 0.6132 (0.6192)  time: 1.5747  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:501]  [ 30/172]  eta: 0:03:49  lr: 0.000056  loss: 0.6063 (0.6150)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:501]  [ 40/172]  eta: 0:03:32  lr: 0.000056  loss: 0.5922 (0.6119)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [ 50/172]  eta: 0:03:15  lr: 0.000056  loss: 0.6009 (0.6143)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [ 60/172]  eta: 0:02:58  lr: 0.000056  loss: 0.6009 (0.6133)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [ 70/172]  eta: 0:02:42  lr: 0.000056  loss: 0.6037 (0.6140)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [ 80/172]  eta: 0:02:26  lr: 0.000056  loss: 0.6093 (0.6122)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:501]  [ 90/172]  eta: 0:02:10  lr: 0.000056  loss: 0.6091 (0.6128)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [100/172]  eta: 0:01:54  lr: 0.000056  loss: 0.6039 (0.6117)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [110/172]  eta: 0:01:38  lr: 0.000056  loss: 0.5994 (0.6118)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [120/172]  eta: 0:01:22  lr: 0.000056  loss: 0.6023 (0.6119)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [130/172]  eta: 0:01:06  lr: 0.000056  loss: 0.5986 (0.6106)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [140/172]  eta: 0:00:50  lr: 0.000056  loss: 0.6001 (0.6098)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [150/172]  eta: 0:00:34  lr: 0.000056  loss: 0.6121 (0.6096)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [160/172]  eta: 0:00:19  lr: 0.000056  loss: 0.6040 (0.6091)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [170/172]  eta: 0:00:03  lr: 0.000056  loss: 0.5990 (0.6094)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501]  [171/172]  eta: 0:00:01  lr: 0.000056  loss: 0.6040 (0.6095)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:501] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000056  loss: 0.6040 (0.6095)\n",
      "Valid: [epoch:501]  [ 0/14]  eta: 0:00:05  loss: 0.5994 (0.5994)  time: 0.3625  data: 0.3454  max mem: 20571\n",
      "Valid: [epoch:501]  [13/14]  eta: 0:00:00  loss: 0.5712 (0.5769)  time: 0.0409  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:501] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.5712 (0.5769)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_501_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.577%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:502]  [  0/172]  eta: 0:08:03  lr: 0.000055  loss: 0.5546 (0.5546)  time: 2.8090  data: 1.2411  max mem: 20571\n",
      "Train: [epoch:502]  [ 10/172]  eta: 0:04:34  lr: 0.000055  loss: 0.6178 (0.6151)  time: 1.6953  data: 0.1130  max mem: 20571\n",
      "Train: [epoch:502]  [ 20/172]  eta: 0:04:09  lr: 0.000055  loss: 0.6149 (0.6058)  time: 1.5830  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [ 30/172]  eta: 0:03:50  lr: 0.000055  loss: 0.5972 (0.6030)  time: 1.5836  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [ 40/172]  eta: 0:03:33  lr: 0.000055  loss: 0.5898 (0.6008)  time: 1.5860  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [ 50/172]  eta: 0:03:16  lr: 0.000055  loss: 0.6077 (0.6052)  time: 1.5854  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [ 60/172]  eta: 0:02:59  lr: 0.000055  loss: 0.6122 (0.6065)  time: 1.5830  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [ 70/172]  eta: 0:02:43  lr: 0.000055  loss: 0.6004 (0.6075)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [ 80/172]  eta: 0:02:27  lr: 0.000055  loss: 0.5988 (0.6060)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [ 90/172]  eta: 0:02:10  lr: 0.000055  loss: 0.5880 (0.6049)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [100/172]  eta: 0:01:54  lr: 0.000055  loss: 0.5954 (0.6054)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [110/172]  eta: 0:01:38  lr: 0.000055  loss: 0.5962 (0.6054)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:502]  [120/172]  eta: 0:01:22  lr: 0.000055  loss: 0.5942 (0.6057)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:502]  [130/172]  eta: 0:01:06  lr: 0.000055  loss: 0.5942 (0.6059)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:502]  [140/172]  eta: 0:00:50  lr: 0.000055  loss: 0.5929 (0.6050)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:502]  [150/172]  eta: 0:00:34  lr: 0.000055  loss: 0.6015 (0.6058)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:502]  [160/172]  eta: 0:00:19  lr: 0.000055  loss: 0.6147 (0.6060)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:502]  [170/172]  eta: 0:00:03  lr: 0.000055  loss: 0.6083 (0.6067)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:502]  [171/172]  eta: 0:00:01  lr: 0.000055  loss: 0.6083 (0.6069)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:502] Total time: 0:04:33 (1.5904 s / it)\n",
      "Averaged stats: lr: 0.000055  loss: 0.6083 (0.6069)\n",
      "Valid: [epoch:502]  [ 0/14]  eta: 0:00:05  loss: 0.5287 (0.5287)  time: 0.4062  data: 0.3877  max mem: 20571\n",
      "Valid: [epoch:502]  [13/14]  eta: 0:00:00  loss: 0.5732 (0.5789)  time: 0.0438  data: 0.0285  max mem: 20571\n",
      "Valid: [epoch:502] Total time: 0:00:00 (0.0518 s / it)\n",
      "Averaged stats: loss: 0.5732 (0.5789)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_502_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.579%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:503]  [  0/172]  eta: 0:07:57  lr: 0.000055  loss: 0.6162 (0.6162)  time: 2.7763  data: 1.1811  max mem: 20571\n",
      "Train: [epoch:503]  [ 10/172]  eta: 0:04:32  lr: 0.000055  loss: 0.6162 (0.6249)  time: 1.6846  data: 0.1075  max mem: 20571\n",
      "Train: [epoch:503]  [ 20/172]  eta: 0:04:08  lr: 0.000055  loss: 0.5986 (0.6138)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [ 30/172]  eta: 0:03:49  lr: 0.000055  loss: 0.6060 (0.6134)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:503]  [ 40/172]  eta: 0:03:32  lr: 0.000055  loss: 0.6113 (0.6099)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:503]  [ 50/172]  eta: 0:03:15  lr: 0.000055  loss: 0.6217 (0.6137)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:503]  [ 60/172]  eta: 0:02:59  lr: 0.000055  loss: 0.6217 (0.6127)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [ 70/172]  eta: 0:02:42  lr: 0.000055  loss: 0.6048 (0.6129)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [ 80/172]  eta: 0:02:26  lr: 0.000055  loss: 0.6048 (0.6127)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [ 90/172]  eta: 0:02:10  lr: 0.000055  loss: 0.5952 (0.6124)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [100/172]  eta: 0:01:54  lr: 0.000055  loss: 0.6069 (0.6128)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [110/172]  eta: 0:01:38  lr: 0.000055  loss: 0.6060 (0.6128)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [120/172]  eta: 0:01:22  lr: 0.000055  loss: 0.5955 (0.6115)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [130/172]  eta: 0:01:06  lr: 0.000055  loss: 0.5955 (0.6111)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [140/172]  eta: 0:00:50  lr: 0.000055  loss: 0.6033 (0.6108)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [150/172]  eta: 0:00:34  lr: 0.000055  loss: 0.6068 (0.6115)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [160/172]  eta: 0:00:19  lr: 0.000055  loss: 0.5945 (0.6101)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [170/172]  eta: 0:00:03  lr: 0.000055  loss: 0.5894 (0.6108)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503]  [171/172]  eta: 0:00:01  lr: 0.000055  loss: 0.5945 (0.6112)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:503] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000055  loss: 0.5945 (0.6112)\n",
      "Valid: [epoch:503]  [ 0/14]  eta: 0:00:04  loss: 0.5797 (0.5797)  time: 0.3215  data: 0.3042  max mem: 20571\n",
      "Valid: [epoch:503]  [13/14]  eta: 0:00:00  loss: 0.5865 (0.5925)  time: 0.0447  data: 0.0295  max mem: 20571\n",
      "Valid: [epoch:503] Total time: 0:00:00 (0.0526 s / it)\n",
      "Averaged stats: loss: 0.5865 (0.5925)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_503_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.593%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:504]  [  0/172]  eta: 0:08:17  lr: 0.000055  loss: 0.6182 (0.6182)  time: 2.8952  data: 1.3275  max mem: 20571\n",
      "Train: [epoch:504]  [ 10/172]  eta: 0:04:35  lr: 0.000055  loss: 0.5969 (0.6138)  time: 1.6976  data: 0.1208  max mem: 20571\n",
      "Train: [epoch:504]  [ 20/172]  eta: 0:04:09  lr: 0.000055  loss: 0.5954 (0.6083)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [ 30/172]  eta: 0:03:50  lr: 0.000055  loss: 0.5989 (0.6122)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [ 40/172]  eta: 0:03:32  lr: 0.000055  loss: 0.5989 (0.6113)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [ 50/172]  eta: 0:03:15  lr: 0.000055  loss: 0.6039 (0.6114)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [ 60/172]  eta: 0:02:59  lr: 0.000055  loss: 0.6039 (0.6108)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [ 70/172]  eta: 0:02:43  lr: 0.000055  loss: 0.6120 (0.6125)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [ 80/172]  eta: 0:02:26  lr: 0.000055  loss: 0.6167 (0.6129)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [ 90/172]  eta: 0:02:10  lr: 0.000055  loss: 0.6042 (0.6121)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [100/172]  eta: 0:01:54  lr: 0.000055  loss: 0.6023 (0.6107)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [110/172]  eta: 0:01:38  lr: 0.000055  loss: 0.6035 (0.6118)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [120/172]  eta: 0:01:22  lr: 0.000055  loss: 0.6077 (0.6121)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [130/172]  eta: 0:01:06  lr: 0.000055  loss: 0.5904 (0.6110)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [140/172]  eta: 0:00:50  lr: 0.000055  loss: 0.5866 (0.6097)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [150/172]  eta: 0:00:34  lr: 0.000055  loss: 0.5962 (0.6098)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [160/172]  eta: 0:00:19  lr: 0.000055  loss: 0.6026 (0.6096)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [170/172]  eta: 0:00:03  lr: 0.000055  loss: 0.6026 (0.6097)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504]  [171/172]  eta: 0:00:01  lr: 0.000055  loss: 0.6026 (0.6096)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:504] Total time: 0:04:33 (1.5905 s / it)\n",
      "Averaged stats: lr: 0.000055  loss: 0.6026 (0.6096)\n",
      "Valid: [epoch:504]  [ 0/14]  eta: 0:00:04  loss: 0.5976 (0.5976)  time: 0.3088  data: 0.2941  max mem: 20571\n",
      "Valid: [epoch:504]  [13/14]  eta: 0:00:00  loss: 0.5708 (0.5755)  time: 0.0374  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:504] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.5708 (0.5755)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_504_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.575%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:505]  [  0/172]  eta: 0:07:39  lr: 0.000055  loss: 0.5989 (0.5989)  time: 2.6739  data: 1.0688  max mem: 20571\n",
      "Train: [epoch:505]  [ 10/172]  eta: 0:04:32  lr: 0.000055  loss: 0.5989 (0.6067)  time: 1.6807  data: 0.0973  max mem: 20571\n",
      "Train: [epoch:505]  [ 20/172]  eta: 0:04:08  lr: 0.000055  loss: 0.5965 (0.6006)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [ 30/172]  eta: 0:03:49  lr: 0.000055  loss: 0.5965 (0.6026)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [ 40/172]  eta: 0:03:32  lr: 0.000055  loss: 0.6048 (0.6049)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [ 50/172]  eta: 0:03:15  lr: 0.000055  loss: 0.6227 (0.6097)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [ 60/172]  eta: 0:02:59  lr: 0.000055  loss: 0.6192 (0.6121)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [ 70/172]  eta: 0:02:42  lr: 0.000055  loss: 0.6192 (0.6126)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [ 80/172]  eta: 0:02:26  lr: 0.000055  loss: 0.6073 (0.6108)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [ 90/172]  eta: 0:02:10  lr: 0.000055  loss: 0.5945 (0.6116)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [100/172]  eta: 0:01:54  lr: 0.000055  loss: 0.5964 (0.6106)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [110/172]  eta: 0:01:38  lr: 0.000055  loss: 0.5981 (0.6099)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [120/172]  eta: 0:01:22  lr: 0.000055  loss: 0.6075 (0.6115)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [130/172]  eta: 0:01:06  lr: 0.000055  loss: 0.6246 (0.6114)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [140/172]  eta: 0:00:50  lr: 0.000055  loss: 0.5999 (0.6110)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [150/172]  eta: 0:00:34  lr: 0.000055  loss: 0.5999 (0.6112)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [160/172]  eta: 0:00:19  lr: 0.000055  loss: 0.5980 (0.6111)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505]  [170/172]  eta: 0:00:03  lr: 0.000055  loss: 0.6122 (0.6116)  time: 1.5816  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:505]  [171/172]  eta: 0:00:01  lr: 0.000055  loss: 0.6122 (0.6113)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:505] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000055  loss: 0.6122 (0.6113)\n",
      "Valid: [epoch:505]  [ 0/14]  eta: 0:00:03  loss: 0.6074 (0.6074)  time: 0.2778  data: 0.2614  max mem: 20571\n",
      "Valid: [epoch:505]  [13/14]  eta: 0:00:00  loss: 0.5791 (0.5854)  time: 0.0442  data: 0.0291  max mem: 20571\n",
      "Valid: [epoch:505] Total time: 0:00:00 (0.0525 s / it)\n",
      "Averaged stats: loss: 0.5791 (0.5854)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_505_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.585%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:506]  [  0/172]  eta: 0:08:34  lr: 0.000055  loss: 0.5569 (0.5569)  time: 2.9907  data: 1.4237  max mem: 20571\n",
      "Train: [epoch:506]  [ 10/172]  eta: 0:04:36  lr: 0.000055  loss: 0.6044 (0.6044)  time: 1.7088  data: 0.1295  max mem: 20571\n",
      "Train: [epoch:506]  [ 20/172]  eta: 0:04:10  lr: 0.000055  loss: 0.6047 (0.6089)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:506]  [ 30/172]  eta: 0:03:51  lr: 0.000055  loss: 0.5948 (0.6070)  time: 1.5843  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:506]  [ 40/172]  eta: 0:03:33  lr: 0.000055  loss: 0.5921 (0.6051)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [ 50/172]  eta: 0:03:16  lr: 0.000055  loss: 0.6071 (0.6075)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [ 60/172]  eta: 0:02:59  lr: 0.000055  loss: 0.6207 (0.6104)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [ 70/172]  eta: 0:02:43  lr: 0.000055  loss: 0.6085 (0.6100)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [ 80/172]  eta: 0:02:27  lr: 0.000055  loss: 0.6016 (0.6104)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [ 90/172]  eta: 0:02:10  lr: 0.000055  loss: 0.5940 (0.6097)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [100/172]  eta: 0:01:54  lr: 0.000055  loss: 0.6039 (0.6107)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [110/172]  eta: 0:01:38  lr: 0.000055  loss: 0.6065 (0.6099)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [120/172]  eta: 0:01:22  lr: 0.000055  loss: 0.6025 (0.6099)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:506]  [130/172]  eta: 0:01:06  lr: 0.000055  loss: 0.6064 (0.6097)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:506]  [140/172]  eta: 0:00:50  lr: 0.000055  loss: 0.6064 (0.6096)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [150/172]  eta: 0:00:34  lr: 0.000055  loss: 0.6110 (0.6105)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [160/172]  eta: 0:00:19  lr: 0.000055  loss: 0.6029 (0.6102)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [170/172]  eta: 0:00:03  lr: 0.000055  loss: 0.6087 (0.6112)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506]  [171/172]  eta: 0:00:01  lr: 0.000055  loss: 0.6211 (0.6113)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:506] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000055  loss: 0.6211 (0.6113)\n",
      "Valid: [epoch:506]  [ 0/14]  eta: 0:00:05  loss: 0.6108 (0.6108)  time: 0.3836  data: 0.3683  max mem: 20571\n",
      "Valid: [epoch:506]  [13/14]  eta: 0:00:00  loss: 0.5858 (0.5899)  time: 0.0446  data: 0.0297  max mem: 20571\n",
      "Valid: [epoch:506] Total time: 0:00:00 (0.0521 s / it)\n",
      "Averaged stats: loss: 0.5858 (0.5899)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_506_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.590%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:507]  [  0/172]  eta: 0:07:36  lr: 0.000055  loss: 0.6656 (0.6656)  time: 2.6519  data: 1.0712  max mem: 20571\n",
      "Train: [epoch:507]  [ 10/172]  eta: 0:04:30  lr: 0.000055  loss: 0.6145 (0.6075)  time: 1.6728  data: 0.0975  max mem: 20571\n",
      "Train: [epoch:507]  [ 20/172]  eta: 0:04:07  lr: 0.000055  loss: 0.6122 (0.6162)  time: 1.5758  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:507]  [ 30/172]  eta: 0:03:49  lr: 0.000055  loss: 0.6049 (0.6179)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [ 40/172]  eta: 0:03:31  lr: 0.000055  loss: 0.6061 (0.6170)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [ 50/172]  eta: 0:03:15  lr: 0.000055  loss: 0.6256 (0.6212)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [ 60/172]  eta: 0:02:58  lr: 0.000055  loss: 0.6319 (0.6222)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [ 70/172]  eta: 0:02:42  lr: 0.000055  loss: 0.6115 (0.6212)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [ 80/172]  eta: 0:02:26  lr: 0.000055  loss: 0.6055 (0.6208)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [ 90/172]  eta: 0:02:10  lr: 0.000055  loss: 0.6016 (0.6190)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [100/172]  eta: 0:01:54  lr: 0.000055  loss: 0.5992 (0.6187)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [110/172]  eta: 0:01:38  lr: 0.000055  loss: 0.5972 (0.6173)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [120/172]  eta: 0:01:22  lr: 0.000055  loss: 0.5964 (0.6187)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [130/172]  eta: 0:01:06  lr: 0.000055  loss: 0.6099 (0.6178)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [140/172]  eta: 0:00:50  lr: 0.000055  loss: 0.5990 (0.6175)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [150/172]  eta: 0:00:34  lr: 0.000055  loss: 0.5990 (0.6167)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [160/172]  eta: 0:00:19  lr: 0.000055  loss: 0.6028 (0.6169)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [170/172]  eta: 0:00:03  lr: 0.000055  loss: 0.6142 (0.6175)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507]  [171/172]  eta: 0:00:01  lr: 0.000055  loss: 0.6142 (0.6172)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:507] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000055  loss: 0.6142 (0.6172)\n",
      "Valid: [epoch:507]  [ 0/14]  eta: 0:00:04  loss: 0.5558 (0.5558)  time: 0.3103  data: 0.2953  max mem: 20571\n",
      "Valid: [epoch:507]  [13/14]  eta: 0:00:00  loss: 0.5682 (0.5739)  time: 0.0412  data: 0.0261  max mem: 20571\n",
      "Valid: [epoch:507] Total time: 0:00:00 (0.0510 s / it)\n",
      "Averaged stats: loss: 0.5682 (0.5739)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_507_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.574%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:508]  [  0/172]  eta: 0:08:17  lr: 0.000055  loss: 0.5552 (0.5552)  time: 2.8949  data: 1.3216  max mem: 20571\n",
      "Train: [epoch:508]  [ 10/172]  eta: 0:04:36  lr: 0.000055  loss: 0.6039 (0.5921)  time: 1.7043  data: 0.1203  max mem: 20571\n",
      "Train: [epoch:508]  [ 20/172]  eta: 0:04:10  lr: 0.000055  loss: 0.6059 (0.6047)  time: 1.5857  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:508]  [ 30/172]  eta: 0:03:51  lr: 0.000055  loss: 0.6042 (0.6026)  time: 1.5856  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:508]  [ 40/172]  eta: 0:03:33  lr: 0.000055  loss: 0.6018 (0.6094)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [ 50/172]  eta: 0:03:16  lr: 0.000055  loss: 0.6068 (0.6098)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [ 60/172]  eta: 0:02:59  lr: 0.000055  loss: 0.5975 (0.6099)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [ 70/172]  eta: 0:02:43  lr: 0.000055  loss: 0.6051 (0.6091)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [ 80/172]  eta: 0:02:27  lr: 0.000055  loss: 0.6089 (0.6108)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [ 90/172]  eta: 0:02:11  lr: 0.000055  loss: 0.6174 (0.6108)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [100/172]  eta: 0:01:54  lr: 0.000055  loss: 0.6064 (0.6100)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [110/172]  eta: 0:01:38  lr: 0.000055  loss: 0.6064 (0.6118)  time: 1.5856  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:508]  [120/172]  eta: 0:01:22  lr: 0.000055  loss: 0.6208 (0.6115)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [130/172]  eta: 0:01:06  lr: 0.000055  loss: 0.6099 (0.6119)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [140/172]  eta: 0:00:50  lr: 0.000055  loss: 0.6173 (0.6127)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [150/172]  eta: 0:00:35  lr: 0.000055  loss: 0.6120 (0.6119)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [160/172]  eta: 0:00:19  lr: 0.000055  loss: 0.6058 (0.6121)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [170/172]  eta: 0:00:03  lr: 0.000055  loss: 0.6082 (0.6126)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508]  [171/172]  eta: 0:00:01  lr: 0.000055  loss: 0.6058 (0.6125)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:508] Total time: 0:04:33 (1.5926 s / it)\n",
      "Averaged stats: lr: 0.000055  loss: 0.6058 (0.6125)\n",
      "Valid: [epoch:508]  [ 0/14]  eta: 0:00:05  loss: 0.6092 (0.6092)  time: 0.3619  data: 0.3472  max mem: 20571\n",
      "Valid: [epoch:508]  [13/14]  eta: 0:00:00  loss: 0.5743 (0.5799)  time: 0.0417  data: 0.0268  max mem: 20571\n",
      "Valid: [epoch:508] Total time: 0:00:00 (0.0485 s / it)\n",
      "Averaged stats: loss: 0.5743 (0.5799)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_508_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.580%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:509]  [  0/172]  eta: 0:07:46  lr: 0.000055  loss: 0.5980 (0.5980)  time: 2.7142  data: 1.1193  max mem: 20571\n",
      "Train: [epoch:509]  [ 10/172]  eta: 0:04:32  lr: 0.000055  loss: 0.6095 (0.6153)  time: 1.6810  data: 0.1019  max mem: 20571\n",
      "Train: [epoch:509]  [ 20/172]  eta: 0:04:08  lr: 0.000055  loss: 0.6136 (0.6116)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [ 30/172]  eta: 0:03:49  lr: 0.000055  loss: 0.6074 (0.6093)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:509]  [ 40/172]  eta: 0:03:32  lr: 0.000055  loss: 0.6006 (0.6094)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:509]  [ 50/172]  eta: 0:03:15  lr: 0.000055  loss: 0.6006 (0.6089)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [ 60/172]  eta: 0:02:59  lr: 0.000055  loss: 0.6063 (0.6096)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [ 70/172]  eta: 0:02:42  lr: 0.000055  loss: 0.6186 (0.6100)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [ 80/172]  eta: 0:02:26  lr: 0.000055  loss: 0.6095 (0.6104)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [ 90/172]  eta: 0:02:10  lr: 0.000055  loss: 0.5990 (0.6096)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [100/172]  eta: 0:01:54  lr: 0.000055  loss: 0.5993 (0.6107)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [110/172]  eta: 0:01:38  lr: 0.000055  loss: 0.6194 (0.6122)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [120/172]  eta: 0:01:22  lr: 0.000055  loss: 0.6242 (0.6137)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [130/172]  eta: 0:01:06  lr: 0.000055  loss: 0.6160 (0.6137)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [140/172]  eta: 0:00:50  lr: 0.000055  loss: 0.6069 (0.6127)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [150/172]  eta: 0:00:34  lr: 0.000055  loss: 0.6056 (0.6131)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [160/172]  eta: 0:00:19  lr: 0.000055  loss: 0.6103 (0.6131)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [170/172]  eta: 0:00:03  lr: 0.000055  loss: 0.6167 (0.6132)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509]  [171/172]  eta: 0:00:01  lr: 0.000055  loss: 0.6103 (0.6131)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:509] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000055  loss: 0.6103 (0.6131)\n",
      "Valid: [epoch:509]  [ 0/14]  eta: 0:00:04  loss: 0.5611 (0.5611)  time: 0.3555  data: 0.3378  max mem: 20571\n",
      "Valid: [epoch:509]  [13/14]  eta: 0:00:00  loss: 0.5739 (0.5793)  time: 0.0407  data: 0.0251  max mem: 20571\n",
      "Valid: [epoch:509] Total time: 0:00:00 (0.0491 s / it)\n",
      "Averaged stats: loss: 0.5739 (0.5793)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_509_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.579%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:510]  [  0/172]  eta: 0:08:09  lr: 0.000055  loss: 0.6142 (0.6142)  time: 2.8487  data: 1.2767  max mem: 20571\n",
      "Train: [epoch:510]  [ 10/172]  eta: 0:04:34  lr: 0.000055  loss: 0.6142 (0.6041)  time: 1.6955  data: 0.1162  max mem: 20571\n",
      "Train: [epoch:510]  [ 20/172]  eta: 0:04:09  lr: 0.000055  loss: 0.6143 (0.6155)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [ 30/172]  eta: 0:03:50  lr: 0.000055  loss: 0.6062 (0.6143)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [ 40/172]  eta: 0:03:32  lr: 0.000055  loss: 0.6168 (0.6200)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [ 50/172]  eta: 0:03:15  lr: 0.000055  loss: 0.6233 (0.6194)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [ 60/172]  eta: 0:02:59  lr: 0.000055  loss: 0.6115 (0.6194)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [ 70/172]  eta: 0:02:43  lr: 0.000055  loss: 0.5991 (0.6184)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [ 80/172]  eta: 0:02:26  lr: 0.000055  loss: 0.6009 (0.6182)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [ 90/172]  eta: 0:02:10  lr: 0.000055  loss: 0.6068 (0.6184)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [100/172]  eta: 0:01:54  lr: 0.000055  loss: 0.6159 (0.6181)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [110/172]  eta: 0:01:38  lr: 0.000055  loss: 0.5937 (0.6166)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [120/172]  eta: 0:01:22  lr: 0.000055  loss: 0.5995 (0.6166)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [130/172]  eta: 0:01:06  lr: 0.000055  loss: 0.6072 (0.6175)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:510]  [140/172]  eta: 0:00:50  lr: 0.000055  loss: 0.6291 (0.6173)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [150/172]  eta: 0:00:34  lr: 0.000055  loss: 0.6265 (0.6176)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [160/172]  eta: 0:00:19  lr: 0.000055  loss: 0.6153 (0.6172)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [170/172]  eta: 0:00:03  lr: 0.000055  loss: 0.6029 (0.6163)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510]  [171/172]  eta: 0:00:01  lr: 0.000055  loss: 0.6029 (0.6160)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:510] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000055  loss: 0.6029 (0.6160)\n",
      "Valid: [epoch:510]  [ 0/14]  eta: 0:00:04  loss: 0.6033 (0.6033)  time: 0.3209  data: 0.3047  max mem: 20571\n",
      "Valid: [epoch:510]  [13/14]  eta: 0:00:00  loss: 0.6155 (0.6193)  time: 0.0401  data: 0.0251  max mem: 20571\n",
      "Valid: [epoch:510] Total time: 0:00:00 (0.0489 s / it)\n",
      "Averaged stats: loss: 0.6155 (0.6193)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_510_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.619%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:511]  [  0/172]  eta: 0:07:56  lr: 0.000054  loss: 0.6152 (0.6152)  time: 2.7727  data: 1.1948  max mem: 20571\n",
      "Train: [epoch:511]  [ 10/172]  eta: 0:04:32  lr: 0.000054  loss: 0.6114 (0.6131)  time: 1.6843  data: 0.1088  max mem: 20571\n",
      "Train: [epoch:511]  [ 20/172]  eta: 0:04:08  lr: 0.000054  loss: 0.6122 (0.6232)  time: 1.5776  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:511]  [ 30/172]  eta: 0:03:49  lr: 0.000054  loss: 0.6216 (0.6206)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [ 40/172]  eta: 0:03:32  lr: 0.000054  loss: 0.6211 (0.6211)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [ 50/172]  eta: 0:03:15  lr: 0.000054  loss: 0.6211 (0.6189)  time: 1.5833  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:511]  [ 60/172]  eta: 0:02:59  lr: 0.000054  loss: 0.6161 (0.6175)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [ 70/172]  eta: 0:02:42  lr: 0.000054  loss: 0.6086 (0.6168)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [ 80/172]  eta: 0:02:26  lr: 0.000054  loss: 0.6086 (0.6178)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [ 90/172]  eta: 0:02:10  lr: 0.000054  loss: 0.6135 (0.6188)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [100/172]  eta: 0:01:54  lr: 0.000054  loss: 0.6152 (0.6181)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [110/172]  eta: 0:01:38  lr: 0.000054  loss: 0.6152 (0.6181)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [120/172]  eta: 0:01:22  lr: 0.000054  loss: 0.6171 (0.6190)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [130/172]  eta: 0:01:06  lr: 0.000054  loss: 0.6105 (0.6180)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [140/172]  eta: 0:00:50  lr: 0.000054  loss: 0.6064 (0.6185)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [150/172]  eta: 0:00:34  lr: 0.000054  loss: 0.6010 (0.6170)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [160/172]  eta: 0:00:19  lr: 0.000054  loss: 0.5963 (0.6168)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [170/172]  eta: 0:00:03  lr: 0.000054  loss: 0.6133 (0.6169)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511]  [171/172]  eta: 0:00:01  lr: 0.000054  loss: 0.6059 (0.6165)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:511] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000054  loss: 0.6059 (0.6165)\n",
      "Valid: [epoch:511]  [ 0/14]  eta: 0:00:04  loss: 0.5764 (0.5764)  time: 0.3022  data: 0.2859  max mem: 20571\n",
      "Valid: [epoch:511]  [13/14]  eta: 0:00:00  loss: 0.5819 (0.5862)  time: 0.0389  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:511] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.5819 (0.5862)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_511_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.586%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:512]  [  0/172]  eta: 0:07:48  lr: 0.000054  loss: 0.5767 (0.5767)  time: 2.7259  data: 1.1546  max mem: 20571\n",
      "Train: [epoch:512]  [ 10/172]  eta: 0:04:33  lr: 0.000054  loss: 0.6224 (0.6141)  time: 1.6900  data: 0.1051  max mem: 20571\n",
      "Train: [epoch:512]  [ 20/172]  eta: 0:04:09  lr: 0.000054  loss: 0.6317 (0.6256)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [ 30/172]  eta: 0:03:50  lr: 0.000054  loss: 0.6061 (0.6183)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [ 40/172]  eta: 0:03:32  lr: 0.000054  loss: 0.5892 (0.6148)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [ 50/172]  eta: 0:03:15  lr: 0.000054  loss: 0.6175 (0.6191)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [ 60/172]  eta: 0:02:59  lr: 0.000054  loss: 0.6098 (0.6179)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [ 70/172]  eta: 0:02:43  lr: 0.000054  loss: 0.6098 (0.6191)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [ 80/172]  eta: 0:02:26  lr: 0.000054  loss: 0.6162 (0.6188)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [ 90/172]  eta: 0:02:10  lr: 0.000054  loss: 0.6113 (0.6187)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [100/172]  eta: 0:01:54  lr: 0.000054  loss: 0.6076 (0.6181)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [110/172]  eta: 0:01:38  lr: 0.000054  loss: 0.6076 (0.6189)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [120/172]  eta: 0:01:22  lr: 0.000054  loss: 0.6079 (0.6185)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [130/172]  eta: 0:01:06  lr: 0.000054  loss: 0.6083 (0.6182)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [140/172]  eta: 0:00:50  lr: 0.000054  loss: 0.5911 (0.6163)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [150/172]  eta: 0:00:34  lr: 0.000054  loss: 0.6080 (0.6175)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [160/172]  eta: 0:00:19  lr: 0.000054  loss: 0.6370 (0.6188)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [170/172]  eta: 0:00:03  lr: 0.000054  loss: 0.6362 (0.6186)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512]  [171/172]  eta: 0:00:01  lr: 0.000054  loss: 0.6419 (0.6190)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:512] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000054  loss: 0.6419 (0.6190)\n",
      "Valid: [epoch:512]  [ 0/14]  eta: 0:00:04  loss: 0.5794 (0.5794)  time: 0.3075  data: 0.2902  max mem: 20571\n",
      "Valid: [epoch:512]  [13/14]  eta: 0:00:00  loss: 0.5794 (0.5850)  time: 0.0444  data: 0.0292  max mem: 20571\n",
      "Valid: [epoch:512] Total time: 0:00:00 (0.0528 s / it)\n",
      "Averaged stats: loss: 0.5794 (0.5850)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_512_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.585%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:513]  [  0/172]  eta: 0:07:42  lr: 0.000054  loss: 0.5588 (0.5588)  time: 2.6914  data: 1.0846  max mem: 20571\n",
      "Train: [epoch:513]  [ 10/172]  eta: 0:04:31  lr: 0.000054  loss: 0.6183 (0.6305)  time: 1.6771  data: 0.0987  max mem: 20571\n",
      "Train: [epoch:513]  [ 20/172]  eta: 0:04:07  lr: 0.000054  loss: 0.6183 (0.6291)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [ 30/172]  eta: 0:03:49  lr: 0.000054  loss: 0.6129 (0.6249)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [ 40/172]  eta: 0:03:32  lr: 0.000054  loss: 0.5963 (0.6191)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [ 50/172]  eta: 0:03:15  lr: 0.000054  loss: 0.5943 (0.6182)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [ 60/172]  eta: 0:02:59  lr: 0.000054  loss: 0.6070 (0.6185)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [ 70/172]  eta: 0:02:42  lr: 0.000054  loss: 0.6053 (0.6186)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [ 80/172]  eta: 0:02:26  lr: 0.000054  loss: 0.6219 (0.6218)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [ 90/172]  eta: 0:02:10  lr: 0.000054  loss: 0.6219 (0.6202)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [100/172]  eta: 0:01:54  lr: 0.000054  loss: 0.6116 (0.6210)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [110/172]  eta: 0:01:38  lr: 0.000054  loss: 0.6162 (0.6203)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:513]  [120/172]  eta: 0:01:22  lr: 0.000054  loss: 0.5991 (0.6187)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:513]  [130/172]  eta: 0:01:06  lr: 0.000054  loss: 0.5991 (0.6186)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [140/172]  eta: 0:00:50  lr: 0.000054  loss: 0.6141 (0.6183)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [150/172]  eta: 0:00:34  lr: 0.000054  loss: 0.6141 (0.6187)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:513]  [160/172]  eta: 0:00:19  lr: 0.000054  loss: 0.6097 (0.6173)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [170/172]  eta: 0:00:03  lr: 0.000054  loss: 0.6113 (0.6173)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513]  [171/172]  eta: 0:00:01  lr: 0.000054  loss: 0.6113 (0.6171)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:513] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000054  loss: 0.6113 (0.6171)\n",
      "Valid: [epoch:513]  [ 0/14]  eta: 0:00:04  loss: 0.5645 (0.5645)  time: 0.3100  data: 0.2950  max mem: 20571\n",
      "Valid: [epoch:513]  [13/14]  eta: 0:00:00  loss: 0.5761 (0.5816)  time: 0.0499  data: 0.0348  max mem: 20571\n",
      "Valid: [epoch:513] Total time: 0:00:00 (0.0582 s / it)\n",
      "Averaged stats: loss: 0.5761 (0.5816)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_513_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.582%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:514]  [  0/172]  eta: 0:07:41  lr: 0.000054  loss: 0.5904 (0.5904)  time: 2.6844  data: 1.1159  max mem: 20571\n",
      "Train: [epoch:514]  [ 10/172]  eta: 0:04:32  lr: 0.000054  loss: 0.6058 (0.6131)  time: 1.6827  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:514]  [ 20/172]  eta: 0:04:08  lr: 0.000054  loss: 0.6042 (0.6107)  time: 1.5845  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:514]  [ 30/172]  eta: 0:03:49  lr: 0.000054  loss: 0.5981 (0.6084)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [ 40/172]  eta: 0:03:32  lr: 0.000054  loss: 0.6130 (0.6123)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [ 50/172]  eta: 0:03:15  lr: 0.000054  loss: 0.6285 (0.6162)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [ 60/172]  eta: 0:02:59  lr: 0.000054  loss: 0.6189 (0.6184)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [ 70/172]  eta: 0:02:43  lr: 0.000054  loss: 0.6216 (0.6193)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [ 80/172]  eta: 0:02:26  lr: 0.000054  loss: 0.6108 (0.6178)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [ 90/172]  eta: 0:02:10  lr: 0.000054  loss: 0.6090 (0.6179)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [100/172]  eta: 0:01:54  lr: 0.000054  loss: 0.6181 (0.6179)  time: 1.5831  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:514]  [110/172]  eta: 0:01:38  lr: 0.000054  loss: 0.6181 (0.6185)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [120/172]  eta: 0:01:22  lr: 0.000054  loss: 0.6365 (0.6211)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [130/172]  eta: 0:01:06  lr: 0.000054  loss: 0.6272 (0.6212)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [140/172]  eta: 0:00:50  lr: 0.000054  loss: 0.6077 (0.6193)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [150/172]  eta: 0:00:34  lr: 0.000054  loss: 0.6011 (0.6194)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [160/172]  eta: 0:00:19  lr: 0.000054  loss: 0.6328 (0.6195)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [170/172]  eta: 0:00:03  lr: 0.000054  loss: 0.6288 (0.6203)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514]  [171/172]  eta: 0:00:01  lr: 0.000054  loss: 0.6369 (0.6205)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:514] Total time: 0:04:33 (1.5897 s / it)\n",
      "Averaged stats: lr: 0.000054  loss: 0.6369 (0.6205)\n",
      "Valid: [epoch:514]  [ 0/14]  eta: 0:00:04  loss: 0.5845 (0.5845)  time: 0.3421  data: 0.3260  max mem: 20571\n",
      "Valid: [epoch:514]  [13/14]  eta: 0:00:00  loss: 0.5845 (0.5903)  time: 0.0392  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:514] Total time: 0:00:00 (0.0448 s / it)\n",
      "Averaged stats: loss: 0.5845 (0.5903)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_514_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.590%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:515]  [  0/172]  eta: 0:07:56  lr: 0.000054  loss: 0.6337 (0.6337)  time: 2.7709  data: 1.1925  max mem: 20571\n",
      "Train: [epoch:515]  [ 10/172]  eta: 0:04:33  lr: 0.000054  loss: 0.6337 (0.6287)  time: 1.6866  data: 0.1085  max mem: 20571\n",
      "Train: [epoch:515]  [ 20/172]  eta: 0:04:08  lr: 0.000054  loss: 0.6123 (0.6167)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:515]  [ 30/172]  eta: 0:03:49  lr: 0.000054  loss: 0.5991 (0.6144)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:515]  [ 40/172]  eta: 0:03:32  lr: 0.000054  loss: 0.6080 (0.6138)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [ 50/172]  eta: 0:03:15  lr: 0.000054  loss: 0.6191 (0.6186)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [ 60/172]  eta: 0:02:59  lr: 0.000054  loss: 0.6205 (0.6185)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [ 70/172]  eta: 0:02:42  lr: 0.000054  loss: 0.6271 (0.6211)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [ 80/172]  eta: 0:02:26  lr: 0.000054  loss: 0.6107 (0.6193)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [ 90/172]  eta: 0:02:10  lr: 0.000054  loss: 0.6180 (0.6210)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [100/172]  eta: 0:01:54  lr: 0.000054  loss: 0.6180 (0.6202)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [110/172]  eta: 0:01:38  lr: 0.000054  loss: 0.6121 (0.6193)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [120/172]  eta: 0:01:22  lr: 0.000054  loss: 0.6123 (0.6186)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [130/172]  eta: 0:01:06  lr: 0.000054  loss: 0.6105 (0.6176)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [140/172]  eta: 0:00:50  lr: 0.000054  loss: 0.6178 (0.6178)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [150/172]  eta: 0:00:34  lr: 0.000054  loss: 0.6200 (0.6178)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [160/172]  eta: 0:00:19  lr: 0.000054  loss: 0.6225 (0.6190)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [170/172]  eta: 0:00:03  lr: 0.000054  loss: 0.6292 (0.6190)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515]  [171/172]  eta: 0:00:01  lr: 0.000054  loss: 0.6292 (0.6189)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:515] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000054  loss: 0.6292 (0.6189)\n",
      "Valid: [epoch:515]  [ 0/14]  eta: 0:00:04  loss: 0.6171 (0.6171)  time: 0.3526  data: 0.3376  max mem: 20571\n",
      "Valid: [epoch:515]  [13/14]  eta: 0:00:00  loss: 0.5841 (0.5873)  time: 0.0398  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:515] Total time: 0:00:00 (0.0447 s / it)\n",
      "Averaged stats: loss: 0.5841 (0.5873)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_515_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.587%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:516]  [  0/172]  eta: 0:07:55  lr: 0.000054  loss: 0.6247 (0.6247)  time: 2.7623  data: 1.1902  max mem: 20571\n",
      "Train: [epoch:516]  [ 10/172]  eta: 0:04:33  lr: 0.000054  loss: 0.6155 (0.6203)  time: 1.6860  data: 0.1083  max mem: 20571\n",
      "Train: [epoch:516]  [ 20/172]  eta: 0:04:08  lr: 0.000054  loss: 0.6155 (0.6232)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [ 30/172]  eta: 0:03:49  lr: 0.000054  loss: 0.6136 (0.6210)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [ 40/172]  eta: 0:03:32  lr: 0.000054  loss: 0.6034 (0.6170)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [ 50/172]  eta: 0:03:15  lr: 0.000054  loss: 0.5978 (0.6152)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [ 60/172]  eta: 0:02:59  lr: 0.000054  loss: 0.6052 (0.6162)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [ 70/172]  eta: 0:02:42  lr: 0.000054  loss: 0.6241 (0.6173)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [ 80/172]  eta: 0:02:26  lr: 0.000054  loss: 0.6285 (0.6194)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [ 90/172]  eta: 0:02:10  lr: 0.000054  loss: 0.6242 (0.6182)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [100/172]  eta: 0:01:54  lr: 0.000054  loss: 0.6102 (0.6180)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [110/172]  eta: 0:01:38  lr: 0.000054  loss: 0.6133 (0.6181)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [120/172]  eta: 0:01:22  lr: 0.000054  loss: 0.6141 (0.6183)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [130/172]  eta: 0:01:06  lr: 0.000054  loss: 0.6204 (0.6183)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [140/172]  eta: 0:00:50  lr: 0.000054  loss: 0.6200 (0.6181)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [150/172]  eta: 0:00:34  lr: 0.000054  loss: 0.6200 (0.6185)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [160/172]  eta: 0:00:19  lr: 0.000054  loss: 0.6226 (0.6187)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516]  [170/172]  eta: 0:00:03  lr: 0.000054  loss: 0.6226 (0.6189)  time: 1.5823  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:516]  [171/172]  eta: 0:00:01  lr: 0.000054  loss: 0.6102 (0.6188)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:516] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000054  loss: 0.6102 (0.6188)\n",
      "Valid: [epoch:516]  [ 0/14]  eta: 0:00:04  loss: 0.5272 (0.5272)  time: 0.3513  data: 0.3332  max mem: 20571\n",
      "Valid: [epoch:516]  [13/14]  eta: 0:00:00  loss: 0.5865 (0.5917)  time: 0.0400  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:516] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 0.5865 (0.5917)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_516_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.592%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:517]  [  0/172]  eta: 0:08:10  lr: 0.000054  loss: 0.6390 (0.6390)  time: 2.8491  data: 1.2758  max mem: 20571\n",
      "Train: [epoch:517]  [ 10/172]  eta: 0:04:34  lr: 0.000054  loss: 0.6059 (0.6161)  time: 1.6916  data: 0.1161  max mem: 20571\n",
      "Train: [epoch:517]  [ 20/172]  eta: 0:04:08  lr: 0.000054  loss: 0.6075 (0.6165)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [ 30/172]  eta: 0:03:49  lr: 0.000054  loss: 0.6198 (0.6168)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [ 40/172]  eta: 0:03:32  lr: 0.000054  loss: 0.6088 (0.6147)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [ 50/172]  eta: 0:03:15  lr: 0.000054  loss: 0.6140 (0.6174)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [ 60/172]  eta: 0:02:59  lr: 0.000054  loss: 0.6253 (0.6171)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [ 70/172]  eta: 0:02:42  lr: 0.000054  loss: 0.6274 (0.6173)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [ 80/172]  eta: 0:02:26  lr: 0.000054  loss: 0.6085 (0.6175)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [ 90/172]  eta: 0:02:10  lr: 0.000054  loss: 0.6085 (0.6190)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [100/172]  eta: 0:01:54  lr: 0.000054  loss: 0.6089 (0.6195)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [110/172]  eta: 0:01:38  lr: 0.000054  loss: 0.6094 (0.6197)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [120/172]  eta: 0:01:22  lr: 0.000054  loss: 0.6287 (0.6201)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [130/172]  eta: 0:01:06  lr: 0.000054  loss: 0.6137 (0.6197)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [140/172]  eta: 0:00:50  lr: 0.000054  loss: 0.6049 (0.6188)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [150/172]  eta: 0:00:34  lr: 0.000054  loss: 0.6235 (0.6199)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [160/172]  eta: 0:00:19  lr: 0.000054  loss: 0.6351 (0.6207)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [170/172]  eta: 0:00:03  lr: 0.000054  loss: 0.6127 (0.6206)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517]  [171/172]  eta: 0:00:01  lr: 0.000054  loss: 0.6127 (0.6209)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:517] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000054  loss: 0.6127 (0.6209)\n",
      "Valid: [epoch:517]  [ 0/14]  eta: 0:00:05  loss: 0.6067 (0.6067)  time: 0.4025  data: 0.3862  max mem: 20571\n",
      "Valid: [epoch:517]  [13/14]  eta: 0:00:00  loss: 0.5780 (0.5835)  time: 0.0428  data: 0.0277  max mem: 20571\n",
      "Valid: [epoch:517] Total time: 0:00:00 (0.0508 s / it)\n",
      "Averaged stats: loss: 0.5780 (0.5835)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_517_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.583%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:518]  [  0/172]  eta: 0:07:43  lr: 0.000054  loss: 0.5900 (0.5900)  time: 2.6928  data: 1.1272  max mem: 20571\n",
      "Train: [epoch:518]  [ 10/172]  eta: 0:04:31  lr: 0.000054  loss: 0.6144 (0.6175)  time: 1.6787  data: 0.1026  max mem: 20571\n",
      "Train: [epoch:518]  [ 20/172]  eta: 0:04:07  lr: 0.000054  loss: 0.6210 (0.6214)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:518]  [ 30/172]  eta: 0:03:49  lr: 0.000054  loss: 0.6309 (0.6213)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [ 40/172]  eta: 0:03:31  lr: 0.000054  loss: 0.6285 (0.6253)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [ 50/172]  eta: 0:03:15  lr: 0.000054  loss: 0.6307 (0.6265)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [ 60/172]  eta: 0:02:58  lr: 0.000054  loss: 0.6262 (0.6251)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [ 70/172]  eta: 0:02:42  lr: 0.000054  loss: 0.6088 (0.6219)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:518]  [ 80/172]  eta: 0:02:26  lr: 0.000054  loss: 0.6093 (0.6236)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:518]  [ 90/172]  eta: 0:02:10  lr: 0.000054  loss: 0.6263 (0.6235)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [100/172]  eta: 0:01:54  lr: 0.000054  loss: 0.6234 (0.6237)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [110/172]  eta: 0:01:38  lr: 0.000054  loss: 0.6161 (0.6240)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [120/172]  eta: 0:01:22  lr: 0.000054  loss: 0.6157 (0.6241)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:518]  [130/172]  eta: 0:01:06  lr: 0.000054  loss: 0.6082 (0.6228)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [140/172]  eta: 0:00:50  lr: 0.000054  loss: 0.6082 (0.6223)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [150/172]  eta: 0:00:34  lr: 0.000054  loss: 0.6137 (0.6225)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [160/172]  eta: 0:00:19  lr: 0.000054  loss: 0.6111 (0.6217)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [170/172]  eta: 0:00:03  lr: 0.000054  loss: 0.6126 (0.6216)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518]  [171/172]  eta: 0:00:01  lr: 0.000054  loss: 0.6126 (0.6215)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:518] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000054  loss: 0.6126 (0.6215)\n",
      "Valid: [epoch:518]  [ 0/14]  eta: 0:00:06  loss: 0.5879 (0.5879)  time: 0.4653  data: 0.4479  max mem: 20571\n",
      "Valid: [epoch:518]  [13/14]  eta: 0:00:00  loss: 0.5879 (0.5926)  time: 0.0473  data: 0.0322  max mem: 20571\n",
      "Valid: [epoch:518] Total time: 0:00:00 (0.0557 s / it)\n",
      "Averaged stats: loss: 0.5879 (0.5926)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_518_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.593%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:519]  [  0/172]  eta: 0:07:38  lr: 0.000054  loss: 0.6879 (0.6879)  time: 2.6636  data: 1.0892  max mem: 20571\n",
      "Train: [epoch:519]  [ 10/172]  eta: 0:04:31  lr: 0.000054  loss: 0.6284 (0.6332)  time: 1.6751  data: 0.0992  max mem: 20571\n",
      "Train: [epoch:519]  [ 20/172]  eta: 0:04:07  lr: 0.000054  loss: 0.6163 (0.6279)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [ 30/172]  eta: 0:03:49  lr: 0.000054  loss: 0.6081 (0.6216)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [ 40/172]  eta: 0:03:32  lr: 0.000054  loss: 0.6115 (0.6203)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [ 50/172]  eta: 0:03:15  lr: 0.000054  loss: 0.6241 (0.6216)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [ 60/172]  eta: 0:02:58  lr: 0.000054  loss: 0.6320 (0.6230)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [ 70/172]  eta: 0:02:42  lr: 0.000054  loss: 0.6320 (0.6230)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [ 80/172]  eta: 0:02:26  lr: 0.000054  loss: 0.6093 (0.6225)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [ 90/172]  eta: 0:02:10  lr: 0.000054  loss: 0.6009 (0.6205)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [100/172]  eta: 0:01:54  lr: 0.000054  loss: 0.6082 (0.6208)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [110/172]  eta: 0:01:38  lr: 0.000054  loss: 0.6142 (0.6216)  time: 1.5822  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:519]  [120/172]  eta: 0:01:22  lr: 0.000054  loss: 0.6142 (0.6224)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [130/172]  eta: 0:01:06  lr: 0.000054  loss: 0.6149 (0.6230)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [140/172]  eta: 0:00:50  lr: 0.000054  loss: 0.6328 (0.6240)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [150/172]  eta: 0:00:34  lr: 0.000054  loss: 0.6197 (0.6238)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [160/172]  eta: 0:00:19  lr: 0.000054  loss: 0.6116 (0.6235)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [170/172]  eta: 0:00:03  lr: 0.000054  loss: 0.6149 (0.6237)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519]  [171/172]  eta: 0:00:01  lr: 0.000054  loss: 0.6149 (0.6238)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:519] Total time: 0:04:32 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000054  loss: 0.6149 (0.6238)\n",
      "Valid: [epoch:519]  [ 0/14]  eta: 0:00:04  loss: 0.6090 (0.6090)  time: 0.2984  data: 0.2829  max mem: 20571\n",
      "Valid: [epoch:519]  [13/14]  eta: 0:00:00  loss: 0.6090 (0.6139)  time: 0.0379  data: 0.0229  max mem: 20571\n",
      "Valid: [epoch:519] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.6090 (0.6139)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_519_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.614%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:520]  [  0/172]  eta: 0:08:17  lr: 0.000053  loss: 0.6385 (0.6385)  time: 2.8929  data: 1.3247  max mem: 20571\n",
      "Train: [epoch:520]  [ 10/172]  eta: 0:04:35  lr: 0.000053  loss: 0.6173 (0.6264)  time: 1.6987  data: 0.1205  max mem: 20571\n",
      "Train: [epoch:520]  [ 20/172]  eta: 0:04:09  lr: 0.000053  loss: 0.6041 (0.6187)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [ 30/172]  eta: 0:03:50  lr: 0.000053  loss: 0.6101 (0.6205)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [ 40/172]  eta: 0:03:32  lr: 0.000053  loss: 0.6174 (0.6193)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [ 50/172]  eta: 0:03:15  lr: 0.000053  loss: 0.6155 (0.6194)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [ 60/172]  eta: 0:02:59  lr: 0.000053  loss: 0.6155 (0.6200)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [ 70/172]  eta: 0:02:43  lr: 0.000053  loss: 0.6215 (0.6227)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [ 80/172]  eta: 0:02:26  lr: 0.000053  loss: 0.6379 (0.6233)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [ 90/172]  eta: 0:02:10  lr: 0.000053  loss: 0.6111 (0.6227)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [100/172]  eta: 0:01:54  lr: 0.000053  loss: 0.6173 (0.6221)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [110/172]  eta: 0:01:38  lr: 0.000053  loss: 0.6143 (0.6210)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [120/172]  eta: 0:01:22  lr: 0.000053  loss: 0.6290 (0.6231)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [130/172]  eta: 0:01:06  lr: 0.000053  loss: 0.6352 (0.6223)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [140/172]  eta: 0:00:50  lr: 0.000053  loss: 0.6230 (0.6231)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [150/172]  eta: 0:00:34  lr: 0.000053  loss: 0.6320 (0.6243)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [160/172]  eta: 0:00:19  lr: 0.000053  loss: 0.6379 (0.6266)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [170/172]  eta: 0:00:03  lr: 0.000053  loss: 0.6379 (0.6285)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520]  [171/172]  eta: 0:00:01  lr: 0.000053  loss: 0.6379 (0.6286)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:520] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000053  loss: 0.6379 (0.6286)\n",
      "Valid: [epoch:520]  [ 0/14]  eta: 0:00:06  loss: 0.6153 (0.6153)  time: 0.4908  data: 0.4743  max mem: 20571\n",
      "Valid: [epoch:520]  [13/14]  eta: 0:00:00  loss: 0.5856 (0.5920)  time: 0.0491  data: 0.0340  max mem: 20571\n",
      "Valid: [epoch:520] Total time: 0:00:00 (0.0540 s / it)\n",
      "Averaged stats: loss: 0.5856 (0.5920)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_520_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.592%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:521]  [  0/172]  eta: 0:08:03  lr: 0.000053  loss: 0.5824 (0.5824)  time: 2.8115  data: 1.2260  max mem: 20571\n",
      "Train: [epoch:521]  [ 10/172]  eta: 0:04:33  lr: 0.000053  loss: 0.6238 (0.6251)  time: 1.6903  data: 0.1116  max mem: 20571\n",
      "Train: [epoch:521]  [ 20/172]  eta: 0:04:08  lr: 0.000053  loss: 0.6157 (0.6165)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [ 30/172]  eta: 0:03:49  lr: 0.000053  loss: 0.6085 (0.6157)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [ 40/172]  eta: 0:03:32  lr: 0.000053  loss: 0.6088 (0.6161)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [ 50/172]  eta: 0:03:15  lr: 0.000053  loss: 0.6168 (0.6196)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [ 60/172]  eta: 0:02:59  lr: 0.000053  loss: 0.6168 (0.6187)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [ 70/172]  eta: 0:02:42  lr: 0.000053  loss: 0.6079 (0.6179)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [ 80/172]  eta: 0:02:26  lr: 0.000053  loss: 0.6253 (0.6195)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [ 90/172]  eta: 0:02:10  lr: 0.000053  loss: 0.6316 (0.6202)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [100/172]  eta: 0:01:54  lr: 0.000053  loss: 0.6063 (0.6205)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [110/172]  eta: 0:01:38  lr: 0.000053  loss: 0.6238 (0.6231)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [120/172]  eta: 0:01:22  lr: 0.000053  loss: 0.6227 (0.6231)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [130/172]  eta: 0:01:06  lr: 0.000053  loss: 0.6103 (0.6230)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [140/172]  eta: 0:00:50  lr: 0.000053  loss: 0.6150 (0.6237)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [150/172]  eta: 0:00:34  lr: 0.000053  loss: 0.6150 (0.6229)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [160/172]  eta: 0:00:19  lr: 0.000053  loss: 0.6167 (0.6227)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [170/172]  eta: 0:00:03  lr: 0.000053  loss: 0.6193 (0.6220)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521]  [171/172]  eta: 0:00:01  lr: 0.000053  loss: 0.6193 (0.6222)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:521] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000053  loss: 0.6193 (0.6222)\n",
      "Valid: [epoch:521]  [ 0/14]  eta: 0:00:03  loss: 0.5786 (0.5786)  time: 0.2817  data: 0.2668  max mem: 20571\n",
      "Valid: [epoch:521]  [13/14]  eta: 0:00:00  loss: 0.5907 (0.5956)  time: 0.0479  data: 0.0328  max mem: 20571\n",
      "Valid: [epoch:521] Total time: 0:00:00 (0.0535 s / it)\n",
      "Averaged stats: loss: 0.5907 (0.5956)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_521_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.596%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:522]  [  0/172]  eta: 0:07:43  lr: 0.000053  loss: 0.6997 (0.6997)  time: 2.6931  data: 1.1248  max mem: 20571\n",
      "Train: [epoch:522]  [ 10/172]  eta: 0:04:32  lr: 0.000053  loss: 0.6062 (0.6213)  time: 1.6799  data: 0.1024  max mem: 20571\n",
      "Train: [epoch:522]  [ 20/172]  eta: 0:04:08  lr: 0.000053  loss: 0.6170 (0.6285)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [ 30/172]  eta: 0:03:49  lr: 0.000053  loss: 0.6170 (0.6255)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [ 40/172]  eta: 0:03:32  lr: 0.000053  loss: 0.6140 (0.6247)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [ 50/172]  eta: 0:03:15  lr: 0.000053  loss: 0.6075 (0.6205)  time: 1.5815  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:522]  [ 60/172]  eta: 0:02:59  lr: 0.000053  loss: 0.6020 (0.6207)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [ 70/172]  eta: 0:02:42  lr: 0.000053  loss: 0.6290 (0.6261)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [ 80/172]  eta: 0:02:26  lr: 0.000053  loss: 0.6346 (0.6268)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [ 90/172]  eta: 0:02:10  lr: 0.000053  loss: 0.6054 (0.6238)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [100/172]  eta: 0:01:54  lr: 0.000053  loss: 0.6026 (0.6251)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [110/172]  eta: 0:01:38  lr: 0.000053  loss: 0.6334 (0.6262)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [120/172]  eta: 0:01:22  lr: 0.000053  loss: 0.6471 (0.6285)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [130/172]  eta: 0:01:06  lr: 0.000053  loss: 0.6381 (0.6285)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [140/172]  eta: 0:00:50  lr: 0.000053  loss: 0.6328 (0.6283)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [150/172]  eta: 0:00:34  lr: 0.000053  loss: 0.6199 (0.6280)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [160/172]  eta: 0:00:19  lr: 0.000053  loss: 0.6138 (0.6277)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [170/172]  eta: 0:00:03  lr: 0.000053  loss: 0.6204 (0.6276)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522]  [171/172]  eta: 0:00:01  lr: 0.000053  loss: 0.6253 (0.6277)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:522] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000053  loss: 0.6253 (0.6277)\n",
      "Valid: [epoch:522]  [ 0/14]  eta: 0:00:06  loss: 0.5536 (0.5536)  time: 0.4333  data: 0.4162  max mem: 20571\n",
      "Valid: [epoch:522]  [13/14]  eta: 0:00:00  loss: 0.5857 (0.5918)  time: 0.0455  data: 0.0302  max mem: 20571\n",
      "Valid: [epoch:522] Total time: 0:00:00 (0.0513 s / it)\n",
      "Averaged stats: loss: 0.5857 (0.5918)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_522_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.592%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:523]  [  0/172]  eta: 0:07:30  lr: 0.000053  loss: 0.5860 (0.5860)  time: 2.6185  data: 1.0474  max mem: 20571\n",
      "Train: [epoch:523]  [ 10/172]  eta: 0:04:30  lr: 0.000053  loss: 0.6202 (0.6277)  time: 1.6723  data: 0.0953  max mem: 20571\n",
      "Train: [epoch:523]  [ 20/172]  eta: 0:04:07  lr: 0.000053  loss: 0.6202 (0.6285)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [ 30/172]  eta: 0:03:49  lr: 0.000053  loss: 0.6282 (0.6288)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [ 40/172]  eta: 0:03:31  lr: 0.000053  loss: 0.6095 (0.6249)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [ 50/172]  eta: 0:03:15  lr: 0.000053  loss: 0.6107 (0.6250)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [ 60/172]  eta: 0:02:58  lr: 0.000053  loss: 0.6238 (0.6255)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [ 70/172]  eta: 0:02:42  lr: 0.000053  loss: 0.6219 (0.6255)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [ 80/172]  eta: 0:02:26  lr: 0.000053  loss: 0.6130 (0.6248)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [ 90/172]  eta: 0:02:10  lr: 0.000053  loss: 0.6122 (0.6238)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [100/172]  eta: 0:01:54  lr: 0.000053  loss: 0.6128 (0.6232)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [110/172]  eta: 0:01:38  lr: 0.000053  loss: 0.6217 (0.6231)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [120/172]  eta: 0:01:22  lr: 0.000053  loss: 0.6082 (0.6217)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [130/172]  eta: 0:01:06  lr: 0.000053  loss: 0.6070 (0.6215)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [140/172]  eta: 0:00:50  lr: 0.000053  loss: 0.6202 (0.6228)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [150/172]  eta: 0:00:34  lr: 0.000053  loss: 0.6165 (0.6224)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [160/172]  eta: 0:00:19  lr: 0.000053  loss: 0.6165 (0.6229)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [170/172]  eta: 0:00:03  lr: 0.000053  loss: 0.6236 (0.6232)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523]  [171/172]  eta: 0:00:01  lr: 0.000053  loss: 0.6236 (0.6235)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:523] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000053  loss: 0.6236 (0.6235)\n",
      "Valid: [epoch:523]  [ 0/14]  eta: 0:00:04  loss: 0.6379 (0.6379)  time: 0.2878  data: 0.2716  max mem: 20571\n",
      "Valid: [epoch:523]  [13/14]  eta: 0:00:00  loss: 0.5865 (0.5929)  time: 0.0402  data: 0.0252  max mem: 20571\n",
      "Valid: [epoch:523] Total time: 0:00:00 (0.0485 s / it)\n",
      "Averaged stats: loss: 0.5865 (0.5929)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_523_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.593%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:524]  [  0/172]  eta: 0:07:42  lr: 0.000053  loss: 0.5690 (0.5690)  time: 2.6880  data: 1.1191  max mem: 20571\n",
      "Train: [epoch:524]  [ 10/172]  eta: 0:04:32  lr: 0.000053  loss: 0.6146 (0.6220)  time: 1.6818  data: 0.1019  max mem: 20571\n",
      "Train: [epoch:524]  [ 20/172]  eta: 0:04:08  lr: 0.000053  loss: 0.6146 (0.6192)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:524]  [ 30/172]  eta: 0:03:49  lr: 0.000053  loss: 0.6398 (0.6270)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [ 40/172]  eta: 0:03:32  lr: 0.000053  loss: 0.6350 (0.6274)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [ 50/172]  eta: 0:03:15  lr: 0.000053  loss: 0.6116 (0.6257)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [ 60/172]  eta: 0:02:59  lr: 0.000053  loss: 0.6116 (0.6242)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [ 70/172]  eta: 0:02:43  lr: 0.000053  loss: 0.6073 (0.6238)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [ 80/172]  eta: 0:02:26  lr: 0.000053  loss: 0.5947 (0.6228)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [ 90/172]  eta: 0:02:10  lr: 0.000053  loss: 0.6144 (0.6221)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [100/172]  eta: 0:01:54  lr: 0.000053  loss: 0.6188 (0.6220)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [110/172]  eta: 0:01:38  lr: 0.000053  loss: 0.6200 (0.6219)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [120/172]  eta: 0:01:22  lr: 0.000053  loss: 0.6278 (0.6232)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [130/172]  eta: 0:01:06  lr: 0.000053  loss: 0.6278 (0.6223)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [140/172]  eta: 0:00:50  lr: 0.000053  loss: 0.6075 (0.6216)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [150/172]  eta: 0:00:34  lr: 0.000053  loss: 0.6230 (0.6224)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [160/172]  eta: 0:00:19  lr: 0.000053  loss: 0.6322 (0.6239)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [170/172]  eta: 0:00:03  lr: 0.000053  loss: 0.6297 (0.6247)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524]  [171/172]  eta: 0:00:01  lr: 0.000053  loss: 0.6297 (0.6249)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:524] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000053  loss: 0.6297 (0.6249)\n",
      "Valid: [epoch:524]  [ 0/14]  eta: 0:00:05  loss: 0.6215 (0.6215)  time: 0.3867  data: 0.3710  max mem: 20571\n",
      "Valid: [epoch:524]  [13/14]  eta: 0:00:00  loss: 0.5940 (0.5988)  time: 0.0518  data: 0.0367  max mem: 20571\n",
      "Valid: [epoch:524] Total time: 0:00:00 (0.0592 s / it)\n",
      "Averaged stats: loss: 0.5940 (0.5988)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_524_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.599%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:525]  [  0/172]  eta: 0:07:56  lr: 0.000053  loss: 0.5752 (0.5752)  time: 2.7704  data: 1.1717  max mem: 20571\n",
      "Train: [epoch:525]  [ 10/172]  eta: 0:04:33  lr: 0.000053  loss: 0.6085 (0.6244)  time: 1.6864  data: 0.1067  max mem: 20571\n",
      "Train: [epoch:525]  [ 20/172]  eta: 0:04:08  lr: 0.000053  loss: 0.6252 (0.6267)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:525]  [ 30/172]  eta: 0:03:49  lr: 0.000053  loss: 0.6252 (0.6223)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [ 40/172]  eta: 0:03:32  lr: 0.000053  loss: 0.6108 (0.6215)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [ 50/172]  eta: 0:03:15  lr: 0.000053  loss: 0.6109 (0.6210)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [ 60/172]  eta: 0:02:59  lr: 0.000053  loss: 0.6241 (0.6221)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [ 70/172]  eta: 0:02:42  lr: 0.000053  loss: 0.6290 (0.6248)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [ 80/172]  eta: 0:02:26  lr: 0.000053  loss: 0.6446 (0.6255)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [ 90/172]  eta: 0:02:10  lr: 0.000053  loss: 0.6416 (0.6286)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [100/172]  eta: 0:01:54  lr: 0.000053  loss: 0.6278 (0.6284)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [110/172]  eta: 0:01:38  lr: 0.000053  loss: 0.6227 (0.6284)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [120/172]  eta: 0:01:22  lr: 0.000053  loss: 0.6227 (0.6307)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [130/172]  eta: 0:01:06  lr: 0.000053  loss: 0.6222 (0.6304)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [140/172]  eta: 0:00:50  lr: 0.000053  loss: 0.6235 (0.6305)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [150/172]  eta: 0:00:34  lr: 0.000053  loss: 0.6292 (0.6303)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [160/172]  eta: 0:00:19  lr: 0.000053  loss: 0.6218 (0.6297)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [170/172]  eta: 0:00:03  lr: 0.000053  loss: 0.6218 (0.6293)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525]  [171/172]  eta: 0:00:01  lr: 0.000053  loss: 0.6201 (0.6290)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:525] Total time: 0:04:33 (1.5896 s / it)\n",
      "Averaged stats: lr: 0.000053  loss: 0.6201 (0.6290)\n",
      "Valid: [epoch:525]  [ 0/14]  eta: 0:00:05  loss: 0.5356 (0.5356)  time: 0.3971  data: 0.3800  max mem: 20571\n",
      "Valid: [epoch:525]  [13/14]  eta: 0:00:00  loss: 0.5958 (0.6007)  time: 0.0425  data: 0.0273  max mem: 20571\n",
      "Valid: [epoch:525] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.5958 (0.6007)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_525_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.601%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:526]  [  0/172]  eta: 0:07:36  lr: 0.000053  loss: 0.6073 (0.6073)  time: 2.6520  data: 1.0820  max mem: 20571\n",
      "Train: [epoch:526]  [ 10/172]  eta: 0:04:31  lr: 0.000053  loss: 0.6379 (0.6400)  time: 1.6771  data: 0.0985  max mem: 20571\n",
      "Train: [epoch:526]  [ 20/172]  eta: 0:04:07  lr: 0.000053  loss: 0.6331 (0.6350)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [ 30/172]  eta: 0:03:49  lr: 0.000053  loss: 0.6183 (0.6319)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [ 40/172]  eta: 0:03:32  lr: 0.000053  loss: 0.6154 (0.6314)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [ 50/172]  eta: 0:03:15  lr: 0.000053  loss: 0.6162 (0.6291)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [ 60/172]  eta: 0:02:59  lr: 0.000053  loss: 0.6159 (0.6293)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [ 70/172]  eta: 0:02:42  lr: 0.000053  loss: 0.6218 (0.6291)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [ 80/172]  eta: 0:02:26  lr: 0.000053  loss: 0.6237 (0.6278)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [ 90/172]  eta: 0:02:10  lr: 0.000053  loss: 0.6262 (0.6279)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [100/172]  eta: 0:01:54  lr: 0.000053  loss: 0.6323 (0.6278)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [110/172]  eta: 0:01:38  lr: 0.000053  loss: 0.6323 (0.6273)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [120/172]  eta: 0:01:22  lr: 0.000053  loss: 0.6135 (0.6263)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [130/172]  eta: 0:01:06  lr: 0.000053  loss: 0.6221 (0.6276)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [140/172]  eta: 0:00:50  lr: 0.000053  loss: 0.6321 (0.6275)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [150/172]  eta: 0:00:34  lr: 0.000053  loss: 0.6245 (0.6273)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [160/172]  eta: 0:00:19  lr: 0.000053  loss: 0.6390 (0.6285)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [170/172]  eta: 0:00:03  lr: 0.000053  loss: 0.6294 (0.6287)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526]  [171/172]  eta: 0:00:01  lr: 0.000053  loss: 0.6263 (0.6286)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:526] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000053  loss: 0.6263 (0.6286)\n",
      "Valid: [epoch:526]  [ 0/14]  eta: 0:00:04  loss: 0.6180 (0.6180)  time: 0.2942  data: 0.2768  max mem: 20571\n",
      "Valid: [epoch:526]  [13/14]  eta: 0:00:00  loss: 0.5888 (0.5954)  time: 0.0366  data: 0.0215  max mem: 20571\n",
      "Valid: [epoch:526] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.5888 (0.5954)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_526_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.595%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:527]  [  0/172]  eta: 0:07:52  lr: 0.000053  loss: 0.6441 (0.6441)  time: 2.7496  data: 1.1746  max mem: 20571\n",
      "Train: [epoch:527]  [ 10/172]  eta: 0:04:32  lr: 0.000053  loss: 0.6125 (0.6252)  time: 1.6844  data: 0.1069  max mem: 20571\n",
      "Train: [epoch:527]  [ 20/172]  eta: 0:04:08  lr: 0.000053  loss: 0.6122 (0.6220)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [ 30/172]  eta: 0:03:49  lr: 0.000053  loss: 0.6197 (0.6276)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [ 40/172]  eta: 0:03:32  lr: 0.000053  loss: 0.6298 (0.6262)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [ 50/172]  eta: 0:03:15  lr: 0.000053  loss: 0.6298 (0.6266)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [ 60/172]  eta: 0:02:59  lr: 0.000053  loss: 0.6476 (0.6299)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [ 70/172]  eta: 0:02:42  lr: 0.000053  loss: 0.6467 (0.6320)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [ 80/172]  eta: 0:02:26  lr: 0.000053  loss: 0.6356 (0.6324)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [ 90/172]  eta: 0:02:10  lr: 0.000053  loss: 0.6190 (0.6308)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [100/172]  eta: 0:01:54  lr: 0.000053  loss: 0.6018 (0.6298)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [110/172]  eta: 0:01:38  lr: 0.000053  loss: 0.6068 (0.6297)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [120/172]  eta: 0:01:22  lr: 0.000053  loss: 0.6411 (0.6301)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [130/172]  eta: 0:01:06  lr: 0.000053  loss: 0.6374 (0.6309)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [140/172]  eta: 0:00:50  lr: 0.000053  loss: 0.6294 (0.6300)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [150/172]  eta: 0:00:34  lr: 0.000053  loss: 0.6300 (0.6293)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [160/172]  eta: 0:00:19  lr: 0.000053  loss: 0.6331 (0.6300)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527]  [170/172]  eta: 0:00:03  lr: 0.000053  loss: 0.6291 (0.6297)  time: 1.5820  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:527]  [171/172]  eta: 0:00:01  lr: 0.000053  loss: 0.6291 (0.6295)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:527] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000053  loss: 0.6291 (0.6295)\n",
      "Valid: [epoch:527]  [ 0/14]  eta: 0:00:04  loss: 0.6199 (0.6199)  time: 0.3286  data: 0.3136  max mem: 20571\n",
      "Valid: [epoch:527]  [13/14]  eta: 0:00:00  loss: 0.5846 (0.5907)  time: 0.0388  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:527] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.5846 (0.5907)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_527_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.591%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:528]  [  0/172]  eta: 0:08:02  lr: 0.000053  loss: 0.5797 (0.5797)  time: 2.8056  data: 1.2390  max mem: 20571\n",
      "Train: [epoch:528]  [ 10/172]  eta: 0:04:33  lr: 0.000053  loss: 0.6346 (0.6234)  time: 1.6888  data: 0.1127  max mem: 20571\n",
      "Train: [epoch:528]  [ 20/172]  eta: 0:04:08  lr: 0.000053  loss: 0.6266 (0.6272)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [ 30/172]  eta: 0:03:49  lr: 0.000053  loss: 0.6257 (0.6252)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [ 40/172]  eta: 0:03:32  lr: 0.000053  loss: 0.6257 (0.6266)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [ 50/172]  eta: 0:03:15  lr: 0.000053  loss: 0.6148 (0.6266)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [ 60/172]  eta: 0:02:59  lr: 0.000053  loss: 0.6221 (0.6247)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [ 70/172]  eta: 0:02:42  lr: 0.000053  loss: 0.6221 (0.6251)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [ 80/172]  eta: 0:02:26  lr: 0.000053  loss: 0.6233 (0.6269)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [ 90/172]  eta: 0:02:10  lr: 0.000053  loss: 0.6167 (0.6274)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [100/172]  eta: 0:01:54  lr: 0.000053  loss: 0.6381 (0.6307)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [110/172]  eta: 0:01:38  lr: 0.000053  loss: 0.6437 (0.6320)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [120/172]  eta: 0:01:22  lr: 0.000053  loss: 0.6357 (0.6339)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [130/172]  eta: 0:01:06  lr: 0.000053  loss: 0.6360 (0.6354)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [140/172]  eta: 0:00:50  lr: 0.000053  loss: 0.6401 (0.6353)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [150/172]  eta: 0:00:34  lr: 0.000053  loss: 0.6166 (0.6340)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [160/172]  eta: 0:00:19  lr: 0.000053  loss: 0.6110 (0.6327)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [170/172]  eta: 0:00:03  lr: 0.000053  loss: 0.6118 (0.6328)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528]  [171/172]  eta: 0:00:01  lr: 0.000053  loss: 0.6147 (0.6328)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:528] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000053  loss: 0.6147 (0.6328)\n",
      "Valid: [epoch:528]  [ 0/14]  eta: 0:00:05  loss: 0.5915 (0.5915)  time: 0.4243  data: 0.4070  max mem: 20571\n",
      "Valid: [epoch:528]  [13/14]  eta: 0:00:00  loss: 0.5985 (0.6033)  time: 0.0447  data: 0.0295  max mem: 20571\n",
      "Valid: [epoch:528] Total time: 0:00:00 (0.0516 s / it)\n",
      "Averaged stats: loss: 0.5985 (0.6033)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_528_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.603%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:529]  [  0/172]  eta: 0:07:54  lr: 0.000052  loss: 0.6513 (0.6513)  time: 2.7600  data: 1.1722  max mem: 20571\n",
      "Train: [epoch:529]  [ 10/172]  eta: 0:04:32  lr: 0.000052  loss: 0.6438 (0.6371)  time: 1.6847  data: 0.1067  max mem: 20571\n",
      "Train: [epoch:529]  [ 20/172]  eta: 0:04:08  lr: 0.000052  loss: 0.6342 (0.6388)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [ 30/172]  eta: 0:03:49  lr: 0.000052  loss: 0.6140 (0.6298)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [ 40/172]  eta: 0:03:32  lr: 0.000052  loss: 0.6140 (0.6293)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [ 50/172]  eta: 0:03:15  lr: 0.000052  loss: 0.6229 (0.6299)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [ 60/172]  eta: 0:02:59  lr: 0.000052  loss: 0.6293 (0.6295)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [ 70/172]  eta: 0:02:43  lr: 0.000052  loss: 0.6269 (0.6296)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [ 80/172]  eta: 0:02:26  lr: 0.000052  loss: 0.6269 (0.6293)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [ 90/172]  eta: 0:02:10  lr: 0.000052  loss: 0.6250 (0.6292)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [100/172]  eta: 0:01:54  lr: 0.000052  loss: 0.6250 (0.6293)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [110/172]  eta: 0:01:38  lr: 0.000052  loss: 0.6230 (0.6292)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [120/172]  eta: 0:01:22  lr: 0.000052  loss: 0.6230 (0.6292)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [130/172]  eta: 0:01:06  lr: 0.000052  loss: 0.6271 (0.6297)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [140/172]  eta: 0:00:50  lr: 0.000052  loss: 0.6185 (0.6292)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [150/172]  eta: 0:00:34  lr: 0.000052  loss: 0.6185 (0.6287)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [160/172]  eta: 0:00:19  lr: 0.000052  loss: 0.6301 (0.6291)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [170/172]  eta: 0:00:03  lr: 0.000052  loss: 0.6402 (0.6299)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529]  [171/172]  eta: 0:00:01  lr: 0.000052  loss: 0.6352 (0.6299)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:529] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000052  loss: 0.6352 (0.6299)\n",
      "Valid: [epoch:529]  [ 0/14]  eta: 0:00:05  loss: 0.5342 (0.5342)  time: 0.3938  data: 0.3738  max mem: 20571\n",
      "Valid: [epoch:529]  [13/14]  eta: 0:00:00  loss: 0.5953 (0.6007)  time: 0.0436  data: 0.0282  max mem: 20571\n",
      "Valid: [epoch:529] Total time: 0:00:00 (0.0517 s / it)\n",
      "Averaged stats: loss: 0.5953 (0.6007)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_529_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.601%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:530]  [  0/172]  eta: 0:07:52  lr: 0.000052  loss: 0.6061 (0.6061)  time: 2.7461  data: 1.1788  max mem: 20571\n",
      "Train: [epoch:530]  [ 10/172]  eta: 0:04:33  lr: 0.000052  loss: 0.6285 (0.6293)  time: 1.6873  data: 0.1073  max mem: 20571\n",
      "Train: [epoch:530]  [ 20/172]  eta: 0:04:08  lr: 0.000052  loss: 0.6285 (0.6293)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [ 30/172]  eta: 0:03:49  lr: 0.000052  loss: 0.6173 (0.6283)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [ 40/172]  eta: 0:03:32  lr: 0.000052  loss: 0.6173 (0.6264)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [ 50/172]  eta: 0:03:15  lr: 0.000052  loss: 0.6266 (0.6296)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [ 60/172]  eta: 0:02:59  lr: 0.000052  loss: 0.6359 (0.6302)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [ 70/172]  eta: 0:02:43  lr: 0.000052  loss: 0.6428 (0.6311)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [ 80/172]  eta: 0:02:26  lr: 0.000052  loss: 0.6212 (0.6320)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [ 90/172]  eta: 0:02:10  lr: 0.000052  loss: 0.6197 (0.6322)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [100/172]  eta: 0:01:54  lr: 0.000052  loss: 0.6134 (0.6311)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [110/172]  eta: 0:01:38  lr: 0.000052  loss: 0.6131 (0.6319)  time: 1.5821  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:530]  [120/172]  eta: 0:01:22  lr: 0.000052  loss: 0.6391 (0.6327)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [130/172]  eta: 0:01:06  lr: 0.000052  loss: 0.6308 (0.6320)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [140/172]  eta: 0:00:50  lr: 0.000052  loss: 0.6228 (0.6319)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [150/172]  eta: 0:00:34  lr: 0.000052  loss: 0.6228 (0.6322)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [160/172]  eta: 0:00:19  lr: 0.000052  loss: 0.6249 (0.6321)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [170/172]  eta: 0:00:03  lr: 0.000052  loss: 0.6232 (0.6321)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530]  [171/172]  eta: 0:00:01  lr: 0.000052  loss: 0.6249 (0.6321)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:530] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000052  loss: 0.6249 (0.6321)\n",
      "Valid: [epoch:530]  [ 0/14]  eta: 0:00:04  loss: 0.5366 (0.5366)  time: 0.2978  data: 0.2824  max mem: 20571\n",
      "Valid: [epoch:530]  [13/14]  eta: 0:00:00  loss: 0.5955 (0.6025)  time: 0.0377  data: 0.0223  max mem: 20571\n",
      "Valid: [epoch:530] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.5955 (0.6025)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_530_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.602%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:531]  [  0/172]  eta: 0:07:30  lr: 0.000052  loss: 0.6360 (0.6360)  time: 2.6202  data: 1.0456  max mem: 20571\n",
      "Train: [epoch:531]  [ 10/172]  eta: 0:04:31  lr: 0.000052  loss: 0.6405 (0.6419)  time: 1.6740  data: 0.0952  max mem: 20571\n",
      "Train: [epoch:531]  [ 20/172]  eta: 0:04:07  lr: 0.000052  loss: 0.6284 (0.6419)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [ 30/172]  eta: 0:03:49  lr: 0.000052  loss: 0.6269 (0.6397)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [ 40/172]  eta: 0:03:32  lr: 0.000052  loss: 0.6296 (0.6382)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [ 50/172]  eta: 0:03:15  lr: 0.000052  loss: 0.6416 (0.6409)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [ 60/172]  eta: 0:02:59  lr: 0.000052  loss: 0.6423 (0.6402)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [ 70/172]  eta: 0:02:42  lr: 0.000052  loss: 0.6307 (0.6385)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [ 80/172]  eta: 0:02:26  lr: 0.000052  loss: 0.6179 (0.6360)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [ 90/172]  eta: 0:02:10  lr: 0.000052  loss: 0.6073 (0.6356)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [100/172]  eta: 0:01:54  lr: 0.000052  loss: 0.6175 (0.6345)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [110/172]  eta: 0:01:38  lr: 0.000052  loss: 0.6214 (0.6342)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [120/172]  eta: 0:01:22  lr: 0.000052  loss: 0.6247 (0.6343)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [130/172]  eta: 0:01:06  lr: 0.000052  loss: 0.6319 (0.6336)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [140/172]  eta: 0:00:50  lr: 0.000052  loss: 0.6335 (0.6340)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [150/172]  eta: 0:00:34  lr: 0.000052  loss: 0.6416 (0.6349)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [160/172]  eta: 0:00:19  lr: 0.000052  loss: 0.6383 (0.6347)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [170/172]  eta: 0:00:03  lr: 0.000052  loss: 0.6243 (0.6345)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531]  [171/172]  eta: 0:00:01  lr: 0.000052  loss: 0.6243 (0.6345)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:531] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000052  loss: 0.6243 (0.6345)\n",
      "Valid: [epoch:531]  [ 0/14]  eta: 0:00:05  loss: 0.6588 (0.6588)  time: 0.3865  data: 0.3710  max mem: 20571\n",
      "Valid: [epoch:531]  [13/14]  eta: 0:00:00  loss: 0.6243 (0.6312)  time: 0.0426  data: 0.0276  max mem: 20571\n",
      "Valid: [epoch:531] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.6243 (0.6312)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_531_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.631%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:532]  [  0/172]  eta: 0:07:38  lr: 0.000052  loss: 0.6755 (0.6755)  time: 2.6632  data: 1.0764  max mem: 20571\n",
      "Train: [epoch:532]  [ 10/172]  eta: 0:04:32  lr: 0.000052  loss: 0.6218 (0.6209)  time: 1.6817  data: 0.0980  max mem: 20571\n",
      "Train: [epoch:532]  [ 20/172]  eta: 0:04:08  lr: 0.000052  loss: 0.6218 (0.6259)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [ 30/172]  eta: 0:03:49  lr: 0.000052  loss: 0.6306 (0.6269)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [ 40/172]  eta: 0:03:32  lr: 0.000052  loss: 0.6345 (0.6292)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [ 50/172]  eta: 0:03:15  lr: 0.000052  loss: 0.6358 (0.6309)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [ 60/172]  eta: 0:02:59  lr: 0.000052  loss: 0.6263 (0.6315)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [ 70/172]  eta: 0:02:43  lr: 0.000052  loss: 0.6365 (0.6326)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:532]  [ 80/172]  eta: 0:02:26  lr: 0.000052  loss: 0.6405 (0.6320)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:532]  [ 90/172]  eta: 0:02:10  lr: 0.000052  loss: 0.6405 (0.6321)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [100/172]  eta: 0:01:54  lr: 0.000052  loss: 0.6231 (0.6311)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [110/172]  eta: 0:01:38  lr: 0.000052  loss: 0.6231 (0.6308)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [120/172]  eta: 0:01:22  lr: 0.000052  loss: 0.6292 (0.6327)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [130/172]  eta: 0:01:06  lr: 0.000052  loss: 0.6232 (0.6325)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [140/172]  eta: 0:00:50  lr: 0.000052  loss: 0.6287 (0.6329)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [150/172]  eta: 0:00:34  lr: 0.000052  loss: 0.6309 (0.6342)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [160/172]  eta: 0:00:19  lr: 0.000052  loss: 0.6306 (0.6337)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [170/172]  eta: 0:00:03  lr: 0.000052  loss: 0.6155 (0.6330)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532]  [171/172]  eta: 0:00:01  lr: 0.000052  loss: 0.6140 (0.6329)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:532] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000052  loss: 0.6140 (0.6329)\n",
      "Valid: [epoch:532]  [ 0/14]  eta: 0:00:06  loss: 0.6371 (0.6371)  time: 0.4678  data: 0.4442  max mem: 20571\n",
      "Valid: [epoch:532]  [13/14]  eta: 0:00:00  loss: 0.5981 (0.6040)  time: 0.0479  data: 0.0323  max mem: 20571\n",
      "Valid: [epoch:532] Total time: 0:00:00 (0.0535 s / it)\n",
      "Averaged stats: loss: 0.5981 (0.6040)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_532_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.604%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:533]  [  0/172]  eta: 0:07:55  lr: 0.000052  loss: 0.6308 (0.6308)  time: 2.7641  data: 1.1868  max mem: 20571\n",
      "Train: [epoch:533]  [ 10/172]  eta: 0:04:32  lr: 0.000052  loss: 0.6329 (0.6347)  time: 1.6834  data: 0.1080  max mem: 20571\n",
      "Train: [epoch:533]  [ 20/172]  eta: 0:04:08  lr: 0.000052  loss: 0.6285 (0.6311)  time: 1.5771  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:533]  [ 30/172]  eta: 0:03:49  lr: 0.000052  loss: 0.6263 (0.6352)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:533]  [ 40/172]  eta: 0:03:32  lr: 0.000052  loss: 0.6277 (0.6331)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [ 50/172]  eta: 0:03:15  lr: 0.000052  loss: 0.6277 (0.6333)  time: 1.5809  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:533]  [ 60/172]  eta: 0:02:59  lr: 0.000052  loss: 0.6268 (0.6319)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [ 70/172]  eta: 0:02:42  lr: 0.000052  loss: 0.6169 (0.6323)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [ 80/172]  eta: 0:02:26  lr: 0.000052  loss: 0.6379 (0.6326)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [ 90/172]  eta: 0:02:10  lr: 0.000052  loss: 0.6268 (0.6323)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [100/172]  eta: 0:01:54  lr: 0.000052  loss: 0.6213 (0.6318)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [110/172]  eta: 0:01:38  lr: 0.000052  loss: 0.6247 (0.6323)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [120/172]  eta: 0:01:22  lr: 0.000052  loss: 0.6265 (0.6316)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [130/172]  eta: 0:01:06  lr: 0.000052  loss: 0.6267 (0.6326)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [140/172]  eta: 0:00:50  lr: 0.000052  loss: 0.6267 (0.6326)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:533]  [150/172]  eta: 0:00:34  lr: 0.000052  loss: 0.6248 (0.6330)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:533]  [160/172]  eta: 0:00:19  lr: 0.000052  loss: 0.6248 (0.6321)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [170/172]  eta: 0:00:03  lr: 0.000052  loss: 0.6245 (0.6327)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533]  [171/172]  eta: 0:00:01  lr: 0.000052  loss: 0.6245 (0.6331)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:533] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000052  loss: 0.6245 (0.6331)\n",
      "Valid: [epoch:533]  [ 0/14]  eta: 0:00:04  loss: 0.6465 (0.6465)  time: 0.2973  data: 0.2824  max mem: 20571\n",
      "Valid: [epoch:533]  [13/14]  eta: 0:00:00  loss: 0.5944 (0.6009)  time: 0.0421  data: 0.0271  max mem: 20571\n",
      "Valid: [epoch:533] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.5944 (0.6009)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_533_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.601%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:534]  [  0/172]  eta: 0:08:37  lr: 0.000052  loss: 0.6191 (0.6191)  time: 3.0092  data: 1.4217  max mem: 20571\n",
      "Train: [epoch:534]  [ 10/172]  eta: 0:04:36  lr: 0.000052  loss: 0.6190 (0.6247)  time: 1.7072  data: 0.1294  max mem: 20571\n",
      "Train: [epoch:534]  [ 20/172]  eta: 0:04:10  lr: 0.000052  loss: 0.6115 (0.6292)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [ 30/172]  eta: 0:03:50  lr: 0.000052  loss: 0.6023 (0.6237)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [ 40/172]  eta: 0:03:33  lr: 0.000052  loss: 0.6130 (0.6258)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:534]  [ 50/172]  eta: 0:03:16  lr: 0.000052  loss: 0.6130 (0.6247)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [ 60/172]  eta: 0:02:59  lr: 0.000052  loss: 0.6261 (0.6282)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [ 70/172]  eta: 0:02:43  lr: 0.000052  loss: 0.6357 (0.6292)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [ 80/172]  eta: 0:02:26  lr: 0.000052  loss: 0.6248 (0.6304)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [ 90/172]  eta: 0:02:10  lr: 0.000052  loss: 0.6344 (0.6305)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [100/172]  eta: 0:01:54  lr: 0.000052  loss: 0.6386 (0.6317)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:534]  [110/172]  eta: 0:01:38  lr: 0.000052  loss: 0.6386 (0.6320)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:534]  [120/172]  eta: 0:01:22  lr: 0.000052  loss: 0.6214 (0.6326)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:534]  [130/172]  eta: 0:01:06  lr: 0.000052  loss: 0.6218 (0.6331)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [140/172]  eta: 0:00:50  lr: 0.000052  loss: 0.6363 (0.6339)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [150/172]  eta: 0:00:34  lr: 0.000052  loss: 0.6317 (0.6335)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [160/172]  eta: 0:00:19  lr: 0.000052  loss: 0.6317 (0.6341)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [170/172]  eta: 0:00:03  lr: 0.000052  loss: 0.6287 (0.6345)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534]  [171/172]  eta: 0:00:01  lr: 0.000052  loss: 0.6287 (0.6344)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:534] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000052  loss: 0.6287 (0.6344)\n",
      "Valid: [epoch:534]  [ 0/14]  eta: 0:00:05  loss: 0.6093 (0.6093)  time: 0.4051  data: 0.3869  max mem: 20571\n",
      "Valid: [epoch:534]  [13/14]  eta: 0:00:00  loss: 0.6152 (0.6216)  time: 0.0443  data: 0.0289  max mem: 20571\n",
      "Valid: [epoch:534] Total time: 0:00:00 (0.0522 s / it)\n",
      "Averaged stats: loss: 0.6152 (0.6216)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_534_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.622%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:535]  [  0/172]  eta: 0:08:18  lr: 0.000052  loss: 0.6434 (0.6434)  time: 2.9002  data: 1.3226  max mem: 20571\n",
      "Train: [epoch:535]  [ 10/172]  eta: 0:04:34  lr: 0.000052  loss: 0.6302 (0.6317)  time: 1.6969  data: 0.1203  max mem: 20571\n",
      "Train: [epoch:535]  [ 20/172]  eta: 0:04:09  lr: 0.000052  loss: 0.6175 (0.6290)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [ 30/172]  eta: 0:03:50  lr: 0.000052  loss: 0.6227 (0.6285)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [ 40/172]  eta: 0:03:33  lr: 0.000052  loss: 0.6227 (0.6305)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [ 50/172]  eta: 0:03:16  lr: 0.000052  loss: 0.6375 (0.6339)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:535]  [ 60/172]  eta: 0:02:59  lr: 0.000052  loss: 0.6300 (0.6332)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [ 70/172]  eta: 0:02:43  lr: 0.000052  loss: 0.6225 (0.6347)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [ 80/172]  eta: 0:02:26  lr: 0.000052  loss: 0.6376 (0.6361)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [ 90/172]  eta: 0:02:10  lr: 0.000052  loss: 0.6307 (0.6346)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [100/172]  eta: 0:01:54  lr: 0.000052  loss: 0.6185 (0.6350)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [110/172]  eta: 0:01:38  lr: 0.000052  loss: 0.6252 (0.6347)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [120/172]  eta: 0:01:22  lr: 0.000052  loss: 0.6252 (0.6351)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [130/172]  eta: 0:01:06  lr: 0.000052  loss: 0.6247 (0.6342)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [140/172]  eta: 0:00:50  lr: 0.000052  loss: 0.6438 (0.6363)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [150/172]  eta: 0:00:34  lr: 0.000052  loss: 0.6438 (0.6353)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [160/172]  eta: 0:00:19  lr: 0.000052  loss: 0.6238 (0.6352)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [170/172]  eta: 0:00:03  lr: 0.000052  loss: 0.6262 (0.6359)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535]  [171/172]  eta: 0:00:01  lr: 0.000052  loss: 0.6253 (0.6357)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:535] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000052  loss: 0.6253 (0.6357)\n",
      "Valid: [epoch:535]  [ 0/14]  eta: 0:00:04  loss: 0.5937 (0.5937)  time: 0.2886  data: 0.2737  max mem: 20571\n",
      "Valid: [epoch:535]  [13/14]  eta: 0:00:00  loss: 0.5994 (0.6054)  time: 0.0380  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:535] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.5994 (0.6054)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_535_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.605%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:536]  [  0/172]  eta: 0:07:29  lr: 0.000052  loss: 0.6834 (0.6834)  time: 2.6107  data: 1.0448  max mem: 20571\n",
      "Train: [epoch:536]  [ 10/172]  eta: 0:04:30  lr: 0.000052  loss: 0.6433 (0.6497)  time: 1.6692  data: 0.0951  max mem: 20571\n",
      "Train: [epoch:536]  [ 20/172]  eta: 0:04:07  lr: 0.000052  loss: 0.6452 (0.6507)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [ 30/172]  eta: 0:03:48  lr: 0.000052  loss: 0.6396 (0.6474)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [ 40/172]  eta: 0:03:31  lr: 0.000052  loss: 0.6248 (0.6427)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [ 50/172]  eta: 0:03:14  lr: 0.000052  loss: 0.6323 (0.6451)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [ 60/172]  eta: 0:02:58  lr: 0.000052  loss: 0.6519 (0.6450)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [ 70/172]  eta: 0:02:42  lr: 0.000052  loss: 0.6499 (0.6445)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [ 80/172]  eta: 0:02:26  lr: 0.000052  loss: 0.6348 (0.6436)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [ 90/172]  eta: 0:02:10  lr: 0.000052  loss: 0.6304 (0.6420)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [100/172]  eta: 0:01:54  lr: 0.000052  loss: 0.6248 (0.6404)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [110/172]  eta: 0:01:38  lr: 0.000052  loss: 0.6239 (0.6388)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [120/172]  eta: 0:01:22  lr: 0.000052  loss: 0.6291 (0.6386)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [130/172]  eta: 0:01:06  lr: 0.000052  loss: 0.6303 (0.6375)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [140/172]  eta: 0:00:50  lr: 0.000052  loss: 0.6355 (0.6380)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [150/172]  eta: 0:00:34  lr: 0.000052  loss: 0.6355 (0.6372)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [160/172]  eta: 0:00:19  lr: 0.000052  loss: 0.6309 (0.6375)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [170/172]  eta: 0:00:03  lr: 0.000052  loss: 0.6403 (0.6380)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536]  [171/172]  eta: 0:00:01  lr: 0.000052  loss: 0.6410 (0.6380)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:536] Total time: 0:04:32 (1.5839 s / it)\n",
      "Averaged stats: lr: 0.000052  loss: 0.6410 (0.6380)\n",
      "Valid: [epoch:536]  [ 0/14]  eta: 0:00:04  loss: 0.5887 (0.5887)  time: 0.3115  data: 0.2967  max mem: 20571\n",
      "Valid: [epoch:536]  [13/14]  eta: 0:00:00  loss: 0.5949 (0.6007)  time: 0.0389  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:536] Total time: 0:00:00 (0.0467 s / it)\n",
      "Averaged stats: loss: 0.5949 (0.6007)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_536_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.601%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:537]  [  0/172]  eta: 0:08:01  lr: 0.000052  loss: 0.5960 (0.5960)  time: 2.7975  data: 1.2253  max mem: 20571\n",
      "Train: [epoch:537]  [ 10/172]  eta: 0:04:32  lr: 0.000052  loss: 0.6344 (0.6290)  time: 1.6839  data: 0.1115  max mem: 20571\n",
      "Train: [epoch:537]  [ 20/172]  eta: 0:04:07  lr: 0.000052  loss: 0.6344 (0.6368)  time: 1.5728  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [ 30/172]  eta: 0:03:49  lr: 0.000052  loss: 0.6348 (0.6399)  time: 1.5736  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [ 40/172]  eta: 0:03:31  lr: 0.000052  loss: 0.6282 (0.6372)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [ 50/172]  eta: 0:03:14  lr: 0.000052  loss: 0.6133 (0.6364)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [ 60/172]  eta: 0:02:58  lr: 0.000052  loss: 0.6318 (0.6356)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [ 70/172]  eta: 0:02:42  lr: 0.000052  loss: 0.6249 (0.6357)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [ 80/172]  eta: 0:02:26  lr: 0.000052  loss: 0.6351 (0.6385)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [ 90/172]  eta: 0:02:10  lr: 0.000052  loss: 0.6423 (0.6365)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [100/172]  eta: 0:01:54  lr: 0.000052  loss: 0.6155 (0.6364)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [110/172]  eta: 0:01:38  lr: 0.000052  loss: 0.6312 (0.6363)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [120/172]  eta: 0:01:22  lr: 0.000052  loss: 0.6360 (0.6382)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [130/172]  eta: 0:01:06  lr: 0.000052  loss: 0.6373 (0.6386)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [140/172]  eta: 0:00:50  lr: 0.000052  loss: 0.6308 (0.6391)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [150/172]  eta: 0:00:34  lr: 0.000052  loss: 0.6314 (0.6402)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [160/172]  eta: 0:00:18  lr: 0.000052  loss: 0.6390 (0.6396)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [170/172]  eta: 0:00:03  lr: 0.000052  loss: 0.6381 (0.6395)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537]  [171/172]  eta: 0:00:01  lr: 0.000052  loss: 0.6390 (0.6396)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:537] Total time: 0:04:32 (1.5835 s / it)\n",
      "Averaged stats: lr: 0.000052  loss: 0.6390 (0.6396)\n",
      "Valid: [epoch:537]  [ 0/14]  eta: 0:00:03  loss: 0.6077 (0.6077)  time: 0.2857  data: 0.2706  max mem: 20571\n",
      "Valid: [epoch:537]  [13/14]  eta: 0:00:00  loss: 0.6077 (0.6114)  time: 0.0411  data: 0.0261  max mem: 20571\n",
      "Valid: [epoch:537] Total time: 0:00:00 (0.0491 s / it)\n",
      "Averaged stats: loss: 0.6077 (0.6114)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_537_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.611%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:538]  [  0/172]  eta: 0:07:24  lr: 0.000051  loss: 0.5815 (0.5815)  time: 2.5833  data: 1.0189  max mem: 20571\n",
      "Train: [epoch:538]  [ 10/172]  eta: 0:04:30  lr: 0.000051  loss: 0.6235 (0.6325)  time: 1.6678  data: 0.0927  max mem: 20571\n",
      "Train: [epoch:538]  [ 20/172]  eta: 0:04:06  lr: 0.000051  loss: 0.6512 (0.6499)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [ 30/172]  eta: 0:03:48  lr: 0.000051  loss: 0.6512 (0.6463)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [ 40/172]  eta: 0:03:31  lr: 0.000051  loss: 0.6463 (0.6438)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [ 50/172]  eta: 0:03:14  lr: 0.000051  loss: 0.6314 (0.6406)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [ 60/172]  eta: 0:02:58  lr: 0.000051  loss: 0.6331 (0.6409)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [ 70/172]  eta: 0:02:42  lr: 0.000051  loss: 0.6332 (0.6405)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [ 80/172]  eta: 0:02:26  lr: 0.000051  loss: 0.6329 (0.6392)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [ 90/172]  eta: 0:02:10  lr: 0.000051  loss: 0.6336 (0.6384)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [100/172]  eta: 0:01:54  lr: 0.000051  loss: 0.6388 (0.6403)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [110/172]  eta: 0:01:38  lr: 0.000051  loss: 0.6446 (0.6405)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [120/172]  eta: 0:01:22  lr: 0.000051  loss: 0.6417 (0.6408)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [130/172]  eta: 0:01:06  lr: 0.000051  loss: 0.6222 (0.6395)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [140/172]  eta: 0:00:50  lr: 0.000051  loss: 0.6256 (0.6395)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [150/172]  eta: 0:00:34  lr: 0.000051  loss: 0.6295 (0.6385)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [160/172]  eta: 0:00:19  lr: 0.000051  loss: 0.6364 (0.6394)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538]  [170/172]  eta: 0:00:03  lr: 0.000051  loss: 0.6353 (0.6390)  time: 1.5780  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:538]  [171/172]  eta: 0:00:01  lr: 0.000051  loss: 0.6225 (0.6386)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:538] Total time: 0:04:32 (1.5838 s / it)\n",
      "Averaged stats: lr: 0.000051  loss: 0.6225 (0.6386)\n",
      "Valid: [epoch:538]  [ 0/14]  eta: 0:00:04  loss: 0.6151 (0.6151)  time: 0.3195  data: 0.3016  max mem: 20571\n",
      "Valid: [epoch:538]  [13/14]  eta: 0:00:00  loss: 0.6211 (0.6269)  time: 0.0398  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:538] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 0.6211 (0.6269)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_538_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.627%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:539]  [  0/172]  eta: 0:07:34  lr: 0.000051  loss: 0.6552 (0.6552)  time: 2.6436  data: 1.0710  max mem: 20571\n",
      "Train: [epoch:539]  [ 10/172]  eta: 0:04:30  lr: 0.000051  loss: 0.6396 (0.6387)  time: 1.6702  data: 0.0975  max mem: 20571\n",
      "Train: [epoch:539]  [ 20/172]  eta: 0:04:06  lr: 0.000051  loss: 0.6373 (0.6417)  time: 1.5739  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:539]  [ 30/172]  eta: 0:03:48  lr: 0.000051  loss: 0.6373 (0.6409)  time: 1.5767  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:539]  [ 40/172]  eta: 0:03:31  lr: 0.000051  loss: 0.6318 (0.6387)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:539]  [ 50/172]  eta: 0:03:14  lr: 0.000051  loss: 0.6405 (0.6395)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [ 60/172]  eta: 0:02:58  lr: 0.000051  loss: 0.6206 (0.6356)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [ 70/172]  eta: 0:02:42  lr: 0.000051  loss: 0.6325 (0.6376)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [ 80/172]  eta: 0:02:26  lr: 0.000051  loss: 0.6325 (0.6391)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [ 90/172]  eta: 0:02:10  lr: 0.000051  loss: 0.6263 (0.6377)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [100/172]  eta: 0:01:54  lr: 0.000051  loss: 0.6340 (0.6380)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [110/172]  eta: 0:01:38  lr: 0.000051  loss: 0.6418 (0.6379)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [120/172]  eta: 0:01:22  lr: 0.000051  loss: 0.6525 (0.6389)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [130/172]  eta: 0:01:06  lr: 0.000051  loss: 0.6372 (0.6381)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [140/172]  eta: 0:00:50  lr: 0.000051  loss: 0.6243 (0.6383)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [150/172]  eta: 0:00:34  lr: 0.000051  loss: 0.6382 (0.6385)  time: 1.5738  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [160/172]  eta: 0:00:18  lr: 0.000051  loss: 0.6422 (0.6389)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [170/172]  eta: 0:00:03  lr: 0.000051  loss: 0.6436 (0.6397)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539]  [171/172]  eta: 0:00:01  lr: 0.000051  loss: 0.6436 (0.6400)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:539] Total time: 0:04:32 (1.5826 s / it)\n",
      "Averaged stats: lr: 0.000051  loss: 0.6436 (0.6400)\n",
      "Valid: [epoch:539]  [ 0/14]  eta: 0:00:04  loss: 0.5576 (0.5576)  time: 0.3057  data: 0.2896  max mem: 20571\n",
      "Valid: [epoch:539]  [13/14]  eta: 0:00:00  loss: 0.6040 (0.6105)  time: 0.0378  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:539] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.6040 (0.6105)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_539_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.611%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:540]  [  0/172]  eta: 0:07:50  lr: 0.000051  loss: 0.6521 (0.6521)  time: 2.7334  data: 1.1711  max mem: 20571\n",
      "Train: [epoch:540]  [ 10/172]  eta: 0:04:31  lr: 0.000051  loss: 0.6372 (0.6343)  time: 1.6784  data: 0.1066  max mem: 20571\n",
      "Train: [epoch:540]  [ 20/172]  eta: 0:04:07  lr: 0.000051  loss: 0.6372 (0.6390)  time: 1.5737  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:540]  [ 30/172]  eta: 0:03:48  lr: 0.000051  loss: 0.6332 (0.6366)  time: 1.5751  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:540]  [ 40/172]  eta: 0:03:31  lr: 0.000051  loss: 0.6297 (0.6364)  time: 1.5763  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:540]  [ 50/172]  eta: 0:03:14  lr: 0.000051  loss: 0.6348 (0.6361)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:540]  [ 60/172]  eta: 0:02:58  lr: 0.000051  loss: 0.6321 (0.6360)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:540]  [ 70/172]  eta: 0:02:42  lr: 0.000051  loss: 0.6285 (0.6357)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:540]  [ 80/172]  eta: 0:02:26  lr: 0.000051  loss: 0.6285 (0.6365)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:540]  [ 90/172]  eta: 0:02:10  lr: 0.000051  loss: 0.6353 (0.6387)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:540]  [100/172]  eta: 0:01:54  lr: 0.000051  loss: 0.6342 (0.6393)  time: 1.5775  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:540]  [110/172]  eta: 0:01:38  lr: 0.000051  loss: 0.6445 (0.6391)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:540]  [120/172]  eta: 0:01:22  lr: 0.000051  loss: 0.6445 (0.6399)  time: 1.5770  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:540]  [130/172]  eta: 0:01:06  lr: 0.000051  loss: 0.6354 (0.6397)  time: 1.5761  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:540]  [140/172]  eta: 0:00:50  lr: 0.000051  loss: 0.6350 (0.6391)  time: 1.5757  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:540]  [150/172]  eta: 0:00:34  lr: 0.000051  loss: 0.6435 (0.6391)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:540]  [160/172]  eta: 0:00:18  lr: 0.000051  loss: 0.6344 (0.6387)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:540]  [170/172]  eta: 0:00:03  lr: 0.000051  loss: 0.6346 (0.6386)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:540]  [171/172]  eta: 0:00:01  lr: 0.000051  loss: 0.6368 (0.6387)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:540] Total time: 0:04:32 (1.5834 s / it)\n",
      "Averaged stats: lr: 0.000051  loss: 0.6368 (0.6387)\n",
      "Valid: [epoch:540]  [ 0/14]  eta: 0:00:04  loss: 0.5837 (0.5837)  time: 0.3256  data: 0.3107  max mem: 20571\n",
      "Valid: [epoch:540]  [13/14]  eta: 0:00:00  loss: 0.5959 (0.6026)  time: 0.0378  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:540] Total time: 0:00:00 (0.0430 s / it)\n",
      "Averaged stats: loss: 0.5959 (0.6026)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_540_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.603%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:541]  [  0/172]  eta: 0:07:39  lr: 0.000051  loss: 0.6398 (0.6398)  time: 2.6719  data: 1.1015  max mem: 20571\n",
      "Train: [epoch:541]  [ 10/172]  eta: 0:04:30  lr: 0.000051  loss: 0.6263 (0.6349)  time: 1.6717  data: 0.1002  max mem: 20571\n",
      "Train: [epoch:541]  [ 20/172]  eta: 0:04:07  lr: 0.000051  loss: 0.6386 (0.6485)  time: 1.5728  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [ 30/172]  eta: 0:03:48  lr: 0.000051  loss: 0.6322 (0.6416)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [ 40/172]  eta: 0:03:31  lr: 0.000051  loss: 0.6239 (0.6398)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:541]  [ 50/172]  eta: 0:03:14  lr: 0.000051  loss: 0.6293 (0.6400)  time: 1.5770  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:541]  [ 60/172]  eta: 0:02:58  lr: 0.000051  loss: 0.6450 (0.6409)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [ 70/172]  eta: 0:02:42  lr: 0.000051  loss: 0.6338 (0.6402)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [ 80/172]  eta: 0:02:26  lr: 0.000051  loss: 0.6285 (0.6400)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [ 90/172]  eta: 0:02:10  lr: 0.000051  loss: 0.6384 (0.6418)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [100/172]  eta: 0:01:54  lr: 0.000051  loss: 0.6356 (0.6412)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [110/172]  eta: 0:01:38  lr: 0.000051  loss: 0.6293 (0.6395)  time: 1.5780  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:541]  [120/172]  eta: 0:01:22  lr: 0.000051  loss: 0.6400 (0.6405)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [130/172]  eta: 0:01:06  lr: 0.000051  loss: 0.6515 (0.6413)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [140/172]  eta: 0:00:50  lr: 0.000051  loss: 0.6514 (0.6413)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [150/172]  eta: 0:00:34  lr: 0.000051  loss: 0.6346 (0.6418)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [160/172]  eta: 0:00:18  lr: 0.000051  loss: 0.6453 (0.6419)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [170/172]  eta: 0:00:03  lr: 0.000051  loss: 0.6532 (0.6435)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541]  [171/172]  eta: 0:00:01  lr: 0.000051  loss: 0.6474 (0.6434)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:541] Total time: 0:04:32 (1.5834 s / it)\n",
      "Averaged stats: lr: 0.000051  loss: 0.6474 (0.6434)\n",
      "Valid: [epoch:541]  [ 0/14]  eta: 0:00:03  loss: 0.6146 (0.6146)  time: 0.2793  data: 0.2640  max mem: 20571\n",
      "Valid: [epoch:541]  [13/14]  eta: 0:00:00  loss: 0.6193 (0.6249)  time: 0.0391  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:541] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.6193 (0.6249)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_541_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.625%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:542]  [  0/172]  eta: 0:07:32  lr: 0.000051  loss: 0.6435 (0.6435)  time: 2.6333  data: 1.0680  max mem: 20571\n",
      "Train: [epoch:542]  [ 10/172]  eta: 0:04:30  lr: 0.000051  loss: 0.6369 (0.6359)  time: 1.6706  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:542]  [ 20/172]  eta: 0:04:06  lr: 0.000051  loss: 0.6369 (0.6510)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [ 30/172]  eta: 0:03:48  lr: 0.000051  loss: 0.6447 (0.6494)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [ 40/172]  eta: 0:03:31  lr: 0.000051  loss: 0.6380 (0.6459)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [ 50/172]  eta: 0:03:14  lr: 0.000051  loss: 0.6507 (0.6459)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [ 60/172]  eta: 0:02:58  lr: 0.000051  loss: 0.6507 (0.6450)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [ 70/172]  eta: 0:02:42  lr: 0.000051  loss: 0.6421 (0.6458)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [ 80/172]  eta: 0:02:26  lr: 0.000051  loss: 0.6380 (0.6446)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [ 90/172]  eta: 0:02:10  lr: 0.000051  loss: 0.6127 (0.6432)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [100/172]  eta: 0:01:54  lr: 0.000051  loss: 0.6401 (0.6424)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [110/172]  eta: 0:01:38  lr: 0.000051  loss: 0.6430 (0.6424)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [120/172]  eta: 0:01:22  lr: 0.000051  loss: 0.6321 (0.6413)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [130/172]  eta: 0:01:06  lr: 0.000051  loss: 0.6321 (0.6407)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [140/172]  eta: 0:00:50  lr: 0.000051  loss: 0.6396 (0.6413)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [150/172]  eta: 0:00:34  lr: 0.000051  loss: 0.6414 (0.6410)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [160/172]  eta: 0:00:18  lr: 0.000051  loss: 0.6271 (0.6401)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [170/172]  eta: 0:00:03  lr: 0.000051  loss: 0.6285 (0.6400)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542]  [171/172]  eta: 0:00:01  lr: 0.000051  loss: 0.6295 (0.6400)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:542] Total time: 0:04:32 (1.5828 s / it)\n",
      "Averaged stats: lr: 0.000051  loss: 0.6295 (0.6400)\n",
      "Valid: [epoch:542]  [ 0/14]  eta: 0:00:04  loss: 0.6574 (0.6574)  time: 0.2891  data: 0.2743  max mem: 20571\n",
      "Valid: [epoch:542]  [13/14]  eta: 0:00:00  loss: 0.6276 (0.6349)  time: 0.0371  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:542] Total time: 0:00:00 (0.0460 s / it)\n",
      "Averaged stats: loss: 0.6276 (0.6349)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_542_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.635%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:543]  [  0/172]  eta: 0:08:33  lr: 0.000051  loss: 0.6567 (0.6567)  time: 2.9842  data: 1.4115  max mem: 20571\n",
      "Train: [epoch:543]  [ 10/172]  eta: 0:04:35  lr: 0.000051  loss: 0.6513 (0.6322)  time: 1.6998  data: 0.1284  max mem: 20571\n",
      "Train: [epoch:543]  [ 20/172]  eta: 0:04:09  lr: 0.000051  loss: 0.6300 (0.6376)  time: 1.5737  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [ 30/172]  eta: 0:03:50  lr: 0.000051  loss: 0.6391 (0.6425)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [ 40/172]  eta: 0:03:32  lr: 0.000051  loss: 0.6351 (0.6389)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [ 50/172]  eta: 0:03:15  lr: 0.000051  loss: 0.6230 (0.6377)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [ 60/172]  eta: 0:02:59  lr: 0.000051  loss: 0.6303 (0.6394)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [ 70/172]  eta: 0:02:42  lr: 0.000051  loss: 0.6383 (0.6388)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [ 80/172]  eta: 0:02:26  lr: 0.000051  loss: 0.6338 (0.6386)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [ 90/172]  eta: 0:02:10  lr: 0.000051  loss: 0.6338 (0.6387)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [100/172]  eta: 0:01:54  lr: 0.000051  loss: 0.6494 (0.6398)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [110/172]  eta: 0:01:38  lr: 0.000051  loss: 0.6510 (0.6403)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [120/172]  eta: 0:01:22  lr: 0.000051  loss: 0.6595 (0.6431)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [130/172]  eta: 0:01:06  lr: 0.000051  loss: 0.6528 (0.6425)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [140/172]  eta: 0:00:50  lr: 0.000051  loss: 0.6474 (0.6431)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [150/172]  eta: 0:00:34  lr: 0.000051  loss: 0.6474 (0.6435)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [160/172]  eta: 0:00:19  lr: 0.000051  loss: 0.6435 (0.6437)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [170/172]  eta: 0:00:03  lr: 0.000051  loss: 0.6509 (0.6443)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543]  [171/172]  eta: 0:00:01  lr: 0.000051  loss: 0.6435 (0.6443)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:543] Total time: 0:04:33 (1.5897 s / it)\n",
      "Averaged stats: lr: 0.000051  loss: 0.6435 (0.6443)\n",
      "Valid: [epoch:543]  [ 0/14]  eta: 0:00:04  loss: 0.5519 (0.5519)  time: 0.3073  data: 0.2921  max mem: 20571\n",
      "Valid: [epoch:543]  [13/14]  eta: 0:00:00  loss: 0.6104 (0.6160)  time: 0.0420  data: 0.0268  max mem: 20571\n",
      "Valid: [epoch:543] Total time: 0:00:00 (0.0505 s / it)\n",
      "Averaged stats: loss: 0.6104 (0.6160)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_543_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.616%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:544]  [  0/172]  eta: 0:07:46  lr: 0.000051  loss: 0.6299 (0.6299)  time: 2.7137  data: 1.1444  max mem: 20571\n",
      "Train: [epoch:544]  [ 10/172]  eta: 0:04:32  lr: 0.000051  loss: 0.6654 (0.6536)  time: 1.6843  data: 0.1042  max mem: 20571\n",
      "Train: [epoch:544]  [ 20/172]  eta: 0:04:08  lr: 0.000051  loss: 0.6406 (0.6455)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [ 30/172]  eta: 0:03:49  lr: 0.000051  loss: 0.6426 (0.6481)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [ 40/172]  eta: 0:03:32  lr: 0.000051  loss: 0.6386 (0.6448)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [ 50/172]  eta: 0:03:15  lr: 0.000051  loss: 0.6334 (0.6456)  time: 1.5846  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:544]  [ 60/172]  eta: 0:02:59  lr: 0.000051  loss: 0.6400 (0.6446)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [ 70/172]  eta: 0:02:43  lr: 0.000051  loss: 0.6370 (0.6438)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [ 80/172]  eta: 0:02:26  lr: 0.000051  loss: 0.6480 (0.6451)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [ 90/172]  eta: 0:02:10  lr: 0.000051  loss: 0.6383 (0.6439)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [100/172]  eta: 0:01:54  lr: 0.000051  loss: 0.6301 (0.6448)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [110/172]  eta: 0:01:38  lr: 0.000051  loss: 0.6301 (0.6440)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [120/172]  eta: 0:01:22  lr: 0.000051  loss: 0.6344 (0.6444)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [130/172]  eta: 0:01:06  lr: 0.000051  loss: 0.6371 (0.6436)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [140/172]  eta: 0:00:50  lr: 0.000051  loss: 0.6308 (0.6431)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [150/172]  eta: 0:00:34  lr: 0.000051  loss: 0.6318 (0.6430)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [160/172]  eta: 0:00:19  lr: 0.000051  loss: 0.6404 (0.6431)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [170/172]  eta: 0:00:03  lr: 0.000051  loss: 0.6446 (0.6438)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544]  [171/172]  eta: 0:00:01  lr: 0.000051  loss: 0.6446 (0.6439)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:544] Total time: 0:04:33 (1.5907 s / it)\n",
      "Averaged stats: lr: 0.000051  loss: 0.6446 (0.6439)\n",
      "Valid: [epoch:544]  [ 0/14]  eta: 0:00:04  loss: 0.5696 (0.5696)  time: 0.2886  data: 0.2719  max mem: 20571\n",
      "Valid: [epoch:544]  [13/14]  eta: 0:00:00  loss: 0.6023 (0.6068)  time: 0.0389  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:544] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.6023 (0.6068)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_544_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.607%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:545]  [  0/172]  eta: 0:07:52  lr: 0.000051  loss: 0.6561 (0.6561)  time: 2.7447  data: 1.1690  max mem: 20571\n",
      "Train: [epoch:545]  [ 10/172]  eta: 0:04:33  lr: 0.000051  loss: 0.6561 (0.6446)  time: 1.6871  data: 0.1064  max mem: 20571\n",
      "Train: [epoch:545]  [ 20/172]  eta: 0:04:08  lr: 0.000051  loss: 0.6502 (0.6474)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [ 30/172]  eta: 0:03:50  lr: 0.000051  loss: 0.6440 (0.6433)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [ 40/172]  eta: 0:03:32  lr: 0.000051  loss: 0.6363 (0.6436)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [ 50/172]  eta: 0:03:15  lr: 0.000051  loss: 0.6407 (0.6437)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [ 60/172]  eta: 0:02:59  lr: 0.000051  loss: 0.6436 (0.6437)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [ 70/172]  eta: 0:02:43  lr: 0.000051  loss: 0.6380 (0.6437)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [ 80/172]  eta: 0:02:26  lr: 0.000051  loss: 0.6380 (0.6442)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [ 90/172]  eta: 0:02:10  lr: 0.000051  loss: 0.6344 (0.6427)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [100/172]  eta: 0:01:54  lr: 0.000051  loss: 0.6350 (0.6419)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [110/172]  eta: 0:01:38  lr: 0.000051  loss: 0.6301 (0.6403)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [120/172]  eta: 0:01:22  lr: 0.000051  loss: 0.6251 (0.6402)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:545]  [130/172]  eta: 0:01:06  lr: 0.000051  loss: 0.6251 (0.6404)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:545]  [140/172]  eta: 0:00:50  lr: 0.000051  loss: 0.6487 (0.6412)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [150/172]  eta: 0:00:34  lr: 0.000051  loss: 0.6492 (0.6415)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [160/172]  eta: 0:00:19  lr: 0.000051  loss: 0.6362 (0.6415)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [170/172]  eta: 0:00:03  lr: 0.000051  loss: 0.6584 (0.6433)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545]  [171/172]  eta: 0:00:01  lr: 0.000051  loss: 0.6658 (0.6437)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:545] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000051  loss: 0.6658 (0.6437)\n",
      "Valid: [epoch:545]  [ 0/14]  eta: 0:00:04  loss: 0.6623 (0.6623)  time: 0.3000  data: 0.2853  max mem: 20571\n",
      "Valid: [epoch:545]  [13/14]  eta: 0:00:00  loss: 0.6263 (0.6348)  time: 0.0483  data: 0.0333  max mem: 20571\n",
      "Valid: [epoch:545] Total time: 0:00:00 (0.0566 s / it)\n",
      "Averaged stats: loss: 0.6263 (0.6348)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_545_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.635%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:546]  [  0/172]  eta: 0:07:56  lr: 0.000051  loss: 0.6907 (0.6907)  time: 2.7732  data: 1.2042  max mem: 20571\n",
      "Train: [epoch:546]  [ 10/172]  eta: 0:04:33  lr: 0.000051  loss: 0.6414 (0.6336)  time: 1.6902  data: 0.1096  max mem: 20571\n",
      "Train: [epoch:546]  [ 20/172]  eta: 0:04:09  lr: 0.000051  loss: 0.6373 (0.6422)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:546]  [ 30/172]  eta: 0:03:50  lr: 0.000051  loss: 0.6301 (0.6389)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [ 40/172]  eta: 0:03:32  lr: 0.000051  loss: 0.6299 (0.6404)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [ 50/172]  eta: 0:03:15  lr: 0.000051  loss: 0.6373 (0.6395)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [ 60/172]  eta: 0:02:59  lr: 0.000051  loss: 0.6415 (0.6426)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [ 70/172]  eta: 0:02:43  lr: 0.000051  loss: 0.6495 (0.6453)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [ 80/172]  eta: 0:02:26  lr: 0.000051  loss: 0.6534 (0.6459)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [ 90/172]  eta: 0:02:10  lr: 0.000051  loss: 0.6421 (0.6448)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [100/172]  eta: 0:01:54  lr: 0.000051  loss: 0.6378 (0.6448)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [110/172]  eta: 0:01:38  lr: 0.000051  loss: 0.6401 (0.6445)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [120/172]  eta: 0:01:22  lr: 0.000051  loss: 0.6374 (0.6455)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [130/172]  eta: 0:01:06  lr: 0.000051  loss: 0.6275 (0.6452)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [140/172]  eta: 0:00:50  lr: 0.000051  loss: 0.6300 (0.6453)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [150/172]  eta: 0:00:34  lr: 0.000051  loss: 0.6502 (0.6461)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [160/172]  eta: 0:00:19  lr: 0.000051  loss: 0.6454 (0.6457)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [170/172]  eta: 0:00:03  lr: 0.000051  loss: 0.6354 (0.6451)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546]  [171/172]  eta: 0:00:01  lr: 0.000051  loss: 0.6384 (0.6453)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:546] Total time: 0:04:33 (1.5907 s / it)\n",
      "Averaged stats: lr: 0.000051  loss: 0.6384 (0.6453)\n",
      "Valid: [epoch:546]  [ 0/14]  eta: 0:00:04  loss: 0.5890 (0.5890)  time: 0.3101  data: 0.2953  max mem: 20571\n",
      "Valid: [epoch:546]  [13/14]  eta: 0:00:00  loss: 0.6197 (0.6248)  time: 0.0397  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:546] Total time: 0:00:00 (0.0475 s / it)\n",
      "Averaged stats: loss: 0.6197 (0.6248)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_546_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.625%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:547]  [  0/172]  eta: 0:07:33  lr: 0.000050  loss: 0.7092 (0.7092)  time: 2.6355  data: 1.0488  max mem: 20571\n",
      "Train: [epoch:547]  [ 10/172]  eta: 0:04:31  lr: 0.000050  loss: 0.6350 (0.6496)  time: 1.6749  data: 0.0954  max mem: 20571\n",
      "Train: [epoch:547]  [ 20/172]  eta: 0:04:07  lr: 0.000050  loss: 0.6350 (0.6482)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [ 30/172]  eta: 0:03:49  lr: 0.000050  loss: 0.6455 (0.6497)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [ 40/172]  eta: 0:03:32  lr: 0.000050  loss: 0.6407 (0.6446)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [ 50/172]  eta: 0:03:15  lr: 0.000050  loss: 0.6440 (0.6489)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [ 60/172]  eta: 0:02:59  lr: 0.000050  loss: 0.6520 (0.6473)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [ 70/172]  eta: 0:02:42  lr: 0.000050  loss: 0.6442 (0.6488)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [ 80/172]  eta: 0:02:26  lr: 0.000050  loss: 0.6392 (0.6475)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.6392 (0.6472)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:547]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.6490 (0.6467)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.6406 (0.6475)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.6370 (0.6473)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.6280 (0.6468)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.6417 (0.6462)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [150/172]  eta: 0:00:34  lr: 0.000050  loss: 0.6417 (0.6458)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.6223 (0.6461)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.6301 (0.6464)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.6301 (0.6463)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:547] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.6301 (0.6463)\n",
      "Valid: [epoch:547]  [ 0/14]  eta: 0:00:04  loss: 0.5899 (0.5899)  time: 0.2906  data: 0.2760  max mem: 20571\n",
      "Valid: [epoch:547]  [13/14]  eta: 0:00:00  loss: 0.6028 (0.6079)  time: 0.0465  data: 0.0315  max mem: 20571\n",
      "Valid: [epoch:547] Total time: 0:00:00 (0.0523 s / it)\n",
      "Averaged stats: loss: 0.6028 (0.6079)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_547_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.608%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:548]  [  0/172]  eta: 0:08:05  lr: 0.000050  loss: 0.6267 (0.6267)  time: 2.8241  data: 1.2557  max mem: 20571\n",
      "Train: [epoch:548]  [ 10/172]  eta: 0:04:34  lr: 0.000050  loss: 0.6520 (0.6526)  time: 1.6942  data: 0.1143  max mem: 20571\n",
      "Train: [epoch:548]  [ 20/172]  eta: 0:04:09  lr: 0.000050  loss: 0.6560 (0.6594)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [ 30/172]  eta: 0:03:50  lr: 0.000050  loss: 0.6512 (0.6556)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [ 40/172]  eta: 0:03:32  lr: 0.000050  loss: 0.6316 (0.6532)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [ 50/172]  eta: 0:03:15  lr: 0.000050  loss: 0.6489 (0.6524)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [ 60/172]  eta: 0:02:59  lr: 0.000050  loss: 0.6572 (0.6535)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [ 70/172]  eta: 0:02:43  lr: 0.000050  loss: 0.6572 (0.6519)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [ 80/172]  eta: 0:02:26  lr: 0.000050  loss: 0.6580 (0.6551)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.6590 (0.6543)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.6599 (0.6566)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.6471 (0.6549)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.6271 (0.6535)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.6333 (0.6534)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.6478 (0.6540)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [150/172]  eta: 0:00:34  lr: 0.000050  loss: 0.6478 (0.6532)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.6400 (0.6526)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.6300 (0.6520)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.6349 (0.6519)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:548] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.6349 (0.6519)\n",
      "Valid: [epoch:548]  [ 0/14]  eta: 0:00:03  loss: 0.6239 (0.6239)  time: 0.2835  data: 0.2674  max mem: 20571\n",
      "Valid: [epoch:548]  [13/14]  eta: 0:00:00  loss: 0.6281 (0.6339)  time: 0.0391  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:548] Total time: 0:00:00 (0.0440 s / it)\n",
      "Averaged stats: loss: 0.6281 (0.6339)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_548_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.634%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:549]  [  0/172]  eta: 0:07:31  lr: 0.000050  loss: 0.6402 (0.6402)  time: 2.6233  data: 1.0457  max mem: 20571\n",
      "Train: [epoch:549]  [ 10/172]  eta: 0:04:30  lr: 0.000050  loss: 0.6518 (0.6792)  time: 1.6715  data: 0.0952  max mem: 20571\n",
      "Train: [epoch:549]  [ 20/172]  eta: 0:04:07  lr: 0.000050  loss: 0.6463 (0.6608)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [ 30/172]  eta: 0:03:48  lr: 0.000050  loss: 0.6375 (0.6514)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [ 40/172]  eta: 0:03:31  lr: 0.000050  loss: 0.6375 (0.6481)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [ 50/172]  eta: 0:03:15  lr: 0.000050  loss: 0.6465 (0.6496)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [ 60/172]  eta: 0:02:58  lr: 0.000050  loss: 0.6391 (0.6477)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [ 70/172]  eta: 0:02:42  lr: 0.000050  loss: 0.6291 (0.6478)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [ 80/172]  eta: 0:02:26  lr: 0.000050  loss: 0.6375 (0.6474)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.6398 (0.6480)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.6420 (0.6479)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.6400 (0.6473)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.6290 (0.6458)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.6277 (0.6450)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.6334 (0.6454)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [150/172]  eta: 0:00:34  lr: 0.000050  loss: 0.6349 (0.6462)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.6354 (0.6459)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.6446 (0.6470)  time: 1.5810  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:549]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.6446 (0.6468)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:549] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.6446 (0.6468)\n",
      "Valid: [epoch:549]  [ 0/14]  eta: 0:00:05  loss: 0.6584 (0.6584)  time: 0.4050  data: 0.3889  max mem: 20571\n",
      "Valid: [epoch:549]  [13/14]  eta: 0:00:00  loss: 0.6061 (0.6122)  time: 0.0445  data: 0.0293  max mem: 20571\n",
      "Valid: [epoch:549] Total time: 0:00:00 (0.0500 s / it)\n",
      "Averaged stats: loss: 0.6061 (0.6122)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_549_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.612%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:550]  [  0/172]  eta: 0:09:15  lr: 0.000050  loss: 0.6210 (0.6210)  time: 3.2273  data: 1.6538  max mem: 20571\n",
      "Train: [epoch:550]  [ 10/172]  eta: 0:04:39  lr: 0.000050  loss: 0.6468 (0.6501)  time: 1.7269  data: 0.1504  max mem: 20571\n",
      "Train: [epoch:550]  [ 20/172]  eta: 0:04:11  lr: 0.000050  loss: 0.6592 (0.6550)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [ 30/172]  eta: 0:03:51  lr: 0.000050  loss: 0.6543 (0.6506)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [ 40/172]  eta: 0:03:33  lr: 0.000050  loss: 0.6397 (0.6489)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [ 50/172]  eta: 0:03:16  lr: 0.000050  loss: 0.6363 (0.6449)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [ 60/172]  eta: 0:02:59  lr: 0.000050  loss: 0.6387 (0.6469)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [ 70/172]  eta: 0:02:43  lr: 0.000050  loss: 0.6342 (0.6440)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [ 80/172]  eta: 0:02:27  lr: 0.000050  loss: 0.6397 (0.6444)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.6397 (0.6434)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.6256 (0.6430)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.6411 (0.6438)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.6758 (0.6469)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.6724 (0.6460)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.6443 (0.6463)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [150/172]  eta: 0:00:34  lr: 0.000050  loss: 0.6488 (0.6470)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.6454 (0.6470)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.6439 (0.6475)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.6460 (0.6476)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:550] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.6460 (0.6476)\n",
      "Valid: [epoch:550]  [ 0/14]  eta: 0:00:04  loss: 0.5677 (0.5677)  time: 0.3136  data: 0.2984  max mem: 20571\n",
      "Valid: [epoch:550]  [13/14]  eta: 0:00:00  loss: 0.6150 (0.6206)  time: 0.0375  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:550] Total time: 0:00:00 (0.0453 s / it)\n",
      "Averaged stats: loss: 0.6150 (0.6206)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_550_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.621%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:551]  [  0/172]  eta: 0:07:47  lr: 0.000050  loss: 0.6604 (0.6604)  time: 2.7168  data: 1.1447  max mem: 20571\n",
      "Train: [epoch:551]  [ 10/172]  eta: 0:04:32  lr: 0.000050  loss: 0.6466 (0.6463)  time: 1.6803  data: 0.1042  max mem: 20571\n",
      "Train: [epoch:551]  [ 20/172]  eta: 0:04:07  lr: 0.000050  loss: 0.6399 (0.6430)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [ 30/172]  eta: 0:03:49  lr: 0.000050  loss: 0.6366 (0.6458)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [ 40/172]  eta: 0:03:32  lr: 0.000050  loss: 0.6555 (0.6496)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [ 50/172]  eta: 0:03:15  lr: 0.000050  loss: 0.6456 (0.6485)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [ 60/172]  eta: 0:02:58  lr: 0.000050  loss: 0.6456 (0.6485)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [ 70/172]  eta: 0:02:42  lr: 0.000050  loss: 0.6484 (0.6472)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [ 80/172]  eta: 0:02:26  lr: 0.000050  loss: 0.6340 (0.6461)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.6396 (0.6466)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.6557 (0.6478)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.6557 (0.6476)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.6363 (0.6474)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.6363 (0.6470)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.6353 (0.6468)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [150/172]  eta: 0:00:34  lr: 0.000050  loss: 0.6357 (0.6474)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.6558 (0.6480)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.6469 (0.6479)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.6469 (0.6479)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:551] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.6469 (0.6479)\n",
      "Valid: [epoch:551]  [ 0/14]  eta: 0:00:04  loss: 0.6368 (0.6368)  time: 0.3232  data: 0.3054  max mem: 20571\n",
      "Valid: [epoch:551]  [13/14]  eta: 0:00:00  loss: 0.6084 (0.6141)  time: 0.0392  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:551] Total time: 0:00:00 (0.0439 s / it)\n",
      "Averaged stats: loss: 0.6084 (0.6141)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_551_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.614%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:552]  [  0/172]  eta: 0:07:49  lr: 0.000050  loss: 0.5943 (0.5943)  time: 2.7285  data: 1.1546  max mem: 20571\n",
      "Train: [epoch:552]  [ 10/172]  eta: 0:04:32  lr: 0.000050  loss: 0.6426 (0.6461)  time: 1.6806  data: 0.1051  max mem: 20571\n",
      "Train: [epoch:552]  [ 20/172]  eta: 0:04:07  lr: 0.000050  loss: 0.6597 (0.6583)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [ 30/172]  eta: 0:03:49  lr: 0.000050  loss: 0.6505 (0.6556)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [ 40/172]  eta: 0:03:31  lr: 0.000050  loss: 0.6494 (0.6547)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [ 50/172]  eta: 0:03:15  lr: 0.000050  loss: 0.6494 (0.6578)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [ 60/172]  eta: 0:02:58  lr: 0.000050  loss: 0.6782 (0.6612)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [ 70/172]  eta: 0:02:42  lr: 0.000050  loss: 0.6660 (0.6596)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [ 80/172]  eta: 0:02:26  lr: 0.000050  loss: 0.6470 (0.6585)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.6401 (0.6574)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.6401 (0.6556)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.6327 (0.6547)  time: 1.5815  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:552]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.6434 (0.6542)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.6501 (0.6544)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.6432 (0.6536)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [150/172]  eta: 0:00:34  lr: 0.000050  loss: 0.6395 (0.6538)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.6403 (0.6536)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.6529 (0.6543)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.6574 (0.6544)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:552] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.6574 (0.6544)\n",
      "Valid: [epoch:552]  [ 0/14]  eta: 0:00:03  loss: 0.7007 (0.7007)  time: 0.2846  data: 0.2695  max mem: 20571\n",
      "Valid: [epoch:552]  [13/14]  eta: 0:00:00  loss: 0.6728 (0.6794)  time: 0.0401  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:552] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.6728 (0.6794)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_552_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.679%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:553]  [  0/172]  eta: 0:08:17  lr: 0.000050  loss: 0.6943 (0.6943)  time: 2.8949  data: 1.3144  max mem: 20571\n",
      "Train: [epoch:553]  [ 10/172]  eta: 0:04:34  lr: 0.000050  loss: 0.6494 (0.6596)  time: 1.6951  data: 0.1196  max mem: 20571\n",
      "Train: [epoch:553]  [ 20/172]  eta: 0:04:09  lr: 0.000050  loss: 0.6499 (0.6633)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [ 30/172]  eta: 0:03:49  lr: 0.000050  loss: 0.6499 (0.6626)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [ 40/172]  eta: 0:03:32  lr: 0.000050  loss: 0.6285 (0.6586)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [ 50/172]  eta: 0:03:15  lr: 0.000050  loss: 0.6321 (0.6571)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [ 60/172]  eta: 0:02:59  lr: 0.000050  loss: 0.6391 (0.6576)  time: 1.5786  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:553]  [ 70/172]  eta: 0:02:42  lr: 0.000050  loss: 0.6449 (0.6563)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [ 80/172]  eta: 0:02:26  lr: 0.000050  loss: 0.6445 (0.6547)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.6446 (0.6555)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.6655 (0.6588)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.6677 (0.6584)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.6580 (0.6575)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.6394 (0.6560)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.6314 (0.6547)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [150/172]  eta: 0:00:34  lr: 0.000050  loss: 0.6448 (0.6538)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.6471 (0.6529)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.6445 (0.6527)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.6445 (0.6530)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:553] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.6445 (0.6530)\n",
      "Valid: [epoch:553]  [ 0/14]  eta: 0:00:04  loss: 0.6366 (0.6366)  time: 0.2874  data: 0.2727  max mem: 20571\n",
      "Valid: [epoch:553]  [13/14]  eta: 0:00:00  loss: 0.6075 (0.6135)  time: 0.0365  data: 0.0214  max mem: 20571\n",
      "Valid: [epoch:553] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.6075 (0.6135)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_553_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.613%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:554]  [  0/172]  eta: 0:08:21  lr: 0.000050  loss: 0.6166 (0.6166)  time: 2.9138  data: 1.3262  max mem: 20571\n",
      "Train: [epoch:554]  [ 10/172]  eta: 0:04:35  lr: 0.000050  loss: 0.6489 (0.6512)  time: 1.7011  data: 0.1207  max mem: 20571\n",
      "Train: [epoch:554]  [ 20/172]  eta: 0:04:09  lr: 0.000050  loss: 0.6488 (0.6498)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [ 30/172]  eta: 0:03:50  lr: 0.000050  loss: 0.6360 (0.6458)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:554]  [ 40/172]  eta: 0:03:33  lr: 0.000050  loss: 0.6296 (0.6444)  time: 1.5837  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:554]  [ 50/172]  eta: 0:03:16  lr: 0.000050  loss: 0.6395 (0.6454)  time: 1.5827  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:554]  [ 60/172]  eta: 0:02:59  lr: 0.000050  loss: 0.6446 (0.6460)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:554]  [ 70/172]  eta: 0:02:43  lr: 0.000050  loss: 0.6446 (0.6475)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [ 80/172]  eta: 0:02:26  lr: 0.000050  loss: 0.6398 (0.6479)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.6532 (0.6487)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.6651 (0.6495)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.6667 (0.6509)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.6646 (0.6523)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.6538 (0.6527)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.6538 (0.6523)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [150/172]  eta: 0:00:34  lr: 0.000050  loss: 0.6358 (0.6514)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.6370 (0.6515)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.6444 (0.6513)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.6451 (0.6515)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:554] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.6451 (0.6515)\n",
      "Valid: [epoch:554]  [ 0/14]  eta: 0:00:04  loss: 0.6380 (0.6380)  time: 0.3410  data: 0.3228  max mem: 20571\n",
      "Valid: [epoch:554]  [13/14]  eta: 0:00:00  loss: 0.6091 (0.6148)  time: 0.0397  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:554] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 0.6091 (0.6148)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_554_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.615%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:555]  [  0/172]  eta: 0:08:03  lr: 0.000050  loss: 0.6557 (0.6557)  time: 2.8136  data: 1.2254  max mem: 20571\n",
      "Train: [epoch:555]  [ 10/172]  eta: 0:04:33  lr: 0.000050  loss: 0.6428 (0.6498)  time: 1.6881  data: 0.1115  max mem: 20571\n",
      "Train: [epoch:555]  [ 20/172]  eta: 0:04:08  lr: 0.000050  loss: 0.6403 (0.6525)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [ 30/172]  eta: 0:03:49  lr: 0.000050  loss: 0.6348 (0.6507)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [ 40/172]  eta: 0:03:32  lr: 0.000050  loss: 0.6348 (0.6486)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [ 50/172]  eta: 0:03:15  lr: 0.000050  loss: 0.6455 (0.6525)  time: 1.5789  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:555]  [ 60/172]  eta: 0:02:59  lr: 0.000050  loss: 0.6503 (0.6542)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [ 70/172]  eta: 0:02:42  lr: 0.000050  loss: 0.6677 (0.6581)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [ 80/172]  eta: 0:02:26  lr: 0.000050  loss: 0.6526 (0.6570)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [ 90/172]  eta: 0:02:10  lr: 0.000050  loss: 0.6396 (0.6564)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [100/172]  eta: 0:01:54  lr: 0.000050  loss: 0.6504 (0.6567)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [110/172]  eta: 0:01:38  lr: 0.000050  loss: 0.6388 (0.6561)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [120/172]  eta: 0:01:22  lr: 0.000050  loss: 0.6388 (0.6557)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [130/172]  eta: 0:01:06  lr: 0.000050  loss: 0.6427 (0.6555)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [140/172]  eta: 0:00:50  lr: 0.000050  loss: 0.6405 (0.6547)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [150/172]  eta: 0:00:34  lr: 0.000050  loss: 0.6478 (0.6544)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [160/172]  eta: 0:00:19  lr: 0.000050  loss: 0.6565 (0.6552)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [170/172]  eta: 0:00:03  lr: 0.000050  loss: 0.6578 (0.6552)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555]  [171/172]  eta: 0:00:01  lr: 0.000050  loss: 0.6578 (0.6550)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:555] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000050  loss: 0.6578 (0.6550)\n",
      "Valid: [epoch:555]  [ 0/14]  eta: 0:00:04  loss: 0.6553 (0.6553)  time: 0.3422  data: 0.3258  max mem: 20571\n",
      "Valid: [epoch:555]  [13/14]  eta: 0:00:00  loss: 0.6212 (0.6265)  time: 0.0394  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:555] Total time: 0:00:00 (0.0453 s / it)\n",
      "Averaged stats: loss: 0.6212 (0.6265)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_555_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.627%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:556]  [  0/172]  eta: 0:07:27  lr: 0.000049  loss: 0.5869 (0.5869)  time: 2.5993  data: 1.0326  max mem: 20571\n",
      "Train: [epoch:556]  [ 10/172]  eta: 0:04:30  lr: 0.000049  loss: 0.6533 (0.6550)  time: 1.6689  data: 0.0940  max mem: 20571\n",
      "Train: [epoch:556]  [ 20/172]  eta: 0:04:07  lr: 0.000049  loss: 0.6500 (0.6525)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [ 30/172]  eta: 0:03:48  lr: 0.000049  loss: 0.6396 (0.6504)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [ 40/172]  eta: 0:03:31  lr: 0.000049  loss: 0.6396 (0.6477)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [ 50/172]  eta: 0:03:15  lr: 0.000049  loss: 0.6308 (0.6472)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [ 60/172]  eta: 0:02:58  lr: 0.000049  loss: 0.6371 (0.6497)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [ 70/172]  eta: 0:02:42  lr: 0.000049  loss: 0.6491 (0.6500)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [ 80/172]  eta: 0:02:26  lr: 0.000049  loss: 0.6481 (0.6509)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [ 90/172]  eta: 0:02:10  lr: 0.000049  loss: 0.6481 (0.6504)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [100/172]  eta: 0:01:54  lr: 0.000049  loss: 0.6515 (0.6508)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [110/172]  eta: 0:01:38  lr: 0.000049  loss: 0.6624 (0.6520)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [120/172]  eta: 0:01:22  lr: 0.000049  loss: 0.6560 (0.6523)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [130/172]  eta: 0:01:06  lr: 0.000049  loss: 0.6560 (0.6526)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [140/172]  eta: 0:00:50  lr: 0.000049  loss: 0.6556 (0.6528)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [150/172]  eta: 0:00:34  lr: 0.000049  loss: 0.6529 (0.6531)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [160/172]  eta: 0:00:19  lr: 0.000049  loss: 0.6529 (0.6530)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [170/172]  eta: 0:00:03  lr: 0.000049  loss: 0.6605 (0.6537)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556]  [171/172]  eta: 0:00:01  lr: 0.000049  loss: 0.6652 (0.6540)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:556] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000049  loss: 0.6652 (0.6540)\n",
      "Valid: [epoch:556]  [ 0/14]  eta: 0:00:04  loss: 0.6619 (0.6619)  time: 0.3514  data: 0.3355  max mem: 20571\n",
      "Valid: [epoch:556]  [13/14]  eta: 0:00:00  loss: 0.6243 (0.6316)  time: 0.0400  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:556] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.6243 (0.6316)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_556_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.632%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:557]  [  0/172]  eta: 0:07:46  lr: 0.000049  loss: 0.6480 (0.6480)  time: 2.7127  data: 1.1309  max mem: 20571\n",
      "Train: [epoch:557]  [ 10/172]  eta: 0:04:32  lr: 0.000049  loss: 0.6538 (0.6569)  time: 1.6805  data: 0.1029  max mem: 20571\n",
      "Train: [epoch:557]  [ 20/172]  eta: 0:04:07  lr: 0.000049  loss: 0.6538 (0.6604)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [ 30/172]  eta: 0:03:49  lr: 0.000049  loss: 0.6443 (0.6568)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [ 40/172]  eta: 0:03:32  lr: 0.000049  loss: 0.6443 (0.6559)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [ 50/172]  eta: 0:03:15  lr: 0.000049  loss: 0.6524 (0.6550)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [ 60/172]  eta: 0:02:58  lr: 0.000049  loss: 0.6508 (0.6531)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [ 70/172]  eta: 0:02:42  lr: 0.000049  loss: 0.6484 (0.6554)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [ 80/172]  eta: 0:02:26  lr: 0.000049  loss: 0.6696 (0.6578)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [ 90/172]  eta: 0:02:10  lr: 0.000049  loss: 0.6698 (0.6583)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [100/172]  eta: 0:01:54  lr: 0.000049  loss: 0.6698 (0.6608)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [110/172]  eta: 0:01:38  lr: 0.000049  loss: 0.6497 (0.6594)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [120/172]  eta: 0:01:22  lr: 0.000049  loss: 0.6502 (0.6601)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [130/172]  eta: 0:01:06  lr: 0.000049  loss: 0.6502 (0.6587)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [140/172]  eta: 0:00:50  lr: 0.000049  loss: 0.6391 (0.6585)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [150/172]  eta: 0:00:34  lr: 0.000049  loss: 0.6391 (0.6573)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [160/172]  eta: 0:00:19  lr: 0.000049  loss: 0.6471 (0.6577)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [170/172]  eta: 0:00:03  lr: 0.000049  loss: 0.6465 (0.6567)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557]  [171/172]  eta: 0:00:01  lr: 0.000049  loss: 0.6465 (0.6572)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:557] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000049  loss: 0.6465 (0.6572)\n",
      "Valid: [epoch:557]  [ 0/14]  eta: 0:00:05  loss: 0.6609 (0.6609)  time: 0.3852  data: 0.3680  max mem: 20571\n",
      "Valid: [epoch:557]  [13/14]  eta: 0:00:00  loss: 0.6334 (0.6387)  time: 0.0416  data: 0.0265  max mem: 20571\n",
      "Valid: [epoch:557] Total time: 0:00:00 (0.0473 s / it)\n",
      "Averaged stats: loss: 0.6334 (0.6387)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_557_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.639%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:558]  [  0/172]  eta: 0:07:29  lr: 0.000049  loss: 0.6989 (0.6989)  time: 2.6144  data: 1.0407  max mem: 20571\n",
      "Train: [epoch:558]  [ 10/172]  eta: 0:04:31  lr: 0.000049  loss: 0.6689 (0.6631)  time: 1.6733  data: 0.0947  max mem: 20571\n",
      "Train: [epoch:558]  [ 20/172]  eta: 0:04:07  lr: 0.000049  loss: 0.6675 (0.6610)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [ 30/172]  eta: 0:03:49  lr: 0.000049  loss: 0.6521 (0.6527)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [ 40/172]  eta: 0:03:32  lr: 0.000049  loss: 0.6354 (0.6481)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [ 50/172]  eta: 0:03:15  lr: 0.000049  loss: 0.6511 (0.6504)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [ 60/172]  eta: 0:02:58  lr: 0.000049  loss: 0.6533 (0.6508)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [ 70/172]  eta: 0:02:42  lr: 0.000049  loss: 0.6593 (0.6539)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [ 80/172]  eta: 0:02:26  lr: 0.000049  loss: 0.6593 (0.6555)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [ 90/172]  eta: 0:02:10  lr: 0.000049  loss: 0.6554 (0.6546)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [100/172]  eta: 0:01:54  lr: 0.000049  loss: 0.6538 (0.6550)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [110/172]  eta: 0:01:38  lr: 0.000049  loss: 0.6538 (0.6546)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [120/172]  eta: 0:01:22  lr: 0.000049  loss: 0.6571 (0.6555)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [130/172]  eta: 0:01:06  lr: 0.000049  loss: 0.6536 (0.6555)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [140/172]  eta: 0:00:50  lr: 0.000049  loss: 0.6482 (0.6565)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [150/172]  eta: 0:00:34  lr: 0.000049  loss: 0.6417 (0.6553)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [160/172]  eta: 0:00:19  lr: 0.000049  loss: 0.6346 (0.6553)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [170/172]  eta: 0:00:03  lr: 0.000049  loss: 0.6491 (0.6548)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558]  [171/172]  eta: 0:00:01  lr: 0.000049  loss: 0.6393 (0.6547)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:558] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000049  loss: 0.6393 (0.6547)\n",
      "Valid: [epoch:558]  [ 0/14]  eta: 0:00:04  loss: 0.6037 (0.6037)  time: 0.3015  data: 0.2868  max mem: 20571\n",
      "Valid: [epoch:558]  [13/14]  eta: 0:00:00  loss: 0.6161 (0.6216)  time: 0.0444  data: 0.0293  max mem: 20571\n",
      "Valid: [epoch:558] Total time: 0:00:00 (0.0531 s / it)\n",
      "Averaged stats: loss: 0.6161 (0.6216)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_558_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.622%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:559]  [  0/172]  eta: 0:07:30  lr: 0.000049  loss: 0.6081 (0.6081)  time: 2.6221  data: 1.0442  max mem: 20571\n",
      "Train: [epoch:559]  [ 10/172]  eta: 0:04:30  lr: 0.000049  loss: 0.6603 (0.6573)  time: 1.6723  data: 0.0950  max mem: 20571\n",
      "Train: [epoch:559]  [ 20/172]  eta: 0:04:07  lr: 0.000049  loss: 0.6621 (0.6674)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [ 30/172]  eta: 0:03:49  lr: 0.000049  loss: 0.6413 (0.6584)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [ 40/172]  eta: 0:03:31  lr: 0.000049  loss: 0.6362 (0.6553)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [ 50/172]  eta: 0:03:15  lr: 0.000049  loss: 0.6478 (0.6559)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [ 60/172]  eta: 0:02:58  lr: 0.000049  loss: 0.6478 (0.6551)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [ 70/172]  eta: 0:02:42  lr: 0.000049  loss: 0.6473 (0.6526)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [ 80/172]  eta: 0:02:26  lr: 0.000049  loss: 0.6521 (0.6547)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [ 90/172]  eta: 0:02:10  lr: 0.000049  loss: 0.6514 (0.6548)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [100/172]  eta: 0:01:54  lr: 0.000049  loss: 0.6475 (0.6538)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [110/172]  eta: 0:01:38  lr: 0.000049  loss: 0.6472 (0.6558)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [120/172]  eta: 0:01:22  lr: 0.000049  loss: 0.6535 (0.6574)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [130/172]  eta: 0:01:06  lr: 0.000049  loss: 0.6840 (0.6607)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [140/172]  eta: 0:00:50  lr: 0.000049  loss: 0.6957 (0.6613)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [150/172]  eta: 0:00:34  lr: 0.000049  loss: 0.6372 (0.6593)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [160/172]  eta: 0:00:19  lr: 0.000049  loss: 0.6319 (0.6592)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [170/172]  eta: 0:00:03  lr: 0.000049  loss: 0.6503 (0.6592)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559]  [171/172]  eta: 0:00:01  lr: 0.000049  loss: 0.6503 (0.6598)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:559] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000049  loss: 0.6503 (0.6598)\n",
      "Valid: [epoch:559]  [ 0/14]  eta: 0:00:04  loss: 0.5976 (0.5976)  time: 0.3400  data: 0.3196  max mem: 20571\n",
      "Valid: [epoch:559]  [13/14]  eta: 0:00:00  loss: 0.6128 (0.6188)  time: 0.0408  data: 0.0253  max mem: 20571\n",
      "Valid: [epoch:559] Total time: 0:00:00 (0.0491 s / it)\n",
      "Averaged stats: loss: 0.6128 (0.6188)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_559_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.619%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:560]  [  0/172]  eta: 0:07:56  lr: 0.000049  loss: 0.6451 (0.6451)  time: 2.7715  data: 1.2037  max mem: 20571\n",
      "Train: [epoch:560]  [ 10/172]  eta: 0:04:33  lr: 0.000049  loss: 0.6398 (0.6539)  time: 1.6868  data: 0.1095  max mem: 20571\n",
      "Train: [epoch:560]  [ 20/172]  eta: 0:04:08  lr: 0.000049  loss: 0.6398 (0.6480)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [ 30/172]  eta: 0:03:49  lr: 0.000049  loss: 0.6351 (0.6478)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [ 40/172]  eta: 0:03:32  lr: 0.000049  loss: 0.6349 (0.6456)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [ 50/172]  eta: 0:03:15  lr: 0.000049  loss: 0.6511 (0.6507)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [ 60/172]  eta: 0:02:59  lr: 0.000049  loss: 0.6623 (0.6545)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [ 70/172]  eta: 0:02:42  lr: 0.000049  loss: 0.6619 (0.6551)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [ 80/172]  eta: 0:02:26  lr: 0.000049  loss: 0.6466 (0.6538)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [ 90/172]  eta: 0:02:10  lr: 0.000049  loss: 0.6758 (0.6565)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [100/172]  eta: 0:01:54  lr: 0.000049  loss: 0.6698 (0.6559)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [110/172]  eta: 0:01:38  lr: 0.000049  loss: 0.6351 (0.6567)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [120/172]  eta: 0:01:22  lr: 0.000049  loss: 0.6453 (0.6557)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [130/172]  eta: 0:01:06  lr: 0.000049  loss: 0.6453 (0.6560)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [140/172]  eta: 0:00:50  lr: 0.000049  loss: 0.6439 (0.6553)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [150/172]  eta: 0:00:34  lr: 0.000049  loss: 0.6388 (0.6547)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [160/172]  eta: 0:00:19  lr: 0.000049  loss: 0.6425 (0.6541)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560]  [170/172]  eta: 0:00:03  lr: 0.000049  loss: 0.6453 (0.6546)  time: 1.5807  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:560]  [171/172]  eta: 0:00:01  lr: 0.000049  loss: 0.6453 (0.6547)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:560] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000049  loss: 0.6453 (0.6547)\n",
      "Valid: [epoch:560]  [ 0/14]  eta: 0:00:03  loss: 0.6647 (0.6647)  time: 0.2787  data: 0.2642  max mem: 20571\n",
      "Valid: [epoch:560]  [13/14]  eta: 0:00:00  loss: 0.6256 (0.6309)  time: 0.0390  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:560] Total time: 0:00:00 (0.0450 s / it)\n",
      "Averaged stats: loss: 0.6256 (0.6309)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_560_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.631%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:561]  [  0/172]  eta: 0:07:44  lr: 0.000049  loss: 0.7477 (0.7477)  time: 2.6998  data: 1.1070  max mem: 20571\n",
      "Train: [epoch:561]  [ 10/172]  eta: 0:04:31  lr: 0.000049  loss: 0.6516 (0.6552)  time: 1.6770  data: 0.1007  max mem: 20571\n",
      "Train: [epoch:561]  [ 20/172]  eta: 0:04:07  lr: 0.000049  loss: 0.6516 (0.6558)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [ 30/172]  eta: 0:03:49  lr: 0.000049  loss: 0.6617 (0.6559)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [ 40/172]  eta: 0:03:31  lr: 0.000049  loss: 0.6722 (0.6624)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [ 50/172]  eta: 0:03:15  lr: 0.000049  loss: 0.6617 (0.6625)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [ 60/172]  eta: 0:02:58  lr: 0.000049  loss: 0.6552 (0.6615)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [ 70/172]  eta: 0:02:42  lr: 0.000049  loss: 0.6557 (0.6609)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [ 80/172]  eta: 0:02:26  lr: 0.000049  loss: 0.6557 (0.6602)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [ 90/172]  eta: 0:02:10  lr: 0.000049  loss: 0.6698 (0.6633)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [100/172]  eta: 0:01:54  lr: 0.000049  loss: 0.6745 (0.6640)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [110/172]  eta: 0:01:38  lr: 0.000049  loss: 0.6454 (0.6625)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [120/172]  eta: 0:01:22  lr: 0.000049  loss: 0.6408 (0.6613)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [130/172]  eta: 0:01:06  lr: 0.000049  loss: 0.6571 (0.6618)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [140/172]  eta: 0:00:50  lr: 0.000049  loss: 0.6635 (0.6617)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [150/172]  eta: 0:00:34  lr: 0.000049  loss: 0.6635 (0.6623)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [160/172]  eta: 0:00:19  lr: 0.000049  loss: 0.6365 (0.6606)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [170/172]  eta: 0:00:03  lr: 0.000049  loss: 0.6258 (0.6602)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561]  [171/172]  eta: 0:00:01  lr: 0.000049  loss: 0.6258 (0.6608)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:561] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000049  loss: 0.6258 (0.6608)\n",
      "Valid: [epoch:561]  [ 0/14]  eta: 0:00:04  loss: 0.6716 (0.6716)  time: 0.2871  data: 0.2723  max mem: 20571\n",
      "Valid: [epoch:561]  [13/14]  eta: 0:00:00  loss: 0.6374 (0.6430)  time: 0.0400  data: 0.0249  max mem: 20571\n",
      "Valid: [epoch:561] Total time: 0:00:00 (0.0453 s / it)\n",
      "Averaged stats: loss: 0.6374 (0.6430)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_561_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.643%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:562]  [  0/172]  eta: 0:07:37  lr: 0.000049  loss: 0.6063 (0.6063)  time: 2.6598  data: 1.0922  max mem: 20571\n",
      "Train: [epoch:562]  [ 10/172]  eta: 0:04:31  lr: 0.000049  loss: 0.6367 (0.6567)  time: 1.6762  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:562]  [ 20/172]  eta: 0:04:07  lr: 0.000049  loss: 0.6690 (0.6601)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [ 30/172]  eta: 0:03:49  lr: 0.000049  loss: 0.6690 (0.6597)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [ 40/172]  eta: 0:03:32  lr: 0.000049  loss: 0.6568 (0.6574)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [ 50/172]  eta: 0:03:15  lr: 0.000049  loss: 0.6605 (0.6589)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [ 60/172]  eta: 0:02:58  lr: 0.000049  loss: 0.6692 (0.6586)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [ 70/172]  eta: 0:02:42  lr: 0.000049  loss: 0.6644 (0.6594)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [ 80/172]  eta: 0:02:26  lr: 0.000049  loss: 0.6544 (0.6592)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [ 90/172]  eta: 0:02:10  lr: 0.000049  loss: 0.6513 (0.6589)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [100/172]  eta: 0:01:54  lr: 0.000049  loss: 0.6513 (0.6597)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [110/172]  eta: 0:01:38  lr: 0.000049  loss: 0.6531 (0.6586)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [120/172]  eta: 0:01:22  lr: 0.000049  loss: 0.6531 (0.6588)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [130/172]  eta: 0:01:06  lr: 0.000049  loss: 0.6619 (0.6589)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [140/172]  eta: 0:00:50  lr: 0.000049  loss: 0.6619 (0.6604)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [150/172]  eta: 0:00:34  lr: 0.000049  loss: 0.6583 (0.6606)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [160/172]  eta: 0:00:19  lr: 0.000049  loss: 0.6480 (0.6603)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [170/172]  eta: 0:00:03  lr: 0.000049  loss: 0.6480 (0.6597)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562]  [171/172]  eta: 0:00:01  lr: 0.000049  loss: 0.6477 (0.6596)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:562] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000049  loss: 0.6477 (0.6596)\n",
      "Valid: [epoch:562]  [ 0/14]  eta: 0:00:04  loss: 0.6810 (0.6810)  time: 0.2910  data: 0.2737  max mem: 20571\n",
      "Valid: [epoch:562]  [13/14]  eta: 0:00:00  loss: 0.6528 (0.6593)  time: 0.0390  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:562] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.6528 (0.6593)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_562_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.659%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:563]  [  0/172]  eta: 0:07:34  lr: 0.000049  loss: 0.6961 (0.6961)  time: 2.6451  data: 1.0683  max mem: 20571\n",
      "Train: [epoch:563]  [ 10/172]  eta: 0:04:31  lr: 0.000049  loss: 0.6592 (0.6610)  time: 1.6735  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:563]  [ 20/172]  eta: 0:04:07  lr: 0.000049  loss: 0.6570 (0.6645)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [ 30/172]  eta: 0:03:48  lr: 0.000049  loss: 0.6405 (0.6595)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [ 40/172]  eta: 0:03:31  lr: 0.000049  loss: 0.6379 (0.6623)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [ 50/172]  eta: 0:03:15  lr: 0.000049  loss: 0.6862 (0.6660)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [ 60/172]  eta: 0:02:58  lr: 0.000049  loss: 0.6617 (0.6634)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [ 70/172]  eta: 0:02:42  lr: 0.000049  loss: 0.6596 (0.6650)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [ 80/172]  eta: 0:02:26  lr: 0.000049  loss: 0.6596 (0.6638)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [ 90/172]  eta: 0:02:10  lr: 0.000049  loss: 0.6669 (0.6661)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [100/172]  eta: 0:01:54  lr: 0.000049  loss: 0.6770 (0.6672)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [110/172]  eta: 0:01:38  lr: 0.000049  loss: 0.6738 (0.6680)  time: 1.5805  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:563]  [120/172]  eta: 0:01:22  lr: 0.000049  loss: 0.6664 (0.6677)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [130/172]  eta: 0:01:06  lr: 0.000049  loss: 0.6506 (0.6662)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [140/172]  eta: 0:00:50  lr: 0.000049  loss: 0.6470 (0.6648)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [150/172]  eta: 0:00:34  lr: 0.000049  loss: 0.6423 (0.6641)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [160/172]  eta: 0:00:19  lr: 0.000049  loss: 0.6419 (0.6630)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [170/172]  eta: 0:00:03  lr: 0.000049  loss: 0.6529 (0.6631)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563]  [171/172]  eta: 0:00:01  lr: 0.000049  loss: 0.6621 (0.6632)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:563] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000049  loss: 0.6621 (0.6632)\n",
      "Valid: [epoch:563]  [ 0/14]  eta: 0:00:04  loss: 0.5665 (0.5665)  time: 0.3041  data: 0.2891  max mem: 20571\n",
      "Valid: [epoch:563]  [13/14]  eta: 0:00:00  loss: 0.6294 (0.6344)  time: 0.0488  data: 0.0337  max mem: 20571\n",
      "Valid: [epoch:563] Total time: 0:00:00 (0.0574 s / it)\n",
      "Averaged stats: loss: 0.6294 (0.6344)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_563_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.634%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:564]  [  0/172]  eta: 0:07:52  lr: 0.000049  loss: 0.6841 (0.6841)  time: 2.7451  data: 1.1735  max mem: 20571\n",
      "Train: [epoch:564]  [ 10/172]  eta: 0:04:32  lr: 0.000049  loss: 0.6612 (0.6640)  time: 1.6849  data: 0.1069  max mem: 20571\n",
      "Train: [epoch:564]  [ 20/172]  eta: 0:04:08  lr: 0.000049  loss: 0.6586 (0.6679)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:564]  [ 30/172]  eta: 0:03:49  lr: 0.000049  loss: 0.6459 (0.6595)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:564]  [ 40/172]  eta: 0:03:32  lr: 0.000049  loss: 0.6381 (0.6604)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:564]  [ 50/172]  eta: 0:03:15  lr: 0.000049  loss: 0.6480 (0.6585)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:564]  [ 60/172]  eta: 0:02:59  lr: 0.000049  loss: 0.6480 (0.6573)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [ 70/172]  eta: 0:02:42  lr: 0.000049  loss: 0.6723 (0.6599)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [ 80/172]  eta: 0:02:26  lr: 0.000049  loss: 0.6750 (0.6607)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [ 90/172]  eta: 0:02:10  lr: 0.000049  loss: 0.6673 (0.6613)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [100/172]  eta: 0:01:54  lr: 0.000049  loss: 0.6578 (0.6605)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [110/172]  eta: 0:01:38  lr: 0.000049  loss: 0.6484 (0.6593)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [120/172]  eta: 0:01:22  lr: 0.000049  loss: 0.6453 (0.6589)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [130/172]  eta: 0:01:06  lr: 0.000049  loss: 0.6403 (0.6579)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [140/172]  eta: 0:00:50  lr: 0.000049  loss: 0.6610 (0.6585)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [150/172]  eta: 0:00:34  lr: 0.000049  loss: 0.6718 (0.6594)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [160/172]  eta: 0:00:19  lr: 0.000049  loss: 0.6586 (0.6593)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [170/172]  eta: 0:00:03  lr: 0.000049  loss: 0.6509 (0.6598)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564]  [171/172]  eta: 0:00:01  lr: 0.000049  loss: 0.6509 (0.6597)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:564] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000049  loss: 0.6509 (0.6597)\n",
      "Valid: [epoch:564]  [ 0/14]  eta: 0:00:04  loss: 0.6535 (0.6535)  time: 0.3023  data: 0.2863  max mem: 20571\n",
      "Valid: [epoch:564]  [13/14]  eta: 0:00:00  loss: 0.6187 (0.6245)  time: 0.0388  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:564] Total time: 0:00:00 (0.0444 s / it)\n",
      "Averaged stats: loss: 0.6187 (0.6245)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_564_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.624%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:565]  [  0/172]  eta: 0:07:33  lr: 0.000048  loss: 0.6061 (0.6061)  time: 2.6391  data: 1.0623  max mem: 20571\n",
      "Train: [epoch:565]  [ 10/172]  eta: 0:04:31  lr: 0.000048  loss: 0.6291 (0.6437)  time: 1.6731  data: 0.0967  max mem: 20571\n",
      "Train: [epoch:565]  [ 20/172]  eta: 0:04:07  lr: 0.000048  loss: 0.6805 (0.6708)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:565]  [ 30/172]  eta: 0:03:49  lr: 0.000048  loss: 0.6871 (0.6751)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [ 40/172]  eta: 0:03:32  lr: 0.000048  loss: 0.6488 (0.6677)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [ 50/172]  eta: 0:03:15  lr: 0.000048  loss: 0.6471 (0.6655)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [ 60/172]  eta: 0:02:59  lr: 0.000048  loss: 0.6522 (0.6650)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [ 70/172]  eta: 0:02:42  lr: 0.000048  loss: 0.6611 (0.6654)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [ 80/172]  eta: 0:02:26  lr: 0.000048  loss: 0.6611 (0.6656)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [ 90/172]  eta: 0:02:10  lr: 0.000048  loss: 0.6517 (0.6636)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [100/172]  eta: 0:01:54  lr: 0.000048  loss: 0.6538 (0.6643)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:565]  [110/172]  eta: 0:01:38  lr: 0.000048  loss: 0.6583 (0.6655)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:565]  [120/172]  eta: 0:01:22  lr: 0.000048  loss: 0.6583 (0.6660)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:565]  [130/172]  eta: 0:01:06  lr: 0.000048  loss: 0.6697 (0.6663)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [140/172]  eta: 0:00:50  lr: 0.000048  loss: 0.6547 (0.6662)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [150/172]  eta: 0:00:34  lr: 0.000048  loss: 0.6481 (0.6650)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [160/172]  eta: 0:00:19  lr: 0.000048  loss: 0.6515 (0.6643)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [170/172]  eta: 0:00:03  lr: 0.000048  loss: 0.6534 (0.6640)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565]  [171/172]  eta: 0:00:01  lr: 0.000048  loss: 0.6534 (0.6642)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:565] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000048  loss: 0.6534 (0.6642)\n",
      "Valid: [epoch:565]  [ 0/14]  eta: 0:00:05  loss: 0.6639 (0.6639)  time: 0.3625  data: 0.3458  max mem: 20571\n",
      "Valid: [epoch:565]  [13/14]  eta: 0:00:00  loss: 0.6254 (0.6309)  time: 0.0407  data: 0.0256  max mem: 20571\n",
      "Valid: [epoch:565] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 0.6254 (0.6309)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_565_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.631%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:566]  [  0/172]  eta: 0:08:03  lr: 0.000048  loss: 0.6919 (0.6919)  time: 2.8135  data: 1.2334  max mem: 20571\n",
      "Train: [epoch:566]  [ 10/172]  eta: 0:04:34  lr: 0.000048  loss: 0.6635 (0.6616)  time: 1.6934  data: 0.1123  max mem: 20571\n",
      "Train: [epoch:566]  [ 20/172]  eta: 0:04:09  lr: 0.000048  loss: 0.6423 (0.6554)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:566]  [ 30/172]  eta: 0:03:50  lr: 0.000048  loss: 0.6423 (0.6548)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:566]  [ 40/172]  eta: 0:03:32  lr: 0.000048  loss: 0.6543 (0.6560)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [ 50/172]  eta: 0:03:15  lr: 0.000048  loss: 0.6578 (0.6576)  time: 1.5824  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:566]  [ 60/172]  eta: 0:02:59  lr: 0.000048  loss: 0.6562 (0.6560)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [ 70/172]  eta: 0:02:43  lr: 0.000048  loss: 0.6528 (0.6562)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [ 80/172]  eta: 0:02:26  lr: 0.000048  loss: 0.6598 (0.6580)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [ 90/172]  eta: 0:02:10  lr: 0.000048  loss: 0.6640 (0.6593)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [100/172]  eta: 0:01:54  lr: 0.000048  loss: 0.6619 (0.6586)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:566]  [110/172]  eta: 0:01:38  lr: 0.000048  loss: 0.6690 (0.6603)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:566]  [120/172]  eta: 0:01:22  lr: 0.000048  loss: 0.6735 (0.6619)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [130/172]  eta: 0:01:06  lr: 0.000048  loss: 0.6735 (0.6613)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [140/172]  eta: 0:00:50  lr: 0.000048  loss: 0.6480 (0.6611)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [150/172]  eta: 0:00:34  lr: 0.000048  loss: 0.6386 (0.6605)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [160/172]  eta: 0:00:19  lr: 0.000048  loss: 0.6591 (0.6606)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [170/172]  eta: 0:00:03  lr: 0.000048  loss: 0.6648 (0.6610)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566]  [171/172]  eta: 0:00:01  lr: 0.000048  loss: 0.6648 (0.6609)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:566] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000048  loss: 0.6648 (0.6609)\n",
      "Valid: [epoch:566]  [ 0/14]  eta: 0:00:04  loss: 0.6627 (0.6627)  time: 0.3085  data: 0.2939  max mem: 20571\n",
      "Valid: [epoch:566]  [13/14]  eta: 0:00:00  loss: 0.6254 (0.6305)  time: 0.0397  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:566] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.6254 (0.6305)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_566_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.631%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:567]  [  0/172]  eta: 0:07:42  lr: 0.000048  loss: 0.6687 (0.6687)  time: 2.6878  data: 1.0935  max mem: 20571\n",
      "Train: [epoch:567]  [ 10/172]  eta: 0:04:32  lr: 0.000048  loss: 0.6684 (0.6573)  time: 1.6800  data: 0.0995  max mem: 20571\n",
      "Train: [epoch:567]  [ 20/172]  eta: 0:04:08  lr: 0.000048  loss: 0.6658 (0.6662)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [ 30/172]  eta: 0:03:49  lr: 0.000048  loss: 0.6573 (0.6609)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:567]  [ 40/172]  eta: 0:03:32  lr: 0.000048  loss: 0.6567 (0.6632)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [ 50/172]  eta: 0:03:15  lr: 0.000048  loss: 0.6648 (0.6622)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [ 60/172]  eta: 0:02:59  lr: 0.000048  loss: 0.6648 (0.6624)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [ 70/172]  eta: 0:02:42  lr: 0.000048  loss: 0.6559 (0.6624)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [ 80/172]  eta: 0:02:26  lr: 0.000048  loss: 0.6697 (0.6623)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [ 90/172]  eta: 0:02:10  lr: 0.000048  loss: 0.6717 (0.6631)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [100/172]  eta: 0:01:54  lr: 0.000048  loss: 0.6730 (0.6637)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [110/172]  eta: 0:01:38  lr: 0.000048  loss: 0.6700 (0.6646)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [120/172]  eta: 0:01:22  lr: 0.000048  loss: 0.6529 (0.6643)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [130/172]  eta: 0:01:06  lr: 0.000048  loss: 0.6529 (0.6650)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [140/172]  eta: 0:00:50  lr: 0.000048  loss: 0.6751 (0.6653)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [150/172]  eta: 0:00:34  lr: 0.000048  loss: 0.6674 (0.6646)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [160/172]  eta: 0:00:19  lr: 0.000048  loss: 0.6675 (0.6650)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [170/172]  eta: 0:00:03  lr: 0.000048  loss: 0.6596 (0.6643)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567]  [171/172]  eta: 0:00:01  lr: 0.000048  loss: 0.6539 (0.6642)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:567] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000048  loss: 0.6539 (0.6642)\n",
      "Valid: [epoch:567]  [ 0/14]  eta: 0:00:04  loss: 0.6654 (0.6654)  time: 0.3059  data: 0.2900  max mem: 20571\n",
      "Valid: [epoch:567]  [13/14]  eta: 0:00:00  loss: 0.6311 (0.6364)  time: 0.0432  data: 0.0282  max mem: 20571\n",
      "Valid: [epoch:567] Total time: 0:00:00 (0.0499 s / it)\n",
      "Averaged stats: loss: 0.6311 (0.6364)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_567_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.636%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:568]  [  0/172]  eta: 0:08:17  lr: 0.000048  loss: 0.7013 (0.7013)  time: 2.8943  data: 1.3275  max mem: 20571\n",
      "Train: [epoch:568]  [ 10/172]  eta: 0:04:35  lr: 0.000048  loss: 0.6751 (0.6820)  time: 1.6982  data: 0.1208  max mem: 20571\n",
      "Train: [epoch:568]  [ 20/172]  eta: 0:04:09  lr: 0.000048  loss: 0.6751 (0.6763)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [ 30/172]  eta: 0:03:50  lr: 0.000048  loss: 0.6501 (0.6708)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [ 40/172]  eta: 0:03:32  lr: 0.000048  loss: 0.6430 (0.6667)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [ 50/172]  eta: 0:03:15  lr: 0.000048  loss: 0.6568 (0.6702)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [ 60/172]  eta: 0:02:59  lr: 0.000048  loss: 0.6677 (0.6685)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [ 70/172]  eta: 0:02:43  lr: 0.000048  loss: 0.6618 (0.6676)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:568]  [ 80/172]  eta: 0:02:26  lr: 0.000048  loss: 0.6618 (0.6692)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:568]  [ 90/172]  eta: 0:02:10  lr: 0.000048  loss: 0.6569 (0.6680)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [100/172]  eta: 0:01:54  lr: 0.000048  loss: 0.6794 (0.6711)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [110/172]  eta: 0:01:38  lr: 0.000048  loss: 0.6794 (0.6716)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [120/172]  eta: 0:01:22  lr: 0.000048  loss: 0.6530 (0.6716)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [130/172]  eta: 0:01:06  lr: 0.000048  loss: 0.6507 (0.6703)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [140/172]  eta: 0:00:50  lr: 0.000048  loss: 0.6561 (0.6693)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:568]  [150/172]  eta: 0:00:34  lr: 0.000048  loss: 0.6431 (0.6678)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [160/172]  eta: 0:00:19  lr: 0.000048  loss: 0.6411 (0.6670)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [170/172]  eta: 0:00:03  lr: 0.000048  loss: 0.6524 (0.6670)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568]  [171/172]  eta: 0:00:01  lr: 0.000048  loss: 0.6544 (0.6669)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:568] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000048  loss: 0.6544 (0.6669)\n",
      "Valid: [epoch:568]  [ 0/14]  eta: 0:00:04  loss: 0.5878 (0.5878)  time: 0.3382  data: 0.3200  max mem: 20571\n",
      "Valid: [epoch:568]  [13/14]  eta: 0:00:00  loss: 0.6214 (0.6270)  time: 0.0399  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:568] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.6214 (0.6270)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_568_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.627%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:569]  [  0/172]  eta: 0:07:41  lr: 0.000048  loss: 0.6760 (0.6760)  time: 2.6814  data: 1.1091  max mem: 20571\n",
      "Train: [epoch:569]  [ 10/172]  eta: 0:04:31  lr: 0.000048  loss: 0.6583 (0.6590)  time: 1.6758  data: 0.1009  max mem: 20571\n",
      "Train: [epoch:569]  [ 20/172]  eta: 0:04:07  lr: 0.000048  loss: 0.6545 (0.6651)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [ 30/172]  eta: 0:03:49  lr: 0.000048  loss: 0.6613 (0.6688)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [ 40/172]  eta: 0:03:31  lr: 0.000048  loss: 0.6565 (0.6652)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [ 50/172]  eta: 0:03:15  lr: 0.000048  loss: 0.6484 (0.6649)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [ 60/172]  eta: 0:02:58  lr: 0.000048  loss: 0.6627 (0.6656)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [ 70/172]  eta: 0:02:42  lr: 0.000048  loss: 0.6718 (0.6660)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [ 80/172]  eta: 0:02:26  lr: 0.000048  loss: 0.6675 (0.6669)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [ 90/172]  eta: 0:02:10  lr: 0.000048  loss: 0.6722 (0.6683)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [100/172]  eta: 0:01:54  lr: 0.000048  loss: 0.6644 (0.6674)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [110/172]  eta: 0:01:38  lr: 0.000048  loss: 0.6465 (0.6667)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [120/172]  eta: 0:01:22  lr: 0.000048  loss: 0.6571 (0.6666)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [130/172]  eta: 0:01:06  lr: 0.000048  loss: 0.6589 (0.6670)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [140/172]  eta: 0:00:50  lr: 0.000048  loss: 0.6603 (0.6667)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [150/172]  eta: 0:00:34  lr: 0.000048  loss: 0.6746 (0.6670)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [160/172]  eta: 0:00:19  lr: 0.000048  loss: 0.6570 (0.6661)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [170/172]  eta: 0:00:03  lr: 0.000048  loss: 0.6511 (0.6650)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569]  [171/172]  eta: 0:00:01  lr: 0.000048  loss: 0.6511 (0.6649)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:569] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000048  loss: 0.6511 (0.6649)\n",
      "Valid: [epoch:569]  [ 0/14]  eta: 0:00:05  loss: 0.6817 (0.6817)  time: 0.4000  data: 0.3836  max mem: 20571\n",
      "Valid: [epoch:569]  [13/14]  eta: 0:00:00  loss: 0.6255 (0.6309)  time: 0.0440  data: 0.0288  max mem: 20571\n",
      "Valid: [epoch:569] Total time: 0:00:00 (0.0520 s / it)\n",
      "Averaged stats: loss: 0.6255 (0.6309)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_569_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.631%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:570]  [  0/172]  eta: 0:08:02  lr: 0.000048  loss: 0.6810 (0.6810)  time: 2.8048  data: 1.2379  max mem: 20571\n",
      "Train: [epoch:570]  [ 10/172]  eta: 0:04:33  lr: 0.000048  loss: 0.6749 (0.6715)  time: 1.6899  data: 0.1127  max mem: 20571\n",
      "Train: [epoch:570]  [ 20/172]  eta: 0:04:08  lr: 0.000048  loss: 0.6629 (0.6669)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:570]  [ 30/172]  eta: 0:03:49  lr: 0.000048  loss: 0.6497 (0.6657)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [ 40/172]  eta: 0:03:32  lr: 0.000048  loss: 0.6570 (0.6664)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [ 50/172]  eta: 0:03:15  lr: 0.000048  loss: 0.6526 (0.6659)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [ 60/172]  eta: 0:02:59  lr: 0.000048  loss: 0.6518 (0.6630)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [ 70/172]  eta: 0:02:42  lr: 0.000048  loss: 0.6594 (0.6645)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [ 80/172]  eta: 0:02:26  lr: 0.000048  loss: 0.6659 (0.6646)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [ 90/172]  eta: 0:02:10  lr: 0.000048  loss: 0.6515 (0.6641)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [100/172]  eta: 0:01:54  lr: 0.000048  loss: 0.6570 (0.6640)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [110/172]  eta: 0:01:38  lr: 0.000048  loss: 0.6650 (0.6629)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [120/172]  eta: 0:01:22  lr: 0.000048  loss: 0.6618 (0.6645)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [130/172]  eta: 0:01:06  lr: 0.000048  loss: 0.6687 (0.6648)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [140/172]  eta: 0:00:50  lr: 0.000048  loss: 0.6479 (0.6647)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [150/172]  eta: 0:00:34  lr: 0.000048  loss: 0.6554 (0.6645)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [160/172]  eta: 0:00:19  lr: 0.000048  loss: 0.6554 (0.6650)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [170/172]  eta: 0:00:03  lr: 0.000048  loss: 0.6748 (0.6667)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570]  [171/172]  eta: 0:00:01  lr: 0.000048  loss: 0.6748 (0.6671)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:570] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000048  loss: 0.6748 (0.6671)\n",
      "Valid: [epoch:570]  [ 0/14]  eta: 0:00:04  loss: 0.6799 (0.6799)  time: 0.3233  data: 0.3061  max mem: 20571\n",
      "Valid: [epoch:570]  [13/14]  eta: 0:00:00  loss: 0.6245 (0.6300)  time: 0.0386  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:570] Total time: 0:00:00 (0.0445 s / it)\n",
      "Averaged stats: loss: 0.6245 (0.6300)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_570_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.630%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:571]  [  0/172]  eta: 0:07:18  lr: 0.000048  loss: 0.6005 (0.6005)  time: 2.5468  data: 0.9717  max mem: 20571\n",
      "Train: [epoch:571]  [ 10/172]  eta: 0:04:30  lr: 0.000048  loss: 0.6566 (0.6556)  time: 1.6667  data: 0.0884  max mem: 20571\n",
      "Train: [epoch:571]  [ 20/172]  eta: 0:04:06  lr: 0.000048  loss: 0.6632 (0.6714)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [ 30/172]  eta: 0:03:48  lr: 0.000048  loss: 0.6649 (0.6686)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [ 40/172]  eta: 0:03:31  lr: 0.000048  loss: 0.6594 (0.6702)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [ 50/172]  eta: 0:03:14  lr: 0.000048  loss: 0.6654 (0.6774)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [ 60/172]  eta: 0:02:58  lr: 0.000048  loss: 0.6914 (0.6779)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [ 70/172]  eta: 0:02:42  lr: 0.000048  loss: 0.6597 (0.6735)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [ 80/172]  eta: 0:02:26  lr: 0.000048  loss: 0.6505 (0.6706)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [ 90/172]  eta: 0:02:10  lr: 0.000048  loss: 0.6664 (0.6713)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [100/172]  eta: 0:01:54  lr: 0.000048  loss: 0.6761 (0.6719)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:571]  [110/172]  eta: 0:01:38  lr: 0.000048  loss: 0.6519 (0.6698)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:571]  [120/172]  eta: 0:01:22  lr: 0.000048  loss: 0.6515 (0.6693)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [130/172]  eta: 0:01:06  lr: 0.000048  loss: 0.6743 (0.6711)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [140/172]  eta: 0:00:50  lr: 0.000048  loss: 0.6732 (0.6705)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [150/172]  eta: 0:00:34  lr: 0.000048  loss: 0.6583 (0.6695)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [160/172]  eta: 0:00:19  lr: 0.000048  loss: 0.6583 (0.6690)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571]  [170/172]  eta: 0:00:03  lr: 0.000048  loss: 0.6672 (0.6690)  time: 1.5811  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:571]  [171/172]  eta: 0:00:01  lr: 0.000048  loss: 0.6738 (0.6693)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:571] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000048  loss: 0.6738 (0.6693)\n",
      "Valid: [epoch:571]  [ 0/14]  eta: 0:00:04  loss: 0.6813 (0.6813)  time: 0.3381  data: 0.3229  max mem: 20571\n",
      "Valid: [epoch:571]  [13/14]  eta: 0:00:00  loss: 0.6422 (0.6488)  time: 0.0383  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:571] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.6422 (0.6488)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_571_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.649%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:572]  [  0/172]  eta: 0:08:17  lr: 0.000048  loss: 0.6176 (0.6176)  time: 2.8936  data: 1.3270  max mem: 20571\n",
      "Train: [epoch:572]  [ 10/172]  eta: 0:04:34  lr: 0.000048  loss: 0.6768 (0.6825)  time: 1.6973  data: 0.1208  max mem: 20571\n",
      "Train: [epoch:572]  [ 20/172]  eta: 0:04:09  lr: 0.000048  loss: 0.6681 (0.6719)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [ 30/172]  eta: 0:03:50  lr: 0.000048  loss: 0.6644 (0.6713)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [ 40/172]  eta: 0:03:32  lr: 0.000048  loss: 0.6654 (0.6678)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [ 50/172]  eta: 0:03:15  lr: 0.000048  loss: 0.6553 (0.6674)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [ 60/172]  eta: 0:02:59  lr: 0.000048  loss: 0.6712 (0.6704)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [ 70/172]  eta: 0:02:43  lr: 0.000048  loss: 0.6572 (0.6666)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [ 80/172]  eta: 0:02:26  lr: 0.000048  loss: 0.6572 (0.6656)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [ 90/172]  eta: 0:02:10  lr: 0.000048  loss: 0.6757 (0.6667)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [100/172]  eta: 0:01:54  lr: 0.000048  loss: 0.6786 (0.6666)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [110/172]  eta: 0:01:38  lr: 0.000048  loss: 0.6673 (0.6667)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [120/172]  eta: 0:01:22  lr: 0.000048  loss: 0.6631 (0.6672)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [130/172]  eta: 0:01:06  lr: 0.000048  loss: 0.6631 (0.6674)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [140/172]  eta: 0:00:50  lr: 0.000048  loss: 0.6697 (0.6681)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [150/172]  eta: 0:00:34  lr: 0.000048  loss: 0.6997 (0.6696)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [160/172]  eta: 0:00:19  lr: 0.000048  loss: 0.6973 (0.6699)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [170/172]  eta: 0:00:03  lr: 0.000048  loss: 0.6670 (0.6697)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572]  [171/172]  eta: 0:00:01  lr: 0.000048  loss: 0.6657 (0.6696)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:572] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000048  loss: 0.6657 (0.6696)\n",
      "Valid: [epoch:572]  [ 0/14]  eta: 0:00:05  loss: 0.6270 (0.6270)  time: 0.3575  data: 0.3426  max mem: 20571\n",
      "Valid: [epoch:572]  [13/14]  eta: 0:00:00  loss: 0.6319 (0.6379)  time: 0.0475  data: 0.0324  max mem: 20571\n",
      "Valid: [epoch:572] Total time: 0:00:00 (0.0524 s / it)\n",
      "Averaged stats: loss: 0.6319 (0.6379)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_572_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.638%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:573]  [  0/172]  eta: 0:07:42  lr: 0.000048  loss: 0.7306 (0.7306)  time: 2.6909  data: 1.1171  max mem: 20571\n",
      "Train: [epoch:573]  [ 10/172]  eta: 0:04:31  lr: 0.000048  loss: 0.6862 (0.6718)  time: 1.6765  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:573]  [ 20/172]  eta: 0:04:07  lr: 0.000048  loss: 0.6630 (0.6677)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [ 30/172]  eta: 0:03:48  lr: 0.000048  loss: 0.6630 (0.6701)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [ 40/172]  eta: 0:03:31  lr: 0.000048  loss: 0.6576 (0.6688)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [ 50/172]  eta: 0:03:15  lr: 0.000048  loss: 0.6526 (0.6700)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [ 60/172]  eta: 0:02:58  lr: 0.000048  loss: 0.6526 (0.6695)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [ 70/172]  eta: 0:02:42  lr: 0.000048  loss: 0.6503 (0.6682)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [ 80/172]  eta: 0:02:26  lr: 0.000048  loss: 0.6693 (0.6708)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [ 90/172]  eta: 0:02:10  lr: 0.000048  loss: 0.6984 (0.6726)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [100/172]  eta: 0:01:54  lr: 0.000048  loss: 0.6726 (0.6718)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [110/172]  eta: 0:01:38  lr: 0.000048  loss: 0.6725 (0.6720)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [120/172]  eta: 0:01:22  lr: 0.000048  loss: 0.6799 (0.6723)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [130/172]  eta: 0:01:06  lr: 0.000048  loss: 0.6696 (0.6720)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [140/172]  eta: 0:00:50  lr: 0.000048  loss: 0.6739 (0.6717)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [150/172]  eta: 0:00:34  lr: 0.000048  loss: 0.6689 (0.6713)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [160/172]  eta: 0:00:19  lr: 0.000048  loss: 0.6568 (0.6706)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [170/172]  eta: 0:00:03  lr: 0.000048  loss: 0.6557 (0.6702)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573]  [171/172]  eta: 0:00:01  lr: 0.000048  loss: 0.6557 (0.6701)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:573] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000048  loss: 0.6557 (0.6701)\n",
      "Valid: [epoch:573]  [ 0/14]  eta: 0:00:04  loss: 0.6324 (0.6324)  time: 0.3464  data: 0.3309  max mem: 20571\n",
      "Valid: [epoch:573]  [13/14]  eta: 0:00:00  loss: 0.6464 (0.6519)  time: 0.0399  data: 0.0247  max mem: 20571\n",
      "Valid: [epoch:573] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.6464 (0.6519)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_573_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.652%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:574]  [  0/172]  eta: 0:07:47  lr: 0.000047  loss: 0.6714 (0.6714)  time: 2.7204  data: 1.1524  max mem: 20571\n",
      "Train: [epoch:574]  [ 10/172]  eta: 0:04:32  lr: 0.000047  loss: 0.6662 (0.6673)  time: 1.6828  data: 0.1049  max mem: 20571\n",
      "Train: [epoch:574]  [ 20/172]  eta: 0:04:08  lr: 0.000047  loss: 0.6660 (0.6712)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [ 30/172]  eta: 0:03:49  lr: 0.000047  loss: 0.6661 (0.6718)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [ 40/172]  eta: 0:03:32  lr: 0.000047  loss: 0.6672 (0.6706)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [ 50/172]  eta: 0:03:15  lr: 0.000047  loss: 0.6672 (0.6696)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [ 60/172]  eta: 0:02:59  lr: 0.000047  loss: 0.6614 (0.6680)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [ 70/172]  eta: 0:02:42  lr: 0.000047  loss: 0.6570 (0.6699)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [ 80/172]  eta: 0:02:26  lr: 0.000047  loss: 0.6819 (0.6734)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [ 90/172]  eta: 0:02:10  lr: 0.000047  loss: 0.6924 (0.6744)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [100/172]  eta: 0:01:54  lr: 0.000047  loss: 0.6791 (0.6743)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [110/172]  eta: 0:01:38  lr: 0.000047  loss: 0.6771 (0.6740)  time: 1.5810  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:574]  [120/172]  eta: 0:01:22  lr: 0.000047  loss: 0.6604 (0.6736)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [130/172]  eta: 0:01:06  lr: 0.000047  loss: 0.6595 (0.6731)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [140/172]  eta: 0:00:50  lr: 0.000047  loss: 0.6591 (0.6722)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [150/172]  eta: 0:00:34  lr: 0.000047  loss: 0.6631 (0.6722)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [160/172]  eta: 0:00:19  lr: 0.000047  loss: 0.6678 (0.6714)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [170/172]  eta: 0:00:03  lr: 0.000047  loss: 0.6666 (0.6715)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574]  [171/172]  eta: 0:00:01  lr: 0.000047  loss: 0.6678 (0.6716)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:574] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000047  loss: 0.6678 (0.6716)\n",
      "Valid: [epoch:574]  [ 0/14]  eta: 0:00:04  loss: 0.6605 (0.6605)  time: 0.3419  data: 0.3240  max mem: 20571\n",
      "Valid: [epoch:574]  [13/14]  eta: 0:00:00  loss: 0.6321 (0.6378)  time: 0.0395  data: 0.0242  max mem: 20571\n",
      "Valid: [epoch:574] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.6321 (0.6378)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_574_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.638%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:575]  [  0/172]  eta: 0:08:24  lr: 0.000047  loss: 0.6863 (0.6863)  time: 2.9345  data: 1.3545  max mem: 20571\n",
      "Train: [epoch:575]  [ 10/172]  eta: 0:04:35  lr: 0.000047  loss: 0.6620 (0.6572)  time: 1.6994  data: 0.1233  max mem: 20571\n",
      "Train: [epoch:575]  [ 20/172]  eta: 0:04:09  lr: 0.000047  loss: 0.6629 (0.6610)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [ 30/172]  eta: 0:03:50  lr: 0.000047  loss: 0.6460 (0.6586)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [ 40/172]  eta: 0:03:32  lr: 0.000047  loss: 0.6502 (0.6611)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [ 50/172]  eta: 0:03:16  lr: 0.000047  loss: 0.6710 (0.6645)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [ 60/172]  eta: 0:02:59  lr: 0.000047  loss: 0.6812 (0.6670)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [ 70/172]  eta: 0:02:43  lr: 0.000047  loss: 0.6923 (0.6701)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [ 80/172]  eta: 0:02:26  lr: 0.000047  loss: 0.6736 (0.6708)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [ 90/172]  eta: 0:02:10  lr: 0.000047  loss: 0.6608 (0.6704)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [100/172]  eta: 0:01:54  lr: 0.000047  loss: 0.6824 (0.6728)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [110/172]  eta: 0:01:38  lr: 0.000047  loss: 0.6801 (0.6728)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [120/172]  eta: 0:01:22  lr: 0.000047  loss: 0.6586 (0.6730)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [130/172]  eta: 0:01:06  lr: 0.000047  loss: 0.6708 (0.6737)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [140/172]  eta: 0:00:50  lr: 0.000047  loss: 0.6683 (0.6728)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [150/172]  eta: 0:00:34  lr: 0.000047  loss: 0.6510 (0.6723)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [160/172]  eta: 0:00:19  lr: 0.000047  loss: 0.6567 (0.6713)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [170/172]  eta: 0:00:03  lr: 0.000047  loss: 0.6454 (0.6707)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575]  [171/172]  eta: 0:00:01  lr: 0.000047  loss: 0.6454 (0.6709)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:575] Total time: 0:04:33 (1.5900 s / it)\n",
      "Averaged stats: lr: 0.000047  loss: 0.6454 (0.6709)\n",
      "Valid: [epoch:575]  [ 0/14]  eta: 0:00:04  loss: 0.6185 (0.6185)  time: 0.3377  data: 0.3221  max mem: 20571\n",
      "Valid: [epoch:575]  [13/14]  eta: 0:00:00  loss: 0.6510 (0.6562)  time: 0.0394  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:575] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.6510 (0.6562)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_575_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.656%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:576]  [  0/172]  eta: 0:08:13  lr: 0.000047  loss: 0.6386 (0.6386)  time: 2.8676  data: 1.2851  max mem: 20571\n",
      "Train: [epoch:576]  [ 10/172]  eta: 0:04:34  lr: 0.000047  loss: 0.6493 (0.6482)  time: 1.6959  data: 0.1169  max mem: 20571\n",
      "Train: [epoch:576]  [ 20/172]  eta: 0:04:09  lr: 0.000047  loss: 0.6541 (0.6646)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [ 30/172]  eta: 0:03:50  lr: 0.000047  loss: 0.6603 (0.6655)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [ 40/172]  eta: 0:03:32  lr: 0.000047  loss: 0.6612 (0.6691)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [ 50/172]  eta: 0:03:15  lr: 0.000047  loss: 0.6747 (0.6728)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [ 60/172]  eta: 0:02:59  lr: 0.000047  loss: 0.6766 (0.6730)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [ 70/172]  eta: 0:02:43  lr: 0.000047  loss: 0.6705 (0.6725)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [ 80/172]  eta: 0:02:26  lr: 0.000047  loss: 0.6427 (0.6698)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [ 90/172]  eta: 0:02:10  lr: 0.000047  loss: 0.6444 (0.6697)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [100/172]  eta: 0:01:54  lr: 0.000047  loss: 0.6474 (0.6685)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [110/172]  eta: 0:01:38  lr: 0.000047  loss: 0.6620 (0.6713)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [120/172]  eta: 0:01:22  lr: 0.000047  loss: 0.6816 (0.6717)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [130/172]  eta: 0:01:06  lr: 0.000047  loss: 0.6772 (0.6730)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [140/172]  eta: 0:00:50  lr: 0.000047  loss: 0.6761 (0.6728)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [150/172]  eta: 0:00:34  lr: 0.000047  loss: 0.6699 (0.6722)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [160/172]  eta: 0:00:19  lr: 0.000047  loss: 0.6719 (0.6723)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [170/172]  eta: 0:00:03  lr: 0.000047  loss: 0.6707 (0.6719)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576]  [171/172]  eta: 0:00:01  lr: 0.000047  loss: 0.6741 (0.6721)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:576] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000047  loss: 0.6741 (0.6721)\n",
      "Valid: [epoch:576]  [ 0/14]  eta: 0:00:05  loss: 0.6595 (0.6595)  time: 0.4006  data: 0.3856  max mem: 20571\n",
      "Valid: [epoch:576]  [13/14]  eta: 0:00:00  loss: 0.6282 (0.6335)  time: 0.0432  data: 0.0282  max mem: 20571\n",
      "Valid: [epoch:576] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.6282 (0.6335)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_576_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.633%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:577]  [  0/172]  eta: 0:07:49  lr: 0.000047  loss: 0.6663 (0.6663)  time: 2.7292  data: 1.1578  max mem: 20571\n",
      "Train: [epoch:577]  [ 10/172]  eta: 0:04:32  lr: 0.000047  loss: 0.6598 (0.6558)  time: 1.6815  data: 0.1053  max mem: 20571\n",
      "Train: [epoch:577]  [ 20/172]  eta: 0:04:08  lr: 0.000047  loss: 0.6578 (0.6628)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [ 30/172]  eta: 0:03:49  lr: 0.000047  loss: 0.6578 (0.6660)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [ 40/172]  eta: 0:03:32  lr: 0.000047  loss: 0.6735 (0.6689)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [ 50/172]  eta: 0:03:15  lr: 0.000047  loss: 0.6735 (0.6701)  time: 1.5815  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:577]  [ 60/172]  eta: 0:02:59  lr: 0.000047  loss: 0.6675 (0.6686)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [ 70/172]  eta: 0:02:42  lr: 0.000047  loss: 0.6587 (0.6690)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [ 80/172]  eta: 0:02:26  lr: 0.000047  loss: 0.6672 (0.6688)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [ 90/172]  eta: 0:02:10  lr: 0.000047  loss: 0.6716 (0.6704)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [100/172]  eta: 0:01:54  lr: 0.000047  loss: 0.6823 (0.6730)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [110/172]  eta: 0:01:38  lr: 0.000047  loss: 0.6904 (0.6745)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [120/172]  eta: 0:01:22  lr: 0.000047  loss: 0.6540 (0.6730)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [130/172]  eta: 0:01:06  lr: 0.000047  loss: 0.6566 (0.6743)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [140/172]  eta: 0:00:50  lr: 0.000047  loss: 0.6629 (0.6739)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [150/172]  eta: 0:00:34  lr: 0.000047  loss: 0.6744 (0.6746)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [160/172]  eta: 0:00:19  lr: 0.000047  loss: 0.6797 (0.6748)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [170/172]  eta: 0:00:03  lr: 0.000047  loss: 0.6683 (0.6742)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577]  [171/172]  eta: 0:00:01  lr: 0.000047  loss: 0.6742 (0.6744)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:577] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000047  loss: 0.6742 (0.6744)\n",
      "Valid: [epoch:577]  [ 0/14]  eta: 0:00:04  loss: 0.5761 (0.5761)  time: 0.3383  data: 0.3230  max mem: 20571\n",
      "Valid: [epoch:577]  [13/14]  eta: 0:00:00  loss: 0.6393 (0.6464)  time: 0.0391  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:577] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.6393 (0.6464)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_577_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.646%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:578]  [  0/172]  eta: 0:07:27  lr: 0.000047  loss: 0.7331 (0.7331)  time: 2.6043  data: 1.0347  max mem: 20571\n",
      "Train: [epoch:578]  [ 10/172]  eta: 0:04:31  lr: 0.000047  loss: 0.6981 (0.7011)  time: 1.6732  data: 0.0942  max mem: 20571\n",
      "Train: [epoch:578]  [ 20/172]  eta: 0:04:07  lr: 0.000047  loss: 0.6696 (0.6886)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [ 30/172]  eta: 0:03:49  lr: 0.000047  loss: 0.6492 (0.6760)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [ 40/172]  eta: 0:03:32  lr: 0.000047  loss: 0.6516 (0.6716)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [ 50/172]  eta: 0:03:15  lr: 0.000047  loss: 0.6562 (0.6747)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [ 60/172]  eta: 0:02:58  lr: 0.000047  loss: 0.6700 (0.6737)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [ 70/172]  eta: 0:02:42  lr: 0.000047  loss: 0.6700 (0.6733)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [ 80/172]  eta: 0:02:26  lr: 0.000047  loss: 0.6657 (0.6717)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [ 90/172]  eta: 0:02:10  lr: 0.000047  loss: 0.6661 (0.6726)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [100/172]  eta: 0:01:54  lr: 0.000047  loss: 0.6676 (0.6725)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [110/172]  eta: 0:01:38  lr: 0.000047  loss: 0.6668 (0.6733)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [120/172]  eta: 0:01:22  lr: 0.000047  loss: 0.6856 (0.6747)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [130/172]  eta: 0:01:06  lr: 0.000047  loss: 0.6756 (0.6742)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [140/172]  eta: 0:00:50  lr: 0.000047  loss: 0.6578 (0.6735)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [150/172]  eta: 0:00:34  lr: 0.000047  loss: 0.6578 (0.6731)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [160/172]  eta: 0:00:19  lr: 0.000047  loss: 0.6534 (0.6720)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [170/172]  eta: 0:00:03  lr: 0.000047  loss: 0.6518 (0.6717)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578]  [171/172]  eta: 0:00:01  lr: 0.000047  loss: 0.6534 (0.6722)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:578] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000047  loss: 0.6534 (0.6722)\n",
      "Valid: [epoch:578]  [ 0/14]  eta: 0:00:04  loss: 0.6618 (0.6618)  time: 0.2894  data: 0.2743  max mem: 20571\n",
      "Valid: [epoch:578]  [13/14]  eta: 0:00:00  loss: 0.6305 (0.6357)  time: 0.0370  data: 0.0221  max mem: 20571\n",
      "Valid: [epoch:578] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.6305 (0.6357)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_578_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.636%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:579]  [  0/172]  eta: 0:07:29  lr: 0.000047  loss: 0.6708 (0.6708)  time: 2.6106  data: 1.0264  max mem: 20571\n",
      "Train: [epoch:579]  [ 10/172]  eta: 0:04:30  lr: 0.000047  loss: 0.6460 (0.6571)  time: 1.6721  data: 0.0934  max mem: 20571\n",
      "Train: [epoch:579]  [ 20/172]  eta: 0:04:07  lr: 0.000047  loss: 0.6752 (0.6750)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [ 30/172]  eta: 0:03:48  lr: 0.000047  loss: 0.6761 (0.6722)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [ 40/172]  eta: 0:03:31  lr: 0.000047  loss: 0.6643 (0.6726)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [ 50/172]  eta: 0:03:15  lr: 0.000047  loss: 0.6598 (0.6713)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [ 60/172]  eta: 0:02:58  lr: 0.000047  loss: 0.6639 (0.6734)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [ 70/172]  eta: 0:02:42  lr: 0.000047  loss: 0.6735 (0.6775)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [ 80/172]  eta: 0:02:26  lr: 0.000047  loss: 0.6735 (0.6773)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [ 90/172]  eta: 0:02:10  lr: 0.000047  loss: 0.6670 (0.6777)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [100/172]  eta: 0:01:54  lr: 0.000047  loss: 0.6664 (0.6769)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [110/172]  eta: 0:01:38  lr: 0.000047  loss: 0.6644 (0.6762)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [120/172]  eta: 0:01:22  lr: 0.000047  loss: 0.6719 (0.6776)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [130/172]  eta: 0:01:06  lr: 0.000047  loss: 0.6608 (0.6758)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [140/172]  eta: 0:00:50  lr: 0.000047  loss: 0.6555 (0.6758)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [150/172]  eta: 0:00:34  lr: 0.000047  loss: 0.6639 (0.6755)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [160/172]  eta: 0:00:19  lr: 0.000047  loss: 0.6632 (0.6750)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [170/172]  eta: 0:00:03  lr: 0.000047  loss: 0.6698 (0.6754)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579]  [171/172]  eta: 0:00:01  lr: 0.000047  loss: 0.6682 (0.6751)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:579] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000047  loss: 0.6682 (0.6751)\n",
      "Valid: [epoch:579]  [ 0/14]  eta: 0:00:04  loss: 0.5927 (0.5927)  time: 0.3003  data: 0.2846  max mem: 20571\n",
      "Valid: [epoch:579]  [13/14]  eta: 0:00:00  loss: 0.6399 (0.6465)  time: 0.0412  data: 0.0262  max mem: 20571\n",
      "Valid: [epoch:579] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.6399 (0.6465)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_579_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.646%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:580]  [  0/172]  eta: 0:07:51  lr: 0.000047  loss: 0.6596 (0.6596)  time: 2.7388  data: 1.1705  max mem: 20571\n",
      "Train: [epoch:580]  [ 10/172]  eta: 0:04:32  lr: 0.000047  loss: 0.6636 (0.6843)  time: 1.6847  data: 0.1065  max mem: 20571\n",
      "Train: [epoch:580]  [ 20/172]  eta: 0:04:08  lr: 0.000047  loss: 0.6636 (0.6757)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [ 30/172]  eta: 0:03:49  lr: 0.000047  loss: 0.6529 (0.6726)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:580]  [ 40/172]  eta: 0:03:32  lr: 0.000047  loss: 0.6529 (0.6719)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [ 50/172]  eta: 0:03:15  lr: 0.000047  loss: 0.6719 (0.6760)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [ 60/172]  eta: 0:02:59  lr: 0.000047  loss: 0.6856 (0.6782)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [ 70/172]  eta: 0:02:42  lr: 0.000047  loss: 0.6814 (0.6770)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [ 80/172]  eta: 0:02:26  lr: 0.000047  loss: 0.6814 (0.6785)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [ 90/172]  eta: 0:02:10  lr: 0.000047  loss: 0.6563 (0.6769)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [100/172]  eta: 0:01:54  lr: 0.000047  loss: 0.6532 (0.6767)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [110/172]  eta: 0:01:38  lr: 0.000047  loss: 0.6625 (0.6756)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [120/172]  eta: 0:01:22  lr: 0.000047  loss: 0.6643 (0.6754)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [130/172]  eta: 0:01:06  lr: 0.000047  loss: 0.6643 (0.6752)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [140/172]  eta: 0:00:50  lr: 0.000047  loss: 0.6677 (0.6751)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [150/172]  eta: 0:00:34  lr: 0.000047  loss: 0.6677 (0.6748)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [160/172]  eta: 0:00:19  lr: 0.000047  loss: 0.6803 (0.6751)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [170/172]  eta: 0:00:03  lr: 0.000047  loss: 0.6822 (0.6758)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580]  [171/172]  eta: 0:00:01  lr: 0.000047  loss: 0.6822 (0.6757)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:580] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000047  loss: 0.6822 (0.6757)\n",
      "Valid: [epoch:580]  [ 0/14]  eta: 0:00:06  loss: 0.6692 (0.6692)  time: 0.4636  data: 0.4465  max mem: 20571\n",
      "Valid: [epoch:580]  [13/14]  eta: 0:00:00  loss: 0.6337 (0.6387)  time: 0.0474  data: 0.0322  max mem: 20571\n",
      "Valid: [epoch:580] Total time: 0:00:00 (0.0524 s / it)\n",
      "Averaged stats: loss: 0.6337 (0.6387)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_580_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.639%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:581]  [  0/172]  eta: 0:07:39  lr: 0.000047  loss: 0.7512 (0.7512)  time: 2.6724  data: 1.0988  max mem: 20571\n",
      "Train: [epoch:581]  [ 10/172]  eta: 0:04:31  lr: 0.000047  loss: 0.6524 (0.6787)  time: 1.6762  data: 0.1000  max mem: 20571\n",
      "Train: [epoch:581]  [ 20/172]  eta: 0:04:07  lr: 0.000047  loss: 0.6524 (0.6842)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [ 30/172]  eta: 0:03:49  lr: 0.000047  loss: 0.6785 (0.6815)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [ 40/172]  eta: 0:03:31  lr: 0.000047  loss: 0.6626 (0.6770)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [ 50/172]  eta: 0:03:15  lr: 0.000047  loss: 0.6626 (0.6783)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [ 60/172]  eta: 0:02:58  lr: 0.000047  loss: 0.6692 (0.6760)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [ 70/172]  eta: 0:02:42  lr: 0.000047  loss: 0.6795 (0.6765)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [ 80/172]  eta: 0:02:26  lr: 0.000047  loss: 0.6780 (0.6766)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [ 90/172]  eta: 0:02:10  lr: 0.000047  loss: 0.6638 (0.6760)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [100/172]  eta: 0:01:54  lr: 0.000047  loss: 0.6638 (0.6751)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [110/172]  eta: 0:01:38  lr: 0.000047  loss: 0.6728 (0.6763)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [120/172]  eta: 0:01:22  lr: 0.000047  loss: 0.6777 (0.6770)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [130/172]  eta: 0:01:06  lr: 0.000047  loss: 0.6732 (0.6763)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [140/172]  eta: 0:00:50  lr: 0.000047  loss: 0.6613 (0.6758)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [150/172]  eta: 0:00:34  lr: 0.000047  loss: 0.6571 (0.6749)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [160/172]  eta: 0:00:19  lr: 0.000047  loss: 0.6661 (0.6764)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [170/172]  eta: 0:00:03  lr: 0.000047  loss: 0.7008 (0.6777)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581]  [171/172]  eta: 0:00:01  lr: 0.000047  loss: 0.6904 (0.6776)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:581] Total time: 0:04:32 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000047  loss: 0.6904 (0.6776)\n",
      "Valid: [epoch:581]  [ 0/14]  eta: 0:00:04  loss: 0.6967 (0.6967)  time: 0.3223  data: 0.3057  max mem: 20571\n",
      "Valid: [epoch:581]  [13/14]  eta: 0:00:00  loss: 0.6364 (0.6439)  time: 0.0378  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:581] Total time: 0:00:00 (0.0426 s / it)\n",
      "Averaged stats: loss: 0.6364 (0.6439)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_581_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.644%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:582]  [  0/172]  eta: 0:07:44  lr: 0.000047  loss: 0.6855 (0.6855)  time: 2.7034  data: 1.1352  max mem: 20571\n",
      "Train: [epoch:582]  [ 10/172]  eta: 0:04:32  lr: 0.000047  loss: 0.6841 (0.6690)  time: 1.6823  data: 0.1033  max mem: 20571\n",
      "Train: [epoch:582]  [ 20/172]  eta: 0:04:08  lr: 0.000047  loss: 0.6812 (0.6750)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [ 30/172]  eta: 0:03:49  lr: 0.000047  loss: 0.6812 (0.6734)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [ 40/172]  eta: 0:03:32  lr: 0.000047  loss: 0.6742 (0.6707)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [ 50/172]  eta: 0:03:15  lr: 0.000047  loss: 0.6773 (0.6733)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [ 60/172]  eta: 0:02:58  lr: 0.000047  loss: 0.6702 (0.6731)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [ 70/172]  eta: 0:02:42  lr: 0.000047  loss: 0.6690 (0.6747)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [ 80/172]  eta: 0:02:26  lr: 0.000047  loss: 0.6869 (0.6770)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [ 90/172]  eta: 0:02:10  lr: 0.000047  loss: 0.7045 (0.6777)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [100/172]  eta: 0:01:54  lr: 0.000047  loss: 0.6824 (0.6778)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [110/172]  eta: 0:01:38  lr: 0.000047  loss: 0.6800 (0.6778)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [120/172]  eta: 0:01:22  lr: 0.000047  loss: 0.6641 (0.6777)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [130/172]  eta: 0:01:06  lr: 0.000047  loss: 0.6838 (0.6779)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [140/172]  eta: 0:00:50  lr: 0.000047  loss: 0.6739 (0.6776)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [150/172]  eta: 0:00:34  lr: 0.000047  loss: 0.6749 (0.6781)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [160/172]  eta: 0:00:19  lr: 0.000047  loss: 0.6749 (0.6781)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582]  [170/172]  eta: 0:00:03  lr: 0.000047  loss: 0.6720 (0.6780)  time: 1.5830  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:582]  [171/172]  eta: 0:00:01  lr: 0.000047  loss: 0.6712 (0.6777)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:582] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000047  loss: 0.6712 (0.6777)\n",
      "Valid: [epoch:582]  [ 0/14]  eta: 0:00:04  loss: 0.6293 (0.6293)  time: 0.2902  data: 0.2745  max mem: 20571\n",
      "Valid: [epoch:582]  [13/14]  eta: 0:00:00  loss: 0.6435 (0.6501)  time: 0.0401  data: 0.0249  max mem: 20571\n",
      "Valid: [epoch:582] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.6435 (0.6501)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_582_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.650%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:583]  [  0/172]  eta: 0:07:32  lr: 0.000046  loss: 0.7364 (0.7364)  time: 2.6334  data: 1.0570  max mem: 20571\n",
      "Train: [epoch:583]  [ 10/172]  eta: 0:04:30  lr: 0.000046  loss: 0.6690 (0.6789)  time: 1.6714  data: 0.0962  max mem: 20571\n",
      "Train: [epoch:583]  [ 20/172]  eta: 0:04:07  lr: 0.000046  loss: 0.6695 (0.6828)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [ 30/172]  eta: 0:03:48  lr: 0.000046  loss: 0.6902 (0.6812)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [ 40/172]  eta: 0:03:31  lr: 0.000046  loss: 0.6902 (0.6832)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [ 50/172]  eta: 0:03:15  lr: 0.000046  loss: 0.6923 (0.6850)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [ 60/172]  eta: 0:02:58  lr: 0.000046  loss: 0.6955 (0.6887)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [ 70/172]  eta: 0:02:42  lr: 0.000046  loss: 0.6806 (0.6861)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [ 80/172]  eta: 0:02:26  lr: 0.000046  loss: 0.6672 (0.6835)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [ 90/172]  eta: 0:02:10  lr: 0.000046  loss: 0.6653 (0.6830)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [100/172]  eta: 0:01:54  lr: 0.000046  loss: 0.6653 (0.6823)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [110/172]  eta: 0:01:38  lr: 0.000046  loss: 0.6830 (0.6815)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [120/172]  eta: 0:01:22  lr: 0.000046  loss: 0.6666 (0.6816)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [130/172]  eta: 0:01:06  lr: 0.000046  loss: 0.6617 (0.6803)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [140/172]  eta: 0:00:50  lr: 0.000046  loss: 0.6537 (0.6796)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [150/172]  eta: 0:00:34  lr: 0.000046  loss: 0.6665 (0.6796)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [160/172]  eta: 0:00:19  lr: 0.000046  loss: 0.6651 (0.6797)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [170/172]  eta: 0:00:03  lr: 0.000046  loss: 0.6642 (0.6791)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583]  [171/172]  eta: 0:00:01  lr: 0.000046  loss: 0.6615 (0.6790)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:583] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000046  loss: 0.6615 (0.6790)\n",
      "Valid: [epoch:583]  [ 0/14]  eta: 0:00:04  loss: 0.5882 (0.5882)  time: 0.3168  data: 0.2997  max mem: 20571\n",
      "Valid: [epoch:583]  [13/14]  eta: 0:00:00  loss: 0.6382 (0.6437)  time: 0.0483  data: 0.0331  max mem: 20571\n",
      "Valid: [epoch:583] Total time: 0:00:00 (0.0563 s / it)\n",
      "Averaged stats: loss: 0.6382 (0.6437)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_583_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.644%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:584]  [  0/172]  eta: 0:08:01  lr: 0.000046  loss: 0.7551 (0.7551)  time: 2.7998  data: 1.2236  max mem: 20571\n",
      "Train: [epoch:584]  [ 10/172]  eta: 0:04:33  lr: 0.000046  loss: 0.6579 (0.6778)  time: 1.6906  data: 0.1114  max mem: 20571\n",
      "Train: [epoch:584]  [ 20/172]  eta: 0:04:08  lr: 0.000046  loss: 0.6592 (0.6810)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [ 30/172]  eta: 0:03:49  lr: 0.000046  loss: 0.6700 (0.6788)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [ 40/172]  eta: 0:03:32  lr: 0.000046  loss: 0.6652 (0.6725)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [ 50/172]  eta: 0:03:15  lr: 0.000046  loss: 0.6626 (0.6724)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [ 60/172]  eta: 0:02:59  lr: 0.000046  loss: 0.6737 (0.6795)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [ 70/172]  eta: 0:02:42  lr: 0.000046  loss: 0.6770 (0.6776)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [ 80/172]  eta: 0:02:26  lr: 0.000046  loss: 0.6666 (0.6772)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [ 90/172]  eta: 0:02:10  lr: 0.000046  loss: 0.6566 (0.6757)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [100/172]  eta: 0:01:54  lr: 0.000046  loss: 0.6624 (0.6766)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [110/172]  eta: 0:01:38  lr: 0.000046  loss: 0.6637 (0.6762)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [120/172]  eta: 0:01:22  lr: 0.000046  loss: 0.6810 (0.6783)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [130/172]  eta: 0:01:06  lr: 0.000046  loss: 0.6924 (0.6788)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [140/172]  eta: 0:00:50  lr: 0.000046  loss: 0.6812 (0.6794)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [150/172]  eta: 0:00:34  lr: 0.000046  loss: 0.6805 (0.6792)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [160/172]  eta: 0:00:19  lr: 0.000046  loss: 0.6849 (0.6788)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:584]  [170/172]  eta: 0:00:03  lr: 0.000046  loss: 0.6739 (0.6784)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584]  [171/172]  eta: 0:00:01  lr: 0.000046  loss: 0.6739 (0.6785)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:584] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000046  loss: 0.6739 (0.6785)\n",
      "Valid: [epoch:584]  [ 0/14]  eta: 0:00:04  loss: 0.6353 (0.6353)  time: 0.2871  data: 0.2723  max mem: 20571\n",
      "Valid: [epoch:584]  [13/14]  eta: 0:00:00  loss: 0.6353 (0.6401)  time: 0.0375  data: 0.0227  max mem: 20571\n",
      "Valid: [epoch:584] Total time: 0:00:00 (0.0432 s / it)\n",
      "Averaged stats: loss: 0.6353 (0.6401)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_584_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.640%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:585]  [  0/172]  eta: 0:08:13  lr: 0.000046  loss: 0.6629 (0.6629)  time: 2.8679  data: 1.2966  max mem: 20571\n",
      "Train: [epoch:585]  [ 10/172]  eta: 0:04:34  lr: 0.000046  loss: 0.6890 (0.6857)  time: 1.6934  data: 0.1180  max mem: 20571\n",
      "Train: [epoch:585]  [ 20/172]  eta: 0:04:09  lr: 0.000046  loss: 0.6859 (0.6852)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [ 30/172]  eta: 0:03:49  lr: 0.000046  loss: 0.6800 (0.6861)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [ 40/172]  eta: 0:03:32  lr: 0.000046  loss: 0.6800 (0.6847)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [ 50/172]  eta: 0:03:15  lr: 0.000046  loss: 0.6609 (0.6820)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [ 60/172]  eta: 0:02:59  lr: 0.000046  loss: 0.6635 (0.6821)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [ 70/172]  eta: 0:02:42  lr: 0.000046  loss: 0.6811 (0.6815)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [ 80/172]  eta: 0:02:26  lr: 0.000046  loss: 0.6743 (0.6804)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [ 90/172]  eta: 0:02:10  lr: 0.000046  loss: 0.6832 (0.6811)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [100/172]  eta: 0:01:54  lr: 0.000046  loss: 0.6928 (0.6824)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [110/172]  eta: 0:01:38  lr: 0.000046  loss: 0.6606 (0.6803)  time: 1.5812  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:585]  [120/172]  eta: 0:01:22  lr: 0.000046  loss: 0.6662 (0.6813)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [130/172]  eta: 0:01:06  lr: 0.000046  loss: 0.6826 (0.6818)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [140/172]  eta: 0:00:50  lr: 0.000046  loss: 0.6693 (0.6812)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [150/172]  eta: 0:00:34  lr: 0.000046  loss: 0.6660 (0.6805)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [160/172]  eta: 0:00:19  lr: 0.000046  loss: 0.6756 (0.6804)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [170/172]  eta: 0:00:03  lr: 0.000046  loss: 0.6756 (0.6802)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585]  [171/172]  eta: 0:00:01  lr: 0.000046  loss: 0.6769 (0.6803)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:585] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000046  loss: 0.6769 (0.6803)\n",
      "Valid: [epoch:585]  [ 0/14]  eta: 0:00:04  loss: 0.6465 (0.6465)  time: 0.3003  data: 0.2838  max mem: 20571\n",
      "Valid: [epoch:585]  [13/14]  eta: 0:00:00  loss: 0.6465 (0.6518)  time: 0.0411  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:585] Total time: 0:00:00 (0.0499 s / it)\n",
      "Averaged stats: loss: 0.6465 (0.6518)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_585_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.652%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:586]  [  0/172]  eta: 0:08:09  lr: 0.000046  loss: 0.7108 (0.7108)  time: 2.8478  data: 1.2718  max mem: 20571\n",
      "Train: [epoch:586]  [ 10/172]  eta: 0:04:34  lr: 0.000046  loss: 0.6696 (0.6795)  time: 1.6935  data: 0.1157  max mem: 20571\n",
      "Train: [epoch:586]  [ 20/172]  eta: 0:04:09  lr: 0.000046  loss: 0.6696 (0.6765)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [ 30/172]  eta: 0:03:49  lr: 0.000046  loss: 0.6857 (0.6784)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [ 40/172]  eta: 0:03:32  lr: 0.000046  loss: 0.6857 (0.6765)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [ 50/172]  eta: 0:03:15  lr: 0.000046  loss: 0.6728 (0.6758)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:586]  [ 60/172]  eta: 0:02:59  lr: 0.000046  loss: 0.6741 (0.6747)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:586]  [ 70/172]  eta: 0:02:42  lr: 0.000046  loss: 0.6692 (0.6736)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [ 80/172]  eta: 0:02:26  lr: 0.000046  loss: 0.6749 (0.6754)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [ 90/172]  eta: 0:02:10  lr: 0.000046  loss: 0.6799 (0.6769)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [100/172]  eta: 0:01:54  lr: 0.000046  loss: 0.6821 (0.6769)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [110/172]  eta: 0:01:38  lr: 0.000046  loss: 0.6821 (0.6776)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [120/172]  eta: 0:01:22  lr: 0.000046  loss: 0.6747 (0.6788)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [130/172]  eta: 0:01:06  lr: 0.000046  loss: 0.6747 (0.6791)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [140/172]  eta: 0:00:50  lr: 0.000046  loss: 0.6689 (0.6776)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [150/172]  eta: 0:00:34  lr: 0.000046  loss: 0.6769 (0.6795)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [160/172]  eta: 0:00:19  lr: 0.000046  loss: 0.7076 (0.6803)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [170/172]  eta: 0:00:03  lr: 0.000046  loss: 0.6978 (0.6808)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586]  [171/172]  eta: 0:00:01  lr: 0.000046  loss: 0.6940 (0.6809)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:586] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000046  loss: 0.6940 (0.6809)\n",
      "Valid: [epoch:586]  [ 0/14]  eta: 0:00:03  loss: 0.6774 (0.6774)  time: 0.2854  data: 0.2705  max mem: 20571\n",
      "Valid: [epoch:586]  [13/14]  eta: 0:00:00  loss: 0.6395 (0.6446)  time: 0.0374  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:586] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.6395 (0.6446)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_586_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.645%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:587]  [  0/172]  eta: 0:07:53  lr: 0.000046  loss: 0.7123 (0.7123)  time: 2.7507  data: 1.1669  max mem: 20571\n",
      "Train: [epoch:587]  [ 10/172]  eta: 0:04:32  lr: 0.000046  loss: 0.6657 (0.6642)  time: 1.6825  data: 0.1062  max mem: 20571\n",
      "Train: [epoch:587]  [ 20/172]  eta: 0:04:08  lr: 0.000046  loss: 0.6609 (0.6632)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:587]  [ 30/172]  eta: 0:03:49  lr: 0.000046  loss: 0.6783 (0.6704)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:587]  [ 40/172]  eta: 0:03:31  lr: 0.000046  loss: 0.6840 (0.6715)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:587]  [ 50/172]  eta: 0:03:15  lr: 0.000046  loss: 0.6795 (0.6748)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:587]  [ 60/172]  eta: 0:02:58  lr: 0.000046  loss: 0.6876 (0.6779)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:587]  [ 70/172]  eta: 0:02:42  lr: 0.000046  loss: 0.6933 (0.6806)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:587]  [ 80/172]  eta: 0:02:26  lr: 0.000046  loss: 0.6875 (0.6820)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:587]  [ 90/172]  eta: 0:02:10  lr: 0.000046  loss: 0.6729 (0.6807)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:587]  [100/172]  eta: 0:01:54  lr: 0.000046  loss: 0.6607 (0.6799)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:587]  [110/172]  eta: 0:01:38  lr: 0.000046  loss: 0.6840 (0.6809)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:587]  [120/172]  eta: 0:01:22  lr: 0.000046  loss: 0.6840 (0.6816)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:587]  [130/172]  eta: 0:01:06  lr: 0.000046  loss: 0.6716 (0.6822)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:587]  [140/172]  eta: 0:00:50  lr: 0.000046  loss: 0.6716 (0.6812)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:587]  [150/172]  eta: 0:00:34  lr: 0.000046  loss: 0.6776 (0.6823)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:587]  [160/172]  eta: 0:00:19  lr: 0.000046  loss: 0.6665 (0.6812)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:587]  [170/172]  eta: 0:00:03  lr: 0.000046  loss: 0.6641 (0.6813)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:587]  [171/172]  eta: 0:00:01  lr: 0.000046  loss: 0.6775 (0.6812)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:587] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000046  loss: 0.6775 (0.6812)\n",
      "Valid: [epoch:587]  [ 0/14]  eta: 0:00:04  loss: 0.6890 (0.6890)  time: 0.3109  data: 0.2960  max mem: 20571\n",
      "Valid: [epoch:587]  [13/14]  eta: 0:00:00  loss: 0.6519 (0.6585)  time: 0.0406  data: 0.0254  max mem: 20571\n",
      "Valid: [epoch:587] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.6519 (0.6585)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_587_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.658%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:588]  [  0/172]  eta: 0:07:26  lr: 0.000046  loss: 0.6703 (0.6703)  time: 2.5966  data: 1.0097  max mem: 20571\n",
      "Train: [epoch:588]  [ 10/172]  eta: 0:04:31  lr: 0.000046  loss: 0.6768 (0.6758)  time: 1.6755  data: 0.0919  max mem: 20571\n",
      "Train: [epoch:588]  [ 20/172]  eta: 0:04:07  lr: 0.000046  loss: 0.6780 (0.6815)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [ 30/172]  eta: 0:03:49  lr: 0.000046  loss: 0.6788 (0.6818)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [ 40/172]  eta: 0:03:31  lr: 0.000046  loss: 0.6741 (0.6792)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [ 50/172]  eta: 0:03:15  lr: 0.000046  loss: 0.6773 (0.6806)  time: 1.5809  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:588]  [ 60/172]  eta: 0:02:58  lr: 0.000046  loss: 0.6888 (0.6829)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [ 70/172]  eta: 0:02:42  lr: 0.000046  loss: 0.6796 (0.6838)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [ 80/172]  eta: 0:02:26  lr: 0.000046  loss: 0.6867 (0.6838)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [ 90/172]  eta: 0:02:10  lr: 0.000046  loss: 0.6773 (0.6829)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [100/172]  eta: 0:01:54  lr: 0.000046  loss: 0.6716 (0.6826)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [110/172]  eta: 0:01:38  lr: 0.000046  loss: 0.6827 (0.6842)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [120/172]  eta: 0:01:22  lr: 0.000046  loss: 0.6984 (0.6863)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [130/172]  eta: 0:01:06  lr: 0.000046  loss: 0.6965 (0.6870)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [140/172]  eta: 0:00:50  lr: 0.000046  loss: 0.6805 (0.6879)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [150/172]  eta: 0:00:34  lr: 0.000046  loss: 0.6769 (0.6871)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [160/172]  eta: 0:00:19  lr: 0.000046  loss: 0.6714 (0.6863)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [170/172]  eta: 0:00:03  lr: 0.000046  loss: 0.6723 (0.6855)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588]  [171/172]  eta: 0:00:01  lr: 0.000046  loss: 0.6723 (0.6853)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:588] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000046  loss: 0.6723 (0.6853)\n",
      "Valid: [epoch:588]  [ 0/14]  eta: 0:00:07  loss: 0.6867 (0.6867)  time: 0.5557  data: 0.5390  max mem: 20571\n",
      "Valid: [epoch:588]  [13/14]  eta: 0:00:00  loss: 0.6474 (0.6540)  time: 0.0541  data: 0.0388  max mem: 20571\n",
      "Valid: [epoch:588] Total time: 0:00:00 (0.0585 s / it)\n",
      "Averaged stats: loss: 0.6474 (0.6540)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_588_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.654%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:589]  [  0/172]  eta: 0:07:54  lr: 0.000046  loss: 0.7568 (0.7568)  time: 2.7570  data: 1.1822  max mem: 20571\n",
      "Train: [epoch:589]  [ 10/172]  eta: 0:04:32  lr: 0.000046  loss: 0.7029 (0.7005)  time: 1.6830  data: 0.1076  max mem: 20571\n",
      "Train: [epoch:589]  [ 20/172]  eta: 0:04:08  lr: 0.000046  loss: 0.6908 (0.6911)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [ 30/172]  eta: 0:03:49  lr: 0.000046  loss: 0.6764 (0.6839)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [ 40/172]  eta: 0:03:31  lr: 0.000046  loss: 0.6717 (0.6826)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [ 50/172]  eta: 0:03:15  lr: 0.000046  loss: 0.6742 (0.6820)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [ 60/172]  eta: 0:02:58  lr: 0.000046  loss: 0.6638 (0.6814)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [ 70/172]  eta: 0:02:42  lr: 0.000046  loss: 0.6638 (0.6802)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [ 80/172]  eta: 0:02:26  lr: 0.000046  loss: 0.6887 (0.6829)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [ 90/172]  eta: 0:02:10  lr: 0.000046  loss: 0.6967 (0.6824)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [100/172]  eta: 0:01:54  lr: 0.000046  loss: 0.6906 (0.6826)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [110/172]  eta: 0:01:38  lr: 0.000046  loss: 0.6752 (0.6819)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [120/172]  eta: 0:01:22  lr: 0.000046  loss: 0.6752 (0.6821)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [130/172]  eta: 0:01:06  lr: 0.000046  loss: 0.6768 (0.6814)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [140/172]  eta: 0:00:50  lr: 0.000046  loss: 0.6768 (0.6810)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [150/172]  eta: 0:00:34  lr: 0.000046  loss: 0.6771 (0.6811)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [160/172]  eta: 0:00:19  lr: 0.000046  loss: 0.6783 (0.6812)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [170/172]  eta: 0:00:03  lr: 0.000046  loss: 0.6783 (0.6812)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589]  [171/172]  eta: 0:00:01  lr: 0.000046  loss: 0.6783 (0.6816)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:589] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000046  loss: 0.6783 (0.6816)\n",
      "Valid: [epoch:589]  [ 0/14]  eta: 0:00:04  loss: 0.6778 (0.6778)  time: 0.3081  data: 0.2916  max mem: 20571\n",
      "Valid: [epoch:589]  [13/14]  eta: 0:00:00  loss: 0.6378 (0.6432)  time: 0.0375  data: 0.0221  max mem: 20571\n",
      "Valid: [epoch:589] Total time: 0:00:00 (0.0421 s / it)\n",
      "Averaged stats: loss: 0.6378 (0.6432)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_589_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.643%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:590]  [  0/172]  eta: 0:07:42  lr: 0.000046  loss: 0.7531 (0.7531)  time: 2.6861  data: 1.1209  max mem: 20571\n",
      "Train: [epoch:590]  [ 10/172]  eta: 0:04:31  lr: 0.000046  loss: 0.6556 (0.6762)  time: 1.6777  data: 0.1020  max mem: 20571\n",
      "Train: [epoch:590]  [ 20/172]  eta: 0:04:07  lr: 0.000046  loss: 0.6840 (0.6911)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [ 30/172]  eta: 0:03:49  lr: 0.000046  loss: 0.7029 (0.6878)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [ 40/172]  eta: 0:03:32  lr: 0.000046  loss: 0.6711 (0.6856)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [ 50/172]  eta: 0:03:15  lr: 0.000046  loss: 0.6605 (0.6810)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [ 60/172]  eta: 0:02:58  lr: 0.000046  loss: 0.6680 (0.6843)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [ 70/172]  eta: 0:02:42  lr: 0.000046  loss: 0.6866 (0.6841)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [ 80/172]  eta: 0:02:26  lr: 0.000046  loss: 0.6753 (0.6837)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [ 90/172]  eta: 0:02:10  lr: 0.000046  loss: 0.6620 (0.6842)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [100/172]  eta: 0:01:54  lr: 0.000046  loss: 0.6726 (0.6839)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [110/172]  eta: 0:01:38  lr: 0.000046  loss: 0.6818 (0.6848)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [120/172]  eta: 0:01:22  lr: 0.000046  loss: 0.6839 (0.6861)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [130/172]  eta: 0:01:06  lr: 0.000046  loss: 0.6900 (0.6861)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [140/172]  eta: 0:00:50  lr: 0.000046  loss: 0.6842 (0.6854)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [150/172]  eta: 0:00:34  lr: 0.000046  loss: 0.6729 (0.6859)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [160/172]  eta: 0:00:19  lr: 0.000046  loss: 0.6686 (0.6839)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [170/172]  eta: 0:00:03  lr: 0.000046  loss: 0.6656 (0.6844)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590]  [171/172]  eta: 0:00:01  lr: 0.000046  loss: 0.6656 (0.6847)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:590] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000046  loss: 0.6656 (0.6847)\n",
      "Valid: [epoch:590]  [ 0/14]  eta: 0:00:06  loss: 0.5977 (0.5977)  time: 0.4298  data: 0.4119  max mem: 20571\n",
      "Valid: [epoch:590]  [13/14]  eta: 0:00:00  loss: 0.6490 (0.6539)  time: 0.0456  data: 0.0304  max mem: 20571\n",
      "Valid: [epoch:590] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.6490 (0.6539)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_590_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.654%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:591]  [  0/172]  eta: 0:07:29  lr: 0.000046  loss: 0.6736 (0.6736)  time: 2.6138  data: 1.0426  max mem: 20571\n",
      "Train: [epoch:591]  [ 10/172]  eta: 0:04:31  lr: 0.000046  loss: 0.6737 (0.6859)  time: 1.6733  data: 0.0949  max mem: 20571\n",
      "Train: [epoch:591]  [ 20/172]  eta: 0:04:07  lr: 0.000046  loss: 0.6763 (0.6888)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [ 30/172]  eta: 0:03:48  lr: 0.000046  loss: 0.6939 (0.6917)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [ 40/172]  eta: 0:03:31  lr: 0.000046  loss: 0.6982 (0.6889)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [ 50/172]  eta: 0:03:15  lr: 0.000046  loss: 0.6906 (0.6903)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [ 60/172]  eta: 0:02:58  lr: 0.000046  loss: 0.6815 (0.6892)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [ 70/172]  eta: 0:02:42  lr: 0.000046  loss: 0.6747 (0.6872)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [ 80/172]  eta: 0:02:26  lr: 0.000046  loss: 0.6789 (0.6852)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [ 90/172]  eta: 0:02:10  lr: 0.000046  loss: 0.6831 (0.6850)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [100/172]  eta: 0:01:54  lr: 0.000046  loss: 0.6694 (0.6859)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [110/172]  eta: 0:01:38  lr: 0.000046  loss: 0.6831 (0.6879)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [120/172]  eta: 0:01:22  lr: 0.000046  loss: 0.6942 (0.6871)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [130/172]  eta: 0:01:06  lr: 0.000046  loss: 0.6729 (0.6864)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [140/172]  eta: 0:00:50  lr: 0.000046  loss: 0.6873 (0.6880)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [150/172]  eta: 0:00:34  lr: 0.000046  loss: 0.6919 (0.6878)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [160/172]  eta: 0:00:19  lr: 0.000046  loss: 0.6700 (0.6871)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [170/172]  eta: 0:00:03  lr: 0.000046  loss: 0.6793 (0.6873)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591]  [171/172]  eta: 0:00:01  lr: 0.000046  loss: 0.6822 (0.6874)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:591] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000046  loss: 0.6822 (0.6874)\n",
      "Valid: [epoch:591]  [ 0/14]  eta: 0:00:04  loss: 0.6815 (0.6815)  time: 0.2910  data: 0.2758  max mem: 20571\n",
      "Valid: [epoch:591]  [13/14]  eta: 0:00:00  loss: 0.6423 (0.6471)  time: 0.0396  data: 0.0247  max mem: 20571\n",
      "Valid: [epoch:591] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.6423 (0.6471)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_591_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.647%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:592]  [  0/172]  eta: 0:07:40  lr: 0.000045  loss: 0.6387 (0.6387)  time: 2.6776  data: 1.1101  max mem: 20571\n",
      "Train: [epoch:592]  [ 10/172]  eta: 0:04:31  lr: 0.000045  loss: 0.6654 (0.6700)  time: 1.6773  data: 0.1011  max mem: 20571\n",
      "Train: [epoch:592]  [ 20/172]  eta: 0:04:07  lr: 0.000045  loss: 0.6680 (0.6792)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [ 30/172]  eta: 0:03:49  lr: 0.000045  loss: 0.6786 (0.6826)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [ 40/172]  eta: 0:03:31  lr: 0.000045  loss: 0.6700 (0.6812)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [ 50/172]  eta: 0:03:15  lr: 0.000045  loss: 0.6790 (0.6825)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [ 60/172]  eta: 0:02:58  lr: 0.000045  loss: 0.6850 (0.6850)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [ 70/172]  eta: 0:02:42  lr: 0.000045  loss: 0.6768 (0.6860)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [ 80/172]  eta: 0:02:26  lr: 0.000045  loss: 0.6768 (0.6864)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [ 90/172]  eta: 0:02:10  lr: 0.000045  loss: 0.6949 (0.6878)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [100/172]  eta: 0:01:54  lr: 0.000045  loss: 0.6934 (0.6901)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [110/172]  eta: 0:01:38  lr: 0.000045  loss: 0.6901 (0.6897)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [120/172]  eta: 0:01:22  lr: 0.000045  loss: 0.6796 (0.6898)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [130/172]  eta: 0:01:06  lr: 0.000045  loss: 0.6690 (0.6885)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [140/172]  eta: 0:00:50  lr: 0.000045  loss: 0.6634 (0.6872)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [150/172]  eta: 0:00:34  lr: 0.000045  loss: 0.6713 (0.6866)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [160/172]  eta: 0:00:19  lr: 0.000045  loss: 0.6824 (0.6867)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [170/172]  eta: 0:00:03  lr: 0.000045  loss: 0.6896 (0.6871)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592]  [171/172]  eta: 0:00:01  lr: 0.000045  loss: 0.6907 (0.6873)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:592] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000045  loss: 0.6907 (0.6873)\n",
      "Valid: [epoch:592]  [ 0/14]  eta: 0:00:04  loss: 0.6735 (0.6735)  time: 0.2972  data: 0.2824  max mem: 20571\n",
      "Valid: [epoch:592]  [13/14]  eta: 0:00:00  loss: 0.6436 (0.6488)  time: 0.0414  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:592] Total time: 0:00:00 (0.0470 s / it)\n",
      "Averaged stats: loss: 0.6436 (0.6488)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_592_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.649%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:593]  [  0/172]  eta: 0:07:45  lr: 0.000045  loss: 0.6657 (0.6657)  time: 2.7062  data: 1.1331  max mem: 20571\n",
      "Train: [epoch:593]  [ 10/172]  eta: 0:04:31  lr: 0.000045  loss: 0.6902 (0.6862)  time: 1.6780  data: 0.1031  max mem: 20571\n",
      "Train: [epoch:593]  [ 20/172]  eta: 0:04:07  lr: 0.000045  loss: 0.6943 (0.6918)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [ 30/172]  eta: 0:03:49  lr: 0.000045  loss: 0.6983 (0.6971)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [ 40/172]  eta: 0:03:32  lr: 0.000045  loss: 0.6859 (0.6964)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [ 50/172]  eta: 0:03:15  lr: 0.000045  loss: 0.6899 (0.6956)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [ 60/172]  eta: 0:02:58  lr: 0.000045  loss: 0.6777 (0.6919)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [ 70/172]  eta: 0:02:42  lr: 0.000045  loss: 0.6729 (0.6906)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [ 80/172]  eta: 0:02:26  lr: 0.000045  loss: 0.6610 (0.6886)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [ 90/172]  eta: 0:02:10  lr: 0.000045  loss: 0.6600 (0.6873)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [100/172]  eta: 0:01:54  lr: 0.000045  loss: 0.6843 (0.6877)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [110/172]  eta: 0:01:38  lr: 0.000045  loss: 0.6915 (0.6876)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [120/172]  eta: 0:01:22  lr: 0.000045  loss: 0.6782 (0.6871)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [130/172]  eta: 0:01:06  lr: 0.000045  loss: 0.6691 (0.6872)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [140/172]  eta: 0:00:50  lr: 0.000045  loss: 0.6720 (0.6862)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [150/172]  eta: 0:00:34  lr: 0.000045  loss: 0.6842 (0.6867)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [160/172]  eta: 0:00:19  lr: 0.000045  loss: 0.6790 (0.6861)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593]  [170/172]  eta: 0:00:03  lr: 0.000045  loss: 0.6772 (0.6860)  time: 1.5816  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:593]  [171/172]  eta: 0:00:01  lr: 0.000045  loss: 0.6772 (0.6859)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:593] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000045  loss: 0.6772 (0.6859)\n",
      "Valid: [epoch:593]  [ 0/14]  eta: 0:00:04  loss: 0.6621 (0.6621)  time: 0.2914  data: 0.2753  max mem: 20571\n",
      "Valid: [epoch:593]  [13/14]  eta: 0:00:00  loss: 0.6714 (0.6782)  time: 0.0376  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:593] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.6714 (0.6782)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_593_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.678%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:594]  [  0/172]  eta: 0:07:57  lr: 0.000045  loss: 0.6942 (0.6942)  time: 2.7777  data: 1.1951  max mem: 20571\n",
      "Train: [epoch:594]  [ 10/172]  eta: 0:04:33  lr: 0.000045  loss: 0.6940 (0.6999)  time: 1.6880  data: 0.1087  max mem: 20571\n",
      "Train: [epoch:594]  [ 20/172]  eta: 0:04:08  lr: 0.000045  loss: 0.6940 (0.7012)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [ 30/172]  eta: 0:03:49  lr: 0.000045  loss: 0.6721 (0.6867)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [ 40/172]  eta: 0:03:32  lr: 0.000045  loss: 0.6660 (0.6838)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [ 50/172]  eta: 0:03:15  lr: 0.000045  loss: 0.6733 (0.6841)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [ 60/172]  eta: 0:02:59  lr: 0.000045  loss: 0.6839 (0.6884)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [ 70/172]  eta: 0:02:42  lr: 0.000045  loss: 0.6869 (0.6878)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [ 80/172]  eta: 0:02:26  lr: 0.000045  loss: 0.6869 (0.6884)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [ 90/172]  eta: 0:02:10  lr: 0.000045  loss: 0.6948 (0.6884)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [100/172]  eta: 0:01:54  lr: 0.000045  loss: 0.6924 (0.6894)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [110/172]  eta: 0:01:38  lr: 0.000045  loss: 0.6873 (0.6886)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [120/172]  eta: 0:01:22  lr: 0.000045  loss: 0.6873 (0.6900)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [130/172]  eta: 0:01:06  lr: 0.000045  loss: 0.6976 (0.6916)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [140/172]  eta: 0:00:50  lr: 0.000045  loss: 0.6812 (0.6902)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [150/172]  eta: 0:00:34  lr: 0.000045  loss: 0.6569 (0.6886)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [160/172]  eta: 0:00:19  lr: 0.000045  loss: 0.6542 (0.6881)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [170/172]  eta: 0:00:03  lr: 0.000045  loss: 0.6571 (0.6882)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594]  [171/172]  eta: 0:00:01  lr: 0.000045  loss: 0.6742 (0.6882)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:594] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000045  loss: 0.6742 (0.6882)\n",
      "Valid: [epoch:594]  [ 0/14]  eta: 0:00:04  loss: 0.6271 (0.6271)  time: 0.2903  data: 0.2755  max mem: 20571\n",
      "Valid: [epoch:594]  [13/14]  eta: 0:00:00  loss: 0.6419 (0.6484)  time: 0.0374  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:594] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.6419 (0.6484)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_594_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.648%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:595]  [  0/172]  eta: 0:07:41  lr: 0.000045  loss: 0.6707 (0.6707)  time: 2.6819  data: 1.1058  max mem: 20571\n",
      "Train: [epoch:595]  [ 10/172]  eta: 0:04:31  lr: 0.000045  loss: 0.6707 (0.6733)  time: 1.6764  data: 0.1006  max mem: 20571\n",
      "Train: [epoch:595]  [ 20/172]  eta: 0:04:07  lr: 0.000045  loss: 0.6889 (0.6867)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [ 30/172]  eta: 0:03:49  lr: 0.000045  loss: 0.6949 (0.6838)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [ 40/172]  eta: 0:03:31  lr: 0.000045  loss: 0.6736 (0.6808)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [ 50/172]  eta: 0:03:15  lr: 0.000045  loss: 0.6773 (0.6822)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [ 60/172]  eta: 0:02:58  lr: 0.000045  loss: 0.6876 (0.6837)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [ 70/172]  eta: 0:02:42  lr: 0.000045  loss: 0.6832 (0.6861)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [ 80/172]  eta: 0:02:26  lr: 0.000045  loss: 0.6841 (0.6867)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [ 90/172]  eta: 0:02:10  lr: 0.000045  loss: 0.6835 (0.6867)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [100/172]  eta: 0:01:54  lr: 0.000045  loss: 0.6887 (0.6881)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [110/172]  eta: 0:01:38  lr: 0.000045  loss: 0.6936 (0.6882)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [120/172]  eta: 0:01:22  lr: 0.000045  loss: 0.6799 (0.6881)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [130/172]  eta: 0:01:06  lr: 0.000045  loss: 0.6728 (0.6884)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [140/172]  eta: 0:00:50  lr: 0.000045  loss: 0.6681 (0.6881)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [150/172]  eta: 0:00:34  lr: 0.000045  loss: 0.6650 (0.6873)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [160/172]  eta: 0:00:19  lr: 0.000045  loss: 0.6827 (0.6879)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [170/172]  eta: 0:00:03  lr: 0.000045  loss: 0.6920 (0.6886)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595]  [171/172]  eta: 0:00:01  lr: 0.000045  loss: 0.6920 (0.6885)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:595] Total time: 0:04:32 (1.5858 s / it)\n",
      "Averaged stats: lr: 0.000045  loss: 0.6920 (0.6885)\n",
      "Valid: [epoch:595]  [ 0/14]  eta: 0:00:04  loss: 0.6938 (0.6938)  time: 0.3520  data: 0.3353  max mem: 20571\n",
      "Valid: [epoch:595]  [13/14]  eta: 0:00:00  loss: 0.6522 (0.6588)  time: 0.0400  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:595] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.6522 (0.6588)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_595_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.659%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:596]  [  0/172]  eta: 0:07:29  lr: 0.000045  loss: 0.6638 (0.6638)  time: 2.6162  data: 1.0490  max mem: 20571\n",
      "Train: [epoch:596]  [ 10/172]  eta: 0:04:30  lr: 0.000045  loss: 0.6671 (0.6793)  time: 1.6724  data: 0.0955  max mem: 20571\n",
      "Train: [epoch:596]  [ 20/172]  eta: 0:04:07  lr: 0.000045  loss: 0.6934 (0.6845)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [ 30/172]  eta: 0:03:49  lr: 0.000045  loss: 0.6944 (0.6852)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [ 40/172]  eta: 0:03:31  lr: 0.000045  loss: 0.6729 (0.6798)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [ 50/172]  eta: 0:03:15  lr: 0.000045  loss: 0.6641 (0.6811)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [ 60/172]  eta: 0:02:58  lr: 0.000045  loss: 0.6714 (0.6843)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [ 70/172]  eta: 0:02:42  lr: 0.000045  loss: 0.6951 (0.6839)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [ 80/172]  eta: 0:02:26  lr: 0.000045  loss: 0.6695 (0.6821)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [ 90/172]  eta: 0:02:10  lr: 0.000045  loss: 0.6695 (0.6819)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [100/172]  eta: 0:01:54  lr: 0.000045  loss: 0.6988 (0.6845)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [110/172]  eta: 0:01:38  lr: 0.000045  loss: 0.7007 (0.6859)  time: 1.5815  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:596]  [120/172]  eta: 0:01:22  lr: 0.000045  loss: 0.6961 (0.6867)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:596]  [130/172]  eta: 0:01:06  lr: 0.000045  loss: 0.6961 (0.6887)  time: 1.5783  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:596]  [140/172]  eta: 0:00:50  lr: 0.000045  loss: 0.6980 (0.6891)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [150/172]  eta: 0:00:34  lr: 0.000045  loss: 0.6886 (0.6898)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [160/172]  eta: 0:00:19  lr: 0.000045  loss: 0.6844 (0.6903)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:596]  [170/172]  eta: 0:00:03  lr: 0.000045  loss: 0.6982 (0.6905)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596]  [171/172]  eta: 0:00:01  lr: 0.000045  loss: 0.7028 (0.6910)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:596] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000045  loss: 0.7028 (0.6910)\n",
      "Valid: [epoch:596]  [ 0/14]  eta: 0:00:04  loss: 0.6762 (0.6762)  time: 0.3477  data: 0.3307  max mem: 20571\n",
      "Valid: [epoch:596]  [13/14]  eta: 0:00:00  loss: 0.6459 (0.6520)  time: 0.0389  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:596] Total time: 0:00:00 (0.0437 s / it)\n",
      "Averaged stats: loss: 0.6459 (0.6520)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_596_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.652%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:597]  [  0/172]  eta: 0:07:43  lr: 0.000045  loss: 0.6642 (0.6642)  time: 2.6967  data: 1.1231  max mem: 20571\n",
      "Train: [epoch:597]  [ 10/172]  eta: 0:04:31  lr: 0.000045  loss: 0.6992 (0.7055)  time: 1.6766  data: 0.1022  max mem: 20571\n",
      "Train: [epoch:597]  [ 20/172]  eta: 0:04:07  lr: 0.000045  loss: 0.6992 (0.7016)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [ 30/172]  eta: 0:03:49  lr: 0.000045  loss: 0.6817 (0.6957)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [ 40/172]  eta: 0:03:31  lr: 0.000045  loss: 0.6817 (0.6952)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [ 50/172]  eta: 0:03:15  lr: 0.000045  loss: 0.6894 (0.6933)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:597]  [ 60/172]  eta: 0:02:58  lr: 0.000045  loss: 0.6894 (0.6925)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [ 70/172]  eta: 0:02:42  lr: 0.000045  loss: 0.7028 (0.6953)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [ 80/172]  eta: 0:02:26  lr: 0.000045  loss: 0.7026 (0.6953)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [ 90/172]  eta: 0:02:10  lr: 0.000045  loss: 0.6831 (0.6928)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [100/172]  eta: 0:01:54  lr: 0.000045  loss: 0.6654 (0.6907)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [110/172]  eta: 0:01:38  lr: 0.000045  loss: 0.6696 (0.6907)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [120/172]  eta: 0:01:22  lr: 0.000045  loss: 0.6862 (0.6905)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [130/172]  eta: 0:01:06  lr: 0.000045  loss: 0.6748 (0.6898)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [140/172]  eta: 0:00:50  lr: 0.000045  loss: 0.6865 (0.6899)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [150/172]  eta: 0:00:34  lr: 0.000045  loss: 0.6965 (0.6895)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [160/172]  eta: 0:00:19  lr: 0.000045  loss: 0.6951 (0.6895)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [170/172]  eta: 0:00:03  lr: 0.000045  loss: 0.6951 (0.6898)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597]  [171/172]  eta: 0:00:01  lr: 0.000045  loss: 0.6926 (0.6899)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:597] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000045  loss: 0.6926 (0.6899)\n",
      "Valid: [epoch:597]  [ 0/14]  eta: 0:00:04  loss: 0.6583 (0.6583)  time: 0.3177  data: 0.3008  max mem: 20571\n",
      "Valid: [epoch:597]  [13/14]  eta: 0:00:00  loss: 0.6583 (0.6650)  time: 0.0475  data: 0.0324  max mem: 20571\n",
      "Valid: [epoch:597] Total time: 0:00:00 (0.0525 s / it)\n",
      "Averaged stats: loss: 0.6583 (0.6650)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_597_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.665%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:598]  [  0/172]  eta: 0:07:50  lr: 0.000045  loss: 0.6548 (0.6548)  time: 2.7355  data: 1.1577  max mem: 20571\n",
      "Train: [epoch:598]  [ 10/172]  eta: 0:04:32  lr: 0.000045  loss: 0.6700 (0.6833)  time: 1.6836  data: 0.1054  max mem: 20571\n",
      "Train: [epoch:598]  [ 20/172]  eta: 0:04:08  lr: 0.000045  loss: 0.6791 (0.6907)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [ 30/172]  eta: 0:03:49  lr: 0.000045  loss: 0.6791 (0.6861)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [ 40/172]  eta: 0:03:32  lr: 0.000045  loss: 0.6806 (0.6835)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [ 50/172]  eta: 0:03:15  lr: 0.000045  loss: 0.6806 (0.6856)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [ 60/172]  eta: 0:02:59  lr: 0.000045  loss: 0.6772 (0.6857)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:598]  [ 70/172]  eta: 0:02:42  lr: 0.000045  loss: 0.6840 (0.6855)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [ 80/172]  eta: 0:02:26  lr: 0.000045  loss: 0.6847 (0.6866)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [ 90/172]  eta: 0:02:10  lr: 0.000045  loss: 0.6906 (0.6875)  time: 1.5819  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:598]  [100/172]  eta: 0:01:54  lr: 0.000045  loss: 0.6885 (0.6873)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [110/172]  eta: 0:01:38  lr: 0.000045  loss: 0.6885 (0.6894)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [120/172]  eta: 0:01:22  lr: 0.000045  loss: 0.7151 (0.6928)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [130/172]  eta: 0:01:06  lr: 0.000045  loss: 0.7008 (0.6929)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [140/172]  eta: 0:00:50  lr: 0.000045  loss: 0.6871 (0.6929)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [150/172]  eta: 0:00:34  lr: 0.000045  loss: 0.6831 (0.6920)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [160/172]  eta: 0:00:19  lr: 0.000045  loss: 0.6730 (0.6918)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [170/172]  eta: 0:00:03  lr: 0.000045  loss: 0.6883 (0.6922)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598]  [171/172]  eta: 0:00:01  lr: 0.000045  loss: 0.6878 (0.6922)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:598] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000045  loss: 0.6878 (0.6922)\n",
      "Valid: [epoch:598]  [ 0/14]  eta: 0:00:05  loss: 0.6906 (0.6906)  time: 0.3881  data: 0.3706  max mem: 20571\n",
      "Valid: [epoch:598]  [13/14]  eta: 0:00:00  loss: 0.6502 (0.6558)  time: 0.0425  data: 0.0272  max mem: 20571\n",
      "Valid: [epoch:598] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.6502 (0.6558)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_598_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.656%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:599]  [  0/172]  eta: 0:07:38  lr: 0.000045  loss: 0.7069 (0.7069)  time: 2.6672  data: 1.0920  max mem: 20571\n",
      "Train: [epoch:599]  [ 10/172]  eta: 0:04:31  lr: 0.000045  loss: 0.6934 (0.6815)  time: 1.6760  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:599]  [ 20/172]  eta: 0:04:07  lr: 0.000045  loss: 0.6808 (0.6812)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [ 30/172]  eta: 0:03:49  lr: 0.000045  loss: 0.6784 (0.6856)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [ 40/172]  eta: 0:03:32  lr: 0.000045  loss: 0.6635 (0.6837)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [ 50/172]  eta: 0:03:15  lr: 0.000045  loss: 0.6599 (0.6857)  time: 1.5793  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:599]  [ 60/172]  eta: 0:02:58  lr: 0.000045  loss: 0.6966 (0.6905)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [ 70/172]  eta: 0:02:42  lr: 0.000045  loss: 0.7011 (0.6894)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [ 80/172]  eta: 0:02:26  lr: 0.000045  loss: 0.6734 (0.6896)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [ 90/172]  eta: 0:02:10  lr: 0.000045  loss: 0.6831 (0.6904)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [100/172]  eta: 0:01:54  lr: 0.000045  loss: 0.6908 (0.6901)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:599]  [110/172]  eta: 0:01:38  lr: 0.000045  loss: 0.7006 (0.6901)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:599]  [120/172]  eta: 0:01:22  lr: 0.000045  loss: 0.6947 (0.6900)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:599]  [130/172]  eta: 0:01:06  lr: 0.000045  loss: 0.6837 (0.6897)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [140/172]  eta: 0:00:50  lr: 0.000045  loss: 0.6796 (0.6901)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [150/172]  eta: 0:00:34  lr: 0.000045  loss: 0.6982 (0.6916)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [160/172]  eta: 0:00:19  lr: 0.000045  loss: 0.6943 (0.6916)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [170/172]  eta: 0:00:03  lr: 0.000045  loss: 0.6835 (0.6918)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599]  [171/172]  eta: 0:00:01  lr: 0.000045  loss: 0.6835 (0.6917)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:599] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000045  loss: 0.6835 (0.6917)\n",
      "Valid: [epoch:599]  [ 0/14]  eta: 0:00:05  loss: 0.7039 (0.7039)  time: 0.4177  data: 0.4003  max mem: 20571\n",
      "Valid: [epoch:599]  [13/14]  eta: 0:00:00  loss: 0.6612 (0.6680)  time: 0.0447  data: 0.0295  max mem: 20571\n",
      "Valid: [epoch:599] Total time: 0:00:00 (0.0498 s / it)\n",
      "Averaged stats: loss: 0.6612 (0.6680)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_599_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.668%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:600]  [  0/172]  eta: 0:07:51  lr: 0.000045  loss: 0.7232 (0.7232)  time: 2.7405  data: 1.1680  max mem: 20571\n",
      "Train: [epoch:600]  [ 10/172]  eta: 0:04:32  lr: 0.000045  loss: 0.6899 (0.6888)  time: 1.6835  data: 0.1063  max mem: 20571\n",
      "Train: [epoch:600]  [ 20/172]  eta: 0:04:08  lr: 0.000045  loss: 0.6899 (0.6922)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [ 30/172]  eta: 0:03:49  lr: 0.000045  loss: 0.6912 (0.6931)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [ 40/172]  eta: 0:03:32  lr: 0.000045  loss: 0.6792 (0.6896)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [ 50/172]  eta: 0:03:15  lr: 0.000045  loss: 0.6971 (0.6927)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [ 60/172]  eta: 0:02:59  lr: 0.000045  loss: 0.6972 (0.6910)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [ 70/172]  eta: 0:02:42  lr: 0.000045  loss: 0.6812 (0.6895)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [ 80/172]  eta: 0:02:26  lr: 0.000045  loss: 0.6859 (0.6897)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [ 90/172]  eta: 0:02:10  lr: 0.000045  loss: 0.6943 (0.6909)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [100/172]  eta: 0:01:54  lr: 0.000045  loss: 0.6943 (0.6911)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [110/172]  eta: 0:01:38  lr: 0.000045  loss: 0.6696 (0.6903)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [120/172]  eta: 0:01:22  lr: 0.000045  loss: 0.6718 (0.6916)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [130/172]  eta: 0:01:06  lr: 0.000045  loss: 0.7054 (0.6928)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [140/172]  eta: 0:00:50  lr: 0.000045  loss: 0.6985 (0.6931)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [150/172]  eta: 0:00:34  lr: 0.000045  loss: 0.6995 (0.6933)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [160/172]  eta: 0:00:19  lr: 0.000045  loss: 0.7108 (0.6946)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [170/172]  eta: 0:00:03  lr: 0.000045  loss: 0.7150 (0.6953)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600]  [171/172]  eta: 0:00:01  lr: 0.000045  loss: 0.7150 (0.6953)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:600] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000045  loss: 0.7150 (0.6953)\n",
      "Valid: [epoch:600]  [ 0/14]  eta: 0:00:04  loss: 0.7128 (0.7128)  time: 0.3246  data: 0.3094  max mem: 20571\n",
      "Valid: [epoch:600]  [13/14]  eta: 0:00:00  loss: 0.6760 (0.6816)  time: 0.0382  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:600] Total time: 0:00:00 (0.0439 s / it)\n",
      "Averaged stats: loss: 0.6760 (0.6816)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_600_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.682%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:601]  [  0/172]  eta: 0:07:36  lr: 0.000044  loss: 0.7871 (0.7871)  time: 2.6524  data: 1.0613  max mem: 20571\n",
      "Train: [epoch:601]  [ 10/172]  eta: 0:04:31  lr: 0.000044  loss: 0.7019 (0.7148)  time: 1.6741  data: 0.0966  max mem: 20571\n",
      "Train: [epoch:601]  [ 20/172]  eta: 0:04:07  lr: 0.000044  loss: 0.6983 (0.7050)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [ 30/172]  eta: 0:03:48  lr: 0.000044  loss: 0.6895 (0.6946)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [ 40/172]  eta: 0:03:31  lr: 0.000044  loss: 0.6834 (0.6933)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [ 50/172]  eta: 0:03:15  lr: 0.000044  loss: 0.6821 (0.6951)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [ 60/172]  eta: 0:02:58  lr: 0.000044  loss: 0.6790 (0.6937)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [ 70/172]  eta: 0:02:42  lr: 0.000044  loss: 0.6961 (0.6965)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [ 80/172]  eta: 0:02:26  lr: 0.000044  loss: 0.6989 (0.6957)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [ 90/172]  eta: 0:02:10  lr: 0.000044  loss: 0.6965 (0.6951)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [100/172]  eta: 0:01:54  lr: 0.000044  loss: 0.6744 (0.6947)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [110/172]  eta: 0:01:38  lr: 0.000044  loss: 0.6834 (0.6949)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [120/172]  eta: 0:01:22  lr: 0.000044  loss: 0.7050 (0.6966)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [130/172]  eta: 0:01:06  lr: 0.000044  loss: 0.6930 (0.6961)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [140/172]  eta: 0:00:50  lr: 0.000044  loss: 0.6886 (0.6964)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [150/172]  eta: 0:00:34  lr: 0.000044  loss: 0.6886 (0.6958)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [160/172]  eta: 0:00:19  lr: 0.000044  loss: 0.6864 (0.6954)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [170/172]  eta: 0:00:03  lr: 0.000044  loss: 0.6792 (0.6942)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601]  [171/172]  eta: 0:00:01  lr: 0.000044  loss: 0.6792 (0.6940)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:601] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000044  loss: 0.6792 (0.6940)\n",
      "Valid: [epoch:601]  [ 0/14]  eta: 0:00:04  loss: 0.7105 (0.7105)  time: 0.2957  data: 0.2794  max mem: 20571\n",
      "Valid: [epoch:601]  [13/14]  eta: 0:00:00  loss: 0.6501 (0.6563)  time: 0.0437  data: 0.0284  max mem: 20571\n",
      "Valid: [epoch:601] Total time: 0:00:00 (0.0518 s / it)\n",
      "Averaged stats: loss: 0.6501 (0.6563)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_601_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.656%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:602]  [  0/172]  eta: 0:07:18  lr: 0.000044  loss: 0.6875 (0.6875)  time: 2.5493  data: 0.9820  max mem: 20571\n",
      "Train: [epoch:602]  [ 10/172]  eta: 0:04:30  lr: 0.000044  loss: 0.6999 (0.7051)  time: 1.6671  data: 0.0894  max mem: 20571\n",
      "Train: [epoch:602]  [ 20/172]  eta: 0:04:07  lr: 0.000044  loss: 0.6922 (0.6971)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [ 30/172]  eta: 0:03:48  lr: 0.000044  loss: 0.6901 (0.6970)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [ 40/172]  eta: 0:03:31  lr: 0.000044  loss: 0.6758 (0.6939)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [ 50/172]  eta: 0:03:15  lr: 0.000044  loss: 0.6965 (0.6969)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [ 60/172]  eta: 0:02:58  lr: 0.000044  loss: 0.7080 (0.6979)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [ 70/172]  eta: 0:02:42  lr: 0.000044  loss: 0.6906 (0.6974)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [ 80/172]  eta: 0:02:26  lr: 0.000044  loss: 0.6906 (0.6971)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [ 90/172]  eta: 0:02:10  lr: 0.000044  loss: 0.6917 (0.6971)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [100/172]  eta: 0:01:54  lr: 0.000044  loss: 0.6970 (0.6956)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [110/172]  eta: 0:01:38  lr: 0.000044  loss: 0.6887 (0.6952)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [120/172]  eta: 0:01:22  lr: 0.000044  loss: 0.6834 (0.6942)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [130/172]  eta: 0:01:06  lr: 0.000044  loss: 0.6861 (0.6933)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [140/172]  eta: 0:00:50  lr: 0.000044  loss: 0.6861 (0.6932)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [150/172]  eta: 0:00:34  lr: 0.000044  loss: 0.6976 (0.6934)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [160/172]  eta: 0:00:19  lr: 0.000044  loss: 0.6976 (0.6946)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [170/172]  eta: 0:00:03  lr: 0.000044  loss: 0.6857 (0.6939)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602]  [171/172]  eta: 0:00:01  lr: 0.000044  loss: 0.6869 (0.6943)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:602] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000044  loss: 0.6869 (0.6943)\n",
      "Valid: [epoch:602]  [ 0/14]  eta: 0:00:07  loss: 0.6371 (0.6371)  time: 0.5188  data: 0.5024  max mem: 20571\n",
      "Valid: [epoch:602]  [13/14]  eta: 0:00:00  loss: 0.6498 (0.6564)  time: 0.0517  data: 0.0364  max mem: 20571\n",
      "Valid: [epoch:602] Total time: 0:00:00 (0.0567 s / it)\n",
      "Averaged stats: loss: 0.6498 (0.6564)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_602_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.656%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:603]  [  0/172]  eta: 0:07:54  lr: 0.000044  loss: 0.7090 (0.7090)  time: 2.7573  data: 1.1763  max mem: 20571\n",
      "Train: [epoch:603]  [ 10/172]  eta: 0:04:32  lr: 0.000044  loss: 0.6862 (0.6837)  time: 1.6824  data: 0.1071  max mem: 20571\n",
      "Train: [epoch:603]  [ 20/172]  eta: 0:04:08  lr: 0.000044  loss: 0.7082 (0.7014)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [ 30/172]  eta: 0:03:49  lr: 0.000044  loss: 0.7150 (0.7025)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [ 40/172]  eta: 0:03:32  lr: 0.000044  loss: 0.6844 (0.6968)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [ 50/172]  eta: 0:03:15  lr: 0.000044  loss: 0.6847 (0.6972)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [ 60/172]  eta: 0:02:58  lr: 0.000044  loss: 0.7006 (0.7009)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [ 70/172]  eta: 0:02:42  lr: 0.000044  loss: 0.6985 (0.7007)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [ 80/172]  eta: 0:02:26  lr: 0.000044  loss: 0.6995 (0.7019)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [ 90/172]  eta: 0:02:10  lr: 0.000044  loss: 0.6942 (0.6994)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [100/172]  eta: 0:01:54  lr: 0.000044  loss: 0.6725 (0.6987)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [110/172]  eta: 0:01:38  lr: 0.000044  loss: 0.6778 (0.6983)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [120/172]  eta: 0:01:22  lr: 0.000044  loss: 0.6890 (0.6987)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [130/172]  eta: 0:01:06  lr: 0.000044  loss: 0.6935 (0.6985)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [140/172]  eta: 0:00:50  lr: 0.000044  loss: 0.7029 (0.6991)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [150/172]  eta: 0:00:34  lr: 0.000044  loss: 0.7029 (0.6980)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:603]  [160/172]  eta: 0:00:19  lr: 0.000044  loss: 0.6713 (0.6981)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:603]  [170/172]  eta: 0:00:03  lr: 0.000044  loss: 0.6812 (0.6970)  time: 1.5827  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:603]  [171/172]  eta: 0:00:01  lr: 0.000044  loss: 0.6853 (0.6975)  time: 1.5827  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:603] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000044  loss: 0.6853 (0.6975)\n",
      "Valid: [epoch:603]  [ 0/14]  eta: 0:00:04  loss: 0.7022 (0.7022)  time: 0.3284  data: 0.3109  max mem: 20571\n",
      "Valid: [epoch:603]  [13/14]  eta: 0:00:00  loss: 0.6676 (0.6726)  time: 0.0402  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:603] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.6676 (0.6726)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_603_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.673%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:604]  [  0/172]  eta: 0:08:13  lr: 0.000044  loss: 0.7518 (0.7518)  time: 2.8710  data: 1.2914  max mem: 20571\n",
      "Train: [epoch:604]  [ 10/172]  eta: 0:04:34  lr: 0.000044  loss: 0.6812 (0.6887)  time: 1.6963  data: 0.1176  max mem: 20571\n",
      "Train: [epoch:604]  [ 20/172]  eta: 0:04:09  lr: 0.000044  loss: 0.6810 (0.6866)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:604]  [ 30/172]  eta: 0:03:50  lr: 0.000044  loss: 0.6852 (0.6921)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [ 40/172]  eta: 0:03:32  lr: 0.000044  loss: 0.6959 (0.6958)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [ 50/172]  eta: 0:03:16  lr: 0.000044  loss: 0.6987 (0.6977)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [ 60/172]  eta: 0:02:59  lr: 0.000044  loss: 0.6991 (0.6987)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [ 70/172]  eta: 0:02:43  lr: 0.000044  loss: 0.6909 (0.6977)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [ 80/172]  eta: 0:02:26  lr: 0.000044  loss: 0.6828 (0.6974)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [ 90/172]  eta: 0:02:10  lr: 0.000044  loss: 0.6761 (0.6953)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [100/172]  eta: 0:01:54  lr: 0.000044  loss: 0.6749 (0.6940)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [110/172]  eta: 0:01:38  lr: 0.000044  loss: 0.6782 (0.6924)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [120/172]  eta: 0:01:22  lr: 0.000044  loss: 0.6874 (0.6935)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [130/172]  eta: 0:01:06  lr: 0.000044  loss: 0.7155 (0.6957)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [140/172]  eta: 0:00:50  lr: 0.000044  loss: 0.7054 (0.6957)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [150/172]  eta: 0:00:34  lr: 0.000044  loss: 0.6818 (0.6952)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [160/172]  eta: 0:00:19  lr: 0.000044  loss: 0.6777 (0.6948)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604]  [170/172]  eta: 0:00:03  lr: 0.000044  loss: 0.7020 (0.6956)  time: 1.5822  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:604]  [171/172]  eta: 0:00:01  lr: 0.000044  loss: 0.7044 (0.6958)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:604] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000044  loss: 0.7044 (0.6958)\n",
      "Valid: [epoch:604]  [ 0/14]  eta: 0:00:03  loss: 0.7127 (0.7127)  time: 0.2794  data: 0.2642  max mem: 20571\n",
      "Valid: [epoch:604]  [13/14]  eta: 0:00:00  loss: 0.6561 (0.6616)  time: 0.0405  data: 0.0255  max mem: 20571\n",
      "Valid: [epoch:604] Total time: 0:00:00 (0.0453 s / it)\n",
      "Averaged stats: loss: 0.6561 (0.6616)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_604_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.662%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:605]  [  0/172]  eta: 0:07:26  lr: 0.000044  loss: 0.6650 (0.6650)  time: 2.5935  data: 1.0178  max mem: 20571\n",
      "Train: [epoch:605]  [ 10/172]  eta: 0:04:30  lr: 0.000044  loss: 0.6720 (0.6846)  time: 1.6701  data: 0.0926  max mem: 20571\n",
      "Train: [epoch:605]  [ 20/172]  eta: 0:04:07  lr: 0.000044  loss: 0.7067 (0.7070)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [ 30/172]  eta: 0:03:48  lr: 0.000044  loss: 0.7076 (0.7032)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [ 40/172]  eta: 0:03:31  lr: 0.000044  loss: 0.6830 (0.7035)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [ 50/172]  eta: 0:03:15  lr: 0.000044  loss: 0.7044 (0.7046)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [ 60/172]  eta: 0:02:58  lr: 0.000044  loss: 0.7107 (0.7057)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [ 70/172]  eta: 0:02:42  lr: 0.000044  loss: 0.7107 (0.7050)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [ 80/172]  eta: 0:02:26  lr: 0.000044  loss: 0.7034 (0.7053)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [ 90/172]  eta: 0:02:10  lr: 0.000044  loss: 0.6669 (0.7043)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [100/172]  eta: 0:01:54  lr: 0.000044  loss: 0.6835 (0.7034)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [110/172]  eta: 0:01:38  lr: 0.000044  loss: 0.6912 (0.7034)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [120/172]  eta: 0:01:22  lr: 0.000044  loss: 0.7035 (0.7043)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [130/172]  eta: 0:01:06  lr: 0.000044  loss: 0.7112 (0.7038)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [140/172]  eta: 0:00:50  lr: 0.000044  loss: 0.6916 (0.7035)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [150/172]  eta: 0:00:34  lr: 0.000044  loss: 0.6872 (0.7022)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [160/172]  eta: 0:00:19  lr: 0.000044  loss: 0.6795 (0.7010)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [170/172]  eta: 0:00:03  lr: 0.000044  loss: 0.7020 (0.7012)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605]  [171/172]  eta: 0:00:01  lr: 0.000044  loss: 0.7020 (0.7012)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:605] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000044  loss: 0.7020 (0.7012)\n",
      "Valid: [epoch:605]  [ 0/14]  eta: 0:00:03  loss: 0.7175 (0.7175)  time: 0.2776  data: 0.2628  max mem: 20571\n",
      "Valid: [epoch:605]  [13/14]  eta: 0:00:00  loss: 0.6750 (0.6818)  time: 0.0383  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:605] Total time: 0:00:00 (0.0439 s / it)\n",
      "Averaged stats: loss: 0.6750 (0.6818)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_605_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.682%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:606]  [  0/172]  eta: 0:07:43  lr: 0.000044  loss: 0.6365 (0.6365)  time: 2.6928  data: 1.1264  max mem: 20571\n",
      "Train: [epoch:606]  [ 10/172]  eta: 0:04:32  lr: 0.000044  loss: 0.6996 (0.6937)  time: 1.6792  data: 0.1025  max mem: 20571\n",
      "Train: [epoch:606]  [ 20/172]  eta: 0:04:08  lr: 0.000044  loss: 0.6996 (0.6979)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [ 30/172]  eta: 0:03:49  lr: 0.000044  loss: 0.6776 (0.6956)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [ 40/172]  eta: 0:03:32  lr: 0.000044  loss: 0.6704 (0.6904)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [ 50/172]  eta: 0:03:15  lr: 0.000044  loss: 0.6770 (0.6949)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [ 60/172]  eta: 0:02:58  lr: 0.000044  loss: 0.6800 (0.6928)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [ 70/172]  eta: 0:02:42  lr: 0.000044  loss: 0.6791 (0.6927)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [ 80/172]  eta: 0:02:26  lr: 0.000044  loss: 0.7015 (0.6950)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [ 90/172]  eta: 0:02:10  lr: 0.000044  loss: 0.7027 (0.6958)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [100/172]  eta: 0:01:54  lr: 0.000044  loss: 0.6873 (0.6950)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [110/172]  eta: 0:01:38  lr: 0.000044  loss: 0.6966 (0.6960)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [120/172]  eta: 0:01:22  lr: 0.000044  loss: 0.7004 (0.6953)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [130/172]  eta: 0:01:06  lr: 0.000044  loss: 0.7035 (0.6968)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [140/172]  eta: 0:00:50  lr: 0.000044  loss: 0.7031 (0.6964)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [150/172]  eta: 0:00:34  lr: 0.000044  loss: 0.6900 (0.6964)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [160/172]  eta: 0:00:19  lr: 0.000044  loss: 0.6900 (0.6966)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [170/172]  eta: 0:00:03  lr: 0.000044  loss: 0.6898 (0.6965)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606]  [171/172]  eta: 0:00:01  lr: 0.000044  loss: 0.6898 (0.6963)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:606] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000044  loss: 0.6898 (0.6963)\n",
      "Valid: [epoch:606]  [ 0/14]  eta: 0:00:04  loss: 0.6370 (0.6370)  time: 0.3039  data: 0.2890  max mem: 20571\n",
      "Valid: [epoch:606]  [13/14]  eta: 0:00:00  loss: 0.6521 (0.6598)  time: 0.0364  data: 0.0215  max mem: 20571\n",
      "Valid: [epoch:606] Total time: 0:00:00 (0.0410 s / it)\n",
      "Averaged stats: loss: 0.6521 (0.6598)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_606_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.660%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:607]  [  0/172]  eta: 0:07:32  lr: 0.000044  loss: 0.6900 (0.6900)  time: 2.6296  data: 1.0543  max mem: 20571\n",
      "Train: [epoch:607]  [ 10/172]  eta: 0:04:31  lr: 0.000044  loss: 0.6685 (0.6889)  time: 1.6729  data: 0.0959  max mem: 20571\n",
      "Train: [epoch:607]  [ 20/172]  eta: 0:04:07  lr: 0.000044  loss: 0.7033 (0.6971)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [ 30/172]  eta: 0:03:49  lr: 0.000044  loss: 0.6936 (0.6910)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [ 40/172]  eta: 0:03:32  lr: 0.000044  loss: 0.6782 (0.6914)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [ 50/172]  eta: 0:03:15  lr: 0.000044  loss: 0.6944 (0.6947)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [ 60/172]  eta: 0:02:59  lr: 0.000044  loss: 0.7195 (0.6981)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [ 70/172]  eta: 0:02:42  lr: 0.000044  loss: 0.7068 (0.6991)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [ 80/172]  eta: 0:02:26  lr: 0.000044  loss: 0.6836 (0.6965)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [ 90/172]  eta: 0:02:10  lr: 0.000044  loss: 0.6813 (0.6966)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [100/172]  eta: 0:01:54  lr: 0.000044  loss: 0.6834 (0.6974)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [110/172]  eta: 0:01:38  lr: 0.000044  loss: 0.6801 (0.6983)  time: 1.5823  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:607]  [120/172]  eta: 0:01:22  lr: 0.000044  loss: 0.6882 (0.6987)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [130/172]  eta: 0:01:06  lr: 0.000044  loss: 0.7000 (0.6997)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [140/172]  eta: 0:00:50  lr: 0.000044  loss: 0.7028 (0.7009)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [150/172]  eta: 0:00:34  lr: 0.000044  loss: 0.7028 (0.7021)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [160/172]  eta: 0:00:19  lr: 0.000044  loss: 0.6982 (0.7019)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [170/172]  eta: 0:00:03  lr: 0.000044  loss: 0.6982 (0.7014)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607]  [171/172]  eta: 0:00:01  lr: 0.000044  loss: 0.6906 (0.7011)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:607] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000044  loss: 0.6906 (0.7011)\n",
      "Valid: [epoch:607]  [ 0/14]  eta: 0:00:04  loss: 0.6974 (0.6974)  time: 0.3533  data: 0.3384  max mem: 20571\n",
      "Valid: [epoch:607]  [13/14]  eta: 0:00:00  loss: 0.6564 (0.6641)  time: 0.0402  data: 0.0252  max mem: 20571\n",
      "Valid: [epoch:607] Total time: 0:00:00 (0.0451 s / it)\n",
      "Averaged stats: loss: 0.6564 (0.6641)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_607_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.664%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:608]  [  0/172]  eta: 0:07:43  lr: 0.000044  loss: 0.6864 (0.6864)  time: 2.6944  data: 1.1091  max mem: 20571\n",
      "Train: [epoch:608]  [ 10/172]  eta: 0:04:32  lr: 0.000044  loss: 0.6888 (0.6996)  time: 1.6813  data: 0.1009  max mem: 20571\n",
      "Train: [epoch:608]  [ 20/172]  eta: 0:04:08  lr: 0.000044  loss: 0.6979 (0.7017)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [ 30/172]  eta: 0:03:49  lr: 0.000044  loss: 0.6993 (0.7077)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [ 40/172]  eta: 0:03:32  lr: 0.000044  loss: 0.6916 (0.7025)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [ 50/172]  eta: 0:03:15  lr: 0.000044  loss: 0.6837 (0.7017)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [ 60/172]  eta: 0:02:59  lr: 0.000044  loss: 0.6827 (0.6983)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [ 70/172]  eta: 0:02:42  lr: 0.000044  loss: 0.7041 (0.7016)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [ 80/172]  eta: 0:02:26  lr: 0.000044  loss: 0.7208 (0.7048)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [ 90/172]  eta: 0:02:10  lr: 0.000044  loss: 0.7040 (0.7019)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [100/172]  eta: 0:01:54  lr: 0.000044  loss: 0.6813 (0.7017)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [110/172]  eta: 0:01:38  lr: 0.000044  loss: 0.7023 (0.7012)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [120/172]  eta: 0:01:22  lr: 0.000044  loss: 0.7032 (0.7014)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [130/172]  eta: 0:01:06  lr: 0.000044  loss: 0.7012 (0.7009)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [140/172]  eta: 0:00:50  lr: 0.000044  loss: 0.6822 (0.6997)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [150/172]  eta: 0:00:34  lr: 0.000044  loss: 0.6813 (0.6999)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [160/172]  eta: 0:00:19  lr: 0.000044  loss: 0.7081 (0.7006)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [170/172]  eta: 0:00:03  lr: 0.000044  loss: 0.6887 (0.6998)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608]  [171/172]  eta: 0:00:01  lr: 0.000044  loss: 0.6888 (0.6998)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:608] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000044  loss: 0.6888 (0.6998)\n",
      "Valid: [epoch:608]  [ 0/14]  eta: 0:00:04  loss: 0.7017 (0.7017)  time: 0.3149  data: 0.2973  max mem: 20571\n",
      "Valid: [epoch:608]  [13/14]  eta: 0:00:00  loss: 0.6590 (0.6661)  time: 0.0370  data: 0.0218  max mem: 20571\n",
      "Valid: [epoch:608] Total time: 0:00:00 (0.0422 s / it)\n",
      "Averaged stats: loss: 0.6590 (0.6661)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_608_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.666%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:609]  [  0/172]  eta: 0:08:02  lr: 0.000044  loss: 0.7188 (0.7188)  time: 2.8081  data: 1.2219  max mem: 20571\n",
      "Train: [epoch:609]  [ 10/172]  eta: 0:04:33  lr: 0.000044  loss: 0.6777 (0.6890)  time: 1.6892  data: 0.1112  max mem: 20571\n",
      "Train: [epoch:609]  [ 20/172]  eta: 0:04:08  lr: 0.000044  loss: 0.6937 (0.6944)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [ 30/172]  eta: 0:03:49  lr: 0.000044  loss: 0.7025 (0.6956)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [ 40/172]  eta: 0:03:32  lr: 0.000044  loss: 0.6959 (0.6954)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [ 50/172]  eta: 0:03:15  lr: 0.000044  loss: 0.7071 (0.6995)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [ 60/172]  eta: 0:02:59  lr: 0.000044  loss: 0.7258 (0.7041)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [ 70/172]  eta: 0:02:42  lr: 0.000044  loss: 0.7097 (0.7040)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [ 80/172]  eta: 0:02:26  lr: 0.000044  loss: 0.7108 (0.7064)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [ 90/172]  eta: 0:02:10  lr: 0.000044  loss: 0.7152 (0.7056)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [100/172]  eta: 0:01:54  lr: 0.000044  loss: 0.6859 (0.7047)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [110/172]  eta: 0:01:38  lr: 0.000044  loss: 0.6859 (0.7041)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [120/172]  eta: 0:01:22  lr: 0.000044  loss: 0.6804 (0.7039)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [130/172]  eta: 0:01:06  lr: 0.000044  loss: 0.6921 (0.7034)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [140/172]  eta: 0:00:50  lr: 0.000044  loss: 0.7104 (0.7049)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [150/172]  eta: 0:00:34  lr: 0.000044  loss: 0.7161 (0.7057)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [160/172]  eta: 0:00:19  lr: 0.000044  loss: 0.6981 (0.7047)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [170/172]  eta: 0:00:03  lr: 0.000044  loss: 0.6941 (0.7042)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609]  [171/172]  eta: 0:00:01  lr: 0.000044  loss: 0.6940 (0.7040)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:609] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000044  loss: 0.6940 (0.7040)\n",
      "Valid: [epoch:609]  [ 0/14]  eta: 0:00:03  loss: 0.6460 (0.6460)  time: 0.2732  data: 0.2566  max mem: 20571\n",
      "Valid: [epoch:609]  [13/14]  eta: 0:00:00  loss: 0.6597 (0.6658)  time: 0.0401  data: 0.0249  max mem: 20571\n",
      "Valid: [epoch:609] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.6597 (0.6658)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_609_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.666%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:610]  [  0/172]  eta: 0:07:55  lr: 0.000043  loss: 0.6939 (0.6939)  time: 2.7659  data: 1.1982  max mem: 20571\n",
      "Train: [epoch:610]  [ 10/172]  eta: 0:04:33  lr: 0.000043  loss: 0.6984 (0.6888)  time: 1.6879  data: 0.1090  max mem: 20571\n",
      "Train: [epoch:610]  [ 20/172]  eta: 0:04:08  lr: 0.000043  loss: 0.7016 (0.6976)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [ 30/172]  eta: 0:03:49  lr: 0.000043  loss: 0.7042 (0.6988)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [ 40/172]  eta: 0:03:32  lr: 0.000043  loss: 0.6906 (0.6934)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [ 50/172]  eta: 0:03:15  lr: 0.000043  loss: 0.6878 (0.6981)  time: 1.5832  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:610]  [ 60/172]  eta: 0:02:59  lr: 0.000043  loss: 0.6997 (0.6979)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [ 70/172]  eta: 0:02:43  lr: 0.000043  loss: 0.6919 (0.6963)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [ 80/172]  eta: 0:02:26  lr: 0.000043  loss: 0.6883 (0.6958)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [ 90/172]  eta: 0:02:10  lr: 0.000043  loss: 0.7001 (0.6969)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [100/172]  eta: 0:01:54  lr: 0.000043  loss: 0.7135 (0.6987)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [110/172]  eta: 0:01:38  lr: 0.000043  loss: 0.7057 (0.6988)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [120/172]  eta: 0:01:22  lr: 0.000043  loss: 0.7079 (0.7010)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [130/172]  eta: 0:01:06  lr: 0.000043  loss: 0.7105 (0.7009)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [140/172]  eta: 0:00:50  lr: 0.000043  loss: 0.6939 (0.7009)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [150/172]  eta: 0:00:34  lr: 0.000043  loss: 0.7069 (0.7009)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [160/172]  eta: 0:00:19  lr: 0.000043  loss: 0.7107 (0.7007)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [170/172]  eta: 0:00:03  lr: 0.000043  loss: 0.7134 (0.7015)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610]  [171/172]  eta: 0:00:01  lr: 0.000043  loss: 0.6880 (0.7012)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:610] Total time: 0:04:33 (1.5896 s / it)\n",
      "Averaged stats: lr: 0.000043  loss: 0.6880 (0.7012)\n",
      "Valid: [epoch:610]  [ 0/14]  eta: 0:00:05  loss: 0.6608 (0.6608)  time: 0.3728  data: 0.3555  max mem: 20571\n",
      "Valid: [epoch:610]  [13/14]  eta: 0:00:00  loss: 0.6747 (0.6795)  time: 0.0411  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:610] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.6747 (0.6795)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_610_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.679%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:611]  [  0/172]  eta: 0:07:35  lr: 0.000043  loss: 0.7556 (0.7556)  time: 2.6460  data: 1.0720  max mem: 20571\n",
      "Train: [epoch:611]  [ 10/172]  eta: 0:04:31  lr: 0.000043  loss: 0.7133 (0.7074)  time: 1.6747  data: 0.0976  max mem: 20571\n",
      "Train: [epoch:611]  [ 20/172]  eta: 0:04:07  lr: 0.000043  loss: 0.6859 (0.7010)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [ 30/172]  eta: 0:03:49  lr: 0.000043  loss: 0.6912 (0.6999)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [ 40/172]  eta: 0:03:32  lr: 0.000043  loss: 0.6855 (0.6956)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [ 50/172]  eta: 0:03:15  lr: 0.000043  loss: 0.6815 (0.6974)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [ 60/172]  eta: 0:02:58  lr: 0.000043  loss: 0.7016 (0.7016)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [ 70/172]  eta: 0:02:42  lr: 0.000043  loss: 0.7022 (0.7018)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [ 80/172]  eta: 0:02:26  lr: 0.000043  loss: 0.6863 (0.7004)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [ 90/172]  eta: 0:02:10  lr: 0.000043  loss: 0.6863 (0.6996)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [100/172]  eta: 0:01:54  lr: 0.000043  loss: 0.7063 (0.6994)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [110/172]  eta: 0:01:38  lr: 0.000043  loss: 0.7083 (0.6993)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [120/172]  eta: 0:01:22  lr: 0.000043  loss: 0.7110 (0.7030)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [130/172]  eta: 0:01:06  lr: 0.000043  loss: 0.7015 (0.7029)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [140/172]  eta: 0:00:50  lr: 0.000043  loss: 0.6949 (0.7034)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [150/172]  eta: 0:00:34  lr: 0.000043  loss: 0.7039 (0.7046)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [160/172]  eta: 0:00:19  lr: 0.000043  loss: 0.7086 (0.7042)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [170/172]  eta: 0:00:03  lr: 0.000043  loss: 0.6830 (0.7034)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611]  [171/172]  eta: 0:00:01  lr: 0.000043  loss: 0.6830 (0.7038)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:611] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000043  loss: 0.6830 (0.7038)\n",
      "Valid: [epoch:611]  [ 0/14]  eta: 0:00:03  loss: 0.6947 (0.6947)  time: 0.2815  data: 0.2654  max mem: 20571\n",
      "Valid: [epoch:611]  [13/14]  eta: 0:00:00  loss: 0.6631 (0.6690)  time: 0.0441  data: 0.0291  max mem: 20571\n",
      "Valid: [epoch:611] Total time: 0:00:00 (0.0491 s / it)\n",
      "Averaged stats: loss: 0.6631 (0.6690)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_611_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.669%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:612]  [  0/172]  eta: 0:07:23  lr: 0.000043  loss: 0.6780 (0.6780)  time: 2.5798  data: 0.9935  max mem: 20571\n",
      "Train: [epoch:612]  [ 10/172]  eta: 0:04:30  lr: 0.000043  loss: 0.6950 (0.7009)  time: 1.6702  data: 0.0904  max mem: 20571\n",
      "Train: [epoch:612]  [ 20/172]  eta: 0:04:07  lr: 0.000043  loss: 0.6950 (0.7017)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [ 30/172]  eta: 0:03:48  lr: 0.000043  loss: 0.6949 (0.6997)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [ 40/172]  eta: 0:03:31  lr: 0.000043  loss: 0.6949 (0.7011)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [ 50/172]  eta: 0:03:15  lr: 0.000043  loss: 0.7056 (0.7035)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [ 60/172]  eta: 0:02:58  lr: 0.000043  loss: 0.7302 (0.7057)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [ 70/172]  eta: 0:02:42  lr: 0.000043  loss: 0.6977 (0.7036)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [ 80/172]  eta: 0:02:26  lr: 0.000043  loss: 0.7137 (0.7054)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [ 90/172]  eta: 0:02:10  lr: 0.000043  loss: 0.7148 (0.7051)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [100/172]  eta: 0:01:54  lr: 0.000043  loss: 0.6912 (0.7055)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [110/172]  eta: 0:01:38  lr: 0.000043  loss: 0.6961 (0.7055)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [120/172]  eta: 0:01:22  lr: 0.000043  loss: 0.7136 (0.7069)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [130/172]  eta: 0:01:06  lr: 0.000043  loss: 0.7062 (0.7063)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [140/172]  eta: 0:00:50  lr: 0.000043  loss: 0.6945 (0.7050)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [150/172]  eta: 0:00:34  lr: 0.000043  loss: 0.7013 (0.7065)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [160/172]  eta: 0:00:19  lr: 0.000043  loss: 0.7182 (0.7072)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [170/172]  eta: 0:00:03  lr: 0.000043  loss: 0.6981 (0.7055)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612]  [171/172]  eta: 0:00:01  lr: 0.000043  loss: 0.6929 (0.7054)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:612] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000043  loss: 0.6929 (0.7054)\n",
      "Valid: [epoch:612]  [ 0/14]  eta: 0:00:04  loss: 0.7103 (0.7103)  time: 0.3177  data: 0.3023  max mem: 20571\n",
      "Valid: [epoch:612]  [13/14]  eta: 0:00:00  loss: 0.6701 (0.6767)  time: 0.0384  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:612] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.6701 (0.6767)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_612_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.677%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:613]  [  0/172]  eta: 0:07:27  lr: 0.000043  loss: 0.7264 (0.7264)  time: 2.6042  data: 1.0276  max mem: 20571\n",
      "Train: [epoch:613]  [ 10/172]  eta: 0:04:30  lr: 0.000043  loss: 0.6730 (0.6820)  time: 1.6701  data: 0.0935  max mem: 20571\n",
      "Train: [epoch:613]  [ 20/172]  eta: 0:04:07  lr: 0.000043  loss: 0.6946 (0.7022)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [ 30/172]  eta: 0:03:48  lr: 0.000043  loss: 0.7004 (0.7025)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [ 40/172]  eta: 0:03:31  lr: 0.000043  loss: 0.6840 (0.6996)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [ 50/172]  eta: 0:03:15  lr: 0.000043  loss: 0.6839 (0.7006)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [ 60/172]  eta: 0:02:58  lr: 0.000043  loss: 0.6908 (0.7004)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [ 70/172]  eta: 0:02:42  lr: 0.000043  loss: 0.6956 (0.7046)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [ 80/172]  eta: 0:02:26  lr: 0.000043  loss: 0.7092 (0.7083)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [ 90/172]  eta: 0:02:10  lr: 0.000043  loss: 0.7043 (0.7077)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [100/172]  eta: 0:01:54  lr: 0.000043  loss: 0.6829 (0.7073)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [110/172]  eta: 0:01:38  lr: 0.000043  loss: 0.7023 (0.7083)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [120/172]  eta: 0:01:22  lr: 0.000043  loss: 0.7023 (0.7080)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [130/172]  eta: 0:01:06  lr: 0.000043  loss: 0.7009 (0.7084)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [140/172]  eta: 0:00:50  lr: 0.000043  loss: 0.6994 (0.7078)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [150/172]  eta: 0:00:34  lr: 0.000043  loss: 0.6904 (0.7069)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [160/172]  eta: 0:00:19  lr: 0.000043  loss: 0.6942 (0.7069)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [170/172]  eta: 0:00:03  lr: 0.000043  loss: 0.7214 (0.7069)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613]  [171/172]  eta: 0:00:01  lr: 0.000043  loss: 0.7214 (0.7070)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:613] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000043  loss: 0.7214 (0.7070)\n",
      "Valid: [epoch:613]  [ 0/14]  eta: 0:00:06  loss: 0.7218 (0.7218)  time: 0.4728  data: 0.4559  max mem: 20571\n",
      "Valid: [epoch:613]  [13/14]  eta: 0:00:00  loss: 0.6606 (0.6671)  time: 0.0488  data: 0.0337  max mem: 20571\n",
      "Valid: [epoch:613] Total time: 0:00:00 (0.0575 s / it)\n",
      "Averaged stats: loss: 0.6606 (0.6671)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_613_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.667%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:614]  [  0/172]  eta: 0:07:44  lr: 0.000043  loss: 0.6943 (0.6943)  time: 2.6995  data: 1.1317  max mem: 20571\n",
      "Train: [epoch:614]  [ 10/172]  eta: 0:04:32  lr: 0.000043  loss: 0.6916 (0.6904)  time: 1.6812  data: 0.1030  max mem: 20571\n",
      "Train: [epoch:614]  [ 20/172]  eta: 0:04:08  lr: 0.000043  loss: 0.6973 (0.7084)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [ 30/172]  eta: 0:03:49  lr: 0.000043  loss: 0.7097 (0.7053)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [ 40/172]  eta: 0:03:32  lr: 0.000043  loss: 0.6940 (0.7052)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [ 50/172]  eta: 0:03:15  lr: 0.000043  loss: 0.6938 (0.7043)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [ 60/172]  eta: 0:02:59  lr: 0.000043  loss: 0.6984 (0.7055)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [ 70/172]  eta: 0:02:42  lr: 0.000043  loss: 0.6984 (0.7044)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [ 80/172]  eta: 0:02:26  lr: 0.000043  loss: 0.6850 (0.7038)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [ 90/172]  eta: 0:02:10  lr: 0.000043  loss: 0.7080 (0.7048)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [100/172]  eta: 0:01:54  lr: 0.000043  loss: 0.7009 (0.7045)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [110/172]  eta: 0:01:38  lr: 0.000043  loss: 0.6961 (0.7034)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [120/172]  eta: 0:01:22  lr: 0.000043  loss: 0.6978 (0.7042)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [130/172]  eta: 0:01:06  lr: 0.000043  loss: 0.7090 (0.7048)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [140/172]  eta: 0:00:50  lr: 0.000043  loss: 0.7017 (0.7044)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [150/172]  eta: 0:00:34  lr: 0.000043  loss: 0.6920 (0.7040)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [160/172]  eta: 0:00:19  lr: 0.000043  loss: 0.7177 (0.7048)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [170/172]  eta: 0:00:03  lr: 0.000043  loss: 0.7091 (0.7050)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614]  [171/172]  eta: 0:00:01  lr: 0.000043  loss: 0.7079 (0.7048)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:614] Total time: 0:04:33 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000043  loss: 0.7079 (0.7048)\n",
      "Valid: [epoch:614]  [ 0/14]  eta: 0:00:04  loss: 0.7160 (0.7160)  time: 0.3036  data: 0.2875  max mem: 20571\n",
      "Valid: [epoch:614]  [13/14]  eta: 0:00:00  loss: 0.6824 (0.6906)  time: 0.0438  data: 0.0288  max mem: 20571\n",
      "Valid: [epoch:614] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 0.6824 (0.6906)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_614_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.691%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:615]  [  0/172]  eta: 0:07:55  lr: 0.000043  loss: 0.6892 (0.6892)  time: 2.7671  data: 1.1851  max mem: 20571\n",
      "Train: [epoch:615]  [ 10/172]  eta: 0:04:32  lr: 0.000043  loss: 0.7092 (0.7115)  time: 1.6851  data: 0.1078  max mem: 20571\n",
      "Train: [epoch:615]  [ 20/172]  eta: 0:04:08  lr: 0.000043  loss: 0.7092 (0.7114)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [ 30/172]  eta: 0:03:49  lr: 0.000043  loss: 0.7054 (0.7087)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [ 40/172]  eta: 0:03:32  lr: 0.000043  loss: 0.7026 (0.7080)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [ 50/172]  eta: 0:03:15  lr: 0.000043  loss: 0.7032 (0.7082)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [ 60/172]  eta: 0:02:59  lr: 0.000043  loss: 0.6951 (0.7054)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [ 70/172]  eta: 0:02:42  lr: 0.000043  loss: 0.6951 (0.7047)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [ 80/172]  eta: 0:02:26  lr: 0.000043  loss: 0.7144 (0.7055)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [ 90/172]  eta: 0:02:10  lr: 0.000043  loss: 0.7032 (0.7059)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [100/172]  eta: 0:01:54  lr: 0.000043  loss: 0.6994 (0.7062)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [110/172]  eta: 0:01:38  lr: 0.000043  loss: 0.7069 (0.7059)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [120/172]  eta: 0:01:22  lr: 0.000043  loss: 0.7069 (0.7052)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [130/172]  eta: 0:01:06  lr: 0.000043  loss: 0.7061 (0.7062)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [140/172]  eta: 0:00:50  lr: 0.000043  loss: 0.7037 (0.7069)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [150/172]  eta: 0:00:34  lr: 0.000043  loss: 0.7004 (0.7070)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [160/172]  eta: 0:00:19  lr: 0.000043  loss: 0.7004 (0.7062)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615]  [170/172]  eta: 0:00:03  lr: 0.000043  loss: 0.7079 (0.7067)  time: 1.5821  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:615]  [171/172]  eta: 0:00:01  lr: 0.000043  loss: 0.7066 (0.7065)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:615] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000043  loss: 0.7066 (0.7065)\n",
      "Valid: [epoch:615]  [ 0/14]  eta: 0:00:04  loss: 0.6446 (0.6446)  time: 0.2860  data: 0.2695  max mem: 20571\n",
      "Valid: [epoch:615]  [13/14]  eta: 0:00:00  loss: 0.6770 (0.6847)  time: 0.0391  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:615] Total time: 0:00:00 (0.0442 s / it)\n",
      "Averaged stats: loss: 0.6770 (0.6847)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_615_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.685%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:616]  [  0/172]  eta: 0:07:18  lr: 0.000043  loss: 0.7490 (0.7490)  time: 2.5472  data: 0.9617  max mem: 20571\n",
      "Train: [epoch:616]  [ 10/172]  eta: 0:04:30  lr: 0.000043  loss: 0.6889 (0.7014)  time: 1.6679  data: 0.0875  max mem: 20571\n",
      "Train: [epoch:616]  [ 20/172]  eta: 0:04:07  lr: 0.000043  loss: 0.6916 (0.7070)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [ 30/172]  eta: 0:03:48  lr: 0.000043  loss: 0.6986 (0.7046)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [ 40/172]  eta: 0:03:31  lr: 0.000043  loss: 0.6978 (0.7031)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [ 50/172]  eta: 0:03:15  lr: 0.000043  loss: 0.6986 (0.7000)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [ 60/172]  eta: 0:02:58  lr: 0.000043  loss: 0.7083 (0.7015)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [ 70/172]  eta: 0:02:42  lr: 0.000043  loss: 0.7097 (0.7020)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [ 80/172]  eta: 0:02:26  lr: 0.000043  loss: 0.7140 (0.7050)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [ 90/172]  eta: 0:02:10  lr: 0.000043  loss: 0.7328 (0.7065)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [100/172]  eta: 0:01:54  lr: 0.000043  loss: 0.7163 (0.7057)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [110/172]  eta: 0:01:38  lr: 0.000043  loss: 0.6927 (0.7043)  time: 1.5854  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:616]  [120/172]  eta: 0:01:22  lr: 0.000043  loss: 0.7058 (0.7058)  time: 1.5819  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:616]  [130/172]  eta: 0:01:06  lr: 0.000043  loss: 0.7252 (0.7067)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:616]  [140/172]  eta: 0:00:50  lr: 0.000043  loss: 0.7041 (0.7066)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [150/172]  eta: 0:00:34  lr: 0.000043  loss: 0.7024 (0.7069)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [160/172]  eta: 0:00:19  lr: 0.000043  loss: 0.6976 (0.7063)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:616]  [170/172]  eta: 0:00:03  lr: 0.000043  loss: 0.6976 (0.7062)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616]  [171/172]  eta: 0:00:01  lr: 0.000043  loss: 0.7047 (0.7064)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:616] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000043  loss: 0.7047 (0.7064)\n",
      "Valid: [epoch:616]  [ 0/14]  eta: 0:00:04  loss: 0.7108 (0.7108)  time: 0.3072  data: 0.2923  max mem: 20571\n",
      "Valid: [epoch:616]  [13/14]  eta: 0:00:00  loss: 0.6708 (0.6772)  time: 0.0434  data: 0.0284  max mem: 20571\n",
      "Valid: [epoch:616] Total time: 0:00:00 (0.0511 s / it)\n",
      "Averaged stats: loss: 0.6708 (0.6772)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_616_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.677%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:617]  [  0/172]  eta: 0:08:03  lr: 0.000043  loss: 0.7400 (0.7400)  time: 2.8084  data: 1.2282  max mem: 20571\n",
      "Train: [epoch:617]  [ 10/172]  eta: 0:04:33  lr: 0.000043  loss: 0.6961 (0.6984)  time: 1.6913  data: 0.1118  max mem: 20571\n",
      "Train: [epoch:617]  [ 20/172]  eta: 0:04:09  lr: 0.000043  loss: 0.7038 (0.7037)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:617]  [ 30/172]  eta: 0:03:49  lr: 0.000043  loss: 0.7038 (0.7000)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:617]  [ 40/172]  eta: 0:03:32  lr: 0.000043  loss: 0.7106 (0.7043)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [ 50/172]  eta: 0:03:15  lr: 0.000043  loss: 0.7106 (0.7035)  time: 1.5841  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:617]  [ 60/172]  eta: 0:02:59  lr: 0.000043  loss: 0.6896 (0.7035)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:617]  [ 70/172]  eta: 0:02:43  lr: 0.000043  loss: 0.6915 (0.7055)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [ 80/172]  eta: 0:02:26  lr: 0.000043  loss: 0.6953 (0.7052)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [ 90/172]  eta: 0:02:10  lr: 0.000043  loss: 0.7006 (0.7047)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [100/172]  eta: 0:01:54  lr: 0.000043  loss: 0.7087 (0.7070)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [110/172]  eta: 0:01:38  lr: 0.000043  loss: 0.7345 (0.7090)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [120/172]  eta: 0:01:22  lr: 0.000043  loss: 0.7218 (0.7100)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [130/172]  eta: 0:01:06  lr: 0.000043  loss: 0.7125 (0.7100)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [140/172]  eta: 0:00:50  lr: 0.000043  loss: 0.7145 (0.7106)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [150/172]  eta: 0:00:34  lr: 0.000043  loss: 0.7145 (0.7118)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [160/172]  eta: 0:00:19  lr: 0.000043  loss: 0.7112 (0.7129)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [170/172]  eta: 0:00:03  lr: 0.000043  loss: 0.7164 (0.7129)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617]  [171/172]  eta: 0:00:01  lr: 0.000043  loss: 0.7164 (0.7131)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:617] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000043  loss: 0.7164 (0.7131)\n",
      "Valid: [epoch:617]  [ 0/14]  eta: 0:00:04  loss: 0.6190 (0.6190)  time: 0.3096  data: 0.2934  max mem: 20571\n",
      "Valid: [epoch:617]  [13/14]  eta: 0:00:00  loss: 0.6832 (0.6908)  time: 0.0426  data: 0.0275  max mem: 20571\n",
      "Valid: [epoch:617] Total time: 0:00:00 (0.0507 s / it)\n",
      "Averaged stats: loss: 0.6832 (0.6908)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_617_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.691%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:618]  [  0/172]  eta: 0:08:19  lr: 0.000043  loss: 0.7086 (0.7086)  time: 2.9016  data: 1.3340  max mem: 20571\n",
      "Train: [epoch:618]  [ 10/172]  eta: 0:04:35  lr: 0.000043  loss: 0.7086 (0.7133)  time: 1.6984  data: 0.1214  max mem: 20571\n",
      "Train: [epoch:618]  [ 20/172]  eta: 0:04:09  lr: 0.000043  loss: 0.6982 (0.7150)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [ 30/172]  eta: 0:03:50  lr: 0.000043  loss: 0.6919 (0.7123)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [ 40/172]  eta: 0:03:32  lr: 0.000043  loss: 0.6893 (0.7073)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [ 50/172]  eta: 0:03:15  lr: 0.000043  loss: 0.6956 (0.7084)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [ 60/172]  eta: 0:02:59  lr: 0.000043  loss: 0.7241 (0.7121)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [ 70/172]  eta: 0:02:43  lr: 0.000043  loss: 0.7241 (0.7109)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [ 80/172]  eta: 0:02:26  lr: 0.000043  loss: 0.6952 (0.7101)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [ 90/172]  eta: 0:02:10  lr: 0.000043  loss: 0.6929 (0.7077)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [100/172]  eta: 0:01:54  lr: 0.000043  loss: 0.6927 (0.7065)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [110/172]  eta: 0:01:38  lr: 0.000043  loss: 0.6981 (0.7053)  time: 1.5805  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:618]  [120/172]  eta: 0:01:22  lr: 0.000043  loss: 0.7092 (0.7060)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [130/172]  eta: 0:01:06  lr: 0.000043  loss: 0.6983 (0.7069)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [140/172]  eta: 0:00:50  lr: 0.000043  loss: 0.7105 (0.7074)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [150/172]  eta: 0:00:34  lr: 0.000043  loss: 0.7009 (0.7063)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [160/172]  eta: 0:00:19  lr: 0.000043  loss: 0.7009 (0.7076)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [170/172]  eta: 0:00:03  lr: 0.000043  loss: 0.7239 (0.7086)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618]  [171/172]  eta: 0:00:01  lr: 0.000043  loss: 0.7267 (0.7089)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:618] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000043  loss: 0.7267 (0.7089)\n",
      "Valid: [epoch:618]  [ 0/14]  eta: 0:00:06  loss: 0.7297 (0.7297)  time: 0.4852  data: 0.4687  max mem: 20571\n",
      "Valid: [epoch:618]  [13/14]  eta: 0:00:00  loss: 0.6684 (0.6746)  time: 0.0497  data: 0.0347  max mem: 20571\n",
      "Valid: [epoch:618] Total time: 0:00:00 (0.0561 s / it)\n",
      "Averaged stats: loss: 0.6684 (0.6746)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_618_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.675%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:619]  [  0/172]  eta: 0:07:42  lr: 0.000042  loss: 0.7453 (0.7453)  time: 2.6894  data: 1.1161  max mem: 20571\n",
      "Train: [epoch:619]  [ 10/172]  eta: 0:04:31  lr: 0.000042  loss: 0.7132 (0.7167)  time: 1.6770  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:619]  [ 20/172]  eta: 0:04:07  lr: 0.000042  loss: 0.7191 (0.7272)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [ 30/172]  eta: 0:03:49  lr: 0.000042  loss: 0.7250 (0.7198)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [ 40/172]  eta: 0:03:32  lr: 0.000042  loss: 0.6831 (0.7107)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [ 50/172]  eta: 0:03:15  lr: 0.000042  loss: 0.6826 (0.7117)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [ 60/172]  eta: 0:02:58  lr: 0.000042  loss: 0.7043 (0.7126)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [ 70/172]  eta: 0:02:42  lr: 0.000042  loss: 0.7045 (0.7127)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [ 80/172]  eta: 0:02:26  lr: 0.000042  loss: 0.7151 (0.7138)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [ 90/172]  eta: 0:02:10  lr: 0.000042  loss: 0.7151 (0.7110)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [100/172]  eta: 0:01:54  lr: 0.000042  loss: 0.7008 (0.7100)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [110/172]  eta: 0:01:38  lr: 0.000042  loss: 0.6944 (0.7100)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [120/172]  eta: 0:01:22  lr: 0.000042  loss: 0.6923 (0.7100)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [130/172]  eta: 0:01:06  lr: 0.000042  loss: 0.6932 (0.7092)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [140/172]  eta: 0:00:50  lr: 0.000042  loss: 0.6890 (0.7084)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [150/172]  eta: 0:00:34  lr: 0.000042  loss: 0.6989 (0.7090)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [160/172]  eta: 0:00:19  lr: 0.000042  loss: 0.7072 (0.7082)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [170/172]  eta: 0:00:03  lr: 0.000042  loss: 0.6958 (0.7082)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619]  [171/172]  eta: 0:00:01  lr: 0.000042  loss: 0.6958 (0.7089)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:619] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000042  loss: 0.6958 (0.7089)\n",
      "Valid: [epoch:619]  [ 0/14]  eta: 0:00:04  loss: 0.7002 (0.7002)  time: 0.3111  data: 0.2949  max mem: 20571\n",
      "Valid: [epoch:619]  [13/14]  eta: 0:00:00  loss: 0.6669 (0.6726)  time: 0.0370  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:619] Total time: 0:00:00 (0.0421 s / it)\n",
      "Averaged stats: loss: 0.6669 (0.6726)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_619_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.673%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:620]  [  0/172]  eta: 0:07:41  lr: 0.000042  loss: 0.6461 (0.6461)  time: 2.6834  data: 1.1145  max mem: 20571\n",
      "Train: [epoch:620]  [ 10/172]  eta: 0:04:32  lr: 0.000042  loss: 0.6846 (0.7045)  time: 1.6829  data: 0.1014  max mem: 20571\n",
      "Train: [epoch:620]  [ 20/172]  eta: 0:04:08  lr: 0.000042  loss: 0.7144 (0.7135)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [ 30/172]  eta: 0:03:49  lr: 0.000042  loss: 0.7168 (0.7152)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [ 40/172]  eta: 0:03:32  lr: 0.000042  loss: 0.7108 (0.7160)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [ 50/172]  eta: 0:03:15  lr: 0.000042  loss: 0.7095 (0.7169)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [ 60/172]  eta: 0:02:59  lr: 0.000042  loss: 0.7084 (0.7138)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:620]  [ 70/172]  eta: 0:02:42  lr: 0.000042  loss: 0.7084 (0.7156)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:620]  [ 80/172]  eta: 0:02:26  lr: 0.000042  loss: 0.7155 (0.7151)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [ 90/172]  eta: 0:02:10  lr: 0.000042  loss: 0.6993 (0.7133)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [100/172]  eta: 0:01:54  lr: 0.000042  loss: 0.7030 (0.7130)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [110/172]  eta: 0:01:38  lr: 0.000042  loss: 0.7100 (0.7119)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [120/172]  eta: 0:01:22  lr: 0.000042  loss: 0.7027 (0.7134)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [130/172]  eta: 0:01:06  lr: 0.000042  loss: 0.6973 (0.7118)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [140/172]  eta: 0:00:50  lr: 0.000042  loss: 0.6973 (0.7113)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [150/172]  eta: 0:00:34  lr: 0.000042  loss: 0.7135 (0.7120)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [160/172]  eta: 0:00:19  lr: 0.000042  loss: 0.7084 (0.7121)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [170/172]  eta: 0:00:03  lr: 0.000042  loss: 0.7076 (0.7124)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620]  [171/172]  eta: 0:00:01  lr: 0.000042  loss: 0.7076 (0.7126)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:620] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000042  loss: 0.7076 (0.7126)\n",
      "Valid: [epoch:620]  [ 0/14]  eta: 0:00:05  loss: 0.7074 (0.7074)  time: 0.3815  data: 0.3649  max mem: 20571\n",
      "Valid: [epoch:620]  [13/14]  eta: 0:00:00  loss: 0.6642 (0.6717)  time: 0.0421  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:620] Total time: 0:00:00 (0.0470 s / it)\n",
      "Averaged stats: loss: 0.6642 (0.6717)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_620_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.672%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:621]  [  0/172]  eta: 0:08:18  lr: 0.000042  loss: 0.7817 (0.7817)  time: 2.8973  data: 1.3184  max mem: 20571\n",
      "Train: [epoch:621]  [ 10/172]  eta: 0:04:34  lr: 0.000042  loss: 0.7012 (0.7139)  time: 1.6958  data: 0.1200  max mem: 20571\n",
      "Train: [epoch:621]  [ 20/172]  eta: 0:04:09  lr: 0.000042  loss: 0.6918 (0.7107)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [ 30/172]  eta: 0:03:50  lr: 0.000042  loss: 0.7167 (0.7174)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [ 40/172]  eta: 0:03:32  lr: 0.000042  loss: 0.7210 (0.7130)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [ 50/172]  eta: 0:03:15  lr: 0.000042  loss: 0.6954 (0.7125)  time: 1.5800  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:621]  [ 60/172]  eta: 0:02:59  lr: 0.000042  loss: 0.7077 (0.7125)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [ 70/172]  eta: 0:02:42  lr: 0.000042  loss: 0.6920 (0.7102)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [ 80/172]  eta: 0:02:26  lr: 0.000042  loss: 0.6826 (0.7082)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [ 90/172]  eta: 0:02:10  lr: 0.000042  loss: 0.7127 (0.7123)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [100/172]  eta: 0:01:54  lr: 0.000042  loss: 0.7349 (0.7134)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [110/172]  eta: 0:01:38  lr: 0.000042  loss: 0.7154 (0.7144)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [120/172]  eta: 0:01:22  lr: 0.000042  loss: 0.7063 (0.7135)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [130/172]  eta: 0:01:06  lr: 0.000042  loss: 0.7006 (0.7135)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [140/172]  eta: 0:00:50  lr: 0.000042  loss: 0.7006 (0.7137)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [150/172]  eta: 0:00:34  lr: 0.000042  loss: 0.7228 (0.7147)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [160/172]  eta: 0:00:19  lr: 0.000042  loss: 0.7057 (0.7145)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [170/172]  eta: 0:00:03  lr: 0.000042  loss: 0.6957 (0.7134)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621]  [171/172]  eta: 0:00:01  lr: 0.000042  loss: 0.7005 (0.7137)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:621] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000042  loss: 0.7005 (0.7137)\n",
      "Valid: [epoch:621]  [ 0/14]  eta: 0:00:04  loss: 0.6636 (0.6636)  time: 0.2993  data: 0.2815  max mem: 20571\n",
      "Valid: [epoch:621]  [13/14]  eta: 0:00:00  loss: 0.6785 (0.6857)  time: 0.0393  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:621] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.6785 (0.6857)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_621_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.686%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:622]  [  0/172]  eta: 0:08:40  lr: 0.000042  loss: 0.7824 (0.7824)  time: 3.0283  data: 1.4625  max mem: 20571\n",
      "Train: [epoch:622]  [ 10/172]  eta: 0:04:36  lr: 0.000042  loss: 0.6893 (0.7053)  time: 1.7096  data: 0.1331  max mem: 20571\n",
      "Train: [epoch:622]  [ 20/172]  eta: 0:04:10  lr: 0.000042  loss: 0.6865 (0.7005)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [ 30/172]  eta: 0:03:50  lr: 0.000042  loss: 0.7039 (0.7076)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [ 40/172]  eta: 0:03:33  lr: 0.000042  loss: 0.7105 (0.7057)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [ 50/172]  eta: 0:03:16  lr: 0.000042  loss: 0.7125 (0.7124)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [ 60/172]  eta: 0:02:59  lr: 0.000042  loss: 0.7247 (0.7111)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [ 70/172]  eta: 0:02:43  lr: 0.000042  loss: 0.6913 (0.7081)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [ 80/172]  eta: 0:02:26  lr: 0.000042  loss: 0.6920 (0.7089)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [ 90/172]  eta: 0:02:10  lr: 0.000042  loss: 0.7143 (0.7102)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [100/172]  eta: 0:01:54  lr: 0.000042  loss: 0.7116 (0.7101)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [110/172]  eta: 0:01:38  lr: 0.000042  loss: 0.7129 (0.7107)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [120/172]  eta: 0:01:22  lr: 0.000042  loss: 0.7149 (0.7118)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [130/172]  eta: 0:01:06  lr: 0.000042  loss: 0.7233 (0.7121)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [140/172]  eta: 0:00:50  lr: 0.000042  loss: 0.7276 (0.7128)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [150/172]  eta: 0:00:34  lr: 0.000042  loss: 0.7114 (0.7124)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [160/172]  eta: 0:00:19  lr: 0.000042  loss: 0.7114 (0.7125)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [170/172]  eta: 0:00:03  lr: 0.000042  loss: 0.7195 (0.7129)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622]  [171/172]  eta: 0:00:01  lr: 0.000042  loss: 0.7195 (0.7127)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:622] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000042  loss: 0.7195 (0.7127)\n",
      "Valid: [epoch:622]  [ 0/14]  eta: 0:00:05  loss: 0.7093 (0.7093)  time: 0.3739  data: 0.3551  max mem: 20571\n",
      "Valid: [epoch:622]  [13/14]  eta: 0:00:00  loss: 0.6774 (0.6839)  time: 0.0422  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:622] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.6774 (0.6839)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_622_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.684%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:623]  [  0/172]  eta: 0:07:39  lr: 0.000042  loss: 0.7659 (0.7659)  time: 2.6707  data: 1.0905  max mem: 20571\n",
      "Train: [epoch:623]  [ 10/172]  eta: 0:04:31  lr: 0.000042  loss: 0.7093 (0.7178)  time: 1.6775  data: 0.0992  max mem: 20571\n",
      "Train: [epoch:623]  [ 20/172]  eta: 0:04:07  lr: 0.000042  loss: 0.7101 (0.7277)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [ 30/172]  eta: 0:03:49  lr: 0.000042  loss: 0.7116 (0.7236)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [ 40/172]  eta: 0:03:32  lr: 0.000042  loss: 0.7003 (0.7182)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [ 50/172]  eta: 0:03:15  lr: 0.000042  loss: 0.6976 (0.7164)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [ 60/172]  eta: 0:02:58  lr: 0.000042  loss: 0.6999 (0.7128)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [ 70/172]  eta: 0:02:42  lr: 0.000042  loss: 0.7098 (0.7142)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [ 80/172]  eta: 0:02:26  lr: 0.000042  loss: 0.7167 (0.7137)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [ 90/172]  eta: 0:02:10  lr: 0.000042  loss: 0.7167 (0.7144)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [100/172]  eta: 0:01:54  lr: 0.000042  loss: 0.7167 (0.7163)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [110/172]  eta: 0:01:38  lr: 0.000042  loss: 0.7023 (0.7145)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [120/172]  eta: 0:01:22  lr: 0.000042  loss: 0.7023 (0.7137)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [130/172]  eta: 0:01:06  lr: 0.000042  loss: 0.7120 (0.7136)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [140/172]  eta: 0:00:50  lr: 0.000042  loss: 0.7094 (0.7135)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [150/172]  eta: 0:00:34  lr: 0.000042  loss: 0.7094 (0.7131)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [160/172]  eta: 0:00:19  lr: 0.000042  loss: 0.6998 (0.7130)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [170/172]  eta: 0:00:03  lr: 0.000042  loss: 0.7103 (0.7134)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623]  [171/172]  eta: 0:00:01  lr: 0.000042  loss: 0.7116 (0.7136)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:623] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000042  loss: 0.7116 (0.7136)\n",
      "Valid: [epoch:623]  [ 0/14]  eta: 0:00:04  loss: 0.7166 (0.7166)  time: 0.3160  data: 0.2993  max mem: 20571\n",
      "Valid: [epoch:623]  [13/14]  eta: 0:00:00  loss: 0.6792 (0.6853)  time: 0.0383  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:623] Total time: 0:00:00 (0.0430 s / it)\n",
      "Averaged stats: loss: 0.6792 (0.6853)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_623_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.685%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:624]  [  0/172]  eta: 0:08:06  lr: 0.000042  loss: 0.7747 (0.7747)  time: 2.8262  data: 1.2575  max mem: 20571\n",
      "Train: [epoch:624]  [ 10/172]  eta: 0:04:34  lr: 0.000042  loss: 0.6982 (0.7214)  time: 1.6917  data: 0.1144  max mem: 20571\n",
      "Train: [epoch:624]  [ 20/172]  eta: 0:04:09  lr: 0.000042  loss: 0.6982 (0.7135)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [ 30/172]  eta: 0:03:49  lr: 0.000042  loss: 0.6944 (0.7125)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [ 40/172]  eta: 0:03:32  lr: 0.000042  loss: 0.6944 (0.7085)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [ 50/172]  eta: 0:03:15  lr: 0.000042  loss: 0.7100 (0.7135)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [ 60/172]  eta: 0:02:59  lr: 0.000042  loss: 0.7256 (0.7129)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [ 70/172]  eta: 0:02:42  lr: 0.000042  loss: 0.7256 (0.7152)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [ 80/172]  eta: 0:02:26  lr: 0.000042  loss: 0.7151 (0.7148)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [ 90/172]  eta: 0:02:10  lr: 0.000042  loss: 0.6959 (0.7142)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [100/172]  eta: 0:01:54  lr: 0.000042  loss: 0.7166 (0.7148)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [110/172]  eta: 0:01:38  lr: 0.000042  loss: 0.7134 (0.7127)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [120/172]  eta: 0:01:22  lr: 0.000042  loss: 0.7041 (0.7129)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [130/172]  eta: 0:01:06  lr: 0.000042  loss: 0.7160 (0.7146)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [140/172]  eta: 0:00:50  lr: 0.000042  loss: 0.7403 (0.7162)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [150/172]  eta: 0:00:34  lr: 0.000042  loss: 0.7371 (0.7169)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [160/172]  eta: 0:00:19  lr: 0.000042  loss: 0.7337 (0.7179)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [170/172]  eta: 0:00:03  lr: 0.000042  loss: 0.7266 (0.7181)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624]  [171/172]  eta: 0:00:01  lr: 0.000042  loss: 0.7266 (0.7177)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:624] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000042  loss: 0.7266 (0.7177)\n",
      "Valid: [epoch:624]  [ 0/14]  eta: 0:00:04  loss: 0.6881 (0.6881)  time: 0.3422  data: 0.3272  max mem: 20571\n",
      "Valid: [epoch:624]  [13/14]  eta: 0:00:00  loss: 0.6881 (0.6948)  time: 0.0392  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:624] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.6881 (0.6948)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_624_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.695%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:625]  [  0/172]  eta: 0:07:22  lr: 0.000042  loss: 0.7478 (0.7478)  time: 2.5744  data: 1.0016  max mem: 20571\n",
      "Train: [epoch:625]  [ 10/172]  eta: 0:04:29  lr: 0.000042  loss: 0.6879 (0.6979)  time: 1.6660  data: 0.0912  max mem: 20571\n",
      "Train: [epoch:625]  [ 20/172]  eta: 0:04:06  lr: 0.000042  loss: 0.7317 (0.7228)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [ 30/172]  eta: 0:03:48  lr: 0.000042  loss: 0.7317 (0.7189)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [ 40/172]  eta: 0:03:31  lr: 0.000042  loss: 0.7070 (0.7148)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [ 50/172]  eta: 0:03:14  lr: 0.000042  loss: 0.7021 (0.7143)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [ 60/172]  eta: 0:02:58  lr: 0.000042  loss: 0.7022 (0.7134)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [ 70/172]  eta: 0:02:42  lr: 0.000042  loss: 0.7136 (0.7157)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [ 80/172]  eta: 0:02:26  lr: 0.000042  loss: 0.7245 (0.7174)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [ 90/172]  eta: 0:02:10  lr: 0.000042  loss: 0.7187 (0.7179)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [100/172]  eta: 0:01:54  lr: 0.000042  loss: 0.7048 (0.7162)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [110/172]  eta: 0:01:38  lr: 0.000042  loss: 0.7124 (0.7164)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [120/172]  eta: 0:01:22  lr: 0.000042  loss: 0.7218 (0.7170)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [130/172]  eta: 0:01:06  lr: 0.000042  loss: 0.7141 (0.7170)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [140/172]  eta: 0:00:50  lr: 0.000042  loss: 0.6993 (0.7164)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [150/172]  eta: 0:00:34  lr: 0.000042  loss: 0.7138 (0.7166)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [160/172]  eta: 0:00:19  lr: 0.000042  loss: 0.7138 (0.7158)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [170/172]  eta: 0:00:03  lr: 0.000042  loss: 0.7064 (0.7155)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625]  [171/172]  eta: 0:00:01  lr: 0.000042  loss: 0.7085 (0.7155)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:625] Total time: 0:04:32 (1.5854 s / it)\n",
      "Averaged stats: lr: 0.000042  loss: 0.7085 (0.7155)\n",
      "Valid: [epoch:625]  [ 0/14]  eta: 0:00:03  loss: 0.7203 (0.7203)  time: 0.2844  data: 0.2683  max mem: 20571\n",
      "Valid: [epoch:625]  [13/14]  eta: 0:00:00  loss: 0.6860 (0.6931)  time: 0.0380  data: 0.0228  max mem: 20571\n",
      "Valid: [epoch:625] Total time: 0:00:00 (0.0427 s / it)\n",
      "Averaged stats: loss: 0.6860 (0.6931)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_625_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.693%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:626]  [  0/172]  eta: 0:07:44  lr: 0.000042  loss: 0.7124 (0.7124)  time: 2.6993  data: 1.1356  max mem: 20571\n",
      "Train: [epoch:626]  [ 10/172]  eta: 0:04:32  lr: 0.000042  loss: 0.7015 (0.7101)  time: 1.6791  data: 0.1033  max mem: 20571\n",
      "Train: [epoch:626]  [ 20/172]  eta: 0:04:07  lr: 0.000042  loss: 0.7014 (0.7107)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [ 30/172]  eta: 0:03:49  lr: 0.000042  loss: 0.7103 (0.7146)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [ 40/172]  eta: 0:03:31  lr: 0.000042  loss: 0.7236 (0.7147)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [ 50/172]  eta: 0:03:15  lr: 0.000042  loss: 0.7187 (0.7162)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [ 60/172]  eta: 0:02:58  lr: 0.000042  loss: 0.7187 (0.7141)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [ 70/172]  eta: 0:02:42  lr: 0.000042  loss: 0.7219 (0.7158)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [ 80/172]  eta: 0:02:26  lr: 0.000042  loss: 0.7156 (0.7161)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [ 90/172]  eta: 0:02:10  lr: 0.000042  loss: 0.7150 (0.7173)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [100/172]  eta: 0:01:54  lr: 0.000042  loss: 0.7047 (0.7159)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [110/172]  eta: 0:01:38  lr: 0.000042  loss: 0.7047 (0.7167)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [120/172]  eta: 0:01:22  lr: 0.000042  loss: 0.7157 (0.7172)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [130/172]  eta: 0:01:06  lr: 0.000042  loss: 0.7144 (0.7170)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [140/172]  eta: 0:00:50  lr: 0.000042  loss: 0.7228 (0.7176)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [150/172]  eta: 0:00:34  lr: 0.000042  loss: 0.7106 (0.7160)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [160/172]  eta: 0:00:19  lr: 0.000042  loss: 0.6907 (0.7164)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626]  [170/172]  eta: 0:00:03  lr: 0.000042  loss: 0.7184 (0.7162)  time: 1.5800  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:626]  [171/172]  eta: 0:00:01  lr: 0.000042  loss: 0.7184 (0.7162)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:626] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000042  loss: 0.7184 (0.7162)\n",
      "Valid: [epoch:626]  [ 0/14]  eta: 0:00:04  loss: 0.7403 (0.7403)  time: 0.2883  data: 0.2722  max mem: 20571\n",
      "Valid: [epoch:626]  [13/14]  eta: 0:00:00  loss: 0.6993 (0.7051)  time: 0.0400  data: 0.0249  max mem: 20571\n",
      "Valid: [epoch:626] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.6993 (0.7051)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_626_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.705%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:627]  [  0/172]  eta: 0:08:10  lr: 0.000042  loss: 0.6975 (0.6975)  time: 2.8489  data: 1.2736  max mem: 20571\n",
      "Train: [epoch:627]  [ 10/172]  eta: 0:04:33  lr: 0.000042  loss: 0.7069 (0.7226)  time: 1.6912  data: 0.1159  max mem: 20571\n",
      "Train: [epoch:627]  [ 20/172]  eta: 0:04:08  lr: 0.000042  loss: 0.7163 (0.7264)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [ 30/172]  eta: 0:03:49  lr: 0.000042  loss: 0.7163 (0.7295)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [ 40/172]  eta: 0:03:32  lr: 0.000042  loss: 0.7187 (0.7275)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [ 50/172]  eta: 0:03:15  lr: 0.000042  loss: 0.7187 (0.7273)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [ 60/172]  eta: 0:02:59  lr: 0.000042  loss: 0.7164 (0.7260)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [ 70/172]  eta: 0:02:42  lr: 0.000042  loss: 0.7164 (0.7248)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [ 80/172]  eta: 0:02:26  lr: 0.000042  loss: 0.7154 (0.7226)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [ 90/172]  eta: 0:02:10  lr: 0.000042  loss: 0.7116 (0.7211)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [100/172]  eta: 0:01:54  lr: 0.000042  loss: 0.7132 (0.7220)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [110/172]  eta: 0:01:38  lr: 0.000042  loss: 0.7135 (0.7212)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [120/172]  eta: 0:01:22  lr: 0.000042  loss: 0.7164 (0.7215)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [130/172]  eta: 0:01:06  lr: 0.000042  loss: 0.7230 (0.7214)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [140/172]  eta: 0:00:50  lr: 0.000042  loss: 0.7187 (0.7213)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [150/172]  eta: 0:00:34  lr: 0.000042  loss: 0.7085 (0.7211)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [160/172]  eta: 0:00:19  lr: 0.000042  loss: 0.6990 (0.7197)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [170/172]  eta: 0:00:03  lr: 0.000042  loss: 0.6960 (0.7188)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627]  [171/172]  eta: 0:00:01  lr: 0.000042  loss: 0.6960 (0.7191)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:627] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000042  loss: 0.6960 (0.7191)\n",
      "Valid: [epoch:627]  [ 0/14]  eta: 0:00:05  loss: 0.6033 (0.6033)  time: 0.3821  data: 0.3641  max mem: 20571\n",
      "Valid: [epoch:627]  [13/14]  eta: 0:00:00  loss: 0.6729 (0.6793)  time: 0.0430  data: 0.0279  max mem: 20571\n",
      "Valid: [epoch:627] Total time: 0:00:00 (0.0509 s / it)\n",
      "Averaged stats: loss: 0.6729 (0.6793)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_627_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.679%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:628]  [  0/172]  eta: 0:07:42  lr: 0.000041  loss: 0.6843 (0.6843)  time: 2.6902  data: 1.1110  max mem: 20571\n",
      "Train: [epoch:628]  [ 10/172]  eta: 0:04:32  lr: 0.000041  loss: 0.6868 (0.6961)  time: 1.6796  data: 0.1012  max mem: 20571\n",
      "Train: [epoch:628]  [ 20/172]  eta: 0:04:08  lr: 0.000041  loss: 0.7003 (0.7082)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:628]  [ 30/172]  eta: 0:03:49  lr: 0.000041  loss: 0.7155 (0.7110)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [ 40/172]  eta: 0:03:32  lr: 0.000041  loss: 0.7238 (0.7144)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [ 50/172]  eta: 0:03:15  lr: 0.000041  loss: 0.7238 (0.7176)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [ 60/172]  eta: 0:02:58  lr: 0.000041  loss: 0.7160 (0.7212)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [ 70/172]  eta: 0:02:42  lr: 0.000041  loss: 0.7045 (0.7192)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [ 80/172]  eta: 0:02:26  lr: 0.000041  loss: 0.7000 (0.7171)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [ 90/172]  eta: 0:02:10  lr: 0.000041  loss: 0.7000 (0.7161)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [100/172]  eta: 0:01:54  lr: 0.000041  loss: 0.7061 (0.7163)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [110/172]  eta: 0:01:38  lr: 0.000041  loss: 0.7015 (0.7160)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [120/172]  eta: 0:01:22  lr: 0.000041  loss: 0.7081 (0.7154)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [130/172]  eta: 0:01:06  lr: 0.000041  loss: 0.7087 (0.7154)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [140/172]  eta: 0:00:50  lr: 0.000041  loss: 0.7117 (0.7149)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [150/172]  eta: 0:00:34  lr: 0.000041  loss: 0.7184 (0.7153)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [160/172]  eta: 0:00:19  lr: 0.000041  loss: 0.7357 (0.7167)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [170/172]  eta: 0:00:03  lr: 0.000041  loss: 0.7221 (0.7167)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628]  [171/172]  eta: 0:00:01  lr: 0.000041  loss: 0.7179 (0.7164)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:628] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000041  loss: 0.7179 (0.7164)\n",
      "Valid: [epoch:628]  [ 0/14]  eta: 0:00:04  loss: 0.6796 (0.6796)  time: 0.3003  data: 0.2836  max mem: 20571\n",
      "Valid: [epoch:628]  [13/14]  eta: 0:00:00  loss: 0.6839 (0.6912)  time: 0.0375  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:628] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.6839 (0.6912)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_628_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.691%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:629]  [  0/172]  eta: 0:07:50  lr: 0.000041  loss: 0.7832 (0.7832)  time: 2.7381  data: 1.1602  max mem: 20571\n",
      "Train: [epoch:629]  [ 10/172]  eta: 0:04:32  lr: 0.000041  loss: 0.7107 (0.7250)  time: 1.6805  data: 0.1056  max mem: 20571\n",
      "Train: [epoch:629]  [ 20/172]  eta: 0:04:08  lr: 0.000041  loss: 0.7056 (0.7193)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [ 30/172]  eta: 0:03:49  lr: 0.000041  loss: 0.7046 (0.7167)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [ 40/172]  eta: 0:03:32  lr: 0.000041  loss: 0.7211 (0.7177)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [ 50/172]  eta: 0:03:15  lr: 0.000041  loss: 0.7056 (0.7158)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [ 60/172]  eta: 0:02:58  lr: 0.000041  loss: 0.7087 (0.7143)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [ 70/172]  eta: 0:02:42  lr: 0.000041  loss: 0.7124 (0.7133)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [ 80/172]  eta: 0:02:26  lr: 0.000041  loss: 0.7174 (0.7152)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [ 90/172]  eta: 0:02:10  lr: 0.000041  loss: 0.7301 (0.7151)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [100/172]  eta: 0:01:54  lr: 0.000041  loss: 0.7219 (0.7159)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [110/172]  eta: 0:01:38  lr: 0.000041  loss: 0.7341 (0.7192)  time: 1.5820  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:629]  [120/172]  eta: 0:01:22  lr: 0.000041  loss: 0.7380 (0.7201)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:629]  [130/172]  eta: 0:01:06  lr: 0.000041  loss: 0.7421 (0.7227)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [140/172]  eta: 0:00:50  lr: 0.000041  loss: 0.7214 (0.7212)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [150/172]  eta: 0:00:34  lr: 0.000041  loss: 0.7099 (0.7211)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [160/172]  eta: 0:00:19  lr: 0.000041  loss: 0.7333 (0.7224)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [170/172]  eta: 0:00:03  lr: 0.000041  loss: 0.7218 (0.7222)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629]  [171/172]  eta: 0:00:01  lr: 0.000041  loss: 0.7217 (0.7217)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:629] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000041  loss: 0.7217 (0.7217)\n",
      "Valid: [epoch:629]  [ 0/14]  eta: 0:00:04  loss: 0.6131 (0.6131)  time: 0.3107  data: 0.2959  max mem: 20571\n",
      "Valid: [epoch:629]  [13/14]  eta: 0:00:00  loss: 0.6803 (0.6875)  time: 0.0437  data: 0.0286  max mem: 20571\n",
      "Valid: [epoch:629] Total time: 0:00:00 (0.0513 s / it)\n",
      "Averaged stats: loss: 0.6803 (0.6875)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_629_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.688%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:630]  [  0/172]  eta: 0:07:33  lr: 0.000041  loss: 0.7799 (0.7799)  time: 2.6350  data: 1.0700  max mem: 20571\n",
      "Train: [epoch:630]  [ 10/172]  eta: 0:04:31  lr: 0.000041  loss: 0.7083 (0.7122)  time: 1.6736  data: 0.0974  max mem: 20571\n",
      "Train: [epoch:630]  [ 20/172]  eta: 0:04:07  lr: 0.000041  loss: 0.7073 (0.7166)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [ 30/172]  eta: 0:03:48  lr: 0.000041  loss: 0.7013 (0.7143)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [ 40/172]  eta: 0:03:31  lr: 0.000041  loss: 0.7013 (0.7145)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [ 50/172]  eta: 0:03:15  lr: 0.000041  loss: 0.7079 (0.7148)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [ 60/172]  eta: 0:02:58  lr: 0.000041  loss: 0.7079 (0.7156)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [ 70/172]  eta: 0:02:42  lr: 0.000041  loss: 0.7020 (0.7146)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [ 80/172]  eta: 0:02:26  lr: 0.000041  loss: 0.7358 (0.7181)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [ 90/172]  eta: 0:02:10  lr: 0.000041  loss: 0.7362 (0.7193)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [100/172]  eta: 0:01:54  lr: 0.000041  loss: 0.7183 (0.7192)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [110/172]  eta: 0:01:38  lr: 0.000041  loss: 0.7057 (0.7172)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [120/172]  eta: 0:01:22  lr: 0.000041  loss: 0.7057 (0.7167)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [130/172]  eta: 0:01:06  lr: 0.000041  loss: 0.7080 (0.7182)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [140/172]  eta: 0:00:50  lr: 0.000041  loss: 0.7221 (0.7191)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [150/172]  eta: 0:00:34  lr: 0.000041  loss: 0.7282 (0.7191)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [160/172]  eta: 0:00:19  lr: 0.000041  loss: 0.7164 (0.7189)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [170/172]  eta: 0:00:03  lr: 0.000041  loss: 0.7164 (0.7197)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630]  [171/172]  eta: 0:00:01  lr: 0.000041  loss: 0.7178 (0.7202)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:630] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000041  loss: 0.7178 (0.7202)\n",
      "Valid: [epoch:630]  [ 0/14]  eta: 0:00:03  loss: 0.6074 (0.6074)  time: 0.2789  data: 0.2625  max mem: 20571\n",
      "Valid: [epoch:630]  [13/14]  eta: 0:00:00  loss: 0.6769 (0.6837)  time: 0.0463  data: 0.0310  max mem: 20571\n",
      "Valid: [epoch:630] Total time: 0:00:00 (0.0518 s / it)\n",
      "Averaged stats: loss: 0.6769 (0.6837)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_630_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.684%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:631]  [  0/172]  eta: 0:07:43  lr: 0.000041  loss: 0.7109 (0.7109)  time: 2.6932  data: 1.1168  max mem: 20571\n",
      "Train: [epoch:631]  [ 10/172]  eta: 0:04:31  lr: 0.000041  loss: 0.7109 (0.7122)  time: 1.6785  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:631]  [ 20/172]  eta: 0:04:07  lr: 0.000041  loss: 0.7143 (0.7343)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [ 30/172]  eta: 0:03:49  lr: 0.000041  loss: 0.7255 (0.7262)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [ 40/172]  eta: 0:03:31  lr: 0.000041  loss: 0.7076 (0.7238)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [ 50/172]  eta: 0:03:15  lr: 0.000041  loss: 0.7213 (0.7228)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [ 60/172]  eta: 0:02:58  lr: 0.000041  loss: 0.7220 (0.7217)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [ 70/172]  eta: 0:02:42  lr: 0.000041  loss: 0.7181 (0.7231)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [ 80/172]  eta: 0:02:26  lr: 0.000041  loss: 0.7066 (0.7223)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [ 90/172]  eta: 0:02:10  lr: 0.000041  loss: 0.7023 (0.7194)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [100/172]  eta: 0:01:54  lr: 0.000041  loss: 0.7162 (0.7209)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [110/172]  eta: 0:01:38  lr: 0.000041  loss: 0.7326 (0.7221)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [120/172]  eta: 0:01:22  lr: 0.000041  loss: 0.7226 (0.7224)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [130/172]  eta: 0:01:06  lr: 0.000041  loss: 0.7081 (0.7213)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [140/172]  eta: 0:00:50  lr: 0.000041  loss: 0.7149 (0.7218)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [150/172]  eta: 0:00:34  lr: 0.000041  loss: 0.7181 (0.7212)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [160/172]  eta: 0:00:19  lr: 0.000041  loss: 0.6978 (0.7202)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [170/172]  eta: 0:00:03  lr: 0.000041  loss: 0.7141 (0.7210)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631]  [171/172]  eta: 0:00:01  lr: 0.000041  loss: 0.7181 (0.7212)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:631] Total time: 0:04:32 (1.5864 s / it)\n",
      "Averaged stats: lr: 0.000041  loss: 0.7181 (0.7212)\n",
      "Valid: [epoch:631]  [ 0/14]  eta: 0:00:03  loss: 0.6765 (0.6765)  time: 0.2800  data: 0.2638  max mem: 20571\n",
      "Valid: [epoch:631]  [13/14]  eta: 0:00:00  loss: 0.6765 (0.6840)  time: 0.0363  data: 0.0211  max mem: 20571\n",
      "Valid: [epoch:631] Total time: 0:00:00 (0.0409 s / it)\n",
      "Averaged stats: loss: 0.6765 (0.6840)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_631_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.684%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:632]  [  0/172]  eta: 0:07:46  lr: 0.000041  loss: 0.7788 (0.7788)  time: 2.7094  data: 1.1432  max mem: 20571\n",
      "Train: [epoch:632]  [ 10/172]  eta: 0:04:32  lr: 0.000041  loss: 0.7239 (0.7174)  time: 1.6818  data: 0.1040  max mem: 20571\n",
      "Train: [epoch:632]  [ 20/172]  eta: 0:04:08  lr: 0.000041  loss: 0.7175 (0.7236)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [ 30/172]  eta: 0:03:49  lr: 0.000041  loss: 0.7142 (0.7190)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [ 40/172]  eta: 0:03:32  lr: 0.000041  loss: 0.7140 (0.7210)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [ 50/172]  eta: 0:03:15  lr: 0.000041  loss: 0.7190 (0.7237)  time: 1.5809  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:632]  [ 60/172]  eta: 0:02:59  lr: 0.000041  loss: 0.7190 (0.7225)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [ 70/172]  eta: 0:02:42  lr: 0.000041  loss: 0.7182 (0.7233)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [ 80/172]  eta: 0:02:26  lr: 0.000041  loss: 0.7140 (0.7227)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [ 90/172]  eta: 0:02:10  lr: 0.000041  loss: 0.7115 (0.7213)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [100/172]  eta: 0:01:54  lr: 0.000041  loss: 0.7165 (0.7226)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [110/172]  eta: 0:01:38  lr: 0.000041  loss: 0.7331 (0.7239)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [120/172]  eta: 0:01:22  lr: 0.000041  loss: 0.7279 (0.7234)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [130/172]  eta: 0:01:06  lr: 0.000041  loss: 0.7222 (0.7239)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [140/172]  eta: 0:00:50  lr: 0.000041  loss: 0.7261 (0.7245)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [150/172]  eta: 0:00:34  lr: 0.000041  loss: 0.6962 (0.7237)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [160/172]  eta: 0:00:19  lr: 0.000041  loss: 0.7018 (0.7237)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [170/172]  eta: 0:00:03  lr: 0.000041  loss: 0.7247 (0.7227)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632]  [171/172]  eta: 0:00:01  lr: 0.000041  loss: 0.7247 (0.7228)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:632] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000041  loss: 0.7247 (0.7228)\n",
      "Valid: [epoch:632]  [ 0/14]  eta: 0:00:04  loss: 0.6703 (0.6703)  time: 0.3236  data: 0.3071  max mem: 20571\n",
      "Valid: [epoch:632]  [13/14]  eta: 0:00:00  loss: 0.6848 (0.6908)  time: 0.0383  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:632] Total time: 0:00:00 (0.0467 s / it)\n",
      "Averaged stats: loss: 0.6848 (0.6908)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_632_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.691%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:633]  [  0/172]  eta: 0:07:41  lr: 0.000041  loss: 0.6760 (0.6760)  time: 2.6823  data: 1.0963  max mem: 20571\n",
      "Train: [epoch:633]  [ 10/172]  eta: 0:04:31  lr: 0.000041  loss: 0.6986 (0.6976)  time: 1.6766  data: 0.0998  max mem: 20571\n",
      "Train: [epoch:633]  [ 20/172]  eta: 0:04:07  lr: 0.000041  loss: 0.7053 (0.7169)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [ 30/172]  eta: 0:03:49  lr: 0.000041  loss: 0.7082 (0.7155)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:633]  [ 40/172]  eta: 0:03:32  lr: 0.000041  loss: 0.7033 (0.7124)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [ 50/172]  eta: 0:03:15  lr: 0.000041  loss: 0.7146 (0.7140)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [ 60/172]  eta: 0:02:58  lr: 0.000041  loss: 0.7198 (0.7166)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [ 70/172]  eta: 0:02:42  lr: 0.000041  loss: 0.7244 (0.7181)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [ 80/172]  eta: 0:02:26  lr: 0.000041  loss: 0.7255 (0.7185)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [ 90/172]  eta: 0:02:10  lr: 0.000041  loss: 0.7048 (0.7196)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [100/172]  eta: 0:01:54  lr: 0.000041  loss: 0.7301 (0.7215)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:633]  [110/172]  eta: 0:01:38  lr: 0.000041  loss: 0.7330 (0.7218)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [120/172]  eta: 0:01:22  lr: 0.000041  loss: 0.7236 (0.7221)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [130/172]  eta: 0:01:06  lr: 0.000041  loss: 0.7117 (0.7212)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [140/172]  eta: 0:00:50  lr: 0.000041  loss: 0.7117 (0.7211)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [150/172]  eta: 0:00:34  lr: 0.000041  loss: 0.7105 (0.7217)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [160/172]  eta: 0:00:19  lr: 0.000041  loss: 0.7082 (0.7211)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [170/172]  eta: 0:00:03  lr: 0.000041  loss: 0.7167 (0.7222)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633]  [171/172]  eta: 0:00:01  lr: 0.000041  loss: 0.7167 (0.7221)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:633] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000041  loss: 0.7167 (0.7221)\n",
      "Valid: [epoch:633]  [ 0/14]  eta: 0:00:03  loss: 0.7280 (0.7280)  time: 0.2797  data: 0.2637  max mem: 20571\n",
      "Valid: [epoch:633]  [13/14]  eta: 0:00:00  loss: 0.6855 (0.6922)  time: 0.0448  data: 0.0298  max mem: 20571\n",
      "Valid: [epoch:633] Total time: 0:00:00 (0.0501 s / it)\n",
      "Averaged stats: loss: 0.6855 (0.6922)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_633_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.692%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:634]  [  0/172]  eta: 0:07:40  lr: 0.000041  loss: 0.6639 (0.6639)  time: 2.6767  data: 1.1095  max mem: 20571\n",
      "Train: [epoch:634]  [ 10/172]  eta: 0:04:31  lr: 0.000041  loss: 0.7062 (0.7220)  time: 1.6790  data: 0.1010  max mem: 20571\n",
      "Train: [epoch:634]  [ 20/172]  eta: 0:04:08  lr: 0.000041  loss: 0.7166 (0.7216)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [ 30/172]  eta: 0:03:49  lr: 0.000041  loss: 0.7359 (0.7269)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [ 40/172]  eta: 0:03:32  lr: 0.000041  loss: 0.7366 (0.7262)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [ 50/172]  eta: 0:03:15  lr: 0.000041  loss: 0.7173 (0.7272)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [ 60/172]  eta: 0:02:58  lr: 0.000041  loss: 0.7231 (0.7269)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [ 70/172]  eta: 0:02:42  lr: 0.000041  loss: 0.7231 (0.7279)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [ 80/172]  eta: 0:02:26  lr: 0.000041  loss: 0.7187 (0.7277)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [ 90/172]  eta: 0:02:10  lr: 0.000041  loss: 0.7160 (0.7269)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [100/172]  eta: 0:01:54  lr: 0.000041  loss: 0.7194 (0.7270)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [110/172]  eta: 0:01:38  lr: 0.000041  loss: 0.7194 (0.7255)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [120/172]  eta: 0:01:22  lr: 0.000041  loss: 0.7192 (0.7252)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [130/172]  eta: 0:01:06  lr: 0.000041  loss: 0.7252 (0.7247)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [140/172]  eta: 0:00:50  lr: 0.000041  loss: 0.7212 (0.7241)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [150/172]  eta: 0:00:34  lr: 0.000041  loss: 0.7257 (0.7250)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [160/172]  eta: 0:00:19  lr: 0.000041  loss: 0.7257 (0.7241)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [170/172]  eta: 0:00:03  lr: 0.000041  loss: 0.7215 (0.7243)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634]  [171/172]  eta: 0:00:01  lr: 0.000041  loss: 0.7215 (0.7248)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:634] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000041  loss: 0.7215 (0.7248)\n",
      "Valid: [epoch:634]  [ 0/14]  eta: 0:00:04  loss: 0.7185 (0.7185)  time: 0.3220  data: 0.3016  max mem: 20571\n",
      "Valid: [epoch:634]  [13/14]  eta: 0:00:00  loss: 0.6836 (0.6900)  time: 0.0385  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:634] Total time: 0:00:00 (0.0433 s / it)\n",
      "Averaged stats: loss: 0.6836 (0.6900)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_634_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.690%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:635]  [  0/172]  eta: 0:07:27  lr: 0.000041  loss: 0.7876 (0.7876)  time: 2.5995  data: 1.0243  max mem: 20571\n",
      "Train: [epoch:635]  [ 10/172]  eta: 0:04:30  lr: 0.000041  loss: 0.7130 (0.7167)  time: 1.6699  data: 0.0933  max mem: 20571\n",
      "Train: [epoch:635]  [ 20/172]  eta: 0:04:07  lr: 0.000041  loss: 0.7047 (0.7133)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:635]  [ 30/172]  eta: 0:03:48  lr: 0.000041  loss: 0.7152 (0.7240)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [ 40/172]  eta: 0:03:31  lr: 0.000041  loss: 0.7173 (0.7215)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [ 50/172]  eta: 0:03:15  lr: 0.000041  loss: 0.7340 (0.7312)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [ 60/172]  eta: 0:02:58  lr: 0.000041  loss: 0.7494 (0.7323)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [ 70/172]  eta: 0:02:42  lr: 0.000041  loss: 0.7297 (0.7303)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [ 80/172]  eta: 0:02:26  lr: 0.000041  loss: 0.7113 (0.7272)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [ 90/172]  eta: 0:02:10  lr: 0.000041  loss: 0.6997 (0.7254)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [100/172]  eta: 0:01:54  lr: 0.000041  loss: 0.7207 (0.7256)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [110/172]  eta: 0:01:38  lr: 0.000041  loss: 0.7207 (0.7248)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [120/172]  eta: 0:01:22  lr: 0.000041  loss: 0.7065 (0.7247)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [130/172]  eta: 0:01:06  lr: 0.000041  loss: 0.7129 (0.7251)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [140/172]  eta: 0:00:50  lr: 0.000041  loss: 0.7226 (0.7251)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [150/172]  eta: 0:00:34  lr: 0.000041  loss: 0.7133 (0.7246)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [160/172]  eta: 0:00:19  lr: 0.000041  loss: 0.7215 (0.7271)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [170/172]  eta: 0:00:03  lr: 0.000041  loss: 0.7517 (0.7278)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635]  [171/172]  eta: 0:00:01  lr: 0.000041  loss: 0.7504 (0.7275)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:635] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000041  loss: 0.7504 (0.7275)\n",
      "Valid: [epoch:635]  [ 0/14]  eta: 0:00:05  loss: 0.7305 (0.7305)  time: 0.4170  data: 0.3988  max mem: 20571\n",
      "Valid: [epoch:635]  [13/14]  eta: 0:00:00  loss: 0.6858 (0.6942)  time: 0.0444  data: 0.0291  max mem: 20571\n",
      "Valid: [epoch:635] Total time: 0:00:00 (0.0519 s / it)\n",
      "Averaged stats: loss: 0.6858 (0.6942)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_635_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.694%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:636]  [  0/172]  eta: 0:07:31  lr: 0.000041  loss: 0.7274 (0.7274)  time: 2.6261  data: 1.0587  max mem: 20571\n",
      "Train: [epoch:636]  [ 10/172]  eta: 0:04:31  lr: 0.000041  loss: 0.7262 (0.7218)  time: 1.6762  data: 0.0964  max mem: 20571\n",
      "Train: [epoch:636]  [ 20/172]  eta: 0:04:07  lr: 0.000041  loss: 0.7262 (0.7300)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:636]  [ 30/172]  eta: 0:03:49  lr: 0.000041  loss: 0.7216 (0.7245)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [ 40/172]  eta: 0:03:31  lr: 0.000041  loss: 0.7043 (0.7230)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [ 50/172]  eta: 0:03:15  lr: 0.000041  loss: 0.7265 (0.7293)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [ 60/172]  eta: 0:02:58  lr: 0.000041  loss: 0.7265 (0.7278)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [ 70/172]  eta: 0:02:42  lr: 0.000041  loss: 0.7139 (0.7263)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [ 80/172]  eta: 0:02:26  lr: 0.000041  loss: 0.7141 (0.7259)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [ 90/172]  eta: 0:02:10  lr: 0.000041  loss: 0.7220 (0.7255)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [100/172]  eta: 0:01:54  lr: 0.000041  loss: 0.7279 (0.7264)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [110/172]  eta: 0:01:38  lr: 0.000041  loss: 0.7375 (0.7256)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [120/172]  eta: 0:01:22  lr: 0.000041  loss: 0.7221 (0.7265)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [130/172]  eta: 0:01:06  lr: 0.000041  loss: 0.7221 (0.7262)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [140/172]  eta: 0:00:50  lr: 0.000041  loss: 0.7342 (0.7270)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [150/172]  eta: 0:00:34  lr: 0.000041  loss: 0.7328 (0.7275)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [160/172]  eta: 0:00:19  lr: 0.000041  loss: 0.7258 (0.7262)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [170/172]  eta: 0:00:03  lr: 0.000041  loss: 0.7121 (0.7255)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636]  [171/172]  eta: 0:00:01  lr: 0.000041  loss: 0.6941 (0.7253)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:636] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000041  loss: 0.6941 (0.7253)\n",
      "Valid: [epoch:636]  [ 0/14]  eta: 0:00:05  loss: 0.7518 (0.7518)  time: 0.4002  data: 0.3849  max mem: 20571\n",
      "Valid: [epoch:636]  [13/14]  eta: 0:00:00  loss: 0.7099 (0.7169)  time: 0.0431  data: 0.0279  max mem: 20571\n",
      "Valid: [epoch:636] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 0.7099 (0.7169)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_636_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.717%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:637]  [  0/172]  eta: 0:08:10  lr: 0.000040  loss: 0.8193 (0.8193)  time: 2.8492  data: 1.2726  max mem: 20571\n",
      "Train: [epoch:637]  [ 10/172]  eta: 0:04:34  lr: 0.000040  loss: 0.7247 (0.7352)  time: 1.6915  data: 0.1158  max mem: 20571\n",
      "Train: [epoch:637]  [ 20/172]  eta: 0:04:08  lr: 0.000040  loss: 0.7142 (0.7260)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:637]  [ 30/172]  eta: 0:03:49  lr: 0.000040  loss: 0.7122 (0.7242)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:637]  [ 40/172]  eta: 0:03:32  lr: 0.000040  loss: 0.7122 (0.7187)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [ 50/172]  eta: 0:03:15  lr: 0.000040  loss: 0.7114 (0.7221)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:637]  [ 60/172]  eta: 0:02:59  lr: 0.000040  loss: 0.7344 (0.7241)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [ 70/172]  eta: 0:02:42  lr: 0.000040  loss: 0.7344 (0.7258)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [ 80/172]  eta: 0:02:26  lr: 0.000040  loss: 0.7337 (0.7266)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.7392 (0.7312)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.7475 (0.7320)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.7185 (0.7308)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.7106 (0.7286)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.7152 (0.7284)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.7154 (0.7275)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [150/172]  eta: 0:00:34  lr: 0.000040  loss: 0.7191 (0.7282)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.7172 (0.7270)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.7140 (0.7274)  time: 1.5828  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:637]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.7242 (0.7275)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:637] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.7242 (0.7275)\n",
      "Valid: [epoch:637]  [ 0/14]  eta: 0:00:04  loss: 0.6365 (0.6365)  time: 0.3077  data: 0.2924  max mem: 20571\n",
      "Valid: [epoch:637]  [13/14]  eta: 0:00:00  loss: 0.6860 (0.6937)  time: 0.0421  data: 0.0270  max mem: 20571\n",
      "Valid: [epoch:637] Total time: 0:00:00 (0.0496 s / it)\n",
      "Averaged stats: loss: 0.6860 (0.6937)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_637_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.694%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:638]  [  0/172]  eta: 0:07:29  lr: 0.000040  loss: 0.7303 (0.7303)  time: 2.6124  data: 1.0251  max mem: 20571\n",
      "Train: [epoch:638]  [ 10/172]  eta: 0:04:31  lr: 0.000040  loss: 0.7303 (0.7285)  time: 1.6752  data: 0.0933  max mem: 20571\n",
      "Train: [epoch:638]  [ 20/172]  eta: 0:04:07  lr: 0.000040  loss: 0.7335 (0.7415)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [ 30/172]  eta: 0:03:49  lr: 0.000040  loss: 0.7293 (0.7381)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [ 40/172]  eta: 0:03:32  lr: 0.000040  loss: 0.7252 (0.7358)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:638]  [ 50/172]  eta: 0:03:15  lr: 0.000040  loss: 0.7078 (0.7338)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [ 60/172]  eta: 0:02:58  lr: 0.000040  loss: 0.7302 (0.7325)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [ 70/172]  eta: 0:02:42  lr: 0.000040  loss: 0.7302 (0.7309)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [ 80/172]  eta: 0:02:26  lr: 0.000040  loss: 0.7096 (0.7289)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.7211 (0.7280)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.7110 (0.7266)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.7091 (0.7260)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.7264 (0.7275)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.7299 (0.7267)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.7375 (0.7280)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [150/172]  eta: 0:00:34  lr: 0.000040  loss: 0.7401 (0.7299)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.7350 (0.7296)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.7293 (0.7296)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.7293 (0.7294)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:638] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.7293 (0.7294)\n",
      "Valid: [epoch:638]  [ 0/14]  eta: 0:00:05  loss: 0.6846 (0.6846)  time: 0.3979  data: 0.3825  max mem: 20571\n",
      "Valid: [epoch:638]  [13/14]  eta: 0:00:00  loss: 0.6963 (0.7064)  time: 0.0426  data: 0.0274  max mem: 20571\n",
      "Valid: [epoch:638] Total time: 0:00:00 (0.0509 s / it)\n",
      "Averaged stats: loss: 0.6963 (0.7064)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_638_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.706%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:639]  [  0/172]  eta: 0:07:44  lr: 0.000040  loss: 0.7719 (0.7719)  time: 2.7022  data: 1.1281  max mem: 20571\n",
      "Train: [epoch:639]  [ 10/172]  eta: 0:04:31  lr: 0.000040  loss: 0.7216 (0.7388)  time: 1.6790  data: 0.1027  max mem: 20571\n",
      "Train: [epoch:639]  [ 20/172]  eta: 0:04:07  lr: 0.000040  loss: 0.7277 (0.7359)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [ 30/172]  eta: 0:03:49  lr: 0.000040  loss: 0.7277 (0.7273)  time: 1.5796  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:639]  [ 40/172]  eta: 0:03:32  lr: 0.000040  loss: 0.7201 (0.7236)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:639]  [ 50/172]  eta: 0:03:15  lr: 0.000040  loss: 0.7267 (0.7257)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [ 60/172]  eta: 0:02:59  lr: 0.000040  loss: 0.7273 (0.7251)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [ 70/172]  eta: 0:02:42  lr: 0.000040  loss: 0.7252 (0.7240)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [ 80/172]  eta: 0:02:26  lr: 0.000040  loss: 0.7145 (0.7243)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.7052 (0.7236)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.7096 (0.7246)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.7292 (0.7244)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.7377 (0.7261)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.7426 (0.7273)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.7220 (0.7263)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [150/172]  eta: 0:00:34  lr: 0.000040  loss: 0.7198 (0.7267)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.7199 (0.7270)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.7365 (0.7276)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.7365 (0.7276)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:639] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.7365 (0.7276)\n",
      "Valid: [epoch:639]  [ 0/14]  eta: 0:00:04  loss: 0.6382 (0.6382)  time: 0.3445  data: 0.3285  max mem: 20571\n",
      "Valid: [epoch:639]  [13/14]  eta: 0:00:00  loss: 0.6888 (0.6969)  time: 0.0450  data: 0.0298  max mem: 20571\n",
      "Valid: [epoch:639] Total time: 0:00:00 (0.0530 s / it)\n",
      "Averaged stats: loss: 0.6888 (0.6969)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_639_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.697%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:640]  [  0/172]  eta: 0:07:25  lr: 0.000040  loss: 0.6242 (0.6242)  time: 2.5922  data: 1.0230  max mem: 20571\n",
      "Train: [epoch:640]  [ 10/172]  eta: 0:04:30  lr: 0.000040  loss: 0.7091 (0.6990)  time: 1.6710  data: 0.0931  max mem: 20571\n",
      "Train: [epoch:640]  [ 20/172]  eta: 0:04:07  lr: 0.000040  loss: 0.7139 (0.7099)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [ 30/172]  eta: 0:03:49  lr: 0.000040  loss: 0.7218 (0.7166)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [ 40/172]  eta: 0:03:31  lr: 0.000040  loss: 0.7218 (0.7243)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [ 50/172]  eta: 0:03:15  lr: 0.000040  loss: 0.7322 (0.7244)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [ 60/172]  eta: 0:02:58  lr: 0.000040  loss: 0.7357 (0.7277)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [ 70/172]  eta: 0:02:42  lr: 0.000040  loss: 0.7331 (0.7260)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [ 80/172]  eta: 0:02:26  lr: 0.000040  loss: 0.7193 (0.7283)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.7210 (0.7287)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.7129 (0.7271)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.7187 (0.7265)  time: 1.5819  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:640]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.7370 (0.7292)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.7417 (0.7294)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.7388 (0.7298)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [150/172]  eta: 0:00:34  lr: 0.000040  loss: 0.7399 (0.7312)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.7317 (0.7305)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.7467 (0.7323)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.7467 (0.7322)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:640] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.7467 (0.7322)\n",
      "Valid: [epoch:640]  [ 0/14]  eta: 0:00:04  loss: 0.6557 (0.6557)  time: 0.3127  data: 0.2979  max mem: 20571\n",
      "Valid: [epoch:640]  [13/14]  eta: 0:00:00  loss: 0.7060 (0.7143)  time: 0.0389  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:640] Total time: 0:00:00 (0.0466 s / it)\n",
      "Averaged stats: loss: 0.7060 (0.7143)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_640_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.714%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:641]  [  0/172]  eta: 0:07:53  lr: 0.000040  loss: 0.7936 (0.7936)  time: 2.7553  data: 1.1783  max mem: 20571\n",
      "Train: [epoch:641]  [ 10/172]  eta: 0:04:32  lr: 0.000040  loss: 0.7177 (0.7246)  time: 1.6842  data: 0.1072  max mem: 20571\n",
      "Train: [epoch:641]  [ 20/172]  eta: 0:04:08  lr: 0.000040  loss: 0.7177 (0.7326)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [ 30/172]  eta: 0:03:49  lr: 0.000040  loss: 0.7298 (0.7308)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [ 40/172]  eta: 0:03:32  lr: 0.000040  loss: 0.7124 (0.7288)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:641]  [ 50/172]  eta: 0:03:15  lr: 0.000040  loss: 0.7221 (0.7270)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:641]  [ 60/172]  eta: 0:02:59  lr: 0.000040  loss: 0.7237 (0.7279)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [ 70/172]  eta: 0:02:42  lr: 0.000040  loss: 0.7237 (0.7295)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [ 80/172]  eta: 0:02:26  lr: 0.000040  loss: 0.7167 (0.7292)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.7129 (0.7284)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.7254 (0.7281)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.7218 (0.7285)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.7260 (0.7301)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.7414 (0.7298)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.7414 (0.7298)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [150/172]  eta: 0:00:34  lr: 0.000040  loss: 0.7383 (0.7305)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.7213 (0.7306)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.7213 (0.7300)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.7213 (0.7298)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:641] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.7213 (0.7298)\n",
      "Valid: [epoch:641]  [ 0/14]  eta: 0:00:04  loss: 0.7541 (0.7541)  time: 0.3440  data: 0.3274  max mem: 20571\n",
      "Valid: [epoch:641]  [13/14]  eta: 0:00:00  loss: 0.6872 (0.6952)  time: 0.0398  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:641] Total time: 0:00:00 (0.0447 s / it)\n",
      "Averaged stats: loss: 0.6872 (0.6952)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_641_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.695%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:642]  [  0/172]  eta: 0:07:32  lr: 0.000040  loss: 0.7213 (0.7213)  time: 2.6288  data: 1.0611  max mem: 20571\n",
      "Train: [epoch:642]  [ 10/172]  eta: 0:04:31  lr: 0.000040  loss: 0.7266 (0.7311)  time: 1.6765  data: 0.0966  max mem: 20571\n",
      "Train: [epoch:642]  [ 20/172]  eta: 0:04:07  lr: 0.000040  loss: 0.7282 (0.7339)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [ 30/172]  eta: 0:03:49  lr: 0.000040  loss: 0.7184 (0.7303)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [ 40/172]  eta: 0:03:32  lr: 0.000040  loss: 0.7130 (0.7295)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [ 50/172]  eta: 0:03:15  lr: 0.000040  loss: 0.7177 (0.7296)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [ 60/172]  eta: 0:02:58  lr: 0.000040  loss: 0.7239 (0.7273)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [ 70/172]  eta: 0:02:42  lr: 0.000040  loss: 0.7145 (0.7263)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [ 80/172]  eta: 0:02:26  lr: 0.000040  loss: 0.7249 (0.7298)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.7349 (0.7289)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.7256 (0.7318)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.7381 (0.7308)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.7151 (0.7322)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.7173 (0.7310)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.7233 (0.7306)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [150/172]  eta: 0:00:34  lr: 0.000040  loss: 0.7365 (0.7313)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:642]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.7365 (0.7313)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:642]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.7341 (0.7322)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:642]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.7341 (0.7320)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:642] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.7341 (0.7320)\n",
      "Valid: [epoch:642]  [ 0/14]  eta: 0:00:04  loss: 0.6626 (0.6626)  time: 0.3335  data: 0.3158  max mem: 20571\n",
      "Valid: [epoch:642]  [13/14]  eta: 0:00:00  loss: 0.7264 (0.7346)  time: 0.0394  data: 0.0242  max mem: 20571\n",
      "Valid: [epoch:642] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.7264 (0.7346)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_642_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.735%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:643]  [  0/172]  eta: 0:07:54  lr: 0.000040  loss: 0.7888 (0.7888)  time: 2.7611  data: 1.1790  max mem: 20571\n",
      "Train: [epoch:643]  [ 10/172]  eta: 0:04:33  lr: 0.000040  loss: 0.7202 (0.7141)  time: 1.6855  data: 0.1073  max mem: 20571\n",
      "Train: [epoch:643]  [ 20/172]  eta: 0:04:08  lr: 0.000040  loss: 0.7202 (0.7255)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [ 30/172]  eta: 0:03:49  lr: 0.000040  loss: 0.7422 (0.7307)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [ 40/172]  eta: 0:03:32  lr: 0.000040  loss: 0.7297 (0.7324)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [ 50/172]  eta: 0:03:15  lr: 0.000040  loss: 0.7297 (0.7331)  time: 1.5845  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:643]  [ 60/172]  eta: 0:02:59  lr: 0.000040  loss: 0.7374 (0.7329)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [ 70/172]  eta: 0:02:43  lr: 0.000040  loss: 0.7359 (0.7312)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [ 80/172]  eta: 0:02:26  lr: 0.000040  loss: 0.7025 (0.7279)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.7111 (0.7284)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.7270 (0.7294)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.7270 (0.7288)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.7427 (0.7312)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.7208 (0.7310)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.7173 (0.7314)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [150/172]  eta: 0:00:34  lr: 0.000040  loss: 0.7423 (0.7327)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.7346 (0.7328)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.7154 (0.7315)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.7154 (0.7316)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:643] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.7154 (0.7316)\n",
      "Valid: [epoch:643]  [ 0/14]  eta: 0:00:04  loss: 0.7249 (0.7249)  time: 0.3011  data: 0.2856  max mem: 20571\n",
      "Valid: [epoch:643]  [13/14]  eta: 0:00:00  loss: 0.6890 (0.6961)  time: 0.0488  data: 0.0338  max mem: 20571\n",
      "Valid: [epoch:643] Total time: 0:00:00 (0.0537 s / it)\n",
      "Averaged stats: loss: 0.6890 (0.6961)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_643_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.696%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:644]  [  0/172]  eta: 0:07:41  lr: 0.000040  loss: 0.7092 (0.7092)  time: 2.6832  data: 1.1052  max mem: 20571\n",
      "Train: [epoch:644]  [ 10/172]  eta: 0:04:32  lr: 0.000040  loss: 0.7092 (0.7165)  time: 1.6812  data: 0.1006  max mem: 20571\n",
      "Train: [epoch:644]  [ 20/172]  eta: 0:04:08  lr: 0.000040  loss: 0.7150 (0.7209)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [ 30/172]  eta: 0:03:49  lr: 0.000040  loss: 0.7195 (0.7301)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:644]  [ 40/172]  eta: 0:03:32  lr: 0.000040  loss: 0.7329 (0.7307)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [ 50/172]  eta: 0:03:15  lr: 0.000040  loss: 0.7370 (0.7334)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [ 60/172]  eta: 0:02:59  lr: 0.000040  loss: 0.7167 (0.7331)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [ 70/172]  eta: 0:02:42  lr: 0.000040  loss: 0.7405 (0.7356)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [ 80/172]  eta: 0:02:26  lr: 0.000040  loss: 0.7412 (0.7357)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.7178 (0.7334)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.7100 (0.7330)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.7376 (0.7346)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.7416 (0.7352)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.7356 (0.7345)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.7395 (0.7351)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [150/172]  eta: 0:00:34  lr: 0.000040  loss: 0.7395 (0.7347)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.7082 (0.7334)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.7158 (0.7339)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.7158 (0.7335)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:644] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.7158 (0.7335)\n",
      "Valid: [epoch:644]  [ 0/14]  eta: 0:00:04  loss: 0.6863 (0.6863)  time: 0.3039  data: 0.2890  max mem: 20571\n",
      "Valid: [epoch:644]  [13/14]  eta: 0:00:00  loss: 0.6910 (0.6986)  time: 0.0378  data: 0.0228  max mem: 20571\n",
      "Valid: [epoch:644] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.6910 (0.6986)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_644_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.699%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:645]  [  0/172]  eta: 0:07:40  lr: 0.000040  loss: 0.7679 (0.7679)  time: 2.6801  data: 1.0945  max mem: 20571\n",
      "Train: [epoch:645]  [ 10/172]  eta: 0:04:32  lr: 0.000040  loss: 0.7731 (0.7535)  time: 1.6804  data: 0.0996  max mem: 20571\n",
      "Train: [epoch:645]  [ 20/172]  eta: 0:04:08  lr: 0.000040  loss: 0.7392 (0.7389)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:645]  [ 30/172]  eta: 0:03:49  lr: 0.000040  loss: 0.7044 (0.7374)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:645]  [ 40/172]  eta: 0:03:32  lr: 0.000040  loss: 0.7219 (0.7363)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:645]  [ 50/172]  eta: 0:03:15  lr: 0.000040  loss: 0.7173 (0.7332)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:645]  [ 60/172]  eta: 0:02:59  lr: 0.000040  loss: 0.7206 (0.7360)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:645]  [ 70/172]  eta: 0:02:42  lr: 0.000040  loss: 0.7294 (0.7340)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:645]  [ 80/172]  eta: 0:02:26  lr: 0.000040  loss: 0.7215 (0.7331)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:645]  [ 90/172]  eta: 0:02:10  lr: 0.000040  loss: 0.7291 (0.7338)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:645]  [100/172]  eta: 0:01:54  lr: 0.000040  loss: 0.7291 (0.7345)  time: 1.5845  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:645]  [110/172]  eta: 0:01:38  lr: 0.000040  loss: 0.7374 (0.7352)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:645]  [120/172]  eta: 0:01:22  lr: 0.000040  loss: 0.7374 (0.7359)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:645]  [130/172]  eta: 0:01:06  lr: 0.000040  loss: 0.7301 (0.7372)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:645]  [140/172]  eta: 0:00:50  lr: 0.000040  loss: 0.7283 (0.7345)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:645]  [150/172]  eta: 0:00:34  lr: 0.000040  loss: 0.7067 (0.7336)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:645]  [160/172]  eta: 0:00:19  lr: 0.000040  loss: 0.7423 (0.7347)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:645]  [170/172]  eta: 0:00:03  lr: 0.000040  loss: 0.7515 (0.7345)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:645]  [171/172]  eta: 0:00:01  lr: 0.000040  loss: 0.7518 (0.7346)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:645] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000040  loss: 0.7518 (0.7346)\n",
      "Valid: [epoch:645]  [ 0/14]  eta: 0:00:04  loss: 0.7430 (0.7430)  time: 0.3075  data: 0.2915  max mem: 20571\n",
      "Valid: [epoch:645]  [13/14]  eta: 0:00:00  loss: 0.7113 (0.7175)  time: 0.0404  data: 0.0253  max mem: 20571\n",
      "Valid: [epoch:645] Total time: 0:00:00 (0.0488 s / it)\n",
      "Averaged stats: loss: 0.7113 (0.7175)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_645_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.717%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:646]  [  0/172]  eta: 0:07:40  lr: 0.000039  loss: 0.8132 (0.8132)  time: 2.6747  data: 1.1062  max mem: 20571\n",
      "Train: [epoch:646]  [ 10/172]  eta: 0:04:31  lr: 0.000039  loss: 0.7411 (0.7421)  time: 1.6784  data: 0.1007  max mem: 20571\n",
      "Train: [epoch:646]  [ 20/172]  eta: 0:04:08  lr: 0.000039  loss: 0.7354 (0.7367)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [ 30/172]  eta: 0:03:49  lr: 0.000039  loss: 0.7333 (0.7310)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [ 40/172]  eta: 0:03:32  lr: 0.000039  loss: 0.7333 (0.7328)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:646]  [ 50/172]  eta: 0:03:15  lr: 0.000039  loss: 0.7411 (0.7342)  time: 1.5841  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:646]  [ 60/172]  eta: 0:02:59  lr: 0.000039  loss: 0.7224 (0.7341)  time: 1.5827  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:646]  [ 70/172]  eta: 0:02:42  lr: 0.000039  loss: 0.7224 (0.7344)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:646]  [ 80/172]  eta: 0:02:26  lr: 0.000039  loss: 0.7304 (0.7359)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [ 90/172]  eta: 0:02:10  lr: 0.000039  loss: 0.7222 (0.7329)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [100/172]  eta: 0:01:54  lr: 0.000039  loss: 0.7186 (0.7321)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [110/172]  eta: 0:01:38  lr: 0.000039  loss: 0.7287 (0.7323)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [120/172]  eta: 0:01:22  lr: 0.000039  loss: 0.7192 (0.7335)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [130/172]  eta: 0:01:06  lr: 0.000039  loss: 0.7282 (0.7350)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [140/172]  eta: 0:00:50  lr: 0.000039  loss: 0.7345 (0.7343)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [150/172]  eta: 0:00:34  lr: 0.000039  loss: 0.7216 (0.7339)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [160/172]  eta: 0:00:19  lr: 0.000039  loss: 0.7306 (0.7340)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [170/172]  eta: 0:00:03  lr: 0.000039  loss: 0.7306 (0.7339)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646]  [171/172]  eta: 0:00:01  lr: 0.000039  loss: 0.7306 (0.7341)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:646] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000039  loss: 0.7306 (0.7341)\n",
      "Valid: [epoch:646]  [ 0/14]  eta: 0:00:03  loss: 0.7384 (0.7384)  time: 0.2830  data: 0.2668  max mem: 20571\n",
      "Valid: [epoch:646]  [13/14]  eta: 0:00:00  loss: 0.6950 (0.7030)  time: 0.0486  data: 0.0335  max mem: 20571\n",
      "Valid: [epoch:646] Total time: 0:00:00 (0.0563 s / it)\n",
      "Averaged stats: loss: 0.6950 (0.7030)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_646_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.703%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:647]  [  0/172]  eta: 0:07:20  lr: 0.000039  loss: 0.7301 (0.7301)  time: 2.5632  data: 0.9722  max mem: 20571\n",
      "Train: [epoch:647]  [ 10/172]  eta: 0:04:29  lr: 0.000039  loss: 0.7301 (0.7504)  time: 1.6663  data: 0.0885  max mem: 20571\n",
      "Train: [epoch:647]  [ 20/172]  eta: 0:04:06  lr: 0.000039  loss: 0.7315 (0.7479)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [ 30/172]  eta: 0:03:48  lr: 0.000039  loss: 0.7315 (0.7402)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [ 40/172]  eta: 0:03:31  lr: 0.000039  loss: 0.7237 (0.7355)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [ 50/172]  eta: 0:03:15  lr: 0.000039  loss: 0.7244 (0.7348)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [ 60/172]  eta: 0:02:58  lr: 0.000039  loss: 0.7328 (0.7361)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [ 70/172]  eta: 0:02:42  lr: 0.000039  loss: 0.7291 (0.7355)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [ 80/172]  eta: 0:02:26  lr: 0.000039  loss: 0.7290 (0.7368)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [ 90/172]  eta: 0:02:10  lr: 0.000039  loss: 0.7343 (0.7350)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [100/172]  eta: 0:01:54  lr: 0.000039  loss: 0.7057 (0.7342)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [110/172]  eta: 0:01:38  lr: 0.000039  loss: 0.7326 (0.7342)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [120/172]  eta: 0:01:22  lr: 0.000039  loss: 0.7492 (0.7348)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [130/172]  eta: 0:01:06  lr: 0.000039  loss: 0.7443 (0.7338)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [140/172]  eta: 0:00:50  lr: 0.000039  loss: 0.7395 (0.7369)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [150/172]  eta: 0:00:34  lr: 0.000039  loss: 0.7286 (0.7354)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [160/172]  eta: 0:00:19  lr: 0.000039  loss: 0.7286 (0.7358)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [170/172]  eta: 0:00:03  lr: 0.000039  loss: 0.7305 (0.7347)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647]  [171/172]  eta: 0:00:01  lr: 0.000039  loss: 0.7305 (0.7350)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:647] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000039  loss: 0.7305 (0.7350)\n",
      "Valid: [epoch:647]  [ 0/14]  eta: 0:00:04  loss: 0.7077 (0.7077)  time: 0.3039  data: 0.2889  max mem: 20571\n",
      "Valid: [epoch:647]  [13/14]  eta: 0:00:00  loss: 0.7077 (0.7127)  time: 0.0420  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:647] Total time: 0:00:00 (0.0501 s / it)\n",
      "Averaged stats: loss: 0.7077 (0.7127)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_647_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.713%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:648]  [  0/172]  eta: 0:07:44  lr: 0.000039  loss: 0.7367 (0.7367)  time: 2.6997  data: 1.1294  max mem: 20571\n",
      "Train: [epoch:648]  [ 10/172]  eta: 0:04:32  lr: 0.000039  loss: 0.7522 (0.7507)  time: 1.6802  data: 0.1028  max mem: 20571\n",
      "Train: [epoch:648]  [ 20/172]  eta: 0:04:08  lr: 0.000039  loss: 0.7498 (0.7440)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [ 30/172]  eta: 0:03:49  lr: 0.000039  loss: 0.7310 (0.7420)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [ 40/172]  eta: 0:03:32  lr: 0.000039  loss: 0.7310 (0.7391)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [ 50/172]  eta: 0:03:15  lr: 0.000039  loss: 0.7273 (0.7388)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [ 60/172]  eta: 0:02:59  lr: 0.000039  loss: 0.7273 (0.7376)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [ 70/172]  eta: 0:02:42  lr: 0.000039  loss: 0.7223 (0.7365)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [ 80/172]  eta: 0:02:26  lr: 0.000039  loss: 0.7456 (0.7398)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [ 90/172]  eta: 0:02:10  lr: 0.000039  loss: 0.7456 (0.7419)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [100/172]  eta: 0:01:54  lr: 0.000039  loss: 0.7457 (0.7449)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [110/172]  eta: 0:01:38  lr: 0.000039  loss: 0.7758 (0.7446)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [120/172]  eta: 0:01:22  lr: 0.000039  loss: 0.7521 (0.7448)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [130/172]  eta: 0:01:06  lr: 0.000039  loss: 0.7468 (0.7437)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [140/172]  eta: 0:00:50  lr: 0.000039  loss: 0.7187 (0.7423)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [150/172]  eta: 0:00:34  lr: 0.000039  loss: 0.7154 (0.7410)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [160/172]  eta: 0:00:19  lr: 0.000039  loss: 0.7290 (0.7414)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648]  [170/172]  eta: 0:00:03  lr: 0.000039  loss: 0.7371 (0.7410)  time: 1.5822  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:648]  [171/172]  eta: 0:00:01  lr: 0.000039  loss: 0.7371 (0.7412)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:648] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000039  loss: 0.7371 (0.7412)\n",
      "Valid: [epoch:648]  [ 0/14]  eta: 0:00:05  loss: 0.7350 (0.7350)  time: 0.3942  data: 0.3760  max mem: 20571\n",
      "Valid: [epoch:648]  [13/14]  eta: 0:00:00  loss: 0.6900 (0.6974)  time: 0.0425  data: 0.0273  max mem: 20571\n",
      "Valid: [epoch:648] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.6900 (0.6974)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_648_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.697%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:649]  [  0/172]  eta: 0:07:28  lr: 0.000039  loss: 0.6394 (0.6394)  time: 2.6091  data: 1.0314  max mem: 20571\n",
      "Train: [epoch:649]  [ 10/172]  eta: 0:04:30  lr: 0.000039  loss: 0.7241 (0.7137)  time: 1.6706  data: 0.0939  max mem: 20571\n",
      "Train: [epoch:649]  [ 20/172]  eta: 0:04:07  lr: 0.000039  loss: 0.7241 (0.7215)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [ 30/172]  eta: 0:03:49  lr: 0.000039  loss: 0.7298 (0.7263)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [ 40/172]  eta: 0:03:31  lr: 0.000039  loss: 0.7358 (0.7321)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [ 50/172]  eta: 0:03:15  lr: 0.000039  loss: 0.7159 (0.7307)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [ 60/172]  eta: 0:02:58  lr: 0.000039  loss: 0.7117 (0.7306)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [ 70/172]  eta: 0:02:42  lr: 0.000039  loss: 0.7280 (0.7320)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [ 80/172]  eta: 0:02:26  lr: 0.000039  loss: 0.7475 (0.7345)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [ 90/172]  eta: 0:02:10  lr: 0.000039  loss: 0.7382 (0.7352)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [100/172]  eta: 0:01:54  lr: 0.000039  loss: 0.7320 (0.7347)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [110/172]  eta: 0:01:38  lr: 0.000039  loss: 0.7263 (0.7333)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [120/172]  eta: 0:01:22  lr: 0.000039  loss: 0.7368 (0.7348)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [130/172]  eta: 0:01:06  lr: 0.000039  loss: 0.7356 (0.7349)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [140/172]  eta: 0:00:50  lr: 0.000039  loss: 0.7333 (0.7358)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [150/172]  eta: 0:00:34  lr: 0.000039  loss: 0.7321 (0.7348)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [160/172]  eta: 0:00:19  lr: 0.000039  loss: 0.7172 (0.7352)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [170/172]  eta: 0:00:03  lr: 0.000039  loss: 0.7335 (0.7344)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649]  [171/172]  eta: 0:00:01  lr: 0.000039  loss: 0.7335 (0.7343)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:649] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000039  loss: 0.7335 (0.7343)\n",
      "Valid: [epoch:649]  [ 0/14]  eta: 0:00:04  loss: 0.6867 (0.6867)  time: 0.3363  data: 0.3179  max mem: 20571\n",
      "Valid: [epoch:649]  [13/14]  eta: 0:00:00  loss: 0.7020 (0.7084)  time: 0.0405  data: 0.0253  max mem: 20571\n",
      "Valid: [epoch:649] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.7020 (0.7084)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_649_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.708%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:650]  [  0/172]  eta: 0:08:14  lr: 0.000039  loss: 0.7928 (0.7928)  time: 2.8764  data: 1.3088  max mem: 20571\n",
      "Train: [epoch:650]  [ 10/172]  eta: 0:04:34  lr: 0.000039  loss: 0.7406 (0.7367)  time: 1.6956  data: 0.1191  max mem: 20571\n",
      "Train: [epoch:650]  [ 20/172]  eta: 0:04:09  lr: 0.000039  loss: 0.7517 (0.7490)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [ 30/172]  eta: 0:03:50  lr: 0.000039  loss: 0.7517 (0.7466)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [ 40/172]  eta: 0:03:32  lr: 0.000039  loss: 0.7210 (0.7395)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [ 50/172]  eta: 0:03:15  lr: 0.000039  loss: 0.7231 (0.7414)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [ 60/172]  eta: 0:02:59  lr: 0.000039  loss: 0.7321 (0.7395)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [ 70/172]  eta: 0:02:43  lr: 0.000039  loss: 0.7367 (0.7410)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [ 80/172]  eta: 0:02:26  lr: 0.000039  loss: 0.7450 (0.7443)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [ 90/172]  eta: 0:02:10  lr: 0.000039  loss: 0.7233 (0.7412)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [100/172]  eta: 0:01:54  lr: 0.000039  loss: 0.7220 (0.7412)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [110/172]  eta: 0:01:38  lr: 0.000039  loss: 0.7423 (0.7417)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [120/172]  eta: 0:01:22  lr: 0.000039  loss: 0.7296 (0.7411)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [130/172]  eta: 0:01:06  lr: 0.000039  loss: 0.7192 (0.7400)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [140/172]  eta: 0:00:50  lr: 0.000039  loss: 0.7050 (0.7379)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [150/172]  eta: 0:00:34  lr: 0.000039  loss: 0.7149 (0.7383)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [160/172]  eta: 0:00:19  lr: 0.000039  loss: 0.7279 (0.7377)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [170/172]  eta: 0:00:03  lr: 0.000039  loss: 0.7297 (0.7380)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650]  [171/172]  eta: 0:00:01  lr: 0.000039  loss: 0.7297 (0.7381)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:650] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000039  loss: 0.7297 (0.7381)\n",
      "Valid: [epoch:650]  [ 0/14]  eta: 0:00:04  loss: 0.7118 (0.7118)  time: 0.3165  data: 0.3003  max mem: 20571\n",
      "Valid: [epoch:650]  [13/14]  eta: 0:00:00  loss: 0.7254 (0.7312)  time: 0.0402  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:650] Total time: 0:00:00 (0.0458 s / it)\n",
      "Averaged stats: loss: 0.7254 (0.7312)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_650_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.731%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:651]  [  0/172]  eta: 0:07:16  lr: 0.000039  loss: 0.7350 (0.7350)  time: 2.5406  data: 0.9613  max mem: 20571\n",
      "Train: [epoch:651]  [ 10/172]  eta: 0:04:29  lr: 0.000039  loss: 0.7350 (0.7403)  time: 1.6634  data: 0.0875  max mem: 20571\n",
      "Train: [epoch:651]  [ 20/172]  eta: 0:04:06  lr: 0.000039  loss: 0.7474 (0.7437)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [ 30/172]  eta: 0:03:48  lr: 0.000039  loss: 0.7244 (0.7371)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [ 40/172]  eta: 0:03:31  lr: 0.000039  loss: 0.7244 (0.7323)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [ 50/172]  eta: 0:03:14  lr: 0.000039  loss: 0.7354 (0.7343)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [ 60/172]  eta: 0:02:58  lr: 0.000039  loss: 0.7355 (0.7363)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [ 70/172]  eta: 0:02:42  lr: 0.000039  loss: 0.7318 (0.7387)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [ 80/172]  eta: 0:02:26  lr: 0.000039  loss: 0.7315 (0.7386)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [ 90/172]  eta: 0:02:10  lr: 0.000039  loss: 0.7244 (0.7383)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [100/172]  eta: 0:01:54  lr: 0.000039  loss: 0.7366 (0.7392)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [110/172]  eta: 0:01:38  lr: 0.000039  loss: 0.7431 (0.7386)  time: 1.5818  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:651]  [120/172]  eta: 0:01:22  lr: 0.000039  loss: 0.7431 (0.7393)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [130/172]  eta: 0:01:06  lr: 0.000039  loss: 0.7459 (0.7398)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [140/172]  eta: 0:00:50  lr: 0.000039  loss: 0.7407 (0.7401)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [150/172]  eta: 0:00:34  lr: 0.000039  loss: 0.7547 (0.7404)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [160/172]  eta: 0:00:19  lr: 0.000039  loss: 0.7612 (0.7416)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [170/172]  eta: 0:00:03  lr: 0.000039  loss: 0.7455 (0.7413)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651]  [171/172]  eta: 0:00:01  lr: 0.000039  loss: 0.7544 (0.7414)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:651] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000039  loss: 0.7544 (0.7414)\n",
      "Valid: [epoch:651]  [ 0/14]  eta: 0:00:04  loss: 0.7365 (0.7365)  time: 0.3148  data: 0.2987  max mem: 20571\n",
      "Valid: [epoch:651]  [13/14]  eta: 0:00:00  loss: 0.7034 (0.7094)  time: 0.0487  data: 0.0336  max mem: 20571\n",
      "Valid: [epoch:651] Total time: 0:00:00 (0.0570 s / it)\n",
      "Averaged stats: loss: 0.7034 (0.7094)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_651_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.709%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:652]  [  0/172]  eta: 0:07:35  lr: 0.000039  loss: 0.7093 (0.7093)  time: 2.6458  data: 1.0762  max mem: 20571\n",
      "Train: [epoch:652]  [ 10/172]  eta: 0:04:31  lr: 0.000039  loss: 0.7276 (0.7353)  time: 1.6758  data: 0.0980  max mem: 20571\n",
      "Train: [epoch:652]  [ 20/172]  eta: 0:04:07  lr: 0.000039  loss: 0.7227 (0.7299)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:652]  [ 30/172]  eta: 0:03:49  lr: 0.000039  loss: 0.7213 (0.7299)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [ 40/172]  eta: 0:03:32  lr: 0.000039  loss: 0.7134 (0.7297)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [ 50/172]  eta: 0:03:15  lr: 0.000039  loss: 0.7172 (0.7357)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [ 60/172]  eta: 0:02:58  lr: 0.000039  loss: 0.7286 (0.7338)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [ 70/172]  eta: 0:02:42  lr: 0.000039  loss: 0.7349 (0.7369)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [ 80/172]  eta: 0:02:26  lr: 0.000039  loss: 0.7578 (0.7388)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [ 90/172]  eta: 0:02:10  lr: 0.000039  loss: 0.7423 (0.7381)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [100/172]  eta: 0:01:54  lr: 0.000039  loss: 0.7270 (0.7379)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [110/172]  eta: 0:01:38  lr: 0.000039  loss: 0.7312 (0.7398)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [120/172]  eta: 0:01:22  lr: 0.000039  loss: 0.7519 (0.7410)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [130/172]  eta: 0:01:06  lr: 0.000039  loss: 0.7339 (0.7403)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [140/172]  eta: 0:00:50  lr: 0.000039  loss: 0.7425 (0.7413)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [150/172]  eta: 0:00:34  lr: 0.000039  loss: 0.7425 (0.7407)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [160/172]  eta: 0:00:19  lr: 0.000039  loss: 0.7214 (0.7394)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [170/172]  eta: 0:00:03  lr: 0.000039  loss: 0.7356 (0.7399)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652]  [171/172]  eta: 0:00:01  lr: 0.000039  loss: 0.7356 (0.7398)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:652] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000039  loss: 0.7356 (0.7398)\n",
      "Valid: [epoch:652]  [ 0/14]  eta: 0:00:05  loss: 0.7346 (0.7346)  time: 0.3834  data: 0.3664  max mem: 20571\n",
      "Valid: [epoch:652]  [13/14]  eta: 0:00:00  loss: 0.6997 (0.7071)  time: 0.0558  data: 0.0405  max mem: 20571\n",
      "Valid: [epoch:652] Total time: 0:00:00 (0.0632 s / it)\n",
      "Averaged stats: loss: 0.6997 (0.7071)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_652_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.707%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:653]  [  0/172]  eta: 0:08:05  lr: 0.000039  loss: 0.7091 (0.7091)  time: 2.8232  data: 1.2450  max mem: 20571\n",
      "Train: [epoch:653]  [ 10/172]  eta: 0:04:33  lr: 0.000039  loss: 0.7221 (0.7418)  time: 1.6904  data: 0.1133  max mem: 20571\n",
      "Train: [epoch:653]  [ 20/172]  eta: 0:04:08  lr: 0.000039  loss: 0.7447 (0.7500)  time: 1.5777  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:653]  [ 30/172]  eta: 0:03:49  lr: 0.000039  loss: 0.7447 (0.7478)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:653]  [ 40/172]  eta: 0:03:32  lr: 0.000039  loss: 0.7231 (0.7455)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:653]  [ 50/172]  eta: 0:03:15  lr: 0.000039  loss: 0.7305 (0.7468)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [ 60/172]  eta: 0:02:59  lr: 0.000039  loss: 0.7401 (0.7442)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [ 70/172]  eta: 0:02:42  lr: 0.000039  loss: 0.7412 (0.7460)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [ 80/172]  eta: 0:02:26  lr: 0.000039  loss: 0.7497 (0.7458)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [ 90/172]  eta: 0:02:10  lr: 0.000039  loss: 0.7234 (0.7429)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [100/172]  eta: 0:01:54  lr: 0.000039  loss: 0.7223 (0.7432)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [110/172]  eta: 0:01:38  lr: 0.000039  loss: 0.7329 (0.7418)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [120/172]  eta: 0:01:22  lr: 0.000039  loss: 0.7258 (0.7403)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [130/172]  eta: 0:01:06  lr: 0.000039  loss: 0.7337 (0.7421)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [140/172]  eta: 0:00:50  lr: 0.000039  loss: 0.7684 (0.7435)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [150/172]  eta: 0:00:34  lr: 0.000039  loss: 0.7498 (0.7448)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:653]  [160/172]  eta: 0:00:19  lr: 0.000039  loss: 0.7342 (0.7437)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [170/172]  eta: 0:00:03  lr: 0.000039  loss: 0.7288 (0.7442)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653]  [171/172]  eta: 0:00:01  lr: 0.000039  loss: 0.7288 (0.7439)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:653] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000039  loss: 0.7288 (0.7439)\n",
      "Valid: [epoch:653]  [ 0/14]  eta: 0:00:04  loss: 0.6337 (0.6337)  time: 0.3190  data: 0.3032  max mem: 20571\n",
      "Valid: [epoch:653]  [13/14]  eta: 0:00:00  loss: 0.7042 (0.7102)  time: 0.0392  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:653] Total time: 0:00:00 (0.0461 s / it)\n",
      "Averaged stats: loss: 0.7042 (0.7102)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_653_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.710%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:654]  [  0/172]  eta: 0:08:14  lr: 0.000039  loss: 0.7102 (0.7102)  time: 2.8779  data: 1.3113  max mem: 20571\n",
      "Train: [epoch:654]  [ 10/172]  eta: 0:04:34  lr: 0.000039  loss: 0.7506 (0.7359)  time: 1.6957  data: 0.1193  max mem: 20571\n",
      "Train: [epoch:654]  [ 20/172]  eta: 0:04:09  lr: 0.000039  loss: 0.7584 (0.7472)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:654]  [ 30/172]  eta: 0:03:50  lr: 0.000039  loss: 0.7533 (0.7443)  time: 1.5796  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:654]  [ 40/172]  eta: 0:03:32  lr: 0.000039  loss: 0.7196 (0.7365)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [ 50/172]  eta: 0:03:15  lr: 0.000039  loss: 0.7232 (0.7387)  time: 1.5829  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:654]  [ 60/172]  eta: 0:02:59  lr: 0.000039  loss: 0.7381 (0.7372)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [ 70/172]  eta: 0:02:43  lr: 0.000039  loss: 0.7340 (0.7371)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [ 80/172]  eta: 0:02:26  lr: 0.000039  loss: 0.7298 (0.7378)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [ 90/172]  eta: 0:02:10  lr: 0.000039  loss: 0.7213 (0.7368)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [100/172]  eta: 0:01:54  lr: 0.000039  loss: 0.7268 (0.7382)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [110/172]  eta: 0:01:38  lr: 0.000039  loss: 0.7268 (0.7375)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [120/172]  eta: 0:01:22  lr: 0.000039  loss: 0.7222 (0.7392)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [130/172]  eta: 0:01:06  lr: 0.000039  loss: 0.7356 (0.7387)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [140/172]  eta: 0:00:50  lr: 0.000039  loss: 0.7149 (0.7382)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [150/172]  eta: 0:00:34  lr: 0.000039  loss: 0.7149 (0.7389)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [160/172]  eta: 0:00:19  lr: 0.000039  loss: 0.7549 (0.7404)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [170/172]  eta: 0:00:03  lr: 0.000039  loss: 0.7500 (0.7408)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654]  [171/172]  eta: 0:00:01  lr: 0.000039  loss: 0.7500 (0.7403)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:654] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000039  loss: 0.7500 (0.7403)\n",
      "Valid: [epoch:654]  [ 0/14]  eta: 0:00:04  loss: 0.7403 (0.7403)  time: 0.3266  data: 0.3112  max mem: 20571\n",
      "Valid: [epoch:654]  [13/14]  eta: 0:00:00  loss: 0.7004 (0.7075)  time: 0.0409  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:654] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.7004 (0.7075)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_654_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.707%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:655]  [  0/172]  eta: 0:08:02  lr: 0.000038  loss: 0.7516 (0.7516)  time: 2.8041  data: 1.2287  max mem: 20571\n",
      "Train: [epoch:655]  [ 10/172]  eta: 0:04:33  lr: 0.000038  loss: 0.7522 (0.7579)  time: 1.6892  data: 0.1118  max mem: 20571\n",
      "Train: [epoch:655]  [ 20/172]  eta: 0:04:08  lr: 0.000038  loss: 0.7522 (0.7579)  time: 1.5777  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:655]  [ 30/172]  eta: 0:03:49  lr: 0.000038  loss: 0.7232 (0.7478)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:655]  [ 40/172]  eta: 0:03:32  lr: 0.000038  loss: 0.7232 (0.7473)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [ 50/172]  eta: 0:03:15  lr: 0.000038  loss: 0.7501 (0.7512)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [ 60/172]  eta: 0:02:59  lr: 0.000038  loss: 0.7531 (0.7488)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [ 70/172]  eta: 0:02:42  lr: 0.000038  loss: 0.7346 (0.7475)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [ 80/172]  eta: 0:02:26  lr: 0.000038  loss: 0.7257 (0.7462)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [ 90/172]  eta: 0:02:10  lr: 0.000038  loss: 0.7519 (0.7484)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [100/172]  eta: 0:01:54  lr: 0.000038  loss: 0.7404 (0.7464)  time: 1.5827  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:655]  [110/172]  eta: 0:01:38  lr: 0.000038  loss: 0.7392 (0.7465)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:655]  [120/172]  eta: 0:01:22  lr: 0.000038  loss: 0.7433 (0.7464)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [130/172]  eta: 0:01:06  lr: 0.000038  loss: 0.7405 (0.7449)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [140/172]  eta: 0:00:50  lr: 0.000038  loss: 0.7357 (0.7447)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [150/172]  eta: 0:00:34  lr: 0.000038  loss: 0.7357 (0.7453)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [160/172]  eta: 0:00:19  lr: 0.000038  loss: 0.7345 (0.7439)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [170/172]  eta: 0:00:03  lr: 0.000038  loss: 0.7272 (0.7433)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655]  [171/172]  eta: 0:00:01  lr: 0.000038  loss: 0.7347 (0.7433)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:655] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000038  loss: 0.7347 (0.7433)\n",
      "Valid: [epoch:655]  [ 0/14]  eta: 0:00:06  loss: 0.6984 (0.6984)  time: 0.4531  data: 0.4360  max mem: 20571\n",
      "Valid: [epoch:655]  [13/14]  eta: 0:00:00  loss: 0.7102 (0.7178)  time: 0.0480  data: 0.0327  max mem: 20571\n",
      "Valid: [epoch:655] Total time: 0:00:00 (0.0536 s / it)\n",
      "Averaged stats: loss: 0.7102 (0.7178)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_655_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.718%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:656]  [  0/172]  eta: 0:08:09  lr: 0.000038  loss: 0.7895 (0.7895)  time: 2.8445  data: 1.2779  max mem: 20571\n",
      "Train: [epoch:656]  [ 10/172]  eta: 0:04:34  lr: 0.000038  loss: 0.7440 (0.7489)  time: 1.6930  data: 0.1163  max mem: 20571\n",
      "Train: [epoch:656]  [ 20/172]  eta: 0:04:09  lr: 0.000038  loss: 0.7233 (0.7397)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [ 30/172]  eta: 0:03:50  lr: 0.000038  loss: 0.7231 (0.7401)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [ 40/172]  eta: 0:03:32  lr: 0.000038  loss: 0.7256 (0.7368)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [ 50/172]  eta: 0:03:15  lr: 0.000038  loss: 0.7352 (0.7409)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [ 60/172]  eta: 0:02:59  lr: 0.000038  loss: 0.7535 (0.7430)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [ 70/172]  eta: 0:02:42  lr: 0.000038  loss: 0.7506 (0.7439)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [ 80/172]  eta: 0:02:26  lr: 0.000038  loss: 0.7459 (0.7440)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:656]  [ 90/172]  eta: 0:02:10  lr: 0.000038  loss: 0.7472 (0.7444)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:656]  [100/172]  eta: 0:01:54  lr: 0.000038  loss: 0.7275 (0.7426)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [110/172]  eta: 0:01:38  lr: 0.000038  loss: 0.7208 (0.7430)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:656]  [120/172]  eta: 0:01:22  lr: 0.000038  loss: 0.7461 (0.7426)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:656]  [130/172]  eta: 0:01:06  lr: 0.000038  loss: 0.7178 (0.7417)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [140/172]  eta: 0:00:50  lr: 0.000038  loss: 0.7322 (0.7435)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [150/172]  eta: 0:00:34  lr: 0.000038  loss: 0.7481 (0.7435)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:656]  [160/172]  eta: 0:00:19  lr: 0.000038  loss: 0.7371 (0.7434)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [170/172]  eta: 0:00:03  lr: 0.000038  loss: 0.7383 (0.7438)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656]  [171/172]  eta: 0:00:01  lr: 0.000038  loss: 0.7383 (0.7447)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:656] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000038  loss: 0.7383 (0.7447)\n",
      "Valid: [epoch:656]  [ 0/14]  eta: 0:00:04  loss: 0.7316 (0.7316)  time: 0.3295  data: 0.3121  max mem: 20571\n",
      "Valid: [epoch:656]  [13/14]  eta: 0:00:00  loss: 0.6984 (0.7059)  time: 0.0390  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:656] Total time: 0:00:00 (0.0474 s / it)\n",
      "Averaged stats: loss: 0.6984 (0.7059)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_656_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.706%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:657]  [  0/172]  eta: 0:08:08  lr: 0.000038  loss: 0.7025 (0.7025)  time: 2.8404  data: 1.2632  max mem: 20571\n",
      "Train: [epoch:657]  [ 10/172]  eta: 0:04:33  lr: 0.000038  loss: 0.7297 (0.7311)  time: 1.6913  data: 0.1150  max mem: 20571\n",
      "Train: [epoch:657]  [ 20/172]  eta: 0:04:08  lr: 0.000038  loss: 0.7362 (0.7405)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:657]  [ 30/172]  eta: 0:03:49  lr: 0.000038  loss: 0.7362 (0.7383)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:657]  [ 40/172]  eta: 0:03:32  lr: 0.000038  loss: 0.7487 (0.7430)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:657]  [ 50/172]  eta: 0:03:15  lr: 0.000038  loss: 0.7454 (0.7392)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:657]  [ 60/172]  eta: 0:02:59  lr: 0.000038  loss: 0.7301 (0.7393)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:657]  [ 70/172]  eta: 0:02:42  lr: 0.000038  loss: 0.7322 (0.7391)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [ 80/172]  eta: 0:02:26  lr: 0.000038  loss: 0.7342 (0.7393)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [ 90/172]  eta: 0:02:10  lr: 0.000038  loss: 0.7326 (0.7389)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:657]  [100/172]  eta: 0:01:54  lr: 0.000038  loss: 0.7421 (0.7395)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [110/172]  eta: 0:01:38  lr: 0.000038  loss: 0.7421 (0.7396)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [120/172]  eta: 0:01:22  lr: 0.000038  loss: 0.7401 (0.7417)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [130/172]  eta: 0:01:06  lr: 0.000038  loss: 0.7758 (0.7438)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [140/172]  eta: 0:00:50  lr: 0.000038  loss: 0.7581 (0.7431)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [150/172]  eta: 0:00:34  lr: 0.000038  loss: 0.7435 (0.7450)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [160/172]  eta: 0:00:19  lr: 0.000038  loss: 0.7523 (0.7455)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [170/172]  eta: 0:00:03  lr: 0.000038  loss: 0.7631 (0.7475)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657]  [171/172]  eta: 0:00:01  lr: 0.000038  loss: 0.7631 (0.7468)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:657] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000038  loss: 0.7631 (0.7468)\n",
      "Valid: [epoch:657]  [ 0/14]  eta: 0:00:05  loss: 0.7177 (0.7177)  time: 0.4232  data: 0.4077  max mem: 20571\n",
      "Valid: [epoch:657]  [13/14]  eta: 0:00:00  loss: 0.7177 (0.7252)  time: 0.0457  data: 0.0308  max mem: 20571\n",
      "Valid: [epoch:657] Total time: 0:00:00 (0.0508 s / it)\n",
      "Averaged stats: loss: 0.7177 (0.7252)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_657_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.725%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:658]  [  0/172]  eta: 0:07:46  lr: 0.000038  loss: 0.7669 (0.7669)  time: 2.7144  data: 1.1448  max mem: 20571\n",
      "Train: [epoch:658]  [ 10/172]  eta: 0:04:32  lr: 0.000038  loss: 0.7466 (0.7575)  time: 1.6830  data: 0.1042  max mem: 20571\n",
      "Train: [epoch:658]  [ 20/172]  eta: 0:04:08  lr: 0.000038  loss: 0.7411 (0.7511)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [ 30/172]  eta: 0:03:49  lr: 0.000038  loss: 0.7375 (0.7459)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [ 40/172]  eta: 0:03:32  lr: 0.000038  loss: 0.7375 (0.7420)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [ 50/172]  eta: 0:03:15  lr: 0.000038  loss: 0.7393 (0.7403)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [ 60/172]  eta: 0:02:59  lr: 0.000038  loss: 0.7470 (0.7437)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [ 70/172]  eta: 0:02:42  lr: 0.000038  loss: 0.7487 (0.7454)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [ 80/172]  eta: 0:02:26  lr: 0.000038  loss: 0.7365 (0.7454)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [ 90/172]  eta: 0:02:10  lr: 0.000038  loss: 0.7193 (0.7460)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [100/172]  eta: 0:01:54  lr: 0.000038  loss: 0.7488 (0.7465)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [110/172]  eta: 0:01:38  lr: 0.000038  loss: 0.7411 (0.7460)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [120/172]  eta: 0:01:22  lr: 0.000038  loss: 0.7396 (0.7466)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [130/172]  eta: 0:01:06  lr: 0.000038  loss: 0.7441 (0.7468)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [140/172]  eta: 0:00:50  lr: 0.000038  loss: 0.7153 (0.7445)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [150/172]  eta: 0:00:34  lr: 0.000038  loss: 0.7183 (0.7452)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [160/172]  eta: 0:00:19  lr: 0.000038  loss: 0.7512 (0.7463)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [170/172]  eta: 0:00:03  lr: 0.000038  loss: 0.7539 (0.7469)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658]  [171/172]  eta: 0:00:01  lr: 0.000038  loss: 0.7556 (0.7476)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:658] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000038  loss: 0.7556 (0.7476)\n",
      "Valid: [epoch:658]  [ 0/14]  eta: 0:00:04  loss: 0.6937 (0.6937)  time: 0.3531  data: 0.3352  max mem: 20571\n",
      "Valid: [epoch:658]  [13/14]  eta: 0:00:00  loss: 0.6986 (0.7065)  time: 0.0398  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:658] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 0.6986 (0.7065)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_658_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.707%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:659]  [  0/172]  eta: 0:07:49  lr: 0.000038  loss: 0.6881 (0.6881)  time: 2.7274  data: 1.1539  max mem: 20571\n",
      "Train: [epoch:659]  [ 10/172]  eta: 0:04:32  lr: 0.000038  loss: 0.7525 (0.7481)  time: 1.6808  data: 0.1050  max mem: 20571\n",
      "Train: [epoch:659]  [ 20/172]  eta: 0:04:08  lr: 0.000038  loss: 0.7442 (0.7469)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [ 30/172]  eta: 0:03:49  lr: 0.000038  loss: 0.7371 (0.7434)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [ 40/172]  eta: 0:03:32  lr: 0.000038  loss: 0.7345 (0.7431)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [ 50/172]  eta: 0:03:15  lr: 0.000038  loss: 0.7323 (0.7413)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [ 60/172]  eta: 0:02:58  lr: 0.000038  loss: 0.7309 (0.7406)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [ 70/172]  eta: 0:02:42  lr: 0.000038  loss: 0.7515 (0.7415)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [ 80/172]  eta: 0:02:26  lr: 0.000038  loss: 0.7382 (0.7403)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [ 90/172]  eta: 0:02:10  lr: 0.000038  loss: 0.7385 (0.7408)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [100/172]  eta: 0:01:54  lr: 0.000038  loss: 0.7379 (0.7392)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [110/172]  eta: 0:01:38  lr: 0.000038  loss: 0.7379 (0.7392)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [120/172]  eta: 0:01:22  lr: 0.000038  loss: 0.7408 (0.7406)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [130/172]  eta: 0:01:06  lr: 0.000038  loss: 0.7468 (0.7413)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [140/172]  eta: 0:00:50  lr: 0.000038  loss: 0.7377 (0.7411)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [150/172]  eta: 0:00:34  lr: 0.000038  loss: 0.7455 (0.7431)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [160/172]  eta: 0:00:19  lr: 0.000038  loss: 0.7707 (0.7457)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659]  [170/172]  eta: 0:00:03  lr: 0.000038  loss: 0.7654 (0.7462)  time: 1.5802  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:659]  [171/172]  eta: 0:00:01  lr: 0.000038  loss: 0.7654 (0.7467)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:659] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000038  loss: 0.7654 (0.7467)\n",
      "Valid: [epoch:659]  [ 0/14]  eta: 0:00:04  loss: 0.7450 (0.7450)  time: 0.3045  data: 0.2893  max mem: 20571\n",
      "Valid: [epoch:659]  [13/14]  eta: 0:00:00  loss: 0.7092 (0.7163)  time: 0.0386  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:659] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.7092 (0.7163)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_659_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.716%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:660]  [  0/172]  eta: 0:07:46  lr: 0.000038  loss: 0.6755 (0.6755)  time: 2.7118  data: 1.1455  max mem: 20571\n",
      "Train: [epoch:660]  [ 10/172]  eta: 0:04:32  lr: 0.000038  loss: 0.7387 (0.7363)  time: 1.6815  data: 0.1042  max mem: 20571\n",
      "Train: [epoch:660]  [ 20/172]  eta: 0:04:08  lr: 0.000038  loss: 0.7452 (0.7562)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [ 30/172]  eta: 0:03:49  lr: 0.000038  loss: 0.7203 (0.7421)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [ 40/172]  eta: 0:03:32  lr: 0.000038  loss: 0.7203 (0.7404)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [ 50/172]  eta: 0:03:15  lr: 0.000038  loss: 0.7234 (0.7415)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [ 60/172]  eta: 0:02:59  lr: 0.000038  loss: 0.7305 (0.7421)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [ 70/172]  eta: 0:02:42  lr: 0.000038  loss: 0.7281 (0.7421)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [ 80/172]  eta: 0:02:26  lr: 0.000038  loss: 0.7422 (0.7411)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [ 90/172]  eta: 0:02:10  lr: 0.000038  loss: 0.7366 (0.7406)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [100/172]  eta: 0:01:54  lr: 0.000038  loss: 0.7289 (0.7390)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [110/172]  eta: 0:01:38  lr: 0.000038  loss: 0.7468 (0.7411)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [120/172]  eta: 0:01:22  lr: 0.000038  loss: 0.7604 (0.7422)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [130/172]  eta: 0:01:06  lr: 0.000038  loss: 0.7486 (0.7424)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [140/172]  eta: 0:00:50  lr: 0.000038  loss: 0.7486 (0.7432)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [150/172]  eta: 0:00:34  lr: 0.000038  loss: 0.7566 (0.7437)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [160/172]  eta: 0:00:19  lr: 0.000038  loss: 0.7568 (0.7447)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [170/172]  eta: 0:00:03  lr: 0.000038  loss: 0.7358 (0.7446)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660]  [171/172]  eta: 0:00:01  lr: 0.000038  loss: 0.7358 (0.7448)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:660] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000038  loss: 0.7358 (0.7448)\n",
      "Valid: [epoch:660]  [ 0/14]  eta: 0:00:05  loss: 0.7727 (0.7727)  time: 0.3774  data: 0.3589  max mem: 20571\n",
      "Valid: [epoch:660]  [13/14]  eta: 0:00:00  loss: 0.7076 (0.7166)  time: 0.0410  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:660] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.7076 (0.7166)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_660_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.717%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:661]  [  0/172]  eta: 0:08:07  lr: 0.000038  loss: 0.7768 (0.7768)  time: 2.8322  data: 1.2530  max mem: 20571\n",
      "Train: [epoch:661]  [ 10/172]  eta: 0:04:33  lr: 0.000038  loss: 0.7592 (0.7652)  time: 1.6894  data: 0.1140  max mem: 20571\n",
      "Train: [epoch:661]  [ 20/172]  eta: 0:04:08  lr: 0.000038  loss: 0.7592 (0.7627)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [ 30/172]  eta: 0:03:49  lr: 0.000038  loss: 0.7361 (0.7538)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [ 40/172]  eta: 0:03:32  lr: 0.000038  loss: 0.7403 (0.7515)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [ 50/172]  eta: 0:03:15  lr: 0.000038  loss: 0.7426 (0.7503)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [ 60/172]  eta: 0:02:59  lr: 0.000038  loss: 0.7571 (0.7523)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [ 70/172]  eta: 0:02:42  lr: 0.000038  loss: 0.7593 (0.7525)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [ 80/172]  eta: 0:02:26  lr: 0.000038  loss: 0.7639 (0.7543)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [ 90/172]  eta: 0:02:10  lr: 0.000038  loss: 0.7499 (0.7540)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [100/172]  eta: 0:01:54  lr: 0.000038  loss: 0.7364 (0.7527)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [110/172]  eta: 0:01:38  lr: 0.000038  loss: 0.7322 (0.7514)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [120/172]  eta: 0:01:22  lr: 0.000038  loss: 0.7337 (0.7525)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [130/172]  eta: 0:01:06  lr: 0.000038  loss: 0.7623 (0.7529)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [140/172]  eta: 0:00:50  lr: 0.000038  loss: 0.7540 (0.7528)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [150/172]  eta: 0:00:34  lr: 0.000038  loss: 0.7463 (0.7528)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [160/172]  eta: 0:00:19  lr: 0.000038  loss: 0.7393 (0.7520)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [170/172]  eta: 0:00:03  lr: 0.000038  loss: 0.7324 (0.7503)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661]  [171/172]  eta: 0:00:01  lr: 0.000038  loss: 0.7324 (0.7504)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:661] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000038  loss: 0.7324 (0.7504)\n",
      "Valid: [epoch:661]  [ 0/14]  eta: 0:00:04  loss: 0.7057 (0.7057)  time: 0.3424  data: 0.3277  max mem: 20571\n",
      "Valid: [epoch:661]  [13/14]  eta: 0:00:00  loss: 0.7187 (0.7275)  time: 0.0398  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:661] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.7187 (0.7275)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_661_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.727%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:662]  [  0/172]  eta: 0:07:14  lr: 0.000038  loss: 0.7380 (0.7380)  time: 2.5284  data: 0.9598  max mem: 20571\n",
      "Train: [epoch:662]  [ 10/172]  eta: 0:04:29  lr: 0.000038  loss: 0.7452 (0.7475)  time: 1.6644  data: 0.0874  max mem: 20571\n",
      "Train: [epoch:662]  [ 20/172]  eta: 0:04:06  lr: 0.000038  loss: 0.7372 (0.7397)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [ 30/172]  eta: 0:03:48  lr: 0.000038  loss: 0.7179 (0.7359)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [ 40/172]  eta: 0:03:31  lr: 0.000038  loss: 0.7572 (0.7455)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [ 50/172]  eta: 0:03:15  lr: 0.000038  loss: 0.7655 (0.7482)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [ 60/172]  eta: 0:02:58  lr: 0.000038  loss: 0.7436 (0.7482)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [ 70/172]  eta: 0:02:42  lr: 0.000038  loss: 0.7435 (0.7480)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [ 80/172]  eta: 0:02:26  lr: 0.000038  loss: 0.7558 (0.7500)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [ 90/172]  eta: 0:02:10  lr: 0.000038  loss: 0.7531 (0.7484)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [100/172]  eta: 0:01:54  lr: 0.000038  loss: 0.7263 (0.7476)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [110/172]  eta: 0:01:38  lr: 0.000038  loss: 0.7424 (0.7488)  time: 1.5816  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:662]  [120/172]  eta: 0:01:22  lr: 0.000038  loss: 0.7503 (0.7489)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [130/172]  eta: 0:01:06  lr: 0.000038  loss: 0.7542 (0.7507)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [140/172]  eta: 0:00:50  lr: 0.000038  loss: 0.7542 (0.7516)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [150/172]  eta: 0:00:34  lr: 0.000038  loss: 0.7449 (0.7502)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [160/172]  eta: 0:00:19  lr: 0.000038  loss: 0.7251 (0.7494)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [170/172]  eta: 0:00:03  lr: 0.000038  loss: 0.7439 (0.7505)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662]  [171/172]  eta: 0:00:01  lr: 0.000038  loss: 0.7538 (0.7507)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:662] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000038  loss: 0.7538 (0.7507)\n",
      "Valid: [epoch:662]  [ 0/14]  eta: 0:00:04  loss: 0.7636 (0.7636)  time: 0.3304  data: 0.3139  max mem: 20571\n",
      "Valid: [epoch:662]  [13/14]  eta: 0:00:00  loss: 0.7255 (0.7297)  time: 0.0665  data: 0.0422  max mem: 20571\n",
      "Valid: [epoch:662] Total time: 0:00:01 (0.0747 s / it)\n",
      "Averaged stats: loss: 0.7255 (0.7297)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_662_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.730%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:663]  [  0/172]  eta: 0:08:13  lr: 0.000038  loss: 0.7401 (0.7401)  time: 2.8698  data: 1.2986  max mem: 20571\n",
      "Train: [epoch:663]  [ 10/172]  eta: 0:04:34  lr: 0.000038  loss: 0.7471 (0.7444)  time: 1.6944  data: 0.1183  max mem: 20571\n",
      "Train: [epoch:663]  [ 20/172]  eta: 0:04:09  lr: 0.000038  loss: 0.7544 (0.7510)  time: 1.5773  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:663]  [ 30/172]  eta: 0:03:50  lr: 0.000038  loss: 0.7412 (0.7436)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [ 40/172]  eta: 0:03:32  lr: 0.000038  loss: 0.7410 (0.7436)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:663]  [ 50/172]  eta: 0:03:15  lr: 0.000038  loss: 0.7470 (0.7450)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:663]  [ 60/172]  eta: 0:02:59  lr: 0.000038  loss: 0.7321 (0.7460)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:663]  [ 70/172]  eta: 0:02:42  lr: 0.000038  loss: 0.7497 (0.7481)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [ 80/172]  eta: 0:02:26  lr: 0.000038  loss: 0.7563 (0.7487)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [ 90/172]  eta: 0:02:10  lr: 0.000038  loss: 0.7417 (0.7484)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [100/172]  eta: 0:01:54  lr: 0.000038  loss: 0.7417 (0.7496)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [110/172]  eta: 0:01:38  lr: 0.000038  loss: 0.7522 (0.7493)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [120/172]  eta: 0:01:22  lr: 0.000038  loss: 0.7539 (0.7494)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [130/172]  eta: 0:01:06  lr: 0.000038  loss: 0.7400 (0.7475)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [140/172]  eta: 0:00:50  lr: 0.000038  loss: 0.7404 (0.7492)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [150/172]  eta: 0:00:34  lr: 0.000038  loss: 0.7638 (0.7508)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [160/172]  eta: 0:00:19  lr: 0.000038  loss: 0.7605 (0.7510)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [170/172]  eta: 0:00:03  lr: 0.000038  loss: 0.7291 (0.7498)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663]  [171/172]  eta: 0:00:01  lr: 0.000038  loss: 0.7303 (0.7500)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:663] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000038  loss: 0.7303 (0.7500)\n",
      "Valid: [epoch:663]  [ 0/14]  eta: 0:00:05  loss: 0.6459 (0.6459)  time: 0.3892  data: 0.3738  max mem: 20571\n",
      "Valid: [epoch:663]  [13/14]  eta: 0:00:00  loss: 0.7150 (0.7226)  time: 0.0435  data: 0.0283  max mem: 20571\n",
      "Valid: [epoch:663] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.7150 (0.7226)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_663_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.723%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:664]  [  0/172]  eta: 0:08:30  lr: 0.000037  loss: 0.7745 (0.7745)  time: 2.9695  data: 1.4018  max mem: 20571\n",
      "Train: [epoch:664]  [ 10/172]  eta: 0:04:36  lr: 0.000037  loss: 0.7745 (0.7721)  time: 1.7057  data: 0.1276  max mem: 20571\n",
      "Train: [epoch:664]  [ 20/172]  eta: 0:04:10  lr: 0.000037  loss: 0.7486 (0.7726)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:664]  [ 30/172]  eta: 0:03:50  lr: 0.000037  loss: 0.7376 (0.7620)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:664]  [ 40/172]  eta: 0:03:33  lr: 0.000037  loss: 0.7339 (0.7587)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [ 50/172]  eta: 0:03:16  lr: 0.000037  loss: 0.7339 (0.7582)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [ 60/172]  eta: 0:02:59  lr: 0.000037  loss: 0.7393 (0.7587)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [ 70/172]  eta: 0:02:43  lr: 0.000037  loss: 0.7528 (0.7581)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [ 80/172]  eta: 0:02:26  lr: 0.000037  loss: 0.7528 (0.7581)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [ 90/172]  eta: 0:02:10  lr: 0.000037  loss: 0.7532 (0.7573)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [100/172]  eta: 0:01:54  lr: 0.000037  loss: 0.7488 (0.7576)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [110/172]  eta: 0:01:38  lr: 0.000037  loss: 0.7489 (0.7566)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [120/172]  eta: 0:01:22  lr: 0.000037  loss: 0.7489 (0.7561)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [130/172]  eta: 0:01:06  lr: 0.000037  loss: 0.7594 (0.7575)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [140/172]  eta: 0:00:50  lr: 0.000037  loss: 0.7307 (0.7560)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [150/172]  eta: 0:00:34  lr: 0.000037  loss: 0.7197 (0.7556)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:664]  [160/172]  eta: 0:00:19  lr: 0.000037  loss: 0.7358 (0.7543)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:664]  [170/172]  eta: 0:00:03  lr: 0.000037  loss: 0.7375 (0.7541)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:664]  [171/172]  eta: 0:00:01  lr: 0.000037  loss: 0.7375 (0.7542)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:664] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000037  loss: 0.7375 (0.7542)\n",
      "Valid: [epoch:664]  [ 0/14]  eta: 0:00:06  loss: 0.7128 (0.7128)  time: 0.4376  data: 0.4199  max mem: 20571\n",
      "Valid: [epoch:664]  [13/14]  eta: 0:00:00  loss: 0.7168 (0.7261)  time: 0.0460  data: 0.0309  max mem: 20571\n",
      "Valid: [epoch:664] Total time: 0:00:00 (0.0511 s / it)\n",
      "Averaged stats: loss: 0.7168 (0.7261)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_664_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.726%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:665]  [  0/172]  eta: 0:07:23  lr: 0.000037  loss: 0.7398 (0.7398)  time: 2.5795  data: 1.0057  max mem: 20571\n",
      "Train: [epoch:665]  [ 10/172]  eta: 0:04:30  lr: 0.000037  loss: 0.7398 (0.7343)  time: 1.6679  data: 0.0915  max mem: 20571\n",
      "Train: [epoch:665]  [ 20/172]  eta: 0:04:06  lr: 0.000037  loss: 0.7417 (0.7443)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [ 30/172]  eta: 0:03:48  lr: 0.000037  loss: 0.7443 (0.7430)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [ 40/172]  eta: 0:03:31  lr: 0.000037  loss: 0.7513 (0.7481)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [ 50/172]  eta: 0:03:14  lr: 0.000037  loss: 0.7385 (0.7466)  time: 1.5793  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:665]  [ 60/172]  eta: 0:02:58  lr: 0.000037  loss: 0.7312 (0.7464)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [ 70/172]  eta: 0:02:42  lr: 0.000037  loss: 0.7320 (0.7468)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [ 80/172]  eta: 0:02:26  lr: 0.000037  loss: 0.7330 (0.7453)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [ 90/172]  eta: 0:02:10  lr: 0.000037  loss: 0.7429 (0.7469)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [100/172]  eta: 0:01:54  lr: 0.000037  loss: 0.7579 (0.7483)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [110/172]  eta: 0:01:38  lr: 0.000037  loss: 0.7423 (0.7492)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [120/172]  eta: 0:01:22  lr: 0.000037  loss: 0.7416 (0.7490)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [130/172]  eta: 0:01:06  lr: 0.000037  loss: 0.7472 (0.7492)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [140/172]  eta: 0:00:50  lr: 0.000037  loss: 0.7547 (0.7504)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [150/172]  eta: 0:00:34  lr: 0.000037  loss: 0.7556 (0.7506)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [160/172]  eta: 0:00:19  lr: 0.000037  loss: 0.7343 (0.7506)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [170/172]  eta: 0:00:03  lr: 0.000037  loss: 0.7474 (0.7504)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665]  [171/172]  eta: 0:00:01  lr: 0.000037  loss: 0.7487 (0.7508)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:665] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000037  loss: 0.7487 (0.7508)\n",
      "Valid: [epoch:665]  [ 0/14]  eta: 0:00:04  loss: 0.7503 (0.7503)  time: 0.2930  data: 0.2762  max mem: 20571\n",
      "Valid: [epoch:665]  [13/14]  eta: 0:00:00  loss: 0.7090 (0.7156)  time: 0.0488  data: 0.0336  max mem: 20571\n",
      "Valid: [epoch:665] Total time: 0:00:00 (0.0555 s / it)\n",
      "Averaged stats: loss: 0.7090 (0.7156)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_665_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.716%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:666]  [  0/172]  eta: 0:08:18  lr: 0.000037  loss: 0.6894 (0.6894)  time: 2.8960  data: 1.3308  max mem: 20571\n",
      "Train: [epoch:666]  [ 10/172]  eta: 0:04:35  lr: 0.000037  loss: 0.7410 (0.7357)  time: 1.6994  data: 0.1211  max mem: 20571\n",
      "Train: [epoch:666]  [ 20/172]  eta: 0:04:09  lr: 0.000037  loss: 0.7574 (0.7524)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:666]  [ 30/172]  eta: 0:03:50  lr: 0.000037  loss: 0.7574 (0.7539)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [ 40/172]  eta: 0:03:32  lr: 0.000037  loss: 0.7397 (0.7470)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [ 50/172]  eta: 0:03:15  lr: 0.000037  loss: 0.7417 (0.7504)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [ 60/172]  eta: 0:02:59  lr: 0.000037  loss: 0.7447 (0.7502)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [ 70/172]  eta: 0:02:43  lr: 0.000037  loss: 0.7391 (0.7516)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [ 80/172]  eta: 0:02:26  lr: 0.000037  loss: 0.7513 (0.7527)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [ 90/172]  eta: 0:02:10  lr: 0.000037  loss: 0.7505 (0.7533)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [100/172]  eta: 0:01:54  lr: 0.000037  loss: 0.7453 (0.7529)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [110/172]  eta: 0:01:38  lr: 0.000037  loss: 0.7488 (0.7529)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [120/172]  eta: 0:01:22  lr: 0.000037  loss: 0.7431 (0.7529)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [130/172]  eta: 0:01:06  lr: 0.000037  loss: 0.7431 (0.7525)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [140/172]  eta: 0:00:50  lr: 0.000037  loss: 0.7634 (0.7537)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [150/172]  eta: 0:00:34  lr: 0.000037  loss: 0.7759 (0.7547)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [160/172]  eta: 0:00:19  lr: 0.000037  loss: 0.7521 (0.7551)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [170/172]  eta: 0:00:03  lr: 0.000037  loss: 0.7541 (0.7549)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666]  [171/172]  eta: 0:00:01  lr: 0.000037  loss: 0.7521 (0.7547)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:666] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000037  loss: 0.7521 (0.7547)\n",
      "Valid: [epoch:666]  [ 0/14]  eta: 0:00:04  loss: 0.7085 (0.7085)  time: 0.3257  data: 0.3095  max mem: 20571\n",
      "Valid: [epoch:666]  [13/14]  eta: 0:00:00  loss: 0.7149 (0.7227)  time: 0.0381  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:666] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.7149 (0.7227)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_666_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.723%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:667]  [  0/172]  eta: 0:08:08  lr: 0.000037  loss: 0.7829 (0.7829)  time: 2.8385  data: 1.2645  max mem: 20571\n",
      "Train: [epoch:667]  [ 10/172]  eta: 0:04:34  lr: 0.000037  loss: 0.7575 (0.7674)  time: 1.6926  data: 0.1151  max mem: 20571\n",
      "Train: [epoch:667]  [ 20/172]  eta: 0:04:08  lr: 0.000037  loss: 0.7575 (0.7704)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:667]  [ 30/172]  eta: 0:03:49  lr: 0.000037  loss: 0.7363 (0.7599)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [ 40/172]  eta: 0:03:32  lr: 0.000037  loss: 0.7446 (0.7566)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [ 50/172]  eta: 0:03:15  lr: 0.000037  loss: 0.7476 (0.7550)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [ 60/172]  eta: 0:02:58  lr: 0.000037  loss: 0.7631 (0.7586)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [ 70/172]  eta: 0:02:42  lr: 0.000037  loss: 0.7712 (0.7599)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [ 80/172]  eta: 0:02:26  lr: 0.000037  loss: 0.7660 (0.7605)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [ 90/172]  eta: 0:02:10  lr: 0.000037  loss: 0.7719 (0.7622)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [100/172]  eta: 0:01:54  lr: 0.000037  loss: 0.7605 (0.7609)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [110/172]  eta: 0:01:38  lr: 0.000037  loss: 0.7521 (0.7609)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [120/172]  eta: 0:01:22  lr: 0.000037  loss: 0.7521 (0.7591)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [130/172]  eta: 0:01:06  lr: 0.000037  loss: 0.7309 (0.7580)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [140/172]  eta: 0:00:50  lr: 0.000037  loss: 0.7301 (0.7560)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [150/172]  eta: 0:00:34  lr: 0.000037  loss: 0.7492 (0.7575)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [160/172]  eta: 0:00:19  lr: 0.000037  loss: 0.7562 (0.7563)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [170/172]  eta: 0:00:03  lr: 0.000037  loss: 0.7357 (0.7557)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667]  [171/172]  eta: 0:00:01  lr: 0.000037  loss: 0.7376 (0.7556)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:667] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000037  loss: 0.7376 (0.7556)\n",
      "Valid: [epoch:667]  [ 0/14]  eta: 0:00:05  loss: 0.7420 (0.7420)  time: 0.4117  data: 0.3969  max mem: 20571\n",
      "Valid: [epoch:667]  [13/14]  eta: 0:00:00  loss: 0.7072 (0.7143)  time: 0.0445  data: 0.0296  max mem: 20571\n",
      "Valid: [epoch:667] Total time: 0:00:00 (0.0495 s / it)\n",
      "Averaged stats: loss: 0.7072 (0.7143)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_667_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.714%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:668]  [  0/172]  eta: 0:07:54  lr: 0.000037  loss: 0.7512 (0.7512)  time: 2.7579  data: 1.1936  max mem: 20571\n",
      "Train: [epoch:668]  [ 10/172]  eta: 0:04:32  lr: 0.000037  loss: 0.7473 (0.7503)  time: 1.6844  data: 0.1086  max mem: 20571\n",
      "Train: [epoch:668]  [ 20/172]  eta: 0:04:08  lr: 0.000037  loss: 0.7408 (0.7511)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [ 30/172]  eta: 0:03:49  lr: 0.000037  loss: 0.7521 (0.7585)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [ 40/172]  eta: 0:03:32  lr: 0.000037  loss: 0.7635 (0.7576)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [ 50/172]  eta: 0:03:15  lr: 0.000037  loss: 0.7644 (0.7559)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [ 60/172]  eta: 0:02:58  lr: 0.000037  loss: 0.7615 (0.7565)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [ 70/172]  eta: 0:02:42  lr: 0.000037  loss: 0.7398 (0.7522)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [ 80/172]  eta: 0:02:26  lr: 0.000037  loss: 0.7356 (0.7505)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [ 90/172]  eta: 0:02:10  lr: 0.000037  loss: 0.7413 (0.7496)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [100/172]  eta: 0:01:54  lr: 0.000037  loss: 0.7480 (0.7497)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [110/172]  eta: 0:01:38  lr: 0.000037  loss: 0.7531 (0.7511)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [120/172]  eta: 0:01:22  lr: 0.000037  loss: 0.7531 (0.7527)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [130/172]  eta: 0:01:06  lr: 0.000037  loss: 0.7423 (0.7521)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [140/172]  eta: 0:00:50  lr: 0.000037  loss: 0.7312 (0.7521)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [150/172]  eta: 0:00:34  lr: 0.000037  loss: 0.7678 (0.7533)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [160/172]  eta: 0:00:19  lr: 0.000037  loss: 0.7522 (0.7529)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [170/172]  eta: 0:00:03  lr: 0.000037  loss: 0.7522 (0.7545)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668]  [171/172]  eta: 0:00:01  lr: 0.000037  loss: 0.7522 (0.7541)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:668] Total time: 0:04:32 (1.5858 s / it)\n",
      "Averaged stats: lr: 0.000037  loss: 0.7522 (0.7541)\n",
      "Valid: [epoch:668]  [ 0/14]  eta: 0:00:04  loss: 0.7563 (0.7563)  time: 0.2876  data: 0.2720  max mem: 20571\n",
      "Valid: [epoch:668]  [13/14]  eta: 0:00:00  loss: 0.7124 (0.7194)  time: 0.0369  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:668] Total time: 0:00:00 (0.0416 s / it)\n",
      "Averaged stats: loss: 0.7124 (0.7194)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_668_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.719%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:669]  [  0/172]  eta: 0:07:17  lr: 0.000037  loss: 0.7416 (0.7416)  time: 2.5426  data: 0.9661  max mem: 20571\n",
      "Train: [epoch:669]  [ 10/172]  eta: 0:04:29  lr: 0.000037  loss: 0.7416 (0.7458)  time: 1.6631  data: 0.0879  max mem: 20571\n",
      "Train: [epoch:669]  [ 20/172]  eta: 0:04:06  lr: 0.000037  loss: 0.7495 (0.7595)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [ 30/172]  eta: 0:03:48  lr: 0.000037  loss: 0.7530 (0.7561)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [ 40/172]  eta: 0:03:31  lr: 0.000037  loss: 0.7316 (0.7498)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [ 50/172]  eta: 0:03:14  lr: 0.000037  loss: 0.7316 (0.7521)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [ 60/172]  eta: 0:02:58  lr: 0.000037  loss: 0.7644 (0.7540)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [ 70/172]  eta: 0:02:42  lr: 0.000037  loss: 0.7617 (0.7552)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [ 80/172]  eta: 0:02:26  lr: 0.000037  loss: 0.7644 (0.7552)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [ 90/172]  eta: 0:02:10  lr: 0.000037  loss: 0.7480 (0.7536)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [100/172]  eta: 0:01:54  lr: 0.000037  loss: 0.7394 (0.7535)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [110/172]  eta: 0:01:38  lr: 0.000037  loss: 0.7404 (0.7538)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:669]  [120/172]  eta: 0:01:22  lr: 0.000037  loss: 0.7567 (0.7539)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:669]  [130/172]  eta: 0:01:06  lr: 0.000037  loss: 0.7567 (0.7548)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [140/172]  eta: 0:00:50  lr: 0.000037  loss: 0.7621 (0.7560)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [150/172]  eta: 0:00:34  lr: 0.000037  loss: 0.7534 (0.7550)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [160/172]  eta: 0:00:19  lr: 0.000037  loss: 0.7505 (0.7558)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [170/172]  eta: 0:00:03  lr: 0.000037  loss: 0.7560 (0.7563)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669]  [171/172]  eta: 0:00:01  lr: 0.000037  loss: 0.7560 (0.7558)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:669] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000037  loss: 0.7560 (0.7558)\n",
      "Valid: [epoch:669]  [ 0/14]  eta: 0:00:04  loss: 0.6577 (0.6577)  time: 0.3149  data: 0.2987  max mem: 20571\n",
      "Valid: [epoch:669]  [13/14]  eta: 0:00:00  loss: 0.7282 (0.7356)  time: 0.0572  data: 0.0422  max mem: 20571\n",
      "Valid: [epoch:669] Total time: 0:00:00 (0.0654 s / it)\n",
      "Averaged stats: loss: 0.7282 (0.7356)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_669_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.736%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:670]  [  0/172]  eta: 0:08:07  lr: 0.000037  loss: 0.7728 (0.7728)  time: 2.8349  data: 1.2511  max mem: 20571\n",
      "Train: [epoch:670]  [ 10/172]  eta: 0:04:33  lr: 0.000037  loss: 0.7700 (0.7625)  time: 1.6913  data: 0.1139  max mem: 20571\n",
      "Train: [epoch:670]  [ 20/172]  eta: 0:04:09  lr: 0.000037  loss: 0.7431 (0.7549)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:670]  [ 30/172]  eta: 0:03:49  lr: 0.000037  loss: 0.7464 (0.7555)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:670]  [ 40/172]  eta: 0:03:32  lr: 0.000037  loss: 0.7498 (0.7510)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:670]  [ 50/172]  eta: 0:03:15  lr: 0.000037  loss: 0.7538 (0.7559)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [ 60/172]  eta: 0:02:59  lr: 0.000037  loss: 0.7705 (0.7566)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [ 70/172]  eta: 0:02:42  lr: 0.000037  loss: 0.7427 (0.7557)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [ 80/172]  eta: 0:02:26  lr: 0.000037  loss: 0.7552 (0.7564)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [ 90/172]  eta: 0:02:10  lr: 0.000037  loss: 0.7755 (0.7588)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [100/172]  eta: 0:01:54  lr: 0.000037  loss: 0.7521 (0.7594)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [110/172]  eta: 0:01:38  lr: 0.000037  loss: 0.7393 (0.7592)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [120/172]  eta: 0:01:22  lr: 0.000037  loss: 0.7393 (0.7590)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [130/172]  eta: 0:01:06  lr: 0.000037  loss: 0.7624 (0.7597)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [140/172]  eta: 0:00:50  lr: 0.000037  loss: 0.7455 (0.7576)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [150/172]  eta: 0:00:34  lr: 0.000037  loss: 0.7447 (0.7575)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [160/172]  eta: 0:00:19  lr: 0.000037  loss: 0.7634 (0.7579)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670]  [170/172]  eta: 0:00:03  lr: 0.000037  loss: 0.7634 (0.7576)  time: 1.5829  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:670]  [171/172]  eta: 0:00:01  lr: 0.000037  loss: 0.7634 (0.7577)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:670] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000037  loss: 0.7634 (0.7577)\n",
      "Valid: [epoch:670]  [ 0/14]  eta: 0:00:04  loss: 0.7619 (0.7619)  time: 0.2875  data: 0.2724  max mem: 20571\n",
      "Valid: [epoch:670]  [13/14]  eta: 0:00:00  loss: 0.7181 (0.7256)  time: 0.0479  data: 0.0328  max mem: 20571\n",
      "Valid: [epoch:670] Total time: 0:00:00 (0.0531 s / it)\n",
      "Averaged stats: loss: 0.7181 (0.7256)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_670_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.726%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:671]  [  0/172]  eta: 0:08:03  lr: 0.000037  loss: 0.8185 (0.8185)  time: 2.8087  data: 1.2280  max mem: 20571\n",
      "Train: [epoch:671]  [ 10/172]  eta: 0:04:33  lr: 0.000037  loss: 0.7646 (0.7638)  time: 1.6900  data: 0.1118  max mem: 20571\n",
      "Train: [epoch:671]  [ 20/172]  eta: 0:04:08  lr: 0.000037  loss: 0.7549 (0.7552)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [ 30/172]  eta: 0:03:49  lr: 0.000037  loss: 0.7470 (0.7523)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [ 40/172]  eta: 0:03:32  lr: 0.000037  loss: 0.7491 (0.7509)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [ 50/172]  eta: 0:03:15  lr: 0.000037  loss: 0.7454 (0.7536)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [ 60/172]  eta: 0:02:59  lr: 0.000037  loss: 0.7458 (0.7535)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [ 70/172]  eta: 0:02:42  lr: 0.000037  loss: 0.7465 (0.7538)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [ 80/172]  eta: 0:02:26  lr: 0.000037  loss: 0.7593 (0.7574)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [ 90/172]  eta: 0:02:10  lr: 0.000037  loss: 0.7593 (0.7574)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [100/172]  eta: 0:01:54  lr: 0.000037  loss: 0.7603 (0.7576)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [110/172]  eta: 0:01:38  lr: 0.000037  loss: 0.7472 (0.7567)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [120/172]  eta: 0:01:22  lr: 0.000037  loss: 0.7424 (0.7562)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [130/172]  eta: 0:01:06  lr: 0.000037  loss: 0.7359 (0.7563)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [140/172]  eta: 0:00:50  lr: 0.000037  loss: 0.7359 (0.7560)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [150/172]  eta: 0:00:34  lr: 0.000037  loss: 0.7683 (0.7561)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [160/172]  eta: 0:00:19  lr: 0.000037  loss: 0.7683 (0.7570)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [170/172]  eta: 0:00:03  lr: 0.000037  loss: 0.7612 (0.7576)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671]  [171/172]  eta: 0:00:01  lr: 0.000037  loss: 0.7567 (0.7575)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:671] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000037  loss: 0.7567 (0.7575)\n",
      "Valid: [epoch:671]  [ 0/14]  eta: 0:00:05  loss: 0.6449 (0.6449)  time: 0.3792  data: 0.3628  max mem: 20571\n",
      "Valid: [epoch:671]  [13/14]  eta: 0:00:00  loss: 0.7160 (0.7239)  time: 0.0423  data: 0.0271  max mem: 20571\n",
      "Valid: [epoch:671] Total time: 0:00:00 (0.0473 s / it)\n",
      "Averaged stats: loss: 0.7160 (0.7239)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_671_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.724%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:672]  [  0/172]  eta: 0:07:49  lr: 0.000037  loss: 0.7034 (0.7034)  time: 2.7285  data: 1.1630  max mem: 20571\n",
      "Train: [epoch:672]  [ 10/172]  eta: 0:04:32  lr: 0.000037  loss: 0.7393 (0.7387)  time: 1.6837  data: 0.1058  max mem: 20571\n",
      "Train: [epoch:672]  [ 20/172]  eta: 0:04:08  lr: 0.000037  loss: 0.7444 (0.7439)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [ 30/172]  eta: 0:03:49  lr: 0.000037  loss: 0.7539 (0.7475)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [ 40/172]  eta: 0:03:32  lr: 0.000037  loss: 0.7720 (0.7584)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [ 50/172]  eta: 0:03:15  lr: 0.000037  loss: 0.7818 (0.7600)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [ 60/172]  eta: 0:02:59  lr: 0.000037  loss: 0.7810 (0.7653)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [ 70/172]  eta: 0:02:42  lr: 0.000037  loss: 0.7776 (0.7664)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [ 80/172]  eta: 0:02:26  lr: 0.000037  loss: 0.7638 (0.7653)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [ 90/172]  eta: 0:02:10  lr: 0.000037  loss: 0.7596 (0.7652)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [100/172]  eta: 0:01:54  lr: 0.000037  loss: 0.7550 (0.7634)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:672]  [110/172]  eta: 0:01:38  lr: 0.000037  loss: 0.7450 (0.7629)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:672]  [120/172]  eta: 0:01:22  lr: 0.000037  loss: 0.7430 (0.7626)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [130/172]  eta: 0:01:06  lr: 0.000037  loss: 0.7466 (0.7610)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [140/172]  eta: 0:00:50  lr: 0.000037  loss: 0.7399 (0.7593)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [150/172]  eta: 0:00:34  lr: 0.000037  loss: 0.7369 (0.7582)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [160/172]  eta: 0:00:19  lr: 0.000037  loss: 0.7449 (0.7586)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [170/172]  eta: 0:00:03  lr: 0.000037  loss: 0.7578 (0.7581)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672]  [171/172]  eta: 0:00:01  lr: 0.000037  loss: 0.7596 (0.7585)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:672] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000037  loss: 0.7596 (0.7585)\n",
      "Valid: [epoch:672]  [ 0/14]  eta: 0:00:04  loss: 0.7124 (0.7124)  time: 0.3403  data: 0.3254  max mem: 20571\n",
      "Valid: [epoch:672]  [13/14]  eta: 0:00:00  loss: 0.7174 (0.7256)  time: 0.0394  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:672] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.7174 (0.7256)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_672_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.726%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:673]  [  0/172]  eta: 0:08:14  lr: 0.000036  loss: 0.7241 (0.7241)  time: 2.8731  data: 1.3016  max mem: 20571\n",
      "Train: [epoch:673]  [ 10/172]  eta: 0:04:34  lr: 0.000036  loss: 0.7563 (0.7710)  time: 1.6962  data: 0.1184  max mem: 20571\n",
      "Train: [epoch:673]  [ 20/172]  eta: 0:04:09  lr: 0.000036  loss: 0.7683 (0.7798)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [ 30/172]  eta: 0:03:50  lr: 0.000036  loss: 0.7359 (0.7690)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [ 40/172]  eta: 0:03:32  lr: 0.000036  loss: 0.7345 (0.7633)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [ 50/172]  eta: 0:03:15  lr: 0.000036  loss: 0.7597 (0.7694)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [ 60/172]  eta: 0:02:59  lr: 0.000036  loss: 0.7645 (0.7678)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [ 70/172]  eta: 0:02:43  lr: 0.000036  loss: 0.7588 (0.7672)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:673]  [ 80/172]  eta: 0:02:26  lr: 0.000036  loss: 0.7457 (0.7660)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [ 90/172]  eta: 0:02:10  lr: 0.000036  loss: 0.7437 (0.7640)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [100/172]  eta: 0:01:54  lr: 0.000036  loss: 0.7459 (0.7647)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [110/172]  eta: 0:01:38  lr: 0.000036  loss: 0.7525 (0.7649)  time: 1.5824  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:673]  [120/172]  eta: 0:01:22  lr: 0.000036  loss: 0.7525 (0.7653)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [130/172]  eta: 0:01:06  lr: 0.000036  loss: 0.7692 (0.7657)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [140/172]  eta: 0:00:50  lr: 0.000036  loss: 0.7692 (0.7645)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [150/172]  eta: 0:00:34  lr: 0.000036  loss: 0.7331 (0.7622)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [160/172]  eta: 0:00:19  lr: 0.000036  loss: 0.7413 (0.7620)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [170/172]  eta: 0:00:03  lr: 0.000036  loss: 0.7512 (0.7613)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673]  [171/172]  eta: 0:00:01  lr: 0.000036  loss: 0.7512 (0.7615)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:673] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000036  loss: 0.7512 (0.7615)\n",
      "Valid: [epoch:673]  [ 0/14]  eta: 0:00:05  loss: 0.7085 (0.7085)  time: 0.4228  data: 0.4066  max mem: 20571\n",
      "Valid: [epoch:673]  [13/14]  eta: 0:00:00  loss: 0.7147 (0.7216)  time: 0.0450  data: 0.0298  max mem: 20571\n",
      "Valid: [epoch:673] Total time: 0:00:00 (0.0501 s / it)\n",
      "Averaged stats: loss: 0.7147 (0.7216)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_673_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.722%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:674]  [  0/172]  eta: 0:07:27  lr: 0.000036  loss: 0.7381 (0.7381)  time: 2.5993  data: 1.0175  max mem: 20571\n",
      "Train: [epoch:674]  [ 10/172]  eta: 0:04:31  lr: 0.000036  loss: 0.7479 (0.7498)  time: 1.6763  data: 0.0926  max mem: 20571\n",
      "Train: [epoch:674]  [ 20/172]  eta: 0:04:07  lr: 0.000036  loss: 0.7479 (0.7441)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [ 30/172]  eta: 0:03:49  lr: 0.000036  loss: 0.7465 (0.7501)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [ 40/172]  eta: 0:03:32  lr: 0.000036  loss: 0.7380 (0.7483)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [ 50/172]  eta: 0:03:15  lr: 0.000036  loss: 0.7346 (0.7468)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [ 60/172]  eta: 0:02:59  lr: 0.000036  loss: 0.7487 (0.7511)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [ 70/172]  eta: 0:02:42  lr: 0.000036  loss: 0.7495 (0.7489)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [ 80/172]  eta: 0:02:26  lr: 0.000036  loss: 0.7627 (0.7531)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [ 90/172]  eta: 0:02:10  lr: 0.000036  loss: 0.7627 (0.7519)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [100/172]  eta: 0:01:54  lr: 0.000036  loss: 0.7719 (0.7567)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [110/172]  eta: 0:01:38  lr: 0.000036  loss: 0.7803 (0.7573)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [120/172]  eta: 0:01:22  lr: 0.000036  loss: 0.7701 (0.7593)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [130/172]  eta: 0:01:06  lr: 0.000036  loss: 0.7701 (0.7598)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [140/172]  eta: 0:00:50  lr: 0.000036  loss: 0.7495 (0.7597)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [150/172]  eta: 0:00:34  lr: 0.000036  loss: 0.7437 (0.7597)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [160/172]  eta: 0:00:19  lr: 0.000036  loss: 0.7599 (0.7598)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [170/172]  eta: 0:00:03  lr: 0.000036  loss: 0.7332 (0.7596)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674]  [171/172]  eta: 0:00:01  lr: 0.000036  loss: 0.7332 (0.7594)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:674] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000036  loss: 0.7332 (0.7594)\n",
      "Valid: [epoch:674]  [ 0/14]  eta: 0:00:05  loss: 0.7676 (0.7676)  time: 0.3944  data: 0.3783  max mem: 20571\n",
      "Valid: [epoch:674]  [13/14]  eta: 0:00:00  loss: 0.7310 (0.7395)  time: 0.0436  data: 0.0285  max mem: 20571\n",
      "Valid: [epoch:674] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.7310 (0.7395)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_674_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.740%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:675]  [  0/172]  eta: 0:07:56  lr: 0.000036  loss: 0.7718 (0.7718)  time: 2.7677  data: 1.1907  max mem: 20571\n",
      "Train: [epoch:675]  [ 10/172]  eta: 0:04:33  lr: 0.000036  loss: 0.7485 (0.7463)  time: 1.6871  data: 0.1083  max mem: 20571\n",
      "Train: [epoch:675]  [ 20/172]  eta: 0:04:08  lr: 0.000036  loss: 0.7321 (0.7502)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [ 30/172]  eta: 0:03:49  lr: 0.000036  loss: 0.7385 (0.7523)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [ 40/172]  eta: 0:03:32  lr: 0.000036  loss: 0.7704 (0.7563)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [ 50/172]  eta: 0:03:15  lr: 0.000036  loss: 0.7567 (0.7569)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [ 60/172]  eta: 0:02:59  lr: 0.000036  loss: 0.7553 (0.7570)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [ 70/172]  eta: 0:02:42  lr: 0.000036  loss: 0.7516 (0.7581)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [ 80/172]  eta: 0:02:26  lr: 0.000036  loss: 0.7563 (0.7599)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:675]  [ 90/172]  eta: 0:02:10  lr: 0.000036  loss: 0.7638 (0.7612)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [100/172]  eta: 0:01:54  lr: 0.000036  loss: 0.7656 (0.7626)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [110/172]  eta: 0:01:38  lr: 0.000036  loss: 0.7651 (0.7626)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [120/172]  eta: 0:01:22  lr: 0.000036  loss: 0.7489 (0.7625)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [130/172]  eta: 0:01:06  lr: 0.000036  loss: 0.7596 (0.7636)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [140/172]  eta: 0:00:50  lr: 0.000036  loss: 0.7653 (0.7642)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [150/172]  eta: 0:00:34  lr: 0.000036  loss: 0.7525 (0.7625)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [160/172]  eta: 0:00:19  lr: 0.000036  loss: 0.7398 (0.7627)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [170/172]  eta: 0:00:03  lr: 0.000036  loss: 0.7435 (0.7639)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675]  [171/172]  eta: 0:00:01  lr: 0.000036  loss: 0.7435 (0.7639)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:675] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000036  loss: 0.7435 (0.7639)\n",
      "Valid: [epoch:675]  [ 0/14]  eta: 0:00:04  loss: 0.7612 (0.7612)  time: 0.2901  data: 0.2735  max mem: 20571\n",
      "Valid: [epoch:675]  [13/14]  eta: 0:00:00  loss: 0.7176 (0.7256)  time: 0.0367  data: 0.0217  max mem: 20571\n",
      "Valid: [epoch:675] Total time: 0:00:00 (0.0444 s / it)\n",
      "Averaged stats: loss: 0.7176 (0.7256)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_675_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.726%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:676]  [  0/172]  eta: 0:07:39  lr: 0.000036  loss: 0.7092 (0.7092)  time: 2.6697  data: 1.1015  max mem: 20571\n",
      "Train: [epoch:676]  [ 10/172]  eta: 0:04:31  lr: 0.000036  loss: 0.7467 (0.7474)  time: 1.6783  data: 0.1003  max mem: 20571\n",
      "Train: [epoch:676]  [ 20/172]  eta: 0:04:07  lr: 0.000036  loss: 0.7582 (0.7684)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [ 30/172]  eta: 0:03:49  lr: 0.000036  loss: 0.7594 (0.7675)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:676]  [ 40/172]  eta: 0:03:32  lr: 0.000036  loss: 0.7438 (0.7605)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:676]  [ 50/172]  eta: 0:03:15  lr: 0.000036  loss: 0.7387 (0.7603)  time: 1.5825  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:676]  [ 60/172]  eta: 0:02:59  lr: 0.000036  loss: 0.7706 (0.7613)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [ 70/172]  eta: 0:02:42  lr: 0.000036  loss: 0.7681 (0.7610)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [ 80/172]  eta: 0:02:26  lr: 0.000036  loss: 0.7681 (0.7637)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [ 90/172]  eta: 0:02:10  lr: 0.000036  loss: 0.7503 (0.7619)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [100/172]  eta: 0:01:54  lr: 0.000036  loss: 0.7467 (0.7609)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [110/172]  eta: 0:01:38  lr: 0.000036  loss: 0.7721 (0.7631)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [120/172]  eta: 0:01:22  lr: 0.000036  loss: 0.7612 (0.7615)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [130/172]  eta: 0:01:06  lr: 0.000036  loss: 0.7493 (0.7622)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [140/172]  eta: 0:00:50  lr: 0.000036  loss: 0.7514 (0.7606)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [150/172]  eta: 0:00:34  lr: 0.000036  loss: 0.7509 (0.7607)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [160/172]  eta: 0:00:19  lr: 0.000036  loss: 0.7576 (0.7615)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [170/172]  eta: 0:00:03  lr: 0.000036  loss: 0.7802 (0.7624)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676]  [171/172]  eta: 0:00:01  lr: 0.000036  loss: 0.7802 (0.7623)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:676] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000036  loss: 0.7802 (0.7623)\n",
      "Valid: [epoch:676]  [ 0/14]  eta: 0:00:04  loss: 0.7152 (0.7152)  time: 0.2980  data: 0.2830  max mem: 20571\n",
      "Valid: [epoch:676]  [13/14]  eta: 0:00:00  loss: 0.7201 (0.7281)  time: 0.0382  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:676] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.7201 (0.7281)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_676_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.728%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:677]  [  0/172]  eta: 0:07:32  lr: 0.000036  loss: 0.7646 (0.7646)  time: 2.6297  data: 1.0420  max mem: 20571\n",
      "Train: [epoch:677]  [ 10/172]  eta: 0:04:31  lr: 0.000036  loss: 0.7690 (0.7683)  time: 1.6748  data: 0.0948  max mem: 20571\n",
      "Train: [epoch:677]  [ 20/172]  eta: 0:04:07  lr: 0.000036  loss: 0.7662 (0.7700)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [ 30/172]  eta: 0:03:49  lr: 0.000036  loss: 0.7593 (0.7725)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [ 40/172]  eta: 0:03:32  lr: 0.000036  loss: 0.7399 (0.7625)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [ 50/172]  eta: 0:03:15  lr: 0.000036  loss: 0.7399 (0.7591)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [ 60/172]  eta: 0:02:59  lr: 0.000036  loss: 0.7568 (0.7606)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [ 70/172]  eta: 0:02:42  lr: 0.000036  loss: 0.7568 (0.7606)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [ 80/172]  eta: 0:02:26  lr: 0.000036  loss: 0.7593 (0.7628)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [ 90/172]  eta: 0:02:10  lr: 0.000036  loss: 0.7806 (0.7636)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [100/172]  eta: 0:01:54  lr: 0.000036  loss: 0.7467 (0.7620)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [110/172]  eta: 0:01:38  lr: 0.000036  loss: 0.7536 (0.7644)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [120/172]  eta: 0:01:22  lr: 0.000036  loss: 0.7686 (0.7647)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [130/172]  eta: 0:01:06  lr: 0.000036  loss: 0.7658 (0.7644)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [140/172]  eta: 0:00:50  lr: 0.000036  loss: 0.7555 (0.7643)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [150/172]  eta: 0:00:34  lr: 0.000036  loss: 0.7483 (0.7632)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [160/172]  eta: 0:00:19  lr: 0.000036  loss: 0.7343 (0.7619)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [170/172]  eta: 0:00:03  lr: 0.000036  loss: 0.7513 (0.7624)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677]  [171/172]  eta: 0:00:01  lr: 0.000036  loss: 0.7501 (0.7622)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:677] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000036  loss: 0.7501 (0.7622)\n",
      "Valid: [epoch:677]  [ 0/14]  eta: 0:00:06  loss: 0.7586 (0.7586)  time: 0.4318  data: 0.4170  max mem: 20571\n",
      "Valid: [epoch:677]  [13/14]  eta: 0:00:00  loss: 0.7210 (0.7290)  time: 0.0456  data: 0.0305  max mem: 20571\n",
      "Valid: [epoch:677] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.7210 (0.7290)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_677_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.729%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:678]  [  0/172]  eta: 0:07:28  lr: 0.000036  loss: 0.7303 (0.7303)  time: 2.6062  data: 1.0389  max mem: 20571\n",
      "Train: [epoch:678]  [ 10/172]  eta: 0:04:31  lr: 0.000036  loss: 0.7514 (0.7547)  time: 1.6742  data: 0.0946  max mem: 20571\n",
      "Train: [epoch:678]  [ 20/172]  eta: 0:04:07  lr: 0.000036  loss: 0.7553 (0.7580)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:678]  [ 30/172]  eta: 0:03:49  lr: 0.000036  loss: 0.7515 (0.7544)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:678]  [ 40/172]  eta: 0:03:31  lr: 0.000036  loss: 0.7396 (0.7551)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [ 50/172]  eta: 0:03:15  lr: 0.000036  loss: 0.7437 (0.7551)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [ 60/172]  eta: 0:02:58  lr: 0.000036  loss: 0.7509 (0.7564)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [ 70/172]  eta: 0:02:42  lr: 0.000036  loss: 0.7595 (0.7580)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [ 80/172]  eta: 0:02:26  lr: 0.000036  loss: 0.7555 (0.7578)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [ 90/172]  eta: 0:02:10  lr: 0.000036  loss: 0.7609 (0.7604)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [100/172]  eta: 0:01:54  lr: 0.000036  loss: 0.7743 (0.7614)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [110/172]  eta: 0:01:38  lr: 0.000036  loss: 0.7703 (0.7618)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [120/172]  eta: 0:01:22  lr: 0.000036  loss: 0.7567 (0.7620)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [130/172]  eta: 0:01:06  lr: 0.000036  loss: 0.7803 (0.7637)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [140/172]  eta: 0:00:50  lr: 0.000036  loss: 0.7868 (0.7643)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [150/172]  eta: 0:00:34  lr: 0.000036  loss: 0.7453 (0.7634)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [160/172]  eta: 0:00:19  lr: 0.000036  loss: 0.7453 (0.7635)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [170/172]  eta: 0:00:03  lr: 0.000036  loss: 0.7783 (0.7649)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678]  [171/172]  eta: 0:00:01  lr: 0.000036  loss: 0.7661 (0.7647)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:678] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000036  loss: 0.7661 (0.7647)\n",
      "Valid: [epoch:678]  [ 0/14]  eta: 0:00:04  loss: 0.6882 (0.6882)  time: 0.3137  data: 0.2963  max mem: 20571\n",
      "Valid: [epoch:678]  [13/14]  eta: 0:00:00  loss: 0.7400 (0.7471)  time: 0.0372  data: 0.0220  max mem: 20571\n",
      "Valid: [epoch:678] Total time: 0:00:00 (0.0419 s / it)\n",
      "Averaged stats: loss: 0.7400 (0.7471)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_678_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.747%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:679]  [  0/172]  eta: 0:07:35  lr: 0.000036  loss: 0.7276 (0.7276)  time: 2.6455  data: 1.0606  max mem: 20571\n",
      "Train: [epoch:679]  [ 10/172]  eta: 0:04:31  lr: 0.000036  loss: 0.7284 (0.7481)  time: 1.6752  data: 0.0965  max mem: 20571\n",
      "Train: [epoch:679]  [ 20/172]  eta: 0:04:07  lr: 0.000036  loss: 0.7373 (0.7553)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [ 30/172]  eta: 0:03:49  lr: 0.000036  loss: 0.7573 (0.7601)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [ 40/172]  eta: 0:03:32  lr: 0.000036  loss: 0.7567 (0.7602)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [ 50/172]  eta: 0:03:15  lr: 0.000036  loss: 0.7855 (0.7696)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [ 60/172]  eta: 0:02:58  lr: 0.000036  loss: 0.7825 (0.7696)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [ 70/172]  eta: 0:02:42  lr: 0.000036  loss: 0.7662 (0.7706)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [ 80/172]  eta: 0:02:26  lr: 0.000036  loss: 0.7685 (0.7679)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [ 90/172]  eta: 0:02:10  lr: 0.000036  loss: 0.7613 (0.7680)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [100/172]  eta: 0:01:54  lr: 0.000036  loss: 0.7608 (0.7666)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [110/172]  eta: 0:01:38  lr: 0.000036  loss: 0.7372 (0.7642)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [120/172]  eta: 0:01:22  lr: 0.000036  loss: 0.7683 (0.7680)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [130/172]  eta: 0:01:06  lr: 0.000036  loss: 0.7801 (0.7674)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [140/172]  eta: 0:00:50  lr: 0.000036  loss: 0.7520 (0.7666)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [150/172]  eta: 0:00:34  lr: 0.000036  loss: 0.7553 (0.7662)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [160/172]  eta: 0:00:19  lr: 0.000036  loss: 0.7563 (0.7660)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [170/172]  eta: 0:00:03  lr: 0.000036  loss: 0.7624 (0.7663)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679]  [171/172]  eta: 0:00:01  lr: 0.000036  loss: 0.7649 (0.7669)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:679] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000036  loss: 0.7649 (0.7669)\n",
      "Valid: [epoch:679]  [ 0/14]  eta: 0:00:04  loss: 0.7633 (0.7633)  time: 0.3249  data: 0.3084  max mem: 20571\n",
      "Valid: [epoch:679]  [13/14]  eta: 0:00:00  loss: 0.7217 (0.7304)  time: 0.0387  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:679] Total time: 0:00:00 (0.0440 s / it)\n",
      "Averaged stats: loss: 0.7217 (0.7304)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_679_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.730%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:680]  [  0/172]  eta: 0:07:22  lr: 0.000036  loss: 0.7896 (0.7896)  time: 2.5729  data: 0.9870  max mem: 20571\n",
      "Train: [epoch:680]  [ 10/172]  eta: 0:04:30  lr: 0.000036  loss: 0.7517 (0.7523)  time: 1.6710  data: 0.0898  max mem: 20571\n",
      "Train: [epoch:680]  [ 20/172]  eta: 0:04:07  lr: 0.000036  loss: 0.7517 (0.7608)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [ 30/172]  eta: 0:03:49  lr: 0.000036  loss: 0.7608 (0.7606)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [ 40/172]  eta: 0:03:32  lr: 0.000036  loss: 0.7608 (0.7628)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [ 50/172]  eta: 0:03:15  lr: 0.000036  loss: 0.7655 (0.7644)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [ 60/172]  eta: 0:02:59  lr: 0.000036  loss: 0.7682 (0.7657)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [ 70/172]  eta: 0:02:42  lr: 0.000036  loss: 0.7650 (0.7647)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [ 80/172]  eta: 0:02:26  lr: 0.000036  loss: 0.7425 (0.7632)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [ 90/172]  eta: 0:02:10  lr: 0.000036  loss: 0.7445 (0.7636)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [100/172]  eta: 0:01:54  lr: 0.000036  loss: 0.7782 (0.7640)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [110/172]  eta: 0:01:38  lr: 0.000036  loss: 0.7717 (0.7654)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [120/172]  eta: 0:01:22  lr: 0.000036  loss: 0.7733 (0.7678)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [130/172]  eta: 0:01:06  lr: 0.000036  loss: 0.7701 (0.7681)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [140/172]  eta: 0:00:50  lr: 0.000036  loss: 0.7567 (0.7678)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [150/172]  eta: 0:00:34  lr: 0.000036  loss: 0.7606 (0.7679)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [160/172]  eta: 0:00:19  lr: 0.000036  loss: 0.7607 (0.7675)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [170/172]  eta: 0:00:03  lr: 0.000036  loss: 0.7568 (0.7673)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680]  [171/172]  eta: 0:00:01  lr: 0.000036  loss: 0.7568 (0.7672)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:680] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000036  loss: 0.7568 (0.7672)\n",
      "Valid: [epoch:680]  [ 0/14]  eta: 0:00:04  loss: 0.7556 (0.7556)  time: 0.3402  data: 0.3219  max mem: 20571\n",
      "Valid: [epoch:680]  [13/14]  eta: 0:00:00  loss: 0.7202 (0.7281)  time: 0.0395  data: 0.0242  max mem: 20571\n",
      "Valid: [epoch:680] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.7202 (0.7281)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_680_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.728%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:681]  [  0/172]  eta: 0:07:44  lr: 0.000036  loss: 0.7021 (0.7021)  time: 2.6993  data: 1.1187  max mem: 20571\n",
      "Train: [epoch:681]  [ 10/172]  eta: 0:04:31  lr: 0.000036  loss: 0.7565 (0.7505)  time: 1.6781  data: 0.1018  max mem: 20571\n",
      "Train: [epoch:681]  [ 20/172]  eta: 0:04:07  lr: 0.000036  loss: 0.7699 (0.7716)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [ 30/172]  eta: 0:03:49  lr: 0.000036  loss: 0.7726 (0.7641)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [ 40/172]  eta: 0:03:31  lr: 0.000036  loss: 0.7609 (0.7650)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [ 50/172]  eta: 0:03:15  lr: 0.000036  loss: 0.7341 (0.7613)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [ 60/172]  eta: 0:02:58  lr: 0.000036  loss: 0.7656 (0.7667)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [ 70/172]  eta: 0:02:42  lr: 0.000036  loss: 0.7726 (0.7669)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [ 80/172]  eta: 0:02:26  lr: 0.000036  loss: 0.7726 (0.7680)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [ 90/172]  eta: 0:02:10  lr: 0.000036  loss: 0.7546 (0.7648)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [100/172]  eta: 0:01:54  lr: 0.000036  loss: 0.7362 (0.7652)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [110/172]  eta: 0:01:38  lr: 0.000036  loss: 0.7540 (0.7656)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [120/172]  eta: 0:01:22  lr: 0.000036  loss: 0.7673 (0.7669)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [130/172]  eta: 0:01:06  lr: 0.000036  loss: 0.7673 (0.7661)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [140/172]  eta: 0:00:50  lr: 0.000036  loss: 0.7655 (0.7659)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [150/172]  eta: 0:00:34  lr: 0.000036  loss: 0.7722 (0.7671)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [160/172]  eta: 0:00:19  lr: 0.000036  loss: 0.7722 (0.7671)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681]  [170/172]  eta: 0:00:03  lr: 0.000036  loss: 0.7745 (0.7671)  time: 1.5784  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:681]  [171/172]  eta: 0:00:01  lr: 0.000036  loss: 0.7745 (0.7668)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:681] Total time: 0:04:32 (1.5847 s / it)\n",
      "Averaged stats: lr: 0.000036  loss: 0.7745 (0.7668)\n",
      "Valid: [epoch:681]  [ 0/14]  eta: 0:00:04  loss: 0.7483 (0.7483)  time: 0.3512  data: 0.3353  max mem: 20571\n",
      "Valid: [epoch:681]  [13/14]  eta: 0:00:00  loss: 0.7483 (0.7565)  time: 0.0400  data: 0.0249  max mem: 20571\n",
      "Valid: [epoch:681] Total time: 0:00:00 (0.0480 s / it)\n",
      "Averaged stats: loss: 0.7483 (0.7565)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_681_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.756%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:682]  [  0/172]  eta: 0:07:44  lr: 0.000035  loss: 0.8148 (0.8148)  time: 2.6993  data: 1.1167  max mem: 20571\n",
      "Train: [epoch:682]  [ 10/172]  eta: 0:04:31  lr: 0.000035  loss: 0.7976 (0.7860)  time: 1.6777  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:682]  [ 20/172]  eta: 0:04:07  lr: 0.000035  loss: 0.7722 (0.7782)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [ 30/172]  eta: 0:03:49  lr: 0.000035  loss: 0.7722 (0.7792)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [ 40/172]  eta: 0:03:31  lr: 0.000035  loss: 0.7643 (0.7740)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [ 50/172]  eta: 0:03:15  lr: 0.000035  loss: 0.7470 (0.7703)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [ 60/172]  eta: 0:02:58  lr: 0.000035  loss: 0.7470 (0.7674)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [ 70/172]  eta: 0:02:42  lr: 0.000035  loss: 0.7554 (0.7679)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [ 80/172]  eta: 0:02:26  lr: 0.000035  loss: 0.7723 (0.7713)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [ 90/172]  eta: 0:02:10  lr: 0.000035  loss: 0.7863 (0.7731)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [100/172]  eta: 0:01:54  lr: 0.000035  loss: 0.7806 (0.7729)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [110/172]  eta: 0:01:38  lr: 0.000035  loss: 0.7806 (0.7742)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [120/172]  eta: 0:01:22  lr: 0.000035  loss: 0.7907 (0.7758)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [130/172]  eta: 0:01:06  lr: 0.000035  loss: 0.7576 (0.7731)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [140/172]  eta: 0:00:50  lr: 0.000035  loss: 0.7499 (0.7735)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [150/172]  eta: 0:00:34  lr: 0.000035  loss: 0.7447 (0.7711)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [160/172]  eta: 0:00:19  lr: 0.000035  loss: 0.7507 (0.7710)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [170/172]  eta: 0:00:03  lr: 0.000035  loss: 0.7652 (0.7715)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682]  [171/172]  eta: 0:00:01  lr: 0.000035  loss: 0.7652 (0.7715)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:682] Total time: 0:04:32 (1.5845 s / it)\n",
      "Averaged stats: lr: 0.000035  loss: 0.7652 (0.7715)\n",
      "Valid: [epoch:682]  [ 0/14]  eta: 0:00:04  loss: 0.7055 (0.7055)  time: 0.2975  data: 0.2828  max mem: 20571\n",
      "Valid: [epoch:682]  [13/14]  eta: 0:00:00  loss: 0.7199 (0.7295)  time: 0.0380  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:682] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.7199 (0.7295)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_682_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.730%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:683]  [  0/172]  eta: 0:07:55  lr: 0.000035  loss: 0.7801 (0.7801)  time: 2.7657  data: 1.1839  max mem: 20571\n",
      "Train: [epoch:683]  [ 10/172]  eta: 0:04:32  lr: 0.000035  loss: 0.7354 (0.7548)  time: 1.6831  data: 0.1077  max mem: 20571\n",
      "Train: [epoch:683]  [ 20/172]  eta: 0:04:08  lr: 0.000035  loss: 0.7683 (0.7647)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [ 30/172]  eta: 0:03:49  lr: 0.000035  loss: 0.7746 (0.7748)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [ 40/172]  eta: 0:03:31  lr: 0.000035  loss: 0.7653 (0.7732)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [ 50/172]  eta: 0:03:15  lr: 0.000035  loss: 0.7553 (0.7731)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [ 60/172]  eta: 0:02:58  lr: 0.000035  loss: 0.7661 (0.7714)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [ 70/172]  eta: 0:02:42  lr: 0.000035  loss: 0.7637 (0.7689)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [ 80/172]  eta: 0:02:26  lr: 0.000035  loss: 0.7700 (0.7699)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [ 90/172]  eta: 0:02:10  lr: 0.000035  loss: 0.7700 (0.7702)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [100/172]  eta: 0:01:54  lr: 0.000035  loss: 0.7589 (0.7682)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [110/172]  eta: 0:01:38  lr: 0.000035  loss: 0.7558 (0.7677)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [120/172]  eta: 0:01:22  lr: 0.000035  loss: 0.7656 (0.7673)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [130/172]  eta: 0:01:06  lr: 0.000035  loss: 0.7693 (0.7678)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [140/172]  eta: 0:00:50  lr: 0.000035  loss: 0.7717 (0.7688)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [150/172]  eta: 0:00:34  lr: 0.000035  loss: 0.7629 (0.7685)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [160/172]  eta: 0:00:19  lr: 0.000035  loss: 0.7499 (0.7665)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [170/172]  eta: 0:00:03  lr: 0.000035  loss: 0.7563 (0.7668)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683]  [171/172]  eta: 0:00:01  lr: 0.000035  loss: 0.7567 (0.7671)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:683] Total time: 0:04:32 (1.5858 s / it)\n",
      "Averaged stats: lr: 0.000035  loss: 0.7567 (0.7671)\n",
      "Valid: [epoch:683]  [ 0/14]  eta: 0:00:03  loss: 0.7922 (0.7922)  time: 0.2764  data: 0.2618  max mem: 20571\n",
      "Valid: [epoch:683]  [13/14]  eta: 0:00:00  loss: 0.7248 (0.7320)  time: 0.0442  data: 0.0290  max mem: 20571\n",
      "Valid: [epoch:683] Total time: 0:00:00 (0.0488 s / it)\n",
      "Averaged stats: loss: 0.7248 (0.7320)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_683_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.732%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:684]  [  0/172]  eta: 0:08:07  lr: 0.000035  loss: 0.7840 (0.7840)  time: 2.8353  data: 1.2689  max mem: 20571\n",
      "Train: [epoch:684]  [ 10/172]  eta: 0:04:34  lr: 0.000035  loss: 0.7833 (0.7717)  time: 1.6933  data: 0.1155  max mem: 20571\n",
      "Train: [epoch:684]  [ 20/172]  eta: 0:04:09  lr: 0.000035  loss: 0.7702 (0.7713)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [ 30/172]  eta: 0:03:49  lr: 0.000035  loss: 0.7749 (0.7712)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [ 40/172]  eta: 0:03:32  lr: 0.000035  loss: 0.7577 (0.7676)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [ 50/172]  eta: 0:03:15  lr: 0.000035  loss: 0.7516 (0.7675)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [ 60/172]  eta: 0:02:59  lr: 0.000035  loss: 0.7582 (0.7653)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [ 70/172]  eta: 0:02:42  lr: 0.000035  loss: 0.7605 (0.7676)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [ 80/172]  eta: 0:02:26  lr: 0.000035  loss: 0.7819 (0.7713)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [ 90/172]  eta: 0:02:10  lr: 0.000035  loss: 0.7697 (0.7700)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [100/172]  eta: 0:01:54  lr: 0.000035  loss: 0.7527 (0.7705)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [110/172]  eta: 0:01:38  lr: 0.000035  loss: 0.7689 (0.7706)  time: 1.5795  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:684]  [120/172]  eta: 0:01:22  lr: 0.000035  loss: 0.7610 (0.7698)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [130/172]  eta: 0:01:06  lr: 0.000035  loss: 0.7532 (0.7682)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [140/172]  eta: 0:00:50  lr: 0.000035  loss: 0.7516 (0.7689)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [150/172]  eta: 0:00:34  lr: 0.000035  loss: 0.7822 (0.7710)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [160/172]  eta: 0:00:19  lr: 0.000035  loss: 0.7805 (0.7711)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [170/172]  eta: 0:00:03  lr: 0.000035  loss: 0.7671 (0.7704)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684]  [171/172]  eta: 0:00:01  lr: 0.000035  loss: 0.7590 (0.7700)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:684] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000035  loss: 0.7590 (0.7700)\n",
      "Valid: [epoch:684]  [ 0/14]  eta: 0:00:05  loss: 0.7604 (0.7604)  time: 0.3702  data: 0.3554  max mem: 20571\n",
      "Valid: [epoch:684]  [13/14]  eta: 0:00:00  loss: 0.7211 (0.7303)  time: 0.0410  data: 0.0261  max mem: 20571\n",
      "Valid: [epoch:684] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.7211 (0.7303)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_684_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.730%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:685]  [  0/172]  eta: 0:07:34  lr: 0.000035  loss: 0.8093 (0.8093)  time: 2.6401  data: 1.0603  max mem: 20571\n",
      "Train: [epoch:685]  [ 10/172]  eta: 0:04:30  lr: 0.000035  loss: 0.7544 (0.7649)  time: 1.6720  data: 0.0965  max mem: 20571\n",
      "Train: [epoch:685]  [ 20/172]  eta: 0:04:07  lr: 0.000035  loss: 0.7489 (0.7635)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [ 30/172]  eta: 0:03:48  lr: 0.000035  loss: 0.7563 (0.7632)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [ 40/172]  eta: 0:03:31  lr: 0.000035  loss: 0.7601 (0.7634)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [ 50/172]  eta: 0:03:14  lr: 0.000035  loss: 0.7720 (0.7662)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [ 60/172]  eta: 0:02:58  lr: 0.000035  loss: 0.7945 (0.7721)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [ 70/172]  eta: 0:02:42  lr: 0.000035  loss: 0.7851 (0.7724)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [ 80/172]  eta: 0:02:26  lr: 0.000035  loss: 0.7679 (0.7709)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [ 90/172]  eta: 0:02:10  lr: 0.000035  loss: 0.7633 (0.7694)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [100/172]  eta: 0:01:54  lr: 0.000035  loss: 0.7642 (0.7706)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [110/172]  eta: 0:01:38  lr: 0.000035  loss: 0.7723 (0.7701)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [120/172]  eta: 0:01:22  lr: 0.000035  loss: 0.7712 (0.7712)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [130/172]  eta: 0:01:06  lr: 0.000035  loss: 0.7712 (0.7714)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [140/172]  eta: 0:00:50  lr: 0.000035  loss: 0.7608 (0.7707)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [150/172]  eta: 0:00:34  lr: 0.000035  loss: 0.7582 (0.7702)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [160/172]  eta: 0:00:19  lr: 0.000035  loss: 0.7622 (0.7700)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [170/172]  eta: 0:00:03  lr: 0.000035  loss: 0.7622 (0.7696)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685]  [171/172]  eta: 0:00:01  lr: 0.000035  loss: 0.7597 (0.7695)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:685] Total time: 0:04:32 (1.5840 s / it)\n",
      "Averaged stats: lr: 0.000035  loss: 0.7597 (0.7695)\n",
      "Valid: [epoch:685]  [ 0/14]  eta: 0:00:04  loss: 0.7612 (0.7612)  time: 0.3189  data: 0.3032  max mem: 20571\n",
      "Valid: [epoch:685]  [13/14]  eta: 0:00:00  loss: 0.7261 (0.7341)  time: 0.0552  data: 0.0400  max mem: 20571\n",
      "Valid: [epoch:685] Total time: 0:00:00 (0.0641 s / it)\n",
      "Averaged stats: loss: 0.7261 (0.7341)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_685_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.734%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:686]  [  0/172]  eta: 0:07:32  lr: 0.000035  loss: 0.7976 (0.7976)  time: 2.6286  data: 1.0638  max mem: 20571\n",
      "Train: [epoch:686]  [ 10/172]  eta: 0:04:30  lr: 0.000035  loss: 0.7631 (0.7761)  time: 1.6717  data: 0.0969  max mem: 20571\n",
      "Train: [epoch:686]  [ 20/172]  eta: 0:04:07  lr: 0.000035  loss: 0.7644 (0.7722)  time: 1.5769  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:686]  [ 30/172]  eta: 0:03:48  lr: 0.000035  loss: 0.7834 (0.7770)  time: 1.5767  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:686]  [ 40/172]  eta: 0:03:31  lr: 0.000035  loss: 0.7694 (0.7712)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [ 50/172]  eta: 0:03:14  lr: 0.000035  loss: 0.7500 (0.7666)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [ 60/172]  eta: 0:02:58  lr: 0.000035  loss: 0.7556 (0.7665)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [ 70/172]  eta: 0:02:42  lr: 0.000035  loss: 0.7611 (0.7671)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [ 80/172]  eta: 0:02:26  lr: 0.000035  loss: 0.7646 (0.7680)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [ 90/172]  eta: 0:02:10  lr: 0.000035  loss: 0.7672 (0.7688)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [100/172]  eta: 0:01:54  lr: 0.000035  loss: 0.7765 (0.7698)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [110/172]  eta: 0:01:38  lr: 0.000035  loss: 0.7765 (0.7688)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [120/172]  eta: 0:01:22  lr: 0.000035  loss: 0.7818 (0.7703)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [130/172]  eta: 0:01:06  lr: 0.000035  loss: 0.8128 (0.7742)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [140/172]  eta: 0:00:50  lr: 0.000035  loss: 0.8108 (0.7743)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [150/172]  eta: 0:00:34  lr: 0.000035  loss: 0.7663 (0.7731)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [160/172]  eta: 0:00:19  lr: 0.000035  loss: 0.7426 (0.7729)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [170/172]  eta: 0:00:03  lr: 0.000035  loss: 0.7792 (0.7744)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686]  [171/172]  eta: 0:00:01  lr: 0.000035  loss: 0.7825 (0.7751)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:686] Total time: 0:04:32 (1.5842 s / it)\n",
      "Averaged stats: lr: 0.000035  loss: 0.7825 (0.7751)\n",
      "Valid: [epoch:686]  [ 0/14]  eta: 0:00:04  loss: 0.7223 (0.7223)  time: 0.2978  data: 0.2825  max mem: 20571\n",
      "Valid: [epoch:686]  [13/14]  eta: 0:00:00  loss: 0.7365 (0.7450)  time: 0.0383  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:686] Total time: 0:00:00 (0.0459 s / it)\n",
      "Averaged stats: loss: 0.7365 (0.7450)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_686_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.745%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:687]  [  0/172]  eta: 0:07:57  lr: 0.000035  loss: 0.8408 (0.8408)  time: 2.7749  data: 1.1880  max mem: 20571\n",
      "Train: [epoch:687]  [ 10/172]  eta: 0:04:32  lr: 0.000035  loss: 0.8008 (0.7949)  time: 1.6837  data: 0.1081  max mem: 20571\n",
      "Train: [epoch:687]  [ 20/172]  eta: 0:04:08  lr: 0.000035  loss: 0.7668 (0.7814)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [ 30/172]  eta: 0:03:49  lr: 0.000035  loss: 0.7668 (0.7841)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:687]  [ 40/172]  eta: 0:03:32  lr: 0.000035  loss: 0.7673 (0.7809)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:687]  [ 50/172]  eta: 0:03:15  lr: 0.000035  loss: 0.7504 (0.7779)  time: 1.5792  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:687]  [ 60/172]  eta: 0:02:58  lr: 0.000035  loss: 0.7501 (0.7760)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [ 70/172]  eta: 0:02:42  lr: 0.000035  loss: 0.7633 (0.7760)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [ 80/172]  eta: 0:02:26  lr: 0.000035  loss: 0.7762 (0.7741)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [ 90/172]  eta: 0:02:10  lr: 0.000035  loss: 0.7604 (0.7737)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [100/172]  eta: 0:01:54  lr: 0.000035  loss: 0.7609 (0.7739)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [110/172]  eta: 0:01:38  lr: 0.000035  loss: 0.7515 (0.7719)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [120/172]  eta: 0:01:22  lr: 0.000035  loss: 0.7589 (0.7736)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [130/172]  eta: 0:01:06  lr: 0.000035  loss: 0.7753 (0.7731)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [140/172]  eta: 0:00:50  lr: 0.000035  loss: 0.7636 (0.7720)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [150/172]  eta: 0:00:34  lr: 0.000035  loss: 0.7575 (0.7716)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [160/172]  eta: 0:00:19  lr: 0.000035  loss: 0.7615 (0.7711)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [170/172]  eta: 0:00:03  lr: 0.000035  loss: 0.7546 (0.7720)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687]  [171/172]  eta: 0:00:01  lr: 0.000035  loss: 0.7546 (0.7719)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:687] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000035  loss: 0.7546 (0.7719)\n",
      "Valid: [epoch:687]  [ 0/14]  eta: 0:00:07  loss: 0.6515 (0.6515)  time: 0.5367  data: 0.5202  max mem: 20571\n",
      "Valid: [epoch:687]  [13/14]  eta: 0:00:00  loss: 0.7232 (0.7331)  time: 0.0568  data: 0.0418  max mem: 20571\n",
      "Valid: [epoch:687] Total time: 0:00:00 (0.0618 s / it)\n",
      "Averaged stats: loss: 0.7232 (0.7331)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_687_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.733%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:688]  [  0/172]  eta: 0:07:48  lr: 0.000035  loss: 0.7818 (0.7818)  time: 2.7253  data: 1.1475  max mem: 20571\n",
      "Train: [epoch:688]  [ 10/172]  eta: 0:04:32  lr: 0.000035  loss: 0.7720 (0.7851)  time: 1.6804  data: 0.1044  max mem: 20571\n",
      "Train: [epoch:688]  [ 20/172]  eta: 0:04:08  lr: 0.000035  loss: 0.7702 (0.7768)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [ 30/172]  eta: 0:03:49  lr: 0.000035  loss: 0.7764 (0.7814)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [ 40/172]  eta: 0:03:31  lr: 0.000035  loss: 0.7817 (0.7804)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [ 50/172]  eta: 0:03:15  lr: 0.000035  loss: 0.7753 (0.7843)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [ 60/172]  eta: 0:02:58  lr: 0.000035  loss: 0.7877 (0.7830)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [ 70/172]  eta: 0:02:42  lr: 0.000035  loss: 0.7700 (0.7788)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [ 80/172]  eta: 0:02:26  lr: 0.000035  loss: 0.7717 (0.7795)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [ 90/172]  eta: 0:02:10  lr: 0.000035  loss: 0.7647 (0.7765)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [100/172]  eta: 0:01:54  lr: 0.000035  loss: 0.7497 (0.7757)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [110/172]  eta: 0:01:38  lr: 0.000035  loss: 0.7506 (0.7733)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [120/172]  eta: 0:01:22  lr: 0.000035  loss: 0.7607 (0.7721)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [130/172]  eta: 0:01:06  lr: 0.000035  loss: 0.7691 (0.7741)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [140/172]  eta: 0:00:50  lr: 0.000035  loss: 0.7837 (0.7739)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [150/172]  eta: 0:00:34  lr: 0.000035  loss: 0.7677 (0.7747)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [160/172]  eta: 0:00:19  lr: 0.000035  loss: 0.7677 (0.7741)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [170/172]  eta: 0:00:03  lr: 0.000035  loss: 0.7697 (0.7750)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688]  [171/172]  eta: 0:00:01  lr: 0.000035  loss: 0.7697 (0.7750)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:688] Total time: 0:04:32 (1.5844 s / it)\n",
      "Averaged stats: lr: 0.000035  loss: 0.7697 (0.7750)\n",
      "Valid: [epoch:688]  [ 0/14]  eta: 0:00:05  loss: 0.7279 (0.7279)  time: 0.3612  data: 0.3429  max mem: 20571\n",
      "Valid: [epoch:688]  [13/14]  eta: 0:00:00  loss: 0.7333 (0.7417)  time: 0.0407  data: 0.0254  max mem: 20571\n",
      "Valid: [epoch:688] Total time: 0:00:00 (0.0486 s / it)\n",
      "Averaged stats: loss: 0.7333 (0.7417)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_688_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.742%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:689]  [  0/172]  eta: 0:07:38  lr: 0.000035  loss: 0.7152 (0.7152)  time: 2.6636  data: 1.0850  max mem: 20571\n",
      "Train: [epoch:689]  [ 10/172]  eta: 0:04:30  lr: 0.000035  loss: 0.7477 (0.7460)  time: 1.6726  data: 0.0987  max mem: 20571\n",
      "Train: [epoch:689]  [ 20/172]  eta: 0:04:07  lr: 0.000035  loss: 0.7658 (0.7688)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [ 30/172]  eta: 0:03:48  lr: 0.000035  loss: 0.7640 (0.7675)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [ 40/172]  eta: 0:03:31  lr: 0.000035  loss: 0.7607 (0.7645)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [ 50/172]  eta: 0:03:14  lr: 0.000035  loss: 0.7610 (0.7642)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [ 60/172]  eta: 0:02:58  lr: 0.000035  loss: 0.7682 (0.7686)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [ 70/172]  eta: 0:02:42  lr: 0.000035  loss: 0.7755 (0.7688)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [ 80/172]  eta: 0:02:26  lr: 0.000035  loss: 0.7755 (0.7697)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [ 90/172]  eta: 0:02:10  lr: 0.000035  loss: 0.7889 (0.7715)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [100/172]  eta: 0:01:54  lr: 0.000035  loss: 0.7921 (0.7731)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [110/172]  eta: 0:01:38  lr: 0.000035  loss: 0.7641 (0.7730)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [120/172]  eta: 0:01:22  lr: 0.000035  loss: 0.7739 (0.7731)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [130/172]  eta: 0:01:06  lr: 0.000035  loss: 0.7794 (0.7726)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [140/172]  eta: 0:00:50  lr: 0.000035  loss: 0.7666 (0.7729)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [150/172]  eta: 0:00:34  lr: 0.000035  loss: 0.7679 (0.7742)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [160/172]  eta: 0:00:18  lr: 0.000035  loss: 0.7745 (0.7745)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [170/172]  eta: 0:00:03  lr: 0.000035  loss: 0.7724 (0.7746)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689]  [171/172]  eta: 0:00:01  lr: 0.000035  loss: 0.7643 (0.7745)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:689] Total time: 0:04:32 (1.5835 s / it)\n",
      "Averaged stats: lr: 0.000035  loss: 0.7643 (0.7745)\n",
      "Valid: [epoch:689]  [ 0/14]  eta: 0:00:03  loss: 0.7375 (0.7375)  time: 0.2823  data: 0.2674  max mem: 20571\n",
      "Valid: [epoch:689]  [13/14]  eta: 0:00:00  loss: 0.7375 (0.7466)  time: 0.0426  data: 0.0277  max mem: 20571\n",
      "Valid: [epoch:689] Total time: 0:00:00 (0.0494 s / it)\n",
      "Averaged stats: loss: 0.7375 (0.7466)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_689_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.747%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:690]  [  0/172]  eta: 0:07:47  lr: 0.000035  loss: 0.7609 (0.7609)  time: 2.7196  data: 1.1373  max mem: 20571\n",
      "Train: [epoch:690]  [ 10/172]  eta: 0:04:32  lr: 0.000035  loss: 0.7797 (0.7871)  time: 1.6804  data: 0.1035  max mem: 20571\n",
      "Train: [epoch:690]  [ 20/172]  eta: 0:04:08  lr: 0.000035  loss: 0.7802 (0.7854)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:690]  [ 30/172]  eta: 0:03:49  lr: 0.000035  loss: 0.7741 (0.7809)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:690]  [ 40/172]  eta: 0:03:32  lr: 0.000035  loss: 0.7697 (0.7769)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [ 50/172]  eta: 0:03:15  lr: 0.000035  loss: 0.7699 (0.7772)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [ 60/172]  eta: 0:02:58  lr: 0.000035  loss: 0.7699 (0.7778)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [ 70/172]  eta: 0:02:42  lr: 0.000035  loss: 0.7843 (0.7816)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [ 80/172]  eta: 0:02:26  lr: 0.000035  loss: 0.7843 (0.7810)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [ 90/172]  eta: 0:02:10  lr: 0.000035  loss: 0.7665 (0.7794)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [100/172]  eta: 0:01:54  lr: 0.000035  loss: 0.7735 (0.7790)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [110/172]  eta: 0:01:38  lr: 0.000035  loss: 0.7829 (0.7781)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [120/172]  eta: 0:01:22  lr: 0.000035  loss: 0.7640 (0.7782)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [130/172]  eta: 0:01:06  lr: 0.000035  loss: 0.7504 (0.7760)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [140/172]  eta: 0:00:50  lr: 0.000035  loss: 0.7517 (0.7751)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [150/172]  eta: 0:00:34  lr: 0.000035  loss: 0.7772 (0.7763)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [160/172]  eta: 0:00:19  lr: 0.000035  loss: 0.7756 (0.7759)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [170/172]  eta: 0:00:03  lr: 0.000035  loss: 0.7582 (0.7753)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690]  [171/172]  eta: 0:00:01  lr: 0.000035  loss: 0.7582 (0.7752)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:690] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000035  loss: 0.7582 (0.7752)\n",
      "Valid: [epoch:690]  [ 0/14]  eta: 0:00:06  loss: 0.7226 (0.7226)  time: 0.4608  data: 0.4430  max mem: 20571\n",
      "Valid: [epoch:690]  [13/14]  eta: 0:00:00  loss: 0.7372 (0.7453)  time: 0.0473  data: 0.0320  max mem: 20571\n",
      "Valid: [epoch:690] Total time: 0:00:00 (0.0536 s / it)\n",
      "Averaged stats: loss: 0.7372 (0.7453)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_690_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.745%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:691]  [  0/172]  eta: 0:07:29  lr: 0.000034  loss: 0.7407 (0.7407)  time: 2.6117  data: 1.0330  max mem: 20571\n",
      "Train: [epoch:691]  [ 10/172]  eta: 0:04:30  lr: 0.000034  loss: 0.7552 (0.7603)  time: 1.6686  data: 0.0940  max mem: 20571\n",
      "Train: [epoch:691]  [ 20/172]  eta: 0:04:06  lr: 0.000034  loss: 0.7610 (0.7689)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [ 30/172]  eta: 0:03:48  lr: 0.000034  loss: 0.7720 (0.7721)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [ 40/172]  eta: 0:03:31  lr: 0.000034  loss: 0.7653 (0.7679)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [ 50/172]  eta: 0:03:14  lr: 0.000034  loss: 0.7463 (0.7672)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [ 60/172]  eta: 0:02:58  lr: 0.000034  loss: 0.7808 (0.7724)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [ 70/172]  eta: 0:02:42  lr: 0.000034  loss: 0.7690 (0.7722)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [ 80/172]  eta: 0:02:26  lr: 0.000034  loss: 0.7569 (0.7720)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [ 90/172]  eta: 0:02:10  lr: 0.000034  loss: 0.7534 (0.7710)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [100/172]  eta: 0:01:54  lr: 0.000034  loss: 0.7813 (0.7740)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [110/172]  eta: 0:01:38  lr: 0.000034  loss: 0.7945 (0.7759)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [120/172]  eta: 0:01:22  lr: 0.000034  loss: 0.7780 (0.7752)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [130/172]  eta: 0:01:06  lr: 0.000034  loss: 0.7651 (0.7754)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [140/172]  eta: 0:00:50  lr: 0.000034  loss: 0.7587 (0.7745)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [150/172]  eta: 0:00:34  lr: 0.000034  loss: 0.7521 (0.7744)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [160/172]  eta: 0:00:19  lr: 0.000034  loss: 0.7747 (0.7754)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [170/172]  eta: 0:00:03  lr: 0.000034  loss: 0.7904 (0.7766)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691]  [171/172]  eta: 0:00:01  lr: 0.000034  loss: 0.7904 (0.7768)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:691] Total time: 0:04:32 (1.5850 s / it)\n",
      "Averaged stats: lr: 0.000034  loss: 0.7904 (0.7768)\n",
      "Valid: [epoch:691]  [ 0/14]  eta: 0:00:05  loss: 0.7306 (0.7306)  time: 0.4075  data: 0.3920  max mem: 20571\n",
      "Valid: [epoch:691]  [13/14]  eta: 0:00:00  loss: 0.7356 (0.7450)  time: 0.0492  data: 0.0339  max mem: 20571\n",
      "Valid: [epoch:691] Total time: 0:00:00 (0.0566 s / it)\n",
      "Averaged stats: loss: 0.7356 (0.7450)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_691_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.745%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:692]  [  0/172]  eta: 0:07:54  lr: 0.000034  loss: 0.7563 (0.7563)  time: 2.7579  data: 1.1931  max mem: 20571\n",
      "Train: [epoch:692]  [ 10/172]  eta: 0:04:32  lr: 0.000034  loss: 0.7990 (0.7965)  time: 1.6830  data: 0.1086  max mem: 20571\n",
      "Train: [epoch:692]  [ 20/172]  eta: 0:04:08  lr: 0.000034  loss: 0.7788 (0.7846)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [ 30/172]  eta: 0:03:49  lr: 0.000034  loss: 0.7729 (0.7853)  time: 1.5767  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:692]  [ 40/172]  eta: 0:03:31  lr: 0.000034  loss: 0.7660 (0.7828)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [ 50/172]  eta: 0:03:15  lr: 0.000034  loss: 0.7908 (0.7881)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [ 60/172]  eta: 0:02:58  lr: 0.000034  loss: 0.7955 (0.7887)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [ 70/172]  eta: 0:02:42  lr: 0.000034  loss: 0.7775 (0.7884)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [ 80/172]  eta: 0:02:26  lr: 0.000034  loss: 0.7755 (0.7868)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [ 90/172]  eta: 0:02:10  lr: 0.000034  loss: 0.7652 (0.7842)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [100/172]  eta: 0:01:54  lr: 0.000034  loss: 0.7717 (0.7828)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [110/172]  eta: 0:01:38  lr: 0.000034  loss: 0.7670 (0.7809)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [120/172]  eta: 0:01:22  lr: 0.000034  loss: 0.7670 (0.7816)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [130/172]  eta: 0:01:06  lr: 0.000034  loss: 0.7781 (0.7815)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [140/172]  eta: 0:00:50  lr: 0.000034  loss: 0.7641 (0.7799)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [150/172]  eta: 0:00:34  lr: 0.000034  loss: 0.7686 (0.7796)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [160/172]  eta: 0:00:19  lr: 0.000034  loss: 0.7728 (0.7781)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692]  [170/172]  eta: 0:00:03  lr: 0.000034  loss: 0.7759 (0.7786)  time: 1.5764  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:692]  [171/172]  eta: 0:00:01  lr: 0.000034  loss: 0.7769 (0.7787)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:692] Total time: 0:04:32 (1.5840 s / it)\n",
      "Averaged stats: lr: 0.000034  loss: 0.7769 (0.7787)\n",
      "Valid: [epoch:692]  [ 0/14]  eta: 0:00:04  loss: 0.6555 (0.6555)  time: 0.3324  data: 0.3164  max mem: 20571\n",
      "Valid: [epoch:692]  [13/14]  eta: 0:00:00  loss: 0.7278 (0.7381)  time: 0.0392  data: 0.0242  max mem: 20571\n",
      "Valid: [epoch:692] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.7278 (0.7381)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_692_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.738%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:693]  [  0/172]  eta: 0:07:49  lr: 0.000034  loss: 0.7514 (0.7514)  time: 2.7273  data: 1.1440  max mem: 20571\n",
      "Train: [epoch:693]  [ 10/172]  eta: 0:04:31  lr: 0.000034  loss: 0.7749 (0.7681)  time: 1.6790  data: 0.1041  max mem: 20571\n",
      "Train: [epoch:693]  [ 20/172]  eta: 0:04:07  lr: 0.000034  loss: 0.7850 (0.7801)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [ 30/172]  eta: 0:03:49  lr: 0.000034  loss: 0.7939 (0.7828)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [ 40/172]  eta: 0:03:31  lr: 0.000034  loss: 0.7827 (0.7782)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [ 50/172]  eta: 0:03:15  lr: 0.000034  loss: 0.7765 (0.7798)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [ 60/172]  eta: 0:02:58  lr: 0.000034  loss: 0.7666 (0.7766)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [ 70/172]  eta: 0:02:42  lr: 0.000034  loss: 0.7654 (0.7771)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [ 80/172]  eta: 0:02:26  lr: 0.000034  loss: 0.7617 (0.7770)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [ 90/172]  eta: 0:02:10  lr: 0.000034  loss: 0.7524 (0.7763)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [100/172]  eta: 0:01:54  lr: 0.000034  loss: 0.7604 (0.7771)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [110/172]  eta: 0:01:38  lr: 0.000034  loss: 0.7792 (0.7784)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [120/172]  eta: 0:01:22  lr: 0.000034  loss: 0.7769 (0.7788)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [130/172]  eta: 0:01:06  lr: 0.000034  loss: 0.7679 (0.7772)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [140/172]  eta: 0:00:50  lr: 0.000034  loss: 0.7498 (0.7764)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [150/172]  eta: 0:00:34  lr: 0.000034  loss: 0.7601 (0.7761)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [160/172]  eta: 0:00:19  lr: 0.000034  loss: 0.7855 (0.7777)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [170/172]  eta: 0:00:03  lr: 0.000034  loss: 0.7926 (0.7779)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693]  [171/172]  eta: 0:00:01  lr: 0.000034  loss: 0.7945 (0.7784)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:693] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000034  loss: 0.7945 (0.7784)\n",
      "Valid: [epoch:693]  [ 0/14]  eta: 0:00:04  loss: 0.7715 (0.7715)  time: 0.3377  data: 0.3208  max mem: 20571\n",
      "Valid: [epoch:693]  [13/14]  eta: 0:00:00  loss: 0.7324 (0.7412)  time: 0.0390  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:693] Total time: 0:00:00 (0.0445 s / it)\n",
      "Averaged stats: loss: 0.7324 (0.7412)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_693_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.741%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:694]  [  0/172]  eta: 0:07:52  lr: 0.000034  loss: 0.7400 (0.7400)  time: 2.7475  data: 1.1813  max mem: 20571\n",
      "Train: [epoch:694]  [ 10/172]  eta: 0:04:32  lr: 0.000034  loss: 0.7844 (0.7976)  time: 1.6832  data: 0.1075  max mem: 20571\n",
      "Train: [epoch:694]  [ 20/172]  eta: 0:04:08  lr: 0.000034  loss: 0.7844 (0.7943)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [ 30/172]  eta: 0:03:49  lr: 0.000034  loss: 0.7656 (0.7912)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [ 40/172]  eta: 0:03:32  lr: 0.000034  loss: 0.7460 (0.7833)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [ 50/172]  eta: 0:03:15  lr: 0.000034  loss: 0.7469 (0.7837)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [ 60/172]  eta: 0:02:59  lr: 0.000034  loss: 0.7672 (0.7845)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [ 70/172]  eta: 0:02:42  lr: 0.000034  loss: 0.7672 (0.7814)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [ 80/172]  eta: 0:02:26  lr: 0.000034  loss: 0.7657 (0.7815)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [ 90/172]  eta: 0:02:10  lr: 0.000034  loss: 0.7657 (0.7783)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [100/172]  eta: 0:01:54  lr: 0.000034  loss: 0.7775 (0.7819)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [110/172]  eta: 0:01:38  lr: 0.000034  loss: 0.7831 (0.7811)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [120/172]  eta: 0:01:22  lr: 0.000034  loss: 0.7571 (0.7803)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [130/172]  eta: 0:01:06  lr: 0.000034  loss: 0.7454 (0.7786)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [140/172]  eta: 0:00:50  lr: 0.000034  loss: 0.7454 (0.7784)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [150/172]  eta: 0:00:34  lr: 0.000034  loss: 0.7744 (0.7793)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [160/172]  eta: 0:00:19  lr: 0.000034  loss: 0.7953 (0.7814)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [170/172]  eta: 0:00:03  lr: 0.000034  loss: 0.8164 (0.7826)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694]  [171/172]  eta: 0:00:01  lr: 0.000034  loss: 0.7891 (0.7825)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:694] Total time: 0:04:32 (1.5868 s / it)\n",
      "Averaged stats: lr: 0.000034  loss: 0.7891 (0.7825)\n",
      "Valid: [epoch:694]  [ 0/14]  eta: 0:00:04  loss: 0.6808 (0.6808)  time: 0.3037  data: 0.2887  max mem: 20571\n",
      "Valid: [epoch:694]  [13/14]  eta: 0:00:00  loss: 0.7357 (0.7451)  time: 0.0395  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:694] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.7357 (0.7451)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_694_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.745%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:695]  [  0/172]  eta: 0:07:37  lr: 0.000034  loss: 0.8663 (0.8663)  time: 2.6584  data: 1.0861  max mem: 20571\n",
      "Train: [epoch:695]  [ 10/172]  eta: 0:04:30  lr: 0.000034  loss: 0.7929 (0.8018)  time: 1.6726  data: 0.0988  max mem: 20571\n",
      "Train: [epoch:695]  [ 20/172]  eta: 0:04:07  lr: 0.000034  loss: 0.7708 (0.7856)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [ 30/172]  eta: 0:03:48  lr: 0.000034  loss: 0.7690 (0.7805)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [ 40/172]  eta: 0:03:31  lr: 0.000034  loss: 0.7480 (0.7772)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [ 50/172]  eta: 0:03:15  lr: 0.000034  loss: 0.7655 (0.7772)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:695]  [ 60/172]  eta: 0:02:58  lr: 0.000034  loss: 0.7871 (0.7808)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [ 70/172]  eta: 0:02:42  lr: 0.000034  loss: 0.7823 (0.7797)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [ 80/172]  eta: 0:02:26  lr: 0.000034  loss: 0.7678 (0.7793)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [ 90/172]  eta: 0:02:10  lr: 0.000034  loss: 0.7835 (0.7814)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [100/172]  eta: 0:01:54  lr: 0.000034  loss: 0.7725 (0.7790)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [110/172]  eta: 0:01:38  lr: 0.000034  loss: 0.7563 (0.7794)  time: 1.5830  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:695]  [120/172]  eta: 0:01:22  lr: 0.000034  loss: 0.7756 (0.7792)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [130/172]  eta: 0:01:06  lr: 0.000034  loss: 0.7768 (0.7795)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [140/172]  eta: 0:00:50  lr: 0.000034  loss: 0.7830 (0.7788)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [150/172]  eta: 0:00:34  lr: 0.000034  loss: 0.7825 (0.7797)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [160/172]  eta: 0:00:19  lr: 0.000034  loss: 0.7690 (0.7797)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [170/172]  eta: 0:00:03  lr: 0.000034  loss: 0.7678 (0.7787)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695]  [171/172]  eta: 0:00:01  lr: 0.000034  loss: 0.7678 (0.7784)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:695] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000034  loss: 0.7678 (0.7784)\n",
      "Valid: [epoch:695]  [ 0/14]  eta: 0:00:03  loss: 0.6664 (0.6664)  time: 0.2850  data: 0.2703  max mem: 20571\n",
      "Valid: [epoch:695]  [13/14]  eta: 0:00:00  loss: 0.7398 (0.7489)  time: 0.0373  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:695] Total time: 0:00:00 (0.0453 s / it)\n",
      "Averaged stats: loss: 0.7398 (0.7489)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_695_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.749%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:696]  [  0/172]  eta: 0:07:40  lr: 0.000034  loss: 0.8457 (0.8457)  time: 2.6759  data: 1.1040  max mem: 20571\n",
      "Train: [epoch:696]  [ 10/172]  eta: 0:04:31  lr: 0.000034  loss: 0.7895 (0.7944)  time: 1.6789  data: 0.1005  max mem: 20571\n",
      "Train: [epoch:696]  [ 20/172]  eta: 0:04:08  lr: 0.000034  loss: 0.7592 (0.7816)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696]  [ 30/172]  eta: 0:03:49  lr: 0.000034  loss: 0.7599 (0.7826)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:696]  [ 40/172]  eta: 0:03:32  lr: 0.000034  loss: 0.7685 (0.7767)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:696]  [ 50/172]  eta: 0:03:15  lr: 0.000034  loss: 0.7598 (0.7757)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:696]  [ 60/172]  eta: 0:02:59  lr: 0.000034  loss: 0.7651 (0.7810)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696]  [ 70/172]  eta: 0:02:42  lr: 0.000034  loss: 0.8047 (0.7836)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696]  [ 80/172]  eta: 0:02:26  lr: 0.000034  loss: 0.7757 (0.7824)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696]  [ 90/172]  eta: 0:02:10  lr: 0.000034  loss: 0.7757 (0.7836)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:696]  [100/172]  eta: 0:01:54  lr: 0.000034  loss: 0.7603 (0.7813)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:696]  [110/172]  eta: 0:01:38  lr: 0.000034  loss: 0.7574 (0.7797)  time: 1.5819  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:696]  [120/172]  eta: 0:01:22  lr: 0.000034  loss: 0.7812 (0.7807)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:696]  [130/172]  eta: 0:01:06  lr: 0.000034  loss: 0.7812 (0.7808)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696]  [140/172]  eta: 0:00:50  lr: 0.000034  loss: 0.7674 (0.7798)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696]  [150/172]  eta: 0:00:34  lr: 0.000034  loss: 0.7666 (0.7799)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696]  [160/172]  eta: 0:00:19  lr: 0.000034  loss: 0.7778 (0.7801)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696]  [170/172]  eta: 0:00:03  lr: 0.000034  loss: 0.7817 (0.7811)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696]  [171/172]  eta: 0:00:01  lr: 0.000034  loss: 0.7817 (0.7817)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:696] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000034  loss: 0.7817 (0.7817)\n",
      "Valid: [epoch:696]  [ 0/14]  eta: 0:00:03  loss: 0.6980 (0.6980)  time: 0.2848  data: 0.2697  max mem: 20571\n",
      "Valid: [epoch:696]  [13/14]  eta: 0:00:00  loss: 0.7354 (0.7443)  time: 0.0398  data: 0.0248  max mem: 20571\n",
      "Valid: [epoch:696] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.7354 (0.7443)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_696_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.744%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:697]  [  0/172]  eta: 0:08:10  lr: 0.000034  loss: 0.7159 (0.7159)  time: 2.8524  data: 1.2751  max mem: 20571\n",
      "Train: [epoch:697]  [ 10/172]  eta: 0:04:34  lr: 0.000034  loss: 0.7491 (0.7658)  time: 1.6939  data: 0.1160  max mem: 20571\n",
      "Train: [epoch:697]  [ 20/172]  eta: 0:04:09  lr: 0.000034  loss: 0.7756 (0.7766)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [ 30/172]  eta: 0:03:50  lr: 0.000034  loss: 0.7751 (0.7765)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [ 40/172]  eta: 0:03:32  lr: 0.000034  loss: 0.7789 (0.7830)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [ 50/172]  eta: 0:03:16  lr: 0.000034  loss: 0.7794 (0.7856)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [ 60/172]  eta: 0:02:59  lr: 0.000034  loss: 0.7883 (0.7853)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [ 70/172]  eta: 0:02:43  lr: 0.000034  loss: 0.7883 (0.7851)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [ 80/172]  eta: 0:02:26  lr: 0.000034  loss: 0.7968 (0.7885)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [ 90/172]  eta: 0:02:10  lr: 0.000034  loss: 0.7970 (0.7889)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [100/172]  eta: 0:01:54  lr: 0.000034  loss: 0.7751 (0.7864)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [110/172]  eta: 0:01:38  lr: 0.000034  loss: 0.7593 (0.7840)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [120/172]  eta: 0:01:22  lr: 0.000034  loss: 0.7667 (0.7846)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [130/172]  eta: 0:01:06  lr: 0.000034  loss: 0.7883 (0.7852)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:697]  [140/172]  eta: 0:00:50  lr: 0.000034  loss: 0.7705 (0.7835)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:697]  [150/172]  eta: 0:00:34  lr: 0.000034  loss: 0.7705 (0.7827)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [160/172]  eta: 0:00:19  lr: 0.000034  loss: 0.7855 (0.7840)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [170/172]  eta: 0:00:03  lr: 0.000034  loss: 0.7783 (0.7841)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697]  [171/172]  eta: 0:00:01  lr: 0.000034  loss: 0.7782 (0.7840)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:697] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000034  loss: 0.7782 (0.7840)\n",
      "Valid: [epoch:697]  [ 0/14]  eta: 0:00:04  loss: 0.8190 (0.8190)  time: 0.3293  data: 0.3142  max mem: 20571\n",
      "Valid: [epoch:697]  [13/14]  eta: 0:00:00  loss: 0.7461 (0.7559)  time: 0.0388  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:697] Total time: 0:00:00 (0.0438 s / it)\n",
      "Averaged stats: loss: 0.7461 (0.7559)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_697_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.756%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:698]  [  0/172]  eta: 0:07:33  lr: 0.000034  loss: 0.7302 (0.7302)  time: 2.6370  data: 1.0681  max mem: 20571\n",
      "Train: [epoch:698]  [ 10/172]  eta: 0:04:32  lr: 0.000034  loss: 0.7698 (0.7740)  time: 1.6796  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:698]  [ 20/172]  eta: 0:04:08  lr: 0.000034  loss: 0.7703 (0.7831)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [ 30/172]  eta: 0:03:49  lr: 0.000034  loss: 0.7703 (0.7764)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [ 40/172]  eta: 0:03:32  lr: 0.000034  loss: 0.7549 (0.7715)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [ 50/172]  eta: 0:03:15  lr: 0.000034  loss: 0.7611 (0.7738)  time: 1.5826  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:698]  [ 60/172]  eta: 0:02:59  lr: 0.000034  loss: 0.7823 (0.7765)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [ 70/172]  eta: 0:02:42  lr: 0.000034  loss: 0.7693 (0.7761)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [ 80/172]  eta: 0:02:26  lr: 0.000034  loss: 0.7693 (0.7785)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [ 90/172]  eta: 0:02:10  lr: 0.000034  loss: 0.7934 (0.7803)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [100/172]  eta: 0:01:54  lr: 0.000034  loss: 0.7911 (0.7808)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [110/172]  eta: 0:01:38  lr: 0.000034  loss: 0.7694 (0.7798)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [120/172]  eta: 0:01:22  lr: 0.000034  loss: 0.7812 (0.7813)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [130/172]  eta: 0:01:06  lr: 0.000034  loss: 0.7812 (0.7801)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [140/172]  eta: 0:00:50  lr: 0.000034  loss: 0.7590 (0.7796)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [150/172]  eta: 0:00:34  lr: 0.000034  loss: 0.7590 (0.7799)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [160/172]  eta: 0:00:19  lr: 0.000034  loss: 0.7841 (0.7803)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [170/172]  eta: 0:00:03  lr: 0.000034  loss: 0.7845 (0.7823)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698]  [171/172]  eta: 0:00:01  lr: 0.000034  loss: 0.7845 (0.7820)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:698] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000034  loss: 0.7845 (0.7820)\n",
      "Valid: [epoch:698]  [ 0/14]  eta: 0:00:04  loss: 0.6991 (0.6991)  time: 0.3246  data: 0.3097  max mem: 20571\n",
      "Valid: [epoch:698]  [13/14]  eta: 0:00:00  loss: 0.7370 (0.7455)  time: 0.0394  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:698] Total time: 0:00:00 (0.0474 s / it)\n",
      "Averaged stats: loss: 0.7370 (0.7455)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_698_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.745%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:699]  [  0/172]  eta: 0:07:57  lr: 0.000034  loss: 0.8644 (0.8644)  time: 2.7791  data: 1.1890  max mem: 20571\n",
      "Train: [epoch:699]  [ 10/172]  eta: 0:04:32  lr: 0.000034  loss: 0.7773 (0.7802)  time: 1.6850  data: 0.1082  max mem: 20571\n",
      "Train: [epoch:699]  [ 20/172]  eta: 0:04:08  lr: 0.000034  loss: 0.7980 (0.7880)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:699]  [ 30/172]  eta: 0:03:49  lr: 0.000034  loss: 0.7983 (0.7887)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:699]  [ 40/172]  eta: 0:03:32  lr: 0.000034  loss: 0.7885 (0.7881)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [ 50/172]  eta: 0:03:15  lr: 0.000034  loss: 0.7887 (0.7890)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [ 60/172]  eta: 0:02:59  lr: 0.000034  loss: 0.7911 (0.7889)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [ 70/172]  eta: 0:02:42  lr: 0.000034  loss: 0.7906 (0.7903)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [ 80/172]  eta: 0:02:26  lr: 0.000034  loss: 0.7786 (0.7891)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [ 90/172]  eta: 0:02:10  lr: 0.000034  loss: 0.7685 (0.7886)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [100/172]  eta: 0:01:54  lr: 0.000034  loss: 0.7858 (0.7876)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [110/172]  eta: 0:01:38  lr: 0.000034  loss: 0.7761 (0.7873)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [120/172]  eta: 0:01:22  lr: 0.000034  loss: 0.7761 (0.7862)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [130/172]  eta: 0:01:06  lr: 0.000034  loss: 0.7812 (0.7859)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [140/172]  eta: 0:00:50  lr: 0.000034  loss: 0.7802 (0.7848)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [150/172]  eta: 0:00:34  lr: 0.000034  loss: 0.7857 (0.7857)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [160/172]  eta: 0:00:19  lr: 0.000034  loss: 0.8030 (0.7855)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [170/172]  eta: 0:00:03  lr: 0.000034  loss: 0.7613 (0.7841)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699]  [171/172]  eta: 0:00:01  lr: 0.000034  loss: 0.7613 (0.7842)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:699] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000034  loss: 0.7613 (0.7842)\n",
      "Valid: [epoch:699]  [ 0/14]  eta: 0:00:04  loss: 0.7433 (0.7433)  time: 0.3102  data: 0.2945  max mem: 20571\n",
      "Valid: [epoch:699]  [13/14]  eta: 0:00:00  loss: 0.7433 (0.7523)  time: 0.0450  data: 0.0299  max mem: 20571\n",
      "Valid: [epoch:699] Total time: 0:00:00 (0.0525 s / it)\n",
      "Averaged stats: loss: 0.7433 (0.7523)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_699_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.752%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:700]  [  0/172]  eta: 0:08:16  lr: 0.000033  loss: 0.7292 (0.7292)  time: 2.8872  data: 1.2938  max mem: 20571\n",
      "Train: [epoch:700]  [ 10/172]  eta: 0:04:35  lr: 0.000033  loss: 0.7838 (0.7790)  time: 1.6984  data: 0.1177  max mem: 20571\n",
      "Train: [epoch:700]  [ 20/172]  eta: 0:04:09  lr: 0.000033  loss: 0.7992 (0.8007)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [ 30/172]  eta: 0:03:50  lr: 0.000033  loss: 0.7933 (0.7972)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [ 40/172]  eta: 0:03:32  lr: 0.000033  loss: 0.7726 (0.7922)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:700]  [ 50/172]  eta: 0:03:16  lr: 0.000033  loss: 0.7682 (0.7911)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [ 60/172]  eta: 0:02:59  lr: 0.000033  loss: 0.7828 (0.7914)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [ 70/172]  eta: 0:02:43  lr: 0.000033  loss: 0.7905 (0.7900)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [ 80/172]  eta: 0:02:26  lr: 0.000033  loss: 0.7995 (0.7882)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [ 90/172]  eta: 0:02:10  lr: 0.000033  loss: 0.7903 (0.7877)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [100/172]  eta: 0:01:54  lr: 0.000033  loss: 0.7952 (0.7895)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [110/172]  eta: 0:01:38  lr: 0.000033  loss: 0.7982 (0.7895)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [120/172]  eta: 0:01:22  lr: 0.000033  loss: 0.7778 (0.7883)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:700]  [130/172]  eta: 0:01:06  lr: 0.000033  loss: 0.7699 (0.7878)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [140/172]  eta: 0:00:50  lr: 0.000033  loss: 0.7610 (0.7862)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [150/172]  eta: 0:00:34  lr: 0.000033  loss: 0.7569 (0.7854)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [160/172]  eta: 0:00:19  lr: 0.000033  loss: 0.7712 (0.7848)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [170/172]  eta: 0:00:03  lr: 0.000033  loss: 0.7805 (0.7848)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700]  [171/172]  eta: 0:00:01  lr: 0.000033  loss: 0.7805 (0.7843)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:700] Total time: 0:04:33 (1.5907 s / it)\n",
      "Averaged stats: lr: 0.000033  loss: 0.7805 (0.7843)\n",
      "Valid: [epoch:700]  [ 0/14]  eta: 0:00:06  loss: 0.7821 (0.7821)  time: 0.4954  data: 0.4793  max mem: 20571\n",
      "Valid: [epoch:700]  [13/14]  eta: 0:00:00  loss: 0.7433 (0.7528)  time: 0.0510  data: 0.0358  max mem: 20571\n",
      "Valid: [epoch:700] Total time: 0:00:00 (0.0589 s / it)\n",
      "Averaged stats: loss: 0.7433 (0.7528)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_700_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.753%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:701]  [  0/172]  eta: 0:07:33  lr: 0.000033  loss: 0.8201 (0.8201)  time: 2.6365  data: 1.0544  max mem: 20571\n",
      "Train: [epoch:701]  [ 10/172]  eta: 0:04:31  lr: 0.000033  loss: 0.7794 (0.7752)  time: 1.6754  data: 0.0960  max mem: 20571\n",
      "Train: [epoch:701]  [ 20/172]  eta: 0:04:07  lr: 0.000033  loss: 0.7794 (0.7792)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [ 30/172]  eta: 0:03:49  lr: 0.000033  loss: 0.7756 (0.7803)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [ 40/172]  eta: 0:03:32  lr: 0.000033  loss: 0.7756 (0.7844)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [ 50/172]  eta: 0:03:15  lr: 0.000033  loss: 0.8037 (0.7869)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [ 60/172]  eta: 0:02:59  lr: 0.000033  loss: 0.7912 (0.7862)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [ 70/172]  eta: 0:02:42  lr: 0.000033  loss: 0.7824 (0.7861)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [ 80/172]  eta: 0:02:26  lr: 0.000033  loss: 0.7840 (0.7867)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [ 90/172]  eta: 0:02:10  lr: 0.000033  loss: 0.7901 (0.7877)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [100/172]  eta: 0:01:54  lr: 0.000033  loss: 0.7944 (0.7882)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [110/172]  eta: 0:01:38  lr: 0.000033  loss: 0.7866 (0.7889)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [120/172]  eta: 0:01:22  lr: 0.000033  loss: 0.7849 (0.7882)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [130/172]  eta: 0:01:06  lr: 0.000033  loss: 0.7941 (0.7895)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [140/172]  eta: 0:00:50  lr: 0.000033  loss: 0.7723 (0.7881)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [150/172]  eta: 0:00:34  lr: 0.000033  loss: 0.7701 (0.7885)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [160/172]  eta: 0:00:19  lr: 0.000033  loss: 0.7771 (0.7884)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [170/172]  eta: 0:00:03  lr: 0.000033  loss: 0.7825 (0.7882)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701]  [171/172]  eta: 0:00:01  lr: 0.000033  loss: 0.7897 (0.7882)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:701] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000033  loss: 0.7897 (0.7882)\n",
      "Valid: [epoch:701]  [ 0/14]  eta: 0:00:04  loss: 0.7374 (0.7374)  time: 0.3374  data: 0.3192  max mem: 20571\n",
      "Valid: [epoch:701]  [13/14]  eta: 0:00:00  loss: 0.7420 (0.7511)  time: 0.0395  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:701] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.7420 (0.7511)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_701_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.751%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:702]  [  0/172]  eta: 0:08:14  lr: 0.000033  loss: 0.8504 (0.8504)  time: 2.8760  data: 1.3062  max mem: 20571\n",
      "Train: [epoch:702]  [ 10/172]  eta: 0:04:35  lr: 0.000033  loss: 0.7683 (0.7750)  time: 1.6997  data: 0.1189  max mem: 20571\n",
      "Train: [epoch:702]  [ 20/172]  eta: 0:04:09  lr: 0.000033  loss: 0.7741 (0.7850)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [ 30/172]  eta: 0:03:50  lr: 0.000033  loss: 0.7898 (0.7848)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [ 40/172]  eta: 0:03:32  lr: 0.000033  loss: 0.7594 (0.7798)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [ 50/172]  eta: 0:03:16  lr: 0.000033  loss: 0.7842 (0.7870)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [ 60/172]  eta: 0:02:59  lr: 0.000033  loss: 0.7980 (0.7876)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [ 70/172]  eta: 0:02:43  lr: 0.000033  loss: 0.7789 (0.7853)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [ 80/172]  eta: 0:02:26  lr: 0.000033  loss: 0.7758 (0.7858)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [ 90/172]  eta: 0:02:10  lr: 0.000033  loss: 0.8039 (0.7898)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [100/172]  eta: 0:01:54  lr: 0.000033  loss: 0.7986 (0.7881)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [110/172]  eta: 0:01:38  lr: 0.000033  loss: 0.7693 (0.7873)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [120/172]  eta: 0:01:22  lr: 0.000033  loss: 0.7836 (0.7880)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [130/172]  eta: 0:01:06  lr: 0.000033  loss: 0.7837 (0.7877)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [140/172]  eta: 0:00:50  lr: 0.000033  loss: 0.7707 (0.7864)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [150/172]  eta: 0:00:34  lr: 0.000033  loss: 0.7587 (0.7845)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [160/172]  eta: 0:00:19  lr: 0.000033  loss: 0.7463 (0.7836)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [170/172]  eta: 0:00:03  lr: 0.000033  loss: 0.7814 (0.7853)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702]  [171/172]  eta: 0:00:01  lr: 0.000033  loss: 0.7814 (0.7853)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:702] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000033  loss: 0.7814 (0.7853)\n",
      "Valid: [epoch:702]  [ 0/14]  eta: 0:00:04  loss: 0.7280 (0.7280)  time: 0.3083  data: 0.2935  max mem: 20571\n",
      "Valid: [epoch:702]  [13/14]  eta: 0:00:00  loss: 0.7426 (0.7518)  time: 0.0377  data: 0.0228  max mem: 20571\n",
      "Valid: [epoch:702] Total time: 0:00:00 (0.0433 s / it)\n",
      "Averaged stats: loss: 0.7426 (0.7518)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_702_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.752%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:703]  [  0/172]  eta: 0:08:13  lr: 0.000033  loss: 0.8286 (0.8286)  time: 2.8692  data: 1.2949  max mem: 20571\n",
      "Train: [epoch:703]  [ 10/172]  eta: 0:04:34  lr: 0.000033  loss: 0.8076 (0.7967)  time: 1.6931  data: 0.1178  max mem: 20571\n",
      "Train: [epoch:703]  [ 20/172]  eta: 0:04:09  lr: 0.000033  loss: 0.7991 (0.7953)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703]  [ 30/172]  eta: 0:03:49  lr: 0.000033  loss: 0.7937 (0.7960)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703]  [ 40/172]  eta: 0:03:32  lr: 0.000033  loss: 0.7793 (0.7920)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:703]  [ 50/172]  eta: 0:03:15  lr: 0.000033  loss: 0.7744 (0.7912)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:703]  [ 60/172]  eta: 0:02:59  lr: 0.000033  loss: 0.7952 (0.7916)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:703]  [ 70/172]  eta: 0:02:42  lr: 0.000033  loss: 0.7852 (0.7902)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:703]  [ 80/172]  eta: 0:02:26  lr: 0.000033  loss: 0.7852 (0.7908)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:703]  [ 90/172]  eta: 0:02:10  lr: 0.000033  loss: 0.7765 (0.7916)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:703]  [100/172]  eta: 0:01:54  lr: 0.000033  loss: 0.7642 (0.7891)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703]  [110/172]  eta: 0:01:38  lr: 0.000033  loss: 0.7622 (0.7882)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703]  [120/172]  eta: 0:01:22  lr: 0.000033  loss: 0.7791 (0.7883)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703]  [130/172]  eta: 0:01:06  lr: 0.000033  loss: 0.7911 (0.7909)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703]  [140/172]  eta: 0:00:50  lr: 0.000033  loss: 0.7930 (0.7907)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703]  [150/172]  eta: 0:00:34  lr: 0.000033  loss: 0.7720 (0.7907)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703]  [160/172]  eta: 0:00:19  lr: 0.000033  loss: 0.7789 (0.7908)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703]  [170/172]  eta: 0:00:03  lr: 0.000033  loss: 0.7789 (0.7917)  time: 1.5841  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:703]  [171/172]  eta: 0:00:01  lr: 0.000033  loss: 0.7675 (0.7914)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:703] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000033  loss: 0.7675 (0.7914)\n",
      "Valid: [epoch:703]  [ 0/14]  eta: 0:00:05  loss: 0.7326 (0.7326)  time: 0.4044  data: 0.3888  max mem: 20571\n",
      "Valid: [epoch:703]  [13/14]  eta: 0:00:00  loss: 0.7482 (0.7576)  time: 0.0437  data: 0.0286  max mem: 20571\n",
      "Valid: [epoch:703] Total time: 0:00:00 (0.0512 s / it)\n",
      "Averaged stats: loss: 0.7482 (0.7576)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_703_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.758%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:704]  [  0/172]  eta: 0:08:05  lr: 0.000033  loss: 0.7217 (0.7217)  time: 2.8239  data: 1.2470  max mem: 20571\n",
      "Train: [epoch:704]  [ 10/172]  eta: 0:04:34  lr: 0.000033  loss: 0.7652 (0.7696)  time: 1.6937  data: 0.1135  max mem: 20571\n",
      "Train: [epoch:704]  [ 20/172]  eta: 0:04:09  lr: 0.000033  loss: 0.7687 (0.7728)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [ 30/172]  eta: 0:03:50  lr: 0.000033  loss: 0.7711 (0.7791)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [ 40/172]  eta: 0:03:32  lr: 0.000033  loss: 0.7690 (0.7742)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [ 50/172]  eta: 0:03:15  lr: 0.000033  loss: 0.7772 (0.7793)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [ 60/172]  eta: 0:02:59  lr: 0.000033  loss: 0.8038 (0.7840)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [ 70/172]  eta: 0:02:43  lr: 0.000033  loss: 0.7902 (0.7831)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [ 80/172]  eta: 0:02:26  lr: 0.000033  loss: 0.7789 (0.7839)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [ 90/172]  eta: 0:02:10  lr: 0.000033  loss: 0.7875 (0.7853)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [100/172]  eta: 0:01:54  lr: 0.000033  loss: 0.7780 (0.7860)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:704]  [110/172]  eta: 0:01:38  lr: 0.000033  loss: 0.7716 (0.7847)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [120/172]  eta: 0:01:22  lr: 0.000033  loss: 0.7731 (0.7864)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [130/172]  eta: 0:01:06  lr: 0.000033  loss: 0.7783 (0.7850)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [140/172]  eta: 0:00:50  lr: 0.000033  loss: 0.7773 (0.7851)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [150/172]  eta: 0:00:34  lr: 0.000033  loss: 0.7864 (0.7859)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [160/172]  eta: 0:00:19  lr: 0.000033  loss: 0.7676 (0.7861)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [170/172]  eta: 0:00:03  lr: 0.000033  loss: 0.7779 (0.7866)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704]  [171/172]  eta: 0:00:01  lr: 0.000033  loss: 0.7779 (0.7865)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:704] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000033  loss: 0.7779 (0.7865)\n",
      "Valid: [epoch:704]  [ 0/14]  eta: 0:00:05  loss: 0.7401 (0.7401)  time: 0.3868  data: 0.3684  max mem: 20571\n",
      "Valid: [epoch:704]  [13/14]  eta: 0:00:00  loss: 0.7461 (0.7547)  time: 0.0424  data: 0.0272  max mem: 20571\n",
      "Valid: [epoch:704] Total time: 0:00:00 (0.0507 s / it)\n",
      "Averaged stats: loss: 0.7461 (0.7547)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_704_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.755%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:705]  [  0/172]  eta: 0:08:00  lr: 0.000033  loss: 0.6909 (0.6909)  time: 2.7929  data: 1.2108  max mem: 20571\n",
      "Train: [epoch:705]  [ 10/172]  eta: 0:04:33  lr: 0.000033  loss: 0.7766 (0.7769)  time: 1.6875  data: 0.1102  max mem: 20571\n",
      "Train: [epoch:705]  [ 20/172]  eta: 0:04:08  lr: 0.000033  loss: 0.7766 (0.7793)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [ 30/172]  eta: 0:03:49  lr: 0.000033  loss: 0.7850 (0.7871)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [ 40/172]  eta: 0:03:32  lr: 0.000033  loss: 0.7850 (0.7851)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [ 50/172]  eta: 0:03:15  lr: 0.000033  loss: 0.7915 (0.7878)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:705]  [ 60/172]  eta: 0:02:59  lr: 0.000033  loss: 0.7915 (0.7863)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:705]  [ 70/172]  eta: 0:02:42  lr: 0.000033  loss: 0.7841 (0.7878)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [ 80/172]  eta: 0:02:26  lr: 0.000033  loss: 0.7790 (0.7874)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [ 90/172]  eta: 0:02:10  lr: 0.000033  loss: 0.7785 (0.7861)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [100/172]  eta: 0:01:54  lr: 0.000033  loss: 0.7932 (0.7896)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [110/172]  eta: 0:01:38  lr: 0.000033  loss: 0.8014 (0.7890)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [120/172]  eta: 0:01:22  lr: 0.000033  loss: 0.8044 (0.7915)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [130/172]  eta: 0:01:06  lr: 0.000033  loss: 0.8101 (0.7937)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [140/172]  eta: 0:00:50  lr: 0.000033  loss: 0.8085 (0.7938)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:705]  [150/172]  eta: 0:00:34  lr: 0.000033  loss: 0.7867 (0.7918)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [160/172]  eta: 0:00:19  lr: 0.000033  loss: 0.7703 (0.7908)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [170/172]  eta: 0:00:03  lr: 0.000033  loss: 0.7953 (0.7928)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705]  [171/172]  eta: 0:00:01  lr: 0.000033  loss: 0.8035 (0.7929)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:705] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000033  loss: 0.8035 (0.7929)\n",
      "Valid: [epoch:705]  [ 0/14]  eta: 0:00:04  loss: 0.7935 (0.7935)  time: 0.3367  data: 0.3181  max mem: 20571\n",
      "Valid: [epoch:705]  [13/14]  eta: 0:00:00  loss: 0.7471 (0.7564)  time: 0.0384  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:705] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.7471 (0.7564)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_705_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.756%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:706]  [  0/172]  eta: 0:07:48  lr: 0.000033  loss: 0.7510 (0.7510)  time: 2.7214  data: 1.1514  max mem: 20571\n",
      "Train: [epoch:706]  [ 10/172]  eta: 0:04:32  lr: 0.000033  loss: 0.7653 (0.7722)  time: 1.6824  data: 0.1048  max mem: 20571\n",
      "Train: [epoch:706]  [ 20/172]  eta: 0:04:08  lr: 0.000033  loss: 0.7720 (0.7808)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [ 30/172]  eta: 0:03:49  lr: 0.000033  loss: 0.7720 (0.7793)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [ 40/172]  eta: 0:03:32  lr: 0.000033  loss: 0.7618 (0.7757)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [ 50/172]  eta: 0:03:15  lr: 0.000033  loss: 0.7652 (0.7767)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [ 60/172]  eta: 0:02:59  lr: 0.000033  loss: 0.7897 (0.7796)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:706]  [ 70/172]  eta: 0:02:42  lr: 0.000033  loss: 0.7920 (0.7818)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [ 80/172]  eta: 0:02:26  lr: 0.000033  loss: 0.7818 (0.7821)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [ 90/172]  eta: 0:02:10  lr: 0.000033  loss: 0.7818 (0.7848)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [100/172]  eta: 0:01:54  lr: 0.000033  loss: 0.7976 (0.7856)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [110/172]  eta: 0:01:38  lr: 0.000033  loss: 0.7832 (0.7849)  time: 1.5819  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:706]  [120/172]  eta: 0:01:22  lr: 0.000033  loss: 0.7682 (0.7844)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [130/172]  eta: 0:01:06  lr: 0.000033  loss: 0.7986 (0.7874)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [140/172]  eta: 0:00:50  lr: 0.000033  loss: 0.8010 (0.7869)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [150/172]  eta: 0:00:34  lr: 0.000033  loss: 0.7952 (0.7885)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [160/172]  eta: 0:00:19  lr: 0.000033  loss: 0.7880 (0.7877)  time: 1.5830  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:706]  [170/172]  eta: 0:00:03  lr: 0.000033  loss: 0.7880 (0.7888)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706]  [171/172]  eta: 0:00:01  lr: 0.000033  loss: 0.7804 (0.7886)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:706] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000033  loss: 0.7804 (0.7886)\n",
      "Valid: [epoch:706]  [ 0/14]  eta: 0:00:05  loss: 0.7083 (0.7083)  time: 0.3729  data: 0.3563  max mem: 20571\n",
      "Valid: [epoch:706]  [13/14]  eta: 0:00:00  loss: 0.7462 (0.7547)  time: 0.0417  data: 0.0267  max mem: 20571\n",
      "Valid: [epoch:706] Total time: 0:00:00 (0.0466 s / it)\n",
      "Averaged stats: loss: 0.7462 (0.7547)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_706_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.755%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:707]  [  0/172]  eta: 0:07:37  lr: 0.000033  loss: 0.7339 (0.7339)  time: 2.6622  data: 1.0725  max mem: 20571\n",
      "Train: [epoch:707]  [ 10/172]  eta: 0:04:31  lr: 0.000033  loss: 0.8132 (0.8122)  time: 1.6772  data: 0.0976  max mem: 20571\n",
      "Train: [epoch:707]  [ 20/172]  eta: 0:04:07  lr: 0.000033  loss: 0.8048 (0.7986)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [ 30/172]  eta: 0:03:49  lr: 0.000033  loss: 0.7680 (0.7908)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [ 40/172]  eta: 0:03:32  lr: 0.000033  loss: 0.7701 (0.7916)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [ 50/172]  eta: 0:03:15  lr: 0.000033  loss: 0.7858 (0.7935)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:707]  [ 60/172]  eta: 0:02:59  lr: 0.000033  loss: 0.7843 (0.7941)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:707]  [ 70/172]  eta: 0:02:42  lr: 0.000033  loss: 0.8092 (0.7940)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [ 80/172]  eta: 0:02:26  lr: 0.000033  loss: 0.8036 (0.7944)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [ 90/172]  eta: 0:02:10  lr: 0.000033  loss: 0.7847 (0.7927)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [100/172]  eta: 0:01:54  lr: 0.000033  loss: 0.7756 (0.7918)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [110/172]  eta: 0:01:38  lr: 0.000033  loss: 0.7756 (0.7907)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [120/172]  eta: 0:01:22  lr: 0.000033  loss: 0.7811 (0.7911)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [130/172]  eta: 0:01:06  lr: 0.000033  loss: 0.7871 (0.7911)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [140/172]  eta: 0:00:50  lr: 0.000033  loss: 0.7871 (0.7915)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [150/172]  eta: 0:00:34  lr: 0.000033  loss: 0.7970 (0.7915)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [160/172]  eta: 0:00:19  lr: 0.000033  loss: 0.8031 (0.7930)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [170/172]  eta: 0:00:03  lr: 0.000033  loss: 0.8019 (0.7929)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707]  [171/172]  eta: 0:00:01  lr: 0.000033  loss: 0.8019 (0.7934)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:707] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000033  loss: 0.8019 (0.7934)\n",
      "Valid: [epoch:707]  [ 0/14]  eta: 0:00:05  loss: 0.8194 (0.8194)  time: 0.3588  data: 0.3393  max mem: 20571\n",
      "Valid: [epoch:707]  [13/14]  eta: 0:00:00  loss: 0.7485 (0.7568)  time: 0.0409  data: 0.0255  max mem: 20571\n",
      "Valid: [epoch:707] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.7485 (0.7568)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_707_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.757%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:708]  [  0/172]  eta: 0:07:37  lr: 0.000033  loss: 0.8078 (0.8078)  time: 2.6622  data: 1.0919  max mem: 20571\n",
      "Train: [epoch:708]  [ 10/172]  eta: 0:04:32  lr: 0.000033  loss: 0.8007 (0.8033)  time: 1.6800  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:708]  [ 20/172]  eta: 0:04:08  lr: 0.000033  loss: 0.7826 (0.7984)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [ 30/172]  eta: 0:03:49  lr: 0.000033  loss: 0.7756 (0.7940)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [ 40/172]  eta: 0:03:32  lr: 0.000033  loss: 0.7757 (0.7926)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [ 50/172]  eta: 0:03:15  lr: 0.000033  loss: 0.7671 (0.7887)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [ 60/172]  eta: 0:02:59  lr: 0.000033  loss: 0.7671 (0.7880)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [ 70/172]  eta: 0:02:43  lr: 0.000033  loss: 0.7831 (0.7880)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [ 80/172]  eta: 0:02:26  lr: 0.000033  loss: 0.7847 (0.7890)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [ 90/172]  eta: 0:02:10  lr: 0.000033  loss: 0.7994 (0.7893)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [100/172]  eta: 0:01:54  lr: 0.000033  loss: 0.7723 (0.7870)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [110/172]  eta: 0:01:38  lr: 0.000033  loss: 0.7669 (0.7879)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [120/172]  eta: 0:01:22  lr: 0.000033  loss: 0.7820 (0.7887)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [130/172]  eta: 0:01:06  lr: 0.000033  loss: 0.8119 (0.7904)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [140/172]  eta: 0:00:50  lr: 0.000033  loss: 0.8119 (0.7906)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [150/172]  eta: 0:00:34  lr: 0.000033  loss: 0.7818 (0.7904)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [160/172]  eta: 0:00:19  lr: 0.000033  loss: 0.8001 (0.7912)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [170/172]  eta: 0:00:03  lr: 0.000033  loss: 0.8044 (0.7917)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708]  [171/172]  eta: 0:00:01  lr: 0.000033  loss: 0.8001 (0.7917)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:708] Total time: 0:04:33 (1.5905 s / it)\n",
      "Averaged stats: lr: 0.000033  loss: 0.8001 (0.7917)\n",
      "Valid: [epoch:708]  [ 0/14]  eta: 0:00:05  loss: 0.7458 (0.7458)  time: 0.3747  data: 0.3568  max mem: 20571\n",
      "Valid: [epoch:708]  [13/14]  eta: 0:00:00  loss: 0.7607 (0.7686)  time: 0.0411  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:708] Total time: 0:00:00 (0.0458 s / it)\n",
      "Averaged stats: loss: 0.7607 (0.7686)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_708_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.769%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:709]  [  0/172]  eta: 0:07:51  lr: 0.000032  loss: 0.7747 (0.7747)  time: 2.7397  data: 1.1635  max mem: 20571\n",
      "Train: [epoch:709]  [ 10/172]  eta: 0:04:32  lr: 0.000032  loss: 0.7904 (0.8017)  time: 1.6851  data: 0.1059  max mem: 20571\n",
      "Train: [epoch:709]  [ 20/172]  eta: 0:04:08  lr: 0.000032  loss: 0.7860 (0.7921)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:709]  [ 30/172]  eta: 0:03:49  lr: 0.000032  loss: 0.7667 (0.7896)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:709]  [ 40/172]  eta: 0:03:32  lr: 0.000032  loss: 0.7667 (0.7853)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [ 50/172]  eta: 0:03:15  lr: 0.000032  loss: 0.7990 (0.7895)  time: 1.5814  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:709]  [ 60/172]  eta: 0:02:59  lr: 0.000032  loss: 0.7989 (0.7904)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [ 70/172]  eta: 0:02:42  lr: 0.000032  loss: 0.7706 (0.7898)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [ 80/172]  eta: 0:02:26  lr: 0.000032  loss: 0.7684 (0.7910)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [ 90/172]  eta: 0:02:10  lr: 0.000032  loss: 0.7683 (0.7892)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [100/172]  eta: 0:01:54  lr: 0.000032  loss: 0.7874 (0.7886)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [110/172]  eta: 0:01:38  lr: 0.000032  loss: 0.7878 (0.7882)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [120/172]  eta: 0:01:22  lr: 0.000032  loss: 0.7837 (0.7888)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [130/172]  eta: 0:01:06  lr: 0.000032  loss: 0.7837 (0.7902)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [140/172]  eta: 0:00:50  lr: 0.000032  loss: 0.7928 (0.7906)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [150/172]  eta: 0:00:34  lr: 0.000032  loss: 0.7927 (0.7912)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [160/172]  eta: 0:00:19  lr: 0.000032  loss: 0.7824 (0.7913)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [170/172]  eta: 0:00:03  lr: 0.000032  loss: 0.7908 (0.7921)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709]  [171/172]  eta: 0:00:01  lr: 0.000032  loss: 0.7908 (0.7924)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:709] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000032  loss: 0.7908 (0.7924)\n",
      "Valid: [epoch:709]  [ 0/14]  eta: 0:00:04  loss: 0.7070 (0.7070)  time: 0.3441  data: 0.3287  max mem: 20571\n",
      "Valid: [epoch:709]  [13/14]  eta: 0:00:00  loss: 0.7441 (0.7535)  time: 0.0403  data: 0.0252  max mem: 20571\n",
      "Valid: [epoch:709] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.7441 (0.7535)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_709_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.753%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:710]  [  0/172]  eta: 0:07:49  lr: 0.000032  loss: 0.8613 (0.8613)  time: 2.7318  data: 1.1640  max mem: 20571\n",
      "Train: [epoch:710]  [ 10/172]  eta: 0:04:32  lr: 0.000032  loss: 0.7805 (0.7826)  time: 1.6839  data: 0.1059  max mem: 20571\n",
      "Train: [epoch:710]  [ 20/172]  eta: 0:04:08  lr: 0.000032  loss: 0.7805 (0.7897)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [ 30/172]  eta: 0:03:49  lr: 0.000032  loss: 0.7912 (0.7885)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [ 40/172]  eta: 0:03:32  lr: 0.000032  loss: 0.7865 (0.7890)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [ 50/172]  eta: 0:03:15  lr: 0.000032  loss: 0.8053 (0.7941)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [ 60/172]  eta: 0:02:59  lr: 0.000032  loss: 0.8053 (0.7956)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [ 70/172]  eta: 0:02:42  lr: 0.000032  loss: 0.7928 (0.7948)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [ 80/172]  eta: 0:02:26  lr: 0.000032  loss: 0.7928 (0.7955)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [ 90/172]  eta: 0:02:10  lr: 0.000032  loss: 0.7909 (0.7926)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [100/172]  eta: 0:01:54  lr: 0.000032  loss: 0.7775 (0.7919)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [110/172]  eta: 0:01:38  lr: 0.000032  loss: 0.7987 (0.7918)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [120/172]  eta: 0:01:22  lr: 0.000032  loss: 0.8113 (0.7947)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [130/172]  eta: 0:01:06  lr: 0.000032  loss: 0.8119 (0.7965)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [140/172]  eta: 0:00:50  lr: 0.000032  loss: 0.7965 (0.7968)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [150/172]  eta: 0:00:34  lr: 0.000032  loss: 0.7865 (0.7969)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [160/172]  eta: 0:00:19  lr: 0.000032  loss: 0.7827 (0.7952)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [170/172]  eta: 0:00:03  lr: 0.000032  loss: 0.7803 (0.7954)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710]  [171/172]  eta: 0:00:01  lr: 0.000032  loss: 0.7803 (0.7951)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:710] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000032  loss: 0.7803 (0.7951)\n",
      "Valid: [epoch:710]  [ 0/14]  eta: 0:00:04  loss: 0.6931 (0.6931)  time: 0.3221  data: 0.3071  max mem: 20571\n",
      "Valid: [epoch:710]  [13/14]  eta: 0:00:00  loss: 0.7482 (0.7570)  time: 0.0392  data: 0.0242  max mem: 20571\n",
      "Valid: [epoch:710] Total time: 0:00:00 (0.0473 s / it)\n",
      "Averaged stats: loss: 0.7482 (0.7570)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_710_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.757%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:711]  [  0/172]  eta: 0:07:31  lr: 0.000032  loss: 0.7757 (0.7757)  time: 2.6240  data: 1.0393  max mem: 20571\n",
      "Train: [epoch:711]  [ 10/172]  eta: 0:04:31  lr: 0.000032  loss: 0.7843 (0.7859)  time: 1.6736  data: 0.0946  max mem: 20571\n",
      "Train: [epoch:711]  [ 20/172]  eta: 0:04:07  lr: 0.000032  loss: 0.7925 (0.8009)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [ 30/172]  eta: 0:03:49  lr: 0.000032  loss: 0.8040 (0.8027)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [ 40/172]  eta: 0:03:32  lr: 0.000032  loss: 0.8040 (0.8026)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [ 50/172]  eta: 0:03:15  lr: 0.000032  loss: 0.7862 (0.8003)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [ 60/172]  eta: 0:02:59  lr: 0.000032  loss: 0.7862 (0.7990)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [ 70/172]  eta: 0:02:42  lr: 0.000032  loss: 0.7987 (0.7997)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [ 80/172]  eta: 0:02:26  lr: 0.000032  loss: 0.8000 (0.7988)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [ 90/172]  eta: 0:02:10  lr: 0.000032  loss: 0.7934 (0.7978)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [100/172]  eta: 0:01:54  lr: 0.000032  loss: 0.7922 (0.7986)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [110/172]  eta: 0:01:38  lr: 0.000032  loss: 0.7959 (0.7987)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [120/172]  eta: 0:01:22  lr: 0.000032  loss: 0.7959 (0.8009)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [130/172]  eta: 0:01:06  lr: 0.000032  loss: 0.8000 (0.8015)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [140/172]  eta: 0:00:50  lr: 0.000032  loss: 0.7820 (0.7989)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [150/172]  eta: 0:00:34  lr: 0.000032  loss: 0.7840 (0.8001)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [160/172]  eta: 0:00:19  lr: 0.000032  loss: 0.7842 (0.7976)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [170/172]  eta: 0:00:03  lr: 0.000032  loss: 0.7658 (0.7964)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711]  [171/172]  eta: 0:00:01  lr: 0.000032  loss: 0.7731 (0.7962)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:711] Total time: 0:04:33 (1.5894 s / it)\n",
      "Averaged stats: lr: 0.000032  loss: 0.7731 (0.7962)\n",
      "Valid: [epoch:711]  [ 0/14]  eta: 0:00:04  loss: 0.6907 (0.6907)  time: 0.3082  data: 0.2934  max mem: 20571\n",
      "Valid: [epoch:711]  [13/14]  eta: 0:00:00  loss: 0.7633 (0.7725)  time: 0.0385  data: 0.0235  max mem: 20571\n",
      "Valid: [epoch:711] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.7633 (0.7725)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_711_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.772%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:712]  [  0/172]  eta: 0:07:27  lr: 0.000032  loss: 0.8734 (0.8734)  time: 2.6024  data: 1.0337  max mem: 20571\n",
      "Train: [epoch:712]  [ 10/172]  eta: 0:04:30  lr: 0.000032  loss: 0.7826 (0.7983)  time: 1.6723  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:712]  [ 20/172]  eta: 0:04:07  lr: 0.000032  loss: 0.7826 (0.7981)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [ 30/172]  eta: 0:03:49  lr: 0.000032  loss: 0.7754 (0.7957)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [ 40/172]  eta: 0:03:31  lr: 0.000032  loss: 0.7754 (0.7955)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [ 50/172]  eta: 0:03:15  lr: 0.000032  loss: 0.7809 (0.7953)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [ 60/172]  eta: 0:02:58  lr: 0.000032  loss: 0.7768 (0.7964)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:712]  [ 70/172]  eta: 0:02:42  lr: 0.000032  loss: 0.7697 (0.7966)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [ 80/172]  eta: 0:02:26  lr: 0.000032  loss: 0.7787 (0.7960)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [ 90/172]  eta: 0:02:10  lr: 0.000032  loss: 0.7845 (0.7948)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [100/172]  eta: 0:01:54  lr: 0.000032  loss: 0.7948 (0.7949)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [110/172]  eta: 0:01:38  lr: 0.000032  loss: 0.7948 (0.7954)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:712]  [120/172]  eta: 0:01:22  lr: 0.000032  loss: 0.7887 (0.7957)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [130/172]  eta: 0:01:06  lr: 0.000032  loss: 0.7894 (0.7953)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [140/172]  eta: 0:00:50  lr: 0.000032  loss: 0.7769 (0.7937)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [150/172]  eta: 0:00:34  lr: 0.000032  loss: 0.7719 (0.7924)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [160/172]  eta: 0:00:19  lr: 0.000032  loss: 0.7655 (0.7918)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [170/172]  eta: 0:00:03  lr: 0.000032  loss: 0.8051 (0.7947)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712]  [171/172]  eta: 0:00:01  lr: 0.000032  loss: 0.8051 (0.7945)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:712] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000032  loss: 0.8051 (0.7945)\n",
      "Valid: [epoch:712]  [ 0/14]  eta: 0:00:06  loss: 0.6926 (0.6926)  time: 0.4376  data: 0.4224  max mem: 20571\n",
      "Valid: [epoch:712]  [13/14]  eta: 0:00:00  loss: 0.7486 (0.7581)  time: 0.0463  data: 0.0313  max mem: 20571\n",
      "Valid: [epoch:712] Total time: 0:00:00 (0.0551 s / it)\n",
      "Averaged stats: loss: 0.7486 (0.7581)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_712_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.758%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:713]  [  0/172]  eta: 0:07:39  lr: 0.000032  loss: 0.7614 (0.7614)  time: 2.6715  data: 1.0977  max mem: 20571\n",
      "Train: [epoch:713]  [ 10/172]  eta: 0:04:31  lr: 0.000032  loss: 0.7869 (0.7934)  time: 1.6763  data: 0.0999  max mem: 20571\n",
      "Train: [epoch:713]  [ 20/172]  eta: 0:04:07  lr: 0.000032  loss: 0.7973 (0.8081)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [ 30/172]  eta: 0:03:49  lr: 0.000032  loss: 0.7831 (0.8011)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [ 40/172]  eta: 0:03:31  lr: 0.000032  loss: 0.7831 (0.7990)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [ 50/172]  eta: 0:03:15  lr: 0.000032  loss: 0.7891 (0.7971)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [ 60/172]  eta: 0:02:58  lr: 0.000032  loss: 0.7943 (0.7971)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [ 70/172]  eta: 0:02:42  lr: 0.000032  loss: 0.7737 (0.7952)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [ 80/172]  eta: 0:02:26  lr: 0.000032  loss: 0.7737 (0.7982)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [ 90/172]  eta: 0:02:10  lr: 0.000032  loss: 0.8036 (0.7986)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [100/172]  eta: 0:01:54  lr: 0.000032  loss: 0.7815 (0.7959)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [110/172]  eta: 0:01:38  lr: 0.000032  loss: 0.7840 (0.7979)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [120/172]  eta: 0:01:22  lr: 0.000032  loss: 0.8289 (0.8016)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [130/172]  eta: 0:01:06  lr: 0.000032  loss: 0.8055 (0.8011)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [140/172]  eta: 0:00:50  lr: 0.000032  loss: 0.7913 (0.8015)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [150/172]  eta: 0:00:34  lr: 0.000032  loss: 0.7913 (0.8004)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [160/172]  eta: 0:00:19  lr: 0.000032  loss: 0.7817 (0.8004)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [170/172]  eta: 0:00:03  lr: 0.000032  loss: 0.7934 (0.8002)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713]  [171/172]  eta: 0:00:01  lr: 0.000032  loss: 0.7923 (0.7998)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:713] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000032  loss: 0.7923 (0.7998)\n",
      "Valid: [epoch:713]  [ 0/14]  eta: 0:00:04  loss: 0.7988 (0.7988)  time: 0.2979  data: 0.2815  max mem: 20571\n",
      "Valid: [epoch:713]  [13/14]  eta: 0:00:00  loss: 0.7497 (0.7595)  time: 0.0369  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:713] Total time: 0:00:00 (0.0447 s / it)\n",
      "Averaged stats: loss: 0.7497 (0.7595)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_713_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.760%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:714]  [  0/172]  eta: 0:08:11  lr: 0.000032  loss: 0.7830 (0.7830)  time: 2.8591  data: 1.2910  max mem: 20571\n",
      "Train: [epoch:714]  [ 10/172]  eta: 0:04:34  lr: 0.000032  loss: 0.7830 (0.7770)  time: 1.6975  data: 0.1175  max mem: 20571\n",
      "Train: [epoch:714]  [ 20/172]  eta: 0:04:09  lr: 0.000032  loss: 0.7816 (0.7792)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:714]  [ 30/172]  eta: 0:03:50  lr: 0.000032  loss: 0.8012 (0.7891)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [ 40/172]  eta: 0:03:33  lr: 0.000032  loss: 0.7808 (0.7861)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [ 50/172]  eta: 0:03:16  lr: 0.000032  loss: 0.7824 (0.7912)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [ 60/172]  eta: 0:02:59  lr: 0.000032  loss: 0.8038 (0.7932)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [ 70/172]  eta: 0:02:43  lr: 0.000032  loss: 0.8085 (0.7951)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [ 80/172]  eta: 0:02:27  lr: 0.000032  loss: 0.8163 (0.7980)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [ 90/172]  eta: 0:02:10  lr: 0.000032  loss: 0.8066 (0.7979)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [100/172]  eta: 0:01:54  lr: 0.000032  loss: 0.7808 (0.7961)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [110/172]  eta: 0:01:38  lr: 0.000032  loss: 0.7806 (0.7958)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [120/172]  eta: 0:01:22  lr: 0.000032  loss: 0.7806 (0.7942)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [130/172]  eta: 0:01:06  lr: 0.000032  loss: 0.7803 (0.7944)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [140/172]  eta: 0:00:50  lr: 0.000032  loss: 0.8063 (0.7961)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [150/172]  eta: 0:00:35  lr: 0.000032  loss: 0.8153 (0.7966)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [160/172]  eta: 0:00:19  lr: 0.000032  loss: 0.7848 (0.7967)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714]  [170/172]  eta: 0:00:03  lr: 0.000032  loss: 0.7741 (0.7961)  time: 1.5837  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:714]  [171/172]  eta: 0:00:01  lr: 0.000032  loss: 0.7823 (0.7964)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:714] Total time: 0:04:33 (1.5912 s / it)\n",
      "Averaged stats: lr: 0.000032  loss: 0.7823 (0.7964)\n",
      "Valid: [epoch:714]  [ 0/14]  eta: 0:00:04  loss: 0.7501 (0.7501)  time: 0.3101  data: 0.2955  max mem: 20571\n",
      "Valid: [epoch:714]  [13/14]  eta: 0:00:00  loss: 0.7549 (0.7645)  time: 0.0443  data: 0.0293  max mem: 20571\n",
      "Valid: [epoch:714] Total time: 0:00:00 (0.0501 s / it)\n",
      "Averaged stats: loss: 0.7549 (0.7645)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_714_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.764%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:715]  [  0/172]  eta: 0:07:31  lr: 0.000032  loss: 0.7500 (0.7500)  time: 2.6238  data: 1.0426  max mem: 20571\n",
      "Train: [epoch:715]  [ 10/172]  eta: 0:04:31  lr: 0.000032  loss: 0.7667 (0.7718)  time: 1.6736  data: 0.0949  max mem: 20571\n",
      "Train: [epoch:715]  [ 20/172]  eta: 0:04:07  lr: 0.000032  loss: 0.7749 (0.7915)  time: 1.5786  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:715]  [ 30/172]  eta: 0:03:48  lr: 0.000032  loss: 0.8238 (0.7985)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:715]  [ 40/172]  eta: 0:03:31  lr: 0.000032  loss: 0.8139 (0.7995)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:715]  [ 50/172]  eta: 0:03:15  lr: 0.000032  loss: 0.7873 (0.7983)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [ 60/172]  eta: 0:02:58  lr: 0.000032  loss: 0.7871 (0.7982)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [ 70/172]  eta: 0:02:42  lr: 0.000032  loss: 0.7933 (0.7990)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [ 80/172]  eta: 0:02:26  lr: 0.000032  loss: 0.8003 (0.7975)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:715]  [ 90/172]  eta: 0:02:10  lr: 0.000032  loss: 0.7912 (0.7979)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:715]  [100/172]  eta: 0:01:54  lr: 0.000032  loss: 0.7912 (0.7979)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:715]  [110/172]  eta: 0:01:38  lr: 0.000032  loss: 0.8033 (0.7978)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [120/172]  eta: 0:01:22  lr: 0.000032  loss: 0.7992 (0.7974)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [130/172]  eta: 0:01:06  lr: 0.000032  loss: 0.8052 (0.7989)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [140/172]  eta: 0:00:50  lr: 0.000032  loss: 0.7859 (0.7986)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [150/172]  eta: 0:00:34  lr: 0.000032  loss: 0.7759 (0.7983)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [160/172]  eta: 0:00:19  lr: 0.000032  loss: 0.8038 (0.7983)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [170/172]  eta: 0:00:03  lr: 0.000032  loss: 0.8038 (0.7992)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715]  [171/172]  eta: 0:00:01  lr: 0.000032  loss: 0.8031 (0.7991)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:715] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000032  loss: 0.8031 (0.7991)\n",
      "Valid: [epoch:715]  [ 0/14]  eta: 0:00:06  loss: 0.7978 (0.7978)  time: 0.4510  data: 0.4354  max mem: 20571\n",
      "Valid: [epoch:715]  [13/14]  eta: 0:00:00  loss: 0.7579 (0.7674)  time: 0.0476  data: 0.0324  max mem: 20571\n",
      "Valid: [epoch:715] Total time: 0:00:00 (0.0531 s / it)\n",
      "Averaged stats: loss: 0.7579 (0.7674)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_715_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.767%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:716]  [  0/172]  eta: 0:07:37  lr: 0.000032  loss: 0.7448 (0.7448)  time: 2.6620  data: 1.0951  max mem: 20571\n",
      "Train: [epoch:716]  [ 10/172]  eta: 0:04:31  lr: 0.000032  loss: 0.8161 (0.8132)  time: 1.6752  data: 0.0997  max mem: 20571\n",
      "Train: [epoch:716]  [ 20/172]  eta: 0:04:07  lr: 0.000032  loss: 0.8161 (0.8107)  time: 1.5773  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:716]  [ 30/172]  eta: 0:03:48  lr: 0.000032  loss: 0.7997 (0.8116)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:716]  [ 40/172]  eta: 0:03:31  lr: 0.000032  loss: 0.7915 (0.8088)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [ 50/172]  eta: 0:03:15  lr: 0.000032  loss: 0.7915 (0.8038)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [ 60/172]  eta: 0:02:58  lr: 0.000032  loss: 0.7934 (0.8032)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [ 70/172]  eta: 0:02:42  lr: 0.000032  loss: 0.7984 (0.8028)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [ 80/172]  eta: 0:02:26  lr: 0.000032  loss: 0.7943 (0.8031)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [ 90/172]  eta: 0:02:10  lr: 0.000032  loss: 0.7798 (0.7989)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [100/172]  eta: 0:01:54  lr: 0.000032  loss: 0.7780 (0.7982)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [110/172]  eta: 0:01:38  lr: 0.000032  loss: 0.7998 (0.7995)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [120/172]  eta: 0:01:22  lr: 0.000032  loss: 0.8193 (0.8009)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [130/172]  eta: 0:01:06  lr: 0.000032  loss: 0.7896 (0.8006)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [140/172]  eta: 0:00:50  lr: 0.000032  loss: 0.7896 (0.7999)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [150/172]  eta: 0:00:34  lr: 0.000032  loss: 0.7824 (0.7987)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [160/172]  eta: 0:00:19  lr: 0.000032  loss: 0.7914 (0.8000)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [170/172]  eta: 0:00:03  lr: 0.000032  loss: 0.7918 (0.7991)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716]  [171/172]  eta: 0:00:01  lr: 0.000032  loss: 0.7918 (0.7993)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:716] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000032  loss: 0.7918 (0.7993)\n",
      "Valid: [epoch:716]  [ 0/14]  eta: 0:00:04  loss: 0.7994 (0.7994)  time: 0.2985  data: 0.2816  max mem: 20571\n",
      "Valid: [epoch:716]  [13/14]  eta: 0:00:00  loss: 0.7591 (0.7684)  time: 0.0398  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:716] Total time: 0:00:00 (0.0476 s / it)\n",
      "Averaged stats: loss: 0.7591 (0.7684)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_716_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.768%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:717]  [  0/172]  eta: 0:07:47  lr: 0.000032  loss: 0.8182 (0.8182)  time: 2.7162  data: 1.1396  max mem: 20571\n",
      "Train: [epoch:717]  [ 10/172]  eta: 0:04:32  lr: 0.000032  loss: 0.7887 (0.7947)  time: 1.6810  data: 0.1038  max mem: 20571\n",
      "Train: [epoch:717]  [ 20/172]  eta: 0:04:08  lr: 0.000032  loss: 0.8165 (0.8070)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:717]  [ 30/172]  eta: 0:03:49  lr: 0.000032  loss: 0.8192 (0.8045)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:717]  [ 40/172]  eta: 0:03:32  lr: 0.000032  loss: 0.7796 (0.7975)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [ 50/172]  eta: 0:03:15  lr: 0.000032  loss: 0.7875 (0.8003)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [ 60/172]  eta: 0:02:59  lr: 0.000032  loss: 0.7875 (0.7980)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:717]  [ 70/172]  eta: 0:02:42  lr: 0.000032  loss: 0.7827 (0.7995)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [ 80/172]  eta: 0:02:26  lr: 0.000032  loss: 0.7827 (0.7965)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [ 90/172]  eta: 0:02:10  lr: 0.000032  loss: 0.7813 (0.7967)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [100/172]  eta: 0:01:54  lr: 0.000032  loss: 0.7980 (0.7994)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [110/172]  eta: 0:01:38  lr: 0.000032  loss: 0.8138 (0.8032)  time: 1.5826  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:717]  [120/172]  eta: 0:01:22  lr: 0.000032  loss: 0.8383 (0.8064)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [130/172]  eta: 0:01:06  lr: 0.000032  loss: 0.8226 (0.8069)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [140/172]  eta: 0:00:50  lr: 0.000032  loss: 0.8033 (0.8066)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [150/172]  eta: 0:00:34  lr: 0.000032  loss: 0.7886 (0.8064)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [160/172]  eta: 0:00:19  lr: 0.000032  loss: 0.8003 (0.8073)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [170/172]  eta: 0:00:03  lr: 0.000032  loss: 0.8029 (0.8067)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717]  [171/172]  eta: 0:00:01  lr: 0.000032  loss: 0.8029 (0.8066)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:717] Total time: 0:04:33 (1.5901 s / it)\n",
      "Averaged stats: lr: 0.000032  loss: 0.8029 (0.8066)\n",
      "Valid: [epoch:717]  [ 0/14]  eta: 0:00:06  loss: 0.7368 (0.7368)  time: 0.4975  data: 0.4793  max mem: 20571\n",
      "Valid: [epoch:717]  [13/14]  eta: 0:00:00  loss: 0.7530 (0.7622)  time: 0.0507  data: 0.0356  max mem: 20571\n",
      "Valid: [epoch:717] Total time: 0:00:00 (0.0558 s / it)\n",
      "Averaged stats: loss: 0.7530 (0.7622)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_717_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.762%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:718]  [  0/172]  eta: 0:07:54  lr: 0.000031  loss: 0.7565 (0.7565)  time: 2.7611  data: 1.1781  max mem: 20571\n",
      "Train: [epoch:718]  [ 10/172]  eta: 0:04:33  lr: 0.000031  loss: 0.7571 (0.7645)  time: 1.6895  data: 0.1072  max mem: 20571\n",
      "Train: [epoch:718]  [ 20/172]  eta: 0:04:09  lr: 0.000031  loss: 0.7805 (0.7807)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [ 30/172]  eta: 0:03:50  lr: 0.000031  loss: 0.7965 (0.7852)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [ 40/172]  eta: 0:03:32  lr: 0.000031  loss: 0.7931 (0.7878)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [ 50/172]  eta: 0:03:16  lr: 0.000031  loss: 0.7931 (0.7910)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [ 60/172]  eta: 0:02:59  lr: 0.000031  loss: 0.7885 (0.7928)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [ 70/172]  eta: 0:02:43  lr: 0.000031  loss: 0.7849 (0.7931)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [ 80/172]  eta: 0:02:27  lr: 0.000031  loss: 0.7858 (0.7949)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [ 90/172]  eta: 0:02:10  lr: 0.000031  loss: 0.7968 (0.7944)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [100/172]  eta: 0:01:54  lr: 0.000031  loss: 0.7859 (0.7943)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [110/172]  eta: 0:01:38  lr: 0.000031  loss: 0.7785 (0.7931)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [120/172]  eta: 0:01:22  lr: 0.000031  loss: 0.8057 (0.7947)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [130/172]  eta: 0:01:06  lr: 0.000031  loss: 0.8098 (0.7955)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [140/172]  eta: 0:00:50  lr: 0.000031  loss: 0.8022 (0.7974)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [150/172]  eta: 0:00:35  lr: 0.000031  loss: 0.7944 (0.7979)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [160/172]  eta: 0:00:19  lr: 0.000031  loss: 0.8050 (0.7990)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [170/172]  eta: 0:00:03  lr: 0.000031  loss: 0.8093 (0.7991)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718]  [171/172]  eta: 0:00:01  lr: 0.000031  loss: 0.8096 (0.7996)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:718] Total time: 0:04:33 (1.5910 s / it)\n",
      "Averaged stats: lr: 0.000031  loss: 0.8096 (0.7996)\n",
      "Valid: [epoch:718]  [ 0/14]  eta: 0:00:04  loss: 0.7413 (0.7413)  time: 0.3244  data: 0.3094  max mem: 20571\n",
      "Valid: [epoch:718]  [13/14]  eta: 0:00:00  loss: 0.7562 (0.7652)  time: 0.0382  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:718] Total time: 0:00:00 (0.0432 s / it)\n",
      "Averaged stats: loss: 0.7562 (0.7652)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_718_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.765%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:719]  [  0/172]  eta: 0:07:51  lr: 0.000031  loss: 0.7780 (0.7780)  time: 2.7425  data: 1.1606  max mem: 20571\n",
      "Train: [epoch:719]  [ 10/172]  eta: 0:04:32  lr: 0.000031  loss: 0.8057 (0.8009)  time: 1.6833  data: 0.1056  max mem: 20571\n",
      "Train: [epoch:719]  [ 20/172]  eta: 0:04:08  lr: 0.000031  loss: 0.8151 (0.8163)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [ 30/172]  eta: 0:03:49  lr: 0.000031  loss: 0.8077 (0.8043)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [ 40/172]  eta: 0:03:32  lr: 0.000031  loss: 0.7600 (0.7944)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [ 50/172]  eta: 0:03:15  lr: 0.000031  loss: 0.7734 (0.7967)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [ 60/172]  eta: 0:02:59  lr: 0.000031  loss: 0.8072 (0.7998)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [ 70/172]  eta: 0:02:43  lr: 0.000031  loss: 0.7995 (0.7994)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [ 80/172]  eta: 0:02:26  lr: 0.000031  loss: 0.8124 (0.8021)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [ 90/172]  eta: 0:02:10  lr: 0.000031  loss: 0.8221 (0.8031)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [100/172]  eta: 0:01:54  lr: 0.000031  loss: 0.7836 (0.8020)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [110/172]  eta: 0:01:38  lr: 0.000031  loss: 0.7783 (0.8007)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [120/172]  eta: 0:01:22  lr: 0.000031  loss: 0.7906 (0.8012)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [130/172]  eta: 0:01:06  lr: 0.000031  loss: 0.8074 (0.8020)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [140/172]  eta: 0:00:50  lr: 0.000031  loss: 0.7984 (0.8013)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [150/172]  eta: 0:00:34  lr: 0.000031  loss: 0.7813 (0.8013)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [160/172]  eta: 0:00:19  lr: 0.000031  loss: 0.8071 (0.8025)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [170/172]  eta: 0:00:03  lr: 0.000031  loss: 0.8132 (0.8033)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719]  [171/172]  eta: 0:00:01  lr: 0.000031  loss: 0.8132 (0.8031)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:719] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000031  loss: 0.8132 (0.8031)\n",
      "Valid: [epoch:719]  [ 0/14]  eta: 0:00:04  loss: 0.7928 (0.7928)  time: 0.3225  data: 0.3065  max mem: 20571\n",
      "Valid: [epoch:719]  [13/14]  eta: 0:00:00  loss: 0.7560 (0.7650)  time: 0.0384  data: 0.0235  max mem: 20571\n",
      "Valid: [epoch:719] Total time: 0:00:00 (0.0442 s / it)\n",
      "Averaged stats: loss: 0.7560 (0.7650)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_719_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.765%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:720]  [  0/172]  eta: 0:07:46  lr: 0.000031  loss: 0.6933 (0.6933)  time: 2.7140  data: 1.1461  max mem: 20571\n",
      "Train: [epoch:720]  [ 10/172]  eta: 0:04:32  lr: 0.000031  loss: 0.8117 (0.8207)  time: 1.6822  data: 0.1043  max mem: 20571\n",
      "Train: [epoch:720]  [ 20/172]  eta: 0:04:08  lr: 0.000031  loss: 0.8021 (0.8150)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [ 30/172]  eta: 0:03:49  lr: 0.000031  loss: 0.7978 (0.8064)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [ 40/172]  eta: 0:03:32  lr: 0.000031  loss: 0.7871 (0.7989)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [ 50/172]  eta: 0:03:15  lr: 0.000031  loss: 0.7889 (0.8023)  time: 1.5806  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:720]  [ 60/172]  eta: 0:02:59  lr: 0.000031  loss: 0.8135 (0.8071)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [ 70/172]  eta: 0:02:42  lr: 0.000031  loss: 0.8049 (0.8074)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [ 80/172]  eta: 0:02:26  lr: 0.000031  loss: 0.7957 (0.8062)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:720]  [ 90/172]  eta: 0:02:10  lr: 0.000031  loss: 0.7908 (0.8055)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [100/172]  eta: 0:01:54  lr: 0.000031  loss: 0.7873 (0.8045)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [110/172]  eta: 0:01:38  lr: 0.000031  loss: 0.8074 (0.8062)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [120/172]  eta: 0:01:22  lr: 0.000031  loss: 0.8061 (0.8069)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [130/172]  eta: 0:01:06  lr: 0.000031  loss: 0.7915 (0.8072)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [140/172]  eta: 0:00:50  lr: 0.000031  loss: 0.7838 (0.8051)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [150/172]  eta: 0:00:34  lr: 0.000031  loss: 0.7838 (0.8047)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [160/172]  eta: 0:00:19  lr: 0.000031  loss: 0.7918 (0.8042)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [170/172]  eta: 0:00:03  lr: 0.000031  loss: 0.7918 (0.8040)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720]  [171/172]  eta: 0:00:01  lr: 0.000031  loss: 0.7918 (0.8040)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:720] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000031  loss: 0.7918 (0.8040)\n",
      "Valid: [epoch:720]  [ 0/14]  eta: 0:00:05  loss: 0.7604 (0.7604)  time: 0.4014  data: 0.3806  max mem: 20571\n",
      "Valid: [epoch:720]  [13/14]  eta: 0:00:00  loss: 0.7640 (0.7743)  time: 0.0443  data: 0.0289  max mem: 20571\n",
      "Valid: [epoch:720] Total time: 0:00:00 (0.0527 s / it)\n",
      "Averaged stats: loss: 0.7640 (0.7743)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_720_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.774%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:721]  [  0/172]  eta: 0:07:56  lr: 0.000031  loss: 0.7879 (0.7879)  time: 2.7692  data: 1.1945  max mem: 20571\n",
      "Train: [epoch:721]  [ 10/172]  eta: 0:04:32  lr: 0.000031  loss: 0.7879 (0.7996)  time: 1.6846  data: 0.1087  max mem: 20571\n",
      "Train: [epoch:721]  [ 20/172]  eta: 0:04:08  lr: 0.000031  loss: 0.7777 (0.7975)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [ 30/172]  eta: 0:03:49  lr: 0.000031  loss: 0.7831 (0.7992)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [ 40/172]  eta: 0:03:32  lr: 0.000031  loss: 0.8112 (0.8000)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [ 50/172]  eta: 0:03:15  lr: 0.000031  loss: 0.7894 (0.7992)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [ 60/172]  eta: 0:02:59  lr: 0.000031  loss: 0.7878 (0.7974)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [ 70/172]  eta: 0:02:42  lr: 0.000031  loss: 0.7899 (0.7991)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [ 80/172]  eta: 0:02:26  lr: 0.000031  loss: 0.7893 (0.7986)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [ 90/172]  eta: 0:02:10  lr: 0.000031  loss: 0.8053 (0.8020)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [100/172]  eta: 0:01:54  lr: 0.000031  loss: 0.8053 (0.8006)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [110/172]  eta: 0:01:38  lr: 0.000031  loss: 0.7892 (0.8012)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [120/172]  eta: 0:01:22  lr: 0.000031  loss: 0.7965 (0.8011)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [130/172]  eta: 0:01:06  lr: 0.000031  loss: 0.8173 (0.8024)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [140/172]  eta: 0:00:50  lr: 0.000031  loss: 0.8117 (0.8028)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [150/172]  eta: 0:00:34  lr: 0.000031  loss: 0.8122 (0.8056)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [160/172]  eta: 0:00:19  lr: 0.000031  loss: 0.8121 (0.8040)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [170/172]  eta: 0:00:03  lr: 0.000031  loss: 0.8118 (0.8051)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721]  [171/172]  eta: 0:00:01  lr: 0.000031  loss: 0.8120 (0.8053)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:721] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000031  loss: 0.8120 (0.8053)\n",
      "Valid: [epoch:721]  [ 0/14]  eta: 0:00:05  loss: 0.7625 (0.7625)  time: 0.4053  data: 0.3892  max mem: 20571\n",
      "Valid: [epoch:721]  [13/14]  eta: 0:00:00  loss: 0.7676 (0.7765)  time: 0.0471  data: 0.0321  max mem: 20571\n",
      "Valid: [epoch:721] Total time: 0:00:00 (0.0520 s / it)\n",
      "Averaged stats: loss: 0.7676 (0.7765)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_721_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.776%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:722]  [  0/172]  eta: 0:08:01  lr: 0.000031  loss: 0.7668 (0.7668)  time: 2.7977  data: 1.2279  max mem: 20571\n",
      "Train: [epoch:722]  [ 10/172]  eta: 0:04:34  lr: 0.000031  loss: 0.7998 (0.7932)  time: 1.6931  data: 0.1117  max mem: 20571\n",
      "Train: [epoch:722]  [ 20/172]  eta: 0:04:09  lr: 0.000031  loss: 0.8147 (0.8041)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [ 30/172]  eta: 0:03:50  lr: 0.000031  loss: 0.8053 (0.8019)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [ 40/172]  eta: 0:03:32  lr: 0.000031  loss: 0.7956 (0.8006)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [ 50/172]  eta: 0:03:16  lr: 0.000031  loss: 0.8039 (0.8033)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [ 60/172]  eta: 0:02:59  lr: 0.000031  loss: 0.8032 (0.8011)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [ 70/172]  eta: 0:02:43  lr: 0.000031  loss: 0.8093 (0.8042)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [ 80/172]  eta: 0:02:26  lr: 0.000031  loss: 0.8143 (0.8048)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [ 90/172]  eta: 0:02:10  lr: 0.000031  loss: 0.8127 (0.8084)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [100/172]  eta: 0:01:54  lr: 0.000031  loss: 0.8127 (0.8071)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [110/172]  eta: 0:01:38  lr: 0.000031  loss: 0.8153 (0.8094)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [120/172]  eta: 0:01:22  lr: 0.000031  loss: 0.7846 (0.8067)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [130/172]  eta: 0:01:06  lr: 0.000031  loss: 0.7941 (0.8071)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [140/172]  eta: 0:00:50  lr: 0.000031  loss: 0.8087 (0.8071)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [150/172]  eta: 0:00:34  lr: 0.000031  loss: 0.8043 (0.8072)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [160/172]  eta: 0:00:19  lr: 0.000031  loss: 0.8103 (0.8071)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [170/172]  eta: 0:00:03  lr: 0.000031  loss: 0.8031 (0.8077)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722]  [171/172]  eta: 0:00:01  lr: 0.000031  loss: 0.8023 (0.8076)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:722] Total time: 0:04:33 (1.5900 s / it)\n",
      "Averaged stats: lr: 0.000031  loss: 0.8023 (0.8076)\n",
      "Valid: [epoch:722]  [ 0/14]  eta: 0:00:04  loss: 0.7442 (0.7442)  time: 0.2879  data: 0.2728  max mem: 20571\n",
      "Valid: [epoch:722]  [13/14]  eta: 0:00:00  loss: 0.7588 (0.7688)  time: 0.0365  data: 0.0216  max mem: 20571\n",
      "Valid: [epoch:722] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.7588 (0.7688)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_722_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.769%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:723]  [  0/172]  eta: 0:07:38  lr: 0.000031  loss: 0.8129 (0.8129)  time: 2.6654  data: 1.0889  max mem: 20571\n",
      "Train: [epoch:723]  [ 10/172]  eta: 0:04:31  lr: 0.000031  loss: 0.7947 (0.8047)  time: 1.6751  data: 0.0991  max mem: 20571\n",
      "Train: [epoch:723]  [ 20/172]  eta: 0:04:07  lr: 0.000031  loss: 0.7947 (0.8108)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [ 30/172]  eta: 0:03:49  lr: 0.000031  loss: 0.7956 (0.8034)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [ 40/172]  eta: 0:03:31  lr: 0.000031  loss: 0.8038 (0.8017)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [ 50/172]  eta: 0:03:15  lr: 0.000031  loss: 0.8144 (0.8054)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [ 60/172]  eta: 0:02:58  lr: 0.000031  loss: 0.8010 (0.8027)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [ 70/172]  eta: 0:02:42  lr: 0.000031  loss: 0.8176 (0.8050)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [ 80/172]  eta: 0:02:26  lr: 0.000031  loss: 0.8256 (0.8074)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [ 90/172]  eta: 0:02:10  lr: 0.000031  loss: 0.8160 (0.8079)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [100/172]  eta: 0:01:54  lr: 0.000031  loss: 0.8078 (0.8061)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [110/172]  eta: 0:01:38  lr: 0.000031  loss: 0.7945 (0.8038)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:723]  [120/172]  eta: 0:01:22  lr: 0.000031  loss: 0.7843 (0.8035)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [130/172]  eta: 0:01:06  lr: 0.000031  loss: 0.7983 (0.8039)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [140/172]  eta: 0:00:50  lr: 0.000031  loss: 0.8200 (0.8056)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [150/172]  eta: 0:00:34  lr: 0.000031  loss: 0.8046 (0.8054)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [160/172]  eta: 0:00:19  lr: 0.000031  loss: 0.8089 (0.8074)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [170/172]  eta: 0:00:03  lr: 0.000031  loss: 0.8153 (0.8080)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723]  [171/172]  eta: 0:00:01  lr: 0.000031  loss: 0.8153 (0.8084)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:723] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000031  loss: 0.8153 (0.8084)\n",
      "Valid: [epoch:723]  [ 0/14]  eta: 0:00:04  loss: 0.7545 (0.7545)  time: 0.3172  data: 0.3005  max mem: 20571\n",
      "Valid: [epoch:723]  [13/14]  eta: 0:00:00  loss: 0.7602 (0.7686)  time: 0.0384  data: 0.0232  max mem: 20571\n",
      "Valid: [epoch:723] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.7602 (0.7686)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_723_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.769%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:724]  [  0/172]  eta: 0:07:24  lr: 0.000031  loss: 0.7694 (0.7694)  time: 2.5863  data: 1.0213  max mem: 20571\n",
      "Train: [epoch:724]  [ 10/172]  eta: 0:04:30  lr: 0.000031  loss: 0.7965 (0.8010)  time: 1.6706  data: 0.0930  max mem: 20571\n",
      "Train: [epoch:724]  [ 20/172]  eta: 0:04:07  lr: 0.000031  loss: 0.7911 (0.7955)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [ 30/172]  eta: 0:03:48  lr: 0.000031  loss: 0.7911 (0.7970)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [ 40/172]  eta: 0:03:31  lr: 0.000031  loss: 0.7885 (0.7920)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [ 50/172]  eta: 0:03:15  lr: 0.000031  loss: 0.7894 (0.7990)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [ 60/172]  eta: 0:02:58  lr: 0.000031  loss: 0.7865 (0.7995)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [ 70/172]  eta: 0:02:42  lr: 0.000031  loss: 0.7810 (0.8025)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [ 80/172]  eta: 0:02:26  lr: 0.000031  loss: 0.8131 (0.8035)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [ 90/172]  eta: 0:02:10  lr: 0.000031  loss: 0.7850 (0.8027)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [100/172]  eta: 0:01:54  lr: 0.000031  loss: 0.8000 (0.8049)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [110/172]  eta: 0:01:38  lr: 0.000031  loss: 0.8000 (0.8035)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [120/172]  eta: 0:01:22  lr: 0.000031  loss: 0.7926 (0.8035)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [130/172]  eta: 0:01:06  lr: 0.000031  loss: 0.8097 (0.8053)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [140/172]  eta: 0:00:50  lr: 0.000031  loss: 0.8048 (0.8050)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [150/172]  eta: 0:00:34  lr: 0.000031  loss: 0.7955 (0.8056)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [160/172]  eta: 0:00:19  lr: 0.000031  loss: 0.8140 (0.8058)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [170/172]  eta: 0:00:03  lr: 0.000031  loss: 0.7956 (0.8061)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724]  [171/172]  eta: 0:00:01  lr: 0.000031  loss: 0.7992 (0.8069)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:724] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000031  loss: 0.7992 (0.8069)\n",
      "Valid: [epoch:724]  [ 0/14]  eta: 0:00:06  loss: 0.8334 (0.8334)  time: 0.4932  data: 0.4779  max mem: 20571\n",
      "Valid: [epoch:724]  [13/14]  eta: 0:00:00  loss: 0.7584 (0.7681)  time: 0.0510  data: 0.0359  max mem: 20571\n",
      "Valid: [epoch:724] Total time: 0:00:00 (0.0591 s / it)\n",
      "Averaged stats: loss: 0.7584 (0.7681)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_724_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.768%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:725]  [  0/172]  eta: 0:07:39  lr: 0.000031  loss: 0.7454 (0.7454)  time: 2.6690  data: 1.0760  max mem: 20571\n",
      "Train: [epoch:725]  [ 10/172]  eta: 0:04:31  lr: 0.000031  loss: 0.8002 (0.7967)  time: 1.6773  data: 0.0980  max mem: 20571\n",
      "Train: [epoch:725]  [ 20/172]  eta: 0:04:07  lr: 0.000031  loss: 0.8093 (0.8032)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [ 30/172]  eta: 0:03:49  lr: 0.000031  loss: 0.7927 (0.7976)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [ 40/172]  eta: 0:03:32  lr: 0.000031  loss: 0.7926 (0.8006)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [ 50/172]  eta: 0:03:15  lr: 0.000031  loss: 0.8050 (0.8015)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [ 60/172]  eta: 0:02:58  lr: 0.000031  loss: 0.8224 (0.8075)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [ 70/172]  eta: 0:02:42  lr: 0.000031  loss: 0.8224 (0.8059)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [ 80/172]  eta: 0:02:26  lr: 0.000031  loss: 0.8041 (0.8084)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [ 90/172]  eta: 0:02:10  lr: 0.000031  loss: 0.8085 (0.8097)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [100/172]  eta: 0:01:54  lr: 0.000031  loss: 0.8071 (0.8101)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [110/172]  eta: 0:01:38  lr: 0.000031  loss: 0.7937 (0.8108)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [120/172]  eta: 0:01:22  lr: 0.000031  loss: 0.8015 (0.8113)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [130/172]  eta: 0:01:06  lr: 0.000031  loss: 0.8126 (0.8120)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [140/172]  eta: 0:00:50  lr: 0.000031  loss: 0.7890 (0.8104)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [150/172]  eta: 0:00:34  lr: 0.000031  loss: 0.7822 (0.8086)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [160/172]  eta: 0:00:19  lr: 0.000031  loss: 0.7904 (0.8087)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725]  [170/172]  eta: 0:00:03  lr: 0.000031  loss: 0.8121 (0.8096)  time: 1.5840  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:725]  [171/172]  eta: 0:00:01  lr: 0.000031  loss: 0.8121 (0.8095)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:725] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000031  loss: 0.8121 (0.8095)\n",
      "Valid: [epoch:725]  [ 0/14]  eta: 0:00:04  loss: 0.7544 (0.7544)  time: 0.3168  data: 0.3019  max mem: 20571\n",
      "Valid: [epoch:725]  [13/14]  eta: 0:00:00  loss: 0.7724 (0.7812)  time: 0.0444  data: 0.0294  max mem: 20571\n",
      "Valid: [epoch:725] Total time: 0:00:00 (0.0493 s / it)\n",
      "Averaged stats: loss: 0.7724 (0.7812)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_725_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.781%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:726]  [  0/172]  eta: 0:08:22  lr: 0.000031  loss: 0.8302 (0.8302)  time: 2.9202  data: 1.3530  max mem: 20571\n",
      "Train: [epoch:726]  [ 10/172]  eta: 0:04:35  lr: 0.000031  loss: 0.8301 (0.8111)  time: 1.7036  data: 0.1231  max mem: 20571\n",
      "Train: [epoch:726]  [ 20/172]  eta: 0:04:10  lr: 0.000031  loss: 0.7929 (0.8048)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [ 30/172]  eta: 0:03:50  lr: 0.000031  loss: 0.7966 (0.8055)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [ 40/172]  eta: 0:03:33  lr: 0.000031  loss: 0.7995 (0.8075)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [ 50/172]  eta: 0:03:16  lr: 0.000031  loss: 0.7974 (0.8053)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [ 60/172]  eta: 0:02:59  lr: 0.000031  loss: 0.7972 (0.8082)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [ 70/172]  eta: 0:02:43  lr: 0.000031  loss: 0.8043 (0.8099)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [ 80/172]  eta: 0:02:27  lr: 0.000031  loss: 0.8011 (0.8089)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [ 90/172]  eta: 0:02:10  lr: 0.000031  loss: 0.7930 (0.8083)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [100/172]  eta: 0:01:54  lr: 0.000031  loss: 0.8051 (0.8090)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [110/172]  eta: 0:01:38  lr: 0.000031  loss: 0.8002 (0.8091)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [120/172]  eta: 0:01:22  lr: 0.000031  loss: 0.7894 (0.8092)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [130/172]  eta: 0:01:06  lr: 0.000031  loss: 0.8118 (0.8096)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [140/172]  eta: 0:00:50  lr: 0.000031  loss: 0.8037 (0.8088)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [150/172]  eta: 0:00:34  lr: 0.000031  loss: 0.7947 (0.8086)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [160/172]  eta: 0:00:19  lr: 0.000031  loss: 0.8124 (0.8092)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [170/172]  eta: 0:00:03  lr: 0.000031  loss: 0.8114 (0.8090)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726]  [171/172]  eta: 0:00:01  lr: 0.000031  loss: 0.8114 (0.8094)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:726] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000031  loss: 0.8114 (0.8094)\n",
      "Valid: [epoch:726]  [ 0/14]  eta: 0:00:04  loss: 0.8197 (0.8197)  time: 0.3162  data: 0.3014  max mem: 20571\n",
      "Valid: [epoch:726]  [13/14]  eta: 0:00:00  loss: 0.7843 (0.7937)  time: 0.0437  data: 0.0286  max mem: 20571\n",
      "Valid: [epoch:726] Total time: 0:00:00 (0.0521 s / it)\n",
      "Averaged stats: loss: 0.7843 (0.7937)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_726_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.794%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:727]  [  0/172]  eta: 0:08:02  lr: 0.000030  loss: 0.8237 (0.8237)  time: 2.8074  data: 1.2372  max mem: 20571\n",
      "Train: [epoch:727]  [ 10/172]  eta: 0:04:33  lr: 0.000030  loss: 0.7994 (0.8106)  time: 1.6873  data: 0.1126  max mem: 20571\n",
      "Train: [epoch:727]  [ 20/172]  eta: 0:04:08  lr: 0.000030  loss: 0.7994 (0.8083)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [ 30/172]  eta: 0:03:49  lr: 0.000030  loss: 0.8100 (0.8157)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [ 40/172]  eta: 0:03:32  lr: 0.000030  loss: 0.8267 (0.8118)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [ 50/172]  eta: 0:03:15  lr: 0.000030  loss: 0.8010 (0.8092)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [ 60/172]  eta: 0:02:59  lr: 0.000030  loss: 0.8015 (0.8120)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [ 70/172]  eta: 0:02:42  lr: 0.000030  loss: 0.7986 (0.8091)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.8062 (0.8106)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.8157 (0.8106)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.8190 (0.8121)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.8047 (0.8110)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.8119 (0.8113)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.8193 (0.8121)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.8075 (0.8107)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.7811 (0.8100)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.7847 (0.8105)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.7994 (0.8101)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.7994 (0.8099)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:727] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.7994 (0.8099)\n",
      "Valid: [epoch:727]  [ 0/14]  eta: 0:00:06  loss: 0.8147 (0.8147)  time: 0.4974  data: 0.4822  max mem: 20571\n",
      "Valid: [epoch:727]  [13/14]  eta: 0:00:00  loss: 0.7666 (0.7757)  time: 0.0518  data: 0.0369  max mem: 20571\n",
      "Valid: [epoch:727] Total time: 0:00:00 (0.0577 s / it)\n",
      "Averaged stats: loss: 0.7666 (0.7757)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_727_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.776%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:728]  [  0/172]  eta: 0:07:54  lr: 0.000030  loss: 0.8128 (0.8128)  time: 2.7585  data: 1.1911  max mem: 20571\n",
      "Train: [epoch:728]  [ 10/172]  eta: 0:04:33  lr: 0.000030  loss: 0.8288 (0.8291)  time: 1.6854  data: 0.1084  max mem: 20571\n",
      "Train: [epoch:728]  [ 20/172]  eta: 0:04:08  lr: 0.000030  loss: 0.8252 (0.8232)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [ 30/172]  eta: 0:03:49  lr: 0.000030  loss: 0.8069 (0.8171)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [ 40/172]  eta: 0:03:32  lr: 0.000030  loss: 0.7882 (0.8092)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [ 50/172]  eta: 0:03:15  lr: 0.000030  loss: 0.7943 (0.8155)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [ 60/172]  eta: 0:02:59  lr: 0.000030  loss: 0.7943 (0.8105)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [ 70/172]  eta: 0:02:43  lr: 0.000030  loss: 0.7907 (0.8110)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.8185 (0.8132)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.8074 (0.8122)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.8062 (0.8117)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.8055 (0.8134)  time: 1.5838  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:728]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.8155 (0.8138)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.7995 (0.8116)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.7908 (0.8109)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.7917 (0.8109)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.8006 (0.8114)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.8034 (0.8119)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.8034 (0.8114)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:728] Total time: 0:04:33 (1.5897 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.8034 (0.8114)\n",
      "Valid: [epoch:728]  [ 0/14]  eta: 0:00:04  loss: 0.7192 (0.7192)  time: 0.3096  data: 0.2932  max mem: 20571\n",
      "Valid: [epoch:728]  [13/14]  eta: 0:00:00  loss: 0.7739 (0.7827)  time: 0.0370  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:728] Total time: 0:00:00 (0.0426 s / it)\n",
      "Averaged stats: loss: 0.7739 (0.7827)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_728_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.783%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:729]  [  0/172]  eta: 0:07:33  lr: 0.000030  loss: 0.8024 (0.8024)  time: 2.6369  data: 1.0636  max mem: 20571\n",
      "Train: [epoch:729]  [ 10/172]  eta: 0:04:31  lr: 0.000030  loss: 0.8081 (0.8066)  time: 1.6742  data: 0.0968  max mem: 20571\n",
      "Train: [epoch:729]  [ 20/172]  eta: 0:04:07  lr: 0.000030  loss: 0.8145 (0.8091)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [ 30/172]  eta: 0:03:49  lr: 0.000030  loss: 0.7927 (0.8046)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [ 40/172]  eta: 0:03:32  lr: 0.000030  loss: 0.7864 (0.8038)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [ 50/172]  eta: 0:03:15  lr: 0.000030  loss: 0.8032 (0.8075)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [ 60/172]  eta: 0:02:59  lr: 0.000030  loss: 0.8032 (0.8090)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [ 70/172]  eta: 0:02:42  lr: 0.000030  loss: 0.8122 (0.8116)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.8135 (0.8113)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.7859 (0.8089)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.7859 (0.8081)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.8246 (0.8112)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.8119 (0.8103)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.7926 (0.8095)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.7956 (0.8096)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.8206 (0.8113)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.8228 (0.8118)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.8042 (0.8115)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.8122 (0.8116)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:729] Total time: 0:04:32 (1.5865 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.8122 (0.8116)\n",
      "Valid: [epoch:729]  [ 0/14]  eta: 0:00:04  loss: 0.8058 (0.8058)  time: 0.2984  data: 0.2833  max mem: 20571\n",
      "Valid: [epoch:729]  [13/14]  eta: 0:00:00  loss: 0.7643 (0.7743)  time: 0.0375  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:729] Total time: 0:00:00 (0.0439 s / it)\n",
      "Averaged stats: loss: 0.7643 (0.7743)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_729_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.774%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:730]  [  0/172]  eta: 0:07:48  lr: 0.000030  loss: 0.8480 (0.8480)  time: 2.7251  data: 1.1553  max mem: 20571\n",
      "Train: [epoch:730]  [ 10/172]  eta: 0:04:32  lr: 0.000030  loss: 0.7807 (0.8064)  time: 1.6809  data: 0.1052  max mem: 20571\n",
      "Train: [epoch:730]  [ 20/172]  eta: 0:04:07  lr: 0.000030  loss: 0.8079 (0.8257)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [ 30/172]  eta: 0:03:49  lr: 0.000030  loss: 0.8273 (0.8230)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [ 40/172]  eta: 0:03:31  lr: 0.000030  loss: 0.8015 (0.8191)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [ 50/172]  eta: 0:03:15  lr: 0.000030  loss: 0.8100 (0.8192)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [ 60/172]  eta: 0:02:58  lr: 0.000030  loss: 0.8179 (0.8184)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [ 70/172]  eta: 0:02:42  lr: 0.000030  loss: 0.8179 (0.8190)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.7930 (0.8163)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.7992 (0.8166)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.8015 (0.8146)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.7999 (0.8150)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.8148 (0.8150)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.8095 (0.8144)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.8058 (0.8139)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.8049 (0.8144)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.8207 (0.8149)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.8172 (0.8146)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.8187 (0.8148)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:730] Total time: 0:04:32 (1.5836 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.8187 (0.8148)\n",
      "Valid: [epoch:730]  [ 0/14]  eta: 0:00:04  loss: 0.8117 (0.8117)  time: 0.3148  data: 0.2998  max mem: 20571\n",
      "Valid: [epoch:730]  [13/14]  eta: 0:00:00  loss: 0.7661 (0.7749)  time: 0.0388  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:730] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.7661 (0.7749)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_730_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.775%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:731]  [  0/172]  eta: 0:07:28  lr: 0.000030  loss: 0.8470 (0.8470)  time: 2.6071  data: 1.0301  max mem: 20571\n",
      "Train: [epoch:731]  [ 10/172]  eta: 0:04:30  lr: 0.000030  loss: 0.7948 (0.7934)  time: 1.6672  data: 0.0937  max mem: 20571\n",
      "Train: [epoch:731]  [ 20/172]  eta: 0:04:06  lr: 0.000030  loss: 0.8024 (0.8020)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [ 30/172]  eta: 0:03:48  lr: 0.000030  loss: 0.8024 (0.8033)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [ 40/172]  eta: 0:03:31  lr: 0.000030  loss: 0.7934 (0.8019)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [ 50/172]  eta: 0:03:14  lr: 0.000030  loss: 0.7872 (0.8016)  time: 1.5800  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:731]  [ 60/172]  eta: 0:02:58  lr: 0.000030  loss: 0.8100 (0.8040)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [ 70/172]  eta: 0:02:42  lr: 0.000030  loss: 0.8100 (0.8052)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.8196 (0.8082)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.7952 (0.8055)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.7952 (0.8078)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.8320 (0.8095)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.8368 (0.8126)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.8361 (0.8134)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.7854 (0.8120)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.7894 (0.8129)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.8146 (0.8145)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.8268 (0.8139)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.8268 (0.8140)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:731] Total time: 0:04:32 (1.5844 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.8268 (0.8140)\n",
      "Valid: [epoch:731]  [ 0/14]  eta: 0:00:04  loss: 0.7544 (0.7544)  time: 0.3010  data: 0.2862  max mem: 20571\n",
      "Valid: [epoch:731]  [13/14]  eta: 0:00:00  loss: 0.7700 (0.7796)  time: 0.0377  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:731] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.7700 (0.7796)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_731_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.780%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:732]  [  0/172]  eta: 0:07:45  lr: 0.000030  loss: 0.8095 (0.8095)  time: 2.7079  data: 1.1408  max mem: 20571\n",
      "Train: [epoch:732]  [ 10/172]  eta: 0:04:32  lr: 0.000030  loss: 0.8095 (0.8122)  time: 1.6822  data: 0.1039  max mem: 20571\n",
      "Train: [epoch:732]  [ 20/172]  eta: 0:04:08  lr: 0.000030  loss: 0.8018 (0.8019)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:732]  [ 30/172]  eta: 0:03:49  lr: 0.000030  loss: 0.8018 (0.8065)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [ 40/172]  eta: 0:03:32  lr: 0.000030  loss: 0.8050 (0.8058)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [ 50/172]  eta: 0:03:15  lr: 0.000030  loss: 0.8050 (0.8065)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:732]  [ 60/172]  eta: 0:02:59  lr: 0.000030  loss: 0.8167 (0.8083)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:732]  [ 70/172]  eta: 0:02:42  lr: 0.000030  loss: 0.8101 (0.8097)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.7969 (0.8087)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.8178 (0.8114)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.8139 (0.8096)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.7974 (0.8106)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.8264 (0.8135)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.8362 (0.8143)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.8049 (0.8133)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.7881 (0.8133)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.7920 (0.8129)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.8004 (0.8131)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.8004 (0.8130)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:732] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.8004 (0.8130)\n",
      "Valid: [epoch:732]  [ 0/14]  eta: 0:00:04  loss: 0.7709 (0.7709)  time: 0.2985  data: 0.2830  max mem: 20571\n",
      "Valid: [epoch:732]  [13/14]  eta: 0:00:00  loss: 0.7709 (0.7804)  time: 0.0475  data: 0.0325  max mem: 20571\n",
      "Valid: [epoch:732] Total time: 0:00:00 (0.0530 s / it)\n",
      "Averaged stats: loss: 0.7709 (0.7804)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_732_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.780%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:733]  [  0/172]  eta: 0:07:51  lr: 0.000030  loss: 0.7562 (0.7562)  time: 2.7410  data: 1.1689  max mem: 20571\n",
      "Train: [epoch:733]  [ 10/172]  eta: 0:04:32  lr: 0.000030  loss: 0.8192 (0.8133)  time: 1.6824  data: 0.1064  max mem: 20571\n",
      "Train: [epoch:733]  [ 20/172]  eta: 0:04:08  lr: 0.000030  loss: 0.8321 (0.8224)  time: 1.5763  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:733]  [ 30/172]  eta: 0:03:49  lr: 0.000030  loss: 0.8290 (0.8176)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [ 40/172]  eta: 0:03:32  lr: 0.000030  loss: 0.8029 (0.8149)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [ 50/172]  eta: 0:03:15  lr: 0.000030  loss: 0.8129 (0.8159)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [ 60/172]  eta: 0:02:58  lr: 0.000030  loss: 0.8309 (0.8172)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [ 70/172]  eta: 0:02:42  lr: 0.000030  loss: 0.8142 (0.8161)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.8025 (0.8166)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.8025 (0.8176)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.8051 (0.8171)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.8143 (0.8177)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.8282 (0.8180)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.8200 (0.8167)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.8061 (0.8170)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.8158 (0.8167)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.8042 (0.8161)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.8286 (0.8175)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.8286 (0.8174)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:733] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.8286 (0.8174)\n",
      "Valid: [epoch:733]  [ 0/14]  eta: 0:00:04  loss: 0.8170 (0.8170)  time: 0.3252  data: 0.3085  max mem: 20571\n",
      "Valid: [epoch:733]  [13/14]  eta: 0:00:00  loss: 0.7708 (0.7806)  time: 0.0386  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:733] Total time: 0:00:00 (0.0479 s / it)\n",
      "Averaged stats: loss: 0.7708 (0.7806)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_733_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.781%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:734]  [  0/172]  eta: 0:07:32  lr: 0.000030  loss: 0.7905 (0.7905)  time: 2.6287  data: 1.0558  max mem: 20571\n",
      "Train: [epoch:734]  [ 10/172]  eta: 0:04:30  lr: 0.000030  loss: 0.8155 (0.8080)  time: 1.6713  data: 0.0961  max mem: 20571\n",
      "Train: [epoch:734]  [ 20/172]  eta: 0:04:07  lr: 0.000030  loss: 0.8155 (0.8150)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [ 30/172]  eta: 0:03:48  lr: 0.000030  loss: 0.8153 (0.8144)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [ 40/172]  eta: 0:03:31  lr: 0.000030  loss: 0.8160 (0.8155)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [ 50/172]  eta: 0:03:14  lr: 0.000030  loss: 0.8236 (0.8192)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [ 60/172]  eta: 0:02:58  lr: 0.000030  loss: 0.8128 (0.8206)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:734]  [ 70/172]  eta: 0:02:42  lr: 0.000030  loss: 0.8147 (0.8221)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:734]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.8239 (0.8214)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.8167 (0.8219)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:734]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.8168 (0.8219)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.8173 (0.8227)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.8375 (0.8235)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.8221 (0.8228)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.8112 (0.8204)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.8081 (0.8195)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.8199 (0.8194)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.8226 (0.8205)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.8219 (0.8205)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:734] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.8219 (0.8205)\n",
      "Valid: [epoch:734]  [ 0/14]  eta: 0:00:06  loss: 0.7622 (0.7622)  time: 0.4497  data: 0.4329  max mem: 20571\n",
      "Valid: [epoch:734]  [13/14]  eta: 0:00:00  loss: 0.7686 (0.7772)  time: 0.0464  data: 0.0312  max mem: 20571\n",
      "Valid: [epoch:734] Total time: 0:00:00 (0.0518 s / it)\n",
      "Averaged stats: loss: 0.7686 (0.7772)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_734_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.777%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:735]  [  0/172]  eta: 0:07:48  lr: 0.000030  loss: 0.8236 (0.8236)  time: 2.7261  data: 1.1381  max mem: 20571\n",
      "Train: [epoch:735]  [ 10/172]  eta: 0:04:32  lr: 0.000030  loss: 0.7877 (0.7970)  time: 1.6794  data: 0.1036  max mem: 20571\n",
      "Train: [epoch:735]  [ 20/172]  eta: 0:04:07  lr: 0.000030  loss: 0.7954 (0.8083)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [ 30/172]  eta: 0:03:49  lr: 0.000030  loss: 0.8068 (0.8137)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [ 40/172]  eta: 0:03:31  lr: 0.000030  loss: 0.7947 (0.8091)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [ 50/172]  eta: 0:03:15  lr: 0.000030  loss: 0.7935 (0.8088)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [ 60/172]  eta: 0:02:58  lr: 0.000030  loss: 0.7944 (0.8083)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [ 70/172]  eta: 0:02:42  lr: 0.000030  loss: 0.8017 (0.8096)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [ 80/172]  eta: 0:02:26  lr: 0.000030  loss: 0.8147 (0.8117)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [ 90/172]  eta: 0:02:10  lr: 0.000030  loss: 0.8001 (0.8107)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [100/172]  eta: 0:01:54  lr: 0.000030  loss: 0.8239 (0.8124)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [110/172]  eta: 0:01:38  lr: 0.000030  loss: 0.8258 (0.8138)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [120/172]  eta: 0:01:22  lr: 0.000030  loss: 0.7967 (0.8120)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [130/172]  eta: 0:01:06  lr: 0.000030  loss: 0.7900 (0.8143)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [140/172]  eta: 0:00:50  lr: 0.000030  loss: 0.8080 (0.8144)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [150/172]  eta: 0:00:34  lr: 0.000030  loss: 0.8094 (0.8154)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [160/172]  eta: 0:00:19  lr: 0.000030  loss: 0.8142 (0.8151)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [170/172]  eta: 0:00:03  lr: 0.000030  loss: 0.8241 (0.8164)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735]  [171/172]  eta: 0:00:01  lr: 0.000030  loss: 0.8220 (0.8162)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:735] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000030  loss: 0.8220 (0.8162)\n",
      "Valid: [epoch:735]  [ 0/14]  eta: 0:00:04  loss: 0.8168 (0.8168)  time: 0.2927  data: 0.2782  max mem: 20571\n",
      "Valid: [epoch:735]  [13/14]  eta: 0:00:00  loss: 0.7794 (0.7885)  time: 0.0429  data: 0.0280  max mem: 20571\n",
      "Valid: [epoch:735] Total time: 0:00:00 (0.0489 s / it)\n",
      "Averaged stats: loss: 0.7794 (0.7885)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_735_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.789%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:736]  [  0/172]  eta: 0:07:20  lr: 0.000029  loss: 0.8123 (0.8123)  time: 2.5605  data: 0.9914  max mem: 20571\n",
      "Train: [epoch:736]  [ 10/172]  eta: 0:04:30  lr: 0.000029  loss: 0.8123 (0.8065)  time: 1.6705  data: 0.0902  max mem: 20571\n",
      "Train: [epoch:736]  [ 20/172]  eta: 0:04:07  lr: 0.000029  loss: 0.7997 (0.8068)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [ 30/172]  eta: 0:03:49  lr: 0.000029  loss: 0.8024 (0.8136)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [ 40/172]  eta: 0:03:32  lr: 0.000029  loss: 0.8105 (0.8111)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [ 50/172]  eta: 0:03:15  lr: 0.000029  loss: 0.8105 (0.8155)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [ 60/172]  eta: 0:02:59  lr: 0.000029  loss: 0.8307 (0.8196)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [ 70/172]  eta: 0:02:42  lr: 0.000029  loss: 0.8380 (0.8216)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [ 80/172]  eta: 0:02:26  lr: 0.000029  loss: 0.8291 (0.8219)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [ 90/172]  eta: 0:02:10  lr: 0.000029  loss: 0.7999 (0.8206)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [100/172]  eta: 0:01:54  lr: 0.000029  loss: 0.8098 (0.8216)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [110/172]  eta: 0:01:38  lr: 0.000029  loss: 0.8138 (0.8201)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [120/172]  eta: 0:01:22  lr: 0.000029  loss: 0.8147 (0.8200)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [130/172]  eta: 0:01:06  lr: 0.000029  loss: 0.8219 (0.8204)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [140/172]  eta: 0:00:50  lr: 0.000029  loss: 0.8053 (0.8195)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [150/172]  eta: 0:00:34  lr: 0.000029  loss: 0.7768 (0.8179)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [160/172]  eta: 0:00:19  lr: 0.000029  loss: 0.8017 (0.8177)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736]  [170/172]  eta: 0:00:03  lr: 0.000029  loss: 0.8127 (0.8173)  time: 1.5809  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:736]  [171/172]  eta: 0:00:01  lr: 0.000029  loss: 0.8127 (0.8177)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:736] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000029  loss: 0.8127 (0.8177)\n",
      "Valid: [epoch:736]  [ 0/14]  eta: 0:00:04  loss: 0.7800 (0.7800)  time: 0.2902  data: 0.2728  max mem: 20571\n",
      "Valid: [epoch:736]  [13/14]  eta: 0:00:00  loss: 0.7800 (0.7894)  time: 0.0397  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:736] Total time: 0:00:00 (0.0459 s / it)\n",
      "Averaged stats: loss: 0.7800 (0.7894)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_736_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.789%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:737]  [  0/172]  eta: 0:08:02  lr: 0.000029  loss: 0.8161 (0.8161)  time: 2.8032  data: 1.2283  max mem: 20571\n",
      "Train: [epoch:737]  [ 10/172]  eta: 0:04:33  lr: 0.000029  loss: 0.8323 (0.8309)  time: 1.6864  data: 0.1118  max mem: 20571\n",
      "Train: [epoch:737]  [ 20/172]  eta: 0:04:08  lr: 0.000029  loss: 0.8116 (0.8219)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [ 30/172]  eta: 0:03:49  lr: 0.000029  loss: 0.8021 (0.8186)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [ 40/172]  eta: 0:03:32  lr: 0.000029  loss: 0.8137 (0.8170)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [ 50/172]  eta: 0:03:15  lr: 0.000029  loss: 0.8240 (0.8201)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [ 60/172]  eta: 0:02:59  lr: 0.000029  loss: 0.8240 (0.8188)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [ 70/172]  eta: 0:02:42  lr: 0.000029  loss: 0.8406 (0.8217)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [ 80/172]  eta: 0:02:26  lr: 0.000029  loss: 0.8223 (0.8207)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [ 90/172]  eta: 0:02:10  lr: 0.000029  loss: 0.8312 (0.8250)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [100/172]  eta: 0:01:54  lr: 0.000029  loss: 0.8350 (0.8237)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [110/172]  eta: 0:01:38  lr: 0.000029  loss: 0.8064 (0.8210)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [120/172]  eta: 0:01:22  lr: 0.000029  loss: 0.8075 (0.8222)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [130/172]  eta: 0:01:06  lr: 0.000029  loss: 0.8191 (0.8217)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [140/172]  eta: 0:00:50  lr: 0.000029  loss: 0.8314 (0.8226)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [150/172]  eta: 0:00:34  lr: 0.000029  loss: 0.8056 (0.8202)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [160/172]  eta: 0:00:19  lr: 0.000029  loss: 0.8056 (0.8213)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [170/172]  eta: 0:00:03  lr: 0.000029  loss: 0.8262 (0.8208)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737]  [171/172]  eta: 0:00:01  lr: 0.000029  loss: 0.8271 (0.8210)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:737] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000029  loss: 0.8271 (0.8210)\n",
      "Valid: [epoch:737]  [ 0/14]  eta: 0:00:06  loss: 0.7654 (0.7654)  time: 0.4369  data: 0.4209  max mem: 20571\n",
      "Valid: [epoch:737]  [13/14]  eta: 0:00:00  loss: 0.7713 (0.7807)  time: 0.0471  data: 0.0319  max mem: 20571\n",
      "Valid: [epoch:737] Total time: 0:00:00 (0.0524 s / it)\n",
      "Averaged stats: loss: 0.7713 (0.7807)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_737_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.781%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:738]  [  0/172]  eta: 0:08:11  lr: 0.000029  loss: 0.8047 (0.8047)  time: 2.8588  data: 1.2922  max mem: 20571\n",
      "Train: [epoch:738]  [ 10/172]  eta: 0:04:34  lr: 0.000029  loss: 0.8254 (0.8319)  time: 1.6941  data: 0.1176  max mem: 20571\n",
      "Train: [epoch:738]  [ 20/172]  eta: 0:04:09  lr: 0.000029  loss: 0.8285 (0.8337)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [ 30/172]  eta: 0:03:50  lr: 0.000029  loss: 0.8183 (0.8249)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [ 40/172]  eta: 0:03:32  lr: 0.000029  loss: 0.8183 (0.8291)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [ 50/172]  eta: 0:03:15  lr: 0.000029  loss: 0.8226 (0.8291)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [ 60/172]  eta: 0:02:59  lr: 0.000029  loss: 0.8129 (0.8277)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [ 70/172]  eta: 0:02:43  lr: 0.000029  loss: 0.8202 (0.8279)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [ 80/172]  eta: 0:02:26  lr: 0.000029  loss: 0.8312 (0.8273)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [ 90/172]  eta: 0:02:10  lr: 0.000029  loss: 0.8203 (0.8257)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [100/172]  eta: 0:01:54  lr: 0.000029  loss: 0.8201 (0.8248)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [110/172]  eta: 0:01:38  lr: 0.000029  loss: 0.8063 (0.8224)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [120/172]  eta: 0:01:22  lr: 0.000029  loss: 0.8179 (0.8249)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [130/172]  eta: 0:01:06  lr: 0.000029  loss: 0.8386 (0.8242)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [140/172]  eta: 0:00:50  lr: 0.000029  loss: 0.8124 (0.8232)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [150/172]  eta: 0:00:34  lr: 0.000029  loss: 0.7906 (0.8215)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [160/172]  eta: 0:00:19  lr: 0.000029  loss: 0.7934 (0.8212)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [170/172]  eta: 0:00:03  lr: 0.000029  loss: 0.7982 (0.8195)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738]  [171/172]  eta: 0:00:01  lr: 0.000029  loss: 0.8001 (0.8195)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:738] Total time: 0:04:33 (1.5900 s / it)\n",
      "Averaged stats: lr: 0.000029  loss: 0.8001 (0.8195)\n",
      "Valid: [epoch:738]  [ 0/14]  eta: 0:00:04  loss: 0.8500 (0.8500)  time: 0.3497  data: 0.3334  max mem: 20571\n",
      "Valid: [epoch:738]  [13/14]  eta: 0:00:00  loss: 0.7738 (0.7830)  time: 0.0409  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:738] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.7738 (0.7830)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_738_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.783%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:739]  [  0/172]  eta: 0:08:07  lr: 0.000029  loss: 0.8949 (0.8949)  time: 2.8369  data: 1.2574  max mem: 20571\n",
      "Train: [epoch:739]  [ 10/172]  eta: 0:04:34  lr: 0.000029  loss: 0.8280 (0.8236)  time: 1.6928  data: 0.1144  max mem: 20571\n",
      "Train: [epoch:739]  [ 20/172]  eta: 0:04:09  lr: 0.000029  loss: 0.8241 (0.8258)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [ 30/172]  eta: 0:03:50  lr: 0.000029  loss: 0.8202 (0.8212)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:739]  [ 40/172]  eta: 0:03:32  lr: 0.000029  loss: 0.8121 (0.8161)  time: 1.5839  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:739]  [ 50/172]  eta: 0:03:15  lr: 0.000029  loss: 0.8177 (0.8185)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [ 60/172]  eta: 0:02:59  lr: 0.000029  loss: 0.8133 (0.8164)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [ 70/172]  eta: 0:02:43  lr: 0.000029  loss: 0.8109 (0.8150)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [ 80/172]  eta: 0:02:26  lr: 0.000029  loss: 0.7984 (0.8141)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [ 90/172]  eta: 0:02:10  lr: 0.000029  loss: 0.7993 (0.8181)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [100/172]  eta: 0:01:54  lr: 0.000029  loss: 0.8287 (0.8182)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [110/172]  eta: 0:01:38  lr: 0.000029  loss: 0.7939 (0.8176)  time: 1.5817  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:739]  [120/172]  eta: 0:01:22  lr: 0.000029  loss: 0.8262 (0.8199)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [130/172]  eta: 0:01:06  lr: 0.000029  loss: 0.8320 (0.8195)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [140/172]  eta: 0:00:50  lr: 0.000029  loss: 0.8126 (0.8189)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [150/172]  eta: 0:00:34  lr: 0.000029  loss: 0.8126 (0.8191)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [160/172]  eta: 0:00:19  lr: 0.000029  loss: 0.8102 (0.8190)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [170/172]  eta: 0:00:03  lr: 0.000029  loss: 0.8234 (0.8208)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739]  [171/172]  eta: 0:00:01  lr: 0.000029  loss: 0.8234 (0.8208)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:739] Total time: 0:04:33 (1.5896 s / it)\n",
      "Averaged stats: lr: 0.000029  loss: 0.8234 (0.8208)\n",
      "Valid: [epoch:739]  [ 0/14]  eta: 0:00:04  loss: 0.7841 (0.7841)  time: 0.3460  data: 0.3282  max mem: 20571\n",
      "Valid: [epoch:739]  [13/14]  eta: 0:00:00  loss: 0.7892 (0.7982)  time: 0.0403  data: 0.0247  max mem: 20571\n",
      "Valid: [epoch:739] Total time: 0:00:00 (0.0493 s / it)\n",
      "Averaged stats: loss: 0.7892 (0.7982)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_739_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.798%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:740]  [  0/172]  eta: 0:07:23  lr: 0.000029  loss: 0.8401 (0.8401)  time: 2.5781  data: 1.0103  max mem: 20571\n",
      "Train: [epoch:740]  [ 10/172]  eta: 0:04:30  lr: 0.000029  loss: 0.8019 (0.8067)  time: 1.6697  data: 0.0920  max mem: 20571\n",
      "Train: [epoch:740]  [ 20/172]  eta: 0:04:07  lr: 0.000029  loss: 0.8019 (0.8115)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [ 30/172]  eta: 0:03:48  lr: 0.000029  loss: 0.8275 (0.8157)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [ 40/172]  eta: 0:03:31  lr: 0.000029  loss: 0.8127 (0.8142)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:740]  [ 50/172]  eta: 0:03:15  lr: 0.000029  loss: 0.8002 (0.8168)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [ 60/172]  eta: 0:02:58  lr: 0.000029  loss: 0.8202 (0.8169)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [ 70/172]  eta: 0:02:42  lr: 0.000029  loss: 0.8204 (0.8186)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [ 80/172]  eta: 0:02:26  lr: 0.000029  loss: 0.8112 (0.8152)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [ 90/172]  eta: 0:02:10  lr: 0.000029  loss: 0.8212 (0.8186)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [100/172]  eta: 0:01:54  lr: 0.000029  loss: 0.8213 (0.8200)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [110/172]  eta: 0:01:38  lr: 0.000029  loss: 0.8115 (0.8203)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [120/172]  eta: 0:01:22  lr: 0.000029  loss: 0.8200 (0.8218)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [130/172]  eta: 0:01:06  lr: 0.000029  loss: 0.8400 (0.8229)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [140/172]  eta: 0:00:50  lr: 0.000029  loss: 0.8134 (0.8215)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [150/172]  eta: 0:00:34  lr: 0.000029  loss: 0.8083 (0.8212)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [160/172]  eta: 0:00:19  lr: 0.000029  loss: 0.8180 (0.8220)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [170/172]  eta: 0:00:03  lr: 0.000029  loss: 0.8327 (0.8220)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740]  [171/172]  eta: 0:00:01  lr: 0.000029  loss: 0.8368 (0.8222)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:740] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000029  loss: 0.8368 (0.8222)\n",
      "Valid: [epoch:740]  [ 0/14]  eta: 0:00:04  loss: 0.8176 (0.8176)  time: 0.2947  data: 0.2767  max mem: 20571\n",
      "Valid: [epoch:740]  [13/14]  eta: 0:00:00  loss: 0.7747 (0.7845)  time: 0.0478  data: 0.0326  max mem: 20571\n",
      "Valid: [epoch:740] Total time: 0:00:00 (0.0552 s / it)\n",
      "Averaged stats: loss: 0.7747 (0.7845)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_740_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.784%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:741]  [  0/172]  eta: 0:07:30  lr: 0.000029  loss: 0.7658 (0.7658)  time: 2.6211  data: 1.0443  max mem: 20571\n",
      "Train: [epoch:741]  [ 10/172]  eta: 0:04:30  lr: 0.000029  loss: 0.8006 (0.8031)  time: 1.6681  data: 0.0950  max mem: 20571\n",
      "Train: [epoch:741]  [ 20/172]  eta: 0:04:06  lr: 0.000029  loss: 0.8079 (0.8246)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [ 30/172]  eta: 0:03:48  lr: 0.000029  loss: 0.8139 (0.8156)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [ 40/172]  eta: 0:03:31  lr: 0.000029  loss: 0.8098 (0.8144)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [ 50/172]  eta: 0:03:14  lr: 0.000029  loss: 0.8195 (0.8171)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [ 60/172]  eta: 0:02:58  lr: 0.000029  loss: 0.8176 (0.8182)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [ 70/172]  eta: 0:02:42  lr: 0.000029  loss: 0.8132 (0.8215)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [ 80/172]  eta: 0:02:26  lr: 0.000029  loss: 0.8132 (0.8218)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [ 90/172]  eta: 0:02:10  lr: 0.000029  loss: 0.8240 (0.8240)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [100/172]  eta: 0:01:54  lr: 0.000029  loss: 0.8172 (0.8221)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [110/172]  eta: 0:01:38  lr: 0.000029  loss: 0.7947 (0.8219)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [120/172]  eta: 0:01:22  lr: 0.000029  loss: 0.8026 (0.8221)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [130/172]  eta: 0:01:06  lr: 0.000029  loss: 0.8119 (0.8215)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [140/172]  eta: 0:00:50  lr: 0.000029  loss: 0.8048 (0.8210)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [150/172]  eta: 0:00:34  lr: 0.000029  loss: 0.8209 (0.8214)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [160/172]  eta: 0:00:19  lr: 0.000029  loss: 0.8267 (0.8218)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [170/172]  eta: 0:00:03  lr: 0.000029  loss: 0.8351 (0.8232)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741]  [171/172]  eta: 0:00:01  lr: 0.000029  loss: 0.8218 (0.8232)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:741] Total time: 0:04:32 (1.5847 s / it)\n",
      "Averaged stats: lr: 0.000029  loss: 0.8218 (0.8232)\n",
      "Valid: [epoch:741]  [ 0/14]  eta: 0:00:05  loss: 0.8159 (0.8159)  time: 0.3920  data: 0.3745  max mem: 20571\n",
      "Valid: [epoch:741]  [13/14]  eta: 0:00:00  loss: 0.7752 (0.7847)  time: 0.0429  data: 0.0278  max mem: 20571\n",
      "Valid: [epoch:741] Total time: 0:00:00 (0.0488 s / it)\n",
      "Averaged stats: loss: 0.7752 (0.7847)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_741_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.785%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:742]  [  0/172]  eta: 0:07:28  lr: 0.000029  loss: 0.8354 (0.8354)  time: 2.6092  data: 1.0409  max mem: 20571\n",
      "Train: [epoch:742]  [ 10/172]  eta: 0:04:31  lr: 0.000029  loss: 0.8192 (0.8190)  time: 1.6738  data: 0.0947  max mem: 20571\n",
      "Train: [epoch:742]  [ 20/172]  eta: 0:04:07  lr: 0.000029  loss: 0.8179 (0.8246)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [ 30/172]  eta: 0:03:49  lr: 0.000029  loss: 0.8272 (0.8294)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [ 40/172]  eta: 0:03:31  lr: 0.000029  loss: 0.8253 (0.8288)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [ 50/172]  eta: 0:03:15  lr: 0.000029  loss: 0.8168 (0.8279)  time: 1.5809  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:742]  [ 60/172]  eta: 0:02:58  lr: 0.000029  loss: 0.8098 (0.8275)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [ 70/172]  eta: 0:02:42  lr: 0.000029  loss: 0.8098 (0.8253)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [ 80/172]  eta: 0:02:26  lr: 0.000029  loss: 0.8117 (0.8243)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [ 90/172]  eta: 0:02:10  lr: 0.000029  loss: 0.8273 (0.8249)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [100/172]  eta: 0:01:54  lr: 0.000029  loss: 0.8282 (0.8258)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [110/172]  eta: 0:01:38  lr: 0.000029  loss: 0.8060 (0.8240)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [120/172]  eta: 0:01:22  lr: 0.000029  loss: 0.8153 (0.8237)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [130/172]  eta: 0:01:06  lr: 0.000029  loss: 0.8239 (0.8259)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [140/172]  eta: 0:00:50  lr: 0.000029  loss: 0.8324 (0.8255)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [150/172]  eta: 0:00:34  lr: 0.000029  loss: 0.8144 (0.8254)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [160/172]  eta: 0:00:19  lr: 0.000029  loss: 0.8154 (0.8251)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [170/172]  eta: 0:00:03  lr: 0.000029  loss: 0.8156 (0.8251)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742]  [171/172]  eta: 0:00:01  lr: 0.000029  loss: 0.8225 (0.8253)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:742] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000029  loss: 0.8225 (0.8253)\n",
      "Valid: [epoch:742]  [ 0/14]  eta: 0:00:04  loss: 0.7704 (0.7704)  time: 0.3263  data: 0.3093  max mem: 20571\n",
      "Valid: [epoch:742]  [13/14]  eta: 0:00:00  loss: 0.8075 (0.8156)  time: 0.0374  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:742] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.8075 (0.8156)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_742_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.816%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:743]  [  0/172]  eta: 0:07:33  lr: 0.000029  loss: 0.8931 (0.8931)  time: 2.6338  data: 1.0501  max mem: 20571\n",
      "Train: [epoch:743]  [ 10/172]  eta: 0:04:31  lr: 0.000029  loss: 0.8635 (0.8485)  time: 1.6733  data: 0.0956  max mem: 20571\n",
      "Train: [epoch:743]  [ 20/172]  eta: 0:04:07  lr: 0.000029  loss: 0.8257 (0.8380)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [ 30/172]  eta: 0:03:48  lr: 0.000029  loss: 0.8081 (0.8312)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [ 40/172]  eta: 0:03:31  lr: 0.000029  loss: 0.8270 (0.8324)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [ 50/172]  eta: 0:03:15  lr: 0.000029  loss: 0.8332 (0.8336)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [ 60/172]  eta: 0:02:58  lr: 0.000029  loss: 0.8380 (0.8345)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [ 70/172]  eta: 0:02:42  lr: 0.000029  loss: 0.8190 (0.8329)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [ 80/172]  eta: 0:02:26  lr: 0.000029  loss: 0.8158 (0.8306)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [ 90/172]  eta: 0:02:10  lr: 0.000029  loss: 0.8142 (0.8303)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [100/172]  eta: 0:01:54  lr: 0.000029  loss: 0.8037 (0.8296)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [110/172]  eta: 0:01:38  lr: 0.000029  loss: 0.8037 (0.8304)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [120/172]  eta: 0:01:22  lr: 0.000029  loss: 0.8265 (0.8303)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [130/172]  eta: 0:01:06  lr: 0.000029  loss: 0.8238 (0.8304)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [140/172]  eta: 0:00:50  lr: 0.000029  loss: 0.8128 (0.8279)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [150/172]  eta: 0:00:34  lr: 0.000029  loss: 0.7952 (0.8272)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [160/172]  eta: 0:00:19  lr: 0.000029  loss: 0.8105 (0.8273)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [170/172]  eta: 0:00:03  lr: 0.000029  loss: 0.8124 (0.8266)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743]  [171/172]  eta: 0:00:01  lr: 0.000029  loss: 0.8124 (0.8266)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:743] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000029  loss: 0.8124 (0.8266)\n",
      "Valid: [epoch:743]  [ 0/14]  eta: 0:00:04  loss: 0.8421 (0.8421)  time: 0.3455  data: 0.3297  max mem: 20571\n",
      "Valid: [epoch:743]  [13/14]  eta: 0:00:00  loss: 0.7951 (0.8042)  time: 0.0391  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:743] Total time: 0:00:00 (0.0460 s / it)\n",
      "Averaged stats: loss: 0.7951 (0.8042)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_743_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.804%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:744]  [  0/172]  eta: 0:07:54  lr: 0.000029  loss: 0.8758 (0.8758)  time: 2.7591  data: 1.1943  max mem: 20571\n",
      "Train: [epoch:744]  [ 10/172]  eta: 0:04:32  lr: 0.000029  loss: 0.8662 (0.8475)  time: 1.6843  data: 0.1087  max mem: 20571\n",
      "Train: [epoch:744]  [ 20/172]  eta: 0:04:08  lr: 0.000029  loss: 0.8413 (0.8432)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [ 30/172]  eta: 0:03:49  lr: 0.000029  loss: 0.8469 (0.8435)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [ 40/172]  eta: 0:03:32  lr: 0.000029  loss: 0.8230 (0.8373)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [ 50/172]  eta: 0:03:15  lr: 0.000029  loss: 0.8222 (0.8376)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [ 60/172]  eta: 0:02:59  lr: 0.000029  loss: 0.8114 (0.8357)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [ 70/172]  eta: 0:02:42  lr: 0.000029  loss: 0.7971 (0.8320)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [ 80/172]  eta: 0:02:26  lr: 0.000029  loss: 0.7933 (0.8288)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [ 90/172]  eta: 0:02:10  lr: 0.000029  loss: 0.8066 (0.8297)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [100/172]  eta: 0:01:54  lr: 0.000029  loss: 0.8234 (0.8291)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [110/172]  eta: 0:01:38  lr: 0.000029  loss: 0.8056 (0.8296)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [120/172]  eta: 0:01:22  lr: 0.000029  loss: 0.8300 (0.8304)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [130/172]  eta: 0:01:06  lr: 0.000029  loss: 0.8300 (0.8289)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [140/172]  eta: 0:00:50  lr: 0.000029  loss: 0.8155 (0.8277)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [150/172]  eta: 0:00:34  lr: 0.000029  loss: 0.7990 (0.8271)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [160/172]  eta: 0:00:19  lr: 0.000029  loss: 0.8194 (0.8284)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [170/172]  eta: 0:00:03  lr: 0.000029  loss: 0.8394 (0.8281)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744]  [171/172]  eta: 0:00:01  lr: 0.000029  loss: 0.8394 (0.8280)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:744] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000029  loss: 0.8394 (0.8280)\n",
      "Valid: [epoch:744]  [ 0/14]  eta: 0:00:04  loss: 0.7204 (0.7204)  time: 0.3024  data: 0.2878  max mem: 20571\n",
      "Valid: [epoch:744]  [13/14]  eta: 0:00:00  loss: 0.7772 (0.7877)  time: 0.0388  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:744] Total time: 0:00:00 (0.0435 s / it)\n",
      "Averaged stats: loss: 0.7772 (0.7877)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_744_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.788%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:745]  [  0/172]  eta: 0:07:24  lr: 0.000028  loss: 0.8339 (0.8339)  time: 2.5829  data: 0.9987  max mem: 20571\n",
      "Train: [epoch:745]  [ 10/172]  eta: 0:04:30  lr: 0.000028  loss: 0.8339 (0.8324)  time: 1.6675  data: 0.0909  max mem: 20571\n",
      "Train: [epoch:745]  [ 20/172]  eta: 0:04:07  lr: 0.000028  loss: 0.8329 (0.8309)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [ 30/172]  eta: 0:03:48  lr: 0.000028  loss: 0.8207 (0.8241)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [ 40/172]  eta: 0:03:31  lr: 0.000028  loss: 0.8088 (0.8230)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [ 50/172]  eta: 0:03:14  lr: 0.000028  loss: 0.8379 (0.8267)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [ 60/172]  eta: 0:02:58  lr: 0.000028  loss: 0.8379 (0.8260)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [ 70/172]  eta: 0:02:42  lr: 0.000028  loss: 0.8341 (0.8276)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [ 80/172]  eta: 0:02:26  lr: 0.000028  loss: 0.8331 (0.8264)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [ 90/172]  eta: 0:02:10  lr: 0.000028  loss: 0.8082 (0.8271)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [100/172]  eta: 0:01:54  lr: 0.000028  loss: 0.8012 (0.8248)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [110/172]  eta: 0:01:38  lr: 0.000028  loss: 0.7935 (0.8249)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [120/172]  eta: 0:01:22  lr: 0.000028  loss: 0.8331 (0.8263)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [130/172]  eta: 0:01:06  lr: 0.000028  loss: 0.8191 (0.8264)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [140/172]  eta: 0:00:50  lr: 0.000028  loss: 0.8193 (0.8268)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [150/172]  eta: 0:00:34  lr: 0.000028  loss: 0.8278 (0.8270)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [160/172]  eta: 0:00:19  lr: 0.000028  loss: 0.8190 (0.8262)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [170/172]  eta: 0:00:03  lr: 0.000028  loss: 0.8091 (0.8262)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745]  [171/172]  eta: 0:00:01  lr: 0.000028  loss: 0.8091 (0.8265)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:745] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000028  loss: 0.8091 (0.8265)\n",
      "Valid: [epoch:745]  [ 0/14]  eta: 0:00:04  loss: 0.8309 (0.8309)  time: 0.3099  data: 0.2949  max mem: 20571\n",
      "Valid: [epoch:745]  [13/14]  eta: 0:00:00  loss: 0.7808 (0.7903)  time: 0.0463  data: 0.0313  max mem: 20571\n",
      "Valid: [epoch:745] Total time: 0:00:00 (0.0528 s / it)\n",
      "Averaged stats: loss: 0.7808 (0.7903)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_745_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.790%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:746]  [  0/172]  eta: 0:07:31  lr: 0.000028  loss: 0.7977 (0.7977)  time: 2.6242  data: 1.0554  max mem: 20571\n",
      "Train: [epoch:746]  [ 10/172]  eta: 0:04:31  lr: 0.000028  loss: 0.8026 (0.8068)  time: 1.6777  data: 0.0960  max mem: 20571\n",
      "Train: [epoch:746]  [ 20/172]  eta: 0:04:08  lr: 0.000028  loss: 0.8146 (0.8258)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [ 30/172]  eta: 0:03:49  lr: 0.000028  loss: 0.8434 (0.8336)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [ 40/172]  eta: 0:03:32  lr: 0.000028  loss: 0.8330 (0.8291)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [ 50/172]  eta: 0:03:15  lr: 0.000028  loss: 0.8122 (0.8335)  time: 1.5832  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:746]  [ 60/172]  eta: 0:02:59  lr: 0.000028  loss: 0.8242 (0.8311)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [ 70/172]  eta: 0:02:42  lr: 0.000028  loss: 0.8277 (0.8328)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [ 80/172]  eta: 0:02:26  lr: 0.000028  loss: 0.8306 (0.8325)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [ 90/172]  eta: 0:02:10  lr: 0.000028  loss: 0.8230 (0.8321)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [100/172]  eta: 0:01:54  lr: 0.000028  loss: 0.8230 (0.8310)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [110/172]  eta: 0:01:38  lr: 0.000028  loss: 0.8307 (0.8298)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [120/172]  eta: 0:01:22  lr: 0.000028  loss: 0.8372 (0.8305)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [130/172]  eta: 0:01:06  lr: 0.000028  loss: 0.8337 (0.8302)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [140/172]  eta: 0:00:50  lr: 0.000028  loss: 0.8359 (0.8306)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [150/172]  eta: 0:00:34  lr: 0.000028  loss: 0.8359 (0.8297)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [160/172]  eta: 0:00:19  lr: 0.000028  loss: 0.8410 (0.8305)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [170/172]  eta: 0:00:03  lr: 0.000028  loss: 0.8193 (0.8287)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746]  [171/172]  eta: 0:00:01  lr: 0.000028  loss: 0.8216 (0.8287)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:746] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000028  loss: 0.8216 (0.8287)\n",
      "Valid: [epoch:746]  [ 0/14]  eta: 0:00:04  loss: 0.7403 (0.7403)  time: 0.3279  data: 0.3100  max mem: 20571\n",
      "Valid: [epoch:746]  [13/14]  eta: 0:00:00  loss: 0.8139 (0.8231)  time: 0.0399  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:746] Total time: 0:00:00 (0.0451 s / it)\n",
      "Averaged stats: loss: 0.8139 (0.8231)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_746_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.823%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:747]  [  0/172]  eta: 0:07:31  lr: 0.000028  loss: 0.9098 (0.9098)  time: 2.6268  data: 1.0471  max mem: 20571\n",
      "Train: [epoch:747]  [ 10/172]  eta: 0:04:30  lr: 0.000028  loss: 0.8491 (0.8572)  time: 1.6724  data: 0.0953  max mem: 20571\n",
      "Train: [epoch:747]  [ 20/172]  eta: 0:04:07  lr: 0.000028  loss: 0.8281 (0.8421)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [ 30/172]  eta: 0:03:49  lr: 0.000028  loss: 0.8187 (0.8371)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [ 40/172]  eta: 0:03:31  lr: 0.000028  loss: 0.7942 (0.8257)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [ 50/172]  eta: 0:03:15  lr: 0.000028  loss: 0.8168 (0.8331)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [ 60/172]  eta: 0:02:58  lr: 0.000028  loss: 0.8349 (0.8325)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [ 70/172]  eta: 0:02:42  lr: 0.000028  loss: 0.8293 (0.8321)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [ 80/172]  eta: 0:02:26  lr: 0.000028  loss: 0.8207 (0.8318)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [ 90/172]  eta: 0:02:10  lr: 0.000028  loss: 0.8091 (0.8296)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [100/172]  eta: 0:01:54  lr: 0.000028  loss: 0.8112 (0.8307)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [110/172]  eta: 0:01:38  lr: 0.000028  loss: 0.8234 (0.8300)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [120/172]  eta: 0:01:22  lr: 0.000028  loss: 0.8144 (0.8287)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [130/172]  eta: 0:01:06  lr: 0.000028  loss: 0.8136 (0.8286)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [140/172]  eta: 0:00:50  lr: 0.000028  loss: 0.8194 (0.8294)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [150/172]  eta: 0:00:34  lr: 0.000028  loss: 0.8363 (0.8305)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [160/172]  eta: 0:00:19  lr: 0.000028  loss: 0.8369 (0.8305)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747]  [170/172]  eta: 0:00:03  lr: 0.000028  loss: 0.8141 (0.8309)  time: 1.5814  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:747]  [171/172]  eta: 0:00:01  lr: 0.000028  loss: 0.8138 (0.8308)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:747] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000028  loss: 0.8138 (0.8308)\n",
      "Valid: [epoch:747]  [ 0/14]  eta: 0:00:04  loss: 0.8360 (0.8360)  time: 0.3320  data: 0.3167  max mem: 20571\n",
      "Valid: [epoch:747]  [13/14]  eta: 0:00:00  loss: 0.7857 (0.7960)  time: 0.0458  data: 0.0309  max mem: 20571\n",
      "Valid: [epoch:747] Total time: 0:00:00 (0.0535 s / it)\n",
      "Averaged stats: loss: 0.7857 (0.7960)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_747_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.796%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:748]  [  0/172]  eta: 0:07:27  lr: 0.000028  loss: 0.7513 (0.7513)  time: 2.6019  data: 1.0337  max mem: 20571\n",
      "Train: [epoch:748]  [ 10/172]  eta: 0:04:30  lr: 0.000028  loss: 0.8234 (0.8328)  time: 1.6699  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:748]  [ 20/172]  eta: 0:04:07  lr: 0.000028  loss: 0.8234 (0.8383)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [ 30/172]  eta: 0:03:48  lr: 0.000028  loss: 0.8208 (0.8309)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [ 40/172]  eta: 0:03:31  lr: 0.000028  loss: 0.8113 (0.8289)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [ 50/172]  eta: 0:03:15  lr: 0.000028  loss: 0.8197 (0.8325)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:748]  [ 60/172]  eta: 0:02:58  lr: 0.000028  loss: 0.8226 (0.8273)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [ 70/172]  eta: 0:02:42  lr: 0.000028  loss: 0.8105 (0.8288)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [ 80/172]  eta: 0:02:26  lr: 0.000028  loss: 0.8364 (0.8298)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [ 90/172]  eta: 0:02:10  lr: 0.000028  loss: 0.8096 (0.8276)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [100/172]  eta: 0:01:54  lr: 0.000028  loss: 0.8096 (0.8287)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [110/172]  eta: 0:01:38  lr: 0.000028  loss: 0.8322 (0.8295)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [120/172]  eta: 0:01:22  lr: 0.000028  loss: 0.8420 (0.8312)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [130/172]  eta: 0:01:06  lr: 0.000028  loss: 0.8295 (0.8310)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [140/172]  eta: 0:00:50  lr: 0.000028  loss: 0.8082 (0.8295)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [150/172]  eta: 0:00:34  lr: 0.000028  loss: 0.8082 (0.8293)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [160/172]  eta: 0:00:19  lr: 0.000028  loss: 0.8282 (0.8305)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [170/172]  eta: 0:00:03  lr: 0.000028  loss: 0.8204 (0.8297)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748]  [171/172]  eta: 0:00:01  lr: 0.000028  loss: 0.8266 (0.8298)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:748] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000028  loss: 0.8266 (0.8298)\n",
      "Valid: [epoch:748]  [ 0/14]  eta: 0:00:04  loss: 0.8359 (0.8359)  time: 0.3115  data: 0.2946  max mem: 20571\n",
      "Valid: [epoch:748]  [13/14]  eta: 0:00:00  loss: 0.7850 (0.7943)  time: 0.0388  data: 0.0235  max mem: 20571\n",
      "Valid: [epoch:748] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.7850 (0.7943)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_748_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.794%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:749]  [  0/172]  eta: 0:07:37  lr: 0.000028  loss: 0.7973 (0.7973)  time: 2.6622  data: 1.0800  max mem: 20571\n",
      "Train: [epoch:749]  [ 10/172]  eta: 0:04:31  lr: 0.000028  loss: 0.8481 (0.8512)  time: 1.6762  data: 0.0983  max mem: 20571\n",
      "Train: [epoch:749]  [ 20/172]  eta: 0:04:07  lr: 0.000028  loss: 0.8360 (0.8416)  time: 1.5784  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:749]  [ 30/172]  eta: 0:03:49  lr: 0.000028  loss: 0.8108 (0.8415)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [ 40/172]  eta: 0:03:32  lr: 0.000028  loss: 0.8412 (0.8423)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [ 50/172]  eta: 0:03:15  lr: 0.000028  loss: 0.8412 (0.8409)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [ 60/172]  eta: 0:02:59  lr: 0.000028  loss: 0.8198 (0.8385)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [ 70/172]  eta: 0:02:42  lr: 0.000028  loss: 0.8164 (0.8389)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [ 80/172]  eta: 0:02:26  lr: 0.000028  loss: 0.8243 (0.8385)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [ 90/172]  eta: 0:02:10  lr: 0.000028  loss: 0.8170 (0.8357)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [100/172]  eta: 0:01:54  lr: 0.000028  loss: 0.8157 (0.8361)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [110/172]  eta: 0:01:38  lr: 0.000028  loss: 0.8148 (0.8339)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [120/172]  eta: 0:01:22  lr: 0.000028  loss: 0.8148 (0.8327)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [130/172]  eta: 0:01:06  lr: 0.000028  loss: 0.8139 (0.8309)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:749]  [140/172]  eta: 0:00:50  lr: 0.000028  loss: 0.8139 (0.8307)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [150/172]  eta: 0:00:34  lr: 0.000028  loss: 0.8330 (0.8310)  time: 1.5797  data: 0.0003  max mem: 20571\n",
      "Train: [epoch:749]  [160/172]  eta: 0:00:19  lr: 0.000028  loss: 0.8330 (0.8309)  time: 1.5822  data: 0.0004  max mem: 20571\n",
      "Train: [epoch:749]  [170/172]  eta: 0:00:03  lr: 0.000028  loss: 0.8396 (0.8305)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749]  [171/172]  eta: 0:00:01  lr: 0.000028  loss: 0.8396 (0.8310)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:749] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000028  loss: 0.8396 (0.8310)\n",
      "Valid: [epoch:749]  [ 0/14]  eta: 0:00:05  loss: 0.7650 (0.7650)  time: 0.3724  data: 0.3567  max mem: 20571\n",
      "Valid: [epoch:749]  [13/14]  eta: 0:00:00  loss: 0.7811 (0.7908)  time: 0.0428  data: 0.0278  max mem: 20571\n",
      "Valid: [epoch:749] Total time: 0:00:00 (0.0513 s / it)\n",
      "Averaged stats: loss: 0.7811 (0.7908)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_749_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.791%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:750]  [  0/172]  eta: 0:07:38  lr: 0.000028  loss: 0.8351 (0.8351)  time: 2.6663  data: 1.0782  max mem: 20571\n",
      "Train: [epoch:750]  [ 10/172]  eta: 0:04:31  lr: 0.000028  loss: 0.8351 (0.8230)  time: 1.6773  data: 0.0981  max mem: 20571\n",
      "Train: [epoch:750]  [ 20/172]  eta: 0:04:07  lr: 0.000028  loss: 0.8426 (0.8336)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [ 30/172]  eta: 0:03:49  lr: 0.000028  loss: 0.8492 (0.8353)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:750]  [ 40/172]  eta: 0:03:32  lr: 0.000028  loss: 0.8199 (0.8312)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [ 50/172]  eta: 0:03:15  lr: 0.000028  loss: 0.8140 (0.8308)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:750]  [ 60/172]  eta: 0:02:58  lr: 0.000028  loss: 0.8331 (0.8338)  time: 1.5786  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:750]  [ 70/172]  eta: 0:02:42  lr: 0.000028  loss: 0.8339 (0.8348)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [ 80/172]  eta: 0:02:26  lr: 0.000028  loss: 0.8373 (0.8414)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [ 90/172]  eta: 0:02:10  lr: 0.000028  loss: 0.8557 (0.8430)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [100/172]  eta: 0:01:54  lr: 0.000028  loss: 0.8330 (0.8392)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [110/172]  eta: 0:01:38  lr: 0.000028  loss: 0.8043 (0.8375)  time: 1.5819  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:750]  [120/172]  eta: 0:01:22  lr: 0.000028  loss: 0.8184 (0.8370)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [130/172]  eta: 0:01:06  lr: 0.000028  loss: 0.8281 (0.8363)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [140/172]  eta: 0:00:50  lr: 0.000028  loss: 0.8200 (0.8360)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:750]  [150/172]  eta: 0:00:34  lr: 0.000028  loss: 0.8629 (0.8370)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [160/172]  eta: 0:00:19  lr: 0.000028  loss: 0.8591 (0.8370)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [170/172]  eta: 0:00:03  lr: 0.000028  loss: 0.8268 (0.8357)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750]  [171/172]  eta: 0:00:01  lr: 0.000028  loss: 0.7946 (0.8354)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:750] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000028  loss: 0.7946 (0.8354)\n",
      "Valid: [epoch:750]  [ 0/14]  eta: 0:00:05  loss: 0.7102 (0.7102)  time: 0.3677  data: 0.3528  max mem: 20571\n",
      "Valid: [epoch:750]  [13/14]  eta: 0:00:00  loss: 0.7891 (0.7983)  time: 0.0411  data: 0.0260  max mem: 20571\n",
      "Valid: [epoch:750] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.7891 (0.7983)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_750_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.798%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:751]  [  0/172]  eta: 0:07:30  lr: 0.000028  loss: 0.7513 (0.7513)  time: 2.6195  data: 1.0465  max mem: 20571\n",
      "Train: [epoch:751]  [ 10/172]  eta: 0:04:30  lr: 0.000028  loss: 0.7752 (0.7879)  time: 1.6700  data: 0.0953  max mem: 20571\n",
      "Train: [epoch:751]  [ 20/172]  eta: 0:04:07  lr: 0.000028  loss: 0.8139 (0.8081)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [ 30/172]  eta: 0:03:48  lr: 0.000028  loss: 0.8186 (0.8113)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [ 40/172]  eta: 0:03:31  lr: 0.000028  loss: 0.8085 (0.8123)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [ 50/172]  eta: 0:03:14  lr: 0.000028  loss: 0.8333 (0.8224)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [ 60/172]  eta: 0:02:58  lr: 0.000028  loss: 0.8333 (0.8240)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [ 70/172]  eta: 0:02:42  lr: 0.000028  loss: 0.8213 (0.8218)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [ 80/172]  eta: 0:02:26  lr: 0.000028  loss: 0.8318 (0.8249)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [ 90/172]  eta: 0:02:10  lr: 0.000028  loss: 0.8538 (0.8265)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:751]  [100/172]  eta: 0:01:54  lr: 0.000028  loss: 0.8273 (0.8269)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:751]  [110/172]  eta: 0:01:38  lr: 0.000028  loss: 0.8305 (0.8293)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [120/172]  eta: 0:01:22  lr: 0.000028  loss: 0.8296 (0.8295)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [130/172]  eta: 0:01:06  lr: 0.000028  loss: 0.8374 (0.8302)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [140/172]  eta: 0:00:50  lr: 0.000028  loss: 0.8429 (0.8300)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [150/172]  eta: 0:00:34  lr: 0.000028  loss: 0.8437 (0.8307)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [160/172]  eta: 0:00:19  lr: 0.000028  loss: 0.8088 (0.8299)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [170/172]  eta: 0:00:03  lr: 0.000028  loss: 0.8318 (0.8301)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751]  [171/172]  eta: 0:00:01  lr: 0.000028  loss: 0.8320 (0.8302)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:751] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000028  loss: 0.8320 (0.8302)\n",
      "Valid: [epoch:751]  [ 0/14]  eta: 0:00:05  loss: 0.8275 (0.8275)  time: 0.3929  data: 0.3770  max mem: 20571\n",
      "Valid: [epoch:751]  [13/14]  eta: 0:00:00  loss: 0.7849 (0.7952)  time: 0.0424  data: 0.0273  max mem: 20571\n",
      "Valid: [epoch:751] Total time: 0:00:00 (0.0505 s / it)\n",
      "Averaged stats: loss: 0.7849 (0.7952)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_751_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.795%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:752]  [  0/172]  eta: 0:07:48  lr: 0.000028  loss: 0.8309 (0.8309)  time: 2.7256  data: 1.1577  max mem: 20571\n",
      "Train: [epoch:752]  [ 10/172]  eta: 0:04:33  lr: 0.000028  loss: 0.7992 (0.8137)  time: 1.6864  data: 0.1054  max mem: 20571\n",
      "Train: [epoch:752]  [ 20/172]  eta: 0:04:08  lr: 0.000028  loss: 0.8219 (0.8312)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:752]  [ 30/172]  eta: 0:03:49  lr: 0.000028  loss: 0.8285 (0.8410)  time: 1.5819  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:752]  [ 40/172]  eta: 0:03:32  lr: 0.000028  loss: 0.8214 (0.8366)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [ 50/172]  eta: 0:03:15  lr: 0.000028  loss: 0.8171 (0.8328)  time: 1.5841  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:752]  [ 60/172]  eta: 0:02:59  lr: 0.000028  loss: 0.8397 (0.8387)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [ 70/172]  eta: 0:02:43  lr: 0.000028  loss: 0.8644 (0.8402)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [ 80/172]  eta: 0:02:26  lr: 0.000028  loss: 0.8393 (0.8394)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [ 90/172]  eta: 0:02:10  lr: 0.000028  loss: 0.8204 (0.8381)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [100/172]  eta: 0:01:54  lr: 0.000028  loss: 0.8101 (0.8375)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [110/172]  eta: 0:01:38  lr: 0.000028  loss: 0.8077 (0.8359)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [120/172]  eta: 0:01:22  lr: 0.000028  loss: 0.8277 (0.8354)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [130/172]  eta: 0:01:06  lr: 0.000028  loss: 0.8374 (0.8348)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [140/172]  eta: 0:00:50  lr: 0.000028  loss: 0.8131 (0.8342)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [150/172]  eta: 0:00:34  lr: 0.000028  loss: 0.8246 (0.8341)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [160/172]  eta: 0:00:19  lr: 0.000028  loss: 0.8063 (0.8336)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [170/172]  eta: 0:00:03  lr: 0.000028  loss: 0.8219 (0.8335)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752]  [171/172]  eta: 0:00:01  lr: 0.000028  loss: 0.8416 (0.8336)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:752] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000028  loss: 0.8416 (0.8336)\n",
      "Valid: [epoch:752]  [ 0/14]  eta: 0:00:04  loss: 0.7854 (0.7854)  time: 0.3171  data: 0.3018  max mem: 20571\n",
      "Valid: [epoch:752]  [13/14]  eta: 0:00:00  loss: 0.7854 (0.7953)  time: 0.0395  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:752] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 0.7854 (0.7953)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_752_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.795%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:753]  [  0/172]  eta: 0:08:12  lr: 0.000028  loss: 0.8758 (0.8758)  time: 2.8631  data: 1.2901  max mem: 20571\n",
      "Train: [epoch:753]  [ 10/172]  eta: 0:04:34  lr: 0.000028  loss: 0.8400 (0.8554)  time: 1.6940  data: 0.1174  max mem: 20571\n",
      "Train: [epoch:753]  [ 20/172]  eta: 0:04:09  lr: 0.000028  loss: 0.8400 (0.8499)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [ 30/172]  eta: 0:03:50  lr: 0.000028  loss: 0.8440 (0.8523)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [ 40/172]  eta: 0:03:32  lr: 0.000028  loss: 0.8254 (0.8444)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [ 50/172]  eta: 0:03:15  lr: 0.000028  loss: 0.8093 (0.8364)  time: 1.5815  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:753]  [ 60/172]  eta: 0:02:59  lr: 0.000028  loss: 0.8376 (0.8392)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [ 70/172]  eta: 0:02:43  lr: 0.000028  loss: 0.8501 (0.8400)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [ 80/172]  eta: 0:02:26  lr: 0.000028  loss: 0.8361 (0.8396)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [ 90/172]  eta: 0:02:10  lr: 0.000028  loss: 0.8337 (0.8400)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [100/172]  eta: 0:01:54  lr: 0.000028  loss: 0.8379 (0.8397)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [110/172]  eta: 0:01:38  lr: 0.000028  loss: 0.8169 (0.8366)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [120/172]  eta: 0:01:22  lr: 0.000028  loss: 0.8066 (0.8362)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [130/172]  eta: 0:01:06  lr: 0.000028  loss: 0.8178 (0.8356)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [140/172]  eta: 0:00:50  lr: 0.000028  loss: 0.8398 (0.8368)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [150/172]  eta: 0:00:34  lr: 0.000028  loss: 0.8408 (0.8367)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [160/172]  eta: 0:00:19  lr: 0.000028  loss: 0.8390 (0.8371)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [170/172]  eta: 0:00:03  lr: 0.000028  loss: 0.8458 (0.8377)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753]  [171/172]  eta: 0:00:01  lr: 0.000028  loss: 0.8458 (0.8377)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:753] Total time: 0:04:33 (1.5889 s / it)\n",
      "Averaged stats: lr: 0.000028  loss: 0.8458 (0.8377)\n",
      "Valid: [epoch:753]  [ 0/14]  eta: 0:00:04  loss: 0.8246 (0.8246)  time: 0.3291  data: 0.3125  max mem: 20571\n",
      "Valid: [epoch:753]  [13/14]  eta: 0:00:00  loss: 0.7845 (0.7951)  time: 0.0415  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:753] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.7845 (0.7951)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_753_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.795%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:754]  [  0/172]  eta: 0:07:51  lr: 0.000027  loss: 0.8607 (0.8607)  time: 2.7437  data: 1.1772  max mem: 20571\n",
      "Train: [epoch:754]  [ 10/172]  eta: 0:04:32  lr: 0.000027  loss: 0.8422 (0.8515)  time: 1.6838  data: 0.1071  max mem: 20571\n",
      "Train: [epoch:754]  [ 20/172]  eta: 0:04:08  lr: 0.000027  loss: 0.8338 (0.8511)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [ 30/172]  eta: 0:03:49  lr: 0.000027  loss: 0.8215 (0.8488)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [ 40/172]  eta: 0:03:32  lr: 0.000027  loss: 0.8324 (0.8473)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:754]  [ 50/172]  eta: 0:03:15  lr: 0.000027  loss: 0.8335 (0.8418)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:754]  [ 60/172]  eta: 0:02:59  lr: 0.000027  loss: 0.8277 (0.8388)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [ 70/172]  eta: 0:02:42  lr: 0.000027  loss: 0.8396 (0.8386)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [ 80/172]  eta: 0:02:26  lr: 0.000027  loss: 0.8456 (0.8383)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [ 90/172]  eta: 0:02:10  lr: 0.000027  loss: 0.8209 (0.8357)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [100/172]  eta: 0:01:54  lr: 0.000027  loss: 0.8170 (0.8334)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [110/172]  eta: 0:01:38  lr: 0.000027  loss: 0.8226 (0.8346)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [120/172]  eta: 0:01:22  lr: 0.000027  loss: 0.8476 (0.8367)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [130/172]  eta: 0:01:06  lr: 0.000027  loss: 0.8303 (0.8356)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [140/172]  eta: 0:00:50  lr: 0.000027  loss: 0.8150 (0.8352)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [150/172]  eta: 0:00:34  lr: 0.000027  loss: 0.8118 (0.8337)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [160/172]  eta: 0:00:19  lr: 0.000027  loss: 0.8176 (0.8354)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [170/172]  eta: 0:00:03  lr: 0.000027  loss: 0.8510 (0.8366)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754]  [171/172]  eta: 0:00:01  lr: 0.000027  loss: 0.8510 (0.8373)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:754] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000027  loss: 0.8510 (0.8373)\n",
      "Valid: [epoch:754]  [ 0/14]  eta: 0:00:04  loss: 0.8260 (0.8260)  time: 0.3055  data: 0.2901  max mem: 20571\n",
      "Valid: [epoch:754]  [13/14]  eta: 0:00:00  loss: 0.7851 (0.7957)  time: 0.0372  data: 0.0221  max mem: 20571\n",
      "Valid: [epoch:754] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.7851 (0.7957)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_754_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.796%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:755]  [  0/172]  eta: 0:07:30  lr: 0.000027  loss: 0.8339 (0.8339)  time: 2.6206  data: 1.0416  max mem: 20571\n",
      "Train: [epoch:755]  [ 10/172]  eta: 0:04:30  lr: 0.000027  loss: 0.8430 (0.8539)  time: 1.6719  data: 0.0948  max mem: 20571\n",
      "Train: [epoch:755]  [ 20/172]  eta: 0:04:07  lr: 0.000027  loss: 0.8353 (0.8415)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [ 30/172]  eta: 0:03:48  lr: 0.000027  loss: 0.8129 (0.8348)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [ 40/172]  eta: 0:03:31  lr: 0.000027  loss: 0.8216 (0.8338)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [ 50/172]  eta: 0:03:15  lr: 0.000027  loss: 0.8313 (0.8360)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [ 60/172]  eta: 0:02:58  lr: 0.000027  loss: 0.8301 (0.8351)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [ 70/172]  eta: 0:02:42  lr: 0.000027  loss: 0.8259 (0.8330)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [ 80/172]  eta: 0:02:26  lr: 0.000027  loss: 0.8340 (0.8320)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [ 90/172]  eta: 0:02:10  lr: 0.000027  loss: 0.8318 (0.8306)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [100/172]  eta: 0:01:54  lr: 0.000027  loss: 0.8106 (0.8294)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [110/172]  eta: 0:01:38  lr: 0.000027  loss: 0.8021 (0.8285)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [120/172]  eta: 0:01:22  lr: 0.000027  loss: 0.8472 (0.8314)  time: 1.5830  data: 0.0032  max mem: 20571\n",
      "Train: [epoch:755]  [130/172]  eta: 0:01:06  lr: 0.000027  loss: 0.8558 (0.8322)  time: 1.5833  data: 0.0033  max mem: 20571\n",
      "Train: [epoch:755]  [140/172]  eta: 0:00:50  lr: 0.000027  loss: 0.8306 (0.8315)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [150/172]  eta: 0:00:34  lr: 0.000027  loss: 0.8248 (0.8313)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [160/172]  eta: 0:00:19  lr: 0.000027  loss: 0.8450 (0.8325)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [170/172]  eta: 0:00:03  lr: 0.000027  loss: 0.8416 (0.8328)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755]  [171/172]  eta: 0:00:01  lr: 0.000027  loss: 0.8396 (0.8325)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:755] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000027  loss: 0.8396 (0.8325)\n",
      "Valid: [epoch:755]  [ 0/14]  eta: 0:00:04  loss: 0.7789 (0.7789)  time: 0.3069  data: 0.2922  max mem: 20571\n",
      "Valid: [epoch:755]  [13/14]  eta: 0:00:00  loss: 0.7963 (0.8056)  time: 0.0389  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:755] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.7963 (0.8056)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_755_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.806%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:756]  [  0/172]  eta: 0:07:38  lr: 0.000027  loss: 0.8586 (0.8586)  time: 2.6677  data: 1.0976  max mem: 20571\n",
      "Train: [epoch:756]  [ 10/172]  eta: 0:04:32  lr: 0.000027  loss: 0.8432 (0.8447)  time: 1.6802  data: 0.0999  max mem: 20571\n",
      "Train: [epoch:756]  [ 20/172]  eta: 0:04:08  lr: 0.000027  loss: 0.8617 (0.8503)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [ 30/172]  eta: 0:03:49  lr: 0.000027  loss: 0.8531 (0.8438)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [ 40/172]  eta: 0:03:32  lr: 0.000027  loss: 0.8392 (0.8421)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [ 50/172]  eta: 0:03:15  lr: 0.000027  loss: 0.8285 (0.8414)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [ 60/172]  eta: 0:02:59  lr: 0.000027  loss: 0.8455 (0.8434)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [ 70/172]  eta: 0:02:42  lr: 0.000027  loss: 0.8582 (0.8446)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [ 80/172]  eta: 0:02:26  lr: 0.000027  loss: 0.8219 (0.8414)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [ 90/172]  eta: 0:02:10  lr: 0.000027  loss: 0.8213 (0.8397)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [100/172]  eta: 0:01:54  lr: 0.000027  loss: 0.8168 (0.8376)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [110/172]  eta: 0:01:38  lr: 0.000027  loss: 0.8178 (0.8384)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [120/172]  eta: 0:01:22  lr: 0.000027  loss: 0.8243 (0.8387)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [130/172]  eta: 0:01:06  lr: 0.000027  loss: 0.8273 (0.8381)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [140/172]  eta: 0:00:50  lr: 0.000027  loss: 0.8149 (0.8373)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [150/172]  eta: 0:00:34  lr: 0.000027  loss: 0.8223 (0.8377)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [160/172]  eta: 0:00:19  lr: 0.000027  loss: 0.8315 (0.8384)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [170/172]  eta: 0:00:03  lr: 0.000027  loss: 0.8296 (0.8379)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756]  [171/172]  eta: 0:00:01  lr: 0.000027  loss: 0.8295 (0.8378)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:756] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000027  loss: 0.8295 (0.8378)\n",
      "Valid: [epoch:756]  [ 0/14]  eta: 0:00:04  loss: 0.7960 (0.7960)  time: 0.3290  data: 0.3127  max mem: 20571\n",
      "Valid: [epoch:756]  [13/14]  eta: 0:00:00  loss: 0.7960 (0.8055)  time: 0.0430  data: 0.0279  max mem: 20571\n",
      "Valid: [epoch:756] Total time: 0:00:00 (0.0508 s / it)\n",
      "Averaged stats: loss: 0.7960 (0.8055)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_756_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.805%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:757]  [  0/172]  eta: 0:08:18  lr: 0.000027  loss: 0.8006 (0.8006)  time: 2.8962  data: 1.3241  max mem: 20571\n",
      "Train: [epoch:757]  [ 10/172]  eta: 0:04:34  lr: 0.000027  loss: 0.8308 (0.8138)  time: 1.6963  data: 0.1205  max mem: 20571\n",
      "Train: [epoch:757]  [ 20/172]  eta: 0:04:09  lr: 0.000027  loss: 0.8338 (0.8346)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [ 30/172]  eta: 0:03:50  lr: 0.000027  loss: 0.8394 (0.8298)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [ 40/172]  eta: 0:03:32  lr: 0.000027  loss: 0.8133 (0.8319)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [ 50/172]  eta: 0:03:15  lr: 0.000027  loss: 0.8482 (0.8343)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [ 60/172]  eta: 0:02:59  lr: 0.000027  loss: 0.8478 (0.8357)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [ 70/172]  eta: 0:02:42  lr: 0.000027  loss: 0.8376 (0.8375)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [ 80/172]  eta: 0:02:26  lr: 0.000027  loss: 0.8443 (0.8376)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [ 90/172]  eta: 0:02:10  lr: 0.000027  loss: 0.8526 (0.8409)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [100/172]  eta: 0:01:54  lr: 0.000027  loss: 0.8462 (0.8395)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [110/172]  eta: 0:01:38  lr: 0.000027  loss: 0.8033 (0.8373)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [120/172]  eta: 0:01:22  lr: 0.000027  loss: 0.8033 (0.8385)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [130/172]  eta: 0:01:06  lr: 0.000027  loss: 0.8245 (0.8382)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [140/172]  eta: 0:00:50  lr: 0.000027  loss: 0.8413 (0.8386)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [150/172]  eta: 0:00:34  lr: 0.000027  loss: 0.8487 (0.8383)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [160/172]  eta: 0:00:19  lr: 0.000027  loss: 0.8174 (0.8371)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [170/172]  eta: 0:00:03  lr: 0.000027  loss: 0.8173 (0.8376)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757]  [171/172]  eta: 0:00:01  lr: 0.000027  loss: 0.8173 (0.8373)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:757] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000027  loss: 0.8173 (0.8373)\n",
      "Valid: [epoch:757]  [ 0/14]  eta: 0:00:04  loss: 0.7218 (0.7218)  time: 0.3233  data: 0.3075  max mem: 20571\n",
      "Valid: [epoch:757]  [13/14]  eta: 0:00:00  loss: 0.7994 (0.8094)  time: 0.0383  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:757] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.7994 (0.8094)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_757_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.809%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:758]  [  0/172]  eta: 0:08:03  lr: 0.000027  loss: 0.7706 (0.7706)  time: 2.8111  data: 1.2428  max mem: 20571\n",
      "Train: [epoch:758]  [ 10/172]  eta: 0:04:33  lr: 0.000027  loss: 0.8578 (0.8356)  time: 1.6892  data: 0.1131  max mem: 20571\n",
      "Train: [epoch:758]  [ 20/172]  eta: 0:04:08  lr: 0.000027  loss: 0.8578 (0.8503)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [ 30/172]  eta: 0:03:49  lr: 0.000027  loss: 0.8448 (0.8426)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [ 40/172]  eta: 0:03:32  lr: 0.000027  loss: 0.8186 (0.8378)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [ 50/172]  eta: 0:03:15  lr: 0.000027  loss: 0.8411 (0.8392)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [ 60/172]  eta: 0:02:59  lr: 0.000027  loss: 0.8217 (0.8365)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [ 70/172]  eta: 0:02:42  lr: 0.000027  loss: 0.8208 (0.8363)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [ 80/172]  eta: 0:02:26  lr: 0.000027  loss: 0.8221 (0.8350)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [ 90/172]  eta: 0:02:10  lr: 0.000027  loss: 0.8433 (0.8377)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [100/172]  eta: 0:01:54  lr: 0.000027  loss: 0.8580 (0.8392)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [110/172]  eta: 0:01:38  lr: 0.000027  loss: 0.8264 (0.8389)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [120/172]  eta: 0:01:22  lr: 0.000027  loss: 0.8413 (0.8403)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [130/172]  eta: 0:01:06  lr: 0.000027  loss: 0.8413 (0.8401)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [140/172]  eta: 0:00:50  lr: 0.000027  loss: 0.8394 (0.8411)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [150/172]  eta: 0:00:34  lr: 0.000027  loss: 0.8339 (0.8410)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [160/172]  eta: 0:00:19  lr: 0.000027  loss: 0.8212 (0.8403)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758]  [170/172]  eta: 0:00:03  lr: 0.000027  loss: 0.8218 (0.8400)  time: 1.5830  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:758]  [171/172]  eta: 0:00:01  lr: 0.000027  loss: 0.8218 (0.8401)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:758] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000027  loss: 0.8218 (0.8401)\n",
      "Valid: [epoch:758]  [ 0/14]  eta: 0:00:04  loss: 0.8411 (0.8411)  time: 0.2873  data: 0.2724  max mem: 20571\n",
      "Valid: [epoch:758]  [13/14]  eta: 0:00:00  loss: 0.7920 (0.8030)  time: 0.0450  data: 0.0299  max mem: 20571\n",
      "Valid: [epoch:758] Total time: 0:00:00 (0.0527 s / it)\n",
      "Averaged stats: loss: 0.7920 (0.8030)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_758_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.803%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:759]  [  0/172]  eta: 0:07:30  lr: 0.000027  loss: 0.7769 (0.7769)  time: 2.6182  data: 1.0399  max mem: 20571\n",
      "Train: [epoch:759]  [ 10/172]  eta: 0:04:31  lr: 0.000027  loss: 0.8406 (0.8305)  time: 1.6737  data: 0.0946  max mem: 20571\n",
      "Train: [epoch:759]  [ 20/172]  eta: 0:04:07  lr: 0.000027  loss: 0.8347 (0.8366)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [ 30/172]  eta: 0:03:49  lr: 0.000027  loss: 0.8347 (0.8402)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [ 40/172]  eta: 0:03:31  lr: 0.000027  loss: 0.8403 (0.8411)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [ 50/172]  eta: 0:03:15  lr: 0.000027  loss: 0.8359 (0.8391)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [ 60/172]  eta: 0:02:58  lr: 0.000027  loss: 0.8162 (0.8372)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [ 70/172]  eta: 0:02:42  lr: 0.000027  loss: 0.8135 (0.8358)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [ 80/172]  eta: 0:02:26  lr: 0.000027  loss: 0.8251 (0.8411)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [ 90/172]  eta: 0:02:10  lr: 0.000027  loss: 0.8299 (0.8400)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [100/172]  eta: 0:01:54  lr: 0.000027  loss: 0.8209 (0.8371)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [110/172]  eta: 0:01:38  lr: 0.000027  loss: 0.8099 (0.8364)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [120/172]  eta: 0:01:22  lr: 0.000027  loss: 0.8387 (0.8376)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [130/172]  eta: 0:01:06  lr: 0.000027  loss: 0.8432 (0.8380)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [140/172]  eta: 0:00:50  lr: 0.000027  loss: 0.8525 (0.8388)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [150/172]  eta: 0:00:34  lr: 0.000027  loss: 0.8525 (0.8399)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [160/172]  eta: 0:00:19  lr: 0.000027  loss: 0.8413 (0.8403)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [170/172]  eta: 0:00:03  lr: 0.000027  loss: 0.8468 (0.8416)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759]  [171/172]  eta: 0:00:01  lr: 0.000027  loss: 0.8468 (0.8411)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:759] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000027  loss: 0.8468 (0.8411)\n",
      "Valid: [epoch:759]  [ 0/14]  eta: 0:00:04  loss: 0.8429 (0.8429)  time: 0.3172  data: 0.3023  max mem: 20571\n",
      "Valid: [epoch:759]  [13/14]  eta: 0:00:00  loss: 0.8005 (0.8099)  time: 0.0384  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:759] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.8005 (0.8099)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_759_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.810%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:760]  [  0/172]  eta: 0:07:22  lr: 0.000027  loss: 0.9066 (0.9066)  time: 2.5723  data: 1.0051  max mem: 20571\n",
      "Train: [epoch:760]  [ 10/172]  eta: 0:04:30  lr: 0.000027  loss: 0.8289 (0.8382)  time: 1.6680  data: 0.0915  max mem: 20571\n",
      "Train: [epoch:760]  [ 20/172]  eta: 0:04:07  lr: 0.000027  loss: 0.8300 (0.8482)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [ 30/172]  eta: 0:03:48  lr: 0.000027  loss: 0.8397 (0.8461)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [ 40/172]  eta: 0:03:31  lr: 0.000027  loss: 0.8262 (0.8390)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [ 50/172]  eta: 0:03:15  lr: 0.000027  loss: 0.8192 (0.8426)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [ 60/172]  eta: 0:02:58  lr: 0.000027  loss: 0.8378 (0.8453)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [ 70/172]  eta: 0:02:42  lr: 0.000027  loss: 0.8378 (0.8466)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [ 80/172]  eta: 0:02:26  lr: 0.000027  loss: 0.8372 (0.8460)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [ 90/172]  eta: 0:02:10  lr: 0.000027  loss: 0.8276 (0.8436)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [100/172]  eta: 0:01:54  lr: 0.000027  loss: 0.8193 (0.8415)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:760]  [110/172]  eta: 0:01:38  lr: 0.000027  loss: 0.8219 (0.8416)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [120/172]  eta: 0:01:22  lr: 0.000027  loss: 0.8219 (0.8415)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [130/172]  eta: 0:01:06  lr: 0.000027  loss: 0.8157 (0.8402)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [140/172]  eta: 0:00:50  lr: 0.000027  loss: 0.8157 (0.8392)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [150/172]  eta: 0:00:34  lr: 0.000027  loss: 0.8196 (0.8399)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [160/172]  eta: 0:00:19  lr: 0.000027  loss: 0.8509 (0.8420)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [170/172]  eta: 0:00:03  lr: 0.000027  loss: 0.8391 (0.8414)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760]  [171/172]  eta: 0:00:01  lr: 0.000027  loss: 0.8390 (0.8412)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:760] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000027  loss: 0.8390 (0.8412)\n",
      "Valid: [epoch:760]  [ 0/14]  eta: 0:00:04  loss: 0.8421 (0.8421)  time: 0.2869  data: 0.2707  max mem: 20571\n",
      "Valid: [epoch:760]  [13/14]  eta: 0:00:00  loss: 0.7912 (0.8018)  time: 0.0404  data: 0.0254  max mem: 20571\n",
      "Valid: [epoch:760] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.7912 (0.8018)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_760_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.802%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:761]  [  0/172]  eta: 0:08:04  lr: 0.000027  loss: 0.7782 (0.7782)  time: 2.8147  data: 1.2203  max mem: 20571\n",
      "Train: [epoch:761]  [ 10/172]  eta: 0:04:33  lr: 0.000027  loss: 0.8136 (0.8194)  time: 1.6899  data: 0.1111  max mem: 20571\n",
      "Train: [epoch:761]  [ 20/172]  eta: 0:04:08  lr: 0.000027  loss: 0.8158 (0.8285)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [ 30/172]  eta: 0:03:49  lr: 0.000027  loss: 0.8241 (0.8296)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [ 40/172]  eta: 0:03:32  lr: 0.000027  loss: 0.8321 (0.8356)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [ 50/172]  eta: 0:03:15  lr: 0.000027  loss: 0.8327 (0.8355)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [ 60/172]  eta: 0:02:59  lr: 0.000027  loss: 0.8287 (0.8337)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:761]  [ 70/172]  eta: 0:02:42  lr: 0.000027  loss: 0.8293 (0.8327)  time: 1.5767  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:761]  [ 80/172]  eta: 0:02:26  lr: 0.000027  loss: 0.8493 (0.8357)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [ 90/172]  eta: 0:02:10  lr: 0.000027  loss: 0.8558 (0.8394)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [100/172]  eta: 0:01:54  lr: 0.000027  loss: 0.8535 (0.8405)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [110/172]  eta: 0:01:38  lr: 0.000027  loss: 0.8535 (0.8422)  time: 1.5796  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:761]  [120/172]  eta: 0:01:22  lr: 0.000027  loss: 0.8684 (0.8446)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [130/172]  eta: 0:01:06  lr: 0.000027  loss: 0.8323 (0.8423)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [140/172]  eta: 0:00:50  lr: 0.000027  loss: 0.8034 (0.8402)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [150/172]  eta: 0:00:34  lr: 0.000027  loss: 0.8291 (0.8419)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [160/172]  eta: 0:00:19  lr: 0.000027  loss: 0.8463 (0.8423)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [170/172]  eta: 0:00:03  lr: 0.000027  loss: 0.8501 (0.8438)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761]  [171/172]  eta: 0:00:01  lr: 0.000027  loss: 0.8436 (0.8437)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:761] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000027  loss: 0.8436 (0.8437)\n",
      "Valid: [epoch:761]  [ 0/14]  eta: 0:00:04  loss: 0.8801 (0.8801)  time: 0.2945  data: 0.2792  max mem: 20571\n",
      "Valid: [epoch:761]  [13/14]  eta: 0:00:00  loss: 0.8022 (0.8103)  time: 0.0402  data: 0.0252  max mem: 20571\n",
      "Valid: [epoch:761] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.8022 (0.8103)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_761_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.810%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:762]  [  0/172]  eta: 0:07:57  lr: 0.000027  loss: 0.9225 (0.9225)  time: 2.7778  data: 1.2123  max mem: 20571\n",
      "Train: [epoch:762]  [ 10/172]  eta: 0:04:33  lr: 0.000027  loss: 0.8663 (0.8636)  time: 1.6871  data: 0.1104  max mem: 20571\n",
      "Train: [epoch:762]  [ 20/172]  eta: 0:04:08  lr: 0.000027  loss: 0.8474 (0.8462)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:762]  [ 30/172]  eta: 0:03:49  lr: 0.000027  loss: 0.8192 (0.8442)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:762]  [ 40/172]  eta: 0:03:32  lr: 0.000027  loss: 0.8321 (0.8426)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [ 50/172]  eta: 0:03:15  lr: 0.000027  loss: 0.8385 (0.8428)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [ 60/172]  eta: 0:02:59  lr: 0.000027  loss: 0.8220 (0.8387)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [ 70/172]  eta: 0:02:42  lr: 0.000027  loss: 0.8269 (0.8386)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [ 80/172]  eta: 0:02:26  lr: 0.000027  loss: 0.8539 (0.8437)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [ 90/172]  eta: 0:02:10  lr: 0.000027  loss: 0.8539 (0.8427)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [100/172]  eta: 0:01:54  lr: 0.000027  loss: 0.8247 (0.8412)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [110/172]  eta: 0:01:38  lr: 0.000027  loss: 0.8275 (0.8421)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [120/172]  eta: 0:01:22  lr: 0.000027  loss: 0.8550 (0.8414)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [130/172]  eta: 0:01:06  lr: 0.000027  loss: 0.8387 (0.8407)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:762]  [140/172]  eta: 0:00:50  lr: 0.000027  loss: 0.8386 (0.8410)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [150/172]  eta: 0:00:34  lr: 0.000027  loss: 0.8386 (0.8410)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [160/172]  eta: 0:00:19  lr: 0.000027  loss: 0.8459 (0.8411)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [170/172]  eta: 0:00:03  lr: 0.000027  loss: 0.8390 (0.8420)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762]  [171/172]  eta: 0:00:01  lr: 0.000027  loss: 0.8390 (0.8422)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:762] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000027  loss: 0.8390 (0.8422)\n",
      "Valid: [epoch:762]  [ 0/14]  eta: 0:00:04  loss: 0.7524 (0.7524)  time: 0.2933  data: 0.2780  max mem: 20571\n",
      "Valid: [epoch:762]  [13/14]  eta: 0:00:00  loss: 0.7942 (0.8028)  time: 0.0378  data: 0.0227  max mem: 20571\n",
      "Valid: [epoch:762] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.7942 (0.8028)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_762_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.803%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:763]  [  0/172]  eta: 0:07:34  lr: 0.000026  loss: 0.8080 (0.8080)  time: 2.6434  data: 1.0673  max mem: 20571\n",
      "Train: [epoch:763]  [ 10/172]  eta: 0:04:30  lr: 0.000026  loss: 0.8141 (0.8254)  time: 1.6728  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:763]  [ 20/172]  eta: 0:04:07  lr: 0.000026  loss: 0.8229 (0.8365)  time: 1.5764  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:763]  [ 30/172]  eta: 0:03:48  lr: 0.000026  loss: 0.8779 (0.8455)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:763]  [ 40/172]  eta: 0:03:31  lr: 0.000026  loss: 0.8302 (0.8450)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:763]  [ 50/172]  eta: 0:03:15  lr: 0.000026  loss: 0.8484 (0.8500)  time: 1.5796  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:763]  [ 60/172]  eta: 0:02:58  lr: 0.000026  loss: 0.8407 (0.8492)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:763]  [ 70/172]  eta: 0:02:42  lr: 0.000026  loss: 0.8395 (0.8499)  time: 1.5782  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:763]  [ 80/172]  eta: 0:02:26  lr: 0.000026  loss: 0.8501 (0.8505)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [ 90/172]  eta: 0:02:10  lr: 0.000026  loss: 0.8490 (0.8504)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [100/172]  eta: 0:01:54  lr: 0.000026  loss: 0.8388 (0.8485)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [110/172]  eta: 0:01:38  lr: 0.000026  loss: 0.8059 (0.8457)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [120/172]  eta: 0:01:22  lr: 0.000026  loss: 0.8294 (0.8473)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [130/172]  eta: 0:01:06  lr: 0.000026  loss: 0.8562 (0.8475)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [140/172]  eta: 0:00:50  lr: 0.000026  loss: 0.8476 (0.8466)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [150/172]  eta: 0:00:34  lr: 0.000026  loss: 0.8324 (0.8453)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [160/172]  eta: 0:00:19  lr: 0.000026  loss: 0.8409 (0.8442)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [170/172]  eta: 0:00:03  lr: 0.000026  loss: 0.8372 (0.8437)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763]  [171/172]  eta: 0:00:01  lr: 0.000026  loss: 0.8372 (0.8437)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:763] Total time: 0:04:32 (1.5858 s / it)\n",
      "Averaged stats: lr: 0.000026  loss: 0.8372 (0.8437)\n",
      "Valid: [epoch:763]  [ 0/14]  eta: 0:00:04  loss: 0.8477 (0.8477)  time: 0.3299  data: 0.3145  max mem: 20571\n",
      "Valid: [epoch:763]  [13/14]  eta: 0:00:00  loss: 0.7971 (0.8073)  time: 0.0420  data: 0.0268  max mem: 20571\n",
      "Valid: [epoch:763] Total time: 0:00:00 (0.0493 s / it)\n",
      "Averaged stats: loss: 0.7971 (0.8073)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_763_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.807%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:764]  [  0/172]  eta: 0:08:02  lr: 0.000026  loss: 0.8078 (0.8078)  time: 2.8024  data: 1.2289  max mem: 20571\n",
      "Train: [epoch:764]  [ 10/172]  eta: 0:04:33  lr: 0.000026  loss: 0.8322 (0.8273)  time: 1.6881  data: 0.1119  max mem: 20571\n",
      "Train: [epoch:764]  [ 20/172]  eta: 0:04:08  lr: 0.000026  loss: 0.8322 (0.8296)  time: 1.5776  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:764]  [ 30/172]  eta: 0:03:49  lr: 0.000026  loss: 0.8516 (0.8367)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [ 40/172]  eta: 0:03:32  lr: 0.000026  loss: 0.8455 (0.8357)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [ 50/172]  eta: 0:03:15  lr: 0.000026  loss: 0.8455 (0.8411)  time: 1.5791  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:764]  [ 60/172]  eta: 0:02:59  lr: 0.000026  loss: 0.8431 (0.8383)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [ 70/172]  eta: 0:02:42  lr: 0.000026  loss: 0.8421 (0.8409)  time: 1.5795  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:764]  [ 80/172]  eta: 0:02:26  lr: 0.000026  loss: 0.8518 (0.8429)  time: 1.5796  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:764]  [ 90/172]  eta: 0:02:10  lr: 0.000026  loss: 0.8380 (0.8428)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [100/172]  eta: 0:01:54  lr: 0.000026  loss: 0.8277 (0.8423)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [110/172]  eta: 0:01:38  lr: 0.000026  loss: 0.8352 (0.8426)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [120/172]  eta: 0:01:22  lr: 0.000026  loss: 0.8367 (0.8418)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [130/172]  eta: 0:01:06  lr: 0.000026  loss: 0.8386 (0.8429)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [140/172]  eta: 0:00:50  lr: 0.000026  loss: 0.8578 (0.8450)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [150/172]  eta: 0:00:34  lr: 0.000026  loss: 0.8582 (0.8451)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [160/172]  eta: 0:00:19  lr: 0.000026  loss: 0.8411 (0.8453)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [170/172]  eta: 0:00:03  lr: 0.000026  loss: 0.8411 (0.8458)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764]  [171/172]  eta: 0:00:01  lr: 0.000026  loss: 0.8411 (0.8455)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:764] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000026  loss: 0.8411 (0.8455)\n",
      "Valid: [epoch:764]  [ 0/14]  eta: 0:00:04  loss: 0.7566 (0.7566)  time: 0.3397  data: 0.3225  max mem: 20571\n",
      "Valid: [epoch:764]  [13/14]  eta: 0:00:00  loss: 0.7958 (0.8058)  time: 0.0395  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:764] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.7958 (0.8058)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_764_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.806%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:765]  [  0/172]  eta: 0:07:47  lr: 0.000026  loss: 0.8015 (0.8015)  time: 2.7197  data: 1.1424  max mem: 20571\n",
      "Train: [epoch:765]  [ 10/172]  eta: 0:04:32  lr: 0.000026  loss: 0.8328 (0.8412)  time: 1.6820  data: 0.1040  max mem: 20571\n",
      "Train: [epoch:765]  [ 20/172]  eta: 0:04:08  lr: 0.000026  loss: 0.8409 (0.8448)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:765]  [ 30/172]  eta: 0:03:49  lr: 0.000026  loss: 0.8345 (0.8419)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [ 40/172]  eta: 0:03:32  lr: 0.000026  loss: 0.8298 (0.8412)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [ 50/172]  eta: 0:03:15  lr: 0.000026  loss: 0.8274 (0.8396)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [ 60/172]  eta: 0:02:58  lr: 0.000026  loss: 0.8459 (0.8434)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [ 70/172]  eta: 0:02:42  lr: 0.000026  loss: 0.8459 (0.8445)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [ 80/172]  eta: 0:02:26  lr: 0.000026  loss: 0.8191 (0.8435)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [ 90/172]  eta: 0:02:10  lr: 0.000026  loss: 0.8382 (0.8451)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [100/172]  eta: 0:01:54  lr: 0.000026  loss: 0.8382 (0.8458)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [110/172]  eta: 0:01:38  lr: 0.000026  loss: 0.8609 (0.8492)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [120/172]  eta: 0:01:22  lr: 0.000026  loss: 0.8617 (0.8492)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [130/172]  eta: 0:01:06  lr: 0.000026  loss: 0.8595 (0.8501)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [140/172]  eta: 0:00:50  lr: 0.000026  loss: 0.8442 (0.8497)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [150/172]  eta: 0:00:34  lr: 0.000026  loss: 0.8356 (0.8488)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [160/172]  eta: 0:00:19  lr: 0.000026  loss: 0.8356 (0.8485)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [170/172]  eta: 0:00:03  lr: 0.000026  loss: 0.8527 (0.8487)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765]  [171/172]  eta: 0:00:01  lr: 0.000026  loss: 0.8527 (0.8488)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:765] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000026  loss: 0.8527 (0.8488)\n",
      "Valid: [epoch:765]  [ 0/14]  eta: 0:00:04  loss: 0.7936 (0.7936)  time: 0.3024  data: 0.2853  max mem: 20571\n",
      "Valid: [epoch:765]  [13/14]  eta: 0:00:00  loss: 0.7996 (0.8098)  time: 0.0378  data: 0.0223  max mem: 20571\n",
      "Valid: [epoch:765] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.7996 (0.8098)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_765_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.810%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:766]  [  0/172]  eta: 0:07:21  lr: 0.000026  loss: 1.0559 (1.0559)  time: 2.5690  data: 1.0026  max mem: 20571\n",
      "Train: [epoch:766]  [ 10/172]  eta: 0:04:30  lr: 0.000026  loss: 0.8385 (0.8642)  time: 1.6694  data: 0.0912  max mem: 20571\n",
      "Train: [epoch:766]  [ 20/172]  eta: 0:04:07  lr: 0.000026  loss: 0.8320 (0.8457)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [ 30/172]  eta: 0:03:48  lr: 0.000026  loss: 0.8262 (0.8402)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [ 40/172]  eta: 0:03:31  lr: 0.000026  loss: 0.8326 (0.8382)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:766]  [ 50/172]  eta: 0:03:15  lr: 0.000026  loss: 0.8496 (0.8436)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:766]  [ 60/172]  eta: 0:02:58  lr: 0.000026  loss: 0.8496 (0.8439)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [ 70/172]  eta: 0:02:42  lr: 0.000026  loss: 0.8234 (0.8424)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [ 80/172]  eta: 0:02:26  lr: 0.000026  loss: 0.8359 (0.8465)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [ 90/172]  eta: 0:02:10  lr: 0.000026  loss: 0.8531 (0.8450)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [100/172]  eta: 0:01:54  lr: 0.000026  loss: 0.8358 (0.8443)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [110/172]  eta: 0:01:38  lr: 0.000026  loss: 0.8162 (0.8426)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [120/172]  eta: 0:01:22  lr: 0.000026  loss: 0.8449 (0.8444)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [130/172]  eta: 0:01:06  lr: 0.000026  loss: 0.8454 (0.8438)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [140/172]  eta: 0:00:50  lr: 0.000026  loss: 0.8454 (0.8450)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [150/172]  eta: 0:00:34  lr: 0.000026  loss: 0.8458 (0.8441)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:766]  [160/172]  eta: 0:00:19  lr: 0.000026  loss: 0.8338 (0.8446)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:766]  [170/172]  eta: 0:00:03  lr: 0.000026  loss: 0.8385 (0.8460)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:766]  [171/172]  eta: 0:00:01  lr: 0.000026  loss: 0.8490 (0.8462)  time: 1.5800  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:766] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000026  loss: 0.8490 (0.8462)\n",
      "Valid: [epoch:766]  [ 0/14]  eta: 0:00:06  loss: 0.8803 (0.8803)  time: 0.4628  data: 0.4448  max mem: 20571\n",
      "Valid: [epoch:766]  [13/14]  eta: 0:00:00  loss: 0.7992 (0.8094)  time: 0.0485  data: 0.0333  max mem: 20571\n",
      "Valid: [epoch:766] Total time: 0:00:00 (0.0533 s / it)\n",
      "Averaged stats: loss: 0.7992 (0.8094)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_766_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.809%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:767]  [  0/172]  eta: 0:07:40  lr: 0.000026  loss: 0.7697 (0.7697)  time: 2.6757  data: 1.1045  max mem: 20571\n",
      "Train: [epoch:767]  [ 10/172]  eta: 0:04:31  lr: 0.000026  loss: 0.8248 (0.8306)  time: 1.6743  data: 0.1005  max mem: 20571\n",
      "Train: [epoch:767]  [ 20/172]  eta: 0:04:07  lr: 0.000026  loss: 0.8425 (0.8460)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [ 30/172]  eta: 0:03:48  lr: 0.000026  loss: 0.8570 (0.8488)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [ 40/172]  eta: 0:03:31  lr: 0.000026  loss: 0.8348 (0.8420)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [ 50/172]  eta: 0:03:15  lr: 0.000026  loss: 0.8306 (0.8435)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [ 60/172]  eta: 0:02:58  lr: 0.000026  loss: 0.8409 (0.8421)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [ 70/172]  eta: 0:02:42  lr: 0.000026  loss: 0.8451 (0.8430)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [ 80/172]  eta: 0:02:26  lr: 0.000026  loss: 0.8451 (0.8442)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [ 90/172]  eta: 0:02:10  lr: 0.000026  loss: 0.8359 (0.8429)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [100/172]  eta: 0:01:54  lr: 0.000026  loss: 0.8245 (0.8416)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [110/172]  eta: 0:01:38  lr: 0.000026  loss: 0.8245 (0.8423)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [120/172]  eta: 0:01:22  lr: 0.000026  loss: 0.8468 (0.8431)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [130/172]  eta: 0:01:06  lr: 0.000026  loss: 0.8602 (0.8449)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [140/172]  eta: 0:00:50  lr: 0.000026  loss: 0.8612 (0.8445)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [150/172]  eta: 0:00:34  lr: 0.000026  loss: 0.8532 (0.8453)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [160/172]  eta: 0:00:19  lr: 0.000026  loss: 0.8532 (0.8458)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [170/172]  eta: 0:00:03  lr: 0.000026  loss: 0.8855 (0.8476)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767]  [171/172]  eta: 0:00:01  lr: 0.000026  loss: 0.8855 (0.8474)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:767] Total time: 0:04:32 (1.5848 s / it)\n",
      "Averaged stats: lr: 0.000026  loss: 0.8855 (0.8474)\n",
      "Valid: [epoch:767]  [ 0/14]  eta: 0:00:04  loss: 0.8448 (0.8448)  time: 0.2908  data: 0.2728  max mem: 20571\n",
      "Valid: [epoch:767]  [13/14]  eta: 0:00:00  loss: 0.8034 (0.8138)  time: 0.0386  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:767] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.8034 (0.8138)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_767_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.814%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:768]  [  0/172]  eta: 0:07:36  lr: 0.000026  loss: 0.8642 (0.8642)  time: 2.6546  data: 1.0892  max mem: 20571\n",
      "Train: [epoch:768]  [ 10/172]  eta: 0:04:31  lr: 0.000026  loss: 0.8347 (0.8361)  time: 1.6749  data: 0.0991  max mem: 20571\n",
      "Train: [epoch:768]  [ 20/172]  eta: 0:04:07  lr: 0.000026  loss: 0.8360 (0.8439)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [ 30/172]  eta: 0:03:48  lr: 0.000026  loss: 0.8360 (0.8411)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [ 40/172]  eta: 0:03:31  lr: 0.000026  loss: 0.8399 (0.8461)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [ 50/172]  eta: 0:03:15  lr: 0.000026  loss: 0.8586 (0.8511)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [ 60/172]  eta: 0:02:58  lr: 0.000026  loss: 0.8467 (0.8501)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [ 70/172]  eta: 0:02:42  lr: 0.000026  loss: 0.8556 (0.8517)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [ 80/172]  eta: 0:02:26  lr: 0.000026  loss: 0.8354 (0.8472)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [ 90/172]  eta: 0:02:10  lr: 0.000026  loss: 0.8303 (0.8489)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [100/172]  eta: 0:01:54  lr: 0.000026  loss: 0.8430 (0.8491)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [110/172]  eta: 0:01:38  lr: 0.000026  loss: 0.8412 (0.8512)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [120/172]  eta: 0:01:22  lr: 0.000026  loss: 0.8376 (0.8505)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [130/172]  eta: 0:01:06  lr: 0.000026  loss: 0.8333 (0.8497)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [140/172]  eta: 0:00:50  lr: 0.000026  loss: 0.8339 (0.8498)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [150/172]  eta: 0:00:34  lr: 0.000026  loss: 0.8450 (0.8494)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [160/172]  eta: 0:00:19  lr: 0.000026  loss: 0.8516 (0.8502)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [170/172]  eta: 0:00:03  lr: 0.000026  loss: 0.8611 (0.8507)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768]  [171/172]  eta: 0:00:01  lr: 0.000026  loss: 0.8446 (0.8505)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:768] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000026  loss: 0.8446 (0.8505)\n",
      "Valid: [epoch:768]  [ 0/14]  eta: 0:00:04  loss: 0.8531 (0.8531)  time: 0.3011  data: 0.2858  max mem: 20571\n",
      "Valid: [epoch:768]  [13/14]  eta: 0:00:00  loss: 0.8025 (0.8123)  time: 0.0383  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:768] Total time: 0:00:00 (0.0461 s / it)\n",
      "Averaged stats: loss: 0.8025 (0.8123)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_768_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.812%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:769]  [  0/172]  eta: 0:07:54  lr: 0.000026  loss: 0.9795 (0.9795)  time: 2.7600  data: 1.1842  max mem: 20571\n",
      "Train: [epoch:769]  [ 10/172]  eta: 0:04:32  lr: 0.000026  loss: 0.8423 (0.8581)  time: 1.6826  data: 0.1078  max mem: 20571\n",
      "Train: [epoch:769]  [ 20/172]  eta: 0:04:08  lr: 0.000026  loss: 0.8160 (0.8425)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [ 30/172]  eta: 0:03:49  lr: 0.000026  loss: 0.8303 (0.8440)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [ 40/172]  eta: 0:03:31  lr: 0.000026  loss: 0.8451 (0.8460)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [ 50/172]  eta: 0:03:15  lr: 0.000026  loss: 0.8325 (0.8449)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [ 60/172]  eta: 0:02:58  lr: 0.000026  loss: 0.8308 (0.8432)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [ 70/172]  eta: 0:02:42  lr: 0.000026  loss: 0.8442 (0.8467)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [ 80/172]  eta: 0:02:26  lr: 0.000026  loss: 0.8691 (0.8475)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [ 90/172]  eta: 0:02:10  lr: 0.000026  loss: 0.8788 (0.8512)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [100/172]  eta: 0:01:54  lr: 0.000026  loss: 0.8564 (0.8509)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [110/172]  eta: 0:01:38  lr: 0.000026  loss: 0.8503 (0.8507)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [120/172]  eta: 0:01:22  lr: 0.000026  loss: 0.8376 (0.8498)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [130/172]  eta: 0:01:06  lr: 0.000026  loss: 0.8519 (0.8511)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [140/172]  eta: 0:00:50  lr: 0.000026  loss: 0.8358 (0.8481)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769]  [150/172]  eta: 0:00:34  lr: 0.000026  loss: 0.8277 (0.8485)  time: 1.5779  data: 0.0004  max mem: 20571\n",
      "Train: [epoch:769]  [160/172]  eta: 0:00:19  lr: 0.000026  loss: 0.8563 (0.8486)  time: 1.5792  data: 0.0004  max mem: 20571\n",
      "Train: [epoch:769]  [170/172]  eta: 0:00:03  lr: 0.000026  loss: 0.8563 (0.8492)  time: 1.5803  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:769]  [171/172]  eta: 0:00:01  lr: 0.000026  loss: 0.8582 (0.8495)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:769] Total time: 0:04:32 (1.5856 s / it)\n",
      "Averaged stats: lr: 0.000026  loss: 0.8582 (0.8495)\n",
      "Valid: [epoch:769]  [ 0/14]  eta: 0:00:06  loss: 0.8540 (0.8540)  time: 0.4734  data: 0.4567  max mem: 20571\n",
      "Valid: [epoch:769]  [13/14]  eta: 0:00:00  loss: 0.8012 (0.8113)  time: 0.0485  data: 0.0335  max mem: 20571\n",
      "Valid: [epoch:769] Total time: 0:00:00 (0.0541 s / it)\n",
      "Averaged stats: loss: 0.8012 (0.8113)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_769_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.811%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:770]  [  0/172]  eta: 0:07:34  lr: 0.000026  loss: 0.9841 (0.9841)  time: 2.6448  data: 1.0802  max mem: 20571\n",
      "Train: [epoch:770]  [ 10/172]  eta: 0:04:31  lr: 0.000026  loss: 0.8510 (0.8701)  time: 1.6732  data: 0.0983  max mem: 20571\n",
      "Train: [epoch:770]  [ 20/172]  eta: 0:04:07  lr: 0.000026  loss: 0.8510 (0.8617)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [ 30/172]  eta: 0:03:48  lr: 0.000026  loss: 0.8395 (0.8556)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [ 40/172]  eta: 0:03:31  lr: 0.000026  loss: 0.8395 (0.8552)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [ 50/172]  eta: 0:03:15  lr: 0.000026  loss: 0.8513 (0.8565)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [ 60/172]  eta: 0:02:58  lr: 0.000026  loss: 0.8513 (0.8561)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [ 70/172]  eta: 0:02:42  lr: 0.000026  loss: 0.8532 (0.8549)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [ 80/172]  eta: 0:02:26  lr: 0.000026  loss: 0.8479 (0.8529)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [ 90/172]  eta: 0:02:10  lr: 0.000026  loss: 0.8362 (0.8519)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [100/172]  eta: 0:01:54  lr: 0.000026  loss: 0.8529 (0.8529)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [110/172]  eta: 0:01:38  lr: 0.000026  loss: 0.8531 (0.8523)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [120/172]  eta: 0:01:22  lr: 0.000026  loss: 0.8531 (0.8526)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [130/172]  eta: 0:01:06  lr: 0.000026  loss: 0.8660 (0.8541)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [140/172]  eta: 0:00:50  lr: 0.000026  loss: 0.8633 (0.8538)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [150/172]  eta: 0:00:34  lr: 0.000026  loss: 0.8479 (0.8526)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [160/172]  eta: 0:00:19  lr: 0.000026  loss: 0.8272 (0.8512)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [170/172]  eta: 0:00:03  lr: 0.000026  loss: 0.8330 (0.8520)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770]  [171/172]  eta: 0:00:01  lr: 0.000026  loss: 0.8365 (0.8525)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:770] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000026  loss: 0.8365 (0.8525)\n",
      "Valid: [epoch:770]  [ 0/14]  eta: 0:00:04  loss: 0.8833 (0.8833)  time: 0.3478  data: 0.3308  max mem: 20571\n",
      "Valid: [epoch:770]  [13/14]  eta: 0:00:00  loss: 0.8052 (0.8143)  time: 0.0406  data: 0.0253  max mem: 20571\n",
      "Valid: [epoch:770] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.8052 (0.8143)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_770_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.814%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:771]  [  0/172]  eta: 0:07:26  lr: 0.000026  loss: 0.8377 (0.8377)  time: 2.5965  data: 1.0106  max mem: 20571\n",
      "Train: [epoch:771]  [ 10/172]  eta: 0:04:30  lr: 0.000026  loss: 0.8424 (0.8445)  time: 1.6678  data: 0.0920  max mem: 20571\n",
      "Train: [epoch:771]  [ 20/172]  eta: 0:04:07  lr: 0.000026  loss: 0.8316 (0.8433)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [ 30/172]  eta: 0:03:48  lr: 0.000026  loss: 0.8316 (0.8517)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [ 40/172]  eta: 0:03:31  lr: 0.000026  loss: 0.8431 (0.8499)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [ 50/172]  eta: 0:03:15  lr: 0.000026  loss: 0.8529 (0.8531)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [ 60/172]  eta: 0:02:58  lr: 0.000026  loss: 0.8495 (0.8511)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [ 70/172]  eta: 0:02:42  lr: 0.000026  loss: 0.8280 (0.8497)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [ 80/172]  eta: 0:02:26  lr: 0.000026  loss: 0.8400 (0.8500)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [ 90/172]  eta: 0:02:10  lr: 0.000026  loss: 0.8535 (0.8502)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [100/172]  eta: 0:01:54  lr: 0.000026  loss: 0.8521 (0.8486)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [110/172]  eta: 0:01:38  lr: 0.000026  loss: 0.8362 (0.8498)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [120/172]  eta: 0:01:22  lr: 0.000026  loss: 0.8698 (0.8536)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [130/172]  eta: 0:01:06  lr: 0.000026  loss: 0.8609 (0.8520)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [140/172]  eta: 0:00:50  lr: 0.000026  loss: 0.8441 (0.8517)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [150/172]  eta: 0:00:34  lr: 0.000026  loss: 0.8531 (0.8517)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [160/172]  eta: 0:00:19  lr: 0.000026  loss: 0.8531 (0.8513)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [170/172]  eta: 0:00:03  lr: 0.000026  loss: 0.8582 (0.8524)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771]  [171/172]  eta: 0:00:01  lr: 0.000026  loss: 0.8582 (0.8528)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:771] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000026  loss: 0.8582 (0.8528)\n",
      "Valid: [epoch:771]  [ 0/14]  eta: 0:00:04  loss: 0.7466 (0.7466)  time: 0.3037  data: 0.2876  max mem: 20571\n",
      "Valid: [epoch:771]  [13/14]  eta: 0:00:00  loss: 0.8046 (0.8141)  time: 0.0371  data: 0.0221  max mem: 20571\n",
      "Valid: [epoch:771] Total time: 0:00:00 (0.0421 s / it)\n",
      "Averaged stats: loss: 0.8046 (0.8141)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_771_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.814%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:772]  [  0/172]  eta: 0:07:21  lr: 0.000025  loss: 0.8851 (0.8851)  time: 2.5669  data: 1.0006  max mem: 20571\n",
      "Train: [epoch:772]  [ 10/172]  eta: 0:04:29  lr: 0.000025  loss: 0.8580 (0.8522)  time: 1.6657  data: 0.0911  max mem: 20571\n",
      "Train: [epoch:772]  [ 20/172]  eta: 0:04:06  lr: 0.000025  loss: 0.8385 (0.8453)  time: 1.5767  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:772]  [ 30/172]  eta: 0:03:48  lr: 0.000025  loss: 0.8414 (0.8477)  time: 1.5770  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:772]  [ 40/172]  eta: 0:03:31  lr: 0.000025  loss: 0.8489 (0.8497)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [ 50/172]  eta: 0:03:14  lr: 0.000025  loss: 0.8587 (0.8531)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [ 60/172]  eta: 0:02:58  lr: 0.000025  loss: 0.8318 (0.8489)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [ 70/172]  eta: 0:02:42  lr: 0.000025  loss: 0.8356 (0.8490)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [ 80/172]  eta: 0:02:26  lr: 0.000025  loss: 0.8570 (0.8497)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [ 90/172]  eta: 0:02:10  lr: 0.000025  loss: 0.8496 (0.8513)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [100/172]  eta: 0:01:54  lr: 0.000025  loss: 0.8496 (0.8521)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [110/172]  eta: 0:01:38  lr: 0.000025  loss: 0.8443 (0.8514)  time: 1.5780  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:772]  [120/172]  eta: 0:01:22  lr: 0.000025  loss: 0.8589 (0.8529)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [130/172]  eta: 0:01:06  lr: 0.000025  loss: 0.8670 (0.8539)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [140/172]  eta: 0:00:50  lr: 0.000025  loss: 0.8539 (0.8526)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [150/172]  eta: 0:00:34  lr: 0.000025  loss: 0.8539 (0.8528)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [160/172]  eta: 0:00:19  lr: 0.000025  loss: 0.8479 (0.8520)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [170/172]  eta: 0:00:03  lr: 0.000025  loss: 0.8479 (0.8529)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772]  [171/172]  eta: 0:00:01  lr: 0.000025  loss: 0.8502 (0.8532)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:772] Total time: 0:04:32 (1.5838 s / it)\n",
      "Averaged stats: lr: 0.000025  loss: 0.8502 (0.8532)\n",
      "Valid: [epoch:772]  [ 0/14]  eta: 0:00:06  loss: 0.7392 (0.7392)  time: 0.4405  data: 0.4245  max mem: 20571\n",
      "Valid: [epoch:772]  [13/14]  eta: 0:00:00  loss: 0.8165 (0.8271)  time: 0.0474  data: 0.0323  max mem: 20571\n",
      "Valid: [epoch:772] Total time: 0:00:00 (0.0555 s / it)\n",
      "Averaged stats: loss: 0.8165 (0.8271)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_772_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.827%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:773]  [  0/172]  eta: 0:07:51  lr: 0.000025  loss: 0.8280 (0.8280)  time: 2.7393  data: 1.1663  max mem: 20571\n",
      "Train: [epoch:773]  [ 10/172]  eta: 0:04:31  lr: 0.000025  loss: 0.8280 (0.8364)  time: 1.6787  data: 0.1062  max mem: 20571\n",
      "Train: [epoch:773]  [ 20/172]  eta: 0:04:07  lr: 0.000025  loss: 0.8336 (0.8435)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [ 30/172]  eta: 0:03:49  lr: 0.000025  loss: 0.8567 (0.8469)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [ 40/172]  eta: 0:03:31  lr: 0.000025  loss: 0.8676 (0.8493)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [ 50/172]  eta: 0:03:15  lr: 0.000025  loss: 0.8583 (0.8551)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [ 60/172]  eta: 0:02:58  lr: 0.000025  loss: 0.8555 (0.8544)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [ 70/172]  eta: 0:02:42  lr: 0.000025  loss: 0.8455 (0.8524)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [ 80/172]  eta: 0:02:26  lr: 0.000025  loss: 0.8455 (0.8506)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [ 90/172]  eta: 0:02:10  lr: 0.000025  loss: 0.8529 (0.8488)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [100/172]  eta: 0:01:54  lr: 0.000025  loss: 0.8383 (0.8513)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [110/172]  eta: 0:01:38  lr: 0.000025  loss: 0.8400 (0.8518)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [120/172]  eta: 0:01:22  lr: 0.000025  loss: 0.8622 (0.8533)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [130/172]  eta: 0:01:06  lr: 0.000025  loss: 0.8699 (0.8540)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [140/172]  eta: 0:00:50  lr: 0.000025  loss: 0.8651 (0.8534)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [150/172]  eta: 0:00:34  lr: 0.000025  loss: 0.8651 (0.8543)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [160/172]  eta: 0:00:19  lr: 0.000025  loss: 0.8525 (0.8536)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [170/172]  eta: 0:00:03  lr: 0.000025  loss: 0.8402 (0.8538)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773]  [171/172]  eta: 0:00:01  lr: 0.000025  loss: 0.8332 (0.8535)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:773] Total time: 0:04:32 (1.5845 s / it)\n",
      "Averaged stats: lr: 0.000025  loss: 0.8332 (0.8535)\n",
      "Valid: [epoch:773]  [ 0/14]  eta: 0:00:04  loss: 0.8488 (0.8488)  time: 0.3137  data: 0.2976  max mem: 20571\n",
      "Valid: [epoch:773]  [13/14]  eta: 0:00:00  loss: 0.8060 (0.8161)  time: 0.0378  data: 0.0228  max mem: 20571\n",
      "Valid: [epoch:773] Total time: 0:00:00 (0.0429 s / it)\n",
      "Averaged stats: loss: 0.8060 (0.8161)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_773_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.816%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:774]  [  0/172]  eta: 0:07:23  lr: 0.000025  loss: 0.7639 (0.7639)  time: 2.5767  data: 1.0075  max mem: 20571\n",
      "Train: [epoch:774]  [ 10/172]  eta: 0:04:30  lr: 0.000025  loss: 0.8492 (0.8417)  time: 1.6670  data: 0.0917  max mem: 20571\n",
      "Train: [epoch:774]  [ 20/172]  eta: 0:04:07  lr: 0.000025  loss: 0.8474 (0.8419)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [ 30/172]  eta: 0:03:48  lr: 0.000025  loss: 0.8594 (0.8496)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [ 40/172]  eta: 0:03:31  lr: 0.000025  loss: 0.8594 (0.8507)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [ 50/172]  eta: 0:03:14  lr: 0.000025  loss: 0.8382 (0.8486)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [ 60/172]  eta: 0:02:58  lr: 0.000025  loss: 0.8444 (0.8518)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [ 70/172]  eta: 0:02:42  lr: 0.000025  loss: 0.8451 (0.8527)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [ 80/172]  eta: 0:02:26  lr: 0.000025  loss: 0.8594 (0.8559)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [ 90/172]  eta: 0:02:10  lr: 0.000025  loss: 0.8594 (0.8543)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [100/172]  eta: 0:01:54  lr: 0.000025  loss: 0.8491 (0.8553)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [110/172]  eta: 0:01:38  lr: 0.000025  loss: 0.8584 (0.8557)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [120/172]  eta: 0:01:22  lr: 0.000025  loss: 0.8584 (0.8573)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [130/172]  eta: 0:01:06  lr: 0.000025  loss: 0.8549 (0.8569)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:774]  [140/172]  eta: 0:00:50  lr: 0.000025  loss: 0.8450 (0.8575)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [150/172]  eta: 0:00:34  lr: 0.000025  loss: 0.8527 (0.8576)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [160/172]  eta: 0:00:19  lr: 0.000025  loss: 0.8440 (0.8570)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [170/172]  eta: 0:00:03  lr: 0.000025  loss: 0.8376 (0.8565)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774]  [171/172]  eta: 0:00:01  lr: 0.000025  loss: 0.8440 (0.8569)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:774] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000025  loss: 0.8440 (0.8569)\n",
      "Valid: [epoch:774]  [ 0/14]  eta: 0:00:06  loss: 0.8476 (0.8476)  time: 0.4602  data: 0.4430  max mem: 20571\n",
      "Valid: [epoch:774]  [13/14]  eta: 0:00:00  loss: 0.8064 (0.8160)  time: 0.0477  data: 0.0324  max mem: 20571\n",
      "Valid: [epoch:774] Total time: 0:00:00 (0.0545 s / it)\n",
      "Averaged stats: loss: 0.8064 (0.8160)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_774_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.816%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:775]  [  0/172]  eta: 0:07:35  lr: 0.000025  loss: 0.7495 (0.7495)  time: 2.6477  data: 1.0684  max mem: 20571\n",
      "Train: [epoch:775]  [ 10/172]  eta: 0:04:30  lr: 0.000025  loss: 0.8599 (0.8546)  time: 1.6725  data: 0.0973  max mem: 20571\n",
      "Train: [epoch:775]  [ 20/172]  eta: 0:04:07  lr: 0.000025  loss: 0.8294 (0.8436)  time: 1.5753  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:775]  [ 30/172]  eta: 0:03:48  lr: 0.000025  loss: 0.8242 (0.8459)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [ 40/172]  eta: 0:03:31  lr: 0.000025  loss: 0.8629 (0.8492)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [ 50/172]  eta: 0:03:14  lr: 0.000025  loss: 0.8629 (0.8514)  time: 1.5780  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:775]  [ 60/172]  eta: 0:02:58  lr: 0.000025  loss: 0.8508 (0.8494)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [ 70/172]  eta: 0:02:42  lr: 0.000025  loss: 0.8508 (0.8528)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [ 80/172]  eta: 0:02:26  lr: 0.000025  loss: 0.8635 (0.8549)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [ 90/172]  eta: 0:02:10  lr: 0.000025  loss: 0.8645 (0.8561)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [100/172]  eta: 0:01:54  lr: 0.000025  loss: 0.8645 (0.8580)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [110/172]  eta: 0:01:38  lr: 0.000025  loss: 0.8452 (0.8576)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [120/172]  eta: 0:01:22  lr: 0.000025  loss: 0.8811 (0.8603)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [130/172]  eta: 0:01:06  lr: 0.000025  loss: 0.8579 (0.8582)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [140/172]  eta: 0:00:50  lr: 0.000025  loss: 0.8465 (0.8581)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [150/172]  eta: 0:00:34  lr: 0.000025  loss: 0.8465 (0.8570)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [160/172]  eta: 0:00:19  lr: 0.000025  loss: 0.8396 (0.8570)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [170/172]  eta: 0:00:03  lr: 0.000025  loss: 0.8558 (0.8571)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775]  [171/172]  eta: 0:00:01  lr: 0.000025  loss: 0.8558 (0.8574)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:775] Total time: 0:04:32 (1.5839 s / it)\n",
      "Averaged stats: lr: 0.000025  loss: 0.8558 (0.8574)\n",
      "Valid: [epoch:775]  [ 0/14]  eta: 0:00:07  loss: 0.8593 (0.8593)  time: 0.5246  data: 0.5095  max mem: 20571\n",
      "Valid: [epoch:775]  [13/14]  eta: 0:00:00  loss: 0.8065 (0.8166)  time: 0.0522  data: 0.0371  max mem: 20571\n",
      "Valid: [epoch:775] Total time: 0:00:00 (0.0599 s / it)\n",
      "Averaged stats: loss: 0.8065 (0.8166)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_775_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.817%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:776]  [  0/172]  eta: 0:07:36  lr: 0.000025  loss: 0.9024 (0.9024)  time: 2.6524  data: 1.0732  max mem: 20571\n",
      "Train: [epoch:776]  [ 10/172]  eta: 0:04:31  lr: 0.000025  loss: 0.8471 (0.8420)  time: 1.6766  data: 0.0977  max mem: 20571\n",
      "Train: [epoch:776]  [ 20/172]  eta: 0:04:07  lr: 0.000025  loss: 0.8448 (0.8477)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [ 30/172]  eta: 0:03:48  lr: 0.000025  loss: 0.8519 (0.8510)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [ 40/172]  eta: 0:03:31  lr: 0.000025  loss: 0.8419 (0.8504)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [ 50/172]  eta: 0:03:15  lr: 0.000025  loss: 0.8419 (0.8529)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [ 60/172]  eta: 0:02:58  lr: 0.000025  loss: 0.8506 (0.8542)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [ 70/172]  eta: 0:02:42  lr: 0.000025  loss: 0.8637 (0.8550)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [ 80/172]  eta: 0:02:26  lr: 0.000025  loss: 0.8587 (0.8565)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [ 90/172]  eta: 0:02:10  lr: 0.000025  loss: 0.8587 (0.8578)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [100/172]  eta: 0:01:54  lr: 0.000025  loss: 0.8530 (0.8569)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [110/172]  eta: 0:01:38  lr: 0.000025  loss: 0.8510 (0.8566)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [120/172]  eta: 0:01:22  lr: 0.000025  loss: 0.8691 (0.8582)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [130/172]  eta: 0:01:06  lr: 0.000025  loss: 0.8514 (0.8569)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [140/172]  eta: 0:00:50  lr: 0.000025  loss: 0.8305 (0.8551)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [150/172]  eta: 0:00:34  lr: 0.000025  loss: 0.8305 (0.8556)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [160/172]  eta: 0:00:19  lr: 0.000025  loss: 0.8414 (0.8548)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [170/172]  eta: 0:00:03  lr: 0.000025  loss: 0.8533 (0.8552)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776]  [171/172]  eta: 0:00:01  lr: 0.000025  loss: 0.8499 (0.8551)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:776] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000025  loss: 0.8499 (0.8551)\n",
      "Valid: [epoch:776]  [ 0/14]  eta: 0:00:04  loss: 0.8624 (0.8624)  time: 0.2934  data: 0.2784  max mem: 20571\n",
      "Valid: [epoch:776]  [13/14]  eta: 0:00:00  loss: 0.8139 (0.8240)  time: 0.0436  data: 0.0284  max mem: 20571\n",
      "Valid: [epoch:776] Total time: 0:00:00 (0.0514 s / it)\n",
      "Averaged stats: loss: 0.8139 (0.8240)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_776_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.824%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:777]  [  0/172]  eta: 0:07:38  lr: 0.000025  loss: 0.8611 (0.8611)  time: 2.6654  data: 1.0773  max mem: 20571\n",
      "Train: [epoch:777]  [ 10/172]  eta: 0:04:31  lr: 0.000025  loss: 0.8640 (0.8637)  time: 1.6761  data: 0.0981  max mem: 20571\n",
      "Train: [epoch:777]  [ 20/172]  eta: 0:04:07  lr: 0.000025  loss: 0.8548 (0.8556)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:777]  [ 30/172]  eta: 0:03:49  lr: 0.000025  loss: 0.8548 (0.8637)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:777]  [ 40/172]  eta: 0:03:31  lr: 0.000025  loss: 0.8388 (0.8566)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [ 50/172]  eta: 0:03:15  lr: 0.000025  loss: 0.8341 (0.8571)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [ 60/172]  eta: 0:02:58  lr: 0.000025  loss: 0.8311 (0.8539)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [ 70/172]  eta: 0:02:42  lr: 0.000025  loss: 0.8365 (0.8553)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [ 80/172]  eta: 0:02:26  lr: 0.000025  loss: 0.8510 (0.8540)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [ 90/172]  eta: 0:02:10  lr: 0.000025  loss: 0.8325 (0.8512)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [100/172]  eta: 0:01:54  lr: 0.000025  loss: 0.8176 (0.8519)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [110/172]  eta: 0:01:38  lr: 0.000025  loss: 0.8452 (0.8513)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [120/172]  eta: 0:01:22  lr: 0.000025  loss: 0.8646 (0.8540)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [130/172]  eta: 0:01:06  lr: 0.000025  loss: 0.8757 (0.8571)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [140/172]  eta: 0:00:50  lr: 0.000025  loss: 0.8673 (0.8563)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [150/172]  eta: 0:00:34  lr: 0.000025  loss: 0.8492 (0.8572)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [160/172]  eta: 0:00:19  lr: 0.000025  loss: 0.8492 (0.8557)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [170/172]  eta: 0:00:03  lr: 0.000025  loss: 0.8437 (0.8557)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777]  [171/172]  eta: 0:00:01  lr: 0.000025  loss: 0.8437 (0.8564)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:777] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000025  loss: 0.8437 (0.8564)\n",
      "Valid: [epoch:777]  [ 0/14]  eta: 0:00:04  loss: 0.8583 (0.8583)  time: 0.3385  data: 0.3213  max mem: 20571\n",
      "Valid: [epoch:777]  [13/14]  eta: 0:00:00  loss: 0.8084 (0.8191)  time: 0.0392  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:777] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.8084 (0.8191)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_777_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.819%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:778]  [  0/172]  eta: 0:08:21  lr: 0.000025  loss: 0.8659 (0.8659)  time: 2.9131  data: 1.3410  max mem: 20571\n",
      "Train: [epoch:778]  [ 10/172]  eta: 0:04:35  lr: 0.000025  loss: 0.8541 (0.8554)  time: 1.6997  data: 0.1220  max mem: 20571\n",
      "Train: [epoch:778]  [ 20/172]  eta: 0:04:09  lr: 0.000025  loss: 0.8541 (0.8701)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [ 30/172]  eta: 0:03:50  lr: 0.000025  loss: 0.8353 (0.8589)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:778]  [ 40/172]  eta: 0:03:32  lr: 0.000025  loss: 0.8353 (0.8589)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:778]  [ 50/172]  eta: 0:03:16  lr: 0.000025  loss: 0.8447 (0.8566)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [ 60/172]  eta: 0:02:59  lr: 0.000025  loss: 0.8287 (0.8506)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [ 70/172]  eta: 0:02:43  lr: 0.000025  loss: 0.8373 (0.8500)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [ 80/172]  eta: 0:02:26  lr: 0.000025  loss: 0.8548 (0.8526)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [ 90/172]  eta: 0:02:10  lr: 0.000025  loss: 0.8536 (0.8549)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [100/172]  eta: 0:01:54  lr: 0.000025  loss: 0.8489 (0.8544)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [110/172]  eta: 0:01:38  lr: 0.000025  loss: 0.8489 (0.8548)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [120/172]  eta: 0:01:22  lr: 0.000025  loss: 0.8806 (0.8583)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [130/172]  eta: 0:01:06  lr: 0.000025  loss: 0.8828 (0.8578)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [140/172]  eta: 0:00:50  lr: 0.000025  loss: 0.8728 (0.8585)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [150/172]  eta: 0:00:34  lr: 0.000025  loss: 0.8758 (0.8597)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [160/172]  eta: 0:00:19  lr: 0.000025  loss: 0.8539 (0.8588)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [170/172]  eta: 0:00:03  lr: 0.000025  loss: 0.8553 (0.8591)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778]  [171/172]  eta: 0:00:01  lr: 0.000025  loss: 0.8553 (0.8602)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:778] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000025  loss: 0.8553 (0.8602)\n",
      "Valid: [epoch:778]  [ 0/14]  eta: 0:00:05  loss: 0.8527 (0.8527)  time: 0.4097  data: 0.3941  max mem: 20571\n",
      "Valid: [epoch:778]  [13/14]  eta: 0:00:00  loss: 0.8081 (0.8184)  time: 0.0435  data: 0.0285  max mem: 20571\n",
      "Valid: [epoch:778] Total time: 0:00:00 (0.0489 s / it)\n",
      "Averaged stats: loss: 0.8081 (0.8184)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_778_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.818%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:779]  [  0/172]  eta: 0:08:51  lr: 0.000025  loss: 0.9351 (0.9351)  time: 3.0911  data: 1.5191  max mem: 20571\n",
      "Train: [epoch:779]  [ 10/172]  eta: 0:04:37  lr: 0.000025  loss: 0.8572 (0.8543)  time: 1.7134  data: 0.1382  max mem: 20571\n",
      "Train: [epoch:779]  [ 20/172]  eta: 0:04:10  lr: 0.000025  loss: 0.8538 (0.8540)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [ 30/172]  eta: 0:03:50  lr: 0.000025  loss: 0.8511 (0.8507)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [ 40/172]  eta: 0:03:33  lr: 0.000025  loss: 0.8592 (0.8560)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [ 50/172]  eta: 0:03:16  lr: 0.000025  loss: 0.8685 (0.8578)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [ 60/172]  eta: 0:02:59  lr: 0.000025  loss: 0.8534 (0.8584)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:779]  [ 70/172]  eta: 0:02:43  lr: 0.000025  loss: 0.8584 (0.8571)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:779]  [ 80/172]  eta: 0:02:27  lr: 0.000025  loss: 0.8526 (0.8572)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [ 90/172]  eta: 0:02:10  lr: 0.000025  loss: 0.8523 (0.8554)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [100/172]  eta: 0:01:54  lr: 0.000025  loss: 0.8615 (0.8567)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [110/172]  eta: 0:01:38  lr: 0.000025  loss: 0.8558 (0.8558)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [120/172]  eta: 0:01:22  lr: 0.000025  loss: 0.8342 (0.8554)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [130/172]  eta: 0:01:06  lr: 0.000025  loss: 0.8342 (0.8573)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [140/172]  eta: 0:00:50  lr: 0.000025  loss: 0.8621 (0.8577)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [150/172]  eta: 0:00:34  lr: 0.000025  loss: 0.8585 (0.8591)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [160/172]  eta: 0:00:19  lr: 0.000025  loss: 0.8612 (0.8582)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [170/172]  eta: 0:00:03  lr: 0.000025  loss: 0.8610 (0.8587)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779]  [171/172]  eta: 0:00:01  lr: 0.000025  loss: 0.8610 (0.8588)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:779] Total time: 0:04:33 (1.5904 s / it)\n",
      "Averaged stats: lr: 0.000025  loss: 0.8610 (0.8588)\n",
      "Valid: [epoch:779]  [ 0/14]  eta: 0:00:05  loss: 0.8580 (0.8580)  time: 0.4058  data: 0.3847  max mem: 20571\n",
      "Valid: [epoch:779]  [13/14]  eta: 0:00:00  loss: 0.8146 (0.8245)  time: 0.0437  data: 0.0281  max mem: 20571\n",
      "Valid: [epoch:779] Total time: 0:00:00 (0.0518 s / it)\n",
      "Averaged stats: loss: 0.8146 (0.8245)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_779_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.824%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:780]  [  0/172]  eta: 0:07:14  lr: 0.000025  loss: 0.8246 (0.8246)  time: 2.5278  data: 0.9610  max mem: 20571\n",
      "Train: [epoch:780]  [ 10/172]  eta: 0:04:29  lr: 0.000025  loss: 0.8616 (0.8522)  time: 1.6661  data: 0.0875  max mem: 20571\n",
      "Train: [epoch:780]  [ 20/172]  eta: 0:04:07  lr: 0.000025  loss: 0.8700 (0.8680)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [ 30/172]  eta: 0:03:48  lr: 0.000025  loss: 0.8645 (0.8606)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [ 40/172]  eta: 0:03:31  lr: 0.000025  loss: 0.8599 (0.8641)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [ 50/172]  eta: 0:03:15  lr: 0.000025  loss: 0.8661 (0.8622)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [ 60/172]  eta: 0:02:58  lr: 0.000025  loss: 0.8447 (0.8628)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [ 70/172]  eta: 0:02:42  lr: 0.000025  loss: 0.8510 (0.8624)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [ 80/172]  eta: 0:02:26  lr: 0.000025  loss: 0.8510 (0.8610)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [ 90/172]  eta: 0:02:10  lr: 0.000025  loss: 0.8697 (0.8633)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [100/172]  eta: 0:01:54  lr: 0.000025  loss: 0.8667 (0.8629)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [110/172]  eta: 0:01:38  lr: 0.000025  loss: 0.8427 (0.8620)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [120/172]  eta: 0:01:22  lr: 0.000025  loss: 0.8300 (0.8595)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [130/172]  eta: 0:01:06  lr: 0.000025  loss: 0.8300 (0.8585)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [140/172]  eta: 0:00:50  lr: 0.000025  loss: 0.8412 (0.8571)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:780]  [150/172]  eta: 0:00:34  lr: 0.000025  loss: 0.8484 (0.8580)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [160/172]  eta: 0:00:19  lr: 0.000025  loss: 0.8538 (0.8581)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780]  [170/172]  eta: 0:00:03  lr: 0.000025  loss: 0.8560 (0.8597)  time: 1.5783  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:780]  [171/172]  eta: 0:00:01  lr: 0.000025  loss: 0.8560 (0.8595)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:780] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000025  loss: 0.8560 (0.8595)\n",
      "Valid: [epoch:780]  [ 0/14]  eta: 0:00:04  loss: 0.8175 (0.8175)  time: 0.2965  data: 0.2817  max mem: 20571\n",
      "Valid: [epoch:780]  [13/14]  eta: 0:00:00  loss: 0.8220 (0.8326)  time: 0.0382  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:780] Total time: 0:00:00 (0.0431 s / it)\n",
      "Averaged stats: loss: 0.8220 (0.8326)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_780_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.833%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:781]  [  0/172]  eta: 0:07:25  lr: 0.000024  loss: 0.9398 (0.9398)  time: 2.5921  data: 0.9921  max mem: 20571\n",
      "Train: [epoch:781]  [ 10/172]  eta: 0:04:29  lr: 0.000024  loss: 0.8766 (0.8623)  time: 1.6662  data: 0.0903  max mem: 20571\n",
      "Train: [epoch:781]  [ 20/172]  eta: 0:04:06  lr: 0.000024  loss: 0.8840 (0.8845)  time: 1.5766  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:781]  [ 30/172]  eta: 0:03:48  lr: 0.000024  loss: 0.8815 (0.8787)  time: 1.5779  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:781]  [ 40/172]  eta: 0:03:31  lr: 0.000024  loss: 0.8610 (0.8717)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [ 50/172]  eta: 0:03:14  lr: 0.000024  loss: 0.8653 (0.8686)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [ 60/172]  eta: 0:02:58  lr: 0.000024  loss: 0.8653 (0.8705)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [ 70/172]  eta: 0:02:42  lr: 0.000024  loss: 0.8666 (0.8696)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [ 80/172]  eta: 0:02:26  lr: 0.000024  loss: 0.8676 (0.8709)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [ 90/172]  eta: 0:02:10  lr: 0.000024  loss: 0.8417 (0.8669)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [100/172]  eta: 0:01:54  lr: 0.000024  loss: 0.8316 (0.8656)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [110/172]  eta: 0:01:38  lr: 0.000024  loss: 0.8497 (0.8656)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [120/172]  eta: 0:01:22  lr: 0.000024  loss: 0.8454 (0.8623)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [130/172]  eta: 0:01:06  lr: 0.000024  loss: 0.8356 (0.8615)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [140/172]  eta: 0:00:50  lr: 0.000024  loss: 0.8568 (0.8607)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [150/172]  eta: 0:00:34  lr: 0.000024  loss: 0.8629 (0.8600)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [160/172]  eta: 0:00:19  lr: 0.000024  loss: 0.8487 (0.8596)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [170/172]  eta: 0:00:03  lr: 0.000024  loss: 0.8666 (0.8603)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781]  [171/172]  eta: 0:00:01  lr: 0.000024  loss: 0.8844 (0.8612)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:781] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000024  loss: 0.8844 (0.8612)\n",
      "Valid: [epoch:781]  [ 0/14]  eta: 0:00:04  loss: 0.8618 (0.8618)  time: 0.3001  data: 0.2850  max mem: 20571\n",
      "Valid: [epoch:781]  [13/14]  eta: 0:00:00  loss: 0.8107 (0.8208)  time: 0.0376  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:781] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.8107 (0.8208)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_781_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.821%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:782]  [  0/172]  eta: 0:07:51  lr: 0.000024  loss: 0.7759 (0.7759)  time: 2.7408  data: 1.1749  max mem: 20571\n",
      "Train: [epoch:782]  [ 10/172]  eta: 0:04:32  lr: 0.000024  loss: 0.8038 (0.8267)  time: 1.6840  data: 0.1069  max mem: 20571\n",
      "Train: [epoch:782]  [ 20/172]  eta: 0:04:08  lr: 0.000024  loss: 0.8347 (0.8452)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [ 30/172]  eta: 0:03:49  lr: 0.000024  loss: 0.8391 (0.8496)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [ 40/172]  eta: 0:03:32  lr: 0.000024  loss: 0.8451 (0.8510)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [ 50/172]  eta: 0:03:15  lr: 0.000024  loss: 0.8574 (0.8568)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [ 60/172]  eta: 0:02:58  lr: 0.000024  loss: 0.8394 (0.8568)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [ 70/172]  eta: 0:02:42  lr: 0.000024  loss: 0.8394 (0.8569)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [ 80/172]  eta: 0:02:26  lr: 0.000024  loss: 0.8445 (0.8548)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [ 90/172]  eta: 0:02:10  lr: 0.000024  loss: 0.8477 (0.8582)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [100/172]  eta: 0:01:54  lr: 0.000024  loss: 0.8492 (0.8572)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [110/172]  eta: 0:01:38  lr: 0.000024  loss: 0.8523 (0.8580)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [120/172]  eta: 0:01:22  lr: 0.000024  loss: 0.8647 (0.8594)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [130/172]  eta: 0:01:06  lr: 0.000024  loss: 0.8486 (0.8576)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [140/172]  eta: 0:00:50  lr: 0.000024  loss: 0.8258 (0.8569)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [150/172]  eta: 0:00:34  lr: 0.000024  loss: 0.8531 (0.8578)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [160/172]  eta: 0:00:19  lr: 0.000024  loss: 0.8803 (0.8611)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [170/172]  eta: 0:00:03  lr: 0.000024  loss: 0.8885 (0.8630)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782]  [171/172]  eta: 0:00:01  lr: 0.000024  loss: 0.8885 (0.8630)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:782] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000024  loss: 0.8885 (0.8630)\n",
      "Valid: [epoch:782]  [ 0/14]  eta: 0:00:04  loss: 0.8597 (0.8597)  time: 0.3527  data: 0.3351  max mem: 20571\n",
      "Valid: [epoch:782]  [13/14]  eta: 0:00:00  loss: 0.8152 (0.8257)  time: 0.0403  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:782] Total time: 0:00:00 (0.0460 s / it)\n",
      "Averaged stats: loss: 0.8152 (0.8257)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_782_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.826%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:783]  [  0/172]  eta: 0:08:20  lr: 0.000024  loss: 0.8563 (0.8563)  time: 2.9084  data: 1.3126  max mem: 20571\n",
      "Train: [epoch:783]  [ 10/172]  eta: 0:04:34  lr: 0.000024  loss: 0.8279 (0.8499)  time: 1.6971  data: 0.1194  max mem: 20571\n",
      "Train: [epoch:783]  [ 20/172]  eta: 0:04:09  lr: 0.000024  loss: 0.8412 (0.8559)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [ 30/172]  eta: 0:03:50  lr: 0.000024  loss: 0.8616 (0.8608)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [ 40/172]  eta: 0:03:32  lr: 0.000024  loss: 0.8538 (0.8526)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [ 50/172]  eta: 0:03:15  lr: 0.000024  loss: 0.8586 (0.8610)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [ 60/172]  eta: 0:02:59  lr: 0.000024  loss: 0.8862 (0.8664)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [ 70/172]  eta: 0:02:42  lr: 0.000024  loss: 0.8546 (0.8640)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [ 80/172]  eta: 0:02:26  lr: 0.000024  loss: 0.8491 (0.8633)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:783]  [ 90/172]  eta: 0:02:10  lr: 0.000024  loss: 0.8516 (0.8639)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [100/172]  eta: 0:01:54  lr: 0.000024  loss: 0.8496 (0.8629)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [110/172]  eta: 0:01:38  lr: 0.000024  loss: 0.8468 (0.8631)  time: 1.5814  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:783]  [120/172]  eta: 0:01:22  lr: 0.000024  loss: 0.8468 (0.8635)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [130/172]  eta: 0:01:06  lr: 0.000024  loss: 0.8684 (0.8649)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [140/172]  eta: 0:00:50  lr: 0.000024  loss: 0.8550 (0.8647)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [150/172]  eta: 0:00:34  lr: 0.000024  loss: 0.8441 (0.8625)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [160/172]  eta: 0:00:19  lr: 0.000024  loss: 0.8347 (0.8615)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [170/172]  eta: 0:00:03  lr: 0.000024  loss: 0.8426 (0.8627)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783]  [171/172]  eta: 0:00:01  lr: 0.000024  loss: 0.8426 (0.8628)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:783] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000024  loss: 0.8426 (0.8628)\n",
      "Valid: [epoch:783]  [ 0/14]  eta: 0:00:05  loss: 0.8677 (0.8677)  time: 0.3667  data: 0.3493  max mem: 20571\n",
      "Valid: [epoch:783]  [13/14]  eta: 0:00:00  loss: 0.8185 (0.8291)  time: 0.0405  data: 0.0254  max mem: 20571\n",
      "Valid: [epoch:783] Total time: 0:00:00 (0.0450 s / it)\n",
      "Averaged stats: loss: 0.8185 (0.8291)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_783_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.829%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:784]  [  0/172]  eta: 0:07:35  lr: 0.000024  loss: 0.8360 (0.8360)  time: 2.6503  data: 1.0834  max mem: 20571\n",
      "Train: [epoch:784]  [ 10/172]  eta: 0:04:31  lr: 0.000024  loss: 0.8648 (0.8595)  time: 1.6753  data: 0.0986  max mem: 20571\n",
      "Train: [epoch:784]  [ 20/172]  eta: 0:04:07  lr: 0.000024  loss: 0.8767 (0.8742)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [ 30/172]  eta: 0:03:49  lr: 0.000024  loss: 0.8560 (0.8620)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [ 40/172]  eta: 0:03:32  lr: 0.000024  loss: 0.8460 (0.8603)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [ 50/172]  eta: 0:03:15  lr: 0.000024  loss: 0.8584 (0.8645)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [ 60/172]  eta: 0:02:58  lr: 0.000024  loss: 0.8571 (0.8657)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:784]  [ 70/172]  eta: 0:02:42  lr: 0.000024  loss: 0.8534 (0.8668)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [ 80/172]  eta: 0:02:26  lr: 0.000024  loss: 0.8457 (0.8640)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [ 90/172]  eta: 0:02:10  lr: 0.000024  loss: 0.8406 (0.8633)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [100/172]  eta: 0:01:54  lr: 0.000024  loss: 0.8524 (0.8637)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [110/172]  eta: 0:01:38  lr: 0.000024  loss: 0.8225 (0.8612)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [120/172]  eta: 0:01:22  lr: 0.000024  loss: 0.8315 (0.8624)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [130/172]  eta: 0:01:06  lr: 0.000024  loss: 0.8500 (0.8633)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [140/172]  eta: 0:00:50  lr: 0.000024  loss: 0.8435 (0.8633)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [150/172]  eta: 0:00:34  lr: 0.000024  loss: 0.8422 (0.8639)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [160/172]  eta: 0:00:19  lr: 0.000024  loss: 0.8420 (0.8634)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [170/172]  eta: 0:00:03  lr: 0.000024  loss: 0.8718 (0.8644)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784]  [171/172]  eta: 0:00:01  lr: 0.000024  loss: 0.8718 (0.8645)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:784] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000024  loss: 0.8718 (0.8645)\n",
      "Valid: [epoch:784]  [ 0/14]  eta: 0:00:04  loss: 0.8667 (0.8667)  time: 0.3544  data: 0.3389  max mem: 20571\n",
      "Valid: [epoch:784]  [13/14]  eta: 0:00:00  loss: 0.8250 (0.8360)  time: 0.0414  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:784] Total time: 0:00:00 (0.0488 s / it)\n",
      "Averaged stats: loss: 0.8250 (0.8360)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_784_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.836%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:785]  [  0/172]  eta: 0:07:54  lr: 0.000024  loss: 0.8904 (0.8904)  time: 2.7594  data: 1.1701  max mem: 20571\n",
      "Train: [epoch:785]  [ 10/172]  eta: 0:04:32  lr: 0.000024  loss: 0.8692 (0.8648)  time: 1.6850  data: 0.1065  max mem: 20571\n",
      "Train: [epoch:785]  [ 20/172]  eta: 0:04:08  lr: 0.000024  loss: 0.8701 (0.8798)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:785]  [ 30/172]  eta: 0:03:49  lr: 0.000024  loss: 0.8762 (0.8763)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:785]  [ 40/172]  eta: 0:03:32  lr: 0.000024  loss: 0.8714 (0.8704)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [ 50/172]  eta: 0:03:15  lr: 0.000024  loss: 0.8485 (0.8701)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [ 60/172]  eta: 0:02:59  lr: 0.000024  loss: 0.8484 (0.8691)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [ 70/172]  eta: 0:02:42  lr: 0.000024  loss: 0.8540 (0.8678)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [ 80/172]  eta: 0:02:26  lr: 0.000024  loss: 0.8440 (0.8668)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [ 90/172]  eta: 0:02:10  lr: 0.000024  loss: 0.8615 (0.8677)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [100/172]  eta: 0:01:54  lr: 0.000024  loss: 0.8687 (0.8672)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [110/172]  eta: 0:01:38  lr: 0.000024  loss: 0.8491 (0.8658)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [120/172]  eta: 0:01:22  lr: 0.000024  loss: 0.8462 (0.8663)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [130/172]  eta: 0:01:06  lr: 0.000024  loss: 0.8588 (0.8678)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [140/172]  eta: 0:00:50  lr: 0.000024  loss: 0.8491 (0.8662)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [150/172]  eta: 0:00:34  lr: 0.000024  loss: 0.8516 (0.8668)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [160/172]  eta: 0:00:19  lr: 0.000024  loss: 0.8382 (0.8654)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [170/172]  eta: 0:00:03  lr: 0.000024  loss: 0.8382 (0.8653)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785]  [171/172]  eta: 0:00:01  lr: 0.000024  loss: 0.8382 (0.8651)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:785] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000024  loss: 0.8382 (0.8651)\n",
      "Valid: [epoch:785]  [ 0/14]  eta: 0:00:04  loss: 0.8577 (0.8577)  time: 0.3263  data: 0.3097  max mem: 20571\n",
      "Valid: [epoch:785]  [13/14]  eta: 0:00:00  loss: 0.8151 (0.8263)  time: 0.0374  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:785] Total time: 0:00:00 (0.0432 s / it)\n",
      "Averaged stats: loss: 0.8151 (0.8263)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_785_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.826%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:786]  [  0/172]  eta: 0:08:20  lr: 0.000024  loss: 0.7956 (0.7956)  time: 2.9082  data: 1.3387  max mem: 20571\n",
      "Train: [epoch:786]  [ 10/172]  eta: 0:04:35  lr: 0.000024  loss: 0.8460 (0.8602)  time: 1.6996  data: 0.1218  max mem: 20571\n",
      "Train: [epoch:786]  [ 20/172]  eta: 0:04:09  lr: 0.000024  loss: 0.8684 (0.8745)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:786]  [ 30/172]  eta: 0:03:50  lr: 0.000024  loss: 0.8501 (0.8684)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:786]  [ 40/172]  eta: 0:03:32  lr: 0.000024  loss: 0.8484 (0.8659)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [ 50/172]  eta: 0:03:15  lr: 0.000024  loss: 0.8484 (0.8647)  time: 1.5800  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:786]  [ 60/172]  eta: 0:02:59  lr: 0.000024  loss: 0.8516 (0.8637)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [ 70/172]  eta: 0:02:43  lr: 0.000024  loss: 0.8604 (0.8616)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [ 80/172]  eta: 0:02:26  lr: 0.000024  loss: 0.8588 (0.8614)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [ 90/172]  eta: 0:02:10  lr: 0.000024  loss: 0.8484 (0.8609)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [100/172]  eta: 0:01:54  lr: 0.000024  loss: 0.8400 (0.8597)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [110/172]  eta: 0:01:38  lr: 0.000024  loss: 0.8410 (0.8602)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [120/172]  eta: 0:01:22  lr: 0.000024  loss: 0.8715 (0.8633)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [130/172]  eta: 0:01:06  lr: 0.000024  loss: 0.8955 (0.8657)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [140/172]  eta: 0:00:50  lr: 0.000024  loss: 0.8768 (0.8657)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [150/172]  eta: 0:00:34  lr: 0.000024  loss: 0.8488 (0.8653)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [160/172]  eta: 0:00:19  lr: 0.000024  loss: 0.8416 (0.8647)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [170/172]  eta: 0:00:03  lr: 0.000024  loss: 0.8627 (0.8660)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786]  [171/172]  eta: 0:00:01  lr: 0.000024  loss: 0.8627 (0.8661)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:786] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000024  loss: 0.8627 (0.8661)\n",
      "Valid: [epoch:786]  [ 0/14]  eta: 0:00:04  loss: 0.8153 (0.8153)  time: 0.3549  data: 0.3389  max mem: 20571\n",
      "Valid: [epoch:786]  [13/14]  eta: 0:00:00  loss: 0.8153 (0.8268)  time: 0.0395  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:786] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.8153 (0.8268)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_786_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.827%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:787]  [  0/172]  eta: 0:07:52  lr: 0.000024  loss: 0.8119 (0.8119)  time: 2.7463  data: 1.1698  max mem: 20571\n",
      "Train: [epoch:787]  [ 10/172]  eta: 0:04:32  lr: 0.000024  loss: 0.8715 (0.8790)  time: 1.6818  data: 0.1064  max mem: 20571\n",
      "Train: [epoch:787]  [ 20/172]  eta: 0:04:08  lr: 0.000024  loss: 0.8715 (0.8892)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [ 30/172]  eta: 0:03:49  lr: 0.000024  loss: 0.8616 (0.8767)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [ 40/172]  eta: 0:03:32  lr: 0.000024  loss: 0.8545 (0.8766)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [ 50/172]  eta: 0:03:15  lr: 0.000024  loss: 0.8691 (0.8805)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [ 60/172]  eta: 0:02:58  lr: 0.000024  loss: 0.8924 (0.8842)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [ 70/172]  eta: 0:02:42  lr: 0.000024  loss: 0.8734 (0.8811)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [ 80/172]  eta: 0:02:26  lr: 0.000024  loss: 0.8631 (0.8787)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [ 90/172]  eta: 0:02:10  lr: 0.000024  loss: 0.8696 (0.8796)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [100/172]  eta: 0:01:54  lr: 0.000024  loss: 0.8714 (0.8772)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [110/172]  eta: 0:01:38  lr: 0.000024  loss: 0.8415 (0.8744)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [120/172]  eta: 0:01:22  lr: 0.000024  loss: 0.8474 (0.8723)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [130/172]  eta: 0:01:06  lr: 0.000024  loss: 0.8569 (0.8723)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [140/172]  eta: 0:00:50  lr: 0.000024  loss: 0.8544 (0.8706)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [150/172]  eta: 0:00:34  lr: 0.000024  loss: 0.8467 (0.8694)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [160/172]  eta: 0:00:19  lr: 0.000024  loss: 0.8407 (0.8672)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [170/172]  eta: 0:00:03  lr: 0.000024  loss: 0.8463 (0.8674)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787]  [171/172]  eta: 0:00:01  lr: 0.000024  loss: 0.8463 (0.8682)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:787] Total time: 0:04:33 (1.5873 s / it)\n",
      "Averaged stats: lr: 0.000024  loss: 0.8463 (0.8682)\n",
      "Valid: [epoch:787]  [ 0/14]  eta: 0:00:03  loss: 0.8032 (0.8032)  time: 0.2727  data: 0.2572  max mem: 20571\n",
      "Valid: [epoch:787]  [13/14]  eta: 0:00:00  loss: 0.8201 (0.8307)  time: 0.0360  data: 0.0210  max mem: 20571\n",
      "Valid: [epoch:787] Total time: 0:00:00 (0.0415 s / it)\n",
      "Averaged stats: loss: 0.8201 (0.8307)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_787_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.831%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:788]  [  0/172]  eta: 0:07:56  lr: 0.000024  loss: 0.7923 (0.7923)  time: 2.7680  data: 1.1877  max mem: 20571\n",
      "Train: [epoch:788]  [ 10/172]  eta: 0:04:32  lr: 0.000024  loss: 0.8907 (0.8724)  time: 1.6845  data: 0.1081  max mem: 20571\n",
      "Train: [epoch:788]  [ 20/172]  eta: 0:04:08  lr: 0.000024  loss: 0.8726 (0.8707)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [ 30/172]  eta: 0:03:49  lr: 0.000024  loss: 0.8631 (0.8706)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [ 40/172]  eta: 0:03:32  lr: 0.000024  loss: 0.8450 (0.8582)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [ 50/172]  eta: 0:03:15  lr: 0.000024  loss: 0.8407 (0.8596)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [ 60/172]  eta: 0:02:59  lr: 0.000024  loss: 0.8595 (0.8618)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [ 70/172]  eta: 0:02:42  lr: 0.000024  loss: 0.8606 (0.8606)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:788]  [ 80/172]  eta: 0:02:26  lr: 0.000024  loss: 0.8864 (0.8652)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [ 90/172]  eta: 0:02:10  lr: 0.000024  loss: 0.8864 (0.8646)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [100/172]  eta: 0:01:54  lr: 0.000024  loss: 0.8665 (0.8658)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [110/172]  eta: 0:01:38  lr: 0.000024  loss: 0.8664 (0.8648)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [120/172]  eta: 0:01:22  lr: 0.000024  loss: 0.8532 (0.8640)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [130/172]  eta: 0:01:06  lr: 0.000024  loss: 0.8446 (0.8638)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [140/172]  eta: 0:00:50  lr: 0.000024  loss: 0.8565 (0.8634)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [150/172]  eta: 0:00:34  lr: 0.000024  loss: 0.8645 (0.8655)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [160/172]  eta: 0:00:19  lr: 0.000024  loss: 0.8823 (0.8666)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [170/172]  eta: 0:00:03  lr: 0.000024  loss: 0.8714 (0.8674)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788]  [171/172]  eta: 0:00:01  lr: 0.000024  loss: 0.8714 (0.8675)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:788] Total time: 0:04:32 (1.5870 s / it)\n",
      "Averaged stats: lr: 0.000024  loss: 0.8714 (0.8675)\n",
      "Valid: [epoch:788]  [ 0/14]  eta: 0:00:03  loss: 0.8640 (0.8640)  time: 0.2811  data: 0.2646  max mem: 20571\n",
      "Valid: [epoch:788]  [13/14]  eta: 0:00:00  loss: 0.8221 (0.8326)  time: 0.0404  data: 0.0251  max mem: 20571\n",
      "Valid: [epoch:788] Total time: 0:00:00 (0.0451 s / it)\n",
      "Averaged stats: loss: 0.8221 (0.8326)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_788_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.833%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:789]  [  0/172]  eta: 0:07:17  lr: 0.000024  loss: 0.8262 (0.8262)  time: 2.5456  data: 0.9516  max mem: 20571\n",
      "Train: [epoch:789]  [ 10/172]  eta: 0:04:29  lr: 0.000024  loss: 0.8805 (0.8697)  time: 1.6649  data: 0.0866  max mem: 20571\n",
      "Train: [epoch:789]  [ 20/172]  eta: 0:04:06  lr: 0.000024  loss: 0.8833 (0.8763)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:789]  [ 30/172]  eta: 0:03:48  lr: 0.000024  loss: 0.8725 (0.8722)  time: 1.5787  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:789]  [ 40/172]  eta: 0:03:31  lr: 0.000024  loss: 0.8502 (0.8676)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [ 50/172]  eta: 0:03:14  lr: 0.000024  loss: 0.8450 (0.8672)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [ 60/172]  eta: 0:02:58  lr: 0.000024  loss: 0.8472 (0.8668)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [ 70/172]  eta: 0:02:42  lr: 0.000024  loss: 0.8535 (0.8667)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [ 80/172]  eta: 0:02:26  lr: 0.000024  loss: 0.8535 (0.8642)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [ 90/172]  eta: 0:02:10  lr: 0.000024  loss: 0.8345 (0.8642)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [100/172]  eta: 0:01:54  lr: 0.000024  loss: 0.8666 (0.8667)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [110/172]  eta: 0:01:38  lr: 0.000024  loss: 0.8768 (0.8681)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [120/172]  eta: 0:01:22  lr: 0.000024  loss: 0.9046 (0.8709)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [130/172]  eta: 0:01:06  lr: 0.000024  loss: 0.8685 (0.8686)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [140/172]  eta: 0:00:50  lr: 0.000024  loss: 0.8557 (0.8705)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [150/172]  eta: 0:00:34  lr: 0.000024  loss: 0.8770 (0.8701)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [160/172]  eta: 0:00:19  lr: 0.000024  loss: 0.8451 (0.8689)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [170/172]  eta: 0:00:03  lr: 0.000024  loss: 0.8451 (0.8687)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789]  [171/172]  eta: 0:00:01  lr: 0.000024  loss: 0.8451 (0.8686)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:789] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000024  loss: 0.8451 (0.8686)\n",
      "Valid: [epoch:789]  [ 0/14]  eta: 0:00:04  loss: 0.8638 (0.8638)  time: 0.3181  data: 0.3032  max mem: 20571\n",
      "Valid: [epoch:789]  [13/14]  eta: 0:00:00  loss: 0.8194 (0.8299)  time: 0.0389  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:789] Total time: 0:00:00 (0.0437 s / it)\n",
      "Averaged stats: loss: 0.8194 (0.8299)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_789_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.830%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:790]  [  0/172]  eta: 0:07:43  lr: 0.000023  loss: 0.8290 (0.8290)  time: 2.6932  data: 1.1262  max mem: 20571\n",
      "Train: [epoch:790]  [ 10/172]  eta: 0:04:32  lr: 0.000023  loss: 0.8335 (0.8430)  time: 1.6794  data: 0.1025  max mem: 20571\n",
      "Train: [epoch:790]  [ 20/172]  eta: 0:04:07  lr: 0.000023  loss: 0.8562 (0.8501)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [ 30/172]  eta: 0:03:49  lr: 0.000023  loss: 0.8678 (0.8613)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [ 40/172]  eta: 0:03:31  lr: 0.000023  loss: 0.8451 (0.8587)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [ 50/172]  eta: 0:03:15  lr: 0.000023  loss: 0.8451 (0.8620)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [ 60/172]  eta: 0:02:58  lr: 0.000023  loss: 0.8649 (0.8679)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [ 70/172]  eta: 0:02:42  lr: 0.000023  loss: 0.8590 (0.8663)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [ 80/172]  eta: 0:02:26  lr: 0.000023  loss: 0.8590 (0.8656)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [ 90/172]  eta: 0:02:10  lr: 0.000023  loss: 0.8744 (0.8669)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [100/172]  eta: 0:01:54  lr: 0.000023  loss: 0.8667 (0.8667)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [110/172]  eta: 0:01:38  lr: 0.000023  loss: 0.8624 (0.8653)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:790]  [120/172]  eta: 0:01:22  lr: 0.000023  loss: 0.8784 (0.8683)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [130/172]  eta: 0:01:06  lr: 0.000023  loss: 0.8968 (0.8706)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [140/172]  eta: 0:00:50  lr: 0.000023  loss: 0.8506 (0.8676)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [150/172]  eta: 0:00:34  lr: 0.000023  loss: 0.8434 (0.8678)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [160/172]  eta: 0:00:19  lr: 0.000023  loss: 0.8645 (0.8677)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [170/172]  eta: 0:00:03  lr: 0.000023  loss: 0.8645 (0.8688)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790]  [171/172]  eta: 0:00:01  lr: 0.000023  loss: 0.8645 (0.8689)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:790] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000023  loss: 0.8645 (0.8689)\n",
      "Valid: [epoch:790]  [ 0/14]  eta: 0:00:03  loss: 0.8617 (0.8617)  time: 0.2824  data: 0.2663  max mem: 20571\n",
      "Valid: [epoch:790]  [13/14]  eta: 0:00:00  loss: 0.8195 (0.8306)  time: 0.0372  data: 0.0220  max mem: 20571\n",
      "Valid: [epoch:790] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.8195 (0.8306)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_790_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.831%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:791]  [  0/172]  eta: 0:07:33  lr: 0.000023  loss: 0.8502 (0.8502)  time: 2.6383  data: 1.0606  max mem: 20571\n",
      "Train: [epoch:791]  [ 10/172]  eta: 0:04:31  lr: 0.000023  loss: 0.8588 (0.8545)  time: 1.6732  data: 0.0965  max mem: 20571\n",
      "Train: [epoch:791]  [ 20/172]  eta: 0:04:07  lr: 0.000023  loss: 0.8731 (0.8640)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [ 30/172]  eta: 0:03:49  lr: 0.000023  loss: 0.8749 (0.8671)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [ 40/172]  eta: 0:03:31  lr: 0.000023  loss: 0.8826 (0.8759)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [ 50/172]  eta: 0:03:15  lr: 0.000023  loss: 0.8767 (0.8735)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [ 60/172]  eta: 0:02:58  lr: 0.000023  loss: 0.8608 (0.8722)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [ 70/172]  eta: 0:02:42  lr: 0.000023  loss: 0.8608 (0.8732)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [ 80/172]  eta: 0:02:26  lr: 0.000023  loss: 0.8538 (0.8726)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [ 90/172]  eta: 0:02:10  lr: 0.000023  loss: 0.8572 (0.8727)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [100/172]  eta: 0:01:54  lr: 0.000023  loss: 0.8690 (0.8728)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [110/172]  eta: 0:01:38  lr: 0.000023  loss: 0.8666 (0.8714)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [120/172]  eta: 0:01:22  lr: 0.000023  loss: 0.8476 (0.8710)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [130/172]  eta: 0:01:06  lr: 0.000023  loss: 0.8838 (0.8736)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [140/172]  eta: 0:00:50  lr: 0.000023  loss: 0.8838 (0.8730)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [150/172]  eta: 0:00:34  lr: 0.000023  loss: 0.8537 (0.8722)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [160/172]  eta: 0:00:19  lr: 0.000023  loss: 0.8537 (0.8717)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791]  [170/172]  eta: 0:00:03  lr: 0.000023  loss: 0.8650 (0.8712)  time: 1.5800  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:791]  [171/172]  eta: 0:00:01  lr: 0.000023  loss: 0.8650 (0.8709)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:791] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000023  loss: 0.8650 (0.8709)\n",
      "Valid: [epoch:791]  [ 0/14]  eta: 0:00:04  loss: 0.8662 (0.8662)  time: 0.3477  data: 0.3324  max mem: 20571\n",
      "Valid: [epoch:791]  [13/14]  eta: 0:00:00  loss: 0.8202 (0.8316)  time: 0.0401  data: 0.0251  max mem: 20571\n",
      "Valid: [epoch:791] Total time: 0:00:00 (0.0483 s / it)\n",
      "Averaged stats: loss: 0.8202 (0.8316)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_791_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.832%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:792]  [  0/172]  eta: 0:07:20  lr: 0.000023  loss: 0.9406 (0.9406)  time: 2.5632  data: 0.9890  max mem: 20571\n",
      "Train: [epoch:792]  [ 10/172]  eta: 0:04:30  lr: 0.000023  loss: 0.8446 (0.8598)  time: 1.6667  data: 0.0900  max mem: 20571\n",
      "Train: [epoch:792]  [ 20/172]  eta: 0:04:07  lr: 0.000023  loss: 0.8478 (0.8657)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [ 30/172]  eta: 0:03:48  lr: 0.000023  loss: 0.8763 (0.8662)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [ 40/172]  eta: 0:03:31  lr: 0.000023  loss: 0.8741 (0.8688)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [ 50/172]  eta: 0:03:14  lr: 0.000023  loss: 0.8916 (0.8752)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [ 60/172]  eta: 0:02:58  lr: 0.000023  loss: 0.8857 (0.8724)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [ 70/172]  eta: 0:02:42  lr: 0.000023  loss: 0.8542 (0.8750)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [ 80/172]  eta: 0:02:26  lr: 0.000023  loss: 0.8756 (0.8737)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [ 90/172]  eta: 0:02:10  lr: 0.000023  loss: 0.8712 (0.8741)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [100/172]  eta: 0:01:54  lr: 0.000023  loss: 0.8636 (0.8752)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [110/172]  eta: 0:01:38  lr: 0.000023  loss: 0.8636 (0.8745)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [120/172]  eta: 0:01:22  lr: 0.000023  loss: 0.8550 (0.8729)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [130/172]  eta: 0:01:06  lr: 0.000023  loss: 0.8439 (0.8726)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [140/172]  eta: 0:00:50  lr: 0.000023  loss: 0.8498 (0.8731)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [150/172]  eta: 0:00:34  lr: 0.000023  loss: 0.8588 (0.8719)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [160/172]  eta: 0:00:19  lr: 0.000023  loss: 0.8603 (0.8725)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [170/172]  eta: 0:00:03  lr: 0.000023  loss: 0.8553 (0.8712)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792]  [171/172]  eta: 0:00:01  lr: 0.000023  loss: 0.8553 (0.8719)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:792] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000023  loss: 0.8553 (0.8719)\n",
      "Valid: [epoch:792]  [ 0/14]  eta: 0:00:05  loss: 0.7395 (0.7395)  time: 0.3918  data: 0.3745  max mem: 20571\n",
      "Valid: [epoch:792]  [13/14]  eta: 0:00:00  loss: 0.8200 (0.8316)  time: 0.0422  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:792] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.8200 (0.8316)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_792_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.832%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:793]  [  0/172]  eta: 0:07:54  lr: 0.000023  loss: 0.7979 (0.7979)  time: 2.7594  data: 1.1797  max mem: 20571\n",
      "Train: [epoch:793]  [ 10/172]  eta: 0:04:32  lr: 0.000023  loss: 0.8466 (0.8659)  time: 1.6832  data: 0.1074  max mem: 20571\n",
      "Train: [epoch:793]  [ 20/172]  eta: 0:04:08  lr: 0.000023  loss: 0.8469 (0.8688)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [ 30/172]  eta: 0:03:49  lr: 0.000023  loss: 0.8737 (0.8748)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [ 40/172]  eta: 0:03:32  lr: 0.000023  loss: 0.8795 (0.8738)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [ 50/172]  eta: 0:03:15  lr: 0.000023  loss: 0.8651 (0.8722)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [ 60/172]  eta: 0:02:58  lr: 0.000023  loss: 0.8671 (0.8740)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [ 70/172]  eta: 0:02:42  lr: 0.000023  loss: 0.8671 (0.8725)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [ 80/172]  eta: 0:02:26  lr: 0.000023  loss: 0.8574 (0.8726)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [ 90/172]  eta: 0:02:10  lr: 0.000023  loss: 0.8483 (0.8701)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [100/172]  eta: 0:01:54  lr: 0.000023  loss: 0.8483 (0.8693)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [110/172]  eta: 0:01:38  lr: 0.000023  loss: 0.8692 (0.8712)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [120/172]  eta: 0:01:22  lr: 0.000023  loss: 0.8741 (0.8714)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [130/172]  eta: 0:01:06  lr: 0.000023  loss: 0.8817 (0.8728)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [140/172]  eta: 0:00:50  lr: 0.000023  loss: 0.8571 (0.8718)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [150/172]  eta: 0:00:34  lr: 0.000023  loss: 0.8777 (0.8736)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [160/172]  eta: 0:00:19  lr: 0.000023  loss: 0.8812 (0.8742)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [170/172]  eta: 0:00:03  lr: 0.000023  loss: 0.8751 (0.8743)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793]  [171/172]  eta: 0:00:01  lr: 0.000023  loss: 0.8751 (0.8742)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:793] Total time: 0:04:33 (1.5883 s / it)\n",
      "Averaged stats: lr: 0.000023  loss: 0.8751 (0.8742)\n",
      "Valid: [epoch:793]  [ 0/14]  eta: 0:00:04  loss: 0.8660 (0.8660)  time: 0.2883  data: 0.2718  max mem: 20571\n",
      "Valid: [epoch:793]  [13/14]  eta: 0:00:00  loss: 0.8243 (0.8355)  time: 0.0422  data: 0.0271  max mem: 20571\n",
      "Valid: [epoch:793] Total time: 0:00:00 (0.0496 s / it)\n",
      "Averaged stats: loss: 0.8243 (0.8355)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_793_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.835%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:794]  [  0/172]  eta: 0:07:29  lr: 0.000023  loss: 0.8231 (0.8231)  time: 2.6110  data: 1.0426  max mem: 20571\n",
      "Train: [epoch:794]  [ 10/172]  eta: 0:04:31  lr: 0.000023  loss: 0.8656 (0.8702)  time: 1.6758  data: 0.0949  max mem: 20571\n",
      "Train: [epoch:794]  [ 20/172]  eta: 0:04:07  lr: 0.000023  loss: 0.8656 (0.8739)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [ 30/172]  eta: 0:03:49  lr: 0.000023  loss: 0.8506 (0.8688)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [ 40/172]  eta: 0:03:32  lr: 0.000023  loss: 0.8407 (0.8652)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [ 50/172]  eta: 0:03:15  lr: 0.000023  loss: 0.8643 (0.8697)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [ 60/172]  eta: 0:02:59  lr: 0.000023  loss: 0.8754 (0.8721)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [ 70/172]  eta: 0:02:42  lr: 0.000023  loss: 0.8836 (0.8734)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [ 80/172]  eta: 0:02:26  lr: 0.000023  loss: 0.8820 (0.8725)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [ 90/172]  eta: 0:02:10  lr: 0.000023  loss: 0.8524 (0.8735)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [100/172]  eta: 0:01:54  lr: 0.000023  loss: 0.8524 (0.8734)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:794]  [110/172]  eta: 0:01:38  lr: 0.000023  loss: 0.8486 (0.8715)  time: 1.5823  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:794]  [120/172]  eta: 0:01:22  lr: 0.000023  loss: 0.8712 (0.8739)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [130/172]  eta: 0:01:06  lr: 0.000023  loss: 0.8672 (0.8726)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [140/172]  eta: 0:00:50  lr: 0.000023  loss: 0.8588 (0.8727)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [150/172]  eta: 0:00:34  lr: 0.000023  loss: 0.8652 (0.8731)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [160/172]  eta: 0:00:19  lr: 0.000023  loss: 0.8657 (0.8722)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [170/172]  eta: 0:00:03  lr: 0.000023  loss: 0.8775 (0.8739)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794]  [171/172]  eta: 0:00:01  lr: 0.000023  loss: 0.8741 (0.8735)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:794] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000023  loss: 0.8741 (0.8735)\n",
      "Valid: [epoch:794]  [ 0/14]  eta: 0:00:06  loss: 0.8720 (0.8720)  time: 0.4677  data: 0.4503  max mem: 20571\n",
      "Valid: [epoch:794]  [13/14]  eta: 0:00:00  loss: 0.8277 (0.8384)  time: 0.0480  data: 0.0327  max mem: 20571\n",
      "Valid: [epoch:794] Total time: 0:00:00 (0.0531 s / it)\n",
      "Averaged stats: loss: 0.8277 (0.8384)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_794_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.838%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:795]  [  0/172]  eta: 0:07:59  lr: 0.000023  loss: 0.8892 (0.8892)  time: 2.7869  data: 1.2105  max mem: 20571\n",
      "Train: [epoch:795]  [ 10/172]  eta: 0:04:33  lr: 0.000023  loss: 0.8970 (0.8958)  time: 1.6870  data: 0.1102  max mem: 20571\n",
      "Train: [epoch:795]  [ 20/172]  eta: 0:04:08  lr: 0.000023  loss: 0.8738 (0.8803)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [ 30/172]  eta: 0:03:49  lr: 0.000023  loss: 0.8597 (0.8782)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:795]  [ 40/172]  eta: 0:03:32  lr: 0.000023  loss: 0.8789 (0.8794)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:795]  [ 50/172]  eta: 0:03:15  lr: 0.000023  loss: 0.8789 (0.8826)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [ 60/172]  eta: 0:02:59  lr: 0.000023  loss: 0.8731 (0.8794)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [ 70/172]  eta: 0:02:42  lr: 0.000023  loss: 0.8505 (0.8756)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [ 80/172]  eta: 0:02:26  lr: 0.000023  loss: 0.8589 (0.8766)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [ 90/172]  eta: 0:02:10  lr: 0.000023  loss: 0.8882 (0.8791)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [100/172]  eta: 0:01:54  lr: 0.000023  loss: 0.8637 (0.8775)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [110/172]  eta: 0:01:38  lr: 0.000023  loss: 0.8541 (0.8772)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [120/172]  eta: 0:01:22  lr: 0.000023  loss: 0.8628 (0.8777)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [130/172]  eta: 0:01:06  lr: 0.000023  loss: 0.8604 (0.8769)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [140/172]  eta: 0:00:50  lr: 0.000023  loss: 0.8501 (0.8750)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [150/172]  eta: 0:00:34  lr: 0.000023  loss: 0.8668 (0.8764)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [160/172]  eta: 0:00:19  lr: 0.000023  loss: 0.8665 (0.8747)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [170/172]  eta: 0:00:03  lr: 0.000023  loss: 0.8534 (0.8751)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795]  [171/172]  eta: 0:00:01  lr: 0.000023  loss: 0.8534 (0.8755)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:795] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000023  loss: 0.8534 (0.8755)\n",
      "Valid: [epoch:795]  [ 0/14]  eta: 0:00:03  loss: 0.9086 (0.9086)  time: 0.2682  data: 0.2526  max mem: 20571\n",
      "Valid: [epoch:795]  [13/14]  eta: 0:00:00  loss: 0.8248 (0.8356)  time: 0.0431  data: 0.0280  max mem: 20571\n",
      "Valid: [epoch:795] Total time: 0:00:00 (0.0502 s / it)\n",
      "Averaged stats: loss: 0.8248 (0.8356)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_795_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.836%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:796]  [  0/172]  eta: 0:07:19  lr: 0.000023  loss: 1.0036 (1.0036)  time: 2.5548  data: 0.9882  max mem: 20571\n",
      "Train: [epoch:796]  [ 10/172]  eta: 0:04:30  lr: 0.000023  loss: 0.8382 (0.8657)  time: 1.6669  data: 0.0899  max mem: 20571\n",
      "Train: [epoch:796]  [ 20/172]  eta: 0:04:07  lr: 0.000023  loss: 0.8467 (0.8703)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:796]  [ 30/172]  eta: 0:03:48  lr: 0.000023  loss: 0.8680 (0.8694)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:796]  [ 40/172]  eta: 0:03:31  lr: 0.000023  loss: 0.8698 (0.8693)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:796]  [ 50/172]  eta: 0:03:15  lr: 0.000023  loss: 0.8823 (0.8685)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [ 60/172]  eta: 0:02:58  lr: 0.000023  loss: 0.8449 (0.8661)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [ 70/172]  eta: 0:02:42  lr: 0.000023  loss: 0.8577 (0.8693)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:796]  [ 80/172]  eta: 0:02:26  lr: 0.000023  loss: 0.8857 (0.8733)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:796]  [ 90/172]  eta: 0:02:10  lr: 0.000023  loss: 0.8834 (0.8711)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [100/172]  eta: 0:01:54  lr: 0.000023  loss: 0.8702 (0.8715)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:796]  [110/172]  eta: 0:01:38  lr: 0.000023  loss: 0.8582 (0.8711)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [120/172]  eta: 0:01:22  lr: 0.000023  loss: 0.8582 (0.8704)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [130/172]  eta: 0:01:06  lr: 0.000023  loss: 0.8649 (0.8721)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [140/172]  eta: 0:00:50  lr: 0.000023  loss: 0.8847 (0.8728)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [150/172]  eta: 0:00:34  lr: 0.000023  loss: 0.8666 (0.8723)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [160/172]  eta: 0:00:19  lr: 0.000023  loss: 0.8958 (0.8750)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [170/172]  eta: 0:00:03  lr: 0.000023  loss: 0.9096 (0.8768)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796]  [171/172]  eta: 0:00:01  lr: 0.000023  loss: 0.9096 (0.8771)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:796] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000023  loss: 0.9096 (0.8771)\n",
      "Valid: [epoch:796]  [ 0/14]  eta: 0:00:04  loss: 0.8238 (0.8238)  time: 0.2887  data: 0.2720  max mem: 20571\n",
      "Valid: [epoch:796]  [13/14]  eta: 0:00:00  loss: 0.8407 (0.8509)  time: 0.0378  data: 0.0226  max mem: 20571\n",
      "Valid: [epoch:796] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.8407 (0.8509)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_796_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.851%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:797]  [  0/172]  eta: 0:08:00  lr: 0.000023  loss: 0.9130 (0.9130)  time: 2.7946  data: 1.2112  max mem: 20571\n",
      "Train: [epoch:797]  [ 10/172]  eta: 0:04:33  lr: 0.000023  loss: 0.8795 (0.8789)  time: 1.6903  data: 0.1102  max mem: 20571\n",
      "Train: [epoch:797]  [ 20/172]  eta: 0:04:08  lr: 0.000023  loss: 0.8765 (0.8786)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [ 30/172]  eta: 0:03:49  lr: 0.000023  loss: 0.8658 (0.8709)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [ 40/172]  eta: 0:03:32  lr: 0.000023  loss: 0.8505 (0.8637)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [ 50/172]  eta: 0:03:15  lr: 0.000023  loss: 0.8659 (0.8725)  time: 1.5820  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:797]  [ 60/172]  eta: 0:02:59  lr: 0.000023  loss: 0.8858 (0.8755)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [ 70/172]  eta: 0:02:43  lr: 0.000023  loss: 0.8802 (0.8784)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [ 80/172]  eta: 0:02:26  lr: 0.000023  loss: 0.8802 (0.8781)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [ 90/172]  eta: 0:02:10  lr: 0.000023  loss: 0.8801 (0.8785)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [100/172]  eta: 0:01:54  lr: 0.000023  loss: 0.8662 (0.8785)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [110/172]  eta: 0:01:38  lr: 0.000023  loss: 0.8427 (0.8768)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [120/172]  eta: 0:01:22  lr: 0.000023  loss: 0.8427 (0.8761)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [130/172]  eta: 0:01:06  lr: 0.000023  loss: 0.8694 (0.8761)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [140/172]  eta: 0:00:50  lr: 0.000023  loss: 0.8568 (0.8738)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [150/172]  eta: 0:00:34  lr: 0.000023  loss: 0.8582 (0.8740)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [160/172]  eta: 0:00:19  lr: 0.000023  loss: 0.8582 (0.8738)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [170/172]  eta: 0:00:03  lr: 0.000023  loss: 0.8998 (0.8760)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797]  [171/172]  eta: 0:00:01  lr: 0.000023  loss: 0.8803 (0.8758)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:797] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000023  loss: 0.8803 (0.8758)\n",
      "Valid: [epoch:797]  [ 0/14]  eta: 0:00:04  loss: 0.7681 (0.7681)  time: 0.3150  data: 0.2997  max mem: 20571\n",
      "Valid: [epoch:797]  [13/14]  eta: 0:00:00  loss: 0.8274 (0.8381)  time: 0.0382  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:797] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.8274 (0.8381)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_797_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.838%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:798]  [  0/172]  eta: 0:07:41  lr: 0.000023  loss: 0.9210 (0.9210)  time: 2.6823  data: 1.1139  max mem: 20571\n",
      "Train: [epoch:798]  [ 10/172]  eta: 0:04:31  lr: 0.000023  loss: 0.8627 (0.8629)  time: 1.6787  data: 0.1014  max mem: 20571\n",
      "Train: [epoch:798]  [ 20/172]  eta: 0:04:07  lr: 0.000023  loss: 0.8626 (0.8626)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [ 30/172]  eta: 0:03:49  lr: 0.000023  loss: 0.8490 (0.8641)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [ 40/172]  eta: 0:03:32  lr: 0.000023  loss: 0.8490 (0.8608)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [ 50/172]  eta: 0:03:15  lr: 0.000023  loss: 0.8715 (0.8637)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [ 60/172]  eta: 0:02:58  lr: 0.000023  loss: 0.8789 (0.8662)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [ 70/172]  eta: 0:02:42  lr: 0.000023  loss: 0.8675 (0.8681)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [ 80/172]  eta: 0:02:26  lr: 0.000023  loss: 0.8573 (0.8655)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [ 90/172]  eta: 0:02:10  lr: 0.000023  loss: 0.8549 (0.8671)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [100/172]  eta: 0:01:54  lr: 0.000023  loss: 0.8821 (0.8697)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [110/172]  eta: 0:01:38  lr: 0.000023  loss: 0.8828 (0.8718)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [120/172]  eta: 0:01:22  lr: 0.000023  loss: 0.9035 (0.8749)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [130/172]  eta: 0:01:06  lr: 0.000023  loss: 0.9035 (0.8772)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [140/172]  eta: 0:00:50  lr: 0.000023  loss: 0.8800 (0.8762)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [150/172]  eta: 0:00:34  lr: 0.000023  loss: 0.8800 (0.8780)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [160/172]  eta: 0:00:19  lr: 0.000023  loss: 0.8779 (0.8762)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [170/172]  eta: 0:00:03  lr: 0.000023  loss: 0.8637 (0.8765)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798]  [171/172]  eta: 0:00:01  lr: 0.000023  loss: 0.8637 (0.8771)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:798] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000023  loss: 0.8637 (0.8771)\n",
      "Valid: [epoch:798]  [ 0/14]  eta: 0:00:04  loss: 0.8717 (0.8717)  time: 0.2977  data: 0.2826  max mem: 20571\n",
      "Valid: [epoch:798]  [13/14]  eta: 0:00:00  loss: 0.8268 (0.8373)  time: 0.0454  data: 0.0304  max mem: 20571\n",
      "Valid: [epoch:798] Total time: 0:00:00 (0.0538 s / it)\n",
      "Averaged stats: loss: 0.8268 (0.8373)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_798_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.837%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:799]  [  0/172]  eta: 0:07:45  lr: 0.000022  loss: 0.8125 (0.8125)  time: 2.7084  data: 1.1283  max mem: 20571\n",
      "Train: [epoch:799]  [ 10/172]  eta: 0:04:31  lr: 0.000022  loss: 0.8654 (0.8787)  time: 1.6771  data: 0.1027  max mem: 20571\n",
      "Train: [epoch:799]  [ 20/172]  eta: 0:04:07  lr: 0.000022  loss: 0.8654 (0.8727)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [ 30/172]  eta: 0:03:48  lr: 0.000022  loss: 0.8750 (0.8781)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [ 40/172]  eta: 0:03:31  lr: 0.000022  loss: 0.8688 (0.8735)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [ 50/172]  eta: 0:03:15  lr: 0.000022  loss: 0.8907 (0.8805)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [ 60/172]  eta: 0:02:58  lr: 0.000022  loss: 0.8701 (0.8748)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [ 70/172]  eta: 0:02:42  lr: 0.000022  loss: 0.8594 (0.8768)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [ 80/172]  eta: 0:02:26  lr: 0.000022  loss: 0.8791 (0.8768)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [ 90/172]  eta: 0:02:10  lr: 0.000022  loss: 0.8778 (0.8768)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [100/172]  eta: 0:01:54  lr: 0.000022  loss: 0.8803 (0.8770)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [110/172]  eta: 0:01:38  lr: 0.000022  loss: 0.8803 (0.8770)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [120/172]  eta: 0:01:22  lr: 0.000022  loss: 0.8873 (0.8796)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [130/172]  eta: 0:01:06  lr: 0.000022  loss: 0.8866 (0.8793)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [140/172]  eta: 0:00:50  lr: 0.000022  loss: 0.8751 (0.8790)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [150/172]  eta: 0:00:34  lr: 0.000022  loss: 0.8751 (0.8792)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [160/172]  eta: 0:00:19  lr: 0.000022  loss: 0.8680 (0.8787)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [170/172]  eta: 0:00:03  lr: 0.000022  loss: 0.8701 (0.8794)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799]  [171/172]  eta: 0:00:01  lr: 0.000022  loss: 0.8718 (0.8800)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:799] Total time: 0:04:32 (1.5865 s / it)\n",
      "Averaged stats: lr: 0.000022  loss: 0.8718 (0.8800)\n",
      "Valid: [epoch:799]  [ 0/14]  eta: 0:00:04  loss: 0.8135 (0.8135)  time: 0.3438  data: 0.3251  max mem: 20571\n",
      "Valid: [epoch:799]  [13/14]  eta: 0:00:00  loss: 0.8307 (0.8411)  time: 0.0400  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:799] Total time: 0:00:00 (0.0485 s / it)\n",
      "Averaged stats: loss: 0.8307 (0.8411)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_799_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.841%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:800]  [  0/172]  eta: 0:07:39  lr: 0.000022  loss: 0.8894 (0.8894)  time: 2.6730  data: 1.1042  max mem: 20571\n",
      "Train: [epoch:800]  [ 10/172]  eta: 0:04:31  lr: 0.000022  loss: 0.8649 (0.8864)  time: 1.6780  data: 0.1005  max mem: 20571\n",
      "Train: [epoch:800]  [ 20/172]  eta: 0:04:08  lr: 0.000022  loss: 0.8677 (0.8904)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800]  [ 30/172]  eta: 0:03:49  lr: 0.000022  loss: 0.8737 (0.8822)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800]  [ 40/172]  eta: 0:03:32  lr: 0.000022  loss: 0.8737 (0.8829)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800]  [ 50/172]  eta: 0:03:15  lr: 0.000022  loss: 0.8923 (0.8887)  time: 1.5793  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:800]  [ 60/172]  eta: 0:02:58  lr: 0.000022  loss: 0.8936 (0.8865)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:800]  [ 70/172]  eta: 0:02:42  lr: 0.000022  loss: 0.8832 (0.8860)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800]  [ 80/172]  eta: 0:02:26  lr: 0.000022  loss: 0.8653 (0.8809)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:800]  [ 90/172]  eta: 0:02:10  lr: 0.000022  loss: 0.8868 (0.8832)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:800]  [100/172]  eta: 0:01:54  lr: 0.000022  loss: 0.9017 (0.8847)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:800]  [110/172]  eta: 0:01:38  lr: 0.000022  loss: 0.8747 (0.8818)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:800]  [120/172]  eta: 0:01:22  lr: 0.000022  loss: 0.8556 (0.8792)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:800]  [130/172]  eta: 0:01:06  lr: 0.000022  loss: 0.8674 (0.8789)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800]  [140/172]  eta: 0:00:50  lr: 0.000022  loss: 0.8640 (0.8782)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800]  [150/172]  eta: 0:00:34  lr: 0.000022  loss: 0.8641 (0.8786)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800]  [160/172]  eta: 0:00:19  lr: 0.000022  loss: 0.8765 (0.8779)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800]  [170/172]  eta: 0:00:03  lr: 0.000022  loss: 0.8828 (0.8791)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800]  [171/172]  eta: 0:00:01  lr: 0.000022  loss: 0.8828 (0.8796)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:800] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000022  loss: 0.8828 (0.8796)\n",
      "Valid: [epoch:800]  [ 0/14]  eta: 0:00:05  loss: 0.7719 (0.7719)  time: 0.4021  data: 0.3835  max mem: 20571\n",
      "Valid: [epoch:800]  [13/14]  eta: 0:00:00  loss: 0.8318 (0.8424)  time: 0.0440  data: 0.0286  max mem: 20571\n",
      "Valid: [epoch:800] Total time: 0:00:00 (0.0487 s / it)\n",
      "Averaged stats: loss: 0.8318 (0.8424)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_800_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.842%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:801]  [  0/172]  eta: 0:07:31  lr: 0.000022  loss: 0.7980 (0.7980)  time: 2.6261  data: 1.0532  max mem: 20571\n",
      "Train: [epoch:801]  [ 10/172]  eta: 0:04:30  lr: 0.000022  loss: 0.8661 (0.8721)  time: 1.6715  data: 0.0959  max mem: 20571\n",
      "Train: [epoch:801]  [ 20/172]  eta: 0:04:07  lr: 0.000022  loss: 0.8661 (0.8714)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [ 30/172]  eta: 0:03:48  lr: 0.000022  loss: 0.8749 (0.8785)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [ 40/172]  eta: 0:03:31  lr: 0.000022  loss: 0.8892 (0.8769)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [ 50/172]  eta: 0:03:15  lr: 0.000022  loss: 0.8728 (0.8780)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [ 60/172]  eta: 0:02:58  lr: 0.000022  loss: 0.8728 (0.8789)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [ 70/172]  eta: 0:02:42  lr: 0.000022  loss: 0.8654 (0.8757)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [ 80/172]  eta: 0:02:26  lr: 0.000022  loss: 0.8822 (0.8782)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [ 90/172]  eta: 0:02:10  lr: 0.000022  loss: 0.8867 (0.8798)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [100/172]  eta: 0:01:54  lr: 0.000022  loss: 0.8718 (0.8784)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [110/172]  eta: 0:01:38  lr: 0.000022  loss: 0.8625 (0.8784)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [120/172]  eta: 0:01:22  lr: 0.000022  loss: 0.8765 (0.8796)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [130/172]  eta: 0:01:06  lr: 0.000022  loss: 0.8765 (0.8785)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [140/172]  eta: 0:00:50  lr: 0.000022  loss: 0.8753 (0.8798)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [150/172]  eta: 0:00:34  lr: 0.000022  loss: 0.8817 (0.8796)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [160/172]  eta: 0:00:19  lr: 0.000022  loss: 0.8840 (0.8806)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [170/172]  eta: 0:00:03  lr: 0.000022  loss: 0.8947 (0.8806)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801]  [171/172]  eta: 0:00:01  lr: 0.000022  loss: 0.8881 (0.8800)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:801] Total time: 0:04:32 (1.5858 s / it)\n",
      "Averaged stats: lr: 0.000022  loss: 0.8881 (0.8800)\n",
      "Valid: [epoch:801]  [ 0/14]  eta: 0:00:04  loss: 0.7734 (0.7734)  time: 0.2895  data: 0.2734  max mem: 20571\n",
      "Valid: [epoch:801]  [13/14]  eta: 0:00:00  loss: 0.8324 (0.8435)  time: 0.0382  data: 0.0231  max mem: 20571\n",
      "Valid: [epoch:801] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.8324 (0.8435)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_801_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.843%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:802]  [  0/172]  eta: 0:07:35  lr: 0.000022  loss: 0.8608 (0.8608)  time: 2.6471  data: 1.0790  max mem: 20571\n",
      "Train: [epoch:802]  [ 10/172]  eta: 0:04:31  lr: 0.000022  loss: 0.8561 (0.8774)  time: 1.6761  data: 0.0982  max mem: 20571\n",
      "Train: [epoch:802]  [ 20/172]  eta: 0:04:07  lr: 0.000022  loss: 0.8637 (0.8822)  time: 1.5797  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [ 30/172]  eta: 0:03:49  lr: 0.000022  loss: 0.8828 (0.8842)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [ 40/172]  eta: 0:03:32  lr: 0.000022  loss: 0.8635 (0.8780)  time: 1.5816  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [ 50/172]  eta: 0:03:15  lr: 0.000022  loss: 0.8459 (0.8757)  time: 1.5817  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [ 60/172]  eta: 0:02:58  lr: 0.000022  loss: 0.8597 (0.8746)  time: 1.5796  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [ 70/172]  eta: 0:02:42  lr: 0.000022  loss: 0.8653 (0.8744)  time: 1.5772  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [ 80/172]  eta: 0:02:26  lr: 0.000022  loss: 0.8740 (0.8786)  time: 1.5773  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [ 90/172]  eta: 0:02:10  lr: 0.000022  loss: 0.8764 (0.8778)  time: 1.5778  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [100/172]  eta: 0:01:54  lr: 0.000022  loss: 0.8746 (0.8776)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [110/172]  eta: 0:01:38  lr: 0.000022  loss: 0.8702 (0.8785)  time: 1.5808  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [120/172]  eta: 0:01:22  lr: 0.000022  loss: 0.8570 (0.8778)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:802]  [130/172]  eta: 0:01:06  lr: 0.000022  loss: 0.8873 (0.8801)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:802]  [140/172]  eta: 0:00:50  lr: 0.000022  loss: 0.8761 (0.8798)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:802]  [150/172]  eta: 0:00:34  lr: 0.000022  loss: 0.8467 (0.8798)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:802]  [160/172]  eta: 0:00:19  lr: 0.000022  loss: 0.8922 (0.8817)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:802]  [170/172]  eta: 0:00:03  lr: 0.000022  loss: 0.8796 (0.8812)  time: 1.5797  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:802]  [171/172]  eta: 0:00:01  lr: 0.000022  loss: 0.8796 (0.8816)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:802] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000022  loss: 0.8796 (0.8816)\n",
      "Valid: [epoch:802]  [ 0/14]  eta: 0:00:06  loss: 0.8312 (0.8312)  time: 0.4721  data: 0.4566  max mem: 20571\n",
      "Valid: [epoch:802]  [13/14]  eta: 0:00:00  loss: 0.8312 (0.8420)  time: 0.0496  data: 0.0345  max mem: 20571\n",
      "Valid: [epoch:802] Total time: 0:00:00 (0.0558 s / it)\n",
      "Averaged stats: loss: 0.8312 (0.8420)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_802_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.842%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:803]  [  0/172]  eta: 0:07:47  lr: 0.000022  loss: 0.8539 (0.8539)  time: 2.7189  data: 1.1416  max mem: 20571\n",
      "Train: [epoch:803]  [ 10/172]  eta: 0:04:31  lr: 0.000022  loss: 0.8383 (0.8473)  time: 1.6786  data: 0.1039  max mem: 20571\n",
      "Train: [epoch:803]  [ 20/172]  eta: 0:04:07  lr: 0.000022  loss: 0.8365 (0.8583)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [ 30/172]  eta: 0:03:49  lr: 0.000022  loss: 0.8485 (0.8572)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [ 40/172]  eta: 0:03:31  lr: 0.000022  loss: 0.8865 (0.8670)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [ 50/172]  eta: 0:03:15  lr: 0.000022  loss: 0.8865 (0.8710)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [ 60/172]  eta: 0:02:58  lr: 0.000022  loss: 0.8758 (0.8711)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [ 70/172]  eta: 0:02:42  lr: 0.000022  loss: 0.8707 (0.8725)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [ 80/172]  eta: 0:02:26  lr: 0.000022  loss: 0.9090 (0.8770)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [ 90/172]  eta: 0:02:10  lr: 0.000022  loss: 0.9153 (0.8802)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [100/172]  eta: 0:01:54  lr: 0.000022  loss: 0.8828 (0.8797)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [110/172]  eta: 0:01:38  lr: 0.000022  loss: 0.8742 (0.8798)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [120/172]  eta: 0:01:22  lr: 0.000022  loss: 0.8592 (0.8783)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [130/172]  eta: 0:01:06  lr: 0.000022  loss: 0.8762 (0.8789)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [140/172]  eta: 0:00:50  lr: 0.000022  loss: 0.8892 (0.8804)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [150/172]  eta: 0:00:34  lr: 0.000022  loss: 0.8917 (0.8816)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [160/172]  eta: 0:00:19  lr: 0.000022  loss: 0.8721 (0.8809)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [170/172]  eta: 0:00:03  lr: 0.000022  loss: 0.8823 (0.8816)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803]  [171/172]  eta: 0:00:01  lr: 0.000022  loss: 0.8863 (0.8820)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:803] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000022  loss: 0.8863 (0.8820)\n",
      "Valid: [epoch:803]  [ 0/14]  eta: 0:00:04  loss: 0.9281 (0.9281)  time: 0.3294  data: 0.3102  max mem: 20571\n",
      "Valid: [epoch:803]  [13/14]  eta: 0:00:00  loss: 0.8464 (0.8562)  time: 0.0379  data: 0.0223  max mem: 20571\n",
      "Valid: [epoch:803] Total time: 0:00:00 (0.0442 s / it)\n",
      "Averaged stats: loss: 0.8464 (0.8562)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_803_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.856%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:804]  [  0/172]  eta: 0:08:20  lr: 0.000022  loss: 0.9551 (0.9551)  time: 2.9119  data: 1.3410  max mem: 20571\n",
      "Train: [epoch:804]  [ 10/172]  eta: 0:04:35  lr: 0.000022  loss: 0.8755 (0.8947)  time: 1.6998  data: 0.1220  max mem: 20571\n",
      "Train: [epoch:804]  [ 20/172]  eta: 0:04:09  lr: 0.000022  loss: 0.8756 (0.8984)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [ 30/172]  eta: 0:03:50  lr: 0.000022  loss: 0.8606 (0.8815)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [ 40/172]  eta: 0:03:32  lr: 0.000022  loss: 0.8571 (0.8827)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [ 50/172]  eta: 0:03:15  lr: 0.000022  loss: 0.8817 (0.8853)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [ 60/172]  eta: 0:02:59  lr: 0.000022  loss: 0.8817 (0.8846)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [ 70/172]  eta: 0:02:43  lr: 0.000022  loss: 0.8795 (0.8852)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [ 80/172]  eta: 0:02:26  lr: 0.000022  loss: 0.8795 (0.8893)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [ 90/172]  eta: 0:02:10  lr: 0.000022  loss: 0.8800 (0.8893)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [100/172]  eta: 0:01:54  lr: 0.000022  loss: 0.8855 (0.8888)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [110/172]  eta: 0:01:38  lr: 0.000022  loss: 0.8955 (0.8878)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [120/172]  eta: 0:01:22  lr: 0.000022  loss: 0.8873 (0.8879)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [130/172]  eta: 0:01:06  lr: 0.000022  loss: 0.8921 (0.8883)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [140/172]  eta: 0:00:50  lr: 0.000022  loss: 0.8895 (0.8881)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [150/172]  eta: 0:00:34  lr: 0.000022  loss: 0.8688 (0.8859)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [160/172]  eta: 0:00:19  lr: 0.000022  loss: 0.8565 (0.8863)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [170/172]  eta: 0:00:03  lr: 0.000022  loss: 0.8850 (0.8871)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804]  [171/172]  eta: 0:00:01  lr: 0.000022  loss: 0.8930 (0.8877)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:804] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000022  loss: 0.8930 (0.8877)\n",
      "Valid: [epoch:804]  [ 0/14]  eta: 0:00:05  loss: 0.8192 (0.8192)  time: 0.3691  data: 0.3525  max mem: 20571\n",
      "Valid: [epoch:804]  [13/14]  eta: 0:00:00  loss: 0.8382 (0.8478)  time: 0.0408  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:804] Total time: 0:00:00 (0.0475 s / it)\n",
      "Averaged stats: loss: 0.8382 (0.8478)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_804_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.848%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:805]  [  0/172]  eta: 0:07:26  lr: 0.000022  loss: 0.9093 (0.9093)  time: 2.5963  data: 1.0037  max mem: 20571\n",
      "Train: [epoch:805]  [ 10/172]  eta: 0:04:30  lr: 0.000022  loss: 0.9093 (0.8845)  time: 1.6680  data: 0.0913  max mem: 20571\n",
      "Train: [epoch:805]  [ 20/172]  eta: 0:04:06  lr: 0.000022  loss: 0.8855 (0.8806)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [ 30/172]  eta: 0:03:48  lr: 0.000022  loss: 0.8947 (0.8878)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [ 40/172]  eta: 0:03:31  lr: 0.000022  loss: 0.8701 (0.8835)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [ 50/172]  eta: 0:03:14  lr: 0.000022  loss: 0.8701 (0.8872)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [ 60/172]  eta: 0:02:58  lr: 0.000022  loss: 0.8724 (0.8831)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [ 70/172]  eta: 0:02:42  lr: 0.000022  loss: 0.8641 (0.8814)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [ 80/172]  eta: 0:02:26  lr: 0.000022  loss: 0.8747 (0.8837)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [ 90/172]  eta: 0:02:10  lr: 0.000022  loss: 0.8692 (0.8827)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [100/172]  eta: 0:01:54  lr: 0.000022  loss: 0.8653 (0.8838)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [110/172]  eta: 0:01:38  lr: 0.000022  loss: 0.8781 (0.8835)  time: 1.5784  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:805]  [120/172]  eta: 0:01:22  lr: 0.000022  loss: 0.8713 (0.8823)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [130/172]  eta: 0:01:06  lr: 0.000022  loss: 0.8840 (0.8836)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [140/172]  eta: 0:00:50  lr: 0.000022  loss: 0.8863 (0.8829)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [150/172]  eta: 0:00:34  lr: 0.000022  loss: 0.8793 (0.8838)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [160/172]  eta: 0:00:19  lr: 0.000022  loss: 0.8867 (0.8842)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [170/172]  eta: 0:00:03  lr: 0.000022  loss: 0.8639 (0.8831)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805]  [171/172]  eta: 0:00:01  lr: 0.000022  loss: 0.8623 (0.8829)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:805] Total time: 0:04:32 (1.5839 s / it)\n",
      "Averaged stats: lr: 0.000022  loss: 0.8623 (0.8829)\n",
      "Valid: [epoch:805]  [ 0/14]  eta: 0:00:04  loss: 0.8797 (0.8797)  time: 0.2939  data: 0.2780  max mem: 20571\n",
      "Valid: [epoch:805]  [13/14]  eta: 0:00:00  loss: 0.8377 (0.8483)  time: 0.0429  data: 0.0278  max mem: 20571\n",
      "Valid: [epoch:805] Total time: 0:00:00 (0.0483 s / it)\n",
      "Averaged stats: loss: 0.8377 (0.8483)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_805_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.848%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:806]  [  0/172]  eta: 0:07:45  lr: 0.000022  loss: 0.8751 (0.8751)  time: 2.7061  data: 1.1410  max mem: 20571\n",
      "Train: [epoch:806]  [ 10/172]  eta: 0:04:32  lr: 0.000022  loss: 0.8751 (0.8764)  time: 1.6791  data: 0.1039  max mem: 20571\n",
      "Train: [epoch:806]  [ 20/172]  eta: 0:04:07  lr: 0.000022  loss: 0.8871 (0.9017)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [ 30/172]  eta: 0:03:49  lr: 0.000022  loss: 0.9020 (0.8980)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [ 40/172]  eta: 0:03:31  lr: 0.000022  loss: 0.8841 (0.8949)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [ 50/172]  eta: 0:03:15  lr: 0.000022  loss: 0.8717 (0.8962)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [ 60/172]  eta: 0:02:58  lr: 0.000022  loss: 0.8586 (0.8923)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [ 70/172]  eta: 0:02:42  lr: 0.000022  loss: 0.8556 (0.8886)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [ 80/172]  eta: 0:02:26  lr: 0.000022  loss: 0.8698 (0.8876)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [ 90/172]  eta: 0:02:10  lr: 0.000022  loss: 0.8711 (0.8887)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [100/172]  eta: 0:01:54  lr: 0.000022  loss: 0.8690 (0.8858)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [110/172]  eta: 0:01:38  lr: 0.000022  loss: 0.8469 (0.8827)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [120/172]  eta: 0:01:22  lr: 0.000022  loss: 0.8585 (0.8830)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [130/172]  eta: 0:01:06  lr: 0.000022  loss: 0.8781 (0.8815)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [140/172]  eta: 0:00:50  lr: 0.000022  loss: 0.8873 (0.8831)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [150/172]  eta: 0:00:34  lr: 0.000022  loss: 0.9099 (0.8847)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [160/172]  eta: 0:00:19  lr: 0.000022  loss: 0.8881 (0.8843)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [170/172]  eta: 0:00:03  lr: 0.000022  loss: 0.8881 (0.8855)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806]  [171/172]  eta: 0:00:01  lr: 0.000022  loss: 0.8942 (0.8857)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:806] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000022  loss: 0.8942 (0.8857)\n",
      "Valid: [epoch:806]  [ 0/14]  eta: 0:00:04  loss: 0.7957 (0.7957)  time: 0.3411  data: 0.3260  max mem: 20571\n",
      "Valid: [epoch:806]  [13/14]  eta: 0:00:00  loss: 0.8392 (0.8500)  time: 0.0393  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:806] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.8392 (0.8500)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_806_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.850%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:807]  [  0/172]  eta: 0:07:48  lr: 0.000022  loss: 0.9076 (0.9076)  time: 2.7242  data: 1.1472  max mem: 20571\n",
      "Train: [epoch:807]  [ 10/172]  eta: 0:04:32  lr: 0.000022  loss: 0.8896 (0.8860)  time: 1.6791  data: 0.1044  max mem: 20571\n",
      "Train: [epoch:807]  [ 20/172]  eta: 0:04:07  lr: 0.000022  loss: 0.8715 (0.8780)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [ 30/172]  eta: 0:03:49  lr: 0.000022  loss: 0.8758 (0.8836)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [ 40/172]  eta: 0:03:31  lr: 0.000022  loss: 0.8833 (0.8844)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [ 50/172]  eta: 0:03:15  lr: 0.000022  loss: 0.8782 (0.8837)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [ 60/172]  eta: 0:02:58  lr: 0.000022  loss: 0.8780 (0.8823)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [ 70/172]  eta: 0:02:42  lr: 0.000022  loss: 0.8780 (0.8812)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [ 80/172]  eta: 0:02:26  lr: 0.000022  loss: 0.8780 (0.8837)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [ 90/172]  eta: 0:02:10  lr: 0.000022  loss: 0.8883 (0.8839)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [100/172]  eta: 0:01:54  lr: 0.000022  loss: 0.8505 (0.8823)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [110/172]  eta: 0:01:38  lr: 0.000022  loss: 0.8792 (0.8833)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [120/172]  eta: 0:01:22  lr: 0.000022  loss: 0.8792 (0.8808)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [130/172]  eta: 0:01:06  lr: 0.000022  loss: 0.8852 (0.8832)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [140/172]  eta: 0:00:50  lr: 0.000022  loss: 0.8734 (0.8809)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [150/172]  eta: 0:00:34  lr: 0.000022  loss: 0.8734 (0.8839)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [160/172]  eta: 0:00:19  lr: 0.000022  loss: 0.9379 (0.8856)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [170/172]  eta: 0:00:03  lr: 0.000022  loss: 0.8684 (0.8847)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807]  [171/172]  eta: 0:00:01  lr: 0.000022  loss: 0.8684 (0.8848)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:807] Total time: 0:04:32 (1.5859 s / it)\n",
      "Averaged stats: lr: 0.000022  loss: 0.8684 (0.8848)\n",
      "Valid: [epoch:807]  [ 0/14]  eta: 0:00:05  loss: 0.8794 (0.8794)  time: 0.3681  data: 0.3527  max mem: 20571\n",
      "Valid: [epoch:807]  [13/14]  eta: 0:00:00  loss: 0.8370 (0.8478)  time: 0.0428  data: 0.0278  max mem: 20571\n",
      "Valid: [epoch:807] Total time: 0:00:00 (0.0512 s / it)\n",
      "Averaged stats: loss: 0.8370 (0.8478)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_807_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.848%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:808]  [  0/172]  eta: 0:08:09  lr: 0.000021  loss: 0.8732 (0.8732)  time: 2.8461  data: 1.2804  max mem: 20571\n",
      "Train: [epoch:808]  [ 10/172]  eta: 0:04:34  lr: 0.000021  loss: 0.8514 (0.8617)  time: 1.6941  data: 0.1166  max mem: 20571\n",
      "Train: [epoch:808]  [ 20/172]  eta: 0:04:09  lr: 0.000021  loss: 0.8653 (0.8747)  time: 1.5790  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:808]  [ 30/172]  eta: 0:03:50  lr: 0.000021  loss: 0.8906 (0.8829)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [ 40/172]  eta: 0:03:32  lr: 0.000021  loss: 0.8778 (0.8797)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [ 50/172]  eta: 0:03:15  lr: 0.000021  loss: 0.8763 (0.8831)  time: 1.5786  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:808]  [ 60/172]  eta: 0:02:59  lr: 0.000021  loss: 0.8978 (0.8862)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [ 70/172]  eta: 0:02:42  lr: 0.000021  loss: 0.9057 (0.8877)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [ 80/172]  eta: 0:02:26  lr: 0.000021  loss: 0.8906 (0.8898)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [ 90/172]  eta: 0:02:10  lr: 0.000021  loss: 0.8908 (0.8898)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [100/172]  eta: 0:01:54  lr: 0.000021  loss: 0.8882 (0.8881)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [110/172]  eta: 0:01:38  lr: 0.000021  loss: 0.8832 (0.8877)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [120/172]  eta: 0:01:22  lr: 0.000021  loss: 0.8895 (0.8875)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [130/172]  eta: 0:01:06  lr: 0.000021  loss: 0.8767 (0.8864)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [140/172]  eta: 0:00:50  lr: 0.000021  loss: 0.8767 (0.8871)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [150/172]  eta: 0:00:34  lr: 0.000021  loss: 0.8669 (0.8863)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [160/172]  eta: 0:00:19  lr: 0.000021  loss: 0.8669 (0.8865)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [170/172]  eta: 0:00:03  lr: 0.000021  loss: 0.8743 (0.8873)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808]  [171/172]  eta: 0:00:01  lr: 0.000021  loss: 0.8743 (0.8878)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:808] Total time: 0:04:32 (1.5866 s / it)\n",
      "Averaged stats: lr: 0.000021  loss: 0.8743 (0.8878)\n",
      "Valid: [epoch:808]  [ 0/14]  eta: 0:00:04  loss: 0.7944 (0.7944)  time: 0.3198  data: 0.3042  max mem: 20571\n",
      "Valid: [epoch:808]  [13/14]  eta: 0:00:00  loss: 0.8362 (0.8479)  time: 0.0383  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:808] Total time: 0:00:00 (0.0466 s / it)\n",
      "Averaged stats: loss: 0.8362 (0.8479)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_808_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.848%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:809]  [  0/172]  eta: 0:07:50  lr: 0.000021  loss: 0.8455 (0.8455)  time: 2.7335  data: 1.1467  max mem: 20571\n",
      "Train: [epoch:809]  [ 10/172]  eta: 0:04:32  lr: 0.000021  loss: 0.8941 (0.8776)  time: 1.6810  data: 0.1044  max mem: 20571\n",
      "Train: [epoch:809]  [ 20/172]  eta: 0:04:07  lr: 0.000021  loss: 0.9099 (0.8951)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [ 30/172]  eta: 0:03:49  lr: 0.000021  loss: 0.8998 (0.8861)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [ 40/172]  eta: 0:03:31  lr: 0.000021  loss: 0.8756 (0.8850)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [ 50/172]  eta: 0:03:15  lr: 0.000021  loss: 0.8846 (0.8864)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [ 60/172]  eta: 0:02:58  lr: 0.000021  loss: 0.9028 (0.8915)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [ 70/172]  eta: 0:02:42  lr: 0.000021  loss: 0.8975 (0.8895)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [ 80/172]  eta: 0:02:26  lr: 0.000021  loss: 0.8662 (0.8908)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [ 90/172]  eta: 0:02:10  lr: 0.000021  loss: 0.8846 (0.8905)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [100/172]  eta: 0:01:54  lr: 0.000021  loss: 0.8812 (0.8892)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [110/172]  eta: 0:01:38  lr: 0.000021  loss: 0.8600 (0.8886)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [120/172]  eta: 0:01:22  lr: 0.000021  loss: 0.8999 (0.8898)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [130/172]  eta: 0:01:06  lr: 0.000021  loss: 0.8994 (0.8901)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [140/172]  eta: 0:00:50  lr: 0.000021  loss: 0.8840 (0.8902)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [150/172]  eta: 0:00:34  lr: 0.000021  loss: 0.8880 (0.8898)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [160/172]  eta: 0:00:19  lr: 0.000021  loss: 0.8884 (0.8891)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [170/172]  eta: 0:00:03  lr: 0.000021  loss: 0.8866 (0.8885)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809]  [171/172]  eta: 0:00:01  lr: 0.000021  loss: 0.8866 (0.8884)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:809] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000021  loss: 0.8866 (0.8884)\n",
      "Valid: [epoch:809]  [ 0/14]  eta: 0:00:04  loss: 0.7992 (0.7992)  time: 0.3001  data: 0.2851  max mem: 20571\n",
      "Valid: [epoch:809]  [13/14]  eta: 0:00:00  loss: 0.8418 (0.8518)  time: 0.0390  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:809] Total time: 0:00:00 (0.0476 s / it)\n",
      "Averaged stats: loss: 0.8418 (0.8518)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_809_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.852%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:810]  [  0/172]  eta: 0:07:28  lr: 0.000021  loss: 0.9223 (0.9223)  time: 2.6073  data: 1.0403  max mem: 20571\n",
      "Train: [epoch:810]  [ 10/172]  eta: 0:04:30  lr: 0.000021  loss: 0.8871 (0.8715)  time: 1.6707  data: 0.0947  max mem: 20571\n",
      "Train: [epoch:810]  [ 20/172]  eta: 0:04:07  lr: 0.000021  loss: 0.8698 (0.8715)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [ 30/172]  eta: 0:03:48  lr: 0.000021  loss: 0.8722 (0.8756)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [ 40/172]  eta: 0:03:31  lr: 0.000021  loss: 0.8661 (0.8771)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [ 50/172]  eta: 0:03:15  lr: 0.000021  loss: 0.8729 (0.8802)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [ 60/172]  eta: 0:02:58  lr: 0.000021  loss: 0.8865 (0.8845)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [ 70/172]  eta: 0:02:42  lr: 0.000021  loss: 0.8794 (0.8849)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [ 80/172]  eta: 0:02:26  lr: 0.000021  loss: 0.8829 (0.8853)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [ 90/172]  eta: 0:02:10  lr: 0.000021  loss: 0.8926 (0.8860)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [100/172]  eta: 0:01:54  lr: 0.000021  loss: 0.8985 (0.8882)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [110/172]  eta: 0:01:38  lr: 0.000021  loss: 0.8988 (0.8904)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [120/172]  eta: 0:01:22  lr: 0.000021  loss: 0.8836 (0.8899)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [130/172]  eta: 0:01:06  lr: 0.000021  loss: 0.8782 (0.8913)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [140/172]  eta: 0:00:50  lr: 0.000021  loss: 0.8805 (0.8897)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [150/172]  eta: 0:00:34  lr: 0.000021  loss: 0.8837 (0.8896)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [160/172]  eta: 0:00:19  lr: 0.000021  loss: 0.8921 (0.8894)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [170/172]  eta: 0:00:03  lr: 0.000021  loss: 0.8704 (0.8881)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810]  [171/172]  eta: 0:00:01  lr: 0.000021  loss: 0.8704 (0.8887)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:810] Total time: 0:04:32 (1.5850 s / it)\n",
      "Averaged stats: lr: 0.000021  loss: 0.8704 (0.8887)\n",
      "Valid: [epoch:810]  [ 0/14]  eta: 0:00:05  loss: 0.7883 (0.7883)  time: 0.3905  data: 0.3758  max mem: 20571\n",
      "Valid: [epoch:810]  [13/14]  eta: 0:00:00  loss: 0.8469 (0.8584)  time: 0.0427  data: 0.0278  max mem: 20571\n",
      "Valid: [epoch:810] Total time: 0:00:00 (0.0474 s / it)\n",
      "Averaged stats: loss: 0.8469 (0.8584)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_810_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.858%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:811]  [  0/172]  eta: 0:07:29  lr: 0.000021  loss: 0.8925 (0.8925)  time: 2.6129  data: 1.0338  max mem: 20571\n",
      "Train: [epoch:811]  [ 10/172]  eta: 0:04:30  lr: 0.000021  loss: 0.8845 (0.8776)  time: 1.6700  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:811]  [ 20/172]  eta: 0:04:07  lr: 0.000021  loss: 0.8851 (0.8964)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [ 30/172]  eta: 0:03:48  lr: 0.000021  loss: 0.8889 (0.8923)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [ 40/172]  eta: 0:03:31  lr: 0.000021  loss: 0.8599 (0.8861)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [ 50/172]  eta: 0:03:14  lr: 0.000021  loss: 0.8547 (0.8858)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [ 60/172]  eta: 0:02:58  lr: 0.000021  loss: 0.8832 (0.8868)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [ 70/172]  eta: 0:02:42  lr: 0.000021  loss: 0.9043 (0.8915)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [ 80/172]  eta: 0:02:26  lr: 0.000021  loss: 0.8941 (0.8892)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [ 90/172]  eta: 0:02:10  lr: 0.000021  loss: 0.8739 (0.8911)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [100/172]  eta: 0:01:54  lr: 0.000021  loss: 0.8791 (0.8899)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [110/172]  eta: 0:01:38  lr: 0.000021  loss: 0.8727 (0.8893)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [120/172]  eta: 0:01:22  lr: 0.000021  loss: 0.8838 (0.8887)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [130/172]  eta: 0:01:06  lr: 0.000021  loss: 0.9009 (0.8904)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [140/172]  eta: 0:00:50  lr: 0.000021  loss: 0.9074 (0.8901)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [150/172]  eta: 0:00:34  lr: 0.000021  loss: 0.8749 (0.8894)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [160/172]  eta: 0:00:19  lr: 0.000021  loss: 0.8801 (0.8904)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [170/172]  eta: 0:00:03  lr: 0.000021  loss: 0.9009 (0.8919)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811]  [171/172]  eta: 0:00:01  lr: 0.000021  loss: 0.8881 (0.8915)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:811] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000021  loss: 0.8881 (0.8915)\n",
      "Valid: [epoch:811]  [ 0/14]  eta: 0:00:04  loss: 0.8395 (0.8395)  time: 0.3329  data: 0.3151  max mem: 20571\n",
      "Valid: [epoch:811]  [13/14]  eta: 0:00:00  loss: 0.8445 (0.8555)  time: 0.0383  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:811] Total time: 0:00:00 (0.0432 s / it)\n",
      "Averaged stats: loss: 0.8445 (0.8555)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_811_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.856%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:812]  [  0/172]  eta: 0:07:24  lr: 0.000021  loss: 0.8676 (0.8676)  time: 2.5863  data: 1.0207  max mem: 20571\n",
      "Train: [epoch:812]  [ 10/172]  eta: 0:04:30  lr: 0.000021  loss: 0.9164 (0.9023)  time: 1.6681  data: 0.0929  max mem: 20571\n",
      "Train: [epoch:812]  [ 20/172]  eta: 0:04:07  lr: 0.000021  loss: 0.8823 (0.8952)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [ 30/172]  eta: 0:03:48  lr: 0.000021  loss: 0.8823 (0.8903)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [ 40/172]  eta: 0:03:31  lr: 0.000021  loss: 0.8586 (0.8852)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [ 50/172]  eta: 0:03:15  lr: 0.000021  loss: 0.8692 (0.8868)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [ 60/172]  eta: 0:02:58  lr: 0.000021  loss: 0.8776 (0.8835)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [ 70/172]  eta: 0:02:42  lr: 0.000021  loss: 0.8645 (0.8823)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [ 80/172]  eta: 0:02:26  lr: 0.000021  loss: 0.8812 (0.8844)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [ 90/172]  eta: 0:02:10  lr: 0.000021  loss: 0.9118 (0.8880)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [100/172]  eta: 0:01:54  lr: 0.000021  loss: 0.9118 (0.8886)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [110/172]  eta: 0:01:38  lr: 0.000021  loss: 0.9056 (0.8908)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [120/172]  eta: 0:01:22  lr: 0.000021  loss: 0.9056 (0.8906)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [130/172]  eta: 0:01:06  lr: 0.000021  loss: 0.8833 (0.8918)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [140/172]  eta: 0:00:50  lr: 0.000021  loss: 0.8825 (0.8907)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [150/172]  eta: 0:00:34  lr: 0.000021  loss: 0.8787 (0.8896)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [160/172]  eta: 0:00:19  lr: 0.000021  loss: 0.8807 (0.8909)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [170/172]  eta: 0:00:03  lr: 0.000021  loss: 0.8944 (0.8908)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812]  [171/172]  eta: 0:00:01  lr: 0.000021  loss: 0.8944 (0.8906)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:812] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000021  loss: 0.8944 (0.8906)\n",
      "Valid: [epoch:812]  [ 0/14]  eta: 0:00:03  loss: 0.8469 (0.8469)  time: 0.2760  data: 0.2598  max mem: 20571\n",
      "Valid: [epoch:812]  [13/14]  eta: 0:00:00  loss: 0.8469 (0.8592)  time: 0.0379  data: 0.0228  max mem: 20571\n",
      "Valid: [epoch:812] Total time: 0:00:00 (0.0434 s / it)\n",
      "Averaged stats: loss: 0.8469 (0.8592)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_812_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.859%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:813]  [  0/172]  eta: 0:08:14  lr: 0.000021  loss: 0.8185 (0.8185)  time: 2.8734  data: 1.2989  max mem: 20571\n",
      "Train: [epoch:813]  [ 10/172]  eta: 0:04:34  lr: 0.000021  loss: 0.9099 (0.8901)  time: 1.6926  data: 0.1182  max mem: 20571\n",
      "Train: [epoch:813]  [ 20/172]  eta: 0:04:08  lr: 0.000021  loss: 0.8876 (0.8858)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [ 30/172]  eta: 0:03:49  lr: 0.000021  loss: 0.8757 (0.8850)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [ 40/172]  eta: 0:03:32  lr: 0.000021  loss: 0.8678 (0.8793)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [ 50/172]  eta: 0:03:15  lr: 0.000021  loss: 0.8541 (0.8825)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [ 60/172]  eta: 0:02:59  lr: 0.000021  loss: 0.8863 (0.8874)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [ 70/172]  eta: 0:02:42  lr: 0.000021  loss: 0.8925 (0.8877)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [ 80/172]  eta: 0:02:26  lr: 0.000021  loss: 0.8925 (0.8880)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [ 90/172]  eta: 0:02:10  lr: 0.000021  loss: 0.8738 (0.8887)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [100/172]  eta: 0:01:54  lr: 0.000021  loss: 0.8950 (0.8896)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [110/172]  eta: 0:01:38  lr: 0.000021  loss: 0.8832 (0.8887)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [120/172]  eta: 0:01:22  lr: 0.000021  loss: 0.8808 (0.8885)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [130/172]  eta: 0:01:06  lr: 0.000021  loss: 0.8705 (0.8884)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [140/172]  eta: 0:00:50  lr: 0.000021  loss: 0.8827 (0.8901)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [150/172]  eta: 0:00:34  lr: 0.000021  loss: 0.8827 (0.8897)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [160/172]  eta: 0:00:19  lr: 0.000021  loss: 0.8839 (0.8908)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813]  [170/172]  eta: 0:00:03  lr: 0.000021  loss: 0.9222 (0.8931)  time: 1.5787  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:813]  [171/172]  eta: 0:00:01  lr: 0.000021  loss: 0.9132 (0.8930)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:813] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000021  loss: 0.9132 (0.8930)\n",
      "Valid: [epoch:813]  [ 0/14]  eta: 0:00:03  loss: 0.8894 (0.8894)  time: 0.2828  data: 0.2682  max mem: 20571\n",
      "Valid: [epoch:813]  [13/14]  eta: 0:00:00  loss: 0.8438 (0.8545)  time: 0.0413  data: 0.0264  max mem: 20571\n",
      "Valid: [epoch:813] Total time: 0:00:00 (0.0470 s / it)\n",
      "Averaged stats: loss: 0.8438 (0.8545)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_813_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.855%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:814]  [  0/172]  eta: 0:07:43  lr: 0.000021  loss: 0.8792 (0.8792)  time: 2.6940  data: 1.1286  max mem: 20571\n",
      "Train: [epoch:814]  [ 10/172]  eta: 0:04:31  lr: 0.000021  loss: 0.8792 (0.8714)  time: 1.6781  data: 0.1027  max mem: 20571\n",
      "Train: [epoch:814]  [ 20/172]  eta: 0:04:07  lr: 0.000021  loss: 0.8693 (0.8833)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [ 30/172]  eta: 0:03:49  lr: 0.000021  loss: 0.8693 (0.8916)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [ 40/172]  eta: 0:03:31  lr: 0.000021  loss: 0.8670 (0.8879)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [ 50/172]  eta: 0:03:15  lr: 0.000021  loss: 0.8938 (0.8923)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [ 60/172]  eta: 0:02:58  lr: 0.000021  loss: 0.9010 (0.8943)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [ 70/172]  eta: 0:02:42  lr: 0.000021  loss: 0.8934 (0.8927)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [ 80/172]  eta: 0:02:26  lr: 0.000021  loss: 0.8972 (0.8942)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [ 90/172]  eta: 0:02:10  lr: 0.000021  loss: 0.9070 (0.8962)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [100/172]  eta: 0:01:54  lr: 0.000021  loss: 0.8875 (0.8942)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [110/172]  eta: 0:01:38  lr: 0.000021  loss: 0.8786 (0.8958)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [120/172]  eta: 0:01:22  lr: 0.000021  loss: 0.8926 (0.8959)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [130/172]  eta: 0:01:06  lr: 0.000021  loss: 0.8851 (0.8950)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [140/172]  eta: 0:00:50  lr: 0.000021  loss: 0.8693 (0.8942)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [150/172]  eta: 0:00:34  lr: 0.000021  loss: 0.8775 (0.8941)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [160/172]  eta: 0:00:19  lr: 0.000021  loss: 0.8875 (0.8934)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [170/172]  eta: 0:00:03  lr: 0.000021  loss: 0.8789 (0.8930)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814]  [171/172]  eta: 0:00:01  lr: 0.000021  loss: 0.8875 (0.8932)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:814] Total time: 0:04:32 (1.5846 s / it)\n",
      "Averaged stats: lr: 0.000021  loss: 0.8875 (0.8932)\n",
      "Valid: [epoch:814]  [ 0/14]  eta: 0:00:03  loss: 0.8413 (0.8413)  time: 0.2786  data: 0.2634  max mem: 20571\n",
      "Valid: [epoch:814]  [13/14]  eta: 0:00:00  loss: 0.8413 (0.8523)  time: 0.0387  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:814] Total time: 0:00:00 (0.0433 s / it)\n",
      "Averaged stats: loss: 0.8413 (0.8523)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_814_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.852%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:815]  [  0/172]  eta: 0:08:07  lr: 0.000021  loss: 0.9455 (0.9455)  time: 2.8318  data: 1.2528  max mem: 20571\n",
      "Train: [epoch:815]  [ 10/172]  eta: 0:04:34  lr: 0.000021  loss: 0.8632 (0.8703)  time: 1.6925  data: 0.1140  max mem: 20571\n",
      "Train: [epoch:815]  [ 20/172]  eta: 0:04:08  lr: 0.000021  loss: 0.8720 (0.8871)  time: 1.5780  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:815]  [ 30/172]  eta: 0:03:49  lr: 0.000021  loss: 0.8933 (0.8895)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [ 40/172]  eta: 0:03:32  lr: 0.000021  loss: 0.8885 (0.8902)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [ 50/172]  eta: 0:03:15  lr: 0.000021  loss: 0.8982 (0.8925)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [ 60/172]  eta: 0:02:59  lr: 0.000021  loss: 0.8843 (0.8908)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [ 70/172]  eta: 0:02:42  lr: 0.000021  loss: 0.8750 (0.8918)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [ 80/172]  eta: 0:02:26  lr: 0.000021  loss: 0.8855 (0.8946)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [ 90/172]  eta: 0:02:10  lr: 0.000021  loss: 0.8803 (0.8920)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [100/172]  eta: 0:01:54  lr: 0.000021  loss: 0.8774 (0.8937)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [110/172]  eta: 0:01:38  lr: 0.000021  loss: 0.8856 (0.8917)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [120/172]  eta: 0:01:22  lr: 0.000021  loss: 0.8866 (0.8925)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [130/172]  eta: 0:01:06  lr: 0.000021  loss: 0.9037 (0.8930)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [140/172]  eta: 0:00:50  lr: 0.000021  loss: 0.8964 (0.8920)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [150/172]  eta: 0:00:34  lr: 0.000021  loss: 0.8966 (0.8929)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [160/172]  eta: 0:00:19  lr: 0.000021  loss: 0.9010 (0.8944)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [170/172]  eta: 0:00:03  lr: 0.000021  loss: 0.8950 (0.8943)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815]  [171/172]  eta: 0:00:01  lr: 0.000021  loss: 0.8916 (0.8943)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:815] Total time: 0:04:32 (1.5862 s / it)\n",
      "Averaged stats: lr: 0.000021  loss: 0.8916 (0.8943)\n",
      "Valid: [epoch:815]  [ 0/14]  eta: 0:00:05  loss: 0.8002 (0.8002)  time: 0.3873  data: 0.3707  max mem: 20571\n",
      "Valid: [epoch:815]  [13/14]  eta: 0:00:00  loss: 0.8420 (0.8541)  time: 0.0426  data: 0.0276  max mem: 20571\n",
      "Valid: [epoch:815] Total time: 0:00:00 (0.0475 s / it)\n",
      "Averaged stats: loss: 0.8420 (0.8541)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_815_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.854%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:816]  [  0/172]  eta: 0:07:50  lr: 0.000021  loss: 0.8648 (0.8648)  time: 2.7350  data: 1.1690  max mem: 20571\n",
      "Train: [epoch:816]  [ 10/172]  eta: 0:04:32  lr: 0.000021  loss: 0.8676 (0.8802)  time: 1.6826  data: 0.1064  max mem: 20571\n",
      "Train: [epoch:816]  [ 20/172]  eta: 0:04:08  lr: 0.000021  loss: 0.8707 (0.8812)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [ 30/172]  eta: 0:03:49  lr: 0.000021  loss: 0.8954 (0.8898)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [ 40/172]  eta: 0:03:32  lr: 0.000021  loss: 0.9042 (0.8930)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [ 50/172]  eta: 0:03:15  lr: 0.000021  loss: 0.8823 (0.8887)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [ 60/172]  eta: 0:02:58  lr: 0.000021  loss: 0.8906 (0.8929)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [ 70/172]  eta: 0:02:42  lr: 0.000021  loss: 0.8968 (0.8934)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [ 80/172]  eta: 0:02:26  lr: 0.000021  loss: 0.8737 (0.8918)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [ 90/172]  eta: 0:02:10  lr: 0.000021  loss: 0.8672 (0.8923)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [100/172]  eta: 0:01:54  lr: 0.000021  loss: 0.8746 (0.8919)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:816]  [110/172]  eta: 0:01:38  lr: 0.000021  loss: 0.8964 (0.8957)  time: 1.5796  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:816]  [120/172]  eta: 0:01:22  lr: 0.000021  loss: 0.9027 (0.8968)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [130/172]  eta: 0:01:06  lr: 0.000021  loss: 0.9011 (0.8972)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [140/172]  eta: 0:00:50  lr: 0.000021  loss: 0.8859 (0.8976)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [150/172]  eta: 0:00:34  lr: 0.000021  loss: 0.8889 (0.8977)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [160/172]  eta: 0:00:19  lr: 0.000021  loss: 0.8931 (0.8988)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [170/172]  eta: 0:00:03  lr: 0.000021  loss: 0.8900 (0.8982)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816]  [171/172]  eta: 0:00:01  lr: 0.000021  loss: 0.8900 (0.8988)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:816] Total time: 0:04:32 (1.5847 s / it)\n",
      "Averaged stats: lr: 0.000021  loss: 0.8900 (0.8988)\n",
      "Valid: [epoch:816]  [ 0/14]  eta: 0:00:04  loss: 0.8997 (0.8997)  time: 0.3409  data: 0.3243  max mem: 20571\n",
      "Valid: [epoch:816]  [13/14]  eta: 0:00:00  loss: 0.8461 (0.8563)  time: 0.0392  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:816] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.8461 (0.8563)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_816_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.856%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:817]  [  0/172]  eta: 0:07:21  lr: 0.000020  loss: 0.8780 (0.8780)  time: 2.5693  data: 0.9969  max mem: 20571\n",
      "Train: [epoch:817]  [ 10/172]  eta: 0:04:29  lr: 0.000020  loss: 0.9012 (0.8892)  time: 1.6629  data: 0.0907  max mem: 20571\n",
      "Train: [epoch:817]  [ 20/172]  eta: 0:04:06  lr: 0.000020  loss: 0.9033 (0.9005)  time: 1.5737  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [ 30/172]  eta: 0:03:48  lr: 0.000020  loss: 0.9105 (0.9024)  time: 1.5756  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [ 40/172]  eta: 0:03:31  lr: 0.000020  loss: 0.9105 (0.9069)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [ 50/172]  eta: 0:03:14  lr: 0.000020  loss: 0.9125 (0.9131)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [ 60/172]  eta: 0:02:58  lr: 0.000020  loss: 0.9095 (0.9104)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [ 70/172]  eta: 0:02:42  lr: 0.000020  loss: 0.9021 (0.9107)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.8843 (0.9039)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.8578 (0.9008)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.8962 (0.9016)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.8917 (0.8998)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.8886 (0.8994)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.8826 (0.8977)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.8745 (0.8965)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [150/172]  eta: 0:00:34  lr: 0.000020  loss: 0.8731 (0.8948)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.8745 (0.8957)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.8814 (0.8947)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.8814 (0.8948)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:817] Total time: 0:04:32 (1.5837 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.8814 (0.8948)\n",
      "Valid: [epoch:817]  [ 0/14]  eta: 0:00:05  loss: 0.8996 (0.8996)  time: 0.4149  data: 0.3976  max mem: 20571\n",
      "Valid: [epoch:817]  [13/14]  eta: 0:00:00  loss: 0.8538 (0.8651)  time: 0.0450  data: 0.0299  max mem: 20571\n",
      "Valid: [epoch:817] Total time: 0:00:00 (0.0498 s / it)\n",
      "Averaged stats: loss: 0.8538 (0.8651)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_817_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.865%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:818]  [  0/172]  eta: 0:07:16  lr: 0.000020  loss: 0.8600 (0.8600)  time: 2.5373  data: 0.9730  max mem: 20571\n",
      "Train: [epoch:818]  [ 10/172]  eta: 0:04:29  lr: 0.000020  loss: 0.8863 (0.8777)  time: 1.6653  data: 0.0886  max mem: 20571\n",
      "Train: [epoch:818]  [ 20/172]  eta: 0:04:06  lr: 0.000020  loss: 0.8863 (0.8855)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [ 30/172]  eta: 0:03:48  lr: 0.000020  loss: 0.8840 (0.8807)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [ 40/172]  eta: 0:03:31  lr: 0.000020  loss: 0.8967 (0.8928)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [ 50/172]  eta: 0:03:14  lr: 0.000020  loss: 0.8967 (0.8904)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [ 60/172]  eta: 0:02:58  lr: 0.000020  loss: 0.8698 (0.8878)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [ 70/172]  eta: 0:02:42  lr: 0.000020  loss: 0.8849 (0.8900)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.8966 (0.8939)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.9106 (0.8948)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.9110 (0.8978)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.8898 (0.8965)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.8779 (0.8959)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.8583 (0.8938)  time: 1.5776  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:818]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.8678 (0.8951)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [150/172]  eta: 0:00:34  lr: 0.000020  loss: 0.9084 (0.8948)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.8818 (0.8950)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.8866 (0.8951)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.8955 (0.8955)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:818] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.8955 (0.8955)\n",
      "Valid: [epoch:818]  [ 0/14]  eta: 0:00:04  loss: 0.8905 (0.8905)  time: 0.3410  data: 0.3255  max mem: 20571\n",
      "Valid: [epoch:818]  [13/14]  eta: 0:00:00  loss: 0.8466 (0.8584)  time: 0.0413  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:818] Total time: 0:00:00 (0.0494 s / it)\n",
      "Averaged stats: loss: 0.8466 (0.8584)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_818_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.858%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:819]  [  0/172]  eta: 0:07:39  lr: 0.000020  loss: 0.9487 (0.9487)  time: 2.6728  data: 1.0947  max mem: 20571\n",
      "Train: [epoch:819]  [ 10/172]  eta: 0:04:31  lr: 0.000020  loss: 0.8715 (0.8853)  time: 1.6732  data: 0.0996  max mem: 20571\n",
      "Train: [epoch:819]  [ 20/172]  eta: 0:04:07  lr: 0.000020  loss: 0.8813 (0.8881)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [ 30/172]  eta: 0:03:48  lr: 0.000020  loss: 0.8813 (0.8829)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [ 40/172]  eta: 0:03:31  lr: 0.000020  loss: 0.8574 (0.8797)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [ 50/172]  eta: 0:03:14  lr: 0.000020  loss: 0.8851 (0.8904)  time: 1.5769  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:819]  [ 60/172]  eta: 0:02:58  lr: 0.000020  loss: 0.8851 (0.8912)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [ 70/172]  eta: 0:02:42  lr: 0.000020  loss: 0.8850 (0.8949)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.9239 (0.8983)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.9211 (0.9006)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.8910 (0.8994)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.8833 (0.8985)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.8925 (0.8992)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.8917 (0.8991)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.8901 (0.8993)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [150/172]  eta: 0:00:34  lr: 0.000020  loss: 0.8983 (0.8996)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.8900 (0.8990)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.8898 (0.8988)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.8898 (0.8989)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:819] Total time: 0:04:32 (1.5848 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.8898 (0.8989)\n",
      "Valid: [epoch:819]  [ 0/14]  eta: 0:00:04  loss: 0.9324 (0.9324)  time: 0.3108  data: 0.2954  max mem: 20571\n",
      "Valid: [epoch:819]  [13/14]  eta: 0:00:00  loss: 0.8455 (0.8573)  time: 0.0372  data: 0.0221  max mem: 20571\n",
      "Valid: [epoch:819] Total time: 0:00:00 (0.0439 s / it)\n",
      "Averaged stats: loss: 0.8455 (0.8573)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_819_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.857%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:820]  [  0/172]  eta: 0:07:48  lr: 0.000020  loss: 0.9307 (0.9307)  time: 2.7265  data: 1.1574  max mem: 20571\n",
      "Train: [epoch:820]  [ 10/172]  eta: 0:04:32  lr: 0.000020  loss: 0.8807 (0.8824)  time: 1.6837  data: 0.1054  max mem: 20571\n",
      "Train: [epoch:820]  [ 20/172]  eta: 0:04:08  lr: 0.000020  loss: 0.8807 (0.9005)  time: 1.5802  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:820]  [ 30/172]  eta: 0:03:49  lr: 0.000020  loss: 0.8914 (0.8999)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:820]  [ 40/172]  eta: 0:03:32  lr: 0.000020  loss: 0.8944 (0.9052)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:820]  [ 50/172]  eta: 0:03:15  lr: 0.000020  loss: 0.9160 (0.9068)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [ 60/172]  eta: 0:02:59  lr: 0.000020  loss: 0.9093 (0.9086)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [ 70/172]  eta: 0:02:42  lr: 0.000020  loss: 0.9039 (0.9049)  time: 1.5798  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:820]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.8829 (0.9039)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.8787 (0.9009)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.8622 (0.8983)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.8774 (0.8991)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.9004 (0.8982)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.9062 (0.9013)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.9125 (0.8998)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [150/172]  eta: 0:00:34  lr: 0.000020  loss: 0.8953 (0.8996)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.8970 (0.8990)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.8783 (0.8974)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.8783 (0.8977)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:820] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.8783 (0.8977)\n",
      "Valid: [epoch:820]  [ 0/14]  eta: 0:00:04  loss: 0.8947 (0.8947)  time: 0.2938  data: 0.2765  max mem: 20571\n",
      "Valid: [epoch:820]  [13/14]  eta: 0:00:00  loss: 0.8482 (0.8593)  time: 0.0469  data: 0.0317  max mem: 20571\n",
      "Valid: [epoch:820] Total time: 0:00:00 (0.0554 s / it)\n",
      "Averaged stats: loss: 0.8482 (0.8593)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_820_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.859%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:821]  [  0/172]  eta: 0:07:37  lr: 0.000020  loss: 0.8980 (0.8980)  time: 2.6621  data: 1.0863  max mem: 20571\n",
      "Train: [epoch:821]  [ 10/172]  eta: 0:04:31  lr: 0.000020  loss: 0.8927 (0.8962)  time: 1.6744  data: 0.0988  max mem: 20571\n",
      "Train: [epoch:821]  [ 20/172]  eta: 0:04:07  lr: 0.000020  loss: 0.8898 (0.8970)  time: 1.5760  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [ 30/172]  eta: 0:03:48  lr: 0.000020  loss: 0.8890 (0.8947)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [ 40/172]  eta: 0:03:31  lr: 0.000020  loss: 0.8754 (0.8877)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [ 50/172]  eta: 0:03:15  lr: 0.000020  loss: 0.8694 (0.8891)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [ 60/172]  eta: 0:02:58  lr: 0.000020  loss: 0.8930 (0.8904)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [ 70/172]  eta: 0:02:42  lr: 0.000020  loss: 0.8995 (0.8906)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.8995 (0.8956)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.9160 (0.8967)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.8914 (0.8980)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.8914 (0.8986)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.8863 (0.8988)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.8863 (0.9004)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.8878 (0.8987)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [150/172]  eta: 0:00:34  lr: 0.000020  loss: 0.8879 (0.8991)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.8985 (0.8986)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.8920 (0.9001)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.8916 (0.8997)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:821] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.8916 (0.8997)\n",
      "Valid: [epoch:821]  [ 0/14]  eta: 0:00:05  loss: 0.7889 (0.7889)  time: 0.3634  data: 0.3461  max mem: 20571\n",
      "Valid: [epoch:821]  [13/14]  eta: 0:00:00  loss: 0.8503 (0.8625)  time: 0.0417  data: 0.0264  max mem: 20571\n",
      "Valid: [epoch:821] Total time: 0:00:00 (0.0495 s / it)\n",
      "Averaged stats: loss: 0.8503 (0.8625)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_821_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.862%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:822]  [  0/172]  eta: 0:07:58  lr: 0.000020  loss: 0.8943 (0.8943)  time: 2.7843  data: 1.2180  max mem: 20571\n",
      "Train: [epoch:822]  [ 10/172]  eta: 0:04:33  lr: 0.000020  loss: 0.9058 (0.9154)  time: 1.6875  data: 0.1108  max mem: 20571\n",
      "Train: [epoch:822]  [ 20/172]  eta: 0:04:08  lr: 0.000020  loss: 0.9159 (0.9162)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [ 30/172]  eta: 0:03:49  lr: 0.000020  loss: 0.9104 (0.9148)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [ 40/172]  eta: 0:03:32  lr: 0.000020  loss: 0.8915 (0.9073)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [ 50/172]  eta: 0:03:15  lr: 0.000020  loss: 0.8877 (0.9057)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [ 60/172]  eta: 0:02:59  lr: 0.000020  loss: 0.8776 (0.9018)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [ 70/172]  eta: 0:02:42  lr: 0.000020  loss: 0.8797 (0.8998)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.8863 (0.9002)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.8805 (0.8998)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.8968 (0.9011)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.8954 (0.9018)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.8946 (0.9018)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.9032 (0.9031)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.9062 (0.9031)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [150/172]  eta: 0:00:34  lr: 0.000020  loss: 0.9024 (0.9032)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.8930 (0.9024)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.8673 (0.9001)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.8679 (0.9000)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:822] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.8679 (0.9000)\n",
      "Valid: [epoch:822]  [ 0/14]  eta: 0:00:04  loss: 0.9055 (0.9055)  time: 0.3137  data: 0.2974  max mem: 20571\n",
      "Valid: [epoch:822]  [13/14]  eta: 0:00:00  loss: 0.8494 (0.8613)  time: 0.0473  data: 0.0322  max mem: 20571\n",
      "Valid: [epoch:822] Total time: 0:00:00 (0.0531 s / it)\n",
      "Averaged stats: loss: 0.8494 (0.8613)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_822_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.861%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:823]  [  0/172]  eta: 0:07:39  lr: 0.000020  loss: 1.0053 (1.0053)  time: 2.6708  data: 1.0921  max mem: 20571\n",
      "Train: [epoch:823]  [ 10/172]  eta: 0:04:31  lr: 0.000020  loss: 0.9069 (0.9118)  time: 1.6786  data: 0.0994  max mem: 20571\n",
      "Train: [epoch:823]  [ 20/172]  eta: 0:04:08  lr: 0.000020  loss: 0.9036 (0.9068)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [ 30/172]  eta: 0:03:49  lr: 0.000020  loss: 0.9000 (0.9063)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [ 40/172]  eta: 0:03:32  lr: 0.000020  loss: 0.8993 (0.9042)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [ 50/172]  eta: 0:03:15  lr: 0.000020  loss: 0.8913 (0.9022)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [ 60/172]  eta: 0:02:59  lr: 0.000020  loss: 0.8883 (0.9028)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [ 70/172]  eta: 0:02:42  lr: 0.000020  loss: 0.8969 (0.9041)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.8841 (0.9038)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.8818 (0.9059)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.9079 (0.9091)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.9140 (0.9090)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.9166 (0.9094)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.9120 (0.9087)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.9078 (0.9085)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [150/172]  eta: 0:00:34  lr: 0.000020  loss: 0.9029 (0.9069)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.8712 (0.9056)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.8712 (0.9045)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.8712 (0.9047)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:823] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.8712 (0.9047)\n",
      "Valid: [epoch:823]  [ 0/14]  eta: 0:00:06  loss: 0.9045 (0.9045)  time: 0.4751  data: 0.4598  max mem: 20571\n",
      "Valid: [epoch:823]  [13/14]  eta: 0:00:00  loss: 0.8501 (0.8615)  time: 0.0507  data: 0.0356  max mem: 20571\n",
      "Valid: [epoch:823] Total time: 0:00:00 (0.0597 s / it)\n",
      "Averaged stats: loss: 0.8501 (0.8615)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_823_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.861%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:824]  [  0/172]  eta: 0:07:52  lr: 0.000020  loss: 0.9304 (0.9304)  time: 2.7468  data: 1.1648  max mem: 20571\n",
      "Train: [epoch:824]  [ 10/172]  eta: 0:04:33  lr: 0.000020  loss: 0.9033 (0.9102)  time: 1.6874  data: 0.1061  max mem: 20571\n",
      "Train: [epoch:824]  [ 20/172]  eta: 0:04:08  lr: 0.000020  loss: 0.8838 (0.9090)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:824]  [ 30/172]  eta: 0:03:49  lr: 0.000020  loss: 0.8718 (0.8958)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [ 40/172]  eta: 0:03:32  lr: 0.000020  loss: 0.8959 (0.8993)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [ 50/172]  eta: 0:03:15  lr: 0.000020  loss: 0.9127 (0.9051)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [ 60/172]  eta: 0:02:59  lr: 0.000020  loss: 0.9145 (0.9096)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [ 70/172]  eta: 0:02:43  lr: 0.000020  loss: 0.8857 (0.9069)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.8760 (0.9060)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.8841 (0.9076)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.8837 (0.9045)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.8797 (0.9070)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.8906 (0.9060)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.8815 (0.9049)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.8760 (0.9032)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [150/172]  eta: 0:00:34  lr: 0.000020  loss: 0.8649 (0.9015)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.8778 (0.9007)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.8792 (0.9010)  time: 1.5807  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:824]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.8778 (0.9009)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:824] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.8778 (0.9009)\n",
      "Valid: [epoch:824]  [ 0/14]  eta: 0:00:05  loss: 0.9401 (0.9401)  time: 0.3654  data: 0.3496  max mem: 20571\n",
      "Valid: [epoch:824]  [13/14]  eta: 0:00:00  loss: 0.8528 (0.8652)  time: 0.0413  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:824] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.8528 (0.8652)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_824_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.865%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:825]  [  0/172]  eta: 0:07:36  lr: 0.000020  loss: 0.9254 (0.9254)  time: 2.6513  data: 1.0818  max mem: 20571\n",
      "Train: [epoch:825]  [ 10/172]  eta: 0:04:30  lr: 0.000020  loss: 0.9135 (0.9038)  time: 1.6720  data: 0.0984  max mem: 20571\n",
      "Train: [epoch:825]  [ 20/172]  eta: 0:04:07  lr: 0.000020  loss: 0.9135 (0.9162)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [ 30/172]  eta: 0:03:48  lr: 0.000020  loss: 0.9045 (0.9091)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [ 40/172]  eta: 0:03:31  lr: 0.000020  loss: 0.8906 (0.9099)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [ 50/172]  eta: 0:03:14  lr: 0.000020  loss: 0.8826 (0.9014)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [ 60/172]  eta: 0:02:58  lr: 0.000020  loss: 0.8675 (0.9018)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [ 70/172]  eta: 0:02:42  lr: 0.000020  loss: 0.9182 (0.9048)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [ 80/172]  eta: 0:02:26  lr: 0.000020  loss: 0.9023 (0.9038)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [ 90/172]  eta: 0:02:10  lr: 0.000020  loss: 0.8820 (0.9025)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [100/172]  eta: 0:01:54  lr: 0.000020  loss: 0.8964 (0.9026)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [110/172]  eta: 0:01:38  lr: 0.000020  loss: 0.8849 (0.9001)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [120/172]  eta: 0:01:22  lr: 0.000020  loss: 0.8971 (0.9024)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [130/172]  eta: 0:01:06  lr: 0.000020  loss: 0.9246 (0.9050)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [140/172]  eta: 0:00:50  lr: 0.000020  loss: 0.8817 (0.9022)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [150/172]  eta: 0:00:34  lr: 0.000020  loss: 0.8687 (0.9022)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [160/172]  eta: 0:00:19  lr: 0.000020  loss: 0.9016 (0.9029)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [170/172]  eta: 0:00:03  lr: 0.000020  loss: 0.9037 (0.9030)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825]  [171/172]  eta: 0:00:01  lr: 0.000020  loss: 0.9037 (0.9029)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:825] Total time: 0:04:32 (1.5854 s / it)\n",
      "Averaged stats: lr: 0.000020  loss: 0.9037 (0.9029)\n",
      "Valid: [epoch:825]  [ 0/14]  eta: 0:00:04  loss: 0.8355 (0.8355)  time: 0.3269  data: 0.3097  max mem: 20571\n",
      "Valid: [epoch:825]  [13/14]  eta: 0:00:00  loss: 0.8531 (0.8643)  time: 0.0389  data: 0.0237  max mem: 20571\n",
      "Valid: [epoch:825] Total time: 0:00:00 (0.0438 s / it)\n",
      "Averaged stats: loss: 0.8531 (0.8643)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_825_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.864%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:826]  [  0/172]  eta: 0:08:02  lr: 0.000019  loss: 0.9397 (0.9397)  time: 2.8044  data: 1.2362  max mem: 20571\n",
      "Train: [epoch:826]  [ 10/172]  eta: 0:04:33  lr: 0.000019  loss: 0.8873 (0.8823)  time: 1.6902  data: 0.1125  max mem: 20571\n",
      "Train: [epoch:826]  [ 20/172]  eta: 0:04:09  lr: 0.000019  loss: 0.8800 (0.8839)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [ 30/172]  eta: 0:03:50  lr: 0.000019  loss: 0.9032 (0.8925)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [ 40/172]  eta: 0:03:32  lr: 0.000019  loss: 0.9047 (0.8952)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [ 50/172]  eta: 0:03:15  lr: 0.000019  loss: 0.8968 (0.8992)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [ 60/172]  eta: 0:02:59  lr: 0.000019  loss: 0.9114 (0.9005)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [ 70/172]  eta: 0:02:42  lr: 0.000019  loss: 0.9208 (0.9049)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [ 80/172]  eta: 0:02:26  lr: 0.000019  loss: 0.9089 (0.9047)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [ 90/172]  eta: 0:02:10  lr: 0.000019  loss: 0.8976 (0.9063)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [100/172]  eta: 0:01:54  lr: 0.000019  loss: 0.9187 (0.9064)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [110/172]  eta: 0:01:38  lr: 0.000019  loss: 0.9060 (0.9048)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [120/172]  eta: 0:01:22  lr: 0.000019  loss: 0.9016 (0.9042)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [130/172]  eta: 0:01:06  lr: 0.000019  loss: 0.9037 (0.9057)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [140/172]  eta: 0:00:50  lr: 0.000019  loss: 0.9015 (0.9048)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [150/172]  eta: 0:00:34  lr: 0.000019  loss: 0.8788 (0.9031)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [160/172]  eta: 0:00:19  lr: 0.000019  loss: 0.8749 (0.9048)  time: 1.5757  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [170/172]  eta: 0:00:03  lr: 0.000019  loss: 0.9210 (0.9051)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826]  [171/172]  eta: 0:00:01  lr: 0.000019  loss: 0.9210 (0.9052)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:826] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000019  loss: 0.9210 (0.9052)\n",
      "Valid: [epoch:826]  [ 0/14]  eta: 0:00:06  loss: 0.8998 (0.8998)  time: 0.4869  data: 0.4703  max mem: 20571\n",
      "Valid: [epoch:826]  [13/14]  eta: 0:00:00  loss: 0.8528 (0.8640)  time: 0.0497  data: 0.0346  max mem: 20571\n",
      "Valid: [epoch:826] Total time: 0:00:00 (0.0550 s / it)\n",
      "Averaged stats: loss: 0.8528 (0.8640)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_826_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.864%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:827]  [  0/172]  eta: 0:07:38  lr: 0.000019  loss: 0.8584 (0.8584)  time: 2.6663  data: 1.0952  max mem: 20571\n",
      "Train: [epoch:827]  [ 10/172]  eta: 0:04:30  lr: 0.000019  loss: 0.8768 (0.8953)  time: 1.6712  data: 0.0997  max mem: 20571\n",
      "Train: [epoch:827]  [ 20/172]  eta: 0:04:06  lr: 0.000019  loss: 0.8950 (0.9078)  time: 1.5725  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [ 30/172]  eta: 0:03:48  lr: 0.000019  loss: 0.9149 (0.9097)  time: 1.5731  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [ 40/172]  eta: 0:03:31  lr: 0.000019  loss: 0.8960 (0.9041)  time: 1.5738  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [ 50/172]  eta: 0:03:14  lr: 0.000019  loss: 0.8865 (0.9028)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [ 60/172]  eta: 0:02:58  lr: 0.000019  loss: 0.9027 (0.9036)  time: 1.5739  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [ 70/172]  eta: 0:02:42  lr: 0.000019  loss: 0.9073 (0.9028)  time: 1.5732  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [ 80/172]  eta: 0:02:26  lr: 0.000019  loss: 0.9140 (0.9040)  time: 1.5738  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [ 90/172]  eta: 0:02:10  lr: 0.000019  loss: 0.8971 (0.9019)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [100/172]  eta: 0:01:54  lr: 0.000019  loss: 0.8914 (0.9016)  time: 1.5755  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [110/172]  eta: 0:01:38  lr: 0.000019  loss: 0.8905 (0.8999)  time: 1.5767  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:827]  [120/172]  eta: 0:01:22  lr: 0.000019  loss: 0.8913 (0.9024)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [130/172]  eta: 0:01:06  lr: 0.000019  loss: 0.9019 (0.9014)  time: 1.5733  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [140/172]  eta: 0:00:50  lr: 0.000019  loss: 0.8914 (0.9022)  time: 1.5731  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [150/172]  eta: 0:00:34  lr: 0.000019  loss: 0.9242 (0.9047)  time: 1.5727  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [160/172]  eta: 0:00:18  lr: 0.000019  loss: 0.9242 (0.9049)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [170/172]  eta: 0:00:03  lr: 0.000019  loss: 0.9110 (0.9055)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827]  [171/172]  eta: 0:00:01  lr: 0.000019  loss: 0.9114 (0.9059)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:827] Total time: 0:04:31 (1.5810 s / it)\n",
      "Averaged stats: lr: 0.000019  loss: 0.9114 (0.9059)\n",
      "Valid: [epoch:827]  [ 0/14]  eta: 0:00:04  loss: 0.8541 (0.8541)  time: 0.3336  data: 0.3189  max mem: 20571\n",
      "Valid: [epoch:827]  [13/14]  eta: 0:00:00  loss: 0.8541 (0.8652)  time: 0.0394  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:827] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.8541 (0.8652)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_827_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.865%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:828]  [  0/172]  eta: 0:07:26  lr: 0.000019  loss: 0.8935 (0.8935)  time: 2.5972  data: 1.0338  max mem: 20571\n",
      "Train: [epoch:828]  [ 10/172]  eta: 0:04:29  lr: 0.000019  loss: 0.9263 (0.9164)  time: 1.6655  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:828]  [ 20/172]  eta: 0:04:06  lr: 0.000019  loss: 0.9263 (0.9231)  time: 1.5739  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:828]  [ 30/172]  eta: 0:03:48  lr: 0.000019  loss: 0.9155 (0.9251)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [ 40/172]  eta: 0:03:31  lr: 0.000019  loss: 0.8976 (0.9157)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [ 50/172]  eta: 0:03:14  lr: 0.000019  loss: 0.8826 (0.9121)  time: 1.5754  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [ 60/172]  eta: 0:02:58  lr: 0.000019  loss: 0.8791 (0.9058)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [ 70/172]  eta: 0:02:42  lr: 0.000019  loss: 0.8802 (0.9064)  time: 1.5739  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [ 80/172]  eta: 0:02:26  lr: 0.000019  loss: 0.8920 (0.9036)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [ 90/172]  eta: 0:02:10  lr: 0.000019  loss: 0.8737 (0.9008)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [100/172]  eta: 0:01:54  lr: 0.000019  loss: 0.8871 (0.9024)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [110/172]  eta: 0:01:38  lr: 0.000019  loss: 0.9040 (0.9038)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [120/172]  eta: 0:01:22  lr: 0.000019  loss: 0.9040 (0.9037)  time: 1.5750  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [130/172]  eta: 0:01:06  lr: 0.000019  loss: 0.9034 (0.9039)  time: 1.5752  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [140/172]  eta: 0:00:50  lr: 0.000019  loss: 0.8999 (0.9052)  time: 1.5762  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [150/172]  eta: 0:00:34  lr: 0.000019  loss: 0.8967 (0.9062)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [160/172]  eta: 0:00:18  lr: 0.000019  loss: 0.8967 (0.9059)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [170/172]  eta: 0:00:03  lr: 0.000019  loss: 0.8837 (0.9048)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828]  [171/172]  eta: 0:00:01  lr: 0.000019  loss: 0.8837 (0.9052)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:828] Total time: 0:04:32 (1.5820 s / it)\n",
      "Averaged stats: lr: 0.000019  loss: 0.8837 (0.9052)\n",
      "Valid: [epoch:828]  [ 0/14]  eta: 0:00:04  loss: 0.8513 (0.8513)  time: 0.3084  data: 0.2932  max mem: 20571\n",
      "Valid: [epoch:828]  [13/14]  eta: 0:00:00  loss: 0.8558 (0.8677)  time: 0.0371  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:828] Total time: 0:00:00 (0.0419 s / it)\n",
      "Averaged stats: loss: 0.8558 (0.8677)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_828_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.868%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:829]  [  0/172]  eta: 0:07:27  lr: 0.000019  loss: 0.8856 (0.8856)  time: 2.5999  data: 1.0018  max mem: 20571\n",
      "Train: [epoch:829]  [ 10/172]  eta: 0:04:29  lr: 0.000019  loss: 0.8856 (0.8905)  time: 1.6653  data: 0.0912  max mem: 20571\n",
      "Train: [epoch:829]  [ 20/172]  eta: 0:04:06  lr: 0.000019  loss: 0.8913 (0.9027)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [ 30/172]  eta: 0:03:48  lr: 0.000019  loss: 0.8912 (0.8986)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [ 40/172]  eta: 0:03:31  lr: 0.000019  loss: 0.8751 (0.8978)  time: 1.5735  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [ 50/172]  eta: 0:03:14  lr: 0.000019  loss: 0.8938 (0.8959)  time: 1.5740  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [ 60/172]  eta: 0:02:58  lr: 0.000019  loss: 0.8795 (0.8970)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [ 70/172]  eta: 0:02:42  lr: 0.000019  loss: 0.8973 (0.9031)  time: 1.5738  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [ 80/172]  eta: 0:02:25  lr: 0.000019  loss: 0.9110 (0.9058)  time: 1.5745  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [ 90/172]  eta: 0:02:09  lr: 0.000019  loss: 0.8964 (0.9035)  time: 1.5743  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [100/172]  eta: 0:01:54  lr: 0.000019  loss: 0.8964 (0.9061)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [110/172]  eta: 0:01:38  lr: 0.000019  loss: 0.9266 (0.9099)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [120/172]  eta: 0:01:22  lr: 0.000019  loss: 0.8980 (0.9087)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [130/172]  eta: 0:01:06  lr: 0.000019  loss: 0.8980 (0.9097)  time: 1.5738  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [140/172]  eta: 0:00:50  lr: 0.000019  loss: 0.8949 (0.9094)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [150/172]  eta: 0:00:34  lr: 0.000019  loss: 0.8949 (0.9097)  time: 1.5746  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [160/172]  eta: 0:00:18  lr: 0.000019  loss: 0.8929 (0.9085)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [170/172]  eta: 0:00:03  lr: 0.000019  loss: 0.8897 (0.9070)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829]  [171/172]  eta: 0:00:01  lr: 0.000019  loss: 0.8928 (0.9069)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:829] Total time: 0:04:32 (1.5816 s / it)\n",
      "Averaged stats: lr: 0.000019  loss: 0.8928 (0.9069)\n",
      "Valid: [epoch:829]  [ 0/14]  eta: 0:00:08  loss: 0.7749 (0.7749)  time: 0.5832  data: 0.5656  max mem: 20571\n",
      "Valid: [epoch:829]  [13/14]  eta: 0:00:00  loss: 0.8577 (0.8701)  time: 0.0559  data: 0.0405  max mem: 20571\n",
      "Valid: [epoch:829] Total time: 0:00:00 (0.0607 s / it)\n",
      "Averaged stats: loss: 0.8577 (0.8701)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_829_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.870%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:830]  [  0/172]  eta: 0:07:40  lr: 0.000019  loss: 0.8859 (0.8859)  time: 2.6775  data: 1.1143  max mem: 20571\n",
      "Train: [epoch:830]  [ 10/172]  eta: 0:04:31  lr: 0.000019  loss: 0.9240 (0.9135)  time: 1.6751  data: 0.1014  max mem: 20571\n",
      "Train: [epoch:830]  [ 20/172]  eta: 0:04:07  lr: 0.000019  loss: 0.9120 (0.9153)  time: 1.5748  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [ 30/172]  eta: 0:03:48  lr: 0.000019  loss: 0.8765 (0.9069)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [ 40/172]  eta: 0:03:31  lr: 0.000019  loss: 0.8761 (0.9031)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [ 50/172]  eta: 0:03:14  lr: 0.000019  loss: 0.8986 (0.9089)  time: 1.5752  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:830]  [ 60/172]  eta: 0:02:58  lr: 0.000019  loss: 0.8997 (0.9085)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [ 70/172]  eta: 0:02:42  lr: 0.000019  loss: 0.8997 (0.9072)  time: 1.5741  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [ 80/172]  eta: 0:02:26  lr: 0.000019  loss: 0.8888 (0.9040)  time: 1.5743  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [ 90/172]  eta: 0:02:10  lr: 0.000019  loss: 0.8888 (0.9034)  time: 1.5742  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [100/172]  eta: 0:01:54  lr: 0.000019  loss: 0.8995 (0.9041)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [110/172]  eta: 0:01:38  lr: 0.000019  loss: 0.9130 (0.9063)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [120/172]  eta: 0:01:22  lr: 0.000019  loss: 0.9355 (0.9087)  time: 1.5744  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [130/172]  eta: 0:01:06  lr: 0.000019  loss: 0.8902 (0.9074)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [140/172]  eta: 0:00:50  lr: 0.000019  loss: 0.8910 (0.9073)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [150/172]  eta: 0:00:34  lr: 0.000019  loss: 0.8915 (0.9083)  time: 1.5759  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [160/172]  eta: 0:00:18  lr: 0.000019  loss: 0.8928 (0.9088)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [170/172]  eta: 0:00:03  lr: 0.000019  loss: 0.8930 (0.9081)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830]  [171/172]  eta: 0:00:01  lr: 0.000019  loss: 0.8978 (0.9081)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:830] Total time: 0:04:32 (1.5821 s / it)\n",
      "Averaged stats: lr: 0.000019  loss: 0.8978 (0.9081)\n",
      "Valid: [epoch:830]  [ 0/14]  eta: 0:00:05  loss: 0.9053 (0.9053)  time: 0.3987  data: 0.3827  max mem: 20571\n",
      "Valid: [epoch:830]  [13/14]  eta: 0:00:00  loss: 0.8567 (0.8689)  time: 0.0436  data: 0.0285  max mem: 20571\n",
      "Valid: [epoch:830] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.8567 (0.8689)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_830_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.869%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:831]  [  0/172]  eta: 0:07:27  lr: 0.000019  loss: 0.8832 (0.8832)  time: 2.6007  data: 1.0231  max mem: 20571\n",
      "Train: [epoch:831]  [ 10/172]  eta: 0:04:29  lr: 0.000019  loss: 0.8832 (0.9041)  time: 1.6665  data: 0.0931  max mem: 20571\n",
      "Train: [epoch:831]  [ 20/172]  eta: 0:04:06  lr: 0.000019  loss: 0.9130 (0.9135)  time: 1.5747  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [ 30/172]  eta: 0:03:48  lr: 0.000019  loss: 0.9005 (0.9063)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [ 40/172]  eta: 0:03:31  lr: 0.000019  loss: 0.8989 (0.9074)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [ 50/172]  eta: 0:03:14  lr: 0.000019  loss: 0.9170 (0.9140)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [ 60/172]  eta: 0:02:58  lr: 0.000019  loss: 0.9135 (0.9152)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [ 70/172]  eta: 0:02:42  lr: 0.000019  loss: 0.8971 (0.9103)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [ 80/172]  eta: 0:02:26  lr: 0.000019  loss: 0.9081 (0.9112)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [ 90/172]  eta: 0:02:10  lr: 0.000019  loss: 0.9208 (0.9131)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [100/172]  eta: 0:01:54  lr: 0.000019  loss: 0.9280 (0.9128)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [110/172]  eta: 0:01:38  lr: 0.000019  loss: 0.8896 (0.9111)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [120/172]  eta: 0:01:22  lr: 0.000019  loss: 0.9006 (0.9134)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [130/172]  eta: 0:01:06  lr: 0.000019  loss: 0.9231 (0.9129)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [140/172]  eta: 0:00:50  lr: 0.000019  loss: 0.9093 (0.9131)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [150/172]  eta: 0:00:34  lr: 0.000019  loss: 0.8767 (0.9102)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [160/172]  eta: 0:00:19  lr: 0.000019  loss: 0.8738 (0.9086)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [170/172]  eta: 0:00:03  lr: 0.000019  loss: 0.9070 (0.9093)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831]  [171/172]  eta: 0:00:01  lr: 0.000019  loss: 0.9127 (0.9095)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:831] Total time: 0:04:32 (1.5852 s / it)\n",
      "Averaged stats: lr: 0.000019  loss: 0.9127 (0.9095)\n",
      "Valid: [epoch:831]  [ 0/14]  eta: 0:00:04  loss: 0.9169 (0.9169)  time: 0.2975  data: 0.2812  max mem: 20571\n",
      "Valid: [epoch:831]  [13/14]  eta: 0:00:00  loss: 0.8627 (0.8749)  time: 0.0397  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:831] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.8627 (0.8749)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_831_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.875%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:832]  [  0/172]  eta: 0:07:20  lr: 0.000019  loss: 0.8730 (0.8730)  time: 2.5602  data: 0.9945  max mem: 20571\n",
      "Train: [epoch:832]  [ 10/172]  eta: 0:04:30  lr: 0.000019  loss: 0.9034 (0.8957)  time: 1.6676  data: 0.0905  max mem: 20571\n",
      "Train: [epoch:832]  [ 20/172]  eta: 0:04:06  lr: 0.000019  loss: 0.9066 (0.9122)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [ 30/172]  eta: 0:03:48  lr: 0.000019  loss: 0.9066 (0.9116)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [ 40/172]  eta: 0:03:31  lr: 0.000019  loss: 0.8834 (0.9096)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [ 50/172]  eta: 0:03:14  lr: 0.000019  loss: 0.9122 (0.9145)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [ 60/172]  eta: 0:02:58  lr: 0.000019  loss: 0.9179 (0.9152)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [ 70/172]  eta: 0:02:42  lr: 0.000019  loss: 0.9120 (0.9156)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [ 80/172]  eta: 0:02:26  lr: 0.000019  loss: 0.9120 (0.9142)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [ 90/172]  eta: 0:02:10  lr: 0.000019  loss: 0.8984 (0.9137)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [100/172]  eta: 0:01:54  lr: 0.000019  loss: 0.8909 (0.9121)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [110/172]  eta: 0:01:38  lr: 0.000019  loss: 0.9078 (0.9138)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [120/172]  eta: 0:01:22  lr: 0.000019  loss: 0.9175 (0.9137)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [130/172]  eta: 0:01:06  lr: 0.000019  loss: 0.8970 (0.9117)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [140/172]  eta: 0:00:50  lr: 0.000019  loss: 0.8888 (0.9105)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [150/172]  eta: 0:00:34  lr: 0.000019  loss: 0.8889 (0.9109)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [160/172]  eta: 0:00:19  lr: 0.000019  loss: 0.9084 (0.9119)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [170/172]  eta: 0:00:03  lr: 0.000019  loss: 0.8761 (0.9110)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832]  [171/172]  eta: 0:00:01  lr: 0.000019  loss: 0.8761 (0.9108)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:832] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000019  loss: 0.8761 (0.9108)\n",
      "Valid: [epoch:832]  [ 0/14]  eta: 0:00:06  loss: 0.9051 (0.9051)  time: 0.4332  data: 0.4165  max mem: 20571\n",
      "Valid: [epoch:832]  [13/14]  eta: 0:00:00  loss: 0.8615 (0.8729)  time: 0.0458  data: 0.0308  max mem: 20571\n",
      "Valid: [epoch:832] Total time: 0:00:00 (0.0509 s / it)\n",
      "Averaged stats: loss: 0.8615 (0.8729)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_832_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.873%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:833]  [  0/172]  eta: 0:07:44  lr: 0.000019  loss: 0.8838 (0.8838)  time: 2.7029  data: 1.1222  max mem: 20571\n",
      "Train: [epoch:833]  [ 10/172]  eta: 0:04:31  lr: 0.000019  loss: 0.8805 (0.8941)  time: 1.6767  data: 0.1021  max mem: 20571\n",
      "Train: [epoch:833]  [ 20/172]  eta: 0:04:07  lr: 0.000019  loss: 0.8835 (0.9039)  time: 1.5753  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [ 30/172]  eta: 0:03:48  lr: 0.000019  loss: 0.9044 (0.9094)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [ 40/172]  eta: 0:03:31  lr: 0.000019  loss: 0.9046 (0.9084)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [ 50/172]  eta: 0:03:14  lr: 0.000019  loss: 0.9046 (0.9103)  time: 1.5767  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [ 60/172]  eta: 0:02:58  lr: 0.000019  loss: 0.9054 (0.9109)  time: 1.5774  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:833]  [ 70/172]  eta: 0:02:42  lr: 0.000019  loss: 0.8971 (0.9073)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [ 80/172]  eta: 0:02:26  lr: 0.000019  loss: 0.9004 (0.9089)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [ 90/172]  eta: 0:02:10  lr: 0.000019  loss: 0.9032 (0.9080)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [100/172]  eta: 0:01:54  lr: 0.000019  loss: 0.9033 (0.9093)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [110/172]  eta: 0:01:38  lr: 0.000019  loss: 0.9145 (0.9094)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [120/172]  eta: 0:01:22  lr: 0.000019  loss: 0.9168 (0.9089)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [130/172]  eta: 0:01:06  lr: 0.000019  loss: 0.8804 (0.9089)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [140/172]  eta: 0:00:50  lr: 0.000019  loss: 0.8845 (0.9085)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [150/172]  eta: 0:00:34  lr: 0.000019  loss: 0.8966 (0.9083)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [160/172]  eta: 0:00:19  lr: 0.000019  loss: 0.9130 (0.9087)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [170/172]  eta: 0:00:03  lr: 0.000019  loss: 0.9389 (0.9115)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833]  [171/172]  eta: 0:00:01  lr: 0.000019  loss: 0.9389 (0.9114)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:833] Total time: 0:04:32 (1.5851 s / it)\n",
      "Averaged stats: lr: 0.000019  loss: 0.9389 (0.9114)\n",
      "Valid: [epoch:833]  [ 0/14]  eta: 0:00:05  loss: 0.8615 (0.8615)  time: 0.3878  data: 0.3689  max mem: 20571\n",
      "Valid: [epoch:833]  [13/14]  eta: 0:00:00  loss: 0.8615 (0.8724)  time: 0.0426  data: 0.0272  max mem: 20571\n",
      "Valid: [epoch:833] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.8615 (0.8724)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_833_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.872%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:834]  [  0/172]  eta: 0:07:35  lr: 0.000019  loss: 0.8495 (0.8495)  time: 2.6470  data: 1.0718  max mem: 20571\n",
      "Train: [epoch:834]  [ 10/172]  eta: 0:04:31  lr: 0.000019  loss: 0.9402 (0.9318)  time: 1.6741  data: 0.0975  max mem: 20571\n",
      "Train: [epoch:834]  [ 20/172]  eta: 0:04:07  lr: 0.000019  loss: 0.9262 (0.9282)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [ 30/172]  eta: 0:03:48  lr: 0.000019  loss: 0.8907 (0.9168)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [ 40/172]  eta: 0:03:31  lr: 0.000019  loss: 0.8937 (0.9137)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [ 50/172]  eta: 0:03:15  lr: 0.000019  loss: 0.9040 (0.9181)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [ 60/172]  eta: 0:02:58  lr: 0.000019  loss: 0.9228 (0.9167)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [ 70/172]  eta: 0:02:42  lr: 0.000019  loss: 0.9122 (0.9174)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [ 80/172]  eta: 0:02:26  lr: 0.000019  loss: 0.8979 (0.9156)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [ 90/172]  eta: 0:02:10  lr: 0.000019  loss: 0.8951 (0.9126)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [100/172]  eta: 0:01:54  lr: 0.000019  loss: 0.8887 (0.9112)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [110/172]  eta: 0:01:38  lr: 0.000019  loss: 0.9087 (0.9132)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [120/172]  eta: 0:01:22  lr: 0.000019  loss: 0.9169 (0.9130)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [130/172]  eta: 0:01:06  lr: 0.000019  loss: 0.8945 (0.9137)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [140/172]  eta: 0:00:50  lr: 0.000019  loss: 0.8786 (0.9105)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [150/172]  eta: 0:00:34  lr: 0.000019  loss: 0.8823 (0.9098)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [160/172]  eta: 0:00:19  lr: 0.000019  loss: 0.9027 (0.9112)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [170/172]  eta: 0:00:03  lr: 0.000019  loss: 0.9316 (0.9113)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834]  [171/172]  eta: 0:00:01  lr: 0.000019  loss: 0.9055 (0.9110)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:834] Total time: 0:04:32 (1.5860 s / it)\n",
      "Averaged stats: lr: 0.000019  loss: 0.9055 (0.9110)\n",
      "Valid: [epoch:834]  [ 0/14]  eta: 0:00:03  loss: 0.9096 (0.9096)  time: 0.2743  data: 0.2593  max mem: 20571\n",
      "Valid: [epoch:834]  [13/14]  eta: 0:00:00  loss: 0.8620 (0.8736)  time: 0.0465  data: 0.0315  max mem: 20571\n",
      "Valid: [epoch:834] Total time: 0:00:00 (0.0520 s / it)\n",
      "Averaged stats: loss: 0.8620 (0.8736)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_834_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.874%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:835]  [  0/172]  eta: 0:07:37  lr: 0.000018  loss: 0.8934 (0.8934)  time: 2.6609  data: 1.0842  max mem: 20571\n",
      "Train: [epoch:835]  [ 10/172]  eta: 0:04:31  lr: 0.000018  loss: 0.8934 (0.8959)  time: 1.6750  data: 0.0986  max mem: 20571\n",
      "Train: [epoch:835]  [ 20/172]  eta: 0:04:07  lr: 0.000018  loss: 0.9366 (0.9268)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [ 30/172]  eta: 0:03:48  lr: 0.000018  loss: 0.8918 (0.9151)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [ 40/172]  eta: 0:03:31  lr: 0.000018  loss: 0.8842 (0.9125)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [ 50/172]  eta: 0:03:15  lr: 0.000018  loss: 0.9130 (0.9118)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [ 60/172]  eta: 0:02:58  lr: 0.000018  loss: 0.9250 (0.9149)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [ 70/172]  eta: 0:02:42  lr: 0.000018  loss: 0.9133 (0.9143)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [ 80/172]  eta: 0:02:26  lr: 0.000018  loss: 0.9169 (0.9156)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [ 90/172]  eta: 0:02:10  lr: 0.000018  loss: 0.9113 (0.9128)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [100/172]  eta: 0:01:54  lr: 0.000018  loss: 0.9049 (0.9142)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [110/172]  eta: 0:01:38  lr: 0.000018  loss: 0.9170 (0.9163)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [120/172]  eta: 0:01:22  lr: 0.000018  loss: 0.8867 (0.9146)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [130/172]  eta: 0:01:06  lr: 0.000018  loss: 0.8936 (0.9157)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [140/172]  eta: 0:00:50  lr: 0.000018  loss: 0.8955 (0.9142)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [150/172]  eta: 0:00:34  lr: 0.000018  loss: 0.8972 (0.9147)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [160/172]  eta: 0:00:19  lr: 0.000018  loss: 0.8972 (0.9136)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835]  [170/172]  eta: 0:00:03  lr: 0.000018  loss: 0.8774 (0.9137)  time: 1.5811  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:835]  [171/172]  eta: 0:00:01  lr: 0.000018  loss: 0.8680 (0.9134)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:835] Total time: 0:04:32 (1.5861 s / it)\n",
      "Averaged stats: lr: 0.000018  loss: 0.8680 (0.9134)\n",
      "Valid: [epoch:835]  [ 0/14]  eta: 0:00:06  loss: 0.9195 (0.9195)  time: 0.4837  data: 0.4677  max mem: 20571\n",
      "Valid: [epoch:835]  [13/14]  eta: 0:00:00  loss: 0.8627 (0.8750)  time: 0.0499  data: 0.0349  max mem: 20571\n",
      "Valid: [epoch:835] Total time: 0:00:00 (0.0555 s / it)\n",
      "Averaged stats: loss: 0.8627 (0.8750)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_835_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.875%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:836]  [  0/172]  eta: 0:07:41  lr: 0.000018  loss: 0.8589 (0.8589)  time: 2.6816  data: 1.1076  max mem: 20571\n",
      "Train: [epoch:836]  [ 10/172]  eta: 0:04:31  lr: 0.000018  loss: 0.9191 (0.9030)  time: 1.6785  data: 0.1008  max mem: 20571\n",
      "Train: [epoch:836]  [ 20/172]  eta: 0:04:07  lr: 0.000018  loss: 0.9240 (0.9207)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [ 30/172]  eta: 0:03:49  lr: 0.000018  loss: 0.9219 (0.9196)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [ 40/172]  eta: 0:03:31  lr: 0.000018  loss: 0.9186 (0.9152)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [ 50/172]  eta: 0:03:15  lr: 0.000018  loss: 0.9232 (0.9201)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [ 60/172]  eta: 0:02:58  lr: 0.000018  loss: 0.9173 (0.9163)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [ 70/172]  eta: 0:02:42  lr: 0.000018  loss: 0.8907 (0.9161)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [ 80/172]  eta: 0:02:26  lr: 0.000018  loss: 0.8859 (0.9147)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [ 90/172]  eta: 0:02:10  lr: 0.000018  loss: 0.8859 (0.9126)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [100/172]  eta: 0:01:54  lr: 0.000018  loss: 0.9116 (0.9126)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [110/172]  eta: 0:01:38  lr: 0.000018  loss: 0.9181 (0.9122)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [120/172]  eta: 0:01:22  lr: 0.000018  loss: 0.9119 (0.9133)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [130/172]  eta: 0:01:06  lr: 0.000018  loss: 0.8995 (0.9119)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [140/172]  eta: 0:00:50  lr: 0.000018  loss: 0.9036 (0.9121)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [150/172]  eta: 0:00:34  lr: 0.000018  loss: 0.9288 (0.9144)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [160/172]  eta: 0:00:19  lr: 0.000018  loss: 0.9128 (0.9132)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [170/172]  eta: 0:00:03  lr: 0.000018  loss: 0.8959 (0.9139)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836]  [171/172]  eta: 0:00:01  lr: 0.000018  loss: 0.8959 (0.9151)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:836] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000018  loss: 0.8959 (0.9151)\n",
      "Valid: [epoch:836]  [ 0/14]  eta: 0:00:04  loss: 0.7772 (0.7772)  time: 0.3027  data: 0.2878  max mem: 20571\n",
      "Valid: [epoch:836]  [13/14]  eta: 0:00:00  loss: 0.8618 (0.8736)  time: 0.0357  data: 0.0206  max mem: 20571\n",
      "Valid: [epoch:836] Total time: 0:00:00 (0.0410 s / it)\n",
      "Averaged stats: loss: 0.8618 (0.8736)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_836_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.874%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:837]  [  0/172]  eta: 0:07:44  lr: 0.000018  loss: 0.9570 (0.9570)  time: 2.6979  data: 1.1169  max mem: 20571\n",
      "Train: [epoch:837]  [ 10/172]  eta: 0:04:31  lr: 0.000018  loss: 0.9007 (0.9192)  time: 1.6782  data: 0.1016  max mem: 20571\n",
      "Train: [epoch:837]  [ 20/172]  eta: 0:04:07  lr: 0.000018  loss: 0.9007 (0.9134)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [ 30/172]  eta: 0:03:49  lr: 0.000018  loss: 0.9039 (0.9072)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [ 40/172]  eta: 0:03:31  lr: 0.000018  loss: 0.9033 (0.9102)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [ 50/172]  eta: 0:03:15  lr: 0.000018  loss: 0.9063 (0.9091)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [ 60/172]  eta: 0:02:58  lr: 0.000018  loss: 0.9110 (0.9157)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [ 70/172]  eta: 0:02:42  lr: 0.000018  loss: 0.8981 (0.9094)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [ 80/172]  eta: 0:02:26  lr: 0.000018  loss: 0.8807 (0.9125)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [ 90/172]  eta: 0:02:10  lr: 0.000018  loss: 0.9071 (0.9114)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [100/172]  eta: 0:01:54  lr: 0.000018  loss: 0.9071 (0.9120)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [110/172]  eta: 0:01:38  lr: 0.000018  loss: 0.9348 (0.9133)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [120/172]  eta: 0:01:22  lr: 0.000018  loss: 0.9273 (0.9146)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [130/172]  eta: 0:01:06  lr: 0.000018  loss: 0.9067 (0.9131)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [140/172]  eta: 0:00:50  lr: 0.000018  loss: 0.9067 (0.9135)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [150/172]  eta: 0:00:34  lr: 0.000018  loss: 0.9200 (0.9144)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [160/172]  eta: 0:00:19  lr: 0.000018  loss: 0.9113 (0.9138)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [170/172]  eta: 0:00:03  lr: 0.000018  loss: 0.9088 (0.9145)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837]  [171/172]  eta: 0:00:01  lr: 0.000018  loss: 0.9088 (0.9144)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:837] Total time: 0:04:32 (1.5853 s / it)\n",
      "Averaged stats: lr: 0.000018  loss: 0.9088 (0.9144)\n",
      "Valid: [epoch:837]  [ 0/14]  eta: 0:00:03  loss: 0.8594 (0.8594)  time: 0.2704  data: 0.2546  max mem: 20571\n",
      "Valid: [epoch:837]  [13/14]  eta: 0:00:00  loss: 0.8647 (0.8765)  time: 0.0414  data: 0.0265  max mem: 20571\n",
      "Valid: [epoch:837] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.8647 (0.8765)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_837_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.876%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:838]  [  0/172]  eta: 0:07:45  lr: 0.000018  loss: 0.8893 (0.8893)  time: 2.7038  data: 1.1386  max mem: 20571\n",
      "Train: [epoch:838]  [ 10/172]  eta: 0:04:32  lr: 0.000018  loss: 0.9001 (0.9160)  time: 1.6803  data: 0.1036  max mem: 20571\n",
      "Train: [epoch:838]  [ 20/172]  eta: 0:04:08  lr: 0.000018  loss: 0.9054 (0.9101)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [ 30/172]  eta: 0:03:49  lr: 0.000018  loss: 0.8998 (0.9070)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [ 40/172]  eta: 0:03:32  lr: 0.000018  loss: 0.8917 (0.9025)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [ 50/172]  eta: 0:03:15  lr: 0.000018  loss: 0.9220 (0.9067)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [ 60/172]  eta: 0:02:58  lr: 0.000018  loss: 0.9304 (0.9119)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [ 70/172]  eta: 0:02:42  lr: 0.000018  loss: 0.9399 (0.9164)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [ 80/172]  eta: 0:02:26  lr: 0.000018  loss: 0.8984 (0.9158)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [ 90/172]  eta: 0:02:10  lr: 0.000018  loss: 0.8906 (0.9147)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [100/172]  eta: 0:01:54  lr: 0.000018  loss: 0.9348 (0.9167)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [110/172]  eta: 0:01:38  lr: 0.000018  loss: 0.9348 (0.9165)  time: 1.5799  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:838]  [120/172]  eta: 0:01:22  lr: 0.000018  loss: 0.9254 (0.9163)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [130/172]  eta: 0:01:06  lr: 0.000018  loss: 0.9154 (0.9156)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [140/172]  eta: 0:00:50  lr: 0.000018  loss: 0.9020 (0.9161)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [150/172]  eta: 0:00:34  lr: 0.000018  loss: 0.9027 (0.9165)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [160/172]  eta: 0:00:19  lr: 0.000018  loss: 0.9167 (0.9160)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [170/172]  eta: 0:00:03  lr: 0.000018  loss: 0.9103 (0.9158)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838]  [171/172]  eta: 0:00:01  lr: 0.000018  loss: 0.9167 (0.9162)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:838] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000018  loss: 0.9167 (0.9162)\n",
      "Valid: [epoch:838]  [ 0/14]  eta: 0:00:04  loss: 0.8215 (0.8215)  time: 0.3099  data: 0.2937  max mem: 20571\n",
      "Valid: [epoch:838]  [13/14]  eta: 0:00:00  loss: 0.8639 (0.8760)  time: 0.0364  data: 0.0213  max mem: 20571\n",
      "Valid: [epoch:838] Total time: 0:00:00 (0.0412 s / it)\n",
      "Averaged stats: loss: 0.8639 (0.8760)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_838_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.876%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:839]  [  0/172]  eta: 0:07:16  lr: 0.000018  loss: 0.9031 (0.9031)  time: 2.5396  data: 0.9662  max mem: 20571\n",
      "Train: [epoch:839]  [ 10/172]  eta: 0:04:29  lr: 0.000018  loss: 0.9030 (0.8928)  time: 1.6641  data: 0.0879  max mem: 20571\n",
      "Train: [epoch:839]  [ 20/172]  eta: 0:04:06  lr: 0.000018  loss: 0.9085 (0.9164)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [ 30/172]  eta: 0:03:48  lr: 0.000018  loss: 0.9340 (0.9204)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [ 40/172]  eta: 0:03:31  lr: 0.000018  loss: 0.9174 (0.9164)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [ 50/172]  eta: 0:03:14  lr: 0.000018  loss: 0.9034 (0.9155)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [ 60/172]  eta: 0:02:58  lr: 0.000018  loss: 0.8993 (0.9128)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [ 70/172]  eta: 0:02:42  lr: 0.000018  loss: 0.8889 (0.9107)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [ 80/172]  eta: 0:02:26  lr: 0.000018  loss: 0.8941 (0.9099)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [ 90/172]  eta: 0:02:10  lr: 0.000018  loss: 0.8947 (0.9110)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [100/172]  eta: 0:01:54  lr: 0.000018  loss: 0.9086 (0.9117)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [110/172]  eta: 0:01:38  lr: 0.000018  loss: 0.9279 (0.9134)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [120/172]  eta: 0:01:22  lr: 0.000018  loss: 0.9175 (0.9131)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [130/172]  eta: 0:01:06  lr: 0.000018  loss: 0.9101 (0.9140)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [140/172]  eta: 0:00:50  lr: 0.000018  loss: 0.9101 (0.9135)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [150/172]  eta: 0:00:34  lr: 0.000018  loss: 0.9221 (0.9153)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [160/172]  eta: 0:00:19  lr: 0.000018  loss: 0.9151 (0.9151)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [170/172]  eta: 0:00:03  lr: 0.000018  loss: 0.9137 (0.9164)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839]  [171/172]  eta: 0:00:01  lr: 0.000018  loss: 0.9137 (0.9168)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:839] Total time: 0:04:32 (1.5857 s / it)\n",
      "Averaged stats: lr: 0.000018  loss: 0.9137 (0.9168)\n",
      "Valid: [epoch:839]  [ 0/14]  eta: 0:00:06  loss: 0.9199 (0.9199)  time: 0.4902  data: 0.4739  max mem: 20571\n",
      "Valid: [epoch:839]  [13/14]  eta: 0:00:00  loss: 0.8656 (0.8768)  time: 0.0522  data: 0.0372  max mem: 20571\n",
      "Valid: [epoch:839] Total time: 0:00:00 (0.0602 s / it)\n",
      "Averaged stats: loss: 0.8656 (0.8768)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_839_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.877%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:840]  [  0/172]  eta: 0:07:28  lr: 0.000018  loss: 0.8980 (0.8980)  time: 2.6062  data: 1.0400  max mem: 20571\n",
      "Train: [epoch:840]  [ 10/172]  eta: 0:04:30  lr: 0.000018  loss: 0.9096 (0.9239)  time: 1.6718  data: 0.0947  max mem: 20571\n",
      "Train: [epoch:840]  [ 20/172]  eta: 0:04:07  lr: 0.000018  loss: 0.9096 (0.9192)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [ 30/172]  eta: 0:03:48  lr: 0.000018  loss: 0.9205 (0.9265)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [ 40/172]  eta: 0:03:31  lr: 0.000018  loss: 0.9036 (0.9182)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [ 50/172]  eta: 0:03:14  lr: 0.000018  loss: 0.9019 (0.9205)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [ 60/172]  eta: 0:02:58  lr: 0.000018  loss: 0.9223 (0.9223)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [ 70/172]  eta: 0:02:42  lr: 0.000018  loss: 0.9282 (0.9229)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [ 80/172]  eta: 0:02:26  lr: 0.000018  loss: 0.9016 (0.9202)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [ 90/172]  eta: 0:02:10  lr: 0.000018  loss: 0.8948 (0.9194)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [100/172]  eta: 0:01:54  lr: 0.000018  loss: 0.9153 (0.9206)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [110/172]  eta: 0:01:38  lr: 0.000018  loss: 0.9199 (0.9208)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [120/172]  eta: 0:01:22  lr: 0.000018  loss: 0.9078 (0.9202)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [130/172]  eta: 0:01:06  lr: 0.000018  loss: 0.8912 (0.9187)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [140/172]  eta: 0:00:50  lr: 0.000018  loss: 0.8755 (0.9176)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [150/172]  eta: 0:00:34  lr: 0.000018  loss: 0.9098 (0.9175)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [160/172]  eta: 0:00:19  lr: 0.000018  loss: 0.9052 (0.9173)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [170/172]  eta: 0:00:03  lr: 0.000018  loss: 0.9029 (0.9185)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840]  [171/172]  eta: 0:00:01  lr: 0.000018  loss: 0.9052 (0.9191)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:840] Total time: 0:04:32 (1.5849 s / it)\n",
      "Averaged stats: lr: 0.000018  loss: 0.9052 (0.9191)\n",
      "Valid: [epoch:840]  [ 0/14]  eta: 0:00:04  loss: 0.8668 (0.8668)  time: 0.2946  data: 0.2801  max mem: 20571\n",
      "Valid: [epoch:840]  [13/14]  eta: 0:00:00  loss: 0.8668 (0.8788)  time: 0.0426  data: 0.0277  max mem: 20571\n",
      "Valid: [epoch:840] Total time: 0:00:00 (0.0475 s / it)\n",
      "Averaged stats: loss: 0.8668 (0.8788)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_840_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.879%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:841]  [  0/172]  eta: 0:07:40  lr: 0.000018  loss: 0.9609 (0.9609)  time: 2.6759  data: 1.0951  max mem: 20571\n",
      "Train: [epoch:841]  [ 10/172]  eta: 0:04:31  lr: 0.000018  loss: 0.9295 (0.9196)  time: 1.6760  data: 0.0997  max mem: 20571\n",
      "Train: [epoch:841]  [ 20/172]  eta: 0:04:07  lr: 0.000018  loss: 0.9142 (0.9261)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [ 30/172]  eta: 0:03:49  lr: 0.000018  loss: 0.8963 (0.9162)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [ 40/172]  eta: 0:03:31  lr: 0.000018  loss: 0.8872 (0.9132)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [ 50/172]  eta: 0:03:15  lr: 0.000018  loss: 0.8990 (0.9213)  time: 1.5797  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:841]  [ 60/172]  eta: 0:02:58  lr: 0.000018  loss: 0.9181 (0.9224)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [ 70/172]  eta: 0:02:42  lr: 0.000018  loss: 0.9155 (0.9200)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [ 80/172]  eta: 0:02:26  lr: 0.000018  loss: 0.9141 (0.9212)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [ 90/172]  eta: 0:02:10  lr: 0.000018  loss: 0.9227 (0.9204)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [100/172]  eta: 0:01:54  lr: 0.000018  loss: 0.9177 (0.9197)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [110/172]  eta: 0:01:38  lr: 0.000018  loss: 0.9069 (0.9198)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [120/172]  eta: 0:01:22  lr: 0.000018  loss: 0.9076 (0.9218)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [130/172]  eta: 0:01:06  lr: 0.000018  loss: 0.9014 (0.9196)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [140/172]  eta: 0:00:50  lr: 0.000018  loss: 0.8948 (0.9202)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [150/172]  eta: 0:00:34  lr: 0.000018  loss: 0.9079 (0.9196)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [160/172]  eta: 0:00:19  lr: 0.000018  loss: 0.9110 (0.9203)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [170/172]  eta: 0:00:03  lr: 0.000018  loss: 0.8993 (0.9191)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841]  [171/172]  eta: 0:00:01  lr: 0.000018  loss: 0.8993 (0.9186)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:841] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000018  loss: 0.8993 (0.9186)\n",
      "Valid: [epoch:841]  [ 0/14]  eta: 0:00:05  loss: 0.9295 (0.9295)  time: 0.3732  data: 0.3553  max mem: 20571\n",
      "Valid: [epoch:841]  [13/14]  eta: 0:00:00  loss: 0.8734 (0.8852)  time: 0.0419  data: 0.0268  max mem: 20571\n",
      "Valid: [epoch:841] Total time: 0:00:00 (0.0485 s / it)\n",
      "Averaged stats: loss: 0.8734 (0.8852)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_841_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.885%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:842]  [  0/172]  eta: 0:07:25  lr: 0.000018  loss: 0.8707 (0.8707)  time: 2.5912  data: 1.0173  max mem: 20571\n",
      "Train: [epoch:842]  [ 10/172]  eta: 0:04:30  lr: 0.000018  loss: 0.8873 (0.9084)  time: 1.6701  data: 0.0926  max mem: 20571\n",
      "Train: [epoch:842]  [ 20/172]  eta: 0:04:07  lr: 0.000018  loss: 0.9138 (0.9218)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [ 30/172]  eta: 0:03:48  lr: 0.000018  loss: 0.9117 (0.9184)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [ 40/172]  eta: 0:03:31  lr: 0.000018  loss: 0.8987 (0.9174)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [ 50/172]  eta: 0:03:14  lr: 0.000018  loss: 0.8974 (0.9168)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [ 60/172]  eta: 0:02:58  lr: 0.000018  loss: 0.9144 (0.9191)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [ 70/172]  eta: 0:02:42  lr: 0.000018  loss: 0.9144 (0.9190)  time: 1.5763  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [ 80/172]  eta: 0:02:26  lr: 0.000018  loss: 0.9061 (0.9197)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [ 90/172]  eta: 0:02:10  lr: 0.000018  loss: 0.8866 (0.9179)  time: 1.5770  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [100/172]  eta: 0:01:54  lr: 0.000018  loss: 0.9111 (0.9168)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [110/172]  eta: 0:01:38  lr: 0.000018  loss: 0.9241 (0.9196)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [120/172]  eta: 0:01:22  lr: 0.000018  loss: 0.9505 (0.9222)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [130/172]  eta: 0:01:06  lr: 0.000018  loss: 0.9277 (0.9214)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [140/172]  eta: 0:00:50  lr: 0.000018  loss: 0.8872 (0.9199)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [150/172]  eta: 0:00:34  lr: 0.000018  loss: 0.9181 (0.9209)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [160/172]  eta: 0:00:19  lr: 0.000018  loss: 0.9181 (0.9196)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [170/172]  eta: 0:00:03  lr: 0.000018  loss: 0.9179 (0.9212)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842]  [171/172]  eta: 0:00:01  lr: 0.000018  loss: 0.9179 (0.9209)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:842] Total time: 0:04:32 (1.5842 s / it)\n",
      "Averaged stats: lr: 0.000018  loss: 0.9179 (0.9209)\n",
      "Valid: [epoch:842]  [ 0/14]  eta: 0:00:04  loss: 0.8649 (0.8649)  time: 0.3279  data: 0.3122  max mem: 20571\n",
      "Valid: [epoch:842]  [13/14]  eta: 0:00:00  loss: 0.8694 (0.8808)  time: 0.0386  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:842] Total time: 0:00:00 (0.0449 s / it)\n",
      "Averaged stats: loss: 0.8694 (0.8808)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_842_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.881%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:843]  [  0/172]  eta: 0:07:31  lr: 0.000018  loss: 0.9115 (0.9115)  time: 2.6260  data: 1.0527  max mem: 20571\n",
      "Train: [epoch:843]  [ 10/172]  eta: 0:04:30  lr: 0.000018  loss: 0.9467 (0.9406)  time: 1.6700  data: 0.0958  max mem: 20571\n",
      "Train: [epoch:843]  [ 20/172]  eta: 0:04:07  lr: 0.000018  loss: 0.9323 (0.9304)  time: 1.5751  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [ 30/172]  eta: 0:03:48  lr: 0.000018  loss: 0.9134 (0.9207)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [ 40/172]  eta: 0:03:31  lr: 0.000018  loss: 0.8955 (0.9134)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [ 50/172]  eta: 0:03:14  lr: 0.000018  loss: 0.9172 (0.9219)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [ 60/172]  eta: 0:02:58  lr: 0.000018  loss: 0.9546 (0.9243)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [ 70/172]  eta: 0:02:42  lr: 0.000018  loss: 0.9445 (0.9270)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [ 80/172]  eta: 0:02:26  lr: 0.000018  loss: 0.9237 (0.9258)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [ 90/172]  eta: 0:02:10  lr: 0.000018  loss: 0.9092 (0.9248)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [100/172]  eta: 0:01:54  lr: 0.000018  loss: 0.9021 (0.9236)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [110/172]  eta: 0:01:38  lr: 0.000018  loss: 0.9166 (0.9245)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [120/172]  eta: 0:01:22  lr: 0.000018  loss: 0.9174 (0.9232)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [130/172]  eta: 0:01:06  lr: 0.000018  loss: 0.9084 (0.9220)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [140/172]  eta: 0:00:50  lr: 0.000018  loss: 0.9031 (0.9206)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [150/172]  eta: 0:00:34  lr: 0.000018  loss: 0.9044 (0.9200)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [160/172]  eta: 0:00:19  lr: 0.000018  loss: 0.9044 (0.9191)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [170/172]  eta: 0:00:03  lr: 0.000018  loss: 0.9165 (0.9200)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843]  [171/172]  eta: 0:00:01  lr: 0.000018  loss: 0.9165 (0.9201)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:843] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000018  loss: 0.9165 (0.9201)\n",
      "Valid: [epoch:843]  [ 0/14]  eta: 0:00:05  loss: 0.9150 (0.9150)  time: 0.3670  data: 0.3521  max mem: 20571\n",
      "Valid: [epoch:843]  [13/14]  eta: 0:00:00  loss: 0.8722 (0.8833)  time: 0.0495  data: 0.0343  max mem: 20571\n",
      "Valid: [epoch:843] Total time: 0:00:00 (0.0556 s / it)\n",
      "Averaged stats: loss: 0.8722 (0.8833)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_843_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.883%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:844]  [  0/172]  eta: 0:07:38  lr: 0.000017  loss: 0.8651 (0.8651)  time: 2.6649  data: 1.0949  max mem: 20571\n",
      "Train: [epoch:844]  [ 10/172]  eta: 0:04:31  lr: 0.000017  loss: 0.9066 (0.9125)  time: 1.6789  data: 0.0996  max mem: 20571\n",
      "Train: [epoch:844]  [ 20/172]  eta: 0:04:08  lr: 0.000017  loss: 0.9192 (0.9185)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [ 30/172]  eta: 0:03:49  lr: 0.000017  loss: 0.9245 (0.9246)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [ 40/172]  eta: 0:03:32  lr: 0.000017  loss: 0.9229 (0.9194)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [ 50/172]  eta: 0:03:15  lr: 0.000017  loss: 0.9276 (0.9283)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:844]  [ 60/172]  eta: 0:02:59  lr: 0.000017  loss: 0.9155 (0.9262)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:844]  [ 70/172]  eta: 0:02:42  lr: 0.000017  loss: 0.9039 (0.9257)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [ 80/172]  eta: 0:02:26  lr: 0.000017  loss: 0.9175 (0.9248)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [ 90/172]  eta: 0:02:10  lr: 0.000017  loss: 0.9254 (0.9265)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [100/172]  eta: 0:01:54  lr: 0.000017  loss: 0.9141 (0.9256)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [110/172]  eta: 0:01:38  lr: 0.000017  loss: 0.8907 (0.9233)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [120/172]  eta: 0:01:22  lr: 0.000017  loss: 0.9158 (0.9267)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [130/172]  eta: 0:01:06  lr: 0.000017  loss: 0.9236 (0.9252)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [140/172]  eta: 0:00:50  lr: 0.000017  loss: 0.8692 (0.9208)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [150/172]  eta: 0:00:34  lr: 0.000017  loss: 0.8820 (0.9203)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [160/172]  eta: 0:00:19  lr: 0.000017  loss: 0.9134 (0.9222)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [170/172]  eta: 0:00:03  lr: 0.000017  loss: 0.9260 (0.9220)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844]  [171/172]  eta: 0:00:01  lr: 0.000017  loss: 0.9134 (0.9219)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:844] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000017  loss: 0.9134 (0.9219)\n",
      "Valid: [epoch:844]  [ 0/14]  eta: 0:00:04  loss: 0.8567 (0.8567)  time: 0.3328  data: 0.3167  max mem: 20571\n",
      "Valid: [epoch:844]  [13/14]  eta: 0:00:00  loss: 0.8745 (0.8856)  time: 0.0442  data: 0.0291  max mem: 20571\n",
      "Valid: [epoch:844] Total time: 0:00:00 (0.0521 s / it)\n",
      "Averaged stats: loss: 0.8745 (0.8856)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_844_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.886%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:845]  [  0/172]  eta: 0:07:57  lr: 0.000017  loss: 0.8920 (0.8920)  time: 2.7744  data: 1.2003  max mem: 20571\n",
      "Train: [epoch:845]  [ 10/172]  eta: 0:04:32  lr: 0.000017  loss: 0.9077 (0.9082)  time: 1.6848  data: 0.1092  max mem: 20571\n",
      "Train: [epoch:845]  [ 20/172]  eta: 0:04:08  lr: 0.000017  loss: 0.9206 (0.9197)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [ 30/172]  eta: 0:03:49  lr: 0.000017  loss: 0.9410 (0.9255)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [ 40/172]  eta: 0:03:32  lr: 0.000017  loss: 0.9180 (0.9225)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [ 50/172]  eta: 0:03:15  lr: 0.000017  loss: 0.9305 (0.9269)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [ 60/172]  eta: 0:02:58  lr: 0.000017  loss: 0.9280 (0.9243)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [ 70/172]  eta: 0:02:42  lr: 0.000017  loss: 0.9158 (0.9249)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [ 80/172]  eta: 0:02:26  lr: 0.000017  loss: 0.9175 (0.9265)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [ 90/172]  eta: 0:02:10  lr: 0.000017  loss: 0.9237 (0.9256)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [100/172]  eta: 0:01:54  lr: 0.000017  loss: 0.9275 (0.9259)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [110/172]  eta: 0:01:38  lr: 0.000017  loss: 0.9047 (0.9231)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [120/172]  eta: 0:01:22  lr: 0.000017  loss: 0.9088 (0.9250)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [130/172]  eta: 0:01:06  lr: 0.000017  loss: 0.9305 (0.9255)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [140/172]  eta: 0:00:50  lr: 0.000017  loss: 0.9174 (0.9245)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [150/172]  eta: 0:00:34  lr: 0.000017  loss: 0.9083 (0.9244)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [160/172]  eta: 0:00:19  lr: 0.000017  loss: 0.9083 (0.9229)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [170/172]  eta: 0:00:03  lr: 0.000017  loss: 0.9168 (0.9239)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845]  [171/172]  eta: 0:00:01  lr: 0.000017  loss: 0.9171 (0.9244)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:845] Total time: 0:04:33 (1.5882 s / it)\n",
      "Averaged stats: lr: 0.000017  loss: 0.9171 (0.9244)\n",
      "Valid: [epoch:845]  [ 0/14]  eta: 0:00:04  loss: 0.9283 (0.9283)  time: 0.2873  data: 0.2725  max mem: 20571\n",
      "Valid: [epoch:845]  [13/14]  eta: 0:00:00  loss: 0.8719 (0.8838)  time: 0.0373  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:845] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.8719 (0.8838)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_845_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.884%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:846]  [  0/172]  eta: 0:07:52  lr: 0.000017  loss: 0.9295 (0.9295)  time: 2.7486  data: 1.1777  max mem: 20571\n",
      "Train: [epoch:846]  [ 10/172]  eta: 0:04:33  lr: 0.000017  loss: 0.9166 (0.8999)  time: 1.6873  data: 0.1072  max mem: 20571\n",
      "Train: [epoch:846]  [ 20/172]  eta: 0:04:08  lr: 0.000017  loss: 0.9148 (0.9135)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [ 30/172]  eta: 0:03:50  lr: 0.000017  loss: 0.9241 (0.9168)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [ 40/172]  eta: 0:03:32  lr: 0.000017  loss: 0.9248 (0.9171)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [ 50/172]  eta: 0:03:15  lr: 0.000017  loss: 0.9138 (0.9179)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [ 60/172]  eta: 0:02:59  lr: 0.000017  loss: 0.9455 (0.9225)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [ 70/172]  eta: 0:02:43  lr: 0.000017  loss: 0.9373 (0.9197)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [ 80/172]  eta: 0:02:26  lr: 0.000017  loss: 0.8951 (0.9219)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [ 90/172]  eta: 0:02:10  lr: 0.000017  loss: 0.9368 (0.9218)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [100/172]  eta: 0:01:54  lr: 0.000017  loss: 0.9175 (0.9196)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [110/172]  eta: 0:01:38  lr: 0.000017  loss: 0.9306 (0.9211)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [120/172]  eta: 0:01:22  lr: 0.000017  loss: 0.9306 (0.9218)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [130/172]  eta: 0:01:06  lr: 0.000017  loss: 0.9098 (0.9208)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [140/172]  eta: 0:00:50  lr: 0.000017  loss: 0.9098 (0.9208)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [150/172]  eta: 0:00:34  lr: 0.000017  loss: 0.9290 (0.9214)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [160/172]  eta: 0:00:19  lr: 0.000017  loss: 0.9292 (0.9226)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846]  [170/172]  eta: 0:00:03  lr: 0.000017  loss: 0.9379 (0.9233)  time: 1.5847  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:846]  [171/172]  eta: 0:00:01  lr: 0.000017  loss: 0.9432 (0.9238)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:846] Total time: 0:04:33 (1.5905 s / it)\n",
      "Averaged stats: lr: 0.000017  loss: 0.9432 (0.9238)\n",
      "Valid: [epoch:846]  [ 0/14]  eta: 0:00:03  loss: 0.8532 (0.8532)  time: 0.2839  data: 0.2691  max mem: 20571\n",
      "Valid: [epoch:846]  [13/14]  eta: 0:00:00  loss: 0.8709 (0.8833)  time: 0.0553  data: 0.0404  max mem: 20571\n",
      "Valid: [epoch:846] Total time: 0:00:00 (0.0618 s / it)\n",
      "Averaged stats: loss: 0.8709 (0.8833)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_846_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.883%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:847]  [  0/172]  eta: 0:07:51  lr: 0.000017  loss: 0.9453 (0.9453)  time: 2.7428  data: 1.1680  max mem: 20571\n",
      "Train: [epoch:847]  [ 10/172]  eta: 0:04:32  lr: 0.000017  loss: 0.9310 (0.9191)  time: 1.6830  data: 0.1063  max mem: 20571\n",
      "Train: [epoch:847]  [ 20/172]  eta: 0:04:08  lr: 0.000017  loss: 0.9244 (0.9240)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [ 30/172]  eta: 0:03:49  lr: 0.000017  loss: 0.9279 (0.9290)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [ 40/172]  eta: 0:03:32  lr: 0.000017  loss: 0.9169 (0.9228)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [ 50/172]  eta: 0:03:15  lr: 0.000017  loss: 0.9127 (0.9241)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [ 60/172]  eta: 0:02:59  lr: 0.000017  loss: 0.9197 (0.9237)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [ 70/172]  eta: 0:02:42  lr: 0.000017  loss: 0.9066 (0.9226)  time: 1.5810  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:847]  [ 80/172]  eta: 0:02:26  lr: 0.000017  loss: 0.9169 (0.9220)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:847]  [ 90/172]  eta: 0:02:10  lr: 0.000017  loss: 0.9159 (0.9216)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [100/172]  eta: 0:01:54  lr: 0.000017  loss: 0.9310 (0.9240)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [110/172]  eta: 0:01:38  lr: 0.000017  loss: 0.9310 (0.9227)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [120/172]  eta: 0:01:22  lr: 0.000017  loss: 0.9243 (0.9247)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [130/172]  eta: 0:01:06  lr: 0.000017  loss: 0.9243 (0.9251)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [140/172]  eta: 0:00:50  lr: 0.000017  loss: 0.9266 (0.9259)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [150/172]  eta: 0:00:34  lr: 0.000017  loss: 0.9266 (0.9261)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [160/172]  eta: 0:00:19  lr: 0.000017  loss: 0.9058 (0.9250)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [170/172]  eta: 0:00:03  lr: 0.000017  loss: 0.9117 (0.9256)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847]  [171/172]  eta: 0:00:01  lr: 0.000017  loss: 0.9052 (0.9255)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:847] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000017  loss: 0.9052 (0.9255)\n",
      "Valid: [epoch:847]  [ 0/14]  eta: 0:00:04  loss: 0.9174 (0.9174)  time: 0.2960  data: 0.2811  max mem: 20571\n",
      "Valid: [epoch:847]  [13/14]  eta: 0:00:00  loss: 0.8730 (0.8851)  time: 0.0373  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:847] Total time: 0:00:00 (0.0451 s / it)\n",
      "Averaged stats: loss: 0.8730 (0.8851)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_847_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.885%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:848]  [  0/172]  eta: 0:07:54  lr: 0.000017  loss: 0.9231 (0.9231)  time: 2.7572  data: 1.1882  max mem: 20571\n",
      "Train: [epoch:848]  [ 10/172]  eta: 0:04:33  lr: 0.000017  loss: 0.9033 (0.9049)  time: 1.6868  data: 0.1082  max mem: 20571\n",
      "Train: [epoch:848]  [ 20/172]  eta: 0:04:08  lr: 0.000017  loss: 0.9167 (0.9212)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:848]  [ 30/172]  eta: 0:03:50  lr: 0.000017  loss: 0.9375 (0.9245)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [ 40/172]  eta: 0:03:32  lr: 0.000017  loss: 0.9130 (0.9213)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [ 50/172]  eta: 0:03:15  lr: 0.000017  loss: 0.9170 (0.9235)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [ 60/172]  eta: 0:02:59  lr: 0.000017  loss: 0.9039 (0.9193)  time: 1.5835  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:848]  [ 70/172]  eta: 0:02:43  lr: 0.000017  loss: 0.9017 (0.9199)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:848]  [ 80/172]  eta: 0:02:26  lr: 0.000017  loss: 0.9071 (0.9193)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [ 90/172]  eta: 0:02:10  lr: 0.000017  loss: 0.9123 (0.9206)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [100/172]  eta: 0:01:54  lr: 0.000017  loss: 0.9275 (0.9227)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [110/172]  eta: 0:01:38  lr: 0.000017  loss: 0.9365 (0.9223)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [120/172]  eta: 0:01:22  lr: 0.000017  loss: 0.9349 (0.9246)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [130/172]  eta: 0:01:06  lr: 0.000017  loss: 0.9349 (0.9244)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [140/172]  eta: 0:00:50  lr: 0.000017  loss: 0.8978 (0.9246)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [150/172]  eta: 0:00:35  lr: 0.000017  loss: 0.8986 (0.9236)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [160/172]  eta: 0:00:19  lr: 0.000017  loss: 0.9252 (0.9247)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [170/172]  eta: 0:00:03  lr: 0.000017  loss: 0.9361 (0.9248)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848]  [171/172]  eta: 0:00:01  lr: 0.000017  loss: 0.9361 (0.9247)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:848] Total time: 0:04:33 (1.5913 s / it)\n",
      "Averaged stats: lr: 0.000017  loss: 0.9361 (0.9247)\n",
      "Valid: [epoch:848]  [ 0/14]  eta: 0:00:04  loss: 0.8691 (0.8691)  time: 0.3464  data: 0.3300  max mem: 20571\n",
      "Valid: [epoch:848]  [13/14]  eta: 0:00:00  loss: 0.8734 (0.8854)  time: 0.0395  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:848] Total time: 0:00:00 (0.0476 s / it)\n",
      "Averaged stats: loss: 0.8734 (0.8854)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_848_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.885%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:849]  [  0/172]  eta: 0:07:49  lr: 0.000017  loss: 0.8726 (0.8726)  time: 2.7276  data: 1.1442  max mem: 20571\n",
      "Train: [epoch:849]  [ 10/172]  eta: 0:04:32  lr: 0.000017  loss: 0.9083 (0.9212)  time: 1.6846  data: 0.1041  max mem: 20571\n",
      "Train: [epoch:849]  [ 20/172]  eta: 0:04:08  lr: 0.000017  loss: 0.9083 (0.9169)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [ 30/172]  eta: 0:03:49  lr: 0.000017  loss: 0.9165 (0.9273)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [ 40/172]  eta: 0:03:32  lr: 0.000017  loss: 0.9337 (0.9263)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [ 50/172]  eta: 0:03:15  lr: 0.000017  loss: 0.9246 (0.9260)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [ 60/172]  eta: 0:02:59  lr: 0.000017  loss: 0.9413 (0.9286)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [ 70/172]  eta: 0:02:42  lr: 0.000017  loss: 0.9291 (0.9295)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [ 80/172]  eta: 0:02:26  lr: 0.000017  loss: 0.9172 (0.9290)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [ 90/172]  eta: 0:02:10  lr: 0.000017  loss: 0.9066 (0.9279)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [100/172]  eta: 0:01:54  lr: 0.000017  loss: 0.8991 (0.9249)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [110/172]  eta: 0:01:38  lr: 0.000017  loss: 0.9015 (0.9231)  time: 1.5832  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:849]  [120/172]  eta: 0:01:22  lr: 0.000017  loss: 0.9090 (0.9238)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [130/172]  eta: 0:01:06  lr: 0.000017  loss: 0.9107 (0.9249)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [140/172]  eta: 0:00:50  lr: 0.000017  loss: 0.9081 (0.9239)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [150/172]  eta: 0:00:34  lr: 0.000017  loss: 0.9075 (0.9238)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [160/172]  eta: 0:00:19  lr: 0.000017  loss: 0.9119 (0.9237)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [170/172]  eta: 0:00:03  lr: 0.000017  loss: 0.9235 (0.9259)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849]  [171/172]  eta: 0:00:01  lr: 0.000017  loss: 0.9321 (0.9262)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:849] Total time: 0:04:33 (1.5896 s / it)\n",
      "Averaged stats: lr: 0.000017  loss: 0.9321 (0.9262)\n",
      "Valid: [epoch:849]  [ 0/14]  eta: 0:00:04  loss: 0.9656 (0.9656)  time: 0.3280  data: 0.3090  max mem: 20571\n",
      "Valid: [epoch:849]  [13/14]  eta: 0:00:00  loss: 0.8746 (0.8862)  time: 0.0383  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:849] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.8746 (0.8862)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_849_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.886%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:850]  [  0/172]  eta: 0:07:39  lr: 0.000017  loss: 0.9839 (0.9839)  time: 2.6702  data: 1.0819  max mem: 20571\n",
      "Train: [epoch:850]  [ 10/172]  eta: 0:04:32  lr: 0.000017  loss: 0.9553 (0.9524)  time: 1.6799  data: 0.0985  max mem: 20571\n",
      "Train: [epoch:850]  [ 20/172]  eta: 0:04:08  lr: 0.000017  loss: 0.9426 (0.9458)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [ 30/172]  eta: 0:03:49  lr: 0.000017  loss: 0.9244 (0.9307)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [ 40/172]  eta: 0:03:32  lr: 0.000017  loss: 0.9070 (0.9247)  time: 1.5825  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:850]  [ 50/172]  eta: 0:03:15  lr: 0.000017  loss: 0.9205 (0.9271)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [ 60/172]  eta: 0:02:59  lr: 0.000017  loss: 0.9259 (0.9303)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [ 70/172]  eta: 0:02:42  lr: 0.000017  loss: 0.9267 (0.9302)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [ 80/172]  eta: 0:02:26  lr: 0.000017  loss: 0.9461 (0.9323)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [ 90/172]  eta: 0:02:10  lr: 0.000017  loss: 0.9117 (0.9290)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [100/172]  eta: 0:01:54  lr: 0.000017  loss: 0.9085 (0.9312)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [110/172]  eta: 0:01:38  lr: 0.000017  loss: 0.9361 (0.9326)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [120/172]  eta: 0:01:22  lr: 0.000017  loss: 0.9276 (0.9319)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [130/172]  eta: 0:01:06  lr: 0.000017  loss: 0.8999 (0.9315)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [140/172]  eta: 0:00:50  lr: 0.000017  loss: 0.8971 (0.9296)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [150/172]  eta: 0:00:34  lr: 0.000017  loss: 0.9047 (0.9294)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [160/172]  eta: 0:00:19  lr: 0.000017  loss: 0.9232 (0.9293)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [170/172]  eta: 0:00:03  lr: 0.000017  loss: 0.9004 (0.9270)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850]  [171/172]  eta: 0:00:01  lr: 0.000017  loss: 0.9004 (0.9275)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:850] Total time: 0:04:33 (1.5896 s / it)\n",
      "Averaged stats: lr: 0.000017  loss: 0.9004 (0.9275)\n",
      "Valid: [epoch:850]  [ 0/14]  eta: 0:00:04  loss: 0.9340 (0.9340)  time: 0.3083  data: 0.2930  max mem: 20571\n",
      "Valid: [epoch:850]  [13/14]  eta: 0:00:00  loss: 0.8794 (0.8908)  time: 0.0478  data: 0.0328  max mem: 20571\n",
      "Valid: [epoch:850] Total time: 0:00:00 (0.0528 s / it)\n",
      "Averaged stats: loss: 0.8794 (0.8908)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_850_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.891%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:851]  [  0/172]  eta: 0:07:30  lr: 0.000017  loss: 0.9118 (0.9118)  time: 2.6186  data: 1.0412  max mem: 20571\n",
      "Train: [epoch:851]  [ 10/172]  eta: 0:04:31  lr: 0.000017  loss: 0.9564 (0.9594)  time: 1.6740  data: 0.0948  max mem: 20571\n",
      "Train: [epoch:851]  [ 20/172]  eta: 0:04:07  lr: 0.000017  loss: 0.9277 (0.9458)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [ 30/172]  eta: 0:03:49  lr: 0.000017  loss: 0.9032 (0.9282)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [ 40/172]  eta: 0:03:32  lr: 0.000017  loss: 0.8952 (0.9234)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [ 50/172]  eta: 0:03:15  lr: 0.000017  loss: 0.9240 (0.9277)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [ 60/172]  eta: 0:02:59  lr: 0.000017  loss: 0.9418 (0.9320)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [ 70/172]  eta: 0:02:42  lr: 0.000017  loss: 0.9485 (0.9310)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [ 80/172]  eta: 0:02:26  lr: 0.000017  loss: 0.9250 (0.9301)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [ 90/172]  eta: 0:02:10  lr: 0.000017  loss: 0.9250 (0.9297)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [100/172]  eta: 0:01:54  lr: 0.000017  loss: 0.9231 (0.9294)  time: 1.5837  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:851]  [110/172]  eta: 0:01:38  lr: 0.000017  loss: 0.9231 (0.9312)  time: 1.5852  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:851]  [120/172]  eta: 0:01:22  lr: 0.000017  loss: 0.9275 (0.9300)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [130/172]  eta: 0:01:06  lr: 0.000017  loss: 0.9212 (0.9296)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [140/172]  eta: 0:00:50  lr: 0.000017  loss: 0.9086 (0.9282)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [150/172]  eta: 0:00:34  lr: 0.000017  loss: 0.8980 (0.9276)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [160/172]  eta: 0:00:19  lr: 0.000017  loss: 0.8980 (0.9269)  time: 1.5843  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:851]  [170/172]  eta: 0:00:03  lr: 0.000017  loss: 0.9087 (0.9277)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851]  [171/172]  eta: 0:00:01  lr: 0.000017  loss: 0.9087 (0.9281)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:851] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000017  loss: 0.9087 (0.9281)\n",
      "Valid: [epoch:851]  [ 0/14]  eta: 0:00:04  loss: 0.8577 (0.8577)  time: 0.2857  data: 0.2693  max mem: 20571\n",
      "Valid: [epoch:851]  [13/14]  eta: 0:00:00  loss: 0.8765 (0.8886)  time: 0.0386  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:851] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.8765 (0.8886)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_851_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.889%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:852]  [  0/172]  eta: 0:07:57  lr: 0.000017  loss: 0.9692 (0.9692)  time: 2.7769  data: 1.2072  max mem: 20571\n",
      "Train: [epoch:852]  [ 10/172]  eta: 0:04:33  lr: 0.000017  loss: 0.9489 (0.9403)  time: 1.6903  data: 0.1099  max mem: 20571\n",
      "Train: [epoch:852]  [ 20/172]  eta: 0:04:09  lr: 0.000017  loss: 0.9394 (0.9449)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:852]  [ 30/172]  eta: 0:03:50  lr: 0.000017  loss: 0.9311 (0.9463)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:852]  [ 40/172]  eta: 0:03:32  lr: 0.000017  loss: 0.9205 (0.9347)  time: 1.5849  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:852]  [ 50/172]  eta: 0:03:16  lr: 0.000017  loss: 0.9114 (0.9368)  time: 1.5854  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:852]  [ 60/172]  eta: 0:02:59  lr: 0.000017  loss: 0.9212 (0.9331)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [ 70/172]  eta: 0:02:43  lr: 0.000017  loss: 0.9037 (0.9291)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [ 80/172]  eta: 0:02:26  lr: 0.000017  loss: 0.9366 (0.9331)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [ 90/172]  eta: 0:02:10  lr: 0.000017  loss: 0.9380 (0.9324)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [100/172]  eta: 0:01:54  lr: 0.000017  loss: 0.9216 (0.9329)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [110/172]  eta: 0:01:38  lr: 0.000017  loss: 0.9172 (0.9316)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [120/172]  eta: 0:01:22  lr: 0.000017  loss: 0.8859 (0.9287)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [130/172]  eta: 0:01:06  lr: 0.000017  loss: 0.9070 (0.9292)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [140/172]  eta: 0:00:50  lr: 0.000017  loss: 0.9514 (0.9294)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [150/172]  eta: 0:00:34  lr: 0.000017  loss: 0.9490 (0.9317)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:852]  [160/172]  eta: 0:00:19  lr: 0.000017  loss: 0.9387 (0.9298)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:852]  [170/172]  eta: 0:00:03  lr: 0.000017  loss: 0.8923 (0.9287)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:852]  [171/172]  eta: 0:00:01  lr: 0.000017  loss: 0.8938 (0.9293)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:852] Total time: 0:04:33 (1.5905 s / it)\n",
      "Averaged stats: lr: 0.000017  loss: 0.8938 (0.9293)\n",
      "Valid: [epoch:852]  [ 0/14]  eta: 0:00:04  loss: 0.8593 (0.8593)  time: 0.3016  data: 0.2868  max mem: 20571\n",
      "Valid: [epoch:852]  [13/14]  eta: 0:00:00  loss: 0.8774 (0.8892)  time: 0.0422  data: 0.0274  max mem: 20571\n",
      "Valid: [epoch:852] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.8774 (0.8892)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_852_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.889%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:853]  [  0/172]  eta: 0:07:53  lr: 0.000016  loss: 0.9310 (0.9310)  time: 2.7536  data: 1.1532  max mem: 20571\n",
      "Train: [epoch:853]  [ 10/172]  eta: 0:04:32  lr: 0.000016  loss: 0.9074 (0.9086)  time: 1.6845  data: 0.1050  max mem: 20571\n",
      "Train: [epoch:853]  [ 20/172]  eta: 0:04:08  lr: 0.000016  loss: 0.9207 (0.9312)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [ 30/172]  eta: 0:03:49  lr: 0.000016  loss: 0.9263 (0.9211)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [ 40/172]  eta: 0:03:32  lr: 0.000016  loss: 0.8909 (0.9197)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:853]  [ 50/172]  eta: 0:03:15  lr: 0.000016  loss: 0.9109 (0.9208)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:853]  [ 60/172]  eta: 0:02:59  lr: 0.000016  loss: 0.9109 (0.9192)  time: 1.5830  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:853]  [ 70/172]  eta: 0:02:42  lr: 0.000016  loss: 0.9116 (0.9201)  time: 1.5831  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:853]  [ 80/172]  eta: 0:02:26  lr: 0.000016  loss: 0.9259 (0.9218)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:853]  [ 90/172]  eta: 0:02:10  lr: 0.000016  loss: 0.9345 (0.9215)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [100/172]  eta: 0:01:54  lr: 0.000016  loss: 0.9120 (0.9222)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [110/172]  eta: 0:01:38  lr: 0.000016  loss: 0.9276 (0.9253)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [120/172]  eta: 0:01:22  lr: 0.000016  loss: 0.9367 (0.9267)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [130/172]  eta: 0:01:06  lr: 0.000016  loss: 0.9430 (0.9296)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [140/172]  eta: 0:00:50  lr: 0.000016  loss: 0.9671 (0.9306)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [150/172]  eta: 0:00:34  lr: 0.000016  loss: 0.9241 (0.9302)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [160/172]  eta: 0:00:19  lr: 0.000016  loss: 0.9338 (0.9305)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [170/172]  eta: 0:00:03  lr: 0.000016  loss: 0.9209 (0.9304)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853]  [171/172]  eta: 0:00:01  lr: 0.000016  loss: 0.9209 (0.9304)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:853] Total time: 0:04:33 (1.5908 s / it)\n",
      "Averaged stats: lr: 0.000016  loss: 0.9209 (0.9304)\n",
      "Valid: [epoch:853]  [ 0/14]  eta: 0:00:05  loss: 0.8608 (0.8608)  time: 0.3580  data: 0.3425  max mem: 20571\n",
      "Valid: [epoch:853]  [13/14]  eta: 0:00:00  loss: 0.8792 (0.8913)  time: 0.0408  data: 0.0257  max mem: 20571\n",
      "Valid: [epoch:853] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 0.8792 (0.8913)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_853_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.891%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:854]  [  0/172]  eta: 0:08:06  lr: 0.000016  loss: 0.8625 (0.8625)  time: 2.8264  data: 1.2544  max mem: 20571\n",
      "Train: [epoch:854]  [ 10/172]  eta: 0:04:34  lr: 0.000016  loss: 0.9282 (0.9136)  time: 1.6962  data: 0.1141  max mem: 20571\n",
      "Train: [epoch:854]  [ 20/172]  eta: 0:04:09  lr: 0.000016  loss: 0.9337 (0.9318)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [ 30/172]  eta: 0:03:50  lr: 0.000016  loss: 0.9409 (0.9315)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [ 40/172]  eta: 0:03:33  lr: 0.000016  loss: 0.9466 (0.9355)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [ 50/172]  eta: 0:03:16  lr: 0.000016  loss: 0.9459 (0.9337)  time: 1.5844  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:854]  [ 60/172]  eta: 0:02:59  lr: 0.000016  loss: 0.9381 (0.9336)  time: 1.5839  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:854]  [ 70/172]  eta: 0:02:43  lr: 0.000016  loss: 0.9395 (0.9375)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:854]  [ 80/172]  eta: 0:02:27  lr: 0.000016  loss: 0.9183 (0.9359)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [ 90/172]  eta: 0:02:11  lr: 0.000016  loss: 0.9061 (0.9349)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [100/172]  eta: 0:01:54  lr: 0.000016  loss: 0.9061 (0.9319)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [110/172]  eta: 0:01:38  lr: 0.000016  loss: 0.9204 (0.9349)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [120/172]  eta: 0:01:22  lr: 0.000016  loss: 0.9310 (0.9338)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [130/172]  eta: 0:01:06  lr: 0.000016  loss: 0.9139 (0.9319)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [140/172]  eta: 0:00:50  lr: 0.000016  loss: 0.9021 (0.9304)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [150/172]  eta: 0:00:35  lr: 0.000016  loss: 0.9194 (0.9309)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [160/172]  eta: 0:00:19  lr: 0.000016  loss: 0.9404 (0.9317)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [170/172]  eta: 0:00:03  lr: 0.000016  loss: 0.9181 (0.9311)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854]  [171/172]  eta: 0:00:01  lr: 0.000016  loss: 0.9244 (0.9316)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:854] Total time: 0:04:33 (1.5917 s / it)\n",
      "Averaged stats: lr: 0.000016  loss: 0.9244 (0.9316)\n",
      "Valid: [epoch:854]  [ 0/14]  eta: 0:00:07  loss: 0.8363 (0.8363)  time: 0.5163  data: 0.5006  max mem: 20571\n",
      "Valid: [epoch:854]  [13/14]  eta: 0:00:00  loss: 0.8806 (0.8923)  time: 0.0526  data: 0.0374  max mem: 20571\n",
      "Valid: [epoch:854] Total time: 0:00:00 (0.0581 s / it)\n",
      "Averaged stats: loss: 0.8806 (0.8923)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_854_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.892%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:855]  [  0/172]  eta: 0:07:47  lr: 0.000016  loss: 0.9063 (0.9063)  time: 2.7156  data: 1.1341  max mem: 20571\n",
      "Train: [epoch:855]  [ 10/172]  eta: 0:04:32  lr: 0.000016  loss: 0.9386 (0.9553)  time: 1.6818  data: 0.1032  max mem: 20571\n",
      "Train: [epoch:855]  [ 20/172]  eta: 0:04:08  lr: 0.000016  loss: 0.9195 (0.9399)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [ 30/172]  eta: 0:03:49  lr: 0.000016  loss: 0.9195 (0.9391)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [ 40/172]  eta: 0:03:32  lr: 0.000016  loss: 0.9223 (0.9315)  time: 1.5834  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:855]  [ 50/172]  eta: 0:03:15  lr: 0.000016  loss: 0.9252 (0.9361)  time: 1.5834  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:855]  [ 60/172]  eta: 0:02:59  lr: 0.000016  loss: 0.9493 (0.9363)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [ 70/172]  eta: 0:02:42  lr: 0.000016  loss: 0.9229 (0.9378)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [ 80/172]  eta: 0:02:26  lr: 0.000016  loss: 0.9022 (0.9354)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [ 90/172]  eta: 0:02:10  lr: 0.000016  loss: 0.9365 (0.9362)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [100/172]  eta: 0:01:54  lr: 0.000016  loss: 0.9340 (0.9346)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [110/172]  eta: 0:01:38  lr: 0.000016  loss: 0.9213 (0.9335)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [120/172]  eta: 0:01:22  lr: 0.000016  loss: 0.9536 (0.9362)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [130/172]  eta: 0:01:06  lr: 0.000016  loss: 0.9536 (0.9374)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [140/172]  eta: 0:00:50  lr: 0.000016  loss: 0.9322 (0.9361)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [150/172]  eta: 0:00:34  lr: 0.000016  loss: 0.9265 (0.9361)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [160/172]  eta: 0:00:19  lr: 0.000016  loss: 0.9193 (0.9353)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [170/172]  eta: 0:00:03  lr: 0.000016  loss: 0.9153 (0.9338)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855]  [171/172]  eta: 0:00:01  lr: 0.000016  loss: 0.9143 (0.9337)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:855] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000016  loss: 0.9143 (0.9337)\n",
      "Valid: [epoch:855]  [ 0/14]  eta: 0:00:04  loss: 0.8191 (0.8191)  time: 0.3098  data: 0.2927  max mem: 20571\n",
      "Valid: [epoch:855]  [13/14]  eta: 0:00:00  loss: 0.8811 (0.8937)  time: 0.0381  data: 0.0228  max mem: 20571\n",
      "Valid: [epoch:855] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.8811 (0.8937)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_855_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.894%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:856]  [  0/172]  eta: 0:07:40  lr: 0.000016  loss: 0.9820 (0.9820)  time: 2.6800  data: 1.1098  max mem: 20571\n",
      "Train: [epoch:856]  [ 10/172]  eta: 0:04:32  lr: 0.000016  loss: 0.9820 (0.9567)  time: 1.6821  data: 0.1010  max mem: 20571\n",
      "Train: [epoch:856]  [ 20/172]  eta: 0:04:08  lr: 0.000016  loss: 0.9470 (0.9441)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [ 30/172]  eta: 0:03:49  lr: 0.000016  loss: 0.9268 (0.9352)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [ 40/172]  eta: 0:03:32  lr: 0.000016  loss: 0.8888 (0.9269)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [ 50/172]  eta: 0:03:15  lr: 0.000016  loss: 0.8921 (0.9261)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [ 60/172]  eta: 0:02:59  lr: 0.000016  loss: 0.9499 (0.9297)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [ 70/172]  eta: 0:02:42  lr: 0.000016  loss: 0.9257 (0.9295)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [ 80/172]  eta: 0:02:26  lr: 0.000016  loss: 0.9187 (0.9335)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [ 90/172]  eta: 0:02:10  lr: 0.000016  loss: 0.9655 (0.9348)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [100/172]  eta: 0:01:54  lr: 0.000016  loss: 0.9718 (0.9368)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [110/172]  eta: 0:01:38  lr: 0.000016  loss: 0.9230 (0.9343)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [120/172]  eta: 0:01:22  lr: 0.000016  loss: 0.9363 (0.9365)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [130/172]  eta: 0:01:06  lr: 0.000016  loss: 0.9213 (0.9346)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [140/172]  eta: 0:00:50  lr: 0.000016  loss: 0.9083 (0.9332)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [150/172]  eta: 0:00:34  lr: 0.000016  loss: 0.9129 (0.9323)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [160/172]  eta: 0:00:19  lr: 0.000016  loss: 0.9129 (0.9316)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [170/172]  eta: 0:00:03  lr: 0.000016  loss: 0.9352 (0.9333)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856]  [171/172]  eta: 0:00:01  lr: 0.000016  loss: 0.9352 (0.9334)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:856] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000016  loss: 0.9352 (0.9334)\n",
      "Valid: [epoch:856]  [ 0/14]  eta: 0:00:04  loss: 0.9394 (0.9394)  time: 0.2940  data: 0.2791  max mem: 20571\n",
      "Valid: [epoch:856]  [13/14]  eta: 0:00:00  loss: 0.8807 (0.8928)  time: 0.0449  data: 0.0300  max mem: 20571\n",
      "Valid: [epoch:856] Total time: 0:00:00 (0.0499 s / it)\n",
      "Averaged stats: loss: 0.8807 (0.8928)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_856_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.893%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:857]  [  0/172]  eta: 0:07:18  lr: 0.000016  loss: 0.9917 (0.9917)  time: 2.5520  data: 0.9717  max mem: 20571\n",
      "Train: [epoch:857]  [ 10/172]  eta: 0:04:29  lr: 0.000016  loss: 0.9481 (0.9435)  time: 1.6663  data: 0.0884  max mem: 20571\n",
      "Train: [epoch:857]  [ 20/172]  eta: 0:04:07  lr: 0.000016  loss: 0.9152 (0.9276)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [ 30/172]  eta: 0:03:48  lr: 0.000016  loss: 0.9122 (0.9264)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [ 40/172]  eta: 0:03:31  lr: 0.000016  loss: 0.9257 (0.9233)  time: 1.5812  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:857]  [ 50/172]  eta: 0:03:15  lr: 0.000016  loss: 0.9308 (0.9263)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [ 60/172]  eta: 0:02:58  lr: 0.000016  loss: 0.9136 (0.9244)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [ 70/172]  eta: 0:02:42  lr: 0.000016  loss: 0.9136 (0.9258)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [ 80/172]  eta: 0:02:26  lr: 0.000016  loss: 0.9133 (0.9250)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [ 90/172]  eta: 0:02:10  lr: 0.000016  loss: 0.9206 (0.9270)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [100/172]  eta: 0:01:54  lr: 0.000016  loss: 0.9305 (0.9282)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [110/172]  eta: 0:01:38  lr: 0.000016  loss: 0.9335 (0.9306)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [120/172]  eta: 0:01:22  lr: 0.000016  loss: 0.9613 (0.9342)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [130/172]  eta: 0:01:06  lr: 0.000016  loss: 0.9481 (0.9342)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [140/172]  eta: 0:00:50  lr: 0.000016  loss: 0.9380 (0.9352)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [150/172]  eta: 0:00:34  lr: 0.000016  loss: 0.9299 (0.9340)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [160/172]  eta: 0:00:19  lr: 0.000016  loss: 0.9122 (0.9332)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857]  [170/172]  eta: 0:00:03  lr: 0.000016  loss: 0.9202 (0.9335)  time: 1.5842  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:857]  [171/172]  eta: 0:00:01  lr: 0.000016  loss: 0.9202 (0.9344)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:857] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000016  loss: 0.9202 (0.9344)\n",
      "Valid: [epoch:857]  [ 0/14]  eta: 0:00:06  loss: 0.8825 (0.8825)  time: 0.4982  data: 0.4805  max mem: 20571\n",
      "Valid: [epoch:857]  [13/14]  eta: 0:00:00  loss: 0.8825 (0.8946)  time: 0.0504  data: 0.0348  max mem: 20571\n",
      "Valid: [epoch:857] Total time: 0:00:00 (0.0561 s / it)\n",
      "Averaged stats: loss: 0.8825 (0.8946)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_857_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.895%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:858]  [  0/172]  eta: 0:08:05  lr: 0.000016  loss: 0.9544 (0.9544)  time: 2.8253  data: 1.2591  max mem: 20571\n",
      "Train: [epoch:858]  [ 10/172]  eta: 0:04:34  lr: 0.000016  loss: 0.9517 (0.9486)  time: 1.6927  data: 0.1146  max mem: 20571\n",
      "Train: [epoch:858]  [ 20/172]  eta: 0:04:09  lr: 0.000016  loss: 0.9482 (0.9513)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [ 30/172]  eta: 0:03:50  lr: 0.000016  loss: 0.9426 (0.9430)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [ 40/172]  eta: 0:03:32  lr: 0.000016  loss: 0.9008 (0.9315)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [ 50/172]  eta: 0:03:15  lr: 0.000016  loss: 0.9004 (0.9341)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [ 60/172]  eta: 0:02:59  lr: 0.000016  loss: 0.9545 (0.9413)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [ 70/172]  eta: 0:02:43  lr: 0.000016  loss: 0.9411 (0.9362)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [ 80/172]  eta: 0:02:26  lr: 0.000016  loss: 0.9282 (0.9354)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [ 90/172]  eta: 0:02:10  lr: 0.000016  loss: 0.9323 (0.9342)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [100/172]  eta: 0:01:54  lr: 0.000016  loss: 0.9378 (0.9357)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [110/172]  eta: 0:01:38  lr: 0.000016  loss: 0.9378 (0.9356)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [120/172]  eta: 0:01:22  lr: 0.000016  loss: 0.9372 (0.9371)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [130/172]  eta: 0:01:06  lr: 0.000016  loss: 0.9096 (0.9343)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [140/172]  eta: 0:00:50  lr: 0.000016  loss: 0.9076 (0.9339)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [150/172]  eta: 0:00:34  lr: 0.000016  loss: 0.9184 (0.9347)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [160/172]  eta: 0:00:19  lr: 0.000016  loss: 0.9445 (0.9354)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [170/172]  eta: 0:00:03  lr: 0.000016  loss: 0.9445 (0.9358)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858]  [171/172]  eta: 0:00:01  lr: 0.000016  loss: 0.9445 (0.9357)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:858] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000016  loss: 0.9445 (0.9357)\n",
      "Valid: [epoch:858]  [ 0/14]  eta: 0:00:04  loss: 0.9762 (0.9762)  time: 0.3050  data: 0.2897  max mem: 20571\n",
      "Valid: [epoch:858]  [13/14]  eta: 0:00:00  loss: 0.8840 (0.8965)  time: 0.0367  data: 0.0214  max mem: 20571\n",
      "Valid: [epoch:858] Total time: 0:00:00 (0.0423 s / it)\n",
      "Averaged stats: loss: 0.8840 (0.8965)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_858_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.897%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:859]  [  0/172]  eta: 0:08:05  lr: 0.000016  loss: 0.9559 (0.9559)  time: 2.8212  data: 1.2388  max mem: 20571\n",
      "Train: [epoch:859]  [ 10/172]  eta: 0:04:34  lr: 0.000016  loss: 0.9336 (0.9460)  time: 1.6920  data: 0.1127  max mem: 20571\n",
      "Train: [epoch:859]  [ 20/172]  eta: 0:04:09  lr: 0.000016  loss: 0.9358 (0.9450)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [ 30/172]  eta: 0:03:50  lr: 0.000016  loss: 0.9291 (0.9304)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [ 40/172]  eta: 0:03:32  lr: 0.000016  loss: 0.9204 (0.9384)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [ 50/172]  eta: 0:03:15  lr: 0.000016  loss: 0.9528 (0.9408)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [ 60/172]  eta: 0:02:59  lr: 0.000016  loss: 0.9278 (0.9375)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [ 70/172]  eta: 0:02:43  lr: 0.000016  loss: 0.9311 (0.9379)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [ 80/172]  eta: 0:02:26  lr: 0.000016  loss: 0.9483 (0.9376)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [ 90/172]  eta: 0:02:10  lr: 0.000016  loss: 0.9447 (0.9377)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [100/172]  eta: 0:01:54  lr: 0.000016  loss: 0.9368 (0.9381)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [110/172]  eta: 0:01:38  lr: 0.000016  loss: 0.9133 (0.9368)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [120/172]  eta: 0:01:22  lr: 0.000016  loss: 0.9125 (0.9390)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [130/172]  eta: 0:01:06  lr: 0.000016  loss: 0.9469 (0.9395)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [140/172]  eta: 0:00:50  lr: 0.000016  loss: 0.9458 (0.9402)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [150/172]  eta: 0:00:34  lr: 0.000016  loss: 0.9479 (0.9414)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [160/172]  eta: 0:00:19  lr: 0.000016  loss: 0.9431 (0.9401)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [170/172]  eta: 0:00:03  lr: 0.000016  loss: 0.8956 (0.9371)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859]  [171/172]  eta: 0:00:01  lr: 0.000016  loss: 0.8956 (0.9374)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:859] Total time: 0:04:33 (1.5902 s / it)\n",
      "Averaged stats: lr: 0.000016  loss: 0.8956 (0.9374)\n",
      "Valid: [epoch:859]  [ 0/14]  eta: 0:00:04  loss: 0.8206 (0.8206)  time: 0.2909  data: 0.2760  max mem: 20571\n",
      "Valid: [epoch:859]  [13/14]  eta: 0:00:00  loss: 0.8857 (0.8972)  time: 0.0385  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:859] Total time: 0:00:00 (0.0460 s / it)\n",
      "Averaged stats: loss: 0.8857 (0.8972)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_859_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.897%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:860]  [  0/172]  eta: 0:08:21  lr: 0.000016  loss: 0.9168 (0.9168)  time: 2.9153  data: 1.3424  max mem: 20571\n",
      "Train: [epoch:860]  [ 10/172]  eta: 0:04:35  lr: 0.000016  loss: 0.9196 (0.9215)  time: 1.7016  data: 0.1221  max mem: 20571\n",
      "Train: [epoch:860]  [ 20/172]  eta: 0:04:10  lr: 0.000016  loss: 0.9208 (0.9245)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [ 30/172]  eta: 0:03:50  lr: 0.000016  loss: 0.9241 (0.9326)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:860]  [ 40/172]  eta: 0:03:33  lr: 0.000016  loss: 0.9591 (0.9376)  time: 1.5840  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:860]  [ 50/172]  eta: 0:03:16  lr: 0.000016  loss: 0.9337 (0.9348)  time: 1.5839  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:860]  [ 60/172]  eta: 0:02:59  lr: 0.000016  loss: 0.9316 (0.9343)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:860]  [ 70/172]  eta: 0:02:43  lr: 0.000016  loss: 0.9313 (0.9298)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:860]  [ 80/172]  eta: 0:02:27  lr: 0.000016  loss: 0.9313 (0.9344)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [ 90/172]  eta: 0:02:10  lr: 0.000016  loss: 0.9201 (0.9312)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [100/172]  eta: 0:01:54  lr: 0.000016  loss: 0.9200 (0.9327)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [110/172]  eta: 0:01:38  lr: 0.000016  loss: 0.9419 (0.9353)  time: 1.5836  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:860]  [120/172]  eta: 0:01:22  lr: 0.000016  loss: 0.9614 (0.9381)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [130/172]  eta: 0:01:06  lr: 0.000016  loss: 0.9614 (0.9399)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [140/172]  eta: 0:00:50  lr: 0.000016  loss: 0.9498 (0.9395)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [150/172]  eta: 0:00:35  lr: 0.000016  loss: 0.9284 (0.9388)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [160/172]  eta: 0:00:19  lr: 0.000016  loss: 0.9320 (0.9383)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [170/172]  eta: 0:00:03  lr: 0.000016  loss: 0.9375 (0.9377)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860]  [171/172]  eta: 0:00:01  lr: 0.000016  loss: 0.9338 (0.9374)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:860] Total time: 0:04:33 (1.5914 s / it)\n",
      "Averaged stats: lr: 0.000016  loss: 0.9338 (0.9374)\n",
      "Valid: [epoch:860]  [ 0/14]  eta: 0:00:04  loss: 0.9403 (0.9403)  time: 0.3316  data: 0.3156  max mem: 20571\n",
      "Valid: [epoch:860]  [13/14]  eta: 0:00:00  loss: 0.8852 (0.8969)  time: 0.0390  data: 0.0239  max mem: 20571\n",
      "Valid: [epoch:860] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.8852 (0.8969)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_860_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.897%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:861]  [  0/172]  eta: 0:08:06  lr: 0.000016  loss: 0.9142 (0.9142)  time: 2.8301  data: 1.2579  max mem: 20571\n",
      "Train: [epoch:861]  [ 10/172]  eta: 0:04:33  lr: 0.000016  loss: 0.9348 (0.9495)  time: 1.6906  data: 0.1145  max mem: 20571\n",
      "Train: [epoch:861]  [ 20/172]  eta: 0:04:09  lr: 0.000016  loss: 0.9591 (0.9593)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [ 30/172]  eta: 0:03:50  lr: 0.000016  loss: 0.9554 (0.9549)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [ 40/172]  eta: 0:03:32  lr: 0.000016  loss: 0.9387 (0.9471)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:861]  [ 50/172]  eta: 0:03:15  lr: 0.000016  loss: 0.9078 (0.9420)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [ 60/172]  eta: 0:02:59  lr: 0.000016  loss: 0.9127 (0.9394)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [ 70/172]  eta: 0:02:43  lr: 0.000016  loss: 0.9127 (0.9379)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [ 80/172]  eta: 0:02:26  lr: 0.000016  loss: 0.9501 (0.9443)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [ 90/172]  eta: 0:02:10  lr: 0.000016  loss: 0.9769 (0.9435)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [100/172]  eta: 0:01:54  lr: 0.000016  loss: 0.9269 (0.9449)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [110/172]  eta: 0:01:38  lr: 0.000016  loss: 0.9299 (0.9441)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [120/172]  eta: 0:01:22  lr: 0.000016  loss: 0.9238 (0.9435)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [130/172]  eta: 0:01:06  lr: 0.000016  loss: 0.9168 (0.9425)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [140/172]  eta: 0:00:50  lr: 0.000016  loss: 0.9176 (0.9404)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [150/172]  eta: 0:00:34  lr: 0.000016  loss: 0.9251 (0.9402)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [160/172]  eta: 0:00:19  lr: 0.000016  loss: 0.9222 (0.9387)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:861]  [170/172]  eta: 0:00:03  lr: 0.000016  loss: 0.9317 (0.9390)  time: 1.5834  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:861]  [171/172]  eta: 0:00:01  lr: 0.000016  loss: 0.9335 (0.9390)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:861] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000016  loss: 0.9335 (0.9390)\n",
      "Valid: [epoch:861]  [ 0/14]  eta: 0:00:04  loss: 0.9317 (0.9317)  time: 0.3028  data: 0.2877  max mem: 20571\n",
      "Valid: [epoch:861]  [13/14]  eta: 0:00:00  loss: 0.8876 (0.8993)  time: 0.0401  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:861] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.8876 (0.8993)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_861_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.899%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:862]  [  0/172]  eta: 0:07:47  lr: 0.000015  loss: 0.9464 (0.9464)  time: 2.7171  data: 1.1488  max mem: 20571\n",
      "Train: [epoch:862]  [ 10/172]  eta: 0:04:32  lr: 0.000015  loss: 0.9150 (0.9232)  time: 1.6833  data: 0.1046  max mem: 20571\n",
      "Train: [epoch:862]  [ 20/172]  eta: 0:04:08  lr: 0.000015  loss: 0.9150 (0.9444)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [ 30/172]  eta: 0:03:49  lr: 0.000015  loss: 0.9335 (0.9437)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [ 40/172]  eta: 0:03:32  lr: 0.000015  loss: 0.9257 (0.9438)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [ 50/172]  eta: 0:03:15  lr: 0.000015  loss: 0.9372 (0.9465)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:862]  [ 60/172]  eta: 0:02:59  lr: 0.000015  loss: 0.9372 (0.9439)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [ 70/172]  eta: 0:02:42  lr: 0.000015  loss: 0.9299 (0.9421)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [ 80/172]  eta: 0:02:26  lr: 0.000015  loss: 0.9411 (0.9442)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [ 90/172]  eta: 0:02:10  lr: 0.000015  loss: 0.9161 (0.9405)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [100/172]  eta: 0:01:54  lr: 0.000015  loss: 0.9111 (0.9412)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [110/172]  eta: 0:01:38  lr: 0.000015  loss: 0.9137 (0.9391)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [120/172]  eta: 0:01:22  lr: 0.000015  loss: 0.9097 (0.9389)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [130/172]  eta: 0:01:06  lr: 0.000015  loss: 0.9369 (0.9389)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [140/172]  eta: 0:00:50  lr: 0.000015  loss: 0.9315 (0.9386)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [150/172]  eta: 0:00:34  lr: 0.000015  loss: 0.9384 (0.9404)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [160/172]  eta: 0:00:19  lr: 0.000015  loss: 0.9529 (0.9403)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [170/172]  eta: 0:00:03  lr: 0.000015  loss: 0.9353 (0.9400)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862]  [171/172]  eta: 0:00:01  lr: 0.000015  loss: 0.9353 (0.9399)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:862] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000015  loss: 0.9353 (0.9399)\n",
      "Valid: [epoch:862]  [ 0/14]  eta: 0:00:04  loss: 0.8895 (0.8895)  time: 0.2956  data: 0.2803  max mem: 20571\n",
      "Valid: [epoch:862]  [13/14]  eta: 0:00:00  loss: 0.8933 (0.9057)  time: 0.0384  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:862] Total time: 0:00:00 (0.0433 s / it)\n",
      "Averaged stats: loss: 0.8933 (0.9057)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_862_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.906%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:863]  [  0/172]  eta: 0:07:51  lr: 0.000015  loss: 0.8307 (0.8307)  time: 2.7416  data: 1.1676  max mem: 20571\n",
      "Train: [epoch:863]  [ 10/172]  eta: 0:04:32  lr: 0.000015  loss: 0.9410 (0.9217)  time: 1.6845  data: 0.1062  max mem: 20571\n",
      "Train: [epoch:863]  [ 20/172]  eta: 0:04:08  lr: 0.000015  loss: 0.9410 (0.9368)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [ 30/172]  eta: 0:03:49  lr: 0.000015  loss: 0.9342 (0.9362)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [ 40/172]  eta: 0:03:32  lr: 0.000015  loss: 0.9030 (0.9312)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [ 50/172]  eta: 0:03:15  lr: 0.000015  loss: 0.9222 (0.9322)  time: 1.5826  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:863]  [ 60/172]  eta: 0:02:59  lr: 0.000015  loss: 0.9222 (0.9326)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [ 70/172]  eta: 0:02:43  lr: 0.000015  loss: 0.9151 (0.9290)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [ 80/172]  eta: 0:02:26  lr: 0.000015  loss: 0.9200 (0.9318)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [ 90/172]  eta: 0:02:10  lr: 0.000015  loss: 0.9508 (0.9350)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [100/172]  eta: 0:01:54  lr: 0.000015  loss: 0.9319 (0.9346)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [110/172]  eta: 0:01:38  lr: 0.000015  loss: 0.9319 (0.9364)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [120/172]  eta: 0:01:22  lr: 0.000015  loss: 0.9419 (0.9378)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [130/172]  eta: 0:01:06  lr: 0.000015  loss: 0.9286 (0.9369)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [140/172]  eta: 0:00:50  lr: 0.000015  loss: 0.9094 (0.9365)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [150/172]  eta: 0:00:34  lr: 0.000015  loss: 0.9202 (0.9362)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [160/172]  eta: 0:00:19  lr: 0.000015  loss: 0.9427 (0.9386)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [170/172]  eta: 0:00:03  lr: 0.000015  loss: 0.9610 (0.9412)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863]  [171/172]  eta: 0:00:01  lr: 0.000015  loss: 0.9610 (0.9414)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:863] Total time: 0:04:33 (1.5904 s / it)\n",
      "Averaged stats: lr: 0.000015  loss: 0.9610 (0.9414)\n",
      "Valid: [epoch:863]  [ 0/14]  eta: 0:00:04  loss: 0.9809 (0.9809)  time: 0.3062  data: 0.2900  max mem: 20571\n",
      "Valid: [epoch:863]  [13/14]  eta: 0:00:00  loss: 0.8883 (0.9008)  time: 0.0376  data: 0.0223  max mem: 20571\n",
      "Valid: [epoch:863] Total time: 0:00:00 (0.0462 s / it)\n",
      "Averaged stats: loss: 0.8883 (0.9008)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_863_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.901%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:864]  [  0/172]  eta: 0:07:32  lr: 0.000015  loss: 0.8538 (0.8538)  time: 2.6296  data: 1.0603  max mem: 20571\n",
      "Train: [epoch:864]  [ 10/172]  eta: 0:04:31  lr: 0.000015  loss: 0.9089 (0.9181)  time: 1.6786  data: 0.0965  max mem: 20571\n",
      "Train: [epoch:864]  [ 20/172]  eta: 0:04:08  lr: 0.000015  loss: 0.9293 (0.9299)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [ 30/172]  eta: 0:03:49  lr: 0.000015  loss: 0.9460 (0.9342)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [ 40/172]  eta: 0:03:32  lr: 0.000015  loss: 0.9325 (0.9347)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [ 50/172]  eta: 0:03:15  lr: 0.000015  loss: 0.9404 (0.9368)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [ 60/172]  eta: 0:02:59  lr: 0.000015  loss: 0.9290 (0.9366)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [ 70/172]  eta: 0:02:43  lr: 0.000015  loss: 0.9248 (0.9364)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [ 80/172]  eta: 0:02:26  lr: 0.000015  loss: 0.9310 (0.9354)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:864]  [ 90/172]  eta: 0:02:10  lr: 0.000015  loss: 0.9405 (0.9380)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [100/172]  eta: 0:01:54  lr: 0.000015  loss: 0.9322 (0.9373)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [110/172]  eta: 0:01:38  lr: 0.000015  loss: 0.9240 (0.9373)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [120/172]  eta: 0:01:22  lr: 0.000015  loss: 0.9429 (0.9391)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [130/172]  eta: 0:01:06  lr: 0.000015  loss: 0.9522 (0.9429)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [140/172]  eta: 0:00:50  lr: 0.000015  loss: 0.9362 (0.9412)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [150/172]  eta: 0:00:34  lr: 0.000015  loss: 0.9163 (0.9405)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [160/172]  eta: 0:00:19  lr: 0.000015  loss: 0.9093 (0.9393)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [170/172]  eta: 0:00:03  lr: 0.000015  loss: 0.9178 (0.9403)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864]  [171/172]  eta: 0:00:01  lr: 0.000015  loss: 0.9302 (0.9404)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:864] Total time: 0:04:33 (1.5901 s / it)\n",
      "Averaged stats: lr: 0.000015  loss: 0.9302 (0.9404)\n",
      "Valid: [epoch:864]  [ 0/14]  eta: 0:00:06  loss: 0.8464 (0.8464)  time: 0.4709  data: 0.4545  max mem: 20571\n",
      "Valid: [epoch:864]  [13/14]  eta: 0:00:00  loss: 0.8901 (0.9021)  time: 0.0487  data: 0.0337  max mem: 20571\n",
      "Valid: [epoch:864] Total time: 0:00:00 (0.0535 s / it)\n",
      "Averaged stats: loss: 0.8901 (0.9021)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_864_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.902%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:865]  [  0/172]  eta: 0:07:28  lr: 0.000015  loss: 0.9287 (0.9287)  time: 2.6085  data: 1.0342  max mem: 20571\n",
      "Train: [epoch:865]  [ 10/172]  eta: 0:04:30  lr: 0.000015  loss: 0.9287 (0.9322)  time: 1.6714  data: 0.0941  max mem: 20571\n",
      "Train: [epoch:865]  [ 20/172]  eta: 0:04:07  lr: 0.000015  loss: 0.9411 (0.9455)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [ 30/172]  eta: 0:03:49  lr: 0.000015  loss: 0.9411 (0.9441)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [ 40/172]  eta: 0:03:31  lr: 0.000015  loss: 0.9405 (0.9388)  time: 1.5815  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:865]  [ 50/172]  eta: 0:03:15  lr: 0.000015  loss: 0.9353 (0.9377)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:865]  [ 60/172]  eta: 0:02:58  lr: 0.000015  loss: 0.9422 (0.9406)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [ 70/172]  eta: 0:02:42  lr: 0.000015  loss: 0.9585 (0.9429)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [ 80/172]  eta: 0:02:26  lr: 0.000015  loss: 0.9570 (0.9438)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [ 90/172]  eta: 0:02:10  lr: 0.000015  loss: 0.9229 (0.9410)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [100/172]  eta: 0:01:54  lr: 0.000015  loss: 0.9251 (0.9409)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [110/172]  eta: 0:01:38  lr: 0.000015  loss: 0.9324 (0.9400)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [120/172]  eta: 0:01:22  lr: 0.000015  loss: 0.9434 (0.9395)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [130/172]  eta: 0:01:06  lr: 0.000015  loss: 0.9341 (0.9398)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [140/172]  eta: 0:00:50  lr: 0.000015  loss: 0.9341 (0.9401)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [150/172]  eta: 0:00:34  lr: 0.000015  loss: 0.9459 (0.9428)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [160/172]  eta: 0:00:19  lr: 0.000015  loss: 0.9276 (0.9415)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [170/172]  eta: 0:00:03  lr: 0.000015  loss: 0.9231 (0.9435)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865]  [171/172]  eta: 0:00:01  lr: 0.000015  loss: 0.9276 (0.9437)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:865] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000015  loss: 0.9276 (0.9437)\n",
      "Valid: [epoch:865]  [ 0/14]  eta: 0:00:04  loss: 0.9468 (0.9468)  time: 0.3085  data: 0.2930  max mem: 20571\n",
      "Valid: [epoch:865]  [13/14]  eta: 0:00:00  loss: 0.8905 (0.9028)  time: 0.0412  data: 0.0260  max mem: 20571\n",
      "Valid: [epoch:865] Total time: 0:00:00 (0.0486 s / it)\n",
      "Averaged stats: loss: 0.8905 (0.9028)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_865_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.903%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:866]  [  0/172]  eta: 0:07:39  lr: 0.000015  loss: 1.0447 (1.0447)  time: 2.6696  data: 1.1000  max mem: 20571\n",
      "Train: [epoch:866]  [ 10/172]  eta: 0:04:32  lr: 0.000015  loss: 0.9235 (0.9329)  time: 1.6811  data: 0.1001  max mem: 20571\n",
      "Train: [epoch:866]  [ 20/172]  eta: 0:04:08  lr: 0.000015  loss: 0.9366 (0.9502)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [ 30/172]  eta: 0:03:49  lr: 0.000015  loss: 0.9534 (0.9495)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [ 40/172]  eta: 0:03:32  lr: 0.000015  loss: 0.9095 (0.9366)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [ 50/172]  eta: 0:03:15  lr: 0.000015  loss: 0.8948 (0.9346)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [ 60/172]  eta: 0:02:59  lr: 0.000015  loss: 0.9400 (0.9380)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [ 70/172]  eta: 0:02:42  lr: 0.000015  loss: 0.9706 (0.9418)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [ 80/172]  eta: 0:02:26  lr: 0.000015  loss: 0.9727 (0.9441)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:866]  [ 90/172]  eta: 0:02:10  lr: 0.000015  loss: 0.9392 (0.9416)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [100/172]  eta: 0:01:54  lr: 0.000015  loss: 0.9392 (0.9415)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [110/172]  eta: 0:01:38  lr: 0.000015  loss: 0.9327 (0.9412)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [120/172]  eta: 0:01:22  lr: 0.000015  loss: 0.9294 (0.9417)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [130/172]  eta: 0:01:06  lr: 0.000015  loss: 0.9201 (0.9408)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [140/172]  eta: 0:00:50  lr: 0.000015  loss: 0.9158 (0.9396)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [150/172]  eta: 0:00:34  lr: 0.000015  loss: 0.9223 (0.9396)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [160/172]  eta: 0:00:19  lr: 0.000015  loss: 0.9341 (0.9403)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [170/172]  eta: 0:00:03  lr: 0.000015  loss: 0.9594 (0.9427)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866]  [171/172]  eta: 0:00:01  lr: 0.000015  loss: 0.9594 (0.9425)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:866] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000015  loss: 0.9594 (0.9425)\n",
      "Valid: [epoch:866]  [ 0/14]  eta: 0:00:04  loss: 0.8465 (0.8465)  time: 0.2954  data: 0.2782  max mem: 20571\n",
      "Valid: [epoch:866]  [13/14]  eta: 0:00:00  loss: 0.8905 (0.9028)  time: 0.0440  data: 0.0288  max mem: 20571\n",
      "Valid: [epoch:866] Total time: 0:00:00 (0.0515 s / it)\n",
      "Averaged stats: loss: 0.8905 (0.9028)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_866_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.903%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:867]  [  0/172]  eta: 0:07:58  lr: 0.000015  loss: 0.8635 (0.8635)  time: 2.7844  data: 1.1969  max mem: 20571\n",
      "Train: [epoch:867]  [ 10/172]  eta: 0:04:33  lr: 0.000015  loss: 0.9136 (0.9237)  time: 1.6877  data: 0.1089  max mem: 20571\n",
      "Train: [epoch:867]  [ 20/172]  eta: 0:04:08  lr: 0.000015  loss: 0.9188 (0.9347)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [ 30/172]  eta: 0:03:49  lr: 0.000015  loss: 0.9069 (0.9264)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [ 40/172]  eta: 0:03:32  lr: 0.000015  loss: 0.9135 (0.9360)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [ 50/172]  eta: 0:03:15  lr: 0.000015  loss: 0.9440 (0.9362)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [ 60/172]  eta: 0:02:59  lr: 0.000015  loss: 0.9380 (0.9351)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [ 70/172]  eta: 0:02:42  lr: 0.000015  loss: 0.9422 (0.9389)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [ 80/172]  eta: 0:02:26  lr: 0.000015  loss: 0.9417 (0.9375)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [ 90/172]  eta: 0:02:10  lr: 0.000015  loss: 0.9179 (0.9374)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [100/172]  eta: 0:01:54  lr: 0.000015  loss: 0.9367 (0.9385)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [110/172]  eta: 0:01:38  lr: 0.000015  loss: 0.9566 (0.9407)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [120/172]  eta: 0:01:22  lr: 0.000015  loss: 0.9566 (0.9419)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [130/172]  eta: 0:01:06  lr: 0.000015  loss: 0.9555 (0.9417)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [140/172]  eta: 0:00:50  lr: 0.000015  loss: 0.9470 (0.9417)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [150/172]  eta: 0:00:34  lr: 0.000015  loss: 0.9354 (0.9412)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [160/172]  eta: 0:00:19  lr: 0.000015  loss: 0.9488 (0.9434)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [170/172]  eta: 0:00:03  lr: 0.000015  loss: 0.9559 (0.9436)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867]  [171/172]  eta: 0:00:01  lr: 0.000015  loss: 0.9559 (0.9434)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:867] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000015  loss: 0.9559 (0.9434)\n",
      "Valid: [epoch:867]  [ 0/14]  eta: 0:00:04  loss: 0.8274 (0.8274)  time: 0.3084  data: 0.2934  max mem: 20571\n",
      "Valid: [epoch:867]  [13/14]  eta: 0:00:00  loss: 0.8911 (0.9034)  time: 0.0405  data: 0.0252  max mem: 20571\n",
      "Valid: [epoch:867] Total time: 0:00:00 (0.0460 s / it)\n",
      "Averaged stats: loss: 0.8911 (0.9034)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_867_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.903%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:868]  [  0/172]  eta: 0:07:23  lr: 0.000015  loss: 0.9229 (0.9229)  time: 2.5804  data: 0.9974  max mem: 20571\n",
      "Train: [epoch:868]  [ 10/172]  eta: 0:04:31  lr: 0.000015  loss: 0.9555 (0.9568)  time: 1.6740  data: 0.0908  max mem: 20571\n",
      "Train: [epoch:868]  [ 20/172]  eta: 0:04:07  lr: 0.000015  loss: 0.9555 (0.9638)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [ 30/172]  eta: 0:03:49  lr: 0.000015  loss: 0.9900 (0.9708)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [ 40/172]  eta: 0:03:32  lr: 0.000015  loss: 0.9496 (0.9604)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [ 50/172]  eta: 0:03:15  lr: 0.000015  loss: 0.9248 (0.9568)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [ 60/172]  eta: 0:02:59  lr: 0.000015  loss: 0.9336 (0.9550)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [ 70/172]  eta: 0:02:42  lr: 0.000015  loss: 0.9364 (0.9544)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:868]  [ 80/172]  eta: 0:02:26  lr: 0.000015  loss: 0.9523 (0.9540)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [ 90/172]  eta: 0:02:10  lr: 0.000015  loss: 0.9523 (0.9534)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [100/172]  eta: 0:01:54  lr: 0.000015  loss: 0.9419 (0.9511)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [110/172]  eta: 0:01:38  lr: 0.000015  loss: 0.9196 (0.9480)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [120/172]  eta: 0:01:22  lr: 0.000015  loss: 0.9261 (0.9470)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [130/172]  eta: 0:01:06  lr: 0.000015  loss: 0.9450 (0.9480)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [140/172]  eta: 0:00:50  lr: 0.000015  loss: 0.9327 (0.9469)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [150/172]  eta: 0:00:34  lr: 0.000015  loss: 0.9213 (0.9461)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [160/172]  eta: 0:00:19  lr: 0.000015  loss: 0.9358 (0.9454)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868]  [170/172]  eta: 0:00:03  lr: 0.000015  loss: 0.9430 (0.9453)  time: 1.5826  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:868]  [171/172]  eta: 0:00:01  lr: 0.000015  loss: 0.9285 (0.9450)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:868] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000015  loss: 0.9285 (0.9450)\n",
      "Valid: [epoch:868]  [ 0/14]  eta: 0:00:04  loss: 0.9888 (0.9888)  time: 0.2981  data: 0.2833  max mem: 20571\n",
      "Valid: [epoch:868]  [13/14]  eta: 0:00:00  loss: 0.8967 (0.9083)  time: 0.0405  data: 0.0255  max mem: 20571\n",
      "Valid: [epoch:868] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.8967 (0.9083)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_868_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.908%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:869]  [  0/172]  eta: 0:08:11  lr: 0.000015  loss: 0.9531 (0.9531)  time: 2.8547  data: 1.2787  max mem: 20571\n",
      "Train: [epoch:869]  [ 10/172]  eta: 0:04:34  lr: 0.000015  loss: 0.9602 (0.9690)  time: 1.6917  data: 0.1163  max mem: 20571\n",
      "Train: [epoch:869]  [ 20/172]  eta: 0:04:08  lr: 0.000015  loss: 0.9324 (0.9472)  time: 1.5764  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [ 30/172]  eta: 0:03:49  lr: 0.000015  loss: 0.9028 (0.9393)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [ 40/172]  eta: 0:03:32  lr: 0.000015  loss: 0.9044 (0.9338)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [ 50/172]  eta: 0:03:15  lr: 0.000015  loss: 0.9151 (0.9328)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:869]  [ 60/172]  eta: 0:02:59  lr: 0.000015  loss: 0.9336 (0.9376)  time: 1.5824  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:869]  [ 70/172]  eta: 0:02:42  lr: 0.000015  loss: 0.9367 (0.9386)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [ 80/172]  eta: 0:02:26  lr: 0.000015  loss: 0.9382 (0.9413)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [ 90/172]  eta: 0:02:10  lr: 0.000015  loss: 0.9429 (0.9408)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [100/172]  eta: 0:01:54  lr: 0.000015  loss: 0.9516 (0.9438)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [110/172]  eta: 0:01:38  lr: 0.000015  loss: 0.9418 (0.9428)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [120/172]  eta: 0:01:22  lr: 0.000015  loss: 0.9309 (0.9423)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [130/172]  eta: 0:01:06  lr: 0.000015  loss: 0.9430 (0.9445)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [140/172]  eta: 0:00:50  lr: 0.000015  loss: 0.9589 (0.9431)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [150/172]  eta: 0:00:34  lr: 0.000015  loss: 0.9415 (0.9437)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [160/172]  eta: 0:00:19  lr: 0.000015  loss: 0.9593 (0.9450)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [170/172]  eta: 0:00:03  lr: 0.000015  loss: 0.9770 (0.9466)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869]  [171/172]  eta: 0:00:01  lr: 0.000015  loss: 0.9695 (0.9466)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:869] Total time: 0:04:33 (1.5896 s / it)\n",
      "Averaged stats: lr: 0.000015  loss: 0.9695 (0.9466)\n",
      "Valid: [epoch:869]  [ 0/14]  eta: 0:00:04  loss: 0.9709 (0.9709)  time: 0.3141  data: 0.2985  max mem: 20571\n",
      "Valid: [epoch:869]  [13/14]  eta: 0:00:00  loss: 0.9127 (0.9255)  time: 0.0410  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:869] Total time: 0:00:00 (0.0505 s / it)\n",
      "Averaged stats: loss: 0.9127 (0.9255)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_869_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.925%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:870]  [  0/172]  eta: 0:07:53  lr: 0.000015  loss: 1.0040 (1.0040)  time: 2.7528  data: 1.1750  max mem: 20571\n",
      "Train: [epoch:870]  [ 10/172]  eta: 0:04:32  lr: 0.000015  loss: 0.9461 (0.9441)  time: 1.6850  data: 0.1069  max mem: 20571\n",
      "Train: [epoch:870]  [ 20/172]  eta: 0:04:08  lr: 0.000015  loss: 0.9341 (0.9494)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [ 30/172]  eta: 0:03:49  lr: 0.000015  loss: 0.9133 (0.9392)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [ 40/172]  eta: 0:03:32  lr: 0.000015  loss: 0.9431 (0.9463)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [ 50/172]  eta: 0:03:15  lr: 0.000015  loss: 0.9468 (0.9406)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [ 60/172]  eta: 0:02:59  lr: 0.000015  loss: 0.9145 (0.9435)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [ 70/172]  eta: 0:02:42  lr: 0.000015  loss: 0.9641 (0.9438)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [ 80/172]  eta: 0:02:26  lr: 0.000015  loss: 0.9235 (0.9425)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [ 90/172]  eta: 0:02:10  lr: 0.000015  loss: 0.9385 (0.9434)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [100/172]  eta: 0:01:54  lr: 0.000015  loss: 0.9595 (0.9458)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [110/172]  eta: 0:01:38  lr: 0.000015  loss: 0.9465 (0.9462)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [120/172]  eta: 0:01:22  lr: 0.000015  loss: 0.9227 (0.9427)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [130/172]  eta: 0:01:06  lr: 0.000015  loss: 0.9217 (0.9439)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [140/172]  eta: 0:00:50  lr: 0.000015  loss: 0.9366 (0.9429)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [150/172]  eta: 0:00:34  lr: 0.000015  loss: 0.9349 (0.9445)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [160/172]  eta: 0:00:19  lr: 0.000015  loss: 0.9404 (0.9455)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [170/172]  eta: 0:00:03  lr: 0.000015  loss: 0.9633 (0.9463)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870]  [171/172]  eta: 0:00:01  lr: 0.000015  loss: 0.9633 (0.9460)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:870] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000015  loss: 0.9633 (0.9460)\n",
      "Valid: [epoch:870]  [ 0/14]  eta: 0:00:04  loss: 0.9437 (0.9437)  time: 0.2892  data: 0.2730  max mem: 20571\n",
      "Valid: [epoch:870]  [13/14]  eta: 0:00:00  loss: 0.8935 (0.9057)  time: 0.0396  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:870] Total time: 0:00:00 (0.0440 s / it)\n",
      "Averaged stats: loss: 0.8935 (0.9057)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_870_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.906%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:871]  [  0/172]  eta: 0:07:42  lr: 0.000014  loss: 0.9304 (0.9304)  time: 2.6878  data: 1.1057  max mem: 20571\n",
      "Train: [epoch:871]  [ 10/172]  eta: 0:04:31  lr: 0.000014  loss: 0.9308 (0.9248)  time: 1.6777  data: 0.1006  max mem: 20571\n",
      "Train: [epoch:871]  [ 20/172]  eta: 0:04:07  lr: 0.000014  loss: 0.9308 (0.9436)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [ 30/172]  eta: 0:03:49  lr: 0.000014  loss: 0.9252 (0.9398)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [ 40/172]  eta: 0:03:32  lr: 0.000014  loss: 0.9252 (0.9449)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [ 50/172]  eta: 0:03:15  lr: 0.000014  loss: 0.9355 (0.9498)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [ 60/172]  eta: 0:02:58  lr: 0.000014  loss: 0.9355 (0.9493)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [ 70/172]  eta: 0:02:42  lr: 0.000014  loss: 0.9402 (0.9492)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [ 80/172]  eta: 0:02:26  lr: 0.000014  loss: 0.9408 (0.9488)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [ 90/172]  eta: 0:02:10  lr: 0.000014  loss: 0.9408 (0.9489)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [100/172]  eta: 0:01:54  lr: 0.000014  loss: 0.9457 (0.9485)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [110/172]  eta: 0:01:38  lr: 0.000014  loss: 0.9514 (0.9481)  time: 1.5830  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:871]  [120/172]  eta: 0:01:22  lr: 0.000014  loss: 0.9331 (0.9489)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [130/172]  eta: 0:01:06  lr: 0.000014  loss: 0.9331 (0.9479)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [140/172]  eta: 0:00:50  lr: 0.000014  loss: 0.9463 (0.9494)  time: 1.5796  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:871]  [150/172]  eta: 0:00:34  lr: 0.000014  loss: 0.9339 (0.9473)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [160/172]  eta: 0:00:19  lr: 0.000014  loss: 0.9393 (0.9473)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:871]  [170/172]  eta: 0:00:03  lr: 0.000014  loss: 0.9604 (0.9484)  time: 1.5832  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:871]  [171/172]  eta: 0:00:01  lr: 0.000014  loss: 0.9604 (0.9483)  time: 1.5832  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:871] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000014  loss: 0.9604 (0.9483)\n",
      "Valid: [epoch:871]  [ 0/14]  eta: 0:00:04  loss: 0.8775 (0.8775)  time: 0.3038  data: 0.2887  max mem: 20571\n",
      "Valid: [epoch:871]  [13/14]  eta: 0:00:00  loss: 0.8956 (0.9087)  time: 0.0415  data: 0.0264  max mem: 20571\n",
      "Valid: [epoch:871] Total time: 0:00:00 (0.0470 s / it)\n",
      "Averaged stats: loss: 0.8956 (0.9087)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_871_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.909%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:872]  [  0/172]  eta: 0:07:50  lr: 0.000014  loss: 0.9779 (0.9779)  time: 2.7342  data: 1.1505  max mem: 20571\n",
      "Train: [epoch:872]  [ 10/172]  eta: 0:04:32  lr: 0.000014  loss: 0.9451 (0.9348)  time: 1.6831  data: 0.1047  max mem: 20571\n",
      "Train: [epoch:872]  [ 20/172]  eta: 0:04:08  lr: 0.000014  loss: 0.9472 (0.9430)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [ 30/172]  eta: 0:03:49  lr: 0.000014  loss: 0.9475 (0.9439)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [ 40/172]  eta: 0:03:32  lr: 0.000014  loss: 0.9632 (0.9490)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [ 50/172]  eta: 0:03:15  lr: 0.000014  loss: 0.9468 (0.9480)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [ 60/172]  eta: 0:02:59  lr: 0.000014  loss: 0.9409 (0.9481)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [ 70/172]  eta: 0:02:42  lr: 0.000014  loss: 0.9487 (0.9489)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [ 80/172]  eta: 0:02:26  lr: 0.000014  loss: 0.9411 (0.9488)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [ 90/172]  eta: 0:02:10  lr: 0.000014  loss: 0.9411 (0.9476)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [100/172]  eta: 0:01:54  lr: 0.000014  loss: 0.9516 (0.9484)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [110/172]  eta: 0:01:38  lr: 0.000014  loss: 0.9384 (0.9472)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [120/172]  eta: 0:01:22  lr: 0.000014  loss: 0.9327 (0.9485)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [130/172]  eta: 0:01:06  lr: 0.000014  loss: 0.9396 (0.9507)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [140/172]  eta: 0:00:50  lr: 0.000014  loss: 0.9371 (0.9490)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [150/172]  eta: 0:00:34  lr: 0.000014  loss: 0.9260 (0.9483)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [160/172]  eta: 0:00:19  lr: 0.000014  loss: 0.9485 (0.9501)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [170/172]  eta: 0:00:03  lr: 0.000014  loss: 0.9580 (0.9496)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872]  [171/172]  eta: 0:00:01  lr: 0.000014  loss: 0.9576 (0.9496)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:872] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000014  loss: 0.9576 (0.9496)\n",
      "Valid: [epoch:872]  [ 0/14]  eta: 0:00:05  loss: 0.8507 (0.8507)  time: 0.3702  data: 0.3520  max mem: 20571\n",
      "Valid: [epoch:872]  [13/14]  eta: 0:00:00  loss: 0.8952 (0.9079)  time: 0.0410  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:872] Total time: 0:00:00 (0.0460 s / it)\n",
      "Averaged stats: loss: 0.8952 (0.9079)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_872_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.908%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:873]  [  0/172]  eta: 0:07:41  lr: 0.000014  loss: 0.9819 (0.9819)  time: 2.6836  data: 1.1011  max mem: 20571\n",
      "Train: [epoch:873]  [ 10/172]  eta: 0:04:32  lr: 0.000014  loss: 0.9662 (0.9591)  time: 1.6799  data: 0.1002  max mem: 20571\n",
      "Train: [epoch:873]  [ 20/172]  eta: 0:04:08  lr: 0.000014  loss: 0.9485 (0.9528)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [ 30/172]  eta: 0:03:49  lr: 0.000014  loss: 0.9330 (0.9499)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [ 40/172]  eta: 0:03:32  lr: 0.000014  loss: 0.9330 (0.9491)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [ 50/172]  eta: 0:03:15  lr: 0.000014  loss: 0.9348 (0.9477)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [ 60/172]  eta: 0:02:59  lr: 0.000014  loss: 0.9531 (0.9543)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [ 70/172]  eta: 0:02:42  lr: 0.000014  loss: 0.9419 (0.9536)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [ 80/172]  eta: 0:02:26  lr: 0.000014  loss: 0.9368 (0.9539)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [ 90/172]  eta: 0:02:10  lr: 0.000014  loss: 0.9667 (0.9538)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [100/172]  eta: 0:01:54  lr: 0.000014  loss: 0.9192 (0.9511)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [110/172]  eta: 0:01:38  lr: 0.000014  loss: 0.9286 (0.9528)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [120/172]  eta: 0:01:22  lr: 0.000014  loss: 0.9359 (0.9521)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [130/172]  eta: 0:01:06  lr: 0.000014  loss: 0.9405 (0.9509)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [140/172]  eta: 0:00:50  lr: 0.000014  loss: 0.9142 (0.9492)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [150/172]  eta: 0:00:34  lr: 0.000014  loss: 0.9556 (0.9529)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [160/172]  eta: 0:00:19  lr: 0.000014  loss: 0.9554 (0.9510)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [170/172]  eta: 0:00:03  lr: 0.000014  loss: 0.9052 (0.9486)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873]  [171/172]  eta: 0:00:01  lr: 0.000014  loss: 0.9059 (0.9490)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:873] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000014  loss: 0.9059 (0.9490)\n",
      "Valid: [epoch:873]  [ 0/14]  eta: 0:00:03  loss: 0.9924 (0.9924)  time: 0.2721  data: 0.2559  max mem: 20571\n",
      "Valid: [epoch:873]  [13/14]  eta: 0:00:00  loss: 0.8988 (0.9118)  time: 0.0428  data: 0.0277  max mem: 20571\n",
      "Valid: [epoch:873] Total time: 0:00:00 (0.0474 s / it)\n",
      "Averaged stats: loss: 0.8988 (0.9118)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_873_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.912%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:874]  [  0/172]  eta: 0:07:37  lr: 0.000014  loss: 0.9201 (0.9201)  time: 2.6602  data: 1.0881  max mem: 20571\n",
      "Train: [epoch:874]  [ 10/172]  eta: 0:04:31  lr: 0.000014  loss: 0.9358 (0.9522)  time: 1.6784  data: 0.0990  max mem: 20571\n",
      "Train: [epoch:874]  [ 20/172]  eta: 0:04:08  lr: 0.000014  loss: 0.9771 (0.9761)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [ 30/172]  eta: 0:03:49  lr: 0.000014  loss: 0.9771 (0.9676)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [ 40/172]  eta: 0:03:32  lr: 0.000014  loss: 0.9435 (0.9647)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [ 50/172]  eta: 0:03:15  lr: 0.000014  loss: 0.9147 (0.9571)  time: 1.5814  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:874]  [ 60/172]  eta: 0:02:59  lr: 0.000014  loss: 0.9359 (0.9575)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [ 70/172]  eta: 0:02:42  lr: 0.000014  loss: 0.9534 (0.9571)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [ 80/172]  eta: 0:02:26  lr: 0.000014  loss: 0.9452 (0.9539)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [ 90/172]  eta: 0:02:10  lr: 0.000014  loss: 0.9304 (0.9534)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [100/172]  eta: 0:01:54  lr: 0.000014  loss: 0.9304 (0.9514)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [110/172]  eta: 0:01:38  lr: 0.000014  loss: 0.9247 (0.9493)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [120/172]  eta: 0:01:22  lr: 0.000014  loss: 0.9368 (0.9493)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [130/172]  eta: 0:01:06  lr: 0.000014  loss: 0.9457 (0.9512)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [140/172]  eta: 0:00:50  lr: 0.000014  loss: 0.9454 (0.9501)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [150/172]  eta: 0:00:34  lr: 0.000014  loss: 0.9399 (0.9514)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [160/172]  eta: 0:00:19  lr: 0.000014  loss: 0.9582 (0.9525)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [170/172]  eta: 0:00:03  lr: 0.000014  loss: 0.9562 (0.9519)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874]  [171/172]  eta: 0:00:01  lr: 0.000014  loss: 0.9500 (0.9516)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:874] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000014  loss: 0.9500 (0.9516)\n",
      "Valid: [epoch:874]  [ 0/14]  eta: 0:00:03  loss: 0.8979 (0.8979)  time: 0.2798  data: 0.2613  max mem: 20571\n",
      "Valid: [epoch:874]  [13/14]  eta: 0:00:00  loss: 0.8979 (0.9107)  time: 0.0356  data: 0.0202  max mem: 20571\n",
      "Valid: [epoch:874] Total time: 0:00:00 (0.0447 s / it)\n",
      "Averaged stats: loss: 0.8979 (0.9107)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_874_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.911%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:875]  [  0/172]  eta: 0:07:15  lr: 0.000014  loss: 0.9359 (0.9359)  time: 2.5348  data: 0.9593  max mem: 20571\n",
      "Train: [epoch:875]  [ 10/172]  eta: 0:04:29  lr: 0.000014  loss: 0.9359 (0.9373)  time: 1.6632  data: 0.0873  max mem: 20571\n",
      "Train: [epoch:875]  [ 20/172]  eta: 0:04:06  lr: 0.000014  loss: 0.9437 (0.9486)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [ 30/172]  eta: 0:03:48  lr: 0.000014  loss: 0.9513 (0.9442)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [ 40/172]  eta: 0:03:31  lr: 0.000014  loss: 0.9402 (0.9424)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [ 50/172]  eta: 0:03:14  lr: 0.000014  loss: 0.9520 (0.9495)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [ 60/172]  eta: 0:02:58  lr: 0.000014  loss: 0.9692 (0.9488)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [ 70/172]  eta: 0:02:42  lr: 0.000014  loss: 0.9460 (0.9492)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [ 80/172]  eta: 0:02:26  lr: 0.000014  loss: 0.9460 (0.9492)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [ 90/172]  eta: 0:02:10  lr: 0.000014  loss: 0.9755 (0.9503)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [100/172]  eta: 0:01:54  lr: 0.000014  loss: 0.9358 (0.9506)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [110/172]  eta: 0:01:38  lr: 0.000014  loss: 0.9281 (0.9504)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [120/172]  eta: 0:01:22  lr: 0.000014  loss: 0.9581 (0.9498)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [130/172]  eta: 0:01:06  lr: 0.000014  loss: 0.9598 (0.9507)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [140/172]  eta: 0:00:50  lr: 0.000014  loss: 0.9414 (0.9497)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [150/172]  eta: 0:00:34  lr: 0.000014  loss: 0.9388 (0.9493)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [160/172]  eta: 0:00:19  lr: 0.000014  loss: 0.9472 (0.9501)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [170/172]  eta: 0:00:03  lr: 0.000014  loss: 0.9695 (0.9517)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875]  [171/172]  eta: 0:00:01  lr: 0.000014  loss: 0.9695 (0.9519)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:875] Total time: 0:04:33 (1.5874 s / it)\n",
      "Averaged stats: lr: 0.000014  loss: 0.9695 (0.9519)\n",
      "Valid: [epoch:875]  [ 0/14]  eta: 0:00:04  loss: 0.9916 (0.9916)  time: 0.3100  data: 0.2936  max mem: 20571\n",
      "Valid: [epoch:875]  [13/14]  eta: 0:00:00  loss: 0.8977 (0.9106)  time: 0.0378  data: 0.0227  max mem: 20571\n",
      "Valid: [epoch:875] Total time: 0:00:00 (0.0434 s / it)\n",
      "Averaged stats: loss: 0.8977 (0.9106)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_875_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.911%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:876]  [  0/172]  eta: 0:07:33  lr: 0.000014  loss: 0.8502 (0.8502)  time: 2.6357  data: 1.0647  max mem: 20571\n",
      "Train: [epoch:876]  [ 10/172]  eta: 0:04:31  lr: 0.000014  loss: 0.9311 (0.9136)  time: 1.6787  data: 0.0970  max mem: 20571\n",
      "Train: [epoch:876]  [ 20/172]  eta: 0:04:08  lr: 0.000014  loss: 0.9323 (0.9319)  time: 1.5832  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:876]  [ 30/172]  eta: 0:03:49  lr: 0.000014  loss: 0.9574 (0.9381)  time: 1.5833  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:876]  [ 40/172]  eta: 0:03:32  lr: 0.000014  loss: 0.9652 (0.9377)  time: 1.5886  data: 0.0049  max mem: 20571\n",
      "Train: [epoch:876]  [ 50/172]  eta: 0:03:15  lr: 0.000014  loss: 0.9483 (0.9405)  time: 1.5887  data: 0.0049  max mem: 20571\n",
      "Train: [epoch:876]  [ 60/172]  eta: 0:02:59  lr: 0.000014  loss: 0.9483 (0.9465)  time: 1.5837  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:876]  [ 70/172]  eta: 0:02:43  lr: 0.000014  loss: 0.9573 (0.9470)  time: 1.5832  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:876]  [ 80/172]  eta: 0:02:26  lr: 0.000014  loss: 0.9444 (0.9453)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [ 90/172]  eta: 0:02:10  lr: 0.000014  loss: 0.9269 (0.9459)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [100/172]  eta: 0:01:54  lr: 0.000014  loss: 0.9460 (0.9458)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [110/172]  eta: 0:01:38  lr: 0.000014  loss: 0.9282 (0.9465)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [120/172]  eta: 0:01:22  lr: 0.000014  loss: 0.9387 (0.9480)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [130/172]  eta: 0:01:06  lr: 0.000014  loss: 0.9645 (0.9496)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [140/172]  eta: 0:00:50  lr: 0.000014  loss: 0.9506 (0.9482)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [150/172]  eta: 0:00:34  lr: 0.000014  loss: 0.9498 (0.9511)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [160/172]  eta: 0:00:19  lr: 0.000014  loss: 0.9655 (0.9524)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [170/172]  eta: 0:00:03  lr: 0.000014  loss: 0.9701 (0.9535)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876]  [171/172]  eta: 0:00:01  lr: 0.000014  loss: 0.9687 (0.9535)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:876] Total time: 0:04:33 (1.5902 s / it)\n",
      "Averaged stats: lr: 0.000014  loss: 0.9687 (0.9535)\n",
      "Valid: [epoch:876]  [ 0/14]  eta: 0:00:07  loss: 0.8839 (0.8839)  time: 0.5276  data: 0.5097  max mem: 20571\n",
      "Valid: [epoch:876]  [13/14]  eta: 0:00:00  loss: 0.9020 (0.9148)  time: 0.0528  data: 0.0376  max mem: 20571\n",
      "Valid: [epoch:876] Total time: 0:00:00 (0.0581 s / it)\n",
      "Averaged stats: loss: 0.9020 (0.9148)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_876_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.915%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:877]  [  0/172]  eta: 0:07:48  lr: 0.000014  loss: 0.9517 (0.9517)  time: 2.7262  data: 1.1450  max mem: 20571\n",
      "Train: [epoch:877]  [ 10/172]  eta: 0:04:32  lr: 0.000014  loss: 0.9340 (0.9433)  time: 1.6838  data: 0.1042  max mem: 20571\n",
      "Train: [epoch:877]  [ 20/172]  eta: 0:04:08  lr: 0.000014  loss: 0.9558 (0.9609)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [ 30/172]  eta: 0:03:49  lr: 0.000014  loss: 0.9558 (0.9489)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [ 40/172]  eta: 0:03:32  lr: 0.000014  loss: 0.9150 (0.9482)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [ 50/172]  eta: 0:03:15  lr: 0.000014  loss: 0.9312 (0.9446)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [ 60/172]  eta: 0:02:59  lr: 0.000014  loss: 0.9312 (0.9427)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [ 70/172]  eta: 0:02:42  lr: 0.000014  loss: 0.9392 (0.9459)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [ 80/172]  eta: 0:02:26  lr: 0.000014  loss: 0.9445 (0.9458)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [ 90/172]  eta: 0:02:10  lr: 0.000014  loss: 0.9338 (0.9445)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [100/172]  eta: 0:01:54  lr: 0.000014  loss: 0.9487 (0.9492)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [110/172]  eta: 0:01:38  lr: 0.000014  loss: 0.9815 (0.9523)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [120/172]  eta: 0:01:22  lr: 0.000014  loss: 0.9391 (0.9512)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [130/172]  eta: 0:01:06  lr: 0.000014  loss: 0.9398 (0.9513)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [140/172]  eta: 0:00:50  lr: 0.000014  loss: 0.9494 (0.9523)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [150/172]  eta: 0:00:34  lr: 0.000014  loss: 0.9739 (0.9554)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [160/172]  eta: 0:00:19  lr: 0.000014  loss: 0.9928 (0.9555)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [170/172]  eta: 0:00:03  lr: 0.000014  loss: 0.9181 (0.9550)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877]  [171/172]  eta: 0:00:01  lr: 0.000014  loss: 0.9410 (0.9549)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:877] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000014  loss: 0.9410 (0.9549)\n",
      "Valid: [epoch:877]  [ 0/14]  eta: 0:00:04  loss: 0.9013 (0.9013)  time: 0.3432  data: 0.3267  max mem: 20571\n",
      "Valid: [epoch:877]  [13/14]  eta: 0:00:00  loss: 0.9013 (0.9140)  time: 0.0396  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:877] Total time: 0:00:00 (0.0483 s / it)\n",
      "Averaged stats: loss: 0.9013 (0.9140)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_877_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.914%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:878]  [  0/172]  eta: 0:07:42  lr: 0.000014  loss: 0.8785 (0.8785)  time: 2.6915  data: 1.1234  max mem: 20571\n",
      "Train: [epoch:878]  [ 10/172]  eta: 0:04:32  lr: 0.000014  loss: 0.9144 (0.9304)  time: 1.6810  data: 0.1022  max mem: 20571\n",
      "Train: [epoch:878]  [ 20/172]  eta: 0:04:08  lr: 0.000014  loss: 0.9324 (0.9411)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [ 30/172]  eta: 0:03:49  lr: 0.000014  loss: 0.9662 (0.9556)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [ 40/172]  eta: 0:03:32  lr: 0.000014  loss: 0.9522 (0.9480)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [ 50/172]  eta: 0:03:15  lr: 0.000014  loss: 0.9247 (0.9497)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [ 60/172]  eta: 0:02:59  lr: 0.000014  loss: 0.9554 (0.9520)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [ 70/172]  eta: 0:02:42  lr: 0.000014  loss: 0.9637 (0.9551)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [ 80/172]  eta: 0:02:26  lr: 0.000014  loss: 0.9491 (0.9521)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [ 90/172]  eta: 0:02:10  lr: 0.000014  loss: 0.9464 (0.9539)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [100/172]  eta: 0:01:54  lr: 0.000014  loss: 0.9480 (0.9519)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [110/172]  eta: 0:01:38  lr: 0.000014  loss: 0.9321 (0.9510)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [120/172]  eta: 0:01:22  lr: 0.000014  loss: 0.9340 (0.9516)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [130/172]  eta: 0:01:06  lr: 0.000014  loss: 0.9389 (0.9500)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [140/172]  eta: 0:00:50  lr: 0.000014  loss: 0.9439 (0.9533)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [150/172]  eta: 0:00:34  lr: 0.000014  loss: 0.9512 (0.9531)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [160/172]  eta: 0:00:19  lr: 0.000014  loss: 0.9349 (0.9528)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [170/172]  eta: 0:00:03  lr: 0.000014  loss: 0.9349 (0.9536)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878]  [171/172]  eta: 0:00:01  lr: 0.000014  loss: 0.9417 (0.9535)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:878] Total time: 0:04:33 (1.5888 s / it)\n",
      "Averaged stats: lr: 0.000014  loss: 0.9417 (0.9535)\n",
      "Valid: [epoch:878]  [ 0/14]  eta: 0:00:03  loss: 0.8157 (0.8157)  time: 0.2845  data: 0.2673  max mem: 20571\n",
      "Valid: [epoch:878]  [13/14]  eta: 0:00:00  loss: 0.9035 (0.9161)  time: 0.0365  data: 0.0213  max mem: 20571\n",
      "Valid: [epoch:878] Total time: 0:00:00 (0.0447 s / it)\n",
      "Averaged stats: loss: 0.9035 (0.9161)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_878_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.916%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:879]  [  0/172]  eta: 0:07:35  lr: 0.000014  loss: 0.8550 (0.8550)  time: 2.6469  data: 1.0642  max mem: 20571\n",
      "Train: [epoch:879]  [ 10/172]  eta: 0:04:31  lr: 0.000014  loss: 0.9377 (0.9312)  time: 1.6746  data: 0.0969  max mem: 20571\n",
      "Train: [epoch:879]  [ 20/172]  eta: 0:04:07  lr: 0.000014  loss: 0.9551 (0.9539)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [ 30/172]  eta: 0:03:49  lr: 0.000014  loss: 0.9551 (0.9468)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [ 40/172]  eta: 0:03:31  lr: 0.000014  loss: 0.9516 (0.9495)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [ 50/172]  eta: 0:03:15  lr: 0.000014  loss: 0.9628 (0.9593)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [ 60/172]  eta: 0:02:58  lr: 0.000014  loss: 0.9559 (0.9568)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [ 70/172]  eta: 0:02:42  lr: 0.000014  loss: 0.9559 (0.9603)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [ 80/172]  eta: 0:02:26  lr: 0.000014  loss: 0.9528 (0.9565)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [ 90/172]  eta: 0:02:10  lr: 0.000014  loss: 0.9359 (0.9551)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [100/172]  eta: 0:01:54  lr: 0.000014  loss: 0.9448 (0.9553)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [110/172]  eta: 0:01:38  lr: 0.000014  loss: 0.9358 (0.9535)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [120/172]  eta: 0:01:22  lr: 0.000014  loss: 0.9475 (0.9563)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [130/172]  eta: 0:01:06  lr: 0.000014  loss: 0.9757 (0.9561)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [140/172]  eta: 0:00:50  lr: 0.000014  loss: 0.9405 (0.9564)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [150/172]  eta: 0:00:34  lr: 0.000014  loss: 0.9345 (0.9563)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [160/172]  eta: 0:00:19  lr: 0.000014  loss: 0.9545 (0.9560)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879]  [170/172]  eta: 0:00:03  lr: 0.000014  loss: 0.9486 (0.9548)  time: 1.5829  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:879]  [171/172]  eta: 0:00:01  lr: 0.000014  loss: 0.9486 (0.9554)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:879] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000014  loss: 0.9486 (0.9554)\n",
      "Valid: [epoch:879]  [ 0/14]  eta: 0:00:04  loss: 0.9548 (0.9548)  time: 0.2947  data: 0.2795  max mem: 20571\n",
      "Valid: [epoch:879]  [13/14]  eta: 0:00:00  loss: 0.9024 (0.9152)  time: 0.0437  data: 0.0288  max mem: 20571\n",
      "Valid: [epoch:879] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 0.9024 (0.9152)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_879_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.915%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:880]  [  0/172]  eta: 0:07:27  lr: 0.000013  loss: 0.9073 (0.9073)  time: 2.5998  data: 1.0319  max mem: 20571\n",
      "Train: [epoch:880]  [ 10/172]  eta: 0:04:30  lr: 0.000013  loss: 0.9704 (0.9604)  time: 1.6705  data: 0.0939  max mem: 20571\n",
      "Train: [epoch:880]  [ 20/172]  eta: 0:04:07  lr: 0.000013  loss: 0.9434 (0.9578)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [ 30/172]  eta: 0:03:48  lr: 0.000013  loss: 0.9322 (0.9519)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [ 40/172]  eta: 0:03:31  lr: 0.000013  loss: 0.9337 (0.9509)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [ 50/172]  eta: 0:03:15  lr: 0.000013  loss: 0.9418 (0.9527)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [ 60/172]  eta: 0:02:58  lr: 0.000013  loss: 0.9574 (0.9507)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [ 70/172]  eta: 0:02:42  lr: 0.000013  loss: 0.9563 (0.9507)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [ 80/172]  eta: 0:02:26  lr: 0.000013  loss: 0.9563 (0.9532)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [ 90/172]  eta: 0:02:10  lr: 0.000013  loss: 0.9654 (0.9556)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [100/172]  eta: 0:01:54  lr: 0.000013  loss: 0.9492 (0.9566)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [110/172]  eta: 0:01:38  lr: 0.000013  loss: 0.9727 (0.9602)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [120/172]  eta: 0:01:22  lr: 0.000013  loss: 0.9557 (0.9582)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [130/172]  eta: 0:01:06  lr: 0.000013  loss: 0.9137 (0.9555)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [140/172]  eta: 0:00:50  lr: 0.000013  loss: 0.9448 (0.9569)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [150/172]  eta: 0:00:34  lr: 0.000013  loss: 0.9476 (0.9555)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [160/172]  eta: 0:00:19  lr: 0.000013  loss: 0.9447 (0.9559)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [170/172]  eta: 0:00:03  lr: 0.000013  loss: 0.9448 (0.9562)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880]  [171/172]  eta: 0:00:01  lr: 0.000013  loss: 0.9448 (0.9569)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:880] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000013  loss: 0.9448 (0.9569)\n",
      "Valid: [epoch:880]  [ 0/14]  eta: 0:00:04  loss: 0.8184 (0.8184)  time: 0.2859  data: 0.2713  max mem: 20571\n",
      "Valid: [epoch:880]  [13/14]  eta: 0:00:00  loss: 0.9070 (0.9195)  time: 0.0374  data: 0.0223  max mem: 20571\n",
      "Valid: [epoch:880] Total time: 0:00:00 (0.0429 s / it)\n",
      "Averaged stats: loss: 0.9070 (0.9195)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_880_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.919%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:881]  [  0/172]  eta: 0:07:51  lr: 0.000013  loss: 0.9719 (0.9719)  time: 2.7429  data: 1.1663  max mem: 20571\n",
      "Train: [epoch:881]  [ 10/172]  eta: 0:04:32  lr: 0.000013  loss: 0.9381 (0.9507)  time: 1.6815  data: 0.1061  max mem: 20571\n",
      "Train: [epoch:881]  [ 20/172]  eta: 0:04:08  lr: 0.000013  loss: 0.9468 (0.9556)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [ 30/172]  eta: 0:03:49  lr: 0.000013  loss: 0.9591 (0.9565)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [ 40/172]  eta: 0:03:32  lr: 0.000013  loss: 0.9788 (0.9609)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [ 50/172]  eta: 0:03:15  lr: 0.000013  loss: 0.9608 (0.9590)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [ 60/172]  eta: 0:02:58  lr: 0.000013  loss: 0.9366 (0.9543)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [ 70/172]  eta: 0:02:42  lr: 0.000013  loss: 0.9366 (0.9570)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [ 80/172]  eta: 0:02:26  lr: 0.000013  loss: 0.9470 (0.9561)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [ 90/172]  eta: 0:02:10  lr: 0.000013  loss: 0.9540 (0.9594)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [100/172]  eta: 0:01:54  lr: 0.000013  loss: 0.9486 (0.9579)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [110/172]  eta: 0:01:38  lr: 0.000013  loss: 0.9378 (0.9589)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [120/172]  eta: 0:01:22  lr: 0.000013  loss: 0.9593 (0.9595)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [130/172]  eta: 0:01:06  lr: 0.000013  loss: 0.9506 (0.9596)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [140/172]  eta: 0:00:50  lr: 0.000013  loss: 0.9200 (0.9578)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [150/172]  eta: 0:00:34  lr: 0.000013  loss: 0.9200 (0.9563)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [160/172]  eta: 0:00:19  lr: 0.000013  loss: 0.9334 (0.9559)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [170/172]  eta: 0:00:03  lr: 0.000013  loss: 0.9603 (0.9580)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881]  [171/172]  eta: 0:00:01  lr: 0.000013  loss: 0.9603 (0.9582)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:881] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000013  loss: 0.9603 (0.9582)\n",
      "Valid: [epoch:881]  [ 0/14]  eta: 0:00:04  loss: 0.8406 (0.8406)  time: 0.3143  data: 0.2992  max mem: 20571\n",
      "Valid: [epoch:881]  [13/14]  eta: 0:00:00  loss: 0.9038 (0.9169)  time: 0.0367  data: 0.0215  max mem: 20571\n",
      "Valid: [epoch:881] Total time: 0:00:00 (0.0422 s / it)\n",
      "Averaged stats: loss: 0.9038 (0.9169)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_881_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.917%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:882]  [  0/172]  eta: 0:07:40  lr: 0.000013  loss: 0.9160 (0.9160)  time: 2.6782  data: 1.1087  max mem: 20571\n",
      "Train: [epoch:882]  [ 10/172]  eta: 0:04:32  lr: 0.000013  loss: 0.9367 (0.9556)  time: 1.6813  data: 0.1009  max mem: 20571\n",
      "Train: [epoch:882]  [ 20/172]  eta: 0:04:08  lr: 0.000013  loss: 0.9575 (0.9730)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [ 30/172]  eta: 0:03:49  lr: 0.000013  loss: 0.9733 (0.9653)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [ 40/172]  eta: 0:03:32  lr: 0.000013  loss: 0.9202 (0.9598)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [ 50/172]  eta: 0:03:15  lr: 0.000013  loss: 0.9202 (0.9602)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [ 60/172]  eta: 0:02:59  lr: 0.000013  loss: 0.9390 (0.9614)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [ 70/172]  eta: 0:02:42  lr: 0.000013  loss: 0.9390 (0.9585)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [ 80/172]  eta: 0:02:26  lr: 0.000013  loss: 0.9432 (0.9599)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [ 90/172]  eta: 0:02:10  lr: 0.000013  loss: 0.9493 (0.9595)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [100/172]  eta: 0:01:54  lr: 0.000013  loss: 0.9482 (0.9587)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [110/172]  eta: 0:01:38  lr: 0.000013  loss: 0.9482 (0.9593)  time: 1.5833  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:882]  [120/172]  eta: 0:01:22  lr: 0.000013  loss: 0.9595 (0.9608)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [130/172]  eta: 0:01:06  lr: 0.000013  loss: 0.9493 (0.9602)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [140/172]  eta: 0:00:50  lr: 0.000013  loss: 0.9461 (0.9613)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [150/172]  eta: 0:00:34  lr: 0.000013  loss: 0.9468 (0.9607)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [160/172]  eta: 0:00:19  lr: 0.000013  loss: 0.9552 (0.9605)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [170/172]  eta: 0:00:03  lr: 0.000013  loss: 0.9552 (0.9590)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882]  [171/172]  eta: 0:00:01  lr: 0.000013  loss: 0.9566 (0.9590)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:882] Total time: 0:04:33 (1.5895 s / it)\n",
      "Averaged stats: lr: 0.000013  loss: 0.9566 (0.9590)\n",
      "Valid: [epoch:882]  [ 0/14]  eta: 0:00:05  loss: 0.9633 (0.9633)  time: 0.3969  data: 0.3815  max mem: 20571\n",
      "Valid: [epoch:882]  [13/14]  eta: 0:00:00  loss: 0.9048 (0.9184)  time: 0.0446  data: 0.0296  max mem: 20571\n",
      "Valid: [epoch:882] Total time: 0:00:00 (0.0521 s / it)\n",
      "Averaged stats: loss: 0.9048 (0.9184)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_882_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.918%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:883]  [  0/172]  eta: 0:07:27  lr: 0.000013  loss: 0.8720 (0.8720)  time: 2.6030  data: 1.0048  max mem: 20571\n",
      "Train: [epoch:883]  [ 10/172]  eta: 0:04:30  lr: 0.000013  loss: 0.9489 (0.9466)  time: 1.6699  data: 0.0915  max mem: 20571\n",
      "Train: [epoch:883]  [ 20/172]  eta: 0:04:07  lr: 0.000013  loss: 0.9594 (0.9578)  time: 1.5775  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:883]  [ 30/172]  eta: 0:03:48  lr: 0.000013  loss: 0.9709 (0.9630)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [ 40/172]  eta: 0:03:31  lr: 0.000013  loss: 0.9450 (0.9572)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [ 50/172]  eta: 0:03:15  lr: 0.000013  loss: 0.9450 (0.9575)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [ 60/172]  eta: 0:02:58  lr: 0.000013  loss: 0.9643 (0.9578)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [ 70/172]  eta: 0:02:42  lr: 0.000013  loss: 0.9375 (0.9569)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [ 80/172]  eta: 0:02:26  lr: 0.000013  loss: 0.9375 (0.9550)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [ 90/172]  eta: 0:02:10  lr: 0.000013  loss: 0.9290 (0.9538)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [100/172]  eta: 0:01:54  lr: 0.000013  loss: 0.9639 (0.9565)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [110/172]  eta: 0:01:38  lr: 0.000013  loss: 0.9753 (0.9599)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [120/172]  eta: 0:01:22  lr: 0.000013  loss: 0.9638 (0.9599)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [130/172]  eta: 0:01:06  lr: 0.000013  loss: 0.9429 (0.9600)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [140/172]  eta: 0:00:50  lr: 0.000013  loss: 0.9439 (0.9593)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [150/172]  eta: 0:00:34  lr: 0.000013  loss: 0.9568 (0.9610)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [160/172]  eta: 0:00:19  lr: 0.000013  loss: 0.9481 (0.9606)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [170/172]  eta: 0:00:03  lr: 0.000013  loss: 0.9381 (0.9599)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883]  [171/172]  eta: 0:00:01  lr: 0.000013  loss: 0.9475 (0.9599)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:883] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000013  loss: 0.9475 (0.9599)\n",
      "Valid: [epoch:883]  [ 0/14]  eta: 0:00:03  loss: 1.0010 (1.0010)  time: 0.2847  data: 0.2697  max mem: 20571\n",
      "Valid: [epoch:883]  [13/14]  eta: 0:00:00  loss: 0.9068 (0.9201)  time: 0.0368  data: 0.0218  max mem: 20571\n",
      "Valid: [epoch:883] Total time: 0:00:00 (0.0439 s / it)\n",
      "Averaged stats: loss: 0.9068 (0.9201)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_883_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.920%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:884]  [  0/172]  eta: 0:08:02  lr: 0.000013  loss: 1.0117 (1.0117)  time: 2.8066  data: 1.2380  max mem: 20571\n",
      "Train: [epoch:884]  [ 10/172]  eta: 0:04:34  lr: 0.000013  loss: 0.9581 (0.9741)  time: 1.6928  data: 0.1127  max mem: 20571\n",
      "Train: [epoch:884]  [ 20/172]  eta: 0:04:09  lr: 0.000013  loss: 0.9696 (0.9763)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [ 30/172]  eta: 0:03:50  lr: 0.000013  loss: 0.9696 (0.9721)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [ 40/172]  eta: 0:03:32  lr: 0.000013  loss: 0.9465 (0.9656)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [ 50/172]  eta: 0:03:15  lr: 0.000013  loss: 0.9367 (0.9630)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [ 60/172]  eta: 0:02:59  lr: 0.000013  loss: 0.9618 (0.9666)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [ 70/172]  eta: 0:02:43  lr: 0.000013  loss: 0.9618 (0.9648)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [ 80/172]  eta: 0:02:26  lr: 0.000013  loss: 0.9240 (0.9627)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [ 90/172]  eta: 0:02:10  lr: 0.000013  loss: 0.9240 (0.9606)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:884]  [100/172]  eta: 0:01:54  lr: 0.000013  loss: 0.9456 (0.9637)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [110/172]  eta: 0:01:38  lr: 0.000013  loss: 0.9495 (0.9624)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [120/172]  eta: 0:01:22  lr: 0.000013  loss: 0.9505 (0.9622)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [130/172]  eta: 0:01:06  lr: 0.000013  loss: 0.9505 (0.9624)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [140/172]  eta: 0:00:50  lr: 0.000013  loss: 0.9463 (0.9619)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [150/172]  eta: 0:00:34  lr: 0.000013  loss: 0.9871 (0.9636)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [160/172]  eta: 0:00:19  lr: 0.000013  loss: 0.9917 (0.9642)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [170/172]  eta: 0:00:03  lr: 0.000013  loss: 0.9508 (0.9626)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884]  [171/172]  eta: 0:00:01  lr: 0.000013  loss: 0.9272 (0.9622)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:884] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000013  loss: 0.9272 (0.9622)\n",
      "Valid: [epoch:884]  [ 0/14]  eta: 0:00:07  loss: 1.0012 (1.0012)  time: 0.5020  data: 0.4864  max mem: 20571\n",
      "Valid: [epoch:884]  [13/14]  eta: 0:00:00  loss: 0.9073 (0.9205)  time: 0.0504  data: 0.0353  max mem: 20571\n",
      "Valid: [epoch:884] Total time: 0:00:00 (0.0558 s / it)\n",
      "Averaged stats: loss: 0.9073 (0.9205)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_884_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.921%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:885]  [  0/172]  eta: 0:07:33  lr: 0.000013  loss: 0.9303 (0.9303)  time: 2.6357  data: 1.0525  max mem: 20571\n",
      "Train: [epoch:885]  [ 10/172]  eta: 0:04:31  lr: 0.000013  loss: 0.9109 (0.9258)  time: 1.6783  data: 0.0958  max mem: 20571\n",
      "Train: [epoch:885]  [ 20/172]  eta: 0:04:07  lr: 0.000013  loss: 0.9109 (0.9334)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [ 30/172]  eta: 0:03:49  lr: 0.000013  loss: 0.9420 (0.9401)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [ 40/172]  eta: 0:03:32  lr: 0.000013  loss: 0.9332 (0.9374)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [ 50/172]  eta: 0:03:15  lr: 0.000013  loss: 0.9297 (0.9419)  time: 1.5853  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:885]  [ 60/172]  eta: 0:02:59  lr: 0.000013  loss: 0.9471 (0.9474)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [ 70/172]  eta: 0:02:43  lr: 0.000013  loss: 0.9431 (0.9478)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [ 80/172]  eta: 0:02:26  lr: 0.000013  loss: 0.9709 (0.9524)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [ 90/172]  eta: 0:02:10  lr: 0.000013  loss: 0.9904 (0.9584)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [100/172]  eta: 0:01:54  lr: 0.000013  loss: 0.9889 (0.9576)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [110/172]  eta: 0:01:38  lr: 0.000013  loss: 0.9194 (0.9571)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [120/172]  eta: 0:01:22  lr: 0.000013  loss: 0.9584 (0.9598)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [130/172]  eta: 0:01:06  lr: 0.000013  loss: 0.9564 (0.9594)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [140/172]  eta: 0:00:50  lr: 0.000013  loss: 0.9510 (0.9606)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [150/172]  eta: 0:00:35  lr: 0.000013  loss: 0.9889 (0.9620)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [160/172]  eta: 0:00:19  lr: 0.000013  loss: 0.9931 (0.9624)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [170/172]  eta: 0:00:03  lr: 0.000013  loss: 0.9614 (0.9627)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885]  [171/172]  eta: 0:00:01  lr: 0.000013  loss: 0.9661 (0.9628)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:885] Total time: 0:04:33 (1.5915 s / it)\n",
      "Averaged stats: lr: 0.000013  loss: 0.9661 (0.9628)\n",
      "Valid: [epoch:885]  [ 0/14]  eta: 0:00:04  loss: 0.9544 (0.9544)  time: 0.2995  data: 0.2842  max mem: 20571\n",
      "Valid: [epoch:885]  [13/14]  eta: 0:00:00  loss: 0.9077 (0.9204)  time: 0.0391  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:885] Total time: 0:00:00 (0.0438 s / it)\n",
      "Averaged stats: loss: 0.9077 (0.9204)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_885_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.920%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:886]  [  0/172]  eta: 0:07:32  lr: 0.000013  loss: 0.9569 (0.9569)  time: 2.6330  data: 1.0609  max mem: 20571\n",
      "Train: [epoch:886]  [ 10/172]  eta: 0:04:31  lr: 0.000013  loss: 0.9569 (0.9509)  time: 1.6787  data: 0.0965  max mem: 20571\n",
      "Train: [epoch:886]  [ 20/172]  eta: 0:04:08  lr: 0.000013  loss: 0.9443 (0.9503)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [ 30/172]  eta: 0:03:49  lr: 0.000013  loss: 0.9723 (0.9561)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [ 40/172]  eta: 0:03:32  lr: 0.000013  loss: 0.9595 (0.9581)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [ 50/172]  eta: 0:03:15  lr: 0.000013  loss: 0.9478 (0.9587)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [ 60/172]  eta: 0:02:59  lr: 0.000013  loss: 0.9569 (0.9645)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [ 70/172]  eta: 0:02:43  lr: 0.000013  loss: 0.9484 (0.9637)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [ 80/172]  eta: 0:02:26  lr: 0.000013  loss: 0.9621 (0.9699)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [ 90/172]  eta: 0:02:10  lr: 0.000013  loss: 0.9677 (0.9669)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [100/172]  eta: 0:01:54  lr: 0.000013  loss: 0.9401 (0.9647)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [110/172]  eta: 0:01:38  lr: 0.000013  loss: 0.9471 (0.9641)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [120/172]  eta: 0:01:22  lr: 0.000013  loss: 0.9802 (0.9673)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [130/172]  eta: 0:01:06  lr: 0.000013  loss: 0.9761 (0.9654)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [140/172]  eta: 0:00:50  lr: 0.000013  loss: 0.9433 (0.9645)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [150/172]  eta: 0:00:35  lr: 0.000013  loss: 0.9435 (0.9625)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [160/172]  eta: 0:00:19  lr: 0.000013  loss: 0.9466 (0.9624)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [170/172]  eta: 0:00:03  lr: 0.000013  loss: 0.9595 (0.9623)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886]  [171/172]  eta: 0:00:01  lr: 0.000013  loss: 0.9459 (0.9621)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:886] Total time: 0:04:33 (1.5913 s / it)\n",
      "Averaged stats: lr: 0.000013  loss: 0.9459 (0.9621)\n",
      "Valid: [epoch:886]  [ 0/14]  eta: 0:00:05  loss: 0.8896 (0.8896)  time: 0.3653  data: 0.3487  max mem: 20571\n",
      "Valid: [epoch:886]  [13/14]  eta: 0:00:00  loss: 0.9090 (0.9218)  time: 0.0416  data: 0.0266  max mem: 20571\n",
      "Valid: [epoch:886] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.9090 (0.9218)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_886_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.922%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:887]  [  0/172]  eta: 0:07:23  lr: 0.000013  loss: 1.0367 (1.0367)  time: 2.5789  data: 0.9981  max mem: 20571\n",
      "Train: [epoch:887]  [ 10/172]  eta: 0:04:30  lr: 0.000013  loss: 0.9631 (0.9639)  time: 1.6713  data: 0.0909  max mem: 20571\n",
      "Train: [epoch:887]  [ 20/172]  eta: 0:04:07  lr: 0.000013  loss: 0.9631 (0.9667)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [ 30/172]  eta: 0:03:49  lr: 0.000013  loss: 0.9459 (0.9624)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [ 40/172]  eta: 0:03:32  lr: 0.000013  loss: 0.9561 (0.9615)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [ 50/172]  eta: 0:03:15  lr: 0.000013  loss: 0.9561 (0.9588)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [ 60/172]  eta: 0:02:59  lr: 0.000013  loss: 0.9470 (0.9623)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [ 70/172]  eta: 0:02:42  lr: 0.000013  loss: 0.9442 (0.9578)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [ 80/172]  eta: 0:02:26  lr: 0.000013  loss: 0.9175 (0.9571)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [ 90/172]  eta: 0:02:10  lr: 0.000013  loss: 0.9603 (0.9603)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [100/172]  eta: 0:01:54  lr: 0.000013  loss: 0.9676 (0.9613)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [110/172]  eta: 0:01:38  lr: 0.000013  loss: 0.9520 (0.9628)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [120/172]  eta: 0:01:22  lr: 0.000013  loss: 0.9434 (0.9622)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [130/172]  eta: 0:01:06  lr: 0.000013  loss: 0.9405 (0.9622)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [140/172]  eta: 0:00:50  lr: 0.000013  loss: 0.9624 (0.9626)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [150/172]  eta: 0:00:34  lr: 0.000013  loss: 0.9572 (0.9614)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [160/172]  eta: 0:00:19  lr: 0.000013  loss: 0.9572 (0.9628)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [170/172]  eta: 0:00:03  lr: 0.000013  loss: 0.9839 (0.9633)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887]  [171/172]  eta: 0:00:01  lr: 0.000013  loss: 0.9780 (0.9634)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:887] Total time: 0:04:33 (1.5897 s / it)\n",
      "Averaged stats: lr: 0.000013  loss: 0.9780 (0.9634)\n",
      "Valid: [epoch:887]  [ 0/14]  eta: 0:00:04  loss: 0.8447 (0.8447)  time: 0.2891  data: 0.2745  max mem: 20571\n",
      "Valid: [epoch:887]  [13/14]  eta: 0:00:00  loss: 0.9093 (0.9222)  time: 0.0419  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:887] Total time: 0:00:00 (0.0463 s / it)\n",
      "Averaged stats: loss: 0.9093 (0.9222)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_887_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.922%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:888]  [  0/172]  eta: 0:07:44  lr: 0.000013  loss: 1.0206 (1.0206)  time: 2.6996  data: 1.1301  max mem: 20571\n",
      "Train: [epoch:888]  [ 10/172]  eta: 0:04:32  lr: 0.000013  loss: 0.9603 (0.9657)  time: 1.6825  data: 0.1028  max mem: 20571\n",
      "Train: [epoch:888]  [ 20/172]  eta: 0:04:08  lr: 0.000013  loss: 0.9535 (0.9614)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [ 30/172]  eta: 0:03:49  lr: 0.000013  loss: 0.9414 (0.9621)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [ 40/172]  eta: 0:03:32  lr: 0.000013  loss: 0.9347 (0.9572)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [ 50/172]  eta: 0:03:15  lr: 0.000013  loss: 0.9619 (0.9608)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [ 60/172]  eta: 0:02:59  lr: 0.000013  loss: 0.9676 (0.9620)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [ 70/172]  eta: 0:02:42  lr: 0.000013  loss: 0.9808 (0.9674)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [ 80/172]  eta: 0:02:26  lr: 0.000013  loss: 0.9808 (0.9706)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [ 90/172]  eta: 0:02:10  lr: 0.000013  loss: 0.9615 (0.9671)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [100/172]  eta: 0:01:54  lr: 0.000013  loss: 0.9264 (0.9664)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [110/172]  eta: 0:01:38  lr: 0.000013  loss: 0.9373 (0.9644)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [120/172]  eta: 0:01:22  lr: 0.000013  loss: 0.9514 (0.9654)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [130/172]  eta: 0:01:06  lr: 0.000013  loss: 0.9678 (0.9654)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [140/172]  eta: 0:00:50  lr: 0.000013  loss: 0.9678 (0.9658)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [150/172]  eta: 0:00:34  lr: 0.000013  loss: 0.9486 (0.9644)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [160/172]  eta: 0:00:19  lr: 0.000013  loss: 0.9442 (0.9639)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [170/172]  eta: 0:00:03  lr: 0.000013  loss: 0.9501 (0.9638)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888]  [171/172]  eta: 0:00:01  lr: 0.000013  loss: 0.9526 (0.9645)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:888] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000013  loss: 0.9526 (0.9645)\n",
      "Valid: [epoch:888]  [ 0/14]  eta: 0:00:04  loss: 0.8205 (0.8205)  time: 0.2860  data: 0.2689  max mem: 20571\n",
      "Valid: [epoch:888]  [13/14]  eta: 0:00:00  loss: 0.9102 (0.9230)  time: 0.0369  data: 0.0217  max mem: 20571\n",
      "Valid: [epoch:888] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.9102 (0.9230)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_888_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.923%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:889]  [  0/172]  eta: 0:07:37  lr: 0.000012  loss: 0.9490 (0.9490)  time: 2.6593  data: 1.0802  max mem: 20571\n",
      "Train: [epoch:889]  [ 10/172]  eta: 0:04:31  lr: 0.000012  loss: 0.9490 (0.9583)  time: 1.6761  data: 0.0983  max mem: 20571\n",
      "Train: [epoch:889]  [ 20/172]  eta: 0:04:07  lr: 0.000012  loss: 0.9482 (0.9615)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [ 30/172]  eta: 0:03:49  lr: 0.000012  loss: 0.9342 (0.9556)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [ 40/172]  eta: 0:03:32  lr: 0.000012  loss: 0.9483 (0.9546)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [ 50/172]  eta: 0:03:15  lr: 0.000012  loss: 0.9661 (0.9627)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [ 60/172]  eta: 0:02:59  lr: 0.000012  loss: 0.9869 (0.9646)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [ 70/172]  eta: 0:02:42  lr: 0.000012  loss: 0.9610 (0.9638)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [ 80/172]  eta: 0:02:26  lr: 0.000012  loss: 0.9737 (0.9650)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [ 90/172]  eta: 0:02:10  lr: 0.000012  loss: 0.9754 (0.9663)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [100/172]  eta: 0:01:54  lr: 0.000012  loss: 0.9569 (0.9635)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [110/172]  eta: 0:01:38  lr: 0.000012  loss: 0.9439 (0.9652)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [120/172]  eta: 0:01:22  lr: 0.000012  loss: 0.9607 (0.9660)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [130/172]  eta: 0:01:06  lr: 0.000012  loss: 0.9607 (0.9658)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [140/172]  eta: 0:00:50  lr: 0.000012  loss: 0.9557 (0.9657)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [150/172]  eta: 0:00:34  lr: 0.000012  loss: 0.9591 (0.9663)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [160/172]  eta: 0:00:19  lr: 0.000012  loss: 0.9487 (0.9651)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [170/172]  eta: 0:00:03  lr: 0.000012  loss: 0.9382 (0.9657)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889]  [171/172]  eta: 0:00:01  lr: 0.000012  loss: 0.9382 (0.9657)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:889] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000012  loss: 0.9382 (0.9657)\n",
      "Valid: [epoch:889]  [ 0/14]  eta: 0:00:04  loss: 0.9626 (0.9626)  time: 0.3400  data: 0.3232  max mem: 20571\n",
      "Valid: [epoch:889]  [13/14]  eta: 0:00:00  loss: 0.9108 (0.9242)  time: 0.0388  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:889] Total time: 0:00:00 (0.0464 s / it)\n",
      "Averaged stats: loss: 0.9108 (0.9242)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_889_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.924%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:890]  [  0/172]  eta: 0:07:35  lr: 0.000012  loss: 0.8866 (0.8866)  time: 2.6454  data: 1.0736  max mem: 20571\n",
      "Train: [epoch:890]  [ 10/172]  eta: 0:04:32  lr: 0.000012  loss: 0.9476 (0.9653)  time: 1.6797  data: 0.0977  max mem: 20571\n",
      "Train: [epoch:890]  [ 20/172]  eta: 0:04:08  lr: 0.000012  loss: 0.9798 (0.9740)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [ 30/172]  eta: 0:03:49  lr: 0.000012  loss: 0.9682 (0.9660)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [ 40/172]  eta: 0:03:32  lr: 0.000012  loss: 0.9572 (0.9656)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [ 50/172]  eta: 0:03:15  lr: 0.000012  loss: 0.9665 (0.9649)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [ 60/172]  eta: 0:02:59  lr: 0.000012  loss: 0.9575 (0.9663)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [ 70/172]  eta: 0:02:43  lr: 0.000012  loss: 0.9788 (0.9703)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [ 80/172]  eta: 0:02:26  lr: 0.000012  loss: 0.9482 (0.9697)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [ 90/172]  eta: 0:02:10  lr: 0.000012  loss: 0.9670 (0.9710)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [100/172]  eta: 0:01:54  lr: 0.000012  loss: 0.9802 (0.9707)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [110/172]  eta: 0:01:38  lr: 0.000012  loss: 0.9482 (0.9684)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [120/172]  eta: 0:01:22  lr: 0.000012  loss: 0.9396 (0.9684)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [130/172]  eta: 0:01:06  lr: 0.000012  loss: 0.9635 (0.9678)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [140/172]  eta: 0:00:50  lr: 0.000012  loss: 0.9643 (0.9676)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [150/172]  eta: 0:00:34  lr: 0.000012  loss: 0.9561 (0.9669)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [160/172]  eta: 0:00:19  lr: 0.000012  loss: 0.9606 (0.9670)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890]  [170/172]  eta: 0:00:03  lr: 0.000012  loss: 0.9680 (0.9671)  time: 1.5852  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:890]  [171/172]  eta: 0:00:01  lr: 0.000012  loss: 0.9680 (0.9673)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:890] Total time: 0:04:33 (1.5908 s / it)\n",
      "Averaged stats: lr: 0.000012  loss: 0.9680 (0.9673)\n",
      "Valid: [epoch:890]  [ 0/14]  eta: 0:00:05  loss: 0.9648 (0.9648)  time: 0.3996  data: 0.3789  max mem: 20571\n",
      "Valid: [epoch:890]  [13/14]  eta: 0:00:00  loss: 0.9128 (0.9255)  time: 0.0444  data: 0.0288  max mem: 20571\n",
      "Valid: [epoch:890] Total time: 0:00:00 (0.0498 s / it)\n",
      "Averaged stats: loss: 0.9128 (0.9255)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_890_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.925%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:891]  [  0/172]  eta: 0:08:07  lr: 0.000012  loss: 0.9858 (0.9858)  time: 2.8337  data: 1.2524  max mem: 20571\n",
      "Train: [epoch:891]  [ 10/172]  eta: 0:04:34  lr: 0.000012  loss: 0.9128 (0.9435)  time: 1.6951  data: 0.1140  max mem: 20571\n",
      "Train: [epoch:891]  [ 20/172]  eta: 0:04:09  lr: 0.000012  loss: 0.9290 (0.9464)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:891]  [ 30/172]  eta: 0:03:50  lr: 0.000012  loss: 0.9473 (0.9505)  time: 1.5806  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:891]  [ 40/172]  eta: 0:03:32  lr: 0.000012  loss: 0.9798 (0.9582)  time: 1.5821  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:891]  [ 50/172]  eta: 0:03:15  lr: 0.000012  loss: 0.9797 (0.9655)  time: 1.5823  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:891]  [ 60/172]  eta: 0:02:59  lr: 0.000012  loss: 0.9797 (0.9676)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [ 70/172]  eta: 0:02:43  lr: 0.000012  loss: 0.9557 (0.9660)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [ 80/172]  eta: 0:02:26  lr: 0.000012  loss: 0.9593 (0.9703)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [ 90/172]  eta: 0:02:10  lr: 0.000012  loss: 0.9732 (0.9699)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [100/172]  eta: 0:01:54  lr: 0.000012  loss: 0.9647 (0.9691)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [110/172]  eta: 0:01:38  lr: 0.000012  loss: 0.9522 (0.9677)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [120/172]  eta: 0:01:22  lr: 0.000012  loss: 0.9563 (0.9684)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [130/172]  eta: 0:01:06  lr: 0.000012  loss: 0.9622 (0.9690)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [140/172]  eta: 0:00:50  lr: 0.000012  loss: 0.9613 (0.9683)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [150/172]  eta: 0:00:34  lr: 0.000012  loss: 0.9602 (0.9678)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [160/172]  eta: 0:00:19  lr: 0.000012  loss: 0.9620 (0.9674)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [170/172]  eta: 0:00:03  lr: 0.000012  loss: 0.9491 (0.9676)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891]  [171/172]  eta: 0:00:01  lr: 0.000012  loss: 0.9491 (0.9676)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:891] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000012  loss: 0.9491 (0.9676)\n",
      "Valid: [epoch:891]  [ 0/14]  eta: 0:00:06  loss: 0.9607 (0.9607)  time: 0.4513  data: 0.4348  max mem: 20571\n",
      "Valid: [epoch:891]  [13/14]  eta: 0:00:00  loss: 0.9136 (0.9263)  time: 0.0466  data: 0.0312  max mem: 20571\n",
      "Valid: [epoch:891] Total time: 0:00:00 (0.0520 s / it)\n",
      "Averaged stats: loss: 0.9136 (0.9263)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_891_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.926%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:892]  [  0/172]  eta: 0:07:39  lr: 0.000012  loss: 0.9523 (0.9523)  time: 2.6732  data: 1.0881  max mem: 20571\n",
      "Train: [epoch:892]  [ 10/172]  eta: 0:04:32  lr: 0.000012  loss: 1.0024 (1.0068)  time: 1.6794  data: 0.0990  max mem: 20571\n",
      "Train: [epoch:892]  [ 20/172]  eta: 0:04:08  lr: 0.000012  loss: 1.0047 (1.0022)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [ 30/172]  eta: 0:03:49  lr: 0.000012  loss: 0.9778 (0.9876)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [ 40/172]  eta: 0:03:32  lr: 0.000012  loss: 0.9444 (0.9791)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [ 50/172]  eta: 0:03:15  lr: 0.000012  loss: 0.9589 (0.9741)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [ 60/172]  eta: 0:02:59  lr: 0.000012  loss: 0.9446 (0.9695)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [ 70/172]  eta: 0:02:42  lr: 0.000012  loss: 0.9359 (0.9660)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [ 80/172]  eta: 0:02:26  lr: 0.000012  loss: 0.9470 (0.9652)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [ 90/172]  eta: 0:02:10  lr: 0.000012  loss: 0.9632 (0.9666)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [100/172]  eta: 0:01:54  lr: 0.000012  loss: 0.9656 (0.9683)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [110/172]  eta: 0:01:38  lr: 0.000012  loss: 0.9758 (0.9683)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [120/172]  eta: 0:01:22  lr: 0.000012  loss: 0.9758 (0.9685)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [130/172]  eta: 0:01:06  lr: 0.000012  loss: 0.9617 (0.9675)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [140/172]  eta: 0:00:50  lr: 0.000012  loss: 0.9565 (0.9676)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [150/172]  eta: 0:00:34  lr: 0.000012  loss: 0.9565 (0.9685)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [160/172]  eta: 0:00:19  lr: 0.000012  loss: 0.9729 (0.9695)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [170/172]  eta: 0:00:03  lr: 0.000012  loss: 0.9562 (0.9691)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892]  [171/172]  eta: 0:00:01  lr: 0.000012  loss: 0.9562 (0.9693)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:892] Total time: 0:04:33 (1.5896 s / it)\n",
      "Averaged stats: lr: 0.000012  loss: 0.9562 (0.9693)\n",
      "Valid: [epoch:892]  [ 0/14]  eta: 0:00:06  loss: 0.9685 (0.9685)  time: 0.4749  data: 0.4603  max mem: 20571\n",
      "Valid: [epoch:892]  [13/14]  eta: 0:00:00  loss: 0.9172 (0.9296)  time: 0.0484  data: 0.0333  max mem: 20571\n",
      "Valid: [epoch:892] Total time: 0:00:00 (0.0534 s / it)\n",
      "Averaged stats: loss: 0.9172 (0.9296)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_892_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.930%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:893]  [  0/172]  eta: 0:08:16  lr: 0.000012  loss: 0.8825 (0.8825)  time: 2.8844  data: 1.3037  max mem: 20571\n",
      "Train: [epoch:893]  [ 10/172]  eta: 0:04:35  lr: 0.000012  loss: 0.9341 (0.9563)  time: 1.6978  data: 0.1186  max mem: 20571\n",
      "Train: [epoch:893]  [ 20/172]  eta: 0:04:09  lr: 0.000012  loss: 0.9346 (0.9637)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [ 30/172]  eta: 0:03:50  lr: 0.000012  loss: 0.9695 (0.9674)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [ 40/172]  eta: 0:03:33  lr: 0.000012  loss: 0.9567 (0.9637)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [ 50/172]  eta: 0:03:16  lr: 0.000012  loss: 0.9324 (0.9582)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [ 60/172]  eta: 0:02:59  lr: 0.000012  loss: 0.9431 (0.9607)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [ 70/172]  eta: 0:02:43  lr: 0.000012  loss: 0.9431 (0.9617)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [ 80/172]  eta: 0:02:27  lr: 0.000012  loss: 0.9472 (0.9610)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [ 90/172]  eta: 0:02:10  lr: 0.000012  loss: 0.9472 (0.9610)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [100/172]  eta: 0:01:54  lr: 0.000012  loss: 0.9534 (0.9620)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [110/172]  eta: 0:01:38  lr: 0.000012  loss: 0.9801 (0.9634)  time: 1.5849  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:893]  [120/172]  eta: 0:01:22  lr: 0.000012  loss: 0.9801 (0.9649)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [130/172]  eta: 0:01:06  lr: 0.000012  loss: 0.9631 (0.9658)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [140/172]  eta: 0:00:50  lr: 0.000012  loss: 0.9688 (0.9660)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [150/172]  eta: 0:00:35  lr: 0.000012  loss: 0.9678 (0.9655)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [160/172]  eta: 0:00:19  lr: 0.000012  loss: 0.9516 (0.9665)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [170/172]  eta: 0:00:03  lr: 0.000012  loss: 0.9821 (0.9687)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893]  [171/172]  eta: 0:00:01  lr: 0.000012  loss: 0.9837 (0.9692)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:893] Total time: 0:04:33 (1.5919 s / it)\n",
      "Averaged stats: lr: 0.000012  loss: 0.9837 (0.9692)\n",
      "Valid: [epoch:893]  [ 0/14]  eta: 0:00:05  loss: 0.8704 (0.8704)  time: 0.3960  data: 0.3793  max mem: 20571\n",
      "Valid: [epoch:893]  [13/14]  eta: 0:00:00  loss: 0.9168 (0.9288)  time: 0.0426  data: 0.0274  max mem: 20571\n",
      "Valid: [epoch:893] Total time: 0:00:00 (0.0493 s / it)\n",
      "Averaged stats: loss: 0.9168 (0.9288)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_893_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.929%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:894]  [  0/172]  eta: 0:07:55  lr: 0.000012  loss: 0.9225 (0.9225)  time: 2.7653  data: 1.1850  max mem: 20571\n",
      "Train: [epoch:894]  [ 10/172]  eta: 0:04:33  lr: 0.000012  loss: 0.9604 (0.9687)  time: 1.6887  data: 0.1078  max mem: 20571\n",
      "Train: [epoch:894]  [ 20/172]  eta: 0:04:09  lr: 0.000012  loss: 0.9821 (0.9824)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [ 30/172]  eta: 0:03:50  lr: 0.000012  loss: 0.9821 (0.9833)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [ 40/172]  eta: 0:03:32  lr: 0.000012  loss: 0.9652 (0.9811)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [ 50/172]  eta: 0:03:16  lr: 0.000012  loss: 0.9929 (0.9869)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [ 60/172]  eta: 0:02:59  lr: 0.000012  loss: 0.9900 (0.9844)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [ 70/172]  eta: 0:02:43  lr: 0.000012  loss: 0.9578 (0.9839)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [ 80/172]  eta: 0:02:27  lr: 0.000012  loss: 0.9449 (0.9789)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [ 90/172]  eta: 0:02:10  lr: 0.000012  loss: 0.9339 (0.9760)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [100/172]  eta: 0:01:54  lr: 0.000012  loss: 0.9522 (0.9754)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [110/172]  eta: 0:01:38  lr: 0.000012  loss: 0.9497 (0.9747)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [120/172]  eta: 0:01:22  lr: 0.000012  loss: 0.9441 (0.9731)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [130/172]  eta: 0:01:06  lr: 0.000012  loss: 0.9542 (0.9726)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [140/172]  eta: 0:00:50  lr: 0.000012  loss: 0.9378 (0.9712)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [150/172]  eta: 0:00:35  lr: 0.000012  loss: 0.9278 (0.9707)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [160/172]  eta: 0:00:19  lr: 0.000012  loss: 0.9569 (0.9697)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [170/172]  eta: 0:00:03  lr: 0.000012  loss: 0.9593 (0.9703)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894]  [171/172]  eta: 0:00:01  lr: 0.000012  loss: 0.9593 (0.9710)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:894] Total time: 0:04:33 (1.5924 s / it)\n",
      "Averaged stats: lr: 0.000012  loss: 0.9593 (0.9710)\n",
      "Valid: [epoch:894]  [ 0/14]  eta: 0:00:04  loss: 0.8985 (0.8985)  time: 0.3131  data: 0.2981  max mem: 20571\n",
      "Valid: [epoch:894]  [13/14]  eta: 0:00:00  loss: 0.9160 (0.9296)  time: 0.0381  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:894] Total time: 0:00:00 (0.0468 s / it)\n",
      "Averaged stats: loss: 0.9160 (0.9296)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_894_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.930%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:895]  [  0/172]  eta: 0:07:32  lr: 0.000012  loss: 1.0434 (1.0434)  time: 2.6314  data: 1.0507  max mem: 20571\n",
      "Train: [epoch:895]  [ 10/172]  eta: 0:04:31  lr: 0.000012  loss: 0.9562 (0.9755)  time: 1.6747  data: 0.0956  max mem: 20571\n",
      "Train: [epoch:895]  [ 20/172]  eta: 0:04:07  lr: 0.000012  loss: 0.9789 (0.9902)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [ 30/172]  eta: 0:03:49  lr: 0.000012  loss: 0.9955 (0.9904)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [ 40/172]  eta: 0:03:32  lr: 0.000012  loss: 0.9528 (0.9790)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [ 50/172]  eta: 0:03:15  lr: 0.000012  loss: 0.9528 (0.9783)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [ 60/172]  eta: 0:02:59  lr: 0.000012  loss: 0.9805 (0.9782)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [ 70/172]  eta: 0:02:42  lr: 0.000012  loss: 0.9682 (0.9755)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [ 80/172]  eta: 0:02:26  lr: 0.000012  loss: 0.9480 (0.9715)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [ 90/172]  eta: 0:02:10  lr: 0.000012  loss: 0.9459 (0.9689)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [100/172]  eta: 0:01:54  lr: 0.000012  loss: 0.9468 (0.9672)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [110/172]  eta: 0:01:38  lr: 0.000012  loss: 0.9522 (0.9677)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [120/172]  eta: 0:01:22  lr: 0.000012  loss: 0.9800 (0.9701)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [130/172]  eta: 0:01:06  lr: 0.000012  loss: 0.9953 (0.9716)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [140/172]  eta: 0:00:50  lr: 0.000012  loss: 0.9906 (0.9710)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [150/172]  eta: 0:00:34  lr: 0.000012  loss: 0.9349 (0.9688)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [160/172]  eta: 0:00:19  lr: 0.000012  loss: 0.9833 (0.9724)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [170/172]  eta: 0:00:03  lr: 0.000012  loss: 0.9833 (0.9711)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895]  [171/172]  eta: 0:00:01  lr: 0.000012  loss: 0.9833 (0.9713)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:895] Total time: 0:04:33 (1.5899 s / it)\n",
      "Averaged stats: lr: 0.000012  loss: 0.9833 (0.9713)\n",
      "Valid: [epoch:895]  [ 0/14]  eta: 0:00:05  loss: 0.8728 (0.8728)  time: 0.3815  data: 0.3652  max mem: 20571\n",
      "Valid: [epoch:895]  [13/14]  eta: 0:00:00  loss: 0.9176 (0.9308)  time: 0.0417  data: 0.0267  max mem: 20571\n",
      "Valid: [epoch:895] Total time: 0:00:00 (0.0469 s / it)\n",
      "Averaged stats: loss: 0.9176 (0.9308)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_895_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.931%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:896]  [  0/172]  eta: 0:07:54  lr: 0.000012  loss: 0.9015 (0.9015)  time: 2.7613  data: 1.1929  max mem: 20571\n",
      "Train: [epoch:896]  [ 10/172]  eta: 0:04:33  lr: 0.000012  loss: 0.9518 (0.9495)  time: 1.6877  data: 0.1085  max mem: 20571\n",
      "Train: [epoch:896]  [ 20/172]  eta: 0:04:08  lr: 0.000012  loss: 0.9451 (0.9513)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [ 30/172]  eta: 0:03:49  lr: 0.000012  loss: 0.9640 (0.9614)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [ 40/172]  eta: 0:03:32  lr: 0.000012  loss: 0.9624 (0.9606)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [ 50/172]  eta: 0:03:15  lr: 0.000012  loss: 0.9624 (0.9665)  time: 1.5829  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:896]  [ 60/172]  eta: 0:02:59  lr: 0.000012  loss: 0.9670 (0.9662)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [ 70/172]  eta: 0:02:43  lr: 0.000012  loss: 0.9578 (0.9709)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [ 80/172]  eta: 0:02:26  lr: 0.000012  loss: 0.9532 (0.9673)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [ 90/172]  eta: 0:02:10  lr: 0.000012  loss: 0.9316 (0.9662)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [100/172]  eta: 0:01:54  lr: 0.000012  loss: 0.9461 (0.9657)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [110/172]  eta: 0:01:38  lr: 0.000012  loss: 0.9579 (0.9656)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [120/172]  eta: 0:01:22  lr: 0.000012  loss: 0.9725 (0.9701)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [130/172]  eta: 0:01:06  lr: 0.000012  loss: 1.0042 (0.9709)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [140/172]  eta: 0:00:50  lr: 0.000012  loss: 0.9939 (0.9714)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [150/172]  eta: 0:00:34  lr: 0.000012  loss: 0.9644 (0.9695)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [160/172]  eta: 0:00:19  lr: 0.000012  loss: 0.9556 (0.9707)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [170/172]  eta: 0:00:03  lr: 0.000012  loss: 0.9823 (0.9723)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896]  [171/172]  eta: 0:00:01  lr: 0.000012  loss: 0.9922 (0.9726)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:896] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000012  loss: 0.9922 (0.9726)\n",
      "Valid: [epoch:896]  [ 0/14]  eta: 0:00:04  loss: 0.9777 (0.9777)  time: 0.2861  data: 0.2714  max mem: 20571\n",
      "Valid: [epoch:896]  [13/14]  eta: 0:00:00  loss: 0.9181 (0.9315)  time: 0.0371  data: 0.0222  max mem: 20571\n",
      "Valid: [epoch:896] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.9181 (0.9315)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_896_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.931%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:897]  [  0/172]  eta: 0:07:37  lr: 0.000012  loss: 0.9245 (0.9245)  time: 2.6596  data: 1.0852  max mem: 20571\n",
      "Train: [epoch:897]  [ 10/172]  eta: 0:04:31  lr: 0.000012  loss: 0.9565 (0.9644)  time: 1.6780  data: 0.0987  max mem: 20571\n",
      "Train: [epoch:897]  [ 20/172]  eta: 0:04:08  lr: 0.000012  loss: 0.9716 (0.9720)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [ 30/172]  eta: 0:03:49  lr: 0.000012  loss: 0.9798 (0.9786)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [ 40/172]  eta: 0:03:32  lr: 0.000012  loss: 0.9583 (0.9732)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [ 50/172]  eta: 0:03:15  lr: 0.000012  loss: 0.9602 (0.9725)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [ 60/172]  eta: 0:02:59  lr: 0.000012  loss: 0.9667 (0.9750)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [ 70/172]  eta: 0:02:43  lr: 0.000012  loss: 0.9671 (0.9741)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [ 80/172]  eta: 0:02:26  lr: 0.000012  loss: 0.9606 (0.9732)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [ 90/172]  eta: 0:02:10  lr: 0.000012  loss: 0.9556 (0.9730)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [100/172]  eta: 0:01:54  lr: 0.000012  loss: 0.9736 (0.9730)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [110/172]  eta: 0:01:38  lr: 0.000012  loss: 0.9736 (0.9719)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [120/172]  eta: 0:01:22  lr: 0.000012  loss: 0.9749 (0.9730)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [130/172]  eta: 0:01:06  lr: 0.000012  loss: 0.9749 (0.9724)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [140/172]  eta: 0:00:50  lr: 0.000012  loss: 0.9810 (0.9736)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [150/172]  eta: 0:00:34  lr: 0.000012  loss: 0.9832 (0.9732)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [160/172]  eta: 0:00:19  lr: 0.000012  loss: 0.9811 (0.9737)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [170/172]  eta: 0:00:03  lr: 0.000012  loss: 0.9687 (0.9731)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897]  [171/172]  eta: 0:00:01  lr: 0.000012  loss: 0.9687 (0.9732)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:897] Total time: 0:04:33 (1.5904 s / it)\n",
      "Averaged stats: lr: 0.000012  loss: 0.9687 (0.9732)\n",
      "Valid: [epoch:897]  [ 0/14]  eta: 0:00:04  loss: 0.9705 (0.9705)  time: 0.2937  data: 0.2782  max mem: 20571\n",
      "Valid: [epoch:897]  [13/14]  eta: 0:00:00  loss: 0.9187 (0.9322)  time: 0.0377  data: 0.0227  max mem: 20571\n",
      "Valid: [epoch:897] Total time: 0:00:00 (0.0428 s / it)\n",
      "Averaged stats: loss: 0.9187 (0.9322)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_897_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.932%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:898]  [  0/172]  eta: 0:07:31  lr: 0.000011  loss: 0.8790 (0.8790)  time: 2.6222  data: 1.0474  max mem: 20571\n",
      "Train: [epoch:898]  [ 10/172]  eta: 0:04:31  lr: 0.000011  loss: 0.9715 (0.9880)  time: 1.6774  data: 0.0953  max mem: 20571\n",
      "Train: [epoch:898]  [ 20/172]  eta: 0:04:08  lr: 0.000011  loss: 0.9766 (0.9835)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [ 30/172]  eta: 0:03:49  lr: 0.000011  loss: 0.9805 (0.9895)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [ 40/172]  eta: 0:03:32  lr: 0.000011  loss: 0.9595 (0.9799)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [ 50/172]  eta: 0:03:15  lr: 0.000011  loss: 0.9494 (0.9797)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [ 60/172]  eta: 0:02:59  lr: 0.000011  loss: 0.9614 (0.9762)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [ 70/172]  eta: 0:02:43  lr: 0.000011  loss: 0.9545 (0.9739)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [ 80/172]  eta: 0:02:26  lr: 0.000011  loss: 0.9733 (0.9794)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [ 90/172]  eta: 0:02:10  lr: 0.000011  loss: 0.9866 (0.9743)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [100/172]  eta: 0:01:54  lr: 0.000011  loss: 0.9528 (0.9747)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [110/172]  eta: 0:01:38  lr: 0.000011  loss: 0.9707 (0.9744)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [120/172]  eta: 0:01:22  lr: 0.000011  loss: 0.9711 (0.9756)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [130/172]  eta: 0:01:06  lr: 0.000011  loss: 0.9754 (0.9754)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [140/172]  eta: 0:00:50  lr: 0.000011  loss: 0.9482 (0.9742)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [150/172]  eta: 0:00:34  lr: 0.000011  loss: 0.9542 (0.9730)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [160/172]  eta: 0:00:19  lr: 0.000011  loss: 0.9684 (0.9751)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [170/172]  eta: 0:00:03  lr: 0.000011  loss: 0.9713 (0.9746)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898]  [171/172]  eta: 0:00:01  lr: 0.000011  loss: 0.9861 (0.9748)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:898] Total time: 0:04:33 (1.5902 s / it)\n",
      "Averaged stats: lr: 0.000011  loss: 0.9861 (0.9748)\n",
      "Valid: [epoch:898]  [ 0/14]  eta: 0:00:05  loss: 0.9863 (0.9863)  time: 0.3818  data: 0.3664  max mem: 20571\n",
      "Valid: [epoch:898]  [13/14]  eta: 0:00:00  loss: 0.9275 (0.9403)  time: 0.0420  data: 0.0270  max mem: 20571\n",
      "Valid: [epoch:898] Total time: 0:00:00 (0.0506 s / it)\n",
      "Averaged stats: loss: 0.9275 (0.9403)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_898_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.940%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:899]  [  0/172]  eta: 0:07:47  lr: 0.000011  loss: 0.9676 (0.9676)  time: 2.7159  data: 1.1387  max mem: 20571\n",
      "Train: [epoch:899]  [ 10/172]  eta: 0:04:32  lr: 0.000011  loss: 1.0017 (0.9821)  time: 1.6804  data: 0.1036  max mem: 20571\n",
      "Train: [epoch:899]  [ 20/172]  eta: 0:04:08  lr: 0.000011  loss: 0.9949 (0.9859)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [ 30/172]  eta: 0:03:49  lr: 0.000011  loss: 0.9666 (0.9784)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [ 40/172]  eta: 0:03:32  lr: 0.000011  loss: 0.9700 (0.9771)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [ 50/172]  eta: 0:03:15  lr: 0.000011  loss: 0.9643 (0.9730)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [ 60/172]  eta: 0:02:59  lr: 0.000011  loss: 0.9409 (0.9722)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [ 70/172]  eta: 0:02:42  lr: 0.000011  loss: 0.9747 (0.9741)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [ 80/172]  eta: 0:02:26  lr: 0.000011  loss: 0.9473 (0.9699)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [ 90/172]  eta: 0:02:10  lr: 0.000011  loss: 0.9642 (0.9720)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [100/172]  eta: 0:01:54  lr: 0.000011  loss: 0.9794 (0.9713)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [110/172]  eta: 0:01:38  lr: 0.000011  loss: 0.9794 (0.9719)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [120/172]  eta: 0:01:22  lr: 0.000011  loss: 0.9946 (0.9743)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [130/172]  eta: 0:01:06  lr: 0.000011  loss: 0.9693 (0.9748)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [140/172]  eta: 0:00:50  lr: 0.000011  loss: 0.9613 (0.9734)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [150/172]  eta: 0:00:34  lr: 0.000011  loss: 0.9608 (0.9727)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [160/172]  eta: 0:00:19  lr: 0.000011  loss: 0.9675 (0.9739)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [170/172]  eta: 0:00:03  lr: 0.000011  loss: 0.9812 (0.9748)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899]  [171/172]  eta: 0:00:01  lr: 0.000011  loss: 0.9865 (0.9749)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:899] Total time: 0:04:33 (1.5892 s / it)\n",
      "Averaged stats: lr: 0.000011  loss: 0.9865 (0.9749)\n",
      "Valid: [epoch:899]  [ 0/14]  eta: 0:00:04  loss: 0.9036 (0.9036)  time: 0.3172  data: 0.3024  max mem: 20571\n",
      "Valid: [epoch:899]  [13/14]  eta: 0:00:00  loss: 0.9209 (0.9344)  time: 0.0383  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:899] Total time: 0:00:00 (0.0430 s / it)\n",
      "Averaged stats: loss: 0.9209 (0.9344)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_899_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.934%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:900]  [  0/172]  eta: 0:07:22  lr: 0.000011  loss: 1.0091 (1.0091)  time: 2.5703  data: 1.0018  max mem: 20571\n",
      "Train: [epoch:900]  [ 10/172]  eta: 0:04:30  lr: 0.000011  loss: 1.0033 (0.9746)  time: 1.6701  data: 0.0912  max mem: 20571\n",
      "Train: [epoch:900]  [ 20/172]  eta: 0:04:07  lr: 0.000011  loss: 0.9735 (0.9857)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [ 30/172]  eta: 0:03:49  lr: 0.000011  loss: 0.9729 (0.9878)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [ 40/172]  eta: 0:03:32  lr: 0.000011  loss: 0.9959 (0.9861)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [ 50/172]  eta: 0:03:15  lr: 0.000011  loss: 0.9959 (0.9860)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [ 60/172]  eta: 0:02:59  lr: 0.000011  loss: 0.9430 (0.9826)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [ 70/172]  eta: 0:02:42  lr: 0.000011  loss: 0.9705 (0.9817)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [ 80/172]  eta: 0:02:26  lr: 0.000011  loss: 0.9583 (0.9777)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [ 90/172]  eta: 0:02:10  lr: 0.000011  loss: 0.9416 (0.9743)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [100/172]  eta: 0:01:54  lr: 0.000011  loss: 0.9473 (0.9730)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [110/172]  eta: 0:01:38  lr: 0.000011  loss: 0.9743 (0.9740)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [120/172]  eta: 0:01:22  lr: 0.000011  loss: 0.9878 (0.9746)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [130/172]  eta: 0:01:06  lr: 0.000011  loss: 0.9713 (0.9744)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [140/172]  eta: 0:00:50  lr: 0.000011  loss: 0.9541 (0.9734)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [150/172]  eta: 0:00:34  lr: 0.000011  loss: 0.9862 (0.9751)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [160/172]  eta: 0:00:19  lr: 0.000011  loss: 0.9838 (0.9762)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [170/172]  eta: 0:00:03  lr: 0.000011  loss: 0.9805 (0.9759)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900]  [171/172]  eta: 0:00:01  lr: 0.000011  loss: 0.9805 (0.9763)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:900] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000011  loss: 0.9805 (0.9763)\n",
      "Valid: [epoch:900]  [ 0/14]  eta: 0:00:03  loss: 0.9702 (0.9702)  time: 0.2799  data: 0.2637  max mem: 20571\n",
      "Valid: [epoch:900]  [13/14]  eta: 0:00:00  loss: 0.9219 (0.9351)  time: 0.0438  data: 0.0288  max mem: 20571\n",
      "Valid: [epoch:900] Total time: 0:00:00 (0.0485 s / it)\n",
      "Averaged stats: loss: 0.9219 (0.9351)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_900_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.935%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:901]  [  0/172]  eta: 0:07:22  lr: 0.000011  loss: 1.0357 (1.0357)  time: 2.5723  data: 0.9960  max mem: 20571\n",
      "Train: [epoch:901]  [ 10/172]  eta: 0:04:30  lr: 0.000011  loss: 0.9664 (0.9763)  time: 1.6683  data: 0.0906  max mem: 20571\n",
      "Train: [epoch:901]  [ 20/172]  eta: 0:04:07  lr: 0.000011  loss: 0.9576 (0.9742)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [ 30/172]  eta: 0:03:48  lr: 0.000011  loss: 0.9659 (0.9757)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [ 40/172]  eta: 0:03:31  lr: 0.000011  loss: 0.9754 (0.9768)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [ 50/172]  eta: 0:03:15  lr: 0.000011  loss: 0.9865 (0.9797)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [ 60/172]  eta: 0:02:58  lr: 0.000011  loss: 0.9426 (0.9733)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [ 70/172]  eta: 0:02:42  lr: 0.000011  loss: 0.9518 (0.9741)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [ 80/172]  eta: 0:02:26  lr: 0.000011  loss: 0.9608 (0.9726)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [ 90/172]  eta: 0:02:10  lr: 0.000011  loss: 0.9771 (0.9746)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [100/172]  eta: 0:01:54  lr: 0.000011  loss: 0.9896 (0.9786)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [110/172]  eta: 0:01:38  lr: 0.000011  loss: 0.9765 (0.9781)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [120/172]  eta: 0:01:22  lr: 0.000011  loss: 0.9791 (0.9807)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [130/172]  eta: 0:01:06  lr: 0.000011  loss: 0.9791 (0.9797)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [140/172]  eta: 0:00:50  lr: 0.000011  loss: 0.9651 (0.9784)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [150/172]  eta: 0:00:34  lr: 0.000011  loss: 0.9573 (0.9777)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [160/172]  eta: 0:00:19  lr: 0.000011  loss: 0.9690 (0.9765)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901]  [170/172]  eta: 0:00:03  lr: 0.000011  loss: 0.9819 (0.9784)  time: 1.5817  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:901]  [171/172]  eta: 0:00:01  lr: 0.000011  loss: 0.9816 (0.9781)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:901] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000011  loss: 0.9816 (0.9781)\n",
      "Valid: [epoch:901]  [ 0/14]  eta: 0:00:05  loss: 0.9041 (0.9041)  time: 0.3807  data: 0.3642  max mem: 20571\n",
      "Valid: [epoch:901]  [13/14]  eta: 0:00:00  loss: 0.9225 (0.9363)  time: 0.0429  data: 0.0278  max mem: 20571\n",
      "Valid: [epoch:901] Total time: 0:00:00 (0.0479 s / it)\n",
      "Averaged stats: loss: 0.9225 (0.9363)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_901_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.936%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:902]  [  0/172]  eta: 0:07:52  lr: 0.000011  loss: 0.9745 (0.9745)  time: 2.7466  data: 1.1795  max mem: 20571\n",
      "Train: [epoch:902]  [ 10/172]  eta: 0:04:33  lr: 0.000011  loss: 0.9723 (0.9719)  time: 1.6862  data: 0.1073  max mem: 20571\n",
      "Train: [epoch:902]  [ 20/172]  eta: 0:04:08  lr: 0.000011  loss: 0.9723 (0.9925)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [ 30/172]  eta: 0:03:49  lr: 0.000011  loss: 0.9757 (0.9911)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [ 40/172]  eta: 0:03:32  lr: 0.000011  loss: 0.9454 (0.9794)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [ 50/172]  eta: 0:03:15  lr: 0.000011  loss: 0.9595 (0.9853)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [ 60/172]  eta: 0:02:59  lr: 0.000011  loss: 0.9857 (0.9865)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [ 70/172]  eta: 0:02:42  lr: 0.000011  loss: 0.9746 (0.9839)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [ 80/172]  eta: 0:02:26  lr: 0.000011  loss: 0.9632 (0.9876)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [ 90/172]  eta: 0:02:10  lr: 0.000011  loss: 1.0024 (0.9869)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [100/172]  eta: 0:01:54  lr: 0.000011  loss: 0.9737 (0.9857)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [110/172]  eta: 0:01:38  lr: 0.000011  loss: 0.9682 (0.9828)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [120/172]  eta: 0:01:22  lr: 0.000011  loss: 0.9466 (0.9810)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [130/172]  eta: 0:01:06  lr: 0.000011  loss: 0.9636 (0.9802)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [140/172]  eta: 0:00:50  lr: 0.000011  loss: 0.9691 (0.9798)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [150/172]  eta: 0:00:34  lr: 0.000011  loss: 0.9691 (0.9782)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [160/172]  eta: 0:00:19  lr: 0.000011  loss: 0.9564 (0.9787)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [170/172]  eta: 0:00:03  lr: 0.000011  loss: 0.9564 (0.9781)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902]  [171/172]  eta: 0:00:01  lr: 0.000011  loss: 0.9701 (0.9786)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:902] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000011  loss: 0.9701 (0.9786)\n",
      "Valid: [epoch:902]  [ 0/14]  eta: 0:00:04  loss: 0.8788 (0.8788)  time: 0.3372  data: 0.3175  max mem: 20571\n",
      "Valid: [epoch:902]  [13/14]  eta: 0:00:00  loss: 0.9240 (0.9375)  time: 0.0396  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:902] Total time: 0:00:00 (0.0478 s / it)\n",
      "Averaged stats: loss: 0.9240 (0.9375)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_902_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.938%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:903]  [  0/172]  eta: 0:08:13  lr: 0.000011  loss: 0.9163 (0.9163)  time: 2.8713  data: 1.2931  max mem: 20571\n",
      "Train: [epoch:903]  [ 10/172]  eta: 0:04:34  lr: 0.000011  loss: 0.9912 (0.9901)  time: 1.6940  data: 0.1177  max mem: 20571\n",
      "Train: [epoch:903]  [ 20/172]  eta: 0:04:09  lr: 0.000011  loss: 0.9829 (0.9843)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [ 30/172]  eta: 0:03:49  lr: 0.000011  loss: 0.9762 (0.9829)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [ 40/172]  eta: 0:03:32  lr: 0.000011  loss: 0.9727 (0.9818)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [ 50/172]  eta: 0:03:15  lr: 0.000011  loss: 0.9741 (0.9855)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [ 60/172]  eta: 0:02:59  lr: 0.000011  loss: 0.9706 (0.9812)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [ 70/172]  eta: 0:02:42  lr: 0.000011  loss: 0.9546 (0.9809)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [ 80/172]  eta: 0:02:26  lr: 0.000011  loss: 0.9825 (0.9838)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [ 90/172]  eta: 0:02:10  lr: 0.000011  loss: 0.9742 (0.9829)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [100/172]  eta: 0:01:54  lr: 0.000011  loss: 0.9750 (0.9820)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [110/172]  eta: 0:01:38  lr: 0.000011  loss: 0.9647 (0.9802)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [120/172]  eta: 0:01:22  lr: 0.000011  loss: 0.9742 (0.9809)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [130/172]  eta: 0:01:06  lr: 0.000011  loss: 0.9778 (0.9806)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [140/172]  eta: 0:00:50  lr: 0.000011  loss: 0.9648 (0.9806)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [150/172]  eta: 0:00:34  lr: 0.000011  loss: 0.9648 (0.9789)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [160/172]  eta: 0:00:19  lr: 0.000011  loss: 0.9736 (0.9792)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [170/172]  eta: 0:00:03  lr: 0.000011  loss: 0.9790 (0.9791)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903]  [171/172]  eta: 0:00:01  lr: 0.000011  loss: 0.9790 (0.9792)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:903] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000011  loss: 0.9790 (0.9792)\n",
      "Valid: [epoch:903]  [ 0/14]  eta: 0:00:04  loss: 0.9780 (0.9780)  time: 0.3492  data: 0.3336  max mem: 20571\n",
      "Valid: [epoch:903]  [13/14]  eta: 0:00:00  loss: 0.9257 (0.9391)  time: 0.0408  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:903] Total time: 0:00:00 (0.0489 s / it)\n",
      "Averaged stats: loss: 0.9257 (0.9391)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_903_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.939%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:904]  [  0/172]  eta: 0:07:21  lr: 0.000011  loss: 0.9723 (0.9723)  time: 2.5667  data: 0.9987  max mem: 20571\n",
      "Train: [epoch:904]  [ 10/172]  eta: 0:04:30  lr: 0.000011  loss: 0.9705 (0.9608)  time: 1.6727  data: 0.0909  max mem: 20571\n",
      "Train: [epoch:904]  [ 20/172]  eta: 0:04:07  lr: 0.000011  loss: 0.9731 (0.9728)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [ 30/172]  eta: 0:03:49  lr: 0.000011  loss: 0.9915 (0.9800)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [ 40/172]  eta: 0:03:32  lr: 0.000011  loss: 0.9815 (0.9789)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [ 50/172]  eta: 0:03:15  lr: 0.000011  loss: 0.9815 (0.9822)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [ 60/172]  eta: 0:02:59  lr: 0.000011  loss: 0.9738 (0.9778)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [ 70/172]  eta: 0:02:42  lr: 0.000011  loss: 0.9511 (0.9727)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [ 80/172]  eta: 0:02:26  lr: 0.000011  loss: 0.9511 (0.9731)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [ 90/172]  eta: 0:02:10  lr: 0.000011  loss: 0.9777 (0.9765)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [100/172]  eta: 0:01:54  lr: 0.000011  loss: 0.9912 (0.9798)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [110/172]  eta: 0:01:38  lr: 0.000011  loss: 0.9940 (0.9799)  time: 1.5824  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:904]  [120/172]  eta: 0:01:22  lr: 0.000011  loss: 1.0060 (0.9839)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [130/172]  eta: 0:01:06  lr: 0.000011  loss: 0.9786 (0.9837)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [140/172]  eta: 0:00:50  lr: 0.000011  loss: 0.9594 (0.9811)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [150/172]  eta: 0:00:34  lr: 0.000011  loss: 0.9390 (0.9811)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [160/172]  eta: 0:00:19  lr: 0.000011  loss: 0.9842 (0.9819)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [170/172]  eta: 0:00:03  lr: 0.000011  loss: 0.9898 (0.9817)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904]  [171/172]  eta: 0:00:01  lr: 0.000011  loss: 0.9898 (0.9817)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:904] Total time: 0:04:33 (1.5890 s / it)\n",
      "Averaged stats: lr: 0.000011  loss: 0.9898 (0.9817)\n",
      "Valid: [epoch:904]  [ 0/14]  eta: 0:00:06  loss: 0.9259 (0.9259)  time: 0.4643  data: 0.4494  max mem: 20571\n",
      "Valid: [epoch:904]  [13/14]  eta: 0:00:00  loss: 0.9259 (0.9393)  time: 0.0473  data: 0.0323  max mem: 20571\n",
      "Valid: [epoch:904] Total time: 0:00:00 (0.0518 s / it)\n",
      "Averaged stats: loss: 0.9259 (0.9393)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_904_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.939%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:905]  [  0/172]  eta: 0:07:44  lr: 0.000011  loss: 0.9069 (0.9069)  time: 2.6987  data: 1.1244  max mem: 20571\n",
      "Train: [epoch:905]  [ 10/172]  eta: 0:04:32  lr: 0.000011  loss: 0.9949 (0.9841)  time: 1.6801  data: 0.1023  max mem: 20571\n",
      "Train: [epoch:905]  [ 20/172]  eta: 0:04:08  lr: 0.000011  loss: 0.9878 (0.9858)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [ 30/172]  eta: 0:03:49  lr: 0.000011  loss: 0.9874 (0.9878)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [ 40/172]  eta: 0:03:32  lr: 0.000011  loss: 0.9780 (0.9789)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [ 50/172]  eta: 0:03:15  lr: 0.000011  loss: 0.9605 (0.9796)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [ 60/172]  eta: 0:02:59  lr: 0.000011  loss: 0.9811 (0.9817)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [ 70/172]  eta: 0:02:42  lr: 0.000011  loss: 0.9811 (0.9806)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [ 80/172]  eta: 0:02:26  lr: 0.000011  loss: 0.9816 (0.9844)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [ 90/172]  eta: 0:02:10  lr: 0.000011  loss: 1.0034 (0.9890)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [100/172]  eta: 0:01:54  lr: 0.000011  loss: 0.9722 (0.9852)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [110/172]  eta: 0:01:38  lr: 0.000011  loss: 0.9382 (0.9835)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [120/172]  eta: 0:01:22  lr: 0.000011  loss: 0.9456 (0.9840)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [130/172]  eta: 0:01:06  lr: 0.000011  loss: 1.0016 (0.9851)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [140/172]  eta: 0:00:50  lr: 0.000011  loss: 0.9820 (0.9845)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [150/172]  eta: 0:00:34  lr: 0.000011  loss: 0.9551 (0.9833)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [160/172]  eta: 0:00:19  lr: 0.000011  loss: 0.9627 (0.9820)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [170/172]  eta: 0:00:03  lr: 0.000011  loss: 0.9704 (0.9823)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905]  [171/172]  eta: 0:00:01  lr: 0.000011  loss: 0.9704 (0.9823)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:905] Total time: 0:04:33 (1.5881 s / it)\n",
      "Averaged stats: lr: 0.000011  loss: 0.9704 (0.9823)\n",
      "Valid: [epoch:905]  [ 0/14]  eta: 0:00:04  loss: 0.9082 (0.9082)  time: 0.3285  data: 0.3121  max mem: 20571\n",
      "Valid: [epoch:905]  [13/14]  eta: 0:00:00  loss: 0.9266 (0.9400)  time: 0.0375  data: 0.0225  max mem: 20571\n",
      "Valid: [epoch:905] Total time: 0:00:00 (0.0425 s / it)\n",
      "Averaged stats: loss: 0.9266 (0.9400)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_905_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.940%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:906]  [  0/172]  eta: 0:07:40  lr: 0.000011  loss: 0.8959 (0.8959)  time: 2.6790  data: 1.1097  max mem: 20571\n",
      "Train: [epoch:906]  [ 10/172]  eta: 0:04:32  lr: 0.000011  loss: 0.9474 (0.9450)  time: 1.6796  data: 0.1010  max mem: 20571\n",
      "Train: [epoch:906]  [ 20/172]  eta: 0:04:08  lr: 0.000011  loss: 0.9741 (0.9651)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [ 30/172]  eta: 0:03:49  lr: 0.000011  loss: 0.9862 (0.9708)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [ 40/172]  eta: 0:03:32  lr: 0.000011  loss: 0.9862 (0.9764)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [ 50/172]  eta: 0:03:15  lr: 0.000011  loss: 0.9794 (0.9754)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [ 60/172]  eta: 0:02:59  lr: 0.000011  loss: 0.9797 (0.9775)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [ 70/172]  eta: 0:02:42  lr: 0.000011  loss: 0.9855 (0.9780)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [ 80/172]  eta: 0:02:26  lr: 0.000011  loss: 0.9962 (0.9797)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [ 90/172]  eta: 0:02:10  lr: 0.000011  loss: 0.9962 (0.9854)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [100/172]  eta: 0:01:54  lr: 0.000011  loss: 0.9739 (0.9828)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [110/172]  eta: 0:01:38  lr: 0.000011  loss: 0.9855 (0.9845)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [120/172]  eta: 0:01:22  lr: 0.000011  loss: 0.9855 (0.9826)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [130/172]  eta: 0:01:06  lr: 0.000011  loss: 0.9841 (0.9856)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [140/172]  eta: 0:00:50  lr: 0.000011  loss: 0.9976 (0.9856)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [150/172]  eta: 0:00:34  lr: 0.000011  loss: 0.9841 (0.9858)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [160/172]  eta: 0:00:19  lr: 0.000011  loss: 0.9694 (0.9844)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [170/172]  eta: 0:00:03  lr: 0.000011  loss: 0.9524 (0.9831)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906]  [171/172]  eta: 0:00:01  lr: 0.000011  loss: 0.9524 (0.9830)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:906] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000011  loss: 0.9524 (0.9830)\n",
      "Valid: [epoch:906]  [ 0/14]  eta: 0:00:04  loss: 0.9895 (0.9895)  time: 0.3212  data: 0.3026  max mem: 20571\n",
      "Valid: [epoch:906]  [13/14]  eta: 0:00:00  loss: 0.9274 (0.9411)  time: 0.0378  data: 0.0223  max mem: 20571\n",
      "Valid: [epoch:906] Total time: 0:00:00 (0.0450 s / it)\n",
      "Averaged stats: loss: 0.9274 (0.9411)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_906_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.941%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:907]  [  0/172]  eta: 0:07:31  lr: 0.000010  loss: 0.8962 (0.8962)  time: 2.6263  data: 1.0519  max mem: 20571\n",
      "Train: [epoch:907]  [ 10/172]  eta: 0:04:31  lr: 0.000010  loss: 0.9714 (0.9755)  time: 1.6742  data: 0.0957  max mem: 20571\n",
      "Train: [epoch:907]  [ 20/172]  eta: 0:04:07  lr: 0.000010  loss: 0.9695 (0.9860)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [ 30/172]  eta: 0:03:48  lr: 0.000010  loss: 0.9679 (0.9860)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [ 40/172]  eta: 0:03:31  lr: 0.000010  loss: 0.9760 (0.9823)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 0.9773 (0.9876)  time: 1.5808  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:907]  [ 60/172]  eta: 0:02:58  lr: 0.000010  loss: 1.0103 (0.9909)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [ 70/172]  eta: 0:02:42  lr: 0.000010  loss: 1.0055 (0.9875)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [ 80/172]  eta: 0:02:26  lr: 0.000010  loss: 0.9790 (0.9883)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 0.9843 (0.9879)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 0.9741 (0.9861)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.9591 (0.9844)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 0.9692 (0.9855)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 0.9831 (0.9852)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.9892 (0.9857)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [150/172]  eta: 0:00:34  lr: 0.000010  loss: 0.9697 (0.9831)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.9654 (0.9836)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 0.9817 (0.9830)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.9870 (0.9834)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:907] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.9870 (0.9834)\n",
      "Valid: [epoch:907]  [ 0/14]  eta: 0:00:03  loss: 0.9899 (0.9899)  time: 0.2824  data: 0.2675  max mem: 20571\n",
      "Valid: [epoch:907]  [13/14]  eta: 0:00:00  loss: 0.9289 (0.9426)  time: 0.0364  data: 0.0214  max mem: 20571\n",
      "Valid: [epoch:907] Total time: 0:00:00 (0.0446 s / it)\n",
      "Averaged stats: loss: 0.9289 (0.9426)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_907_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.943%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:908]  [  0/172]  eta: 0:07:37  lr: 0.000010  loss: 1.1223 (1.1223)  time: 2.6626  data: 1.0950  max mem: 20571\n",
      "Train: [epoch:908]  [ 10/172]  eta: 0:04:31  lr: 0.000010  loss: 0.9526 (0.9598)  time: 1.6775  data: 0.0996  max mem: 20571\n",
      "Train: [epoch:908]  [ 20/172]  eta: 0:04:07  lr: 0.000010  loss: 0.9653 (0.9801)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [ 30/172]  eta: 0:03:49  lr: 0.000010  loss: 0.9986 (0.9825)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [ 40/172]  eta: 0:03:32  lr: 0.000010  loss: 0.9898 (0.9797)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 0.9680 (0.9820)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [ 60/172]  eta: 0:02:59  lr: 0.000010  loss: 0.9680 (0.9824)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [ 70/172]  eta: 0:02:42  lr: 0.000010  loss: 0.9909 (0.9844)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [ 80/172]  eta: 0:02:26  lr: 0.000010  loss: 1.0065 (0.9838)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 0.9864 (0.9863)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 0.9771 (0.9855)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.9733 (0.9833)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 0.9684 (0.9841)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 0.9907 (0.9841)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.9703 (0.9844)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [150/172]  eta: 0:00:34  lr: 0.000010  loss: 0.9733 (0.9847)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.9770 (0.9840)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 0.9770 (0.9846)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.9732 (0.9845)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:908] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.9732 (0.9845)\n",
      "Valid: [epoch:908]  [ 0/14]  eta: 0:00:04  loss: 0.9254 (0.9254)  time: 0.3145  data: 0.2976  max mem: 20571\n",
      "Valid: [epoch:908]  [13/14]  eta: 0:00:00  loss: 0.9287 (0.9422)  time: 0.0364  data: 0.0214  max mem: 20571\n",
      "Valid: [epoch:908] Total time: 0:00:00 (0.0413 s / it)\n",
      "Averaged stats: loss: 0.9287 (0.9422)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_908_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.942%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:909]  [  0/172]  eta: 0:08:00  lr: 0.000010  loss: 1.0502 (1.0502)  time: 2.7912  data: 1.2150  max mem: 20571\n",
      "Train: [epoch:909]  [ 10/172]  eta: 0:04:33  lr: 0.000010  loss: 0.9719 (0.9651)  time: 1.6862  data: 0.1106  max mem: 20571\n",
      "Train: [epoch:909]  [ 20/172]  eta: 0:04:08  lr: 0.000010  loss: 0.9683 (0.9719)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [ 30/172]  eta: 0:03:49  lr: 0.000010  loss: 0.9683 (0.9726)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [ 40/172]  eta: 0:03:32  lr: 0.000010  loss: 0.9685 (0.9750)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 0.9853 (0.9823)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [ 60/172]  eta: 0:02:58  lr: 0.000010  loss: 1.0230 (0.9881)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [ 70/172]  eta: 0:02:42  lr: 0.000010  loss: 1.0135 (0.9894)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [ 80/172]  eta: 0:02:26  lr: 0.000010  loss: 0.9749 (0.9864)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 0.9707 (0.9854)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 0.9487 (0.9843)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.9601 (0.9867)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 1.0174 (0.9866)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 0.9655 (0.9855)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.9754 (0.9867)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [150/172]  eta: 0:00:34  lr: 0.000010  loss: 1.0153 (0.9883)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.9969 (0.9883)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 0.9759 (0.9871)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.9784 (0.9872)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:909] Total time: 0:04:32 (1.5871 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.9784 (0.9872)\n",
      "Valid: [epoch:909]  [ 0/14]  eta: 0:00:03  loss: 1.0287 (1.0287)  time: 0.2811  data: 0.2658  max mem: 20571\n",
      "Valid: [epoch:909]  [13/14]  eta: 0:00:00  loss: 0.9329 (0.9461)  time: 0.0379  data: 0.0229  max mem: 20571\n",
      "Valid: [epoch:909] Total time: 0:00:00 (0.0429 s / it)\n",
      "Averaged stats: loss: 0.9329 (0.9461)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_909_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.946%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:910]  [  0/172]  eta: 0:07:38  lr: 0.000010  loss: 0.9974 (0.9974)  time: 2.6631  data: 1.0967  max mem: 20571\n",
      "Train: [epoch:910]  [ 10/172]  eta: 0:04:31  lr: 0.000010  loss: 0.9725 (0.9790)  time: 1.6768  data: 0.0998  max mem: 20571\n",
      "Train: [epoch:910]  [ 20/172]  eta: 0:04:07  lr: 0.000010  loss: 0.9595 (0.9743)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [ 30/172]  eta: 0:03:49  lr: 0.000010  loss: 0.9715 (0.9824)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [ 40/172]  eta: 0:03:32  lr: 0.000010  loss: 0.9794 (0.9806)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 0.9794 (0.9791)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [ 60/172]  eta: 0:02:58  lr: 0.000010  loss: 0.9797 (0.9813)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [ 70/172]  eta: 0:02:42  lr: 0.000010  loss: 0.9763 (0.9811)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [ 80/172]  eta: 0:02:26  lr: 0.000010  loss: 0.9759 (0.9823)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 0.9896 (0.9850)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 1.0024 (0.9863)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.9886 (0.9869)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 0.9886 (0.9877)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 0.9968 (0.9885)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.9840 (0.9876)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [150/172]  eta: 0:00:34  lr: 0.000010  loss: 0.9621 (0.9866)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.9816 (0.9877)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 0.9816 (0.9868)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.9816 (0.9868)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:910] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.9816 (0.9868)\n",
      "Valid: [epoch:910]  [ 0/14]  eta: 0:00:03  loss: 0.8404 (0.8404)  time: 0.2777  data: 0.2629  max mem: 20571\n",
      "Valid: [epoch:910]  [13/14]  eta: 0:00:00  loss: 0.9311 (0.9442)  time: 0.0384  data: 0.0233  max mem: 20571\n",
      "Valid: [epoch:910] Total time: 0:00:00 (0.0429 s / it)\n",
      "Averaged stats: loss: 0.9311 (0.9442)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_910_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.944%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:911]  [  0/172]  eta: 0:08:12  lr: 0.000010  loss: 0.9222 (0.9222)  time: 2.8635  data: 1.2826  max mem: 20571\n",
      "Train: [epoch:911]  [ 10/172]  eta: 0:04:34  lr: 0.000010  loss: 0.9936 (0.9991)  time: 1.6937  data: 0.1167  max mem: 20571\n",
      "Train: [epoch:911]  [ 20/172]  eta: 0:04:09  lr: 0.000010  loss: 0.9814 (0.9938)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [ 30/172]  eta: 0:03:49  lr: 0.000010  loss: 0.9814 (0.9915)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [ 40/172]  eta: 0:03:32  lr: 0.000010  loss: 0.9827 (0.9894)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 0.9907 (0.9907)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [ 60/172]  eta: 0:02:59  lr: 0.000010  loss: 0.9894 (0.9889)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [ 70/172]  eta: 0:02:42  lr: 0.000010  loss: 0.9535 (0.9838)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [ 80/172]  eta: 0:02:26  lr: 0.000010  loss: 0.9588 (0.9854)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 0.9687 (0.9863)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 0.9687 (0.9866)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.9989 (0.9879)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 0.9875 (0.9874)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 0.9699 (0.9877)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.9646 (0.9882)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [150/172]  eta: 0:00:34  lr: 0.000010  loss: 0.9990 (0.9875)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.9990 (0.9887)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 1.0073 (0.9887)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.9837 (0.9885)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:911] Total time: 0:04:33 (1.5880 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.9837 (0.9885)\n",
      "Valid: [epoch:911]  [ 0/14]  eta: 0:00:03  loss: 0.9851 (0.9851)  time: 0.2774  data: 0.2612  max mem: 20571\n",
      "Valid: [epoch:911]  [13/14]  eta: 0:00:00  loss: 0.9333 (0.9457)  time: 0.0404  data: 0.0254  max mem: 20571\n",
      "Valid: [epoch:911] Total time: 0:00:00 (0.0457 s / it)\n",
      "Averaged stats: loss: 0.9333 (0.9457)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_911_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.946%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:912]  [  0/172]  eta: 0:08:02  lr: 0.000010  loss: 1.1441 (1.1441)  time: 2.8060  data: 1.2380  max mem: 20571\n",
      "Train: [epoch:912]  [ 10/172]  eta: 0:04:34  lr: 0.000010  loss: 0.9654 (0.9810)  time: 1.6919  data: 0.1127  max mem: 20571\n",
      "Train: [epoch:912]  [ 20/172]  eta: 0:04:09  lr: 0.000010  loss: 0.9773 (0.9890)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [ 30/172]  eta: 0:03:50  lr: 0.000010  loss: 0.9952 (0.9849)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [ 40/172]  eta: 0:03:32  lr: 0.000010  loss: 0.9819 (0.9826)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 1.0036 (0.9867)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [ 60/172]  eta: 0:02:59  lr: 0.000010  loss: 1.0015 (0.9856)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [ 70/172]  eta: 0:02:43  lr: 0.000010  loss: 0.9701 (0.9834)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [ 80/172]  eta: 0:02:26  lr: 0.000010  loss: 0.9652 (0.9786)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 0.9649 (0.9785)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 0.9715 (0.9796)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.9778 (0.9813)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 0.9923 (0.9834)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 0.9950 (0.9835)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.9626 (0.9846)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [150/172]  eta: 0:00:34  lr: 0.000010  loss: 0.9810 (0.9856)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.9810 (0.9857)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 0.9864 (0.9882)  time: 1.5831  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:912]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.9990 (0.9884)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:912] Total time: 0:04:33 (1.5893 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.9990 (0.9884)\n",
      "Valid: [epoch:912]  [ 0/14]  eta: 0:00:03  loss: 0.9941 (0.9941)  time: 0.2752  data: 0.2595  max mem: 20571\n",
      "Valid: [epoch:912]  [13/14]  eta: 0:00:00  loss: 0.9345 (0.9471)  time: 0.0359  data: 0.0209  max mem: 20571\n",
      "Valid: [epoch:912] Total time: 0:00:00 (0.0412 s / it)\n",
      "Averaged stats: loss: 0.9345 (0.9471)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_912_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.947%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:913]  [  0/172]  eta: 0:07:41  lr: 0.000010  loss: 1.0029 (1.0029)  time: 2.6819  data: 1.1097  max mem: 20571\n",
      "Train: [epoch:913]  [ 10/172]  eta: 0:04:32  lr: 0.000010  loss: 0.9764 (0.9803)  time: 1.6802  data: 0.1010  max mem: 20571\n",
      "Train: [epoch:913]  [ 20/172]  eta: 0:04:08  lr: 0.000010  loss: 0.9710 (0.9765)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [ 30/172]  eta: 0:03:49  lr: 0.000010  loss: 0.9799 (0.9782)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [ 40/172]  eta: 0:03:32  lr: 0.000010  loss: 0.9394 (0.9652)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 0.9476 (0.9778)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [ 60/172]  eta: 0:02:59  lr: 0.000010  loss: 1.0050 (0.9800)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [ 70/172]  eta: 0:02:42  lr: 0.000010  loss: 0.9866 (0.9822)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [ 80/172]  eta: 0:02:26  lr: 0.000010  loss: 0.9958 (0.9853)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 1.0141 (0.9888)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 1.0043 (0.9885)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.9825 (0.9878)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 0.9913 (0.9888)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 1.0244 (0.9932)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.9816 (0.9907)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [150/172]  eta: 0:00:34  lr: 0.000010  loss: 0.9409 (0.9893)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.9426 (0.9877)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 0.9601 (0.9887)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.9601 (0.9890)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:913] Total time: 0:04:33 (1.5901 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.9601 (0.9890)\n",
      "Valid: [epoch:913]  [ 0/14]  eta: 0:00:04  loss: 0.9307 (0.9307)  time: 0.3073  data: 0.2908  max mem: 20571\n",
      "Valid: [epoch:913]  [13/14]  eta: 0:00:00  loss: 0.9349 (0.9478)  time: 0.0376  data: 0.0227  max mem: 20571\n",
      "Valid: [epoch:913] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.9349 (0.9478)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_913_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.948%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:914]  [  0/172]  eta: 0:07:47  lr: 0.000010  loss: 1.0221 (1.0221)  time: 2.7173  data: 1.1329  max mem: 20571\n",
      "Train: [epoch:914]  [ 10/172]  eta: 0:04:32  lr: 0.000010  loss: 1.0111 (1.0064)  time: 1.6844  data: 0.1031  max mem: 20571\n",
      "Train: [epoch:914]  [ 20/172]  eta: 0:04:08  lr: 0.000010  loss: 0.9920 (1.0029)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [ 30/172]  eta: 0:03:50  lr: 0.000010  loss: 0.9888 (1.0068)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [ 40/172]  eta: 0:03:32  lr: 0.000010  loss: 0.9708 (0.9952)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 0.9769 (0.9988)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [ 60/172]  eta: 0:02:59  lr: 0.000010  loss: 0.9754 (0.9951)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [ 70/172]  eta: 0:02:43  lr: 0.000010  loss: 0.9619 (0.9917)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [ 80/172]  eta: 0:02:27  lr: 0.000010  loss: 0.9794 (0.9918)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 0.9858 (0.9912)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 0.9980 (0.9920)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.9980 (0.9939)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 0.9860 (0.9939)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 0.9834 (0.9936)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.9818 (0.9922)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [150/172]  eta: 0:00:35  lr: 0.000010  loss: 0.9805 (0.9915)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.9888 (0.9924)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 0.9857 (0.9909)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.9857 (0.9910)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:914] Total time: 0:04:33 (1.5914 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.9857 (0.9910)\n",
      "Valid: [epoch:914]  [ 0/14]  eta: 0:00:04  loss: 0.9880 (0.9880)  time: 0.3209  data: 0.3037  max mem: 20571\n",
      "Valid: [epoch:914]  [13/14]  eta: 0:00:00  loss: 0.9351 (0.9482)  time: 0.0372  data: 0.0219  max mem: 20571\n",
      "Valid: [epoch:914] Total time: 0:00:00 (0.0452 s / it)\n",
      "Averaged stats: loss: 0.9351 (0.9482)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_914_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.948%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:915]  [  0/172]  eta: 0:07:45  lr: 0.000010  loss: 0.9133 (0.9133)  time: 2.7078  data: 1.1278  max mem: 20571\n",
      "Train: [epoch:915]  [ 10/172]  eta: 0:04:32  lr: 0.000010  loss: 0.9942 (0.9806)  time: 1.6821  data: 0.1026  max mem: 20571\n",
      "Train: [epoch:915]  [ 20/172]  eta: 0:04:08  lr: 0.000010  loss: 0.9897 (0.9877)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [ 30/172]  eta: 0:03:49  lr: 0.000010  loss: 0.9928 (0.9904)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [ 40/172]  eta: 0:03:32  lr: 0.000010  loss: 1.0014 (0.9909)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [ 50/172]  eta: 0:03:15  lr: 0.000010  loss: 0.9887 (0.9883)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [ 60/172]  eta: 0:02:59  lr: 0.000010  loss: 0.9933 (0.9942)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [ 70/172]  eta: 0:02:42  lr: 0.000010  loss: 1.0002 (0.9946)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [ 80/172]  eta: 0:02:26  lr: 0.000010  loss: 0.9897 (0.9956)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [ 90/172]  eta: 0:02:10  lr: 0.000010  loss: 1.0080 (0.9988)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [100/172]  eta: 0:01:54  lr: 0.000010  loss: 0.9949 (0.9977)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [110/172]  eta: 0:01:38  lr: 0.000010  loss: 0.9797 (0.9956)  time: 1.5838  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:915]  [120/172]  eta: 0:01:22  lr: 0.000010  loss: 0.9797 (0.9976)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [130/172]  eta: 0:01:06  lr: 0.000010  loss: 0.9595 (0.9964)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [140/172]  eta: 0:00:50  lr: 0.000010  loss: 0.9595 (0.9952)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [150/172]  eta: 0:00:34  lr: 0.000010  loss: 0.9654 (0.9943)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [160/172]  eta: 0:00:19  lr: 0.000010  loss: 0.9852 (0.9919)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [170/172]  eta: 0:00:03  lr: 0.000010  loss: 0.9679 (0.9912)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915]  [171/172]  eta: 0:00:01  lr: 0.000010  loss: 0.9679 (0.9910)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:915] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 0.9679 (0.9910)\n",
      "Valid: [epoch:915]  [ 0/14]  eta: 0:00:05  loss: 0.8705 (0.8705)  time: 0.4023  data: 0.3845  max mem: 20571\n",
      "Valid: [epoch:915]  [13/14]  eta: 0:00:00  loss: 0.9362 (0.9497)  time: 0.0433  data: 0.0281  max mem: 20571\n",
      "Valid: [epoch:915] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 0.9362 (0.9497)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_915_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.950%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:916]  [  0/172]  eta: 0:07:48  lr: 0.000009  loss: 0.9529 (0.9529)  time: 2.7242  data: 1.1559  max mem: 20571\n",
      "Train: [epoch:916]  [ 10/172]  eta: 0:04:32  lr: 0.000009  loss: 0.9849 (0.9826)  time: 1.6849  data: 0.1052  max mem: 20571\n",
      "Train: [epoch:916]  [ 20/172]  eta: 0:04:08  lr: 0.000009  loss: 0.9938 (0.9977)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [ 30/172]  eta: 0:03:49  lr: 0.000009  loss: 1.0001 (1.0017)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [ 40/172]  eta: 0:03:32  lr: 0.000009  loss: 0.9745 (0.9938)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [ 50/172]  eta: 0:03:15  lr: 0.000009  loss: 0.9770 (0.9972)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [ 60/172]  eta: 0:02:59  lr: 0.000009  loss: 0.9936 (0.9973)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [ 70/172]  eta: 0:02:43  lr: 0.000009  loss: 0.9977 (0.9992)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [ 80/172]  eta: 0:02:26  lr: 0.000009  loss: 0.9977 (0.9974)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [ 90/172]  eta: 0:02:10  lr: 0.000009  loss: 0.9966 (0.9981)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [100/172]  eta: 0:01:54  lr: 0.000009  loss: 0.9966 (0.9962)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [110/172]  eta: 0:01:38  lr: 0.000009  loss: 0.9842 (0.9946)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [120/172]  eta: 0:01:22  lr: 0.000009  loss: 0.9945 (0.9993)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [130/172]  eta: 0:01:06  lr: 0.000009  loss: 1.0128 (0.9974)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [140/172]  eta: 0:00:50  lr: 0.000009  loss: 0.9750 (0.9961)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [150/172]  eta: 0:00:34  lr: 0.000009  loss: 0.9851 (0.9960)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [160/172]  eta: 0:00:19  lr: 0.000009  loss: 0.9599 (0.9937)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [170/172]  eta: 0:00:03  lr: 0.000009  loss: 0.9622 (0.9942)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916]  [171/172]  eta: 0:00:01  lr: 0.000009  loss: 0.9622 (0.9941)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:916] Total time: 0:04:33 (1.5903 s / it)\n",
      "Averaged stats: lr: 0.000009  loss: 0.9622 (0.9941)\n",
      "Valid: [epoch:916]  [ 0/14]  eta: 0:00:04  loss: 0.8915 (0.8915)  time: 0.3174  data: 0.3012  max mem: 20571\n",
      "Valid: [epoch:916]  [13/14]  eta: 0:00:00  loss: 0.9381 (0.9512)  time: 0.0368  data: 0.0216  max mem: 20571\n",
      "Valid: [epoch:916] Total time: 0:00:00 (0.0417 s / it)\n",
      "Averaged stats: loss: 0.9381 (0.9512)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_916_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.951%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:917]  [  0/172]  eta: 0:07:36  lr: 0.000009  loss: 1.0432 (1.0432)  time: 2.6539  data: 1.0482  max mem: 20571\n",
      "Train: [epoch:917]  [ 10/172]  eta: 0:04:32  lr: 0.000009  loss: 0.9869 (0.9714)  time: 1.6792  data: 0.0954  max mem: 20571\n",
      "Train: [epoch:917]  [ 20/172]  eta: 0:04:08  lr: 0.000009  loss: 0.9858 (0.9829)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [ 30/172]  eta: 0:03:49  lr: 0.000009  loss: 0.9912 (0.9968)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [ 40/172]  eta: 0:03:32  lr: 0.000009  loss: 1.0010 (0.9934)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [ 50/172]  eta: 0:03:15  lr: 0.000009  loss: 0.9865 (0.9983)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [ 60/172]  eta: 0:02:59  lr: 0.000009  loss: 1.0009 (0.9979)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [ 70/172]  eta: 0:02:43  lr: 0.000009  loss: 1.0009 (0.9999)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [ 80/172]  eta: 0:02:26  lr: 0.000009  loss: 0.9943 (1.0006)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [ 90/172]  eta: 0:02:10  lr: 0.000009  loss: 0.9783 (0.9985)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [100/172]  eta: 0:01:54  lr: 0.000009  loss: 0.9868 (0.9979)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [110/172]  eta: 0:01:38  lr: 0.000009  loss: 0.9957 (0.9981)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [120/172]  eta: 0:01:22  lr: 0.000009  loss: 0.9619 (0.9972)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [130/172]  eta: 0:01:06  lr: 0.000009  loss: 0.9708 (0.9970)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [140/172]  eta: 0:00:50  lr: 0.000009  loss: 0.9883 (0.9964)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [150/172]  eta: 0:00:35  lr: 0.000009  loss: 0.9883 (0.9949)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [160/172]  eta: 0:00:19  lr: 0.000009  loss: 0.9701 (0.9936)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [170/172]  eta: 0:00:03  lr: 0.000009  loss: 0.9765 (0.9938)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917]  [171/172]  eta: 0:00:01  lr: 0.000009  loss: 0.9765 (0.9938)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:917] Total time: 0:04:33 (1.5914 s / it)\n",
      "Averaged stats: lr: 0.000009  loss: 0.9765 (0.9938)\n",
      "Valid: [epoch:917]  [ 0/14]  eta: 0:00:05  loss: 0.9866 (0.9866)  time: 0.4209  data: 0.4031  max mem: 20571\n",
      "Valid: [epoch:917]  [13/14]  eta: 0:00:00  loss: 0.9391 (0.9519)  time: 0.0447  data: 0.0294  max mem: 20571\n",
      "Valid: [epoch:917] Total time: 0:00:00 (0.0502 s / it)\n",
      "Averaged stats: loss: 0.9391 (0.9519)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_917_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.952%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:918]  [  0/172]  eta: 0:07:41  lr: 0.000009  loss: 0.9536 (0.9536)  time: 2.6811  data: 1.1099  max mem: 20571\n",
      "Train: [epoch:918]  [ 10/172]  eta: 0:04:32  lr: 0.000009  loss: 0.9638 (0.9952)  time: 1.6830  data: 0.1010  max mem: 20571\n",
      "Train: [epoch:918]  [ 20/172]  eta: 0:04:08  lr: 0.000009  loss: 0.9918 (0.9948)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [ 30/172]  eta: 0:03:50  lr: 0.000009  loss: 0.9954 (0.9924)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [ 40/172]  eta: 0:03:32  lr: 0.000009  loss: 0.9617 (0.9854)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [ 50/172]  eta: 0:03:16  lr: 0.000009  loss: 0.9941 (0.9906)  time: 1.5853  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:918]  [ 60/172]  eta: 0:02:59  lr: 0.000009  loss: 0.9959 (0.9932)  time: 1.5847  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:918]  [ 70/172]  eta: 0:02:43  lr: 0.000009  loss: 0.9777 (0.9909)  time: 1.5849  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:918]  [ 80/172]  eta: 0:02:27  lr: 0.000009  loss: 0.9688 (0.9905)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [ 90/172]  eta: 0:02:11  lr: 0.000009  loss: 0.9868 (0.9894)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [100/172]  eta: 0:01:54  lr: 0.000009  loss: 0.9912 (0.9899)  time: 1.5872  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:918]  [110/172]  eta: 0:01:38  lr: 0.000009  loss: 1.0151 (0.9923)  time: 1.5894  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [120/172]  eta: 0:01:22  lr: 0.000009  loss: 1.0192 (0.9933)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [130/172]  eta: 0:01:06  lr: 0.000009  loss: 1.0192 (0.9948)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [140/172]  eta: 0:00:51  lr: 0.000009  loss: 0.9906 (0.9940)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [150/172]  eta: 0:00:35  lr: 0.000009  loss: 0.9906 (0.9933)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [160/172]  eta: 0:00:19  lr: 0.000009  loss: 0.9937 (0.9940)  time: 1.5869  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:918]  [170/172]  eta: 0:00:03  lr: 0.000009  loss: 0.9790 (0.9940)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918]  [171/172]  eta: 0:00:01  lr: 0.000009  loss: 0.9914 (0.9949)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:918] Total time: 0:04:34 (1.5933 s / it)\n",
      "Averaged stats: lr: 0.000009  loss: 0.9914 (0.9949)\n",
      "Valid: [epoch:918]  [ 0/14]  eta: 0:00:05  loss: 0.9918 (0.9918)  time: 0.4144  data: 0.3989  max mem: 20571\n",
      "Valid: [epoch:918]  [13/14]  eta: 0:00:00  loss: 0.9383 (0.9520)  time: 0.0444  data: 0.0294  max mem: 20571\n",
      "Valid: [epoch:918] Total time: 0:00:00 (0.0500 s / it)\n",
      "Averaged stats: loss: 0.9383 (0.9520)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_918_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.952%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:919]  [  0/172]  eta: 0:07:41  lr: 0.000009  loss: 0.9103 (0.9103)  time: 2.6817  data: 1.0995  max mem: 20571\n",
      "Train: [epoch:919]  [ 10/172]  eta: 0:04:32  lr: 0.000009  loss: 0.9651 (0.9805)  time: 1.6799  data: 0.1001  max mem: 20571\n",
      "Train: [epoch:919]  [ 20/172]  eta: 0:04:08  lr: 0.000009  loss: 0.9858 (0.9789)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [ 30/172]  eta: 0:03:49  lr: 0.000009  loss: 0.9858 (0.9836)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [ 40/172]  eta: 0:03:32  lr: 0.000009  loss: 0.9859 (0.9879)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [ 50/172]  eta: 0:03:15  lr: 0.000009  loss: 0.9859 (0.9897)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [ 60/172]  eta: 0:02:59  lr: 0.000009  loss: 0.9871 (0.9908)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [ 70/172]  eta: 0:02:43  lr: 0.000009  loss: 1.0075 (0.9917)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [ 80/172]  eta: 0:02:26  lr: 0.000009  loss: 1.0091 (0.9926)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [ 90/172]  eta: 0:02:10  lr: 0.000009  loss: 1.0161 (0.9968)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [100/172]  eta: 0:01:54  lr: 0.000009  loss: 0.9992 (0.9946)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [110/172]  eta: 0:01:38  lr: 0.000009  loss: 0.9637 (0.9934)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [120/172]  eta: 0:01:22  lr: 0.000009  loss: 0.9707 (0.9922)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [130/172]  eta: 0:01:06  lr: 0.000009  loss: 0.9838 (0.9948)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [140/172]  eta: 0:00:50  lr: 0.000009  loss: 1.0106 (0.9957)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [150/172]  eta: 0:00:35  lr: 0.000009  loss: 0.9902 (0.9939)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [160/172]  eta: 0:00:19  lr: 0.000009  loss: 0.9902 (0.9946)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [170/172]  eta: 0:00:03  lr: 0.000009  loss: 0.9956 (0.9956)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919]  [171/172]  eta: 0:00:01  lr: 0.000009  loss: 0.9931 (0.9952)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:919] Total time: 0:04:33 (1.5919 s / it)\n",
      "Averaged stats: lr: 0.000009  loss: 0.9931 (0.9952)\n",
      "Valid: [epoch:919]  [ 0/14]  eta: 0:00:04  loss: 0.9385 (0.9385)  time: 0.3083  data: 0.2921  max mem: 20571\n",
      "Valid: [epoch:919]  [13/14]  eta: 0:00:00  loss: 0.9415 (0.9545)  time: 0.0367  data: 0.0215  max mem: 20571\n",
      "Valid: [epoch:919] Total time: 0:00:00 (0.0413 s / it)\n",
      "Averaged stats: loss: 0.9415 (0.9545)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_919_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.954%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:920]  [  0/172]  eta: 0:07:34  lr: 0.000009  loss: 0.9563 (0.9563)  time: 2.6415  data: 1.0403  max mem: 20571\n",
      "Train: [epoch:920]  [ 10/172]  eta: 0:04:32  lr: 0.000009  loss: 0.9599 (0.9656)  time: 1.6808  data: 0.0947  max mem: 20571\n",
      "Train: [epoch:920]  [ 20/172]  eta: 0:04:08  lr: 0.000009  loss: 0.9741 (0.9886)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [ 30/172]  eta: 0:03:49  lr: 0.000009  loss: 1.0020 (0.9951)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [ 40/172]  eta: 0:03:32  lr: 0.000009  loss: 0.9694 (0.9908)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [ 50/172]  eta: 0:03:15  lr: 0.000009  loss: 0.9908 (1.0017)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [ 60/172]  eta: 0:02:59  lr: 0.000009  loss: 1.0149 (1.0026)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [ 70/172]  eta: 0:02:43  lr: 0.000009  loss: 0.9752 (1.0004)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [ 80/172]  eta: 0:02:26  lr: 0.000009  loss: 0.9758 (0.9982)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [ 90/172]  eta: 0:02:10  lr: 0.000009  loss: 0.9713 (0.9948)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [100/172]  eta: 0:01:54  lr: 0.000009  loss: 0.9636 (0.9947)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [110/172]  eta: 0:01:38  lr: 0.000009  loss: 0.9801 (0.9958)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [120/172]  eta: 0:01:22  lr: 0.000009  loss: 1.0173 (0.9962)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [130/172]  eta: 0:01:06  lr: 0.000009  loss: 1.0173 (0.9992)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [140/172]  eta: 0:00:50  lr: 0.000009  loss: 1.0008 (0.9990)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [150/172]  eta: 0:00:35  lr: 0.000009  loss: 0.9685 (0.9981)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [160/172]  eta: 0:00:19  lr: 0.000009  loss: 0.9782 (0.9982)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [170/172]  eta: 0:00:03  lr: 0.000009  loss: 0.9690 (0.9971)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920]  [171/172]  eta: 0:00:01  lr: 0.000009  loss: 0.9697 (0.9972)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:920] Total time: 0:04:33 (1.5912 s / it)\n",
      "Averaged stats: lr: 0.000009  loss: 0.9697 (0.9972)\n",
      "Valid: [epoch:920]  [ 0/14]  eta: 0:00:05  loss: 0.8497 (0.8497)  time: 0.4263  data: 0.4100  max mem: 20571\n",
      "Valid: [epoch:920]  [13/14]  eta: 0:00:00  loss: 0.9410 (0.9543)  time: 0.0454  data: 0.0303  max mem: 20571\n",
      "Valid: [epoch:920] Total time: 0:00:00 (0.0497 s / it)\n",
      "Averaged stats: loss: 0.9410 (0.9543)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_920_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.954%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:921]  [  0/172]  eta: 0:07:50  lr: 0.000009  loss: 0.9986 (0.9986)  time: 2.7370  data: 1.1415  max mem: 20571\n",
      "Train: [epoch:921]  [ 10/172]  eta: 0:04:32  lr: 0.000009  loss: 1.0009 (0.9901)  time: 1.6845  data: 0.1039  max mem: 20571\n",
      "Train: [epoch:921]  [ 20/172]  eta: 0:04:08  lr: 0.000009  loss: 0.9828 (0.9787)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [ 30/172]  eta: 0:03:49  lr: 0.000009  loss: 0.9772 (0.9814)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [ 40/172]  eta: 0:03:32  lr: 0.000009  loss: 0.9594 (0.9764)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [ 50/172]  eta: 0:03:15  lr: 0.000009  loss: 0.9641 (0.9787)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [ 60/172]  eta: 0:02:59  lr: 0.000009  loss: 0.9953 (0.9818)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [ 70/172]  eta: 0:02:43  lr: 0.000009  loss: 0.9961 (0.9835)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [ 80/172]  eta: 0:02:26  lr: 0.000009  loss: 0.9830 (0.9846)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [ 90/172]  eta: 0:02:10  lr: 0.000009  loss: 0.9897 (0.9850)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [100/172]  eta: 0:01:54  lr: 0.000009  loss: 0.9920 (0.9880)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [110/172]  eta: 0:01:38  lr: 0.000009  loss: 1.0285 (0.9940)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [120/172]  eta: 0:01:22  lr: 0.000009  loss: 1.0279 (0.9960)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [130/172]  eta: 0:01:06  lr: 0.000009  loss: 1.0165 (0.9965)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [140/172]  eta: 0:00:50  lr: 0.000009  loss: 0.9873 (0.9968)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [150/172]  eta: 0:00:35  lr: 0.000009  loss: 0.9873 (0.9995)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [160/172]  eta: 0:00:19  lr: 0.000009  loss: 1.0124 (0.9988)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [170/172]  eta: 0:00:03  lr: 0.000009  loss: 0.9905 (0.9978)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921]  [171/172]  eta: 0:00:01  lr: 0.000009  loss: 0.9926 (0.9980)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:921] Total time: 0:04:33 (1.5915 s / it)\n",
      "Averaged stats: lr: 0.000009  loss: 0.9926 (0.9980)\n",
      "Valid: [epoch:921]  [ 0/14]  eta: 0:00:04  loss: 0.9419 (0.9419)  time: 0.3063  data: 0.2899  max mem: 20571\n",
      "Valid: [epoch:921]  [13/14]  eta: 0:00:00  loss: 0.9419 (0.9552)  time: 0.0372  data: 0.0221  max mem: 20571\n",
      "Valid: [epoch:921] Total time: 0:00:00 (0.0427 s / it)\n",
      "Averaged stats: loss: 0.9419 (0.9552)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_921_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.955%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:922]  [  0/172]  eta: 0:08:10  lr: 0.000009  loss: 1.0302 (1.0302)  time: 2.8518  data: 1.2841  max mem: 20571\n",
      "Train: [epoch:922]  [ 10/172]  eta: 0:04:35  lr: 0.000009  loss: 1.0029 (0.9969)  time: 1.6978  data: 0.1168  max mem: 20571\n",
      "Train: [epoch:922]  [ 20/172]  eta: 0:04:09  lr: 0.000009  loss: 1.0029 (1.0084)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [ 30/172]  eta: 0:03:50  lr: 0.000009  loss: 1.0157 (1.0118)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [ 40/172]  eta: 0:03:32  lr: 0.000009  loss: 0.9889 (1.0022)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [ 50/172]  eta: 0:03:16  lr: 0.000009  loss: 0.9771 (0.9991)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [ 60/172]  eta: 0:02:59  lr: 0.000009  loss: 0.9903 (0.9966)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [ 70/172]  eta: 0:02:43  lr: 0.000009  loss: 0.9652 (0.9951)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [ 80/172]  eta: 0:02:27  lr: 0.000009  loss: 0.9744 (0.9928)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [ 90/172]  eta: 0:02:10  lr: 0.000009  loss: 0.9898 (0.9953)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [100/172]  eta: 0:01:54  lr: 0.000009  loss: 0.9964 (0.9985)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [110/172]  eta: 0:01:38  lr: 0.000009  loss: 0.9907 (0.9976)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [120/172]  eta: 0:01:22  lr: 0.000009  loss: 0.9854 (0.9991)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [130/172]  eta: 0:01:06  lr: 0.000009  loss: 0.9756 (0.9975)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [140/172]  eta: 0:00:50  lr: 0.000009  loss: 0.9729 (0.9968)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [150/172]  eta: 0:00:34  lr: 0.000009  loss: 0.9922 (0.9974)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [160/172]  eta: 0:00:19  lr: 0.000009  loss: 0.9854 (0.9977)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [170/172]  eta: 0:00:03  lr: 0.000009  loss: 0.9908 (0.9989)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922]  [171/172]  eta: 0:00:01  lr: 0.000009  loss: 0.9908 (0.9990)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:922] Total time: 0:04:33 (1.5902 s / it)\n",
      "Averaged stats: lr: 0.000009  loss: 0.9908 (0.9990)\n",
      "Valid: [epoch:922]  [ 0/14]  eta: 0:00:05  loss: 1.0412 (1.0412)  time: 0.4172  data: 0.4007  max mem: 20571\n",
      "Valid: [epoch:922]  [13/14]  eta: 0:00:00  loss: 0.9420 (0.9560)  time: 0.0446  data: 0.0296  max mem: 20571\n",
      "Valid: [epoch:922] Total time: 0:00:00 (0.0498 s / it)\n",
      "Averaged stats: loss: 0.9420 (0.9560)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_922_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.956%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:923]  [  0/172]  eta: 0:07:50  lr: 0.000009  loss: 0.9968 (0.9968)  time: 2.7365  data: 1.1606  max mem: 20571\n",
      "Train: [epoch:923]  [ 10/172]  eta: 0:04:32  lr: 0.000009  loss: 1.0030 (1.0154)  time: 1.6808  data: 0.1056  max mem: 20571\n",
      "Train: [epoch:923]  [ 20/172]  eta: 0:04:08  lr: 0.000009  loss: 1.0094 (1.0145)  time: 1.5774  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [ 30/172]  eta: 0:03:49  lr: 0.000009  loss: 0.9950 (1.0056)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [ 40/172]  eta: 0:03:31  lr: 0.000009  loss: 0.9950 (1.0028)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [ 50/172]  eta: 0:03:15  lr: 0.000009  loss: 0.9953 (1.0010)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [ 60/172]  eta: 0:02:58  lr: 0.000009  loss: 0.9969 (1.0057)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [ 70/172]  eta: 0:02:42  lr: 0.000009  loss: 0.9893 (1.0011)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [ 80/172]  eta: 0:02:26  lr: 0.000009  loss: 0.9706 (0.9977)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [ 90/172]  eta: 0:02:10  lr: 0.000009  loss: 0.9766 (0.9952)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [100/172]  eta: 0:01:54  lr: 0.000009  loss: 0.9862 (0.9943)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [110/172]  eta: 0:01:38  lr: 0.000009  loss: 0.9981 (0.9977)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [120/172]  eta: 0:01:22  lr: 0.000009  loss: 1.0076 (0.9981)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [130/172]  eta: 0:01:06  lr: 0.000009  loss: 1.0076 (0.9982)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [140/172]  eta: 0:00:50  lr: 0.000009  loss: 1.0048 (0.9986)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [150/172]  eta: 0:00:34  lr: 0.000009  loss: 1.0194 (1.0004)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [160/172]  eta: 0:00:19  lr: 0.000009  loss: 1.0088 (1.0008)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923]  [170/172]  eta: 0:00:03  lr: 0.000009  loss: 1.0084 (0.9998)  time: 1.5797  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:923]  [171/172]  eta: 0:00:01  lr: 0.000009  loss: 1.0084 (0.9999)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:923] Total time: 0:04:32 (1.5855 s / it)\n",
      "Averaged stats: lr: 0.000009  loss: 1.0084 (0.9999)\n",
      "Valid: [epoch:923]  [ 0/14]  eta: 0:00:04  loss: 1.0424 (1.0424)  time: 0.3282  data: 0.3133  max mem: 20571\n",
      "Valid: [epoch:923]  [13/14]  eta: 0:00:00  loss: 0.9445 (0.9573)  time: 0.0393  data: 0.0242  max mem: 20571\n",
      "Valid: [epoch:923] Total time: 0:00:00 (0.0486 s / it)\n",
      "Averaged stats: loss: 0.9445 (0.9573)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_923_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.957%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:924]  [  0/172]  eta: 0:07:31  lr: 0.000009  loss: 0.9617 (0.9617)  time: 2.6245  data: 1.0589  max mem: 20571\n",
      "Train: [epoch:924]  [ 10/172]  eta: 0:04:31  lr: 0.000009  loss: 1.0020 (0.9975)  time: 1.6746  data: 0.0964  max mem: 20571\n",
      "Train: [epoch:924]  [ 20/172]  eta: 0:04:07  lr: 0.000009  loss: 1.0020 (1.0033)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [ 30/172]  eta: 0:03:49  lr: 0.000009  loss: 0.9854 (1.0042)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [ 40/172]  eta: 0:03:32  lr: 0.000009  loss: 0.9689 (0.9988)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [ 50/172]  eta: 0:03:15  lr: 0.000009  loss: 0.9923 (1.0001)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [ 60/172]  eta: 0:02:59  lr: 0.000009  loss: 0.9949 (0.9982)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [ 70/172]  eta: 0:02:42  lr: 0.000009  loss: 0.9907 (0.9962)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [ 80/172]  eta: 0:02:26  lr: 0.000009  loss: 0.9984 (0.9979)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [ 90/172]  eta: 0:02:10  lr: 0.000009  loss: 0.9979 (0.9978)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [100/172]  eta: 0:01:54  lr: 0.000009  loss: 1.0040 (1.0005)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [110/172]  eta: 0:01:38  lr: 0.000009  loss: 0.9974 (0.9984)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [120/172]  eta: 0:01:22  lr: 0.000009  loss: 0.9766 (0.9965)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [130/172]  eta: 0:01:06  lr: 0.000009  loss: 0.9833 (0.9972)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [140/172]  eta: 0:00:50  lr: 0.000009  loss: 0.9830 (0.9975)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [150/172]  eta: 0:00:34  lr: 0.000009  loss: 0.9770 (0.9996)  time: 1.5805  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:924]  [160/172]  eta: 0:00:19  lr: 0.000009  loss: 1.0210 (0.9994)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [170/172]  eta: 0:00:03  lr: 0.000009  loss: 1.0210 (1.0001)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924]  [171/172]  eta: 0:00:01  lr: 0.000009  loss: 1.0210 (1.0002)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:924] Total time: 0:04:33 (1.5876 s / it)\n",
      "Averaged stats: lr: 0.000009  loss: 1.0210 (1.0002)\n",
      "Valid: [epoch:924]  [ 0/14]  eta: 0:00:04  loss: 0.8533 (0.8533)  time: 0.2879  data: 0.2731  max mem: 20571\n",
      "Valid: [epoch:924]  [13/14]  eta: 0:00:00  loss: 0.9455 (0.9583)  time: 0.0395  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:924] Total time: 0:00:00 (0.0476 s / it)\n",
      "Averaged stats: loss: 0.9455 (0.9583)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_924_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.958%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:925]  [  0/172]  eta: 0:08:08  lr: 0.000008  loss: 0.9695 (0.9695)  time: 2.8405  data: 1.2622  max mem: 20571\n",
      "Train: [epoch:925]  [ 10/172]  eta: 0:04:33  lr: 0.000008  loss: 0.9859 (0.9972)  time: 1.6907  data: 0.1148  max mem: 20571\n",
      "Train: [epoch:925]  [ 20/172]  eta: 0:04:08  lr: 0.000008  loss: 0.9859 (0.9920)  time: 1.5766  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [ 30/172]  eta: 0:03:49  lr: 0.000008  loss: 0.9832 (0.9873)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [ 40/172]  eta: 0:03:32  lr: 0.000008  loss: 0.9827 (0.9909)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [ 50/172]  eta: 0:03:15  lr: 0.000008  loss: 1.0073 (0.9964)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [ 60/172]  eta: 0:02:59  lr: 0.000008  loss: 0.9932 (0.9946)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [ 70/172]  eta: 0:02:42  lr: 0.000008  loss: 0.9932 (0.9954)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [ 80/172]  eta: 0:02:26  lr: 0.000008  loss: 1.0017 (0.9973)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [ 90/172]  eta: 0:02:10  lr: 0.000008  loss: 0.9850 (0.9944)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [100/172]  eta: 0:01:54  lr: 0.000008  loss: 0.9896 (0.9967)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [110/172]  eta: 0:01:38  lr: 0.000008  loss: 1.0189 (0.9970)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [120/172]  eta: 0:01:22  lr: 0.000008  loss: 1.0203 (0.9995)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [130/172]  eta: 0:01:06  lr: 0.000008  loss: 1.0080 (0.9976)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [140/172]  eta: 0:00:50  lr: 0.000008  loss: 0.9842 (0.9970)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [150/172]  eta: 0:00:34  lr: 0.000008  loss: 1.0284 (1.0009)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [160/172]  eta: 0:00:19  lr: 0.000008  loss: 1.0352 (1.0003)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [170/172]  eta: 0:00:03  lr: 0.000008  loss: 1.0109 (1.0012)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925]  [171/172]  eta: 0:00:01  lr: 0.000008  loss: 1.0175 (1.0021)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:925] Total time: 0:04:33 (1.5878 s / it)\n",
      "Averaged stats: lr: 0.000008  loss: 1.0175 (1.0021)\n",
      "Valid: [epoch:925]  [ 0/14]  eta: 0:00:04  loss: 0.9456 (0.9456)  time: 0.2983  data: 0.2831  max mem: 20571\n",
      "Valid: [epoch:925]  [13/14]  eta: 0:00:00  loss: 0.9456 (0.9589)  time: 0.0395  data: 0.0245  max mem: 20571\n",
      "Valid: [epoch:925] Total time: 0:00:00 (0.0455 s / it)\n",
      "Averaged stats: loss: 0.9456 (0.9589)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_925_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.959%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:926]  [  0/172]  eta: 0:08:13  lr: 0.000008  loss: 1.1090 (1.1090)  time: 2.8681  data: 1.3009  max mem: 20571\n",
      "Train: [epoch:926]  [ 10/172]  eta: 0:04:35  lr: 0.000008  loss: 1.0223 (1.0183)  time: 1.6982  data: 0.1184  max mem: 20571\n",
      "Train: [epoch:926]  [ 20/172]  eta: 0:04:09  lr: 0.000008  loss: 0.9831 (1.0033)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [ 30/172]  eta: 0:03:50  lr: 0.000008  loss: 0.9831 (0.9987)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [ 40/172]  eta: 0:03:32  lr: 0.000008  loss: 0.9883 (0.9977)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [ 50/172]  eta: 0:03:16  lr: 0.000008  loss: 1.0258 (1.0062)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [ 60/172]  eta: 0:02:59  lr: 0.000008  loss: 1.0104 (1.0030)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [ 70/172]  eta: 0:02:43  lr: 0.000008  loss: 0.9957 (1.0037)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [ 80/172]  eta: 0:02:26  lr: 0.000008  loss: 1.0161 (1.0068)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [ 90/172]  eta: 0:02:10  lr: 0.000008  loss: 1.0161 (1.0054)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [100/172]  eta: 0:01:54  lr: 0.000008  loss: 0.9997 (1.0044)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [110/172]  eta: 0:01:38  lr: 0.000008  loss: 1.0094 (1.0054)  time: 1.5811  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:926]  [120/172]  eta: 0:01:22  lr: 0.000008  loss: 1.0094 (1.0052)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [130/172]  eta: 0:01:06  lr: 0.000008  loss: 0.9887 (1.0036)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [140/172]  eta: 0:00:50  lr: 0.000008  loss: 0.9887 (1.0041)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [150/172]  eta: 0:00:34  lr: 0.000008  loss: 0.9844 (1.0040)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [160/172]  eta: 0:00:19  lr: 0.000008  loss: 0.9859 (1.0040)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [170/172]  eta: 0:00:03  lr: 0.000008  loss: 0.9859 (1.0025)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926]  [171/172]  eta: 0:00:01  lr: 0.000008  loss: 0.9859 (1.0030)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:926] Total time: 0:04:33 (1.5885 s / it)\n",
      "Averaged stats: lr: 0.000008  loss: 0.9859 (1.0030)\n",
      "Valid: [epoch:926]  [ 0/14]  eta: 0:00:05  loss: 0.9266 (0.9266)  time: 0.3607  data: 0.3249  max mem: 20571\n",
      "Valid: [epoch:926]  [13/14]  eta: 0:00:00  loss: 0.9462 (0.9593)  time: 0.0419  data: 0.0234  max mem: 20571\n",
      "Valid: [epoch:926] Total time: 0:00:00 (0.0500 s / it)\n",
      "Averaged stats: loss: 0.9462 (0.9593)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_926_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.959%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:927]  [  0/172]  eta: 0:08:07  lr: 0.000008  loss: 0.9793 (0.9793)  time: 2.8354  data: 1.2639  max mem: 20571\n",
      "Train: [epoch:927]  [ 10/172]  eta: 0:04:33  lr: 0.000008  loss: 0.9981 (0.9942)  time: 1.6884  data: 0.1150  max mem: 20571\n",
      "Train: [epoch:927]  [ 20/172]  eta: 0:04:08  lr: 0.000008  loss: 1.0102 (1.0109)  time: 1.5772  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [ 30/172]  eta: 0:03:49  lr: 0.000008  loss: 0.9933 (1.0043)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [ 40/172]  eta: 0:03:32  lr: 0.000008  loss: 0.9874 (1.0053)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [ 50/172]  eta: 0:03:15  lr: 0.000008  loss: 0.9796 (0.9979)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [ 60/172]  eta: 0:02:59  lr: 0.000008  loss: 1.0165 (1.0070)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [ 70/172]  eta: 0:02:42  lr: 0.000008  loss: 1.0090 (1.0049)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [ 80/172]  eta: 0:02:26  lr: 0.000008  loss: 1.0010 (1.0052)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [ 90/172]  eta: 0:02:10  lr: 0.000008  loss: 1.0076 (1.0052)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [100/172]  eta: 0:01:54  lr: 0.000008  loss: 1.0154 (1.0054)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [110/172]  eta: 0:01:38  lr: 0.000008  loss: 1.0226 (1.0069)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [120/172]  eta: 0:01:22  lr: 0.000008  loss: 1.0241 (1.0084)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [130/172]  eta: 0:01:06  lr: 0.000008  loss: 1.0159 (1.0083)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [140/172]  eta: 0:00:50  lr: 0.000008  loss: 0.9833 (1.0067)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [150/172]  eta: 0:00:34  lr: 0.000008  loss: 0.9709 (1.0031)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [160/172]  eta: 0:00:19  lr: 0.000008  loss: 0.9593 (1.0033)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [170/172]  eta: 0:00:03  lr: 0.000008  loss: 0.9840 (1.0037)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927]  [171/172]  eta: 0:00:01  lr: 0.000008  loss: 0.9978 (1.0041)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:927] Total time: 0:04:33 (1.5877 s / it)\n",
      "Averaged stats: lr: 0.000008  loss: 0.9978 (1.0041)\n",
      "Valid: [epoch:927]  [ 0/14]  eta: 0:00:04  loss: 1.0472 (1.0472)  time: 0.3081  data: 0.2924  max mem: 20571\n",
      "Valid: [epoch:927]  [13/14]  eta: 0:00:00  loss: 0.9483 (0.9614)  time: 0.0410  data: 0.0258  max mem: 20571\n",
      "Valid: [epoch:927] Total time: 0:00:00 (0.0459 s / it)\n",
      "Averaged stats: loss: 0.9483 (0.9614)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_927_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.961%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:928]  [  0/172]  eta: 0:07:48  lr: 0.000008  loss: 1.0735 (1.0735)  time: 2.7239  data: 1.1572  max mem: 20571\n",
      "Train: [epoch:928]  [ 10/172]  eta: 0:04:32  lr: 0.000008  loss: 1.0171 (0.9982)  time: 1.6808  data: 0.1053  max mem: 20571\n",
      "Train: [epoch:928]  [ 20/172]  eta: 0:04:08  lr: 0.000008  loss: 1.0057 (1.0003)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [ 30/172]  eta: 0:03:49  lr: 0.000008  loss: 0.9895 (0.9925)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [ 40/172]  eta: 0:03:32  lr: 0.000008  loss: 0.9657 (0.9917)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [ 50/172]  eta: 0:03:15  lr: 0.000008  loss: 0.9682 (0.9888)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [ 60/172]  eta: 0:02:59  lr: 0.000008  loss: 0.9772 (0.9925)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [ 70/172]  eta: 0:02:42  lr: 0.000008  loss: 1.0110 (0.9946)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [ 80/172]  eta: 0:02:26  lr: 0.000008  loss: 1.0068 (0.9962)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [ 90/172]  eta: 0:02:10  lr: 0.000008  loss: 0.9963 (0.9985)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [100/172]  eta: 0:01:54  lr: 0.000008  loss: 0.9866 (0.9984)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [110/172]  eta: 0:01:38  lr: 0.000008  loss: 0.9794 (0.9985)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [120/172]  eta: 0:01:22  lr: 0.000008  loss: 0.9888 (0.9990)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [130/172]  eta: 0:01:06  lr: 0.000008  loss: 1.0171 (1.0005)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [140/172]  eta: 0:00:50  lr: 0.000008  loss: 0.9984 (1.0000)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [150/172]  eta: 0:00:34  lr: 0.000008  loss: 0.9867 (1.0022)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [160/172]  eta: 0:00:19  lr: 0.000008  loss: 0.9912 (1.0018)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [170/172]  eta: 0:00:03  lr: 0.000008  loss: 1.0094 (1.0041)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928]  [171/172]  eta: 0:00:01  lr: 0.000008  loss: 1.0308 (1.0046)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:928] Total time: 0:04:33 (1.5872 s / it)\n",
      "Averaged stats: lr: 0.000008  loss: 1.0308 (1.0046)\n",
      "Valid: [epoch:928]  [ 0/14]  eta: 0:00:04  loss: 0.9484 (0.9484)  time: 0.3424  data: 0.3262  max mem: 20571\n",
      "Valid: [epoch:928]  [13/14]  eta: 0:00:00  loss: 0.9484 (0.9616)  time: 0.0391  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:928] Total time: 0:00:00 (0.0438 s / it)\n",
      "Averaged stats: loss: 0.9484 (0.9616)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_928_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.962%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:929]  [  0/172]  eta: 0:08:00  lr: 0.000008  loss: 1.0546 (1.0546)  time: 2.7910  data: 1.2127  max mem: 20571\n",
      "Train: [epoch:929]  [ 10/172]  eta: 0:04:33  lr: 0.000008  loss: 1.0161 (1.0041)  time: 1.6859  data: 0.1103  max mem: 20571\n",
      "Train: [epoch:929]  [ 20/172]  eta: 0:04:08  lr: 0.000008  loss: 1.0161 (1.0106)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [ 30/172]  eta: 0:03:49  lr: 0.000008  loss: 0.9887 (1.0022)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [ 40/172]  eta: 0:03:32  lr: 0.000008  loss: 0.9791 (0.9993)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [ 50/172]  eta: 0:03:15  lr: 0.000008  loss: 1.0015 (1.0011)  time: 1.5821  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:929]  [ 60/172]  eta: 0:02:59  lr: 0.000008  loss: 1.0015 (1.0022)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [ 70/172]  eta: 0:02:42  lr: 0.000008  loss: 0.9885 (1.0010)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [ 80/172]  eta: 0:02:26  lr: 0.000008  loss: 1.0067 (1.0044)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [ 90/172]  eta: 0:02:10  lr: 0.000008  loss: 1.0227 (1.0056)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [100/172]  eta: 0:01:54  lr: 0.000008  loss: 0.9956 (1.0058)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [110/172]  eta: 0:01:38  lr: 0.000008  loss: 0.9998 (1.0094)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [120/172]  eta: 0:01:22  lr: 0.000008  loss: 0.9998 (1.0102)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [130/172]  eta: 0:01:06  lr: 0.000008  loss: 0.9976 (1.0091)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [140/172]  eta: 0:00:50  lr: 0.000008  loss: 0.9742 (1.0068)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [150/172]  eta: 0:00:34  lr: 0.000008  loss: 0.9712 (1.0059)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [160/172]  eta: 0:00:19  lr: 0.000008  loss: 0.9869 (1.0062)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:929]  [170/172]  eta: 0:00:03  lr: 0.000008  loss: 1.0185 (1.0068)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:929]  [171/172]  eta: 0:00:01  lr: 0.000008  loss: 1.0185 (1.0070)  time: 1.5804  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:929] Total time: 0:04:33 (1.5891 s / it)\n",
      "Averaged stats: lr: 0.000008  loss: 1.0185 (1.0070)\n",
      "Valid: [epoch:929]  [ 0/14]  eta: 0:00:04  loss: 0.9305 (0.9305)  time: 0.3067  data: 0.2892  max mem: 20571\n",
      "Valid: [epoch:929]  [13/14]  eta: 0:00:00  loss: 0.9506 (0.9633)  time: 0.0398  data: 0.0246  max mem: 20571\n",
      "Valid: [epoch:929] Total time: 0:00:00 (0.0454 s / it)\n",
      "Averaged stats: loss: 0.9506 (0.9633)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_929_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.963%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:930]  [  0/172]  eta: 0:07:46  lr: 0.000008  loss: 1.0029 (1.0029)  time: 2.7148  data: 1.1471  max mem: 20571\n",
      "Train: [epoch:930]  [ 10/172]  eta: 0:04:32  lr: 0.000008  loss: 1.0029 (1.0109)  time: 1.6821  data: 0.1044  max mem: 20571\n",
      "Train: [epoch:930]  [ 20/172]  eta: 0:04:08  lr: 0.000008  loss: 0.9890 (1.0107)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [ 30/172]  eta: 0:03:49  lr: 0.000008  loss: 0.9796 (0.9992)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [ 40/172]  eta: 0:03:32  lr: 0.000008  loss: 0.9746 (0.9969)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [ 50/172]  eta: 0:03:15  lr: 0.000008  loss: 1.0039 (1.0024)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [ 60/172]  eta: 0:02:59  lr: 0.000008  loss: 0.9788 (0.9978)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [ 70/172]  eta: 0:02:42  lr: 0.000008  loss: 0.9554 (0.9996)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [ 80/172]  eta: 0:02:26  lr: 0.000008  loss: 1.0348 (1.0032)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [ 90/172]  eta: 0:02:10  lr: 0.000008  loss: 1.0033 (1.0034)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [100/172]  eta: 0:01:54  lr: 0.000008  loss: 1.0086 (1.0054)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [110/172]  eta: 0:01:38  lr: 0.000008  loss: 0.9820 (1.0021)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [120/172]  eta: 0:01:22  lr: 0.000008  loss: 0.9687 (1.0017)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [130/172]  eta: 0:01:06  lr: 0.000008  loss: 1.0090 (1.0031)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [140/172]  eta: 0:00:50  lr: 0.000008  loss: 1.0245 (1.0050)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [150/172]  eta: 0:00:34  lr: 0.000008  loss: 1.0287 (1.0062)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [160/172]  eta: 0:00:19  lr: 0.000008  loss: 0.9790 (1.0054)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [170/172]  eta: 0:00:03  lr: 0.000008  loss: 1.0042 (1.0059)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930]  [171/172]  eta: 0:00:01  lr: 0.000008  loss: 1.0242 (1.0065)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:930] Total time: 0:04:33 (1.5884 s / it)\n",
      "Averaged stats: lr: 0.000008  loss: 1.0242 (1.0065)\n",
      "Valid: [epoch:930]  [ 0/14]  eta: 0:00:04  loss: 0.9509 (0.9509)  time: 0.3181  data: 0.3032  max mem: 20571\n",
      "Valid: [epoch:930]  [13/14]  eta: 0:00:00  loss: 0.9509 (0.9640)  time: 0.0385  data: 0.0236  max mem: 20571\n",
      "Valid: [epoch:930] Total time: 0:00:00 (0.0480 s / it)\n",
      "Averaged stats: loss: 0.9509 (0.9640)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_930_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.964%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:931]  [  0/172]  eta: 0:08:16  lr: 0.000008  loss: 1.0107 (1.0107)  time: 2.8879  data: 1.2843  max mem: 20571\n",
      "Train: [epoch:931]  [ 10/172]  eta: 0:04:34  lr: 0.000008  loss: 1.0107 (1.0103)  time: 1.6966  data: 0.1169  max mem: 20571\n",
      "Train: [epoch:931]  [ 20/172]  eta: 0:04:09  lr: 0.000008  loss: 1.0012 (1.0080)  time: 1.5788  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:931]  [ 30/172]  eta: 0:03:50  lr: 0.000008  loss: 1.0012 (1.0069)  time: 1.5822  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:931]  [ 40/172]  eta: 0:03:33  lr: 0.000008  loss: 1.0034 (1.0035)  time: 1.5888  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:931]  [ 50/172]  eta: 0:03:16  lr: 0.000008  loss: 1.0073 (1.0038)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [ 60/172]  eta: 0:02:59  lr: 0.000008  loss: 1.0142 (1.0079)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [ 70/172]  eta: 0:02:43  lr: 0.000008  loss: 1.0262 (1.0076)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [ 80/172]  eta: 0:02:27  lr: 0.000008  loss: 0.9992 (1.0077)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [ 90/172]  eta: 0:02:10  lr: 0.000008  loss: 0.9817 (1.0059)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [100/172]  eta: 0:01:54  lr: 0.000008  loss: 0.9938 (1.0039)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [110/172]  eta: 0:01:38  lr: 0.000008  loss: 0.9951 (1.0018)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [120/172]  eta: 0:01:22  lr: 0.000008  loss: 0.9997 (1.0029)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [130/172]  eta: 0:01:06  lr: 0.000008  loss: 1.0162 (1.0038)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [140/172]  eta: 0:00:50  lr: 0.000008  loss: 1.0275 (1.0061)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [150/172]  eta: 0:00:35  lr: 0.000008  loss: 1.0180 (1.0068)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [160/172]  eta: 0:00:19  lr: 0.000008  loss: 1.0017 (1.0065)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [170/172]  eta: 0:00:03  lr: 0.000008  loss: 1.0017 (1.0073)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931]  [171/172]  eta: 0:00:01  lr: 0.000008  loss: 1.0046 (1.0078)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:931] Total time: 0:04:33 (1.5913 s / it)\n",
      "Averaged stats: lr: 0.000008  loss: 1.0046 (1.0078)\n",
      "Valid: [epoch:931]  [ 0/14]  eta: 0:00:04  loss: 1.0121 (1.0121)  time: 0.3068  data: 0.2921  max mem: 20571\n",
      "Valid: [epoch:931]  [13/14]  eta: 0:00:00  loss: 0.9518 (0.9652)  time: 0.0416  data: 0.0267  max mem: 20571\n",
      "Valid: [epoch:931] Total time: 0:00:00 (0.0472 s / it)\n",
      "Averaged stats: loss: 0.9518 (0.9652)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_931_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.965%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:932]  [  0/172]  eta: 0:08:07  lr: 0.000008  loss: 1.0373 (1.0373)  time: 2.8366  data: 1.2701  max mem: 20571\n",
      "Train: [epoch:932]  [ 10/172]  eta: 0:04:34  lr: 0.000008  loss: 1.0247 (0.9906)  time: 1.6966  data: 0.1156  max mem: 20571\n",
      "Train: [epoch:932]  [ 20/172]  eta: 0:04:09  lr: 0.000008  loss: 1.0019 (1.0016)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [ 30/172]  eta: 0:03:50  lr: 0.000008  loss: 1.0019 (1.0058)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [ 40/172]  eta: 0:03:32  lr: 0.000008  loss: 1.0080 (1.0038)  time: 1.5836  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:932]  [ 50/172]  eta: 0:03:16  lr: 0.000008  loss: 1.0196 (1.0132)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [ 60/172]  eta: 0:02:59  lr: 0.000008  loss: 1.0415 (1.0164)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [ 70/172]  eta: 0:02:43  lr: 0.000008  loss: 1.0118 (1.0132)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [ 80/172]  eta: 0:02:26  lr: 0.000008  loss: 1.0322 (1.0183)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [ 90/172]  eta: 0:02:10  lr: 0.000008  loss: 1.0346 (1.0170)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [100/172]  eta: 0:01:54  lr: 0.000008  loss: 1.0079 (1.0161)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:932]  [110/172]  eta: 0:01:38  lr: 0.000008  loss: 0.9866 (1.0132)  time: 1.5831  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:932]  [120/172]  eta: 0:01:22  lr: 0.000008  loss: 0.9923 (1.0120)  time: 1.5801  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:932]  [130/172]  eta: 0:01:06  lr: 0.000008  loss: 1.0131 (1.0134)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [140/172]  eta: 0:00:50  lr: 0.000008  loss: 1.0141 (1.0108)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [150/172]  eta: 0:00:34  lr: 0.000008  loss: 0.9775 (1.0093)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [160/172]  eta: 0:00:19  lr: 0.000008  loss: 0.9796 (1.0100)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [170/172]  eta: 0:00:03  lr: 0.000008  loss: 0.9902 (1.0087)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932]  [171/172]  eta: 0:00:01  lr: 0.000008  loss: 0.9843 (1.0085)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:932] Total time: 0:04:33 (1.5902 s / it)\n",
      "Averaged stats: lr: 0.000008  loss: 0.9843 (1.0085)\n",
      "Valid: [epoch:932]  [ 0/14]  eta: 0:00:05  loss: 1.0525 (1.0525)  time: 0.3958  data: 0.3776  max mem: 20571\n",
      "Valid: [epoch:932]  [13/14]  eta: 0:00:00  loss: 0.9531 (0.9668)  time: 0.0442  data: 0.0289  max mem: 20571\n",
      "Valid: [epoch:932] Total time: 0:00:00 (0.0523 s / it)\n",
      "Averaged stats: loss: 0.9531 (0.9668)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_932_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.967%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:933]  [  0/172]  eta: 0:07:32  lr: 0.000008  loss: 1.0787 (1.0787)  time: 2.6290  data: 1.0553  max mem: 20571\n",
      "Train: [epoch:933]  [ 10/172]  eta: 0:04:31  lr: 0.000008  loss: 0.9906 (1.0007)  time: 1.6755  data: 0.0961  max mem: 20571\n",
      "Train: [epoch:933]  [ 20/172]  eta: 0:04:07  lr: 0.000008  loss: 0.9906 (1.0058)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [ 30/172]  eta: 0:03:49  lr: 0.000008  loss: 1.0041 (1.0106)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [ 40/172]  eta: 0:03:32  lr: 0.000008  loss: 0.9850 (1.0045)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [ 50/172]  eta: 0:03:15  lr: 0.000008  loss: 0.9891 (1.0083)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [ 60/172]  eta: 0:02:59  lr: 0.000008  loss: 1.0124 (1.0093)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [ 70/172]  eta: 0:02:42  lr: 0.000008  loss: 0.9986 (1.0066)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [ 80/172]  eta: 0:02:26  lr: 0.000008  loss: 0.9886 (1.0045)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [ 90/172]  eta: 0:02:10  lr: 0.000008  loss: 0.9976 (1.0035)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [100/172]  eta: 0:01:54  lr: 0.000008  loss: 1.0106 (1.0064)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [110/172]  eta: 0:01:38  lr: 0.000008  loss: 1.0215 (1.0077)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [120/172]  eta: 0:01:22  lr: 0.000008  loss: 1.0187 (1.0088)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [130/172]  eta: 0:01:06  lr: 0.000008  loss: 1.0187 (1.0104)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [140/172]  eta: 0:00:50  lr: 0.000008  loss: 1.0029 (1.0087)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [150/172]  eta: 0:00:34  lr: 0.000008  loss: 0.9718 (1.0083)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [160/172]  eta: 0:00:19  lr: 0.000008  loss: 1.0087 (1.0095)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [170/172]  eta: 0:00:03  lr: 0.000008  loss: 1.0014 (1.0083)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933]  [171/172]  eta: 0:00:01  lr: 0.000008  loss: 1.0014 (1.0084)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:933] Total time: 0:04:33 (1.5898 s / it)\n",
      "Averaged stats: lr: 0.000008  loss: 1.0014 (1.0084)\n",
      "Valid: [epoch:933]  [ 0/14]  eta: 0:00:04  loss: 1.0019 (1.0019)  time: 0.2868  data: 0.2715  max mem: 20571\n",
      "Valid: [epoch:933]  [13/14]  eta: 0:00:00  loss: 0.9529 (0.9666)  time: 0.0375  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:933] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 0.9529 (0.9666)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_933_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.967%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:934]  [  0/172]  eta: 0:07:44  lr: 0.000007  loss: 0.9142 (0.9142)  time: 2.6994  data: 1.1240  max mem: 20571\n",
      "Train: [epoch:934]  [ 10/172]  eta: 0:04:32  lr: 0.000007  loss: 0.9991 (1.0010)  time: 1.6813  data: 0.1023  max mem: 20571\n",
      "Train: [epoch:934]  [ 20/172]  eta: 0:04:08  lr: 0.000007  loss: 1.0072 (1.0166)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [ 30/172]  eta: 0:03:49  lr: 0.000007  loss: 1.0072 (1.0112)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [ 40/172]  eta: 0:03:32  lr: 0.000007  loss: 1.0124 (1.0153)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [ 50/172]  eta: 0:03:15  lr: 0.000007  loss: 1.0129 (1.0149)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [ 60/172]  eta: 0:02:59  lr: 0.000007  loss: 1.0039 (1.0134)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [ 70/172]  eta: 0:02:43  lr: 0.000007  loss: 1.0093 (1.0158)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [ 80/172]  eta: 0:02:27  lr: 0.000007  loss: 1.0147 (1.0156)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [ 90/172]  eta: 0:02:10  lr: 0.000007  loss: 0.9975 (1.0135)  time: 1.5882  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:934]  [100/172]  eta: 0:01:54  lr: 0.000007  loss: 0.9975 (1.0115)  time: 1.5897  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:934]  [110/172]  eta: 0:01:38  lr: 0.000007  loss: 1.0007 (1.0119)  time: 1.5926  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:934]  [120/172]  eta: 0:01:22  lr: 0.000007  loss: 0.9910 (1.0107)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [130/172]  eta: 0:01:06  lr: 0.000007  loss: 0.9910 (1.0084)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [140/172]  eta: 0:00:51  lr: 0.000007  loss: 1.0013 (1.0101)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [150/172]  eta: 0:00:35  lr: 0.000007  loss: 1.0291 (1.0110)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [160/172]  eta: 0:00:19  lr: 0.000007  loss: 1.0213 (1.0123)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934]  [170/172]  eta: 0:00:03  lr: 0.000007  loss: 1.0187 (1.0118)  time: 1.5862  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:934]  [171/172]  eta: 0:00:01  lr: 0.000007  loss: 1.0101 (1.0111)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:934] Total time: 0:04:34 (1.5934 s / it)\n",
      "Averaged stats: lr: 0.000007  loss: 1.0101 (1.0111)\n",
      "Valid: [epoch:934]  [ 0/14]  eta: 0:00:04  loss: 1.0540 (1.0540)  time: 0.2905  data: 0.2737  max mem: 20571\n",
      "Valid: [epoch:934]  [13/14]  eta: 0:00:00  loss: 0.9546 (0.9680)  time: 0.0456  data: 0.0303  max mem: 20571\n",
      "Valid: [epoch:934] Total time: 0:00:00 (0.0523 s / it)\n",
      "Averaged stats: loss: 0.9546 (0.9680)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_934_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.968%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:935]  [  0/172]  eta: 0:07:50  lr: 0.000007  loss: 0.9922 (0.9922)  time: 2.7362  data: 1.1345  max mem: 20571\n",
      "Train: [epoch:935]  [ 10/172]  eta: 0:04:32  lr: 0.000007  loss: 0.9590 (0.9920)  time: 1.6851  data: 0.1033  max mem: 20571\n",
      "Train: [epoch:935]  [ 20/172]  eta: 0:04:08  lr: 0.000007  loss: 0.9877 (1.0107)  time: 1.5819  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:935]  [ 30/172]  eta: 0:03:49  lr: 0.000007  loss: 1.0184 (1.0137)  time: 1.5835  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:935]  [ 40/172]  eta: 0:03:32  lr: 0.000007  loss: 1.0096 (1.0108)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [ 50/172]  eta: 0:03:15  lr: 0.000007  loss: 1.0022 (1.0071)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [ 60/172]  eta: 0:02:59  lr: 0.000007  loss: 1.0088 (1.0097)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [ 70/172]  eta: 0:02:43  lr: 0.000007  loss: 1.0088 (1.0081)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [ 80/172]  eta: 0:02:27  lr: 0.000007  loss: 0.9907 (1.0094)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [ 90/172]  eta: 0:02:10  lr: 0.000007  loss: 1.0052 (1.0087)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [100/172]  eta: 0:01:54  lr: 0.000007  loss: 0.9898 (1.0079)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [110/172]  eta: 0:01:38  lr: 0.000007  loss: 0.9876 (1.0107)  time: 1.5891  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [120/172]  eta: 0:01:22  lr: 0.000007  loss: 1.0171 (1.0120)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [130/172]  eta: 0:01:06  lr: 0.000007  loss: 1.0171 (1.0119)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [140/172]  eta: 0:00:50  lr: 0.000007  loss: 0.9926 (1.0116)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [150/172]  eta: 0:00:35  lr: 0.000007  loss: 1.0149 (1.0134)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [160/172]  eta: 0:00:19  lr: 0.000007  loss: 1.0013 (1.0113)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [170/172]  eta: 0:00:03  lr: 0.000007  loss: 1.0013 (1.0121)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935]  [171/172]  eta: 0:00:01  lr: 0.000007  loss: 1.0024 (1.0121)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:935] Total time: 0:04:33 (1.5930 s / it)\n",
      "Averaged stats: lr: 0.000007  loss: 1.0024 (1.0121)\n",
      "Valid: [epoch:935]  [ 0/14]  eta: 0:00:05  loss: 1.0153 (1.0153)  time: 0.3886  data: 0.3734  max mem: 20571\n",
      "Valid: [epoch:935]  [13/14]  eta: 0:00:00  loss: 0.9550 (0.9685)  time: 0.0492  data: 0.0343  max mem: 20571\n",
      "Valid: [epoch:935] Total time: 0:00:00 (0.0573 s / it)\n",
      "Averaged stats: loss: 0.9550 (0.9685)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_935_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.968%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:936]  [  0/172]  eta: 0:08:23  lr: 0.000007  loss: 1.0572 (1.0572)  time: 2.9244  data: 1.3505  max mem: 20571\n",
      "Train: [epoch:936]  [ 10/172]  eta: 0:04:36  lr: 0.000007  loss: 1.0125 (1.0245)  time: 1.7063  data: 0.1229  max mem: 20571\n",
      "Train: [epoch:936]  [ 20/172]  eta: 0:04:10  lr: 0.000007  loss: 1.0031 (1.0192)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [ 30/172]  eta: 0:03:51  lr: 0.000007  loss: 1.0021 (1.0100)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [ 40/172]  eta: 0:03:33  lr: 0.000007  loss: 1.0065 (1.0108)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [ 50/172]  eta: 0:03:16  lr: 0.000007  loss: 1.0078 (1.0097)  time: 1.5838  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:936]  [ 60/172]  eta: 0:02:59  lr: 0.000007  loss: 0.9992 (1.0105)  time: 1.5846  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:936]  [ 70/172]  eta: 0:02:43  lr: 0.000007  loss: 1.0104 (1.0141)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [ 80/172]  eta: 0:02:27  lr: 0.000007  loss: 1.0082 (1.0118)  time: 1.5823  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [ 90/172]  eta: 0:02:11  lr: 0.000007  loss: 0.9753 (1.0088)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [100/172]  eta: 0:01:55  lr: 0.000007  loss: 1.0083 (1.0102)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [110/172]  eta: 0:01:39  lr: 0.000007  loss: 1.0362 (1.0111)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [120/172]  eta: 0:01:23  lr: 0.000007  loss: 1.0178 (1.0110)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [130/172]  eta: 0:01:07  lr: 0.000007  loss: 0.9889 (1.0087)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [140/172]  eta: 0:00:51  lr: 0.000007  loss: 0.9778 (1.0085)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [150/172]  eta: 0:00:35  lr: 0.000007  loss: 1.0289 (1.0111)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [160/172]  eta: 0:00:19  lr: 0.000007  loss: 1.0289 (1.0127)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [170/172]  eta: 0:00:03  lr: 0.000007  loss: 1.0415 (1.0140)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936]  [171/172]  eta: 0:00:01  lr: 0.000007  loss: 1.0247 (1.0140)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:936] Total time: 0:04:34 (1.5944 s / it)\n",
      "Averaged stats: lr: 0.000007  loss: 1.0247 (1.0140)\n",
      "Valid: [epoch:936]  [ 0/14]  eta: 0:00:06  loss: 1.0083 (1.0083)  time: 0.4385  data: 0.4159  max mem: 20571\n",
      "Valid: [epoch:936]  [13/14]  eta: 0:00:00  loss: 0.9559 (0.9695)  time: 0.0460  data: 0.0303  max mem: 20571\n",
      "Valid: [epoch:936] Total time: 0:00:00 (0.0529 s / it)\n",
      "Averaged stats: loss: 0.9559 (0.9695)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_936_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.970%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:937]  [  0/172]  eta: 0:08:02  lr: 0.000007  loss: 0.9843 (0.9843)  time: 2.8076  data: 1.2330  max mem: 20571\n",
      "Train: [epoch:937]  [ 10/172]  eta: 0:04:34  lr: 0.000007  loss: 0.9987 (1.0193)  time: 1.6932  data: 0.1122  max mem: 20571\n",
      "Train: [epoch:937]  [ 20/172]  eta: 0:04:09  lr: 0.000007  loss: 0.9966 (1.0159)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [ 30/172]  eta: 0:03:50  lr: 0.000007  loss: 0.9876 (1.0112)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [ 40/172]  eta: 0:03:32  lr: 0.000007  loss: 0.9826 (1.0044)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [ 50/172]  eta: 0:03:16  lr: 0.000007  loss: 0.9979 (1.0080)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [ 60/172]  eta: 0:02:59  lr: 0.000007  loss: 1.0180 (1.0075)  time: 1.5865  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:937]  [ 70/172]  eta: 0:02:43  lr: 0.000007  loss: 1.0182 (1.0130)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [ 80/172]  eta: 0:02:27  lr: 0.000007  loss: 1.0061 (1.0127)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [ 90/172]  eta: 0:02:11  lr: 0.000007  loss: 1.0061 (1.0125)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [100/172]  eta: 0:01:54  lr: 0.000007  loss: 1.0226 (1.0181)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [110/172]  eta: 0:01:38  lr: 0.000007  loss: 1.0051 (1.0154)  time: 1.5873  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:937]  [120/172]  eta: 0:01:22  lr: 0.000007  loss: 0.9914 (1.0168)  time: 1.5842  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:937]  [130/172]  eta: 0:01:06  lr: 0.000007  loss: 0.9909 (1.0157)  time: 1.5848  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:937]  [140/172]  eta: 0:00:50  lr: 0.000007  loss: 0.9769 (1.0135)  time: 1.5863  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:937]  [150/172]  eta: 0:00:35  lr: 0.000007  loss: 1.0244 (1.0169)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [160/172]  eta: 0:00:19  lr: 0.000007  loss: 1.0279 (1.0162)  time: 1.5890  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [170/172]  eta: 0:00:03  lr: 0.000007  loss: 0.9814 (1.0147)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937]  [171/172]  eta: 0:00:01  lr: 0.000007  loss: 0.9814 (1.0146)  time: 1.5891  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:937] Total time: 0:04:34 (1.5935 s / it)\n",
      "Averaged stats: lr: 0.000007  loss: 0.9814 (1.0146)\n",
      "Valid: [epoch:937]  [ 0/14]  eta: 0:00:07  loss: 0.8652 (0.8652)  time: 0.5241  data: 0.5073  max mem: 20571\n",
      "Valid: [epoch:937]  [13/14]  eta: 0:00:00  loss: 0.9576 (0.9712)  time: 0.0521  data: 0.0367  max mem: 20571\n",
      "Valid: [epoch:937] Total time: 0:00:00 (0.0570 s / it)\n",
      "Averaged stats: loss: 0.9576 (0.9712)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_937_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.971%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:938]  [  0/172]  eta: 0:08:01  lr: 0.000007  loss: 0.9809 (0.9809)  time: 2.7970  data: 1.2055  max mem: 20571\n",
      "Train: [epoch:938]  [ 10/172]  eta: 0:04:34  lr: 0.000007  loss: 1.0145 (1.0321)  time: 1.6965  data: 0.1097  max mem: 20571\n",
      "Train: [epoch:938]  [ 20/172]  eta: 0:04:10  lr: 0.000007  loss: 0.9898 (1.0274)  time: 1.5875  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:938]  [ 30/172]  eta: 0:03:50  lr: 0.000007  loss: 1.0158 (1.0193)  time: 1.5877  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:938]  [ 40/172]  eta: 0:03:33  lr: 0.000007  loss: 0.9967 (1.0046)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [ 50/172]  eta: 0:03:16  lr: 0.000007  loss: 0.9913 (1.0047)  time: 1.5859  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:938]  [ 60/172]  eta: 0:02:59  lr: 0.000007  loss: 1.0101 (1.0078)  time: 1.5866  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:938]  [ 70/172]  eta: 0:02:43  lr: 0.000007  loss: 1.0059 (1.0076)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [ 80/172]  eta: 0:02:27  lr: 0.000007  loss: 0.9854 (1.0041)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [ 90/172]  eta: 0:02:11  lr: 0.000007  loss: 0.9952 (1.0041)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [100/172]  eta: 0:01:55  lr: 0.000007  loss: 1.0081 (1.0073)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [110/172]  eta: 0:01:39  lr: 0.000007  loss: 0.9994 (1.0087)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [120/172]  eta: 0:01:22  lr: 0.000007  loss: 1.0426 (1.0125)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [130/172]  eta: 0:01:07  lr: 0.000007  loss: 1.0217 (1.0119)  time: 1.5863  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:938]  [140/172]  eta: 0:00:51  lr: 0.000007  loss: 1.0104 (1.0125)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [150/172]  eta: 0:00:35  lr: 0.000007  loss: 1.0249 (1.0134)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [160/172]  eta: 0:00:19  lr: 0.000007  loss: 1.0235 (1.0136)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [170/172]  eta: 0:00:03  lr: 0.000007  loss: 1.0303 (1.0148)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938]  [171/172]  eta: 0:00:01  lr: 0.000007  loss: 1.0303 (1.0146)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:938] Total time: 0:04:34 (1.5937 s / it)\n",
      "Averaged stats: lr: 0.000007  loss: 1.0303 (1.0146)\n",
      "Valid: [epoch:938]  [ 0/14]  eta: 0:00:05  loss: 0.9111 (0.9111)  time: 0.3647  data: 0.3450  max mem: 20571\n",
      "Valid: [epoch:938]  [13/14]  eta: 0:00:00  loss: 0.9581 (0.9719)  time: 0.0413  data: 0.0259  max mem: 20571\n",
      "Valid: [epoch:938] Total time: 0:00:00 (0.0504 s / it)\n",
      "Averaged stats: loss: 0.9581 (0.9719)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_938_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.972%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:939]  [  0/172]  eta: 0:08:04  lr: 0.000007  loss: 1.0232 (1.0232)  time: 2.8146  data: 1.2346  max mem: 20571\n",
      "Train: [epoch:939]  [ 10/172]  eta: 0:04:34  lr: 0.000007  loss: 1.0291 (1.0221)  time: 1.6950  data: 0.1123  max mem: 20571\n",
      "Train: [epoch:939]  [ 20/172]  eta: 0:04:09  lr: 0.000007  loss: 1.0291 (1.0189)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [ 30/172]  eta: 0:03:50  lr: 0.000007  loss: 1.0105 (1.0121)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [ 40/172]  eta: 0:03:33  lr: 0.000007  loss: 0.9887 (1.0128)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [ 50/172]  eta: 0:03:16  lr: 0.000007  loss: 1.0256 (1.0160)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [ 60/172]  eta: 0:02:59  lr: 0.000007  loss: 1.0256 (1.0156)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [ 70/172]  eta: 0:02:43  lr: 0.000007  loss: 1.0170 (1.0197)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [ 80/172]  eta: 0:02:27  lr: 0.000007  loss: 1.0093 (1.0185)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [ 90/172]  eta: 0:02:11  lr: 0.000007  loss: 1.0218 (1.0203)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [100/172]  eta: 0:01:55  lr: 0.000007  loss: 1.0246 (1.0203)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [110/172]  eta: 0:01:38  lr: 0.000007  loss: 1.0233 (1.0200)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [120/172]  eta: 0:01:22  lr: 0.000007  loss: 1.0182 (1.0187)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [130/172]  eta: 0:01:06  lr: 0.000007  loss: 1.0112 (1.0179)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [140/172]  eta: 0:00:51  lr: 0.000007  loss: 1.0007 (1.0167)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [150/172]  eta: 0:00:35  lr: 0.000007  loss: 1.0007 (1.0161)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [160/172]  eta: 0:00:19  lr: 0.000007  loss: 1.0081 (1.0155)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [170/172]  eta: 0:00:03  lr: 0.000007  loss: 1.0215 (1.0153)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939]  [171/172]  eta: 0:00:01  lr: 0.000007  loss: 1.0241 (1.0155)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:939] Total time: 0:04:33 (1.5926 s / it)\n",
      "Averaged stats: lr: 0.000007  loss: 1.0241 (1.0155)\n",
      "Valid: [epoch:939]  [ 0/14]  eta: 0:00:05  loss: 0.9580 (0.9580)  time: 0.3587  data: 0.3401  max mem: 20571\n",
      "Valid: [epoch:939]  [13/14]  eta: 0:00:00  loss: 0.9580 (0.9725)  time: 0.0398  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:939] Total time: 0:00:00 (0.0451 s / it)\n",
      "Averaged stats: loss: 0.9580 (0.9725)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_939_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.973%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:940]  [  0/172]  eta: 0:07:43  lr: 0.000007  loss: 0.9912 (0.9912)  time: 2.6974  data: 1.1273  max mem: 20571\n",
      "Train: [epoch:940]  [ 10/172]  eta: 0:04:32  lr: 0.000007  loss: 0.9819 (1.0122)  time: 1.6819  data: 0.1026  max mem: 20571\n",
      "Train: [epoch:940]  [ 20/172]  eta: 0:04:08  lr: 0.000007  loss: 1.0239 (1.0256)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [ 30/172]  eta: 0:03:49  lr: 0.000007  loss: 1.0149 (1.0174)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [ 40/172]  eta: 0:03:32  lr: 0.000007  loss: 0.9775 (1.0123)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [ 50/172]  eta: 0:03:15  lr: 0.000007  loss: 1.0041 (1.0153)  time: 1.5807  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:940]  [ 60/172]  eta: 0:02:59  lr: 0.000007  loss: 1.0266 (1.0163)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [ 70/172]  eta: 0:02:42  lr: 0.000007  loss: 1.0133 (1.0125)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [ 80/172]  eta: 0:02:26  lr: 0.000007  loss: 1.0013 (1.0163)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [ 90/172]  eta: 0:02:10  lr: 0.000007  loss: 0.9770 (1.0116)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [100/172]  eta: 0:01:54  lr: 0.000007  loss: 0.9770 (1.0133)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [110/172]  eta: 0:01:38  lr: 0.000007  loss: 1.0075 (1.0162)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [120/172]  eta: 0:01:22  lr: 0.000007  loss: 1.0116 (1.0174)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [130/172]  eta: 0:01:06  lr: 0.000007  loss: 1.0126 (1.0167)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [140/172]  eta: 0:00:50  lr: 0.000007  loss: 0.9841 (1.0152)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [150/172]  eta: 0:00:34  lr: 0.000007  loss: 0.9841 (1.0156)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [160/172]  eta: 0:00:19  lr: 0.000007  loss: 1.0194 (1.0149)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [170/172]  eta: 0:00:03  lr: 0.000007  loss: 1.0221 (1.0153)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940]  [171/172]  eta: 0:00:01  lr: 0.000007  loss: 1.0221 (1.0160)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:940] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000007  loss: 1.0221 (1.0160)\n",
      "Valid: [epoch:940]  [ 0/14]  eta: 0:00:03  loss: 1.0142 (1.0142)  time: 0.2798  data: 0.2644  max mem: 20571\n",
      "Valid: [epoch:940]  [13/14]  eta: 0:00:00  loss: 0.9609 (0.9738)  time: 0.0388  data: 0.0238  max mem: 20571\n",
      "Valid: [epoch:940] Total time: 0:00:00 (0.0441 s / it)\n",
      "Averaged stats: loss: 0.9609 (0.9738)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_940_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.974%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:941]  [  0/172]  eta: 0:08:21  lr: 0.000007  loss: 0.9801 (0.9801)  time: 2.9170  data: 1.3482  max mem: 20571\n",
      "Train: [epoch:941]  [ 10/172]  eta: 0:04:34  lr: 0.000007  loss: 0.9801 (0.9920)  time: 1.6957  data: 0.1227  max mem: 20571\n",
      "Train: [epoch:941]  [ 20/172]  eta: 0:04:09  lr: 0.000007  loss: 0.9842 (1.0035)  time: 1.5749  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [ 30/172]  eta: 0:03:50  lr: 0.000007  loss: 0.9981 (1.0038)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [ 40/172]  eta: 0:03:32  lr: 0.000007  loss: 0.9926 (1.0006)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [ 50/172]  eta: 0:03:15  lr: 0.000007  loss: 1.0055 (1.0049)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [ 60/172]  eta: 0:02:59  lr: 0.000007  loss: 1.0129 (1.0105)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [ 70/172]  eta: 0:02:43  lr: 0.000007  loss: 0.9983 (1.0082)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [ 80/172]  eta: 0:02:26  lr: 0.000007  loss: 0.9785 (1.0092)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [ 90/172]  eta: 0:02:10  lr: 0.000007  loss: 0.9793 (1.0093)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [100/172]  eta: 0:01:54  lr: 0.000007  loss: 1.0473 (1.0154)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [110/172]  eta: 0:01:38  lr: 0.000007  loss: 1.0601 (1.0179)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [120/172]  eta: 0:01:22  lr: 0.000007  loss: 1.0288 (1.0170)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [130/172]  eta: 0:01:06  lr: 0.000007  loss: 1.0227 (1.0167)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [140/172]  eta: 0:00:50  lr: 0.000007  loss: 1.0314 (1.0164)  time: 1.5769  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [150/172]  eta: 0:00:34  lr: 0.000007  loss: 1.0350 (1.0191)  time: 1.5761  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [160/172]  eta: 0:00:19  lr: 0.000007  loss: 1.0293 (1.0190)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [170/172]  eta: 0:00:03  lr: 0.000007  loss: 1.0056 (1.0170)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941]  [171/172]  eta: 0:00:01  lr: 0.000007  loss: 1.0056 (1.0180)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:941] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000007  loss: 1.0056 (1.0180)\n",
      "Valid: [epoch:941]  [ 0/14]  eta: 0:00:05  loss: 1.0221 (1.0221)  time: 0.3657  data: 0.3508  max mem: 20571\n",
      "Valid: [epoch:941]  [13/14]  eta: 0:00:00  loss: 0.9616 (0.9747)  time: 0.0423  data: 0.0272  max mem: 20571\n",
      "Valid: [epoch:941] Total time: 0:00:00 (0.0505 s / it)\n",
      "Averaged stats: loss: 0.9616 (0.9747)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_941_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.975%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:942]  [  0/172]  eta: 0:08:20  lr: 0.000007  loss: 1.0443 (1.0443)  time: 2.9107  data: 1.3445  max mem: 20571\n",
      "Train: [epoch:942]  [ 10/172]  eta: 0:04:35  lr: 0.000007  loss: 1.0384 (1.0302)  time: 1.6994  data: 0.1224  max mem: 20571\n",
      "Train: [epoch:942]  [ 20/172]  eta: 0:04:09  lr: 0.000007  loss: 1.0229 (1.0277)  time: 1.5785  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:942]  [ 30/172]  eta: 0:03:50  lr: 0.000007  loss: 0.9989 (1.0183)  time: 1.5803  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:942]  [ 40/172]  eta: 0:03:32  lr: 0.000007  loss: 0.9673 (1.0075)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [ 50/172]  eta: 0:03:15  lr: 0.000007  loss: 0.9673 (1.0045)  time: 1.5792  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [ 60/172]  eta: 0:02:59  lr: 0.000007  loss: 1.0165 (1.0083)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [ 70/172]  eta: 0:02:43  lr: 0.000007  loss: 1.0165 (1.0090)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [ 80/172]  eta: 0:02:26  lr: 0.000007  loss: 1.0355 (1.0147)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [ 90/172]  eta: 0:02:10  lr: 0.000007  loss: 1.0370 (1.0144)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [100/172]  eta: 0:01:54  lr: 0.000007  loss: 1.0096 (1.0130)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [110/172]  eta: 0:01:38  lr: 0.000007  loss: 1.0168 (1.0166)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [120/172]  eta: 0:01:22  lr: 0.000007  loss: 1.0168 (1.0170)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [130/172]  eta: 0:01:06  lr: 0.000007  loss: 1.0090 (1.0161)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [140/172]  eta: 0:00:50  lr: 0.000007  loss: 1.0256 (1.0163)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [150/172]  eta: 0:00:34  lr: 0.000007  loss: 1.0509 (1.0194)  time: 1.5773  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [160/172]  eta: 0:00:19  lr: 0.000007  loss: 1.0013 (1.0185)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [170/172]  eta: 0:00:03  lr: 0.000007  loss: 0.9930 (1.0181)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942]  [171/172]  eta: 0:00:01  lr: 0.000007  loss: 0.9930 (1.0181)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:942] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000007  loss: 0.9930 (1.0181)\n",
      "Valid: [epoch:942]  [ 0/14]  eta: 0:00:05  loss: 1.0254 (1.0254)  time: 0.3843  data: 0.3662  max mem: 20571\n",
      "Valid: [epoch:942]  [13/14]  eta: 0:00:00  loss: 0.9615 (0.9754)  time: 0.0421  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:942] Total time: 0:00:00 (0.0475 s / it)\n",
      "Averaged stats: loss: 0.9615 (0.9754)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_942_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.975%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:943]  [  0/172]  eta: 0:07:49  lr: 0.000006  loss: 1.0057 (1.0057)  time: 2.7321  data: 1.1619  max mem: 20571\n",
      "Train: [epoch:943]  [ 10/172]  eta: 0:04:32  lr: 0.000006  loss: 1.0228 (1.0146)  time: 1.6791  data: 0.1058  max mem: 20571\n",
      "Train: [epoch:943]  [ 20/172]  eta: 0:04:07  lr: 0.000006  loss: 1.0228 (1.0268)  time: 1.5752  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:943]  [ 30/172]  eta: 0:03:49  lr: 0.000006  loss: 1.0162 (1.0255)  time: 1.5781  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:943]  [ 40/172]  eta: 0:03:32  lr: 0.000006  loss: 1.0029 (1.0226)  time: 1.5807  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:943]  [ 50/172]  eta: 0:03:15  lr: 0.000006  loss: 1.0029 (1.0186)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [ 60/172]  eta: 0:02:58  lr: 0.000006  loss: 1.0040 (1.0180)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [ 70/172]  eta: 0:02:42  lr: 0.000006  loss: 1.0235 (1.0225)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [ 80/172]  eta: 0:02:26  lr: 0.000006  loss: 1.0235 (1.0208)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [ 90/172]  eta: 0:02:10  lr: 0.000006  loss: 1.0000 (1.0196)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [100/172]  eta: 0:01:54  lr: 0.000006  loss: 1.0405 (1.0233)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [110/172]  eta: 0:01:38  lr: 0.000006  loss: 1.0561 (1.0229)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [120/172]  eta: 0:01:22  lr: 0.000006  loss: 1.0218 (1.0230)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [130/172]  eta: 0:01:06  lr: 0.000006  loss: 0.9968 (1.0200)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [140/172]  eta: 0:00:50  lr: 0.000006  loss: 0.9782 (1.0185)  time: 1.5777  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [150/172]  eta: 0:00:34  lr: 0.000006  loss: 1.0013 (1.0195)  time: 1.5771  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [160/172]  eta: 0:00:19  lr: 0.000006  loss: 1.0255 (1.0193)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [170/172]  eta: 0:00:03  lr: 0.000006  loss: 0.9948 (1.0187)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943]  [171/172]  eta: 0:00:01  lr: 0.000006  loss: 0.9961 (1.0186)  time: 1.5800  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:943] Total time: 0:04:32 (1.5863 s / it)\n",
      "Averaged stats: lr: 0.000006  loss: 0.9961 (1.0186)\n",
      "Valid: [epoch:943]  [ 0/14]  eta: 0:00:05  loss: 1.0166 (1.0166)  time: 0.3874  data: 0.3726  max mem: 20571\n",
      "Valid: [epoch:943]  [13/14]  eta: 0:00:00  loss: 0.9632 (0.9769)  time: 0.0460  data: 0.0311  max mem: 20571\n",
      "Valid: [epoch:943] Total time: 0:00:00 (0.0534 s / it)\n",
      "Averaged stats: loss: 0.9632 (0.9769)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_943_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.977%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:944]  [  0/172]  eta: 0:08:15  lr: 0.000006  loss: 1.0934 (1.0934)  time: 2.8786  data: 1.3121  max mem: 20571\n",
      "Train: [epoch:944]  [ 10/172]  eta: 0:04:34  lr: 0.000006  loss: 1.0166 (1.0193)  time: 1.6941  data: 0.1194  max mem: 20571\n",
      "Train: [epoch:944]  [ 20/172]  eta: 0:04:09  lr: 0.000006  loss: 0.9990 (1.0148)  time: 1.5768  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:944]  [ 30/172]  eta: 0:03:49  lr: 0.000006  loss: 1.0015 (1.0161)  time: 1.5783  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:944]  [ 40/172]  eta: 0:03:32  lr: 0.000006  loss: 1.0256 (1.0208)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [ 50/172]  eta: 0:03:15  lr: 0.000006  loss: 1.0256 (1.0256)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [ 60/172]  eta: 0:02:59  lr: 0.000006  loss: 1.0321 (1.0270)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [ 70/172]  eta: 0:02:42  lr: 0.000006  loss: 1.0116 (1.0268)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [ 80/172]  eta: 0:02:26  lr: 0.000006  loss: 1.0116 (1.0268)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [ 90/172]  eta: 0:02:10  lr: 0.000006  loss: 0.9760 (1.0206)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [100/172]  eta: 0:01:54  lr: 0.000006  loss: 0.9894 (1.0203)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [110/172]  eta: 0:01:38  lr: 0.000006  loss: 1.0143 (1.0210)  time: 1.5788  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [120/172]  eta: 0:01:22  lr: 0.000006  loss: 1.0353 (1.0211)  time: 1.5776  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [130/172]  eta: 0:01:06  lr: 0.000006  loss: 1.0144 (1.0210)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [140/172]  eta: 0:00:50  lr: 0.000006  loss: 1.0035 (1.0194)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [150/172]  eta: 0:00:34  lr: 0.000006  loss: 1.0076 (1.0201)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [160/172]  eta: 0:00:19  lr: 0.000006  loss: 1.0226 (1.0200)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [170/172]  eta: 0:00:03  lr: 0.000006  loss: 1.0170 (1.0204)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944]  [171/172]  eta: 0:00:01  lr: 0.000006  loss: 1.0170 (1.0205)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:944] Total time: 0:04:32 (1.5869 s / it)\n",
      "Averaged stats: lr: 0.000006  loss: 1.0170 (1.0205)\n",
      "Valid: [epoch:944]  [ 0/14]  eta: 0:00:05  loss: 1.0245 (1.0245)  time: 0.4131  data: 0.3965  max mem: 20571\n",
      "Valid: [epoch:944]  [13/14]  eta: 0:00:00  loss: 0.9647 (0.9776)  time: 0.0440  data: 0.0289  max mem: 20571\n",
      "Valid: [epoch:944] Total time: 0:00:00 (0.0514 s / it)\n",
      "Averaged stats: loss: 0.9647 (0.9776)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_944_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.978%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:945]  [  0/172]  eta: 0:08:32  lr: 0.000006  loss: 0.9547 (0.9547)  time: 2.9795  data: 1.4100  max mem: 20571\n",
      "Train: [epoch:945]  [ 10/172]  eta: 0:04:35  lr: 0.000006  loss: 1.0252 (1.0203)  time: 1.7024  data: 0.1283  max mem: 20571\n",
      "Train: [epoch:945]  [ 20/172]  eta: 0:04:09  lr: 0.000006  loss: 1.0301 (1.0332)  time: 1.5768  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [ 30/172]  eta: 0:03:50  lr: 0.000006  loss: 1.0147 (1.0220)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [ 40/172]  eta: 0:03:32  lr: 0.000006  loss: 0.9888 (1.0193)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [ 50/172]  eta: 0:03:15  lr: 0.000006  loss: 0.9982 (1.0164)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [ 60/172]  eta: 0:02:59  lr: 0.000006  loss: 1.0020 (1.0180)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [ 70/172]  eta: 0:02:42  lr: 0.000006  loss: 1.0086 (1.0154)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [ 80/172]  eta: 0:02:26  lr: 0.000006  loss: 1.0187 (1.0206)  time: 1.5780  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [ 90/172]  eta: 0:02:10  lr: 0.000006  loss: 1.0306 (1.0211)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [100/172]  eta: 0:01:54  lr: 0.000006  loss: 1.0211 (1.0209)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [110/172]  eta: 0:01:38  lr: 0.000006  loss: 1.0181 (1.0209)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [120/172]  eta: 0:01:22  lr: 0.000006  loss: 1.0399 (1.0243)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945]  [130/172]  eta: 0:01:06  lr: 0.000006  loss: 1.0291 (1.0228)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:945]  [140/172]  eta: 0:00:50  lr: 0.000006  loss: 0.9961 (1.0199)  time: 1.5791  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:945]  [150/172]  eta: 0:00:34  lr: 0.000006  loss: 0.9961 (1.0188)  time: 1.5792  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:945]  [160/172]  eta: 0:00:19  lr: 0.000006  loss: 1.0154 (1.0223)  time: 1.5813  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:945]  [170/172]  eta: 0:00:03  lr: 0.000006  loss: 1.0186 (1.0216)  time: 1.5804  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:945]  [171/172]  eta: 0:00:01  lr: 0.000006  loss: 1.0154 (1.0216)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:945] Total time: 0:04:33 (1.5879 s / it)\n",
      "Averaged stats: lr: 0.000006  loss: 1.0154 (1.0216)\n",
      "Valid: [epoch:945]  [ 0/14]  eta: 0:00:05  loss: 0.9603 (0.9603)  time: 0.3679  data: 0.3510  max mem: 20571\n",
      "Valid: [epoch:945]  [13/14]  eta: 0:00:00  loss: 0.9646 (0.9780)  time: 0.0520  data: 0.0368  max mem: 20571\n",
      "Valid: [epoch:945] Total time: 0:00:00 (0.0598 s / it)\n",
      "Averaged stats: loss: 0.9646 (0.9780)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_945_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.978%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:946]  [  0/172]  eta: 0:08:18  lr: 0.000006  loss: 1.1698 (1.1698)  time: 2.9001  data: 1.3109  max mem: 20571\n",
      "Train: [epoch:946]  [ 10/172]  eta: 0:04:35  lr: 0.000006  loss: 1.0034 (1.0184)  time: 1.6981  data: 0.1193  max mem: 20571\n",
      "Train: [epoch:946]  [ 20/172]  eta: 0:04:09  lr: 0.000006  loss: 1.0114 (1.0332)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [ 30/172]  eta: 0:03:50  lr: 0.000006  loss: 1.0127 (1.0243)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [ 40/172]  eta: 0:03:32  lr: 0.000006  loss: 1.0060 (1.0176)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [ 50/172]  eta: 0:03:15  lr: 0.000006  loss: 0.9946 (1.0229)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [ 60/172]  eta: 0:02:59  lr: 0.000006  loss: 0.9950 (1.0196)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [ 70/172]  eta: 0:02:42  lr: 0.000006  loss: 0.9975 (1.0168)  time: 1.5775  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [ 80/172]  eta: 0:02:26  lr: 0.000006  loss: 1.0031 (1.0155)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [ 90/172]  eta: 0:02:10  lr: 0.000006  loss: 1.0100 (1.0164)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [100/172]  eta: 0:01:54  lr: 0.000006  loss: 1.0253 (1.0191)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [110/172]  eta: 0:01:38  lr: 0.000006  loss: 1.0268 (1.0200)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [120/172]  eta: 0:01:22  lr: 0.000006  loss: 1.0273 (1.0207)  time: 1.5781  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [130/172]  eta: 0:01:06  lr: 0.000006  loss: 1.0426 (1.0224)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [140/172]  eta: 0:00:50  lr: 0.000006  loss: 1.0015 (1.0209)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [150/172]  eta: 0:00:34  lr: 0.000006  loss: 1.0015 (1.0204)  time: 1.5765  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [160/172]  eta: 0:00:19  lr: 0.000006  loss: 1.0420 (1.0239)  time: 1.5784  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [170/172]  eta: 0:00:03  lr: 0.000006  loss: 1.0237 (1.0223)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946]  [171/172]  eta: 0:00:01  lr: 0.000006  loss: 1.0237 (1.0226)  time: 1.5783  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:946] Total time: 0:04:32 (1.5867 s / it)\n",
      "Averaged stats: lr: 0.000006  loss: 1.0237 (1.0226)\n",
      "Valid: [epoch:946]  [ 0/14]  eta: 0:00:05  loss: 1.0666 (1.0666)  time: 0.3803  data: 0.3644  max mem: 20571\n",
      "Valid: [epoch:946]  [13/14]  eta: 0:00:00  loss: 0.9645 (0.9790)  time: 0.0441  data: 0.0291  max mem: 20571\n",
      "Valid: [epoch:946] Total time: 0:00:00 (0.0490 s / it)\n",
      "Averaged stats: loss: 0.9645 (0.9790)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_946_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.979%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:947]  [  0/172]  eta: 0:07:55  lr: 0.000006  loss: 1.0300 (1.0300)  time: 2.7661  data: 1.1939  max mem: 20571\n",
      "Train: [epoch:947]  [ 10/172]  eta: 0:04:32  lr: 0.000006  loss: 1.0300 (1.0373)  time: 1.6820  data: 0.1086  max mem: 20571\n",
      "Train: [epoch:947]  [ 20/172]  eta: 0:04:08  lr: 0.000006  loss: 1.0098 (1.0257)  time: 1.5758  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [ 30/172]  eta: 0:03:49  lr: 0.000006  loss: 1.0131 (1.0323)  time: 1.5790  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [ 40/172]  eta: 0:03:32  lr: 0.000006  loss: 1.0195 (1.0267)  time: 1.5815  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [ 50/172]  eta: 0:03:15  lr: 0.000006  loss: 1.0143 (1.0266)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [ 60/172]  eta: 0:02:59  lr: 0.000006  loss: 1.0143 (1.0247)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [ 70/172]  eta: 0:02:42  lr: 0.000006  loss: 1.0186 (1.0259)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [ 80/172]  eta: 0:02:26  lr: 0.000006  loss: 1.0171 (1.0223)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [ 90/172]  eta: 0:02:10  lr: 0.000006  loss: 1.0049 (1.0203)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [100/172]  eta: 0:01:54  lr: 0.000006  loss: 1.0049 (1.0198)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [110/172]  eta: 0:01:38  lr: 0.000006  loss: 1.0098 (1.0224)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [120/172]  eta: 0:01:22  lr: 0.000006  loss: 1.0297 (1.0234)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [130/172]  eta: 0:01:06  lr: 0.000006  loss: 1.0027 (1.0230)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [140/172]  eta: 0:00:50  lr: 0.000006  loss: 1.0027 (1.0227)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [150/172]  eta: 0:00:34  lr: 0.000006  loss: 1.0022 (1.0225)  time: 1.5794  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:947]  [160/172]  eta: 0:00:19  lr: 0.000006  loss: 1.0134 (1.0225)  time: 1.5807  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [170/172]  eta: 0:00:03  lr: 0.000006  loss: 1.0319 (1.0239)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947]  [171/172]  eta: 0:00:01  lr: 0.000006  loss: 1.0319 (1.0241)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:947] Total time: 0:04:33 (1.5875 s / it)\n",
      "Averaged stats: lr: 0.000006  loss: 1.0319 (1.0241)\n",
      "Valid: [epoch:947]  [ 0/14]  eta: 0:00:06  loss: 1.0175 (1.0175)  time: 0.4725  data: 0.4573  max mem: 20571\n",
      "Valid: [epoch:947]  [13/14]  eta: 0:00:00  loss: 0.9665 (0.9806)  time: 0.0485  data: 0.0333  max mem: 20571\n",
      "Valid: [epoch:947] Total time: 0:00:00 (0.0561 s / it)\n",
      "Averaged stats: loss: 0.9665 (0.9806)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_947_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.981%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:948]  [  0/172]  eta: 0:08:00  lr: 0.000006  loss: 1.0153 (1.0153)  time: 2.7910  data: 1.2236  max mem: 20571\n",
      "Train: [epoch:948]  [ 10/172]  eta: 0:04:33  lr: 0.000006  loss: 1.0067 (1.0203)  time: 1.6906  data: 0.1113  max mem: 20571\n",
      "Train: [epoch:948]  [ 20/172]  eta: 0:04:08  lr: 0.000006  loss: 1.0122 (1.0272)  time: 1.5799  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [ 30/172]  eta: 0:03:49  lr: 0.000006  loss: 1.0409 (1.0280)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [ 40/172]  eta: 0:03:32  lr: 0.000006  loss: 1.0134 (1.0217)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [ 50/172]  eta: 0:03:15  lr: 0.000006  loss: 0.9979 (1.0191)  time: 1.5803  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [ 60/172]  eta: 0:02:59  lr: 0.000006  loss: 0.9933 (1.0148)  time: 1.5786  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [ 70/172]  eta: 0:02:42  lr: 0.000006  loss: 1.0115 (1.0192)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [ 80/172]  eta: 0:02:26  lr: 0.000006  loss: 1.0261 (1.0194)  time: 1.5785  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [ 90/172]  eta: 0:02:10  lr: 0.000006  loss: 1.0059 (1.0201)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [100/172]  eta: 0:01:54  lr: 0.000006  loss: 1.0059 (1.0197)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [110/172]  eta: 0:01:38  lr: 0.000006  loss: 1.0170 (1.0205)  time: 1.5808  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:948]  [120/172]  eta: 0:01:22  lr: 0.000006  loss: 1.0300 (1.0235)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [130/172]  eta: 0:01:06  lr: 0.000006  loss: 1.0434 (1.0265)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [140/172]  eta: 0:00:50  lr: 0.000006  loss: 1.0306 (1.0243)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [150/172]  eta: 0:00:34  lr: 0.000006  loss: 1.0183 (1.0257)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [160/172]  eta: 0:00:19  lr: 0.000006  loss: 1.0441 (1.0258)  time: 1.5828  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:948]  [170/172]  eta: 0:00:03  lr: 0.000006  loss: 1.0214 (1.0255)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948]  [171/172]  eta: 0:00:01  lr: 0.000006  loss: 1.0214 (1.0255)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:948] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000006  loss: 1.0214 (1.0255)\n",
      "Valid: [epoch:948]  [ 0/14]  eta: 0:00:05  loss: 1.0175 (1.0175)  time: 0.3743  data: 0.3570  max mem: 20571\n",
      "Valid: [epoch:948]  [13/14]  eta: 0:00:00  loss: 0.9667 (0.9810)  time: 0.0423  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:948] Total time: 0:00:00 (0.0486 s / it)\n",
      "Averaged stats: loss: 0.9667 (0.9810)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_948_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.981%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:949]  [  0/172]  eta: 0:07:44  lr: 0.000006  loss: 0.9775 (0.9775)  time: 2.6993  data: 1.1115  max mem: 20571\n",
      "Train: [epoch:949]  [ 10/172]  eta: 0:04:33  lr: 0.000006  loss: 0.9775 (0.9883)  time: 1.6884  data: 0.1012  max mem: 20571\n",
      "Train: [epoch:949]  [ 20/172]  eta: 0:04:09  lr: 0.000006  loss: 1.0173 (1.0176)  time: 1.5877  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:949]  [ 30/172]  eta: 0:03:50  lr: 0.000006  loss: 1.0357 (1.0163)  time: 1.5900  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [ 40/172]  eta: 0:03:33  lr: 0.000006  loss: 1.0415 (1.0262)  time: 1.5936  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:949]  [ 50/172]  eta: 0:03:16  lr: 0.000006  loss: 1.0458 (1.0278)  time: 1.5929  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:949]  [ 60/172]  eta: 0:03:00  lr: 0.000006  loss: 1.0035 (1.0251)  time: 1.5891  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [ 70/172]  eta: 0:02:43  lr: 0.000006  loss: 0.9905 (1.0208)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [ 80/172]  eta: 0:02:27  lr: 0.000006  loss: 0.9981 (1.0221)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [ 90/172]  eta: 0:02:11  lr: 0.000006  loss: 1.0182 (1.0245)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [100/172]  eta: 0:01:55  lr: 0.000006  loss: 1.0182 (1.0248)  time: 1.5900  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [110/172]  eta: 0:01:39  lr: 0.000006  loss: 1.0148 (1.0259)  time: 1.5921  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [120/172]  eta: 0:01:23  lr: 0.000006  loss: 1.0228 (1.0269)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [130/172]  eta: 0:01:07  lr: 0.000006  loss: 1.0442 (1.0286)  time: 1.5876  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:949]  [140/172]  eta: 0:00:51  lr: 0.000006  loss: 1.0290 (1.0279)  time: 1.5859  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:949]  [150/172]  eta: 0:00:35  lr: 0.000006  loss: 1.0042 (1.0258)  time: 1.5845  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:949]  [160/172]  eta: 0:00:19  lr: 0.000006  loss: 0.9989 (1.0246)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [170/172]  eta: 0:00:03  lr: 0.000006  loss: 1.0216 (1.0256)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949]  [171/172]  eta: 0:00:01  lr: 0.000006  loss: 1.0216 (1.0260)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:949] Total time: 0:04:34 (1.5958 s / it)\n",
      "Averaged stats: lr: 0.000006  loss: 1.0216 (1.0260)\n",
      "Valid: [epoch:949]  [ 0/14]  eta: 0:00:05  loss: 0.8751 (0.8751)  time: 0.4206  data: 0.4055  max mem: 20571\n",
      "Valid: [epoch:949]  [13/14]  eta: 0:00:00  loss: 0.9688 (0.9827)  time: 0.0462  data: 0.0312  max mem: 20571\n",
      "Valid: [epoch:949] Total time: 0:00:00 (0.0540 s / it)\n",
      "Averaged stats: loss: 0.9688 (0.9827)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_949_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.983%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:950]  [  0/172]  eta: 0:08:05  lr: 0.000006  loss: 1.1237 (1.1237)  time: 2.8244  data: 1.2399  max mem: 20571\n",
      "Train: [epoch:950]  [ 10/172]  eta: 0:04:35  lr: 0.000006  loss: 1.0384 (1.0215)  time: 1.6983  data: 0.1129  max mem: 20571\n",
      "Train: [epoch:950]  [ 20/172]  eta: 0:04:09  lr: 0.000006  loss: 1.0299 (1.0268)  time: 1.5850  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:950]  [ 30/172]  eta: 0:03:50  lr: 0.000006  loss: 1.0383 (1.0372)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [ 40/172]  eta: 0:03:33  lr: 0.000006  loss: 1.0137 (1.0322)  time: 1.5892  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [ 50/172]  eta: 0:03:16  lr: 0.000006  loss: 1.0213 (1.0340)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [ 60/172]  eta: 0:02:59  lr: 0.000006  loss: 1.0213 (1.0327)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [ 70/172]  eta: 0:02:43  lr: 0.000006  loss: 1.0027 (1.0307)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [ 80/172]  eta: 0:02:27  lr: 0.000006  loss: 1.0085 (1.0309)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [ 90/172]  eta: 0:02:11  lr: 0.000006  loss: 1.0248 (1.0300)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [100/172]  eta: 0:01:55  lr: 0.000006  loss: 1.0143 (1.0303)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [110/172]  eta: 0:01:39  lr: 0.000006  loss: 1.0056 (1.0304)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [120/172]  eta: 0:01:22  lr: 0.000006  loss: 0.9946 (1.0300)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [130/172]  eta: 0:01:07  lr: 0.000006  loss: 1.0282 (1.0299)  time: 1.5840  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:950]  [140/172]  eta: 0:00:51  lr: 0.000006  loss: 1.0144 (1.0287)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [150/172]  eta: 0:00:35  lr: 0.000006  loss: 1.0151 (1.0294)  time: 1.5789  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:950]  [160/172]  eta: 0:00:19  lr: 0.000006  loss: 1.0115 (1.0268)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [170/172]  eta: 0:00:03  lr: 0.000006  loss: 0.9915 (1.0273)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950]  [171/172]  eta: 0:00:01  lr: 0.000006  loss: 1.0035 (1.0274)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:950] Total time: 0:04:33 (1.5928 s / it)\n",
      "Averaged stats: lr: 0.000006  loss: 1.0035 (1.0274)\n",
      "Valid: [epoch:950]  [ 0/14]  eta: 0:00:05  loss: 1.0312 (1.0312)  time: 0.4036  data: 0.3883  max mem: 20571\n",
      "Valid: [epoch:950]  [13/14]  eta: 0:00:00  loss: 0.9685 (0.9831)  time: 0.0446  data: 0.0293  max mem: 20571\n",
      "Valid: [epoch:950] Total time: 0:00:00 (0.0523 s / it)\n",
      "Averaged stats: loss: 0.9685 (0.9831)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_950_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.983%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:951]  [  0/172]  eta: 0:08:06  lr: 0.000006  loss: 1.0418 (1.0418)  time: 2.8294  data: 1.2338  max mem: 20571\n",
      "Train: [epoch:951]  [ 10/172]  eta: 0:04:34  lr: 0.000006  loss: 1.0348 (1.0184)  time: 1.6966  data: 0.1123  max mem: 20571\n",
      "Train: [epoch:951]  [ 20/172]  eta: 0:04:09  lr: 0.000006  loss: 1.0131 (1.0305)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [ 30/172]  eta: 0:03:50  lr: 0.000006  loss: 1.0151 (1.0307)  time: 1.5838  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:951]  [ 40/172]  eta: 0:03:33  lr: 0.000006  loss: 1.0263 (1.0321)  time: 1.5880  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:951]  [ 50/172]  eta: 0:03:16  lr: 0.000006  loss: 1.0291 (1.0336)  time: 1.5850  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:951]  [ 60/172]  eta: 0:02:59  lr: 0.000006  loss: 1.0246 (1.0346)  time: 1.5834  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:951]  [ 70/172]  eta: 0:02:43  lr: 0.000006  loss: 1.0099 (1.0296)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [ 80/172]  eta: 0:02:27  lr: 0.000006  loss: 1.0001 (1.0288)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [ 90/172]  eta: 0:02:10  lr: 0.000006  loss: 1.0062 (1.0278)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:951]  [100/172]  eta: 0:01:54  lr: 0.000006  loss: 1.0346 (1.0316)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [110/172]  eta: 0:01:38  lr: 0.000006  loss: 1.0183 (1.0296)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [120/172]  eta: 0:01:22  lr: 0.000006  loss: 1.0142 (1.0287)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [130/172]  eta: 0:01:06  lr: 0.000006  loss: 1.0227 (1.0260)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [140/172]  eta: 0:00:50  lr: 0.000006  loss: 0.9964 (1.0262)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [150/172]  eta: 0:00:35  lr: 0.000006  loss: 1.0208 (1.0257)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [160/172]  eta: 0:00:19  lr: 0.000006  loss: 1.0206 (1.0259)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [170/172]  eta: 0:00:03  lr: 0.000006  loss: 1.0160 (1.0275)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951]  [171/172]  eta: 0:00:01  lr: 0.000006  loss: 1.0188 (1.0275)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:951] Total time: 0:04:34 (1.5931 s / it)\n",
      "Averaged stats: lr: 0.000006  loss: 1.0188 (1.0275)\n",
      "Valid: [epoch:951]  [ 0/14]  eta: 0:00:05  loss: 0.9500 (0.9500)  time: 0.3721  data: 0.3563  max mem: 20571\n",
      "Valid: [epoch:951]  [13/14]  eta: 0:00:00  loss: 0.9698 (0.9842)  time: 0.0438  data: 0.0280  max mem: 20571\n",
      "Valid: [epoch:951] Total time: 0:00:00 (0.0507 s / it)\n",
      "Averaged stats: loss: 0.9698 (0.9842)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_951_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.984%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:952]  [  0/172]  eta: 0:07:32  lr: 0.000005  loss: 1.0524 (1.0524)  time: 2.6300  data: 1.0631  max mem: 20571\n",
      "Train: [epoch:952]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 0.9948 (1.0027)  time: 1.6809  data: 0.0968  max mem: 20571\n",
      "Train: [epoch:952]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 0.9948 (1.0100)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0237 (1.0187)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0129 (1.0168)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [ 50/172]  eta: 0:03:15  lr: 0.000005  loss: 1.0352 (1.0242)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0391 (1.0260)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0315 (1.0269)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [ 80/172]  eta: 0:02:26  lr: 0.000005  loss: 1.0348 (1.0294)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0508 (1.0335)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0508 (1.0342)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0219 (1.0343)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 0.9978 (1.0316)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 0.9963 (1.0316)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 0.9927 (1.0280)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0178 (1.0291)  time: 1.5813  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0290 (1.0288)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0397 (1.0299)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0340 (1.0297)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:952] Total time: 0:04:33 (1.5910 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0340 (1.0297)\n",
      "Valid: [epoch:952]  [ 0/14]  eta: 0:00:05  loss: 0.8772 (0.8772)  time: 0.4025  data: 0.3864  max mem: 20571\n",
      "Valid: [epoch:952]  [13/14]  eta: 0:00:00  loss: 0.9722 (0.9855)  time: 0.0450  data: 0.0298  max mem: 20571\n",
      "Valid: [epoch:952] Total time: 0:00:00 (0.0520 s / it)\n",
      "Averaged stats: loss: 0.9722 (0.9855)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_952_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.985%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:953]  [  0/172]  eta: 0:08:43  lr: 0.000005  loss: 0.9435 (0.9435)  time: 3.0436  data: 1.4639  max mem: 20571\n",
      "Train: [epoch:953]  [ 10/172]  eta: 0:04:37  lr: 0.000005  loss: 1.0203 (1.0030)  time: 1.7140  data: 0.1332  max mem: 20571\n",
      "Train: [epoch:953]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0173 (1.0038)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:953]  [ 30/172]  eta: 0:03:51  lr: 0.000005  loss: 0.9998 (1.0068)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 0.9975 (1.0046)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0157 (1.0125)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0307 (1.0179)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0506 (1.0226)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0233 (1.0216)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0192 (1.0226)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0202 (1.0242)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0306 (1.0265)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0559 (1.0313)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0387 (1.0312)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0445 (1.0327)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0445 (1.0313)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0144 (1.0315)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0144 (1.0305)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0131 (1.0304)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:953] Total time: 0:04:34 (1.5940 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0131 (1.0304)\n",
      "Valid: [epoch:953]  [ 0/14]  eta: 0:00:05  loss: 0.8778 (0.8778)  time: 0.3604  data: 0.3452  max mem: 20571\n",
      "Valid: [epoch:953]  [13/14]  eta: 0:00:00  loss: 0.9712 (0.9858)  time: 0.0423  data: 0.0268  max mem: 20571\n",
      "Valid: [epoch:953] Total time: 0:00:00 (0.0499 s / it)\n",
      "Averaged stats: loss: 0.9712 (0.9858)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_953_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.986%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:954]  [  0/172]  eta: 0:07:25  lr: 0.000005  loss: 1.0650 (1.0650)  time: 2.5928  data: 1.0179  max mem: 20571\n",
      "Train: [epoch:954]  [ 10/172]  eta: 0:04:31  lr: 0.000005  loss: 1.0107 (0.9931)  time: 1.6740  data: 0.0927  max mem: 20571\n",
      "Train: [epoch:954]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0076 (0.9947)  time: 1.5838  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:954]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0131 (1.0128)  time: 1.5853  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:954]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0426 (1.0176)  time: 1.5877  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:954]  [ 50/172]  eta: 0:03:15  lr: 0.000005  loss: 1.0158 (1.0251)  time: 1.5894  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0224 (1.0264)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0224 (1.0249)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0245 (1.0285)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0198 (1.0284)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0078 (1.0266)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0069 (1.0259)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 0.9972 (1.0245)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0083 (1.0265)  time: 1.5796  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0216 (1.0249)  time: 1.5801  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [150/172]  eta: 0:00:34  lr: 0.000005  loss: 1.0196 (1.0259)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0311 (1.0283)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0793 (1.0309)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0793 (1.0313)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:954] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0793 (1.0313)\n",
      "Valid: [epoch:954]  [ 0/14]  eta: 0:00:04  loss: 0.9544 (0.9544)  time: 0.3526  data: 0.3370  max mem: 20571\n",
      "Valid: [epoch:954]  [13/14]  eta: 0:00:00  loss: 0.9737 (0.9877)  time: 0.0438  data: 0.0282  max mem: 20571\n",
      "Valid: [epoch:954] Total time: 0:00:00 (0.0515 s / it)\n",
      "Averaged stats: loss: 0.9737 (0.9877)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_954_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.988%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:955]  [  0/172]  eta: 0:07:36  lr: 0.000005  loss: 1.0289 (1.0289)  time: 2.6556  data: 1.0784  max mem: 20571\n",
      "Train: [epoch:955]  [ 10/172]  eta: 0:04:31  lr: 0.000005  loss: 1.0289 (1.0269)  time: 1.6773  data: 0.0982  max mem: 20571\n",
      "Train: [epoch:955]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0177 (1.0218)  time: 1.5809  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:955]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0148 (1.0225)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0269 (1.0250)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [ 50/172]  eta: 0:03:15  lr: 0.000005  loss: 1.0355 (1.0297)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0366 (1.0284)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [ 70/172]  eta: 0:02:42  lr: 0.000005  loss: 1.0457 (1.0294)  time: 1.5814  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [ 80/172]  eta: 0:02:26  lr: 0.000005  loss: 1.0374 (1.0292)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0295 (1.0282)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0289 (1.0302)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0419 (1.0325)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0444 (1.0343)  time: 1.5829  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0444 (1.0343)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0038 (1.0303)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [150/172]  eta: 0:00:34  lr: 0.000005  loss: 1.0002 (1.0301)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0131 (1.0298)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0343 (1.0317)  time: 1.5900  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0426 (1.0320)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:955] Total time: 0:04:33 (1.5906 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0426 (1.0320)\n",
      "Valid: [epoch:955]  [ 0/14]  eta: 0:00:05  loss: 1.0364 (1.0364)  time: 0.4079  data: 0.3926  max mem: 20571\n",
      "Valid: [epoch:955]  [13/14]  eta: 0:00:00  loss: 0.9743 (0.9885)  time: 0.0445  data: 0.0294  max mem: 20571\n",
      "Valid: [epoch:955] Total time: 0:00:00 (0.0512 s / it)\n",
      "Averaged stats: loss: 0.9743 (0.9885)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_955_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.989%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:956]  [  0/172]  eta: 0:07:47  lr: 0.000005  loss: 1.0234 (1.0234)  time: 2.7209  data: 1.1540  max mem: 20571\n",
      "Train: [epoch:956]  [ 10/172]  eta: 0:04:33  lr: 0.000005  loss: 1.0177 (1.0431)  time: 1.6898  data: 0.1050  max mem: 20571\n",
      "Train: [epoch:956]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0177 (1.0462)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0067 (1.0313)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0060 (1.0325)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0246 (1.0256)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0111 (1.0239)  time: 1.5844  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:956]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0134 (1.0234)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0307 (1.0261)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0307 (1.0263)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0213 (1.0266)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0238 (1.0281)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0622 (1.0308)  time: 1.5811  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0229 (1.0311)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0057 (1.0294)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0135 (1.0303)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0214 (1.0305)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0395 (1.0336)  time: 1.5850  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:956]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0395 (1.0335)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:956] Total time: 0:04:33 (1.5912 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0395 (1.0335)\n",
      "Valid: [epoch:956]  [ 0/14]  eta: 0:00:05  loss: 1.0264 (1.0264)  time: 0.3978  data: 0.3824  max mem: 20571\n",
      "Valid: [epoch:956]  [13/14]  eta: 0:00:00  loss: 0.9761 (0.9900)  time: 0.0454  data: 0.0301  max mem: 20571\n",
      "Valid: [epoch:956] Total time: 0:00:00 (0.0522 s / it)\n",
      "Averaged stats: loss: 0.9761 (0.9900)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_956_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.990%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:957]  [  0/172]  eta: 0:07:41  lr: 0.000005  loss: 1.1189 (1.1189)  time: 2.6846  data: 1.1028  max mem: 20571\n",
      "Train: [epoch:957]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0333 (1.0424)  time: 1.6799  data: 0.1004  max mem: 20571\n",
      "Train: [epoch:957]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0301 (1.0453)  time: 1.5805  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0380 (1.0438)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0380 (1.0443)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [ 50/172]  eta: 0:03:15  lr: 0.000005  loss: 1.0317 (1.0400)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0316 (1.0419)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [ 70/172]  eta: 0:02:42  lr: 0.000005  loss: 1.0239 (1.0388)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [ 80/172]  eta: 0:02:26  lr: 0.000005  loss: 1.0169 (1.0365)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0314 (1.0380)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0483 (1.0403)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0376 (1.0396)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0349 (1.0389)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0256 (1.0389)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0157 (1.0369)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 0.9953 (1.0353)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0059 (1.0336)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0248 (1.0339)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0252 (1.0342)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:957] Total time: 0:04:33 (1.5914 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0252 (1.0342)\n",
      "Valid: [epoch:957]  [ 0/14]  eta: 0:00:05  loss: 1.0784 (1.0784)  time: 0.3693  data: 0.3538  max mem: 20571\n",
      "Valid: [epoch:957]  [13/14]  eta: 0:00:00  loss: 0.9768 (0.9905)  time: 0.0436  data: 0.0280  max mem: 20571\n",
      "Valid: [epoch:957] Total time: 0:00:00 (0.0518 s / it)\n",
      "Averaged stats: loss: 0.9768 (0.9905)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_957_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.990%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:958]  [  0/172]  eta: 0:08:18  lr: 0.000005  loss: 1.0945 (1.0945)  time: 2.9003  data: 1.3231  max mem: 20571\n",
      "Train: [epoch:958]  [ 10/172]  eta: 0:04:36  lr: 0.000005  loss: 0.9945 (1.0069)  time: 1.7045  data: 0.1204  max mem: 20571\n",
      "Train: [epoch:958]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0174 (1.0259)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0211 (1.0249)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0078 (1.0243)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0249 (1.0334)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0358 (1.0355)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0306 (1.0362)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0306 (1.0365)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0176 (1.0362)  time: 1.5830  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0049 (1.0326)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0259 (1.0340)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0259 (1.0333)  time: 1.5850  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:958]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0249 (1.0351)  time: 1.5850  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:958]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0300 (1.0359)  time: 1.5840  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:958]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0257 (1.0355)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:958]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0197 (1.0348)  time: 1.5843  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:958]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0156 (1.0353)  time: 1.5840  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:958]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0156 (1.0354)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:958] Total time: 0:04:33 (1.5925 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0156 (1.0354)\n",
      "Valid: [epoch:958]  [ 0/14]  eta: 0:00:06  loss: 0.9283 (0.9283)  time: 0.4391  data: 0.4238  max mem: 20571\n",
      "Valid: [epoch:958]  [13/14]  eta: 0:00:00  loss: 0.9777 (0.9910)  time: 0.0462  data: 0.0312  max mem: 20571\n",
      "Valid: [epoch:958] Total time: 0:00:00 (0.0547 s / it)\n",
      "Averaged stats: loss: 0.9777 (0.9910)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_958_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.991%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:959]  [  0/172]  eta: 0:07:31  lr: 0.000005  loss: 0.9989 (0.9989)  time: 2.6274  data: 1.0321  max mem: 20571\n",
      "Train: [epoch:959]  [ 10/172]  eta: 0:04:31  lr: 0.000005  loss: 1.0304 (1.0309)  time: 1.6761  data: 0.0940  max mem: 20571\n",
      "Train: [epoch:959]  [ 20/172]  eta: 0:04:07  lr: 0.000005  loss: 1.0110 (1.0290)  time: 1.5808  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0231 (1.0300)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0311 (1.0254)  time: 1.5880  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:959]  [ 50/172]  eta: 0:03:15  lr: 0.000005  loss: 1.0177 (1.0266)  time: 1.5871  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:959]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0195 (1.0306)  time: 1.5836  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:959]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0430 (1.0291)  time: 1.5838  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:959]  [ 80/172]  eta: 0:02:26  lr: 0.000005  loss: 1.0526 (1.0361)  time: 1.5844  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:959]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0715 (1.0353)  time: 1.5846  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:959]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0603 (1.0379)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0603 (1.0388)  time: 1.5862  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:959]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0417 (1.0404)  time: 1.5832  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0417 (1.0381)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 0.9980 (1.0350)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 0.9936 (1.0333)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0099 (1.0342)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0334 (1.0364)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0414 (1.0365)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:959] Total time: 0:04:33 (1.5917 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0414 (1.0365)\n",
      "Valid: [epoch:959]  [ 0/14]  eta: 0:00:04  loss: 0.8838 (0.8838)  time: 0.3045  data: 0.2897  max mem: 20571\n",
      "Valid: [epoch:959]  [13/14]  eta: 0:00:00  loss: 0.9785 (0.9922)  time: 0.0367  data: 0.0217  max mem: 20571\n",
      "Valid: [epoch:959] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.9785 (0.9922)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_959_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.992%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:960]  [  0/172]  eta: 0:08:03  lr: 0.000005  loss: 0.9627 (0.9627)  time: 2.8128  data: 1.2181  max mem: 20571\n",
      "Train: [epoch:960]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0279 (1.0337)  time: 1.6958  data: 0.1108  max mem: 20571\n",
      "Train: [epoch:960]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0256 (1.0301)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0331 (1.0347)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0392 (1.0322)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0321 (1.0350)  time: 1.5845  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0321 (1.0375)  time: 1.5818  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:960]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0150 (1.0314)  time: 1.5799  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:960]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0005 (1.0320)  time: 1.5829  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:960]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0209 (1.0334)  time: 1.5845  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:960]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0185 (1.0320)  time: 1.5856  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:960]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0185 (1.0315)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0360 (1.0352)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0513 (1.0385)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0523 (1.0385)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0028 (1.0355)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0047 (1.0361)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0265 (1.0374)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0335 (1.0379)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:960] Total time: 0:04:33 (1.5926 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0335 (1.0379)\n",
      "Valid: [epoch:960]  [ 0/14]  eta: 0:00:04  loss: 0.9590 (0.9590)  time: 0.3527  data: 0.3347  max mem: 20571\n",
      "Valid: [epoch:960]  [13/14]  eta: 0:00:00  loss: 0.9798 (0.9936)  time: 0.0392  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:960] Total time: 0:00:00 (0.0471 s / it)\n",
      "Averaged stats: loss: 0.9798 (0.9936)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_960_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.994%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:961]  [  0/172]  eta: 0:07:29  lr: 0.000005  loss: 1.0665 (1.0665)  time: 2.6126  data: 1.0188  max mem: 20571\n",
      "Train: [epoch:961]  [ 10/172]  eta: 0:04:31  lr: 0.000005  loss: 1.0002 (1.0179)  time: 1.6759  data: 0.0928  max mem: 20571\n",
      "Train: [epoch:961]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0236 (1.0523)  time: 1.5851  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:961]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0704 (1.0538)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 0.9976 (1.0363)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 0.9976 (1.0357)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0013 (1.0285)  time: 1.5876  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:961]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 0.9958 (1.0270)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0400 (1.0313)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0618 (1.0367)  time: 1.5897  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0472 (1.0360)  time: 1.5902  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0170 (1.0367)  time: 1.5921  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0393 (1.0385)  time: 1.5912  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0411 (1.0387)  time: 1.5892  data: 0.0003  max mem: 20571\n",
      "Train: [epoch:961]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0450 (1.0395)  time: 1.5874  data: 0.0003  max mem: 20571\n",
      "Train: [epoch:961]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0531 (1.0405)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0466 (1.0389)  time: 1.5903  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0095 (1.0381)  time: 1.5894  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0150 (1.0384)  time: 1.5898  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:961] Total time: 0:04:34 (1.5952 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0150 (1.0384)\n",
      "Valid: [epoch:961]  [ 0/14]  eta: 0:00:04  loss: 0.9111 (0.9111)  time: 0.3062  data: 0.2887  max mem: 20571\n",
      "Valid: [epoch:961]  [13/14]  eta: 0:00:00  loss: 0.9801 (0.9939)  time: 0.0383  data: 0.0229  max mem: 20571\n",
      "Valid: [epoch:961] Total time: 0:00:00 (0.0450 s / it)\n",
      "Averaged stats: loss: 0.9801 (0.9939)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_961_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.994%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:962]  [  0/172]  eta: 0:07:42  lr: 0.000005  loss: 1.0361 (1.0361)  time: 2.6904  data: 1.1039  max mem: 20571\n",
      "Train: [epoch:962]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0361 (1.0360)  time: 1.6846  data: 0.1005  max mem: 20571\n",
      "Train: [epoch:962]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0520 (1.0592)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0642 (1.0500)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0331 (1.0482)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0411 (1.0498)  time: 1.5846  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:962]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0527 (1.0494)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0579 (1.0502)  time: 1.5822  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [ 80/172]  eta: 0:02:26  lr: 0.000005  loss: 1.0519 (1.0510)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0320 (1.0459)  time: 1.5795  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 0.9975 (1.0427)  time: 1.5804  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0227 (1.0422)  time: 1.5827  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0339 (1.0411)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0158 (1.0415)  time: 1.5798  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0280 (1.0402)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [150/172]  eta: 0:00:34  lr: 0.000005  loss: 1.0192 (1.0392)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0405 (1.0391)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0425 (1.0392)  time: 1.5782  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0425 (1.0394)  time: 1.5779  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:962] Total time: 0:04:33 (1.5887 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0425 (1.0394)\n",
      "Valid: [epoch:962]  [ 0/14]  eta: 0:00:04  loss: 0.9608 (0.9608)  time: 0.3431  data: 0.3278  max mem: 20571\n",
      "Valid: [epoch:962]  [13/14]  eta: 0:00:00  loss: 0.9815 (0.9954)  time: 0.0398  data: 0.0247  max mem: 20571\n",
      "Valid: [epoch:962] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.9815 (0.9954)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_962_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.995%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:963]  [  0/172]  eta: 0:07:42  lr: 0.000005  loss: 0.9854 (0.9854)  time: 2.6915  data: 1.1149  max mem: 20571\n",
      "Train: [epoch:963]  [ 10/172]  eta: 0:04:31  lr: 0.000005  loss: 0.9995 (1.0183)  time: 1.6780  data: 0.1015  max mem: 20571\n",
      "Train: [epoch:963]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0202 (1.0265)  time: 1.5787  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0371 (1.0306)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0272 (1.0313)  time: 1.5835  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [ 50/172]  eta: 0:03:15  lr: 0.000005  loss: 1.0247 (1.0330)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0245 (1.0342)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0252 (1.0348)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [ 80/172]  eta: 0:02:26  lr: 0.000005  loss: 1.0567 (1.0396)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0629 (1.0416)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0369 (1.0422)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0339 (1.0426)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0366 (1.0428)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0469 (1.0442)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0448 (1.0419)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0257 (1.0423)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0257 (1.0417)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0235 (1.0414)  time: 1.5900  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0235 (1.0412)  time: 1.5895  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:963] Total time: 0:04:33 (1.5923 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0235 (1.0412)\n",
      "Valid: [epoch:963]  [ 0/14]  eta: 0:00:03  loss: 1.0392 (1.0392)  time: 0.2818  data: 0.2663  max mem: 20571\n",
      "Valid: [epoch:963]  [13/14]  eta: 0:00:00  loss: 0.9827 (0.9968)  time: 0.0363  data: 0.0212  max mem: 20571\n",
      "Valid: [epoch:963] Total time: 0:00:00 (0.0415 s / it)\n",
      "Averaged stats: loss: 0.9827 (0.9968)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_963_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.997%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:964]  [  0/172]  eta: 0:07:52  lr: 0.000005  loss: 1.0444 (1.0444)  time: 2.7444  data: 1.1586  max mem: 20571\n",
      "Train: [epoch:964]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0368 (1.0363)  time: 1.6957  data: 0.1054  max mem: 20571\n",
      "Train: [epoch:964]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0308 (1.0370)  time: 1.5915  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [ 30/172]  eta: 0:03:51  lr: 0.000005  loss: 1.0206 (1.0408)  time: 1.5899  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0234 (1.0383)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0275 (1.0344)  time: 1.5899  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0379 (1.0352)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0517 (1.0407)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0367 (1.0394)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0228 (1.0416)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0335 (1.0422)  time: 1.5891  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0381 (1.0415)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0381 (1.0418)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0191 (1.0419)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0158 (1.0407)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0200 (1.0410)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0336 (1.0415)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0387 (1.0410)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0387 (1.0418)  time: 1.5890  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:964] Total time: 0:04:34 (1.5955 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0387 (1.0418)\n",
      "Valid: [epoch:964]  [ 0/14]  eta: 0:00:04  loss: 0.9137 (0.9137)  time: 0.3329  data: 0.3174  max mem: 20571\n",
      "Valid: [epoch:964]  [13/14]  eta: 0:00:00  loss: 0.9825 (0.9972)  time: 0.0393  data: 0.0243  max mem: 20571\n",
      "Valid: [epoch:964] Total time: 0:00:00 (0.0451 s / it)\n",
      "Averaged stats: loss: 0.9825 (0.9972)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_964_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.997%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:965]  [  0/172]  eta: 0:07:55  lr: 0.000005  loss: 0.9470 (0.9470)  time: 2.7639  data: 1.1543  max mem: 20571\n",
      "Train: [epoch:965]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0035 (1.0225)  time: 1.6929  data: 0.1050  max mem: 20571\n",
      "Train: [epoch:965]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0313 (1.0423)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0321 (1.0400)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0279 (1.0373)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0129 (1.0325)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0231 (1.0348)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0531 (1.0411)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0541 (1.0447)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0301 (1.0404)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0024 (1.0397)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0355 (1.0403)  time: 1.5897  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0418 (1.0413)  time: 1.5898  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0340 (1.0407)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0135 (1.0396)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0187 (1.0392)  time: 1.5880  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0420 (1.0404)  time: 1.5904  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0681 (1.0430)  time: 1.5900  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0681 (1.0430)  time: 1.5894  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:965] Total time: 0:04:34 (1.5948 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0681 (1.0430)\n",
      "Valid: [epoch:965]  [ 0/14]  eta: 0:00:04  loss: 1.0345 (1.0345)  time: 0.2891  data: 0.2735  max mem: 20571\n",
      "Valid: [epoch:965]  [13/14]  eta: 0:00:00  loss: 0.9843 (0.9982)  time: 0.0424  data: 0.0274  max mem: 20571\n",
      "Valid: [epoch:965] Total time: 0:00:00 (0.0493 s / it)\n",
      "Averaged stats: loss: 0.9843 (0.9982)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_965_input_n_20.png\n",
      "loss of the network on the 14 valid images: 0.998%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:966]  [  0/172]  eta: 0:08:17  lr: 0.000005  loss: 1.1700 (1.1700)  time: 2.8937  data: 1.3094  max mem: 20571\n",
      "Train: [epoch:966]  [ 10/172]  eta: 0:04:36  lr: 0.000005  loss: 1.0546 (1.0534)  time: 1.7077  data: 0.1191  max mem: 20571\n",
      "Train: [epoch:966]  [ 20/172]  eta: 0:04:11  lr: 0.000005  loss: 1.0371 (1.0430)  time: 1.5907  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [ 30/172]  eta: 0:03:52  lr: 0.000005  loss: 1.0226 (1.0443)  time: 1.5935  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [ 40/172]  eta: 0:03:34  lr: 0.000005  loss: 1.0454 (1.0430)  time: 1.5937  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [ 50/172]  eta: 0:03:17  lr: 0.000005  loss: 1.0440 (1.0404)  time: 1.5923  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0440 (1.0402)  time: 1.5901  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [ 70/172]  eta: 0:02:44  lr: 0.000005  loss: 1.0187 (1.0402)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0313 (1.0429)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0451 (1.0448)  time: 1.5901  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0603 (1.0472)  time: 1.5916  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0376 (1.0464)  time: 1.5902  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0376 (1.0462)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0466 (1.0439)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0202 (1.0420)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0341 (1.0432)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0222 (1.0427)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0249 (1.0441)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0222 (1.0434)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:966] Total time: 0:04:34 (1.5979 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0222 (1.0434)\n",
      "Valid: [epoch:966]  [ 0/14]  eta: 0:00:06  loss: 0.9657 (0.9657)  time: 0.4424  data: 0.4240  max mem: 20571\n",
      "Valid: [epoch:966]  [13/14]  eta: 0:00:00  loss: 0.9851 (0.9996)  time: 0.0473  data: 0.0322  max mem: 20571\n",
      "Valid: [epoch:966] Total time: 0:00:00 (0.0520 s / it)\n",
      "Averaged stats: loss: 0.9851 (0.9996)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_966_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:967]  [  0/172]  eta: 0:07:34  lr: 0.000005  loss: 1.0807 (1.0807)  time: 2.6401  data: 1.0646  max mem: 20571\n",
      "Train: [epoch:967]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0165 (1.0311)  time: 1.6802  data: 0.0969  max mem: 20571\n",
      "Train: [epoch:967]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0016 (1.0219)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0219 (1.0277)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0482 (1.0268)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0448 (1.0309)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0308 (1.0315)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0213 (1.0324)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0430 (1.0346)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0516 (1.0345)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0469 (1.0361)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0449 (1.0370)  time: 1.5890  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0402 (1.0387)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0582 (1.0412)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0703 (1.0441)  time: 1.5880  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0703 (1.0428)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0305 (1.0446)  time: 1.5913  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0356 (1.0437)  time: 1.5908  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:967]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0397 (1.0438)  time: 1.5904  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:967] Total time: 0:04:34 (1.5950 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0397 (1.0438)\n",
      "Valid: [epoch:967]  [ 0/14]  eta: 0:00:04  loss: 1.0408 (1.0408)  time: 0.3239  data: 0.3061  max mem: 20571\n",
      "Valid: [epoch:967]  [13/14]  eta: 0:00:00  loss: 0.9864 (1.0003)  time: 0.0391  data: 0.0240  max mem: 20571\n",
      "Valid: [epoch:967] Total time: 0:00:00 (0.0443 s / it)\n",
      "Averaged stats: loss: 0.9864 (1.0003)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_967_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.000%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:968]  [  0/172]  eta: 0:07:30  lr: 0.000005  loss: 1.1184 (1.1184)  time: 2.6189  data: 1.0349  max mem: 20571\n",
      "Train: [epoch:968]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0247 (1.0436)  time: 1.6803  data: 0.0942  max mem: 20571\n",
      "Train: [epoch:968]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0229 (1.0461)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0354 (1.0501)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0348 (1.0473)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0289 (1.0474)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0289 (1.0455)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0461 (1.0476)  time: 1.5895  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0290 (1.0442)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0399 (1.0478)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0702 (1.0481)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0619 (1.0472)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0564 (1.0478)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0538 (1.0483)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0091 (1.0442)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0025 (1.0439)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0143 (1.0419)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0318 (1.0446)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0610 (1.0450)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:968] Total time: 0:04:34 (1.5939 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0610 (1.0450)\n",
      "Valid: [epoch:968]  [ 0/14]  eta: 0:00:04  loss: 1.0500 (1.0500)  time: 0.3118  data: 0.2966  max mem: 20571\n",
      "Valid: [epoch:968]  [13/14]  eta: 0:00:00  loss: 0.9877 (1.0015)  time: 0.0439  data: 0.0287  max mem: 20571\n",
      "Valid: [epoch:968] Total time: 0:00:00 (0.0523 s / it)\n",
      "Averaged stats: loss: 0.9877 (1.0015)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_968_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.002%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:969]  [  0/172]  eta: 0:08:06  lr: 0.000005  loss: 1.1443 (1.1443)  time: 2.8265  data: 1.2495  max mem: 20571\n",
      "Train: [epoch:969]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0294 (1.0351)  time: 1.6930  data: 0.1137  max mem: 20571\n",
      "Train: [epoch:969]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0478 (1.0554)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:969]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0561 (1.0500)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0327 (1.0427)  time: 1.5860  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0441 (1.0518)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0394 (1.0490)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0201 (1.0451)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0226 (1.0449)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0372 (1.0481)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0272 (1.0458)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0394 (1.0461)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0515 (1.0471)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0260 (1.0452)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0106 (1.0430)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0410 (1.0440)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0658 (1.0466)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0604 (1.0462)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0604 (1.0468)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:969] Total time: 0:04:34 (1.5938 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0604 (1.0468)\n",
      "Valid: [epoch:969]  [ 0/14]  eta: 0:00:05  loss: 1.0511 (1.0511)  time: 0.3626  data: 0.3464  max mem: 20571\n",
      "Valid: [epoch:969]  [13/14]  eta: 0:00:00  loss: 0.9877 (1.0017)  time: 0.0415  data: 0.0263  max mem: 20571\n",
      "Valid: [epoch:969] Total time: 0:00:00 (0.0465 s / it)\n",
      "Averaged stats: loss: 0.9877 (1.0017)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_969_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.002%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:970]  [  0/172]  eta: 0:07:43  lr: 0.000005  loss: 1.0004 (1.0004)  time: 2.6924  data: 1.1003  max mem: 20571\n",
      "Train: [epoch:970]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0316 (1.0426)  time: 1.6847  data: 0.1001  max mem: 20571\n",
      "Train: [epoch:970]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0529 (1.0597)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0440 (1.0621)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0309 (1.0522)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0309 (1.0543)  time: 1.5880  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0488 (1.0551)  time: 1.5867  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:970]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0418 (1.0527)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0508 (1.0528)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0508 (1.0513)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0392 (1.0503)  time: 1.5897  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0416 (1.0494)  time: 1.5897  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:970]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0416 (1.0493)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0423 (1.0496)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0203 (1.0471)  time: 1.5866  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:970]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0284 (1.0478)  time: 1.5839  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:970]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0623 (1.0482)  time: 1.5865  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:970]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0583 (1.0485)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0583 (1.0483)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:970] Total time: 0:04:34 (1.5940 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0583 (1.0483)\n",
      "Valid: [epoch:970]  [ 0/14]  eta: 0:00:04  loss: 1.0540 (1.0540)  time: 0.3449  data: 0.3300  max mem: 20571\n",
      "Valid: [epoch:970]  [13/14]  eta: 0:00:00  loss: 0.9883 (1.0030)  time: 0.0396  data: 0.0244  max mem: 20571\n",
      "Valid: [epoch:970] Total time: 0:00:00 (0.0477 s / it)\n",
      "Averaged stats: loss: 0.9883 (1.0030)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_970_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.003%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:971]  [  0/172]  eta: 0:07:29  lr: 0.000005  loss: 1.1281 (1.1281)  time: 2.6134  data: 1.0363  max mem: 20571\n",
      "Train: [epoch:971]  [ 10/172]  eta: 0:04:31  lr: 0.000005  loss: 1.0592 (1.0389)  time: 1.6740  data: 0.0944  max mem: 20571\n",
      "Train: [epoch:971]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0504 (1.0467)  time: 1.5826  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:971]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0302 (1.0403)  time: 1.5852  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:971]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0280 (1.0492)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [ 50/172]  eta: 0:03:15  lr: 0.000005  loss: 1.0483 (1.0488)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0483 (1.0482)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0222 (1.0455)  time: 1.5856  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:971]  [ 80/172]  eta: 0:02:26  lr: 0.000005  loss: 1.0303 (1.0440)  time: 1.5861  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:971]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0279 (1.0417)  time: 1.5852  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:971]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0279 (1.0451)  time: 1.5867  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:971]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0355 (1.0446)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0355 (1.0474)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0851 (1.0479)  time: 1.5901  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0550 (1.0478)  time: 1.5892  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0445 (1.0470)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0500 (1.0482)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0599 (1.0487)  time: 1.5909  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0496 (1.0487)  time: 1.5909  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:971] Total time: 0:04:34 (1.5937 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0496 (1.0487)\n",
      "Valid: [epoch:971]  [ 0/14]  eta: 0:00:05  loss: 1.0412 (1.0412)  time: 0.3605  data: 0.3446  max mem: 20571\n",
      "Valid: [epoch:971]  [13/14]  eta: 0:00:00  loss: 0.9899 (1.0043)  time: 0.0488  data: 0.0337  max mem: 20571\n",
      "Valid: [epoch:971] Total time: 0:00:00 (0.0563 s / it)\n",
      "Averaged stats: loss: 0.9899 (1.0043)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_971_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.004%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:972]  [  0/172]  eta: 0:07:55  lr: 0.000005  loss: 1.0221 (1.0221)  time: 2.7624  data: 1.1769  max mem: 20571\n",
      "Train: [epoch:972]  [ 10/172]  eta: 0:04:33  lr: 0.000005  loss: 1.0249 (1.0484)  time: 1.6913  data: 0.1071  max mem: 20571\n",
      "Train: [epoch:972]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0462 (1.0514)  time: 1.5853  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:972]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0414 (1.0483)  time: 1.5870  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:972]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0326 (1.0500)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0665 (1.0573)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0647 (1.0552)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0404 (1.0557)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0268 (1.0508)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0332 (1.0538)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0457 (1.0501)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0226 (1.0514)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0804 (1.0543)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0737 (1.0558)  time: 1.5851  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0438 (1.0548)  time: 1.5855  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0211 (1.0528)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0145 (1.0508)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0098 (1.0502)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0091 (1.0500)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:972] Total time: 0:04:34 (1.5932 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0091 (1.0500)\n",
      "Valid: [epoch:972]  [ 0/14]  eta: 0:00:06  loss: 1.0482 (1.0482)  time: 0.4654  data: 0.4483  max mem: 20571\n",
      "Valid: [epoch:972]  [13/14]  eta: 0:00:00  loss: 0.9907 (1.0051)  time: 0.0475  data: 0.0321  max mem: 20571\n",
      "Valid: [epoch:972] Total time: 0:00:00 (0.0550 s / it)\n",
      "Averaged stats: loss: 0.9907 (1.0051)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_972_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.005%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:973]  [  0/172]  eta: 0:08:02  lr: 0.000005  loss: 1.0082 (1.0082)  time: 2.8075  data: 1.2231  max mem: 20571\n",
      "Train: [epoch:973]  [ 10/172]  eta: 0:04:33  lr: 0.000005  loss: 1.0123 (1.0240)  time: 1.6912  data: 0.1113  max mem: 20571\n",
      "Train: [epoch:973]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0603 (1.0679)  time: 1.5816  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0396 (1.0524)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0180 (1.0484)  time: 1.5857  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:973]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0501 (1.0508)  time: 1.5850  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:973]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0596 (1.0510)  time: 1.5827  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:973]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0390 (1.0505)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0168 (1.0486)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0166 (1.0456)  time: 1.5810  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0399 (1.0484)  time: 1.5812  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0777 (1.0495)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0651 (1.0509)  time: 1.5820  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0575 (1.0490)  time: 1.5794  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0509 (1.0496)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [150/172]  eta: 0:00:34  lr: 0.000005  loss: 1.0670 (1.0504)  time: 1.5802  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0572 (1.0501)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0517 (1.0501)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0543 (1.0507)  time: 1.5831  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:973] Total time: 0:04:33 (1.5902 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0543 (1.0507)\n",
      "Valid: [epoch:973]  [ 0/14]  eta: 0:00:05  loss: 1.0569 (1.0569)  time: 0.4078  data: 0.3890  max mem: 20571\n",
      "Valid: [epoch:973]  [13/14]  eta: 0:00:00  loss: 0.9915 (1.0059)  time: 0.0438  data: 0.0284  max mem: 20571\n",
      "Valid: [epoch:973] Total time: 0:00:00 (0.0494 s / it)\n",
      "Averaged stats: loss: 0.9915 (1.0059)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_973_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.006%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:974]  [  0/172]  eta: 0:07:54  lr: 0.000005  loss: 1.0350 (1.0350)  time: 2.7613  data: 1.1836  max mem: 20571\n",
      "Train: [epoch:974]  [ 10/172]  eta: 0:04:33  lr: 0.000005  loss: 1.0525 (1.0412)  time: 1.6874  data: 0.1077  max mem: 20571\n",
      "Train: [epoch:974]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0566 (1.0538)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0502 (1.0488)  time: 1.5854  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0194 (1.0473)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0455 (1.0573)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0890 (1.0559)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0230 (1.0523)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0424 (1.0538)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0487 (1.0547)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0477 (1.0540)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0432 (1.0541)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0432 (1.0535)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0499 (1.0535)  time: 1.5837  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0589 (1.0552)  time: 1.5826  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0174 (1.0526)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0174 (1.0517)  time: 1.5880  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0428 (1.0514)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0428 (1.0515)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:974] Total time: 0:04:34 (1.5932 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0428 (1.0515)\n",
      "Valid: [epoch:974]  [ 0/14]  eta: 0:00:05  loss: 0.8975 (0.8975)  time: 0.3689  data: 0.3535  max mem: 20571\n",
      "Valid: [epoch:974]  [13/14]  eta: 0:00:00  loss: 0.9927 (1.0070)  time: 0.0493  data: 0.0342  max mem: 20571\n",
      "Valid: [epoch:974] Total time: 0:00:00 (0.0544 s / it)\n",
      "Averaged stats: loss: 0.9927 (1.0070)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_974_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.007%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:975]  [  0/172]  eta: 0:08:06  lr: 0.000005  loss: 1.0470 (1.0470)  time: 2.8291  data: 1.2372  max mem: 20571\n",
      "Train: [epoch:975]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0470 (1.0576)  time: 1.6939  data: 0.1126  max mem: 20571\n",
      "Train: [epoch:975]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0445 (1.0514)  time: 1.5806  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0438 (1.0455)  time: 1.5825  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0438 (1.0438)  time: 1.5853  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0456 (1.0442)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0418 (1.0448)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0303 (1.0432)  time: 1.5839  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0507 (1.0466)  time: 1.5847  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0394 (1.0443)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0079 (1.0446)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0395 (1.0461)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0655 (1.0503)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0655 (1.0513)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0251 (1.0513)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0332 (1.0505)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0453 (1.0508)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0595 (1.0540)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0595 (1.0540)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:975] Total time: 0:04:34 (1.5934 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0595 (1.0540)\n",
      "Valid: [epoch:975]  [ 0/14]  eta: 0:00:05  loss: 0.8989 (0.8989)  time: 0.3745  data: 0.3598  max mem: 20571\n",
      "Valid: [epoch:975]  [13/14]  eta: 0:00:00  loss: 0.9939 (1.0084)  time: 0.0420  data: 0.0269  max mem: 20571\n",
      "Valid: [epoch:975] Total time: 0:00:00 (0.0502 s / it)\n",
      "Averaged stats: loss: 0.9939 (1.0084)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_975_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.008%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:976]  [  0/172]  eta: 0:07:51  lr: 0.000005  loss: 0.9863 (0.9863)  time: 2.7439  data: 1.1718  max mem: 20571\n",
      "Train: [epoch:976]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0131 (1.0183)  time: 1.6933  data: 0.1066  max mem: 20571\n",
      "Train: [epoch:976]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0350 (1.0332)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0640 (1.0397)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0484 (1.0480)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0426 (1.0437)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0475 (1.0496)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0805 (1.0532)  time: 1.5850  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0477 (1.0523)  time: 1.5842  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0284 (1.0503)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0579 (1.0512)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0404 (1.0493)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0393 (1.0521)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0376 (1.0517)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0416 (1.0527)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0547 (1.0536)  time: 1.5880  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0656 (1.0552)  time: 1.5899  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0581 (1.0543)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0514 (1.0541)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:976] Total time: 0:04:34 (1.5945 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0514 (1.0541)\n",
      "Valid: [epoch:976]  [ 0/14]  eta: 0:00:05  loss: 1.0502 (1.0502)  time: 0.4037  data: 0.3882  max mem: 20571\n",
      "Valid: [epoch:976]  [13/14]  eta: 0:00:00  loss: 0.9952 (1.0089)  time: 0.0432  data: 0.0278  max mem: 20571\n",
      "Valid: [epoch:976] Total time: 0:00:00 (0.0489 s / it)\n",
      "Averaged stats: loss: 0.9952 (1.0089)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_976_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.009%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:977]  [  0/172]  eta: 0:07:54  lr: 0.000005  loss: 0.9849 (0.9849)  time: 2.7558  data: 1.1796  max mem: 20571\n",
      "Train: [epoch:977]  [ 10/172]  eta: 0:04:33  lr: 0.000005  loss: 1.0126 (1.0279)  time: 1.6893  data: 0.1074  max mem: 20571\n",
      "Train: [epoch:977]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0335 (1.0423)  time: 1.5849  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:977]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0584 (1.0512)  time: 1.5883  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:977]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0287 (1.0390)  time: 1.5912  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0240 (1.0439)  time: 1.5905  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:977]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0915 (1.0545)  time: 1.5878  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:977]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0700 (1.0556)  time: 1.5876  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:977]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0373 (1.0552)  time: 1.5875  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:977]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0492 (1.0553)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0448 (1.0547)  time: 1.5895  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0425 (1.0551)  time: 1.5921  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0498 (1.0552)  time: 1.5901  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0465 (1.0551)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0536 (1.0571)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0384 (1.0551)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0220 (1.0550)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0351 (1.0551)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0466 (1.0554)  time: 1.5897  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:977] Total time: 0:04:34 (1.5961 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0466 (1.0554)\n",
      "Valid: [epoch:977]  [ 0/14]  eta: 0:00:06  loss: 1.0518 (1.0518)  time: 0.4688  data: 0.4515  max mem: 20571\n",
      "Valid: [epoch:977]  [13/14]  eta: 0:00:00  loss: 0.9967 (1.0111)  time: 0.0480  data: 0.0325  max mem: 20571\n",
      "Valid: [epoch:977] Total time: 0:00:00 (0.0536 s / it)\n",
      "Averaged stats: loss: 0.9967 (1.0111)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_977_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.011%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:978]  [  0/172]  eta: 0:08:01  lr: 0.000005  loss: 1.0227 (1.0227)  time: 2.7989  data: 1.2194  max mem: 20571\n",
      "Train: [epoch:978]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0227 (1.0340)  time: 1.6959  data: 0.1110  max mem: 20571\n",
      "Train: [epoch:978]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0269 (1.0439)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0200 (1.0396)  time: 1.5880  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:978]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0388 (1.0470)  time: 1.5884  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:978]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0780 (1.0513)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0439 (1.0498)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0770 (1.0536)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0820 (1.0549)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0612 (1.0546)  time: 1.5880  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0427 (1.0547)  time: 1.5892  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0583 (1.0548)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0561 (1.0558)  time: 1.5892  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:978]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0636 (1.0577)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0706 (1.0579)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0445 (1.0554)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0368 (1.0558)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0435 (1.0562)  time: 1.5882  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:978]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0435 (1.0566)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:978] Total time: 0:04:34 (1.5957 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0435 (1.0566)\n",
      "Valid: [epoch:978]  [ 0/14]  eta: 0:00:06  loss: 0.9263 (0.9263)  time: 0.4972  data: 0.4776  max mem: 20571\n",
      "Valid: [epoch:978]  [13/14]  eta: 0:00:00  loss: 0.9962 (1.0108)  time: 0.0496  data: 0.0342  max mem: 20571\n",
      "Valid: [epoch:978] Total time: 0:00:00 (0.0577 s / it)\n",
      "Averaged stats: loss: 0.9962 (1.0108)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_978_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.011%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:979]  [  0/172]  eta: 0:08:06  lr: 0.000005  loss: 0.9805 (0.9805)  time: 2.8293  data: 1.2565  max mem: 20571\n",
      "Train: [epoch:979]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0542 (1.0528)  time: 1.6960  data: 0.1144  max mem: 20571\n",
      "Train: [epoch:979]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0416 (1.0535)  time: 1.5855  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:979]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0358 (1.0507)  time: 1.5874  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:979]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0455 (1.0544)  time: 1.5881  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:979]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0619 (1.0568)  time: 1.5882  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:979]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0603 (1.0586)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0479 (1.0552)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0271 (1.0543)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0548 (1.0576)  time: 1.5890  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0630 (1.0563)  time: 1.5901  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0202 (1.0545)  time: 1.5944  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0264 (1.0530)  time: 1.5950  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0276 (1.0523)  time: 1.5920  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0246 (1.0537)  time: 1.5911  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0565 (1.0549)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0801 (1.0556)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0834 (1.0571)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0834 (1.0573)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:979] Total time: 0:04:34 (1.5970 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0834 (1.0573)\n",
      "Valid: [epoch:979]  [ 0/14]  eta: 0:00:05  loss: 1.0604 (1.0604)  time: 0.3856  data: 0.3706  max mem: 20571\n",
      "Valid: [epoch:979]  [13/14]  eta: 0:00:00  loss: 0.9981 (1.0121)  time: 0.0521  data: 0.0370  max mem: 20571\n",
      "Valid: [epoch:979] Total time: 0:00:00 (0.0576 s / it)\n",
      "Averaged stats: loss: 0.9981 (1.0121)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_979_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.012%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:980]  [  0/172]  eta: 0:07:57  lr: 0.000005  loss: 1.1759 (1.1759)  time: 2.7736  data: 1.2002  max mem: 20571\n",
      "Train: [epoch:980]  [ 10/172]  eta: 0:04:33  lr: 0.000005  loss: 1.0677 (1.0788)  time: 1.6904  data: 0.1093  max mem: 20571\n",
      "Train: [epoch:980]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0677 (1.0819)  time: 1.5855  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:980]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0633 (1.0687)  time: 1.5870  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:980]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0350 (1.0617)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0567 (1.0700)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0567 (1.0655)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0264 (1.0636)  time: 1.5844  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0320 (1.0604)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0301 (1.0582)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0501 (1.0596)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0514 (1.0596)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0461 (1.0585)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0292 (1.0594)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0217 (1.0566)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0217 (1.0574)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0546 (1.0574)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:980]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0546 (1.0579)  time: 1.5873  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:980]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0633 (1.0583)  time: 1.5867  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:980] Total time: 0:04:34 (1.5933 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0633 (1.0583)\n",
      "Valid: [epoch:980]  [ 0/14]  eta: 0:00:06  loss: 0.9026 (0.9026)  time: 0.4466  data: 0.4302  max mem: 20571\n",
      "Valid: [epoch:980]  [13/14]  eta: 0:00:00  loss: 0.9990 (1.0133)  time: 0.0468  data: 0.0314  max mem: 20571\n",
      "Valid: [epoch:980] Total time: 0:00:00 (0.0545 s / it)\n",
      "Averaged stats: loss: 0.9990 (1.0133)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_980_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.013%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:981]  [  0/172]  eta: 0:07:37  lr: 0.000005  loss: 1.0744 (1.0744)  time: 2.6598  data: 1.0763  max mem: 20571\n",
      "Train: [epoch:981]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0651 (1.0495)  time: 1.6812  data: 0.0980  max mem: 20571\n",
      "Train: [epoch:981]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0401 (1.0553)  time: 1.5842  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:981]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0587 (1.0548)  time: 1.5866  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:981]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0607 (1.0572)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0607 (1.0579)  time: 1.5891  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0369 (1.0534)  time: 1.5881  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:981]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0492 (1.0597)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0848 (1.0625)  time: 1.5895  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0653 (1.0630)  time: 1.5901  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:981]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0547 (1.0628)  time: 1.5902  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0524 (1.0617)  time: 1.5922  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:981]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0557 (1.0624)  time: 1.5904  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0313 (1.0609)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0302 (1.0603)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0196 (1.0580)  time: 1.5892  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0378 (1.0584)  time: 1.5915  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0669 (1.0599)  time: 1.5915  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0669 (1.0602)  time: 1.5912  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:981] Total time: 0:04:34 (1.5959 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0669 (1.0602)\n",
      "Valid: [epoch:981]  [ 0/14]  eta: 0:00:04  loss: 0.9956 (0.9956)  time: 0.2890  data: 0.2717  max mem: 20571\n",
      "Valid: [epoch:981]  [13/14]  eta: 0:00:00  loss: 0.9992 (1.0137)  time: 0.0525  data: 0.0371  max mem: 20571\n",
      "Valid: [epoch:981] Total time: 0:00:00 (0.0611 s / it)\n",
      "Averaged stats: loss: 0.9992 (1.0137)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_981_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.014%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:982]  [  0/172]  eta: 0:08:35  lr: 0.000005  loss: 1.0003 (1.0003)  time: 2.9975  data: 1.4101  max mem: 20571\n",
      "Train: [epoch:982]  [ 10/172]  eta: 0:04:38  lr: 0.000005  loss: 1.0356 (1.0469)  time: 1.7161  data: 0.1284  max mem: 20571\n",
      "Train: [epoch:982]  [ 20/172]  eta: 0:04:11  lr: 0.000005  loss: 1.0448 (1.0581)  time: 1.5880  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:982]  [ 30/172]  eta: 0:03:51  lr: 0.000005  loss: 1.0448 (1.0623)  time: 1.5881  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:982]  [ 40/172]  eta: 0:03:34  lr: 0.000005  loss: 1.0566 (1.0588)  time: 1.5889  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:982]  [ 50/172]  eta: 0:03:17  lr: 0.000005  loss: 1.0547 (1.0595)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0566 (1.0619)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0661 (1.0606)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0349 (1.0631)  time: 1.5843  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0357 (1.0614)  time: 1.5855  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:982]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0357 (1.0628)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0743 (1.0641)  time: 1.5880  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0725 (1.0637)  time: 1.5846  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0761 (1.0672)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0564 (1.0641)  time: 1.5821  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0325 (1.0629)  time: 1.5819  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0395 (1.0605)  time: 1.5840  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0465 (1.0608)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0478 (1.0611)  time: 1.5824  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:982] Total time: 0:04:34 (1.5944 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0478 (1.0611)\n",
      "Valid: [epoch:982]  [ 0/14]  eta: 0:00:04  loss: 1.0586 (1.0586)  time: 0.3479  data: 0.3329  max mem: 20571\n",
      "Valid: [epoch:982]  [13/14]  eta: 0:00:00  loss: 1.0015 (1.0159)  time: 0.0401  data: 0.0250  max mem: 20571\n",
      "Valid: [epoch:982] Total time: 0:00:00 (0.0473 s / it)\n",
      "Averaged stats: loss: 1.0015 (1.0159)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_982_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.016%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:983]  [  0/172]  eta: 0:07:36  lr: 0.000005  loss: 1.0745 (1.0745)  time: 2.6558  data: 1.0642  max mem: 20571\n",
      "Train: [epoch:983]  [ 10/172]  eta: 0:04:31  lr: 0.000005  loss: 1.0489 (1.0604)  time: 1.6743  data: 0.0969  max mem: 20571\n",
      "Train: [epoch:983]  [ 20/172]  eta: 0:04:07  lr: 0.000005  loss: 1.0489 (1.0699)  time: 1.5778  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0414 (1.0618)  time: 1.5797  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [ 40/172]  eta: 0:03:31  lr: 0.000005  loss: 1.0379 (1.0599)  time: 1.5811  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:983]  [ 50/172]  eta: 0:03:15  lr: 0.000005  loss: 1.0576 (1.0574)  time: 1.5809  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [ 60/172]  eta: 0:02:58  lr: 0.000005  loss: 1.0314 (1.0530)  time: 1.5791  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [ 70/172]  eta: 0:02:42  lr: 0.000005  loss: 1.0425 (1.0595)  time: 1.5789  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [ 80/172]  eta: 0:02:26  lr: 0.000005  loss: 1.0512 (1.0608)  time: 1.5793  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [ 90/172]  eta: 0:02:10  lr: 0.000005  loss: 1.0363 (1.0574)  time: 1.5818  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0223 (1.0550)  time: 1.5836  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0332 (1.0542)  time: 1.5828  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0415 (1.0539)  time: 1.5814  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:983]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0482 (1.0559)  time: 1.5817  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [140/172]  eta: 0:00:50  lr: 0.000005  loss: 1.0582 (1.0556)  time: 1.5820  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:983]  [150/172]  eta: 0:00:34  lr: 0.000005  loss: 1.0635 (1.0584)  time: 1.5834  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0511 (1.0582)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0628 (1.0607)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0628 (1.0606)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:983] Total time: 0:04:33 (1.5886 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0628 (1.0606)\n",
      "Valid: [epoch:983]  [ 0/14]  eta: 0:00:04  loss: 1.0658 (1.0658)  time: 0.2962  data: 0.2808  max mem: 20571\n",
      "Valid: [epoch:983]  [13/14]  eta: 0:00:00  loss: 1.0024 (1.0166)  time: 0.0383  data: 0.0230  max mem: 20571\n",
      "Valid: [epoch:983] Total time: 0:00:00 (0.0461 s / it)\n",
      "Averaged stats: loss: 1.0024 (1.0166)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_983_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.017%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:984]  [  0/172]  eta: 0:07:33  lr: 0.000005  loss: 1.1940 (1.1940)  time: 2.6367  data: 1.0684  max mem: 20571\n",
      "Train: [epoch:984]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0571 (1.0606)  time: 1.6792  data: 0.0972  max mem: 20571\n",
      "Train: [epoch:984]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0421 (1.0468)  time: 1.5855  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:984]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0412 (1.0454)  time: 1.5867  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:984]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0622 (1.0486)  time: 1.5864  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:984]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0622 (1.0529)  time: 1.5868  data: 0.0002  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:984]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0544 (1.0569)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0544 (1.0622)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0462 (1.0619)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0458 (1.0626)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0426 (1.0625)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0368 (1.0630)  time: 1.5892  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0602 (1.0627)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0580 (1.0613)  time: 1.5880  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0580 (1.0632)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0510 (1.0615)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0476 (1.0623)  time: 1.5898  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0668 (1.0624)  time: 1.5899  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0716 (1.0629)  time: 1.5899  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:984] Total time: 0:04:34 (1.5944 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0716 (1.0629)\n",
      "Valid: [epoch:984]  [ 0/14]  eta: 0:00:04  loss: 1.0543 (1.0543)  time: 0.3271  data: 0.3091  max mem: 20571\n",
      "Valid: [epoch:984]  [13/14]  eta: 0:00:00  loss: 1.0036 (1.0175)  time: 0.0397  data: 0.0241  max mem: 20571\n",
      "Valid: [epoch:984] Total time: 0:00:00 (0.0453 s / it)\n",
      "Averaged stats: loss: 1.0036 (1.0175)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_984_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.018%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:985]  [  0/172]  eta: 0:08:09  lr: 0.000005  loss: 1.0234 (1.0234)  time: 2.8439  data: 1.2589  max mem: 20571\n",
      "Train: [epoch:985]  [ 10/172]  eta: 0:04:35  lr: 0.000005  loss: 1.0704 (1.0614)  time: 1.6990  data: 0.1145  max mem: 20571\n",
      "Train: [epoch:985]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0748 (1.0735)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0922 (1.0783)  time: 1.5863  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:985]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0479 (1.0671)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0438 (1.0677)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0580 (1.0641)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0122 (1.0586)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0341 (1.0597)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0663 (1.0643)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0769 (1.0653)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0522 (1.0636)  time: 1.5895  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0568 (1.0653)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0689 (1.0678)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0772 (1.0674)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0588 (1.0652)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0427 (1.0643)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0432 (1.0647)  time: 1.5904  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0432 (1.0642)  time: 1.5901  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:985] Total time: 0:04:34 (1.5955 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0432 (1.0642)\n",
      "Valid: [epoch:985]  [ 0/14]  eta: 0:00:04  loss: 1.0593 (1.0593)  time: 0.3183  data: 0.3016  max mem: 20571\n",
      "Valid: [epoch:985]  [13/14]  eta: 0:00:00  loss: 1.0043 (1.0184)  time: 0.0375  data: 0.0221  max mem: 20571\n",
      "Valid: [epoch:985] Total time: 0:00:00 (0.0426 s / it)\n",
      "Averaged stats: loss: 1.0043 (1.0184)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_985_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.018%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:986]  [  0/172]  eta: 0:08:34  lr: 0.000005  loss: 1.0838 (1.0838)  time: 2.9898  data: 1.4146  max mem: 20571\n",
      "Train: [epoch:986]  [ 10/172]  eta: 0:04:37  lr: 0.000005  loss: 1.0683 (1.0699)  time: 1.7137  data: 0.1287  max mem: 20571\n",
      "Train: [epoch:986]  [ 20/172]  eta: 0:04:11  lr: 0.000005  loss: 1.0638 (1.0677)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [ 30/172]  eta: 0:03:51  lr: 0.000005  loss: 1.0602 (1.0713)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [ 40/172]  eta: 0:03:34  lr: 0.000005  loss: 1.0602 (1.0714)  time: 1.5900  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [ 50/172]  eta: 0:03:17  lr: 0.000005  loss: 1.0707 (1.0710)  time: 1.5900  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0818 (1.0726)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [ 70/172]  eta: 0:02:44  lr: 0.000005  loss: 1.0490 (1.0696)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0433 (1.0681)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0520 (1.0671)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0666 (1.0679)  time: 1.5898  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0560 (1.0643)  time: 1.5914  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0395 (1.0657)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0778 (1.0661)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0362 (1.0637)  time: 1.5881  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:986]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0362 (1.0631)  time: 1.5882  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:986]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0690 (1.0643)  time: 1.5907  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0661 (1.0644)  time: 1.5916  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0690 (1.0649)  time: 1.5922  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:986] Total time: 0:04:34 (1.5979 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0690 (1.0649)\n",
      "Valid: [epoch:986]  [ 0/14]  eta: 0:00:04  loss: 0.9843 (0.9843)  time: 0.3180  data: 0.3014  max mem: 20571\n",
      "Valid: [epoch:986]  [13/14]  eta: 0:00:00  loss: 1.0058 (1.0192)  time: 0.0401  data: 0.0247  max mem: 20571\n",
      "Valid: [epoch:986] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 1.0058 (1.0192)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_986_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.019%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:987]  [  0/172]  eta: 0:08:04  lr: 0.000005  loss: 1.0524 (1.0524)  time: 2.8162  data: 1.2305  max mem: 20571\n",
      "Train: [epoch:987]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0524 (1.0531)  time: 1.6945  data: 0.1120  max mem: 20571\n",
      "Train: [epoch:987]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0405 (1.0525)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0405 (1.0547)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0605 (1.0541)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0551 (1.0542)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0598 (1.0536)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0693 (1.0567)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0772 (1.0599)  time: 1.5838  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0897 (1.0616)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0259 (1.0605)  time: 1.5899  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0754 (1.0658)  time: 1.5911  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.1012 (1.0680)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0655 (1.0680)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0437 (1.0675)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0243 (1.0653)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0348 (1.0660)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0597 (1.0658)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0597 (1.0659)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:987] Total time: 0:04:34 (1.5954 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0597 (1.0659)\n",
      "Valid: [epoch:987]  [ 0/14]  eta: 0:00:07  loss: 0.9557 (0.9557)  time: 0.5538  data: 0.5373  max mem: 20571\n",
      "Valid: [epoch:987]  [13/14]  eta: 0:00:00  loss: 1.0063 (1.0201)  time: 0.0546  data: 0.0393  max mem: 20571\n",
      "Valid: [epoch:987] Total time: 0:00:00 (0.0628 s / it)\n",
      "Averaged stats: loss: 1.0063 (1.0201)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_987_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.020%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:988]  [  0/172]  eta: 0:07:46  lr: 0.000005  loss: 1.1032 (1.1032)  time: 2.7123  data: 1.1235  max mem: 20571\n",
      "Train: [epoch:988]  [ 10/172]  eta: 0:04:33  lr: 0.000005  loss: 1.0781 (1.0717)  time: 1.6901  data: 0.1023  max mem: 20571\n",
      "Train: [epoch:988]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0781 (1.0936)  time: 1.5877  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:988]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0759 (1.0770)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0278 (1.0671)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0400 (1.0668)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0694 (1.0667)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0544 (1.0636)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0263 (1.0607)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0427 (1.0632)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0686 (1.0634)  time: 1.5901  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0709 (1.0636)  time: 1.5905  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0493 (1.0626)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0363 (1.0634)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0656 (1.0638)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0749 (1.0657)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0919 (1.0669)  time: 1.5911  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0919 (1.0665)  time: 1.5903  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0919 (1.0668)  time: 1.5902  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:988] Total time: 0:04:34 (1.5964 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0919 (1.0668)\n",
      "Valid: [epoch:988]  [ 0/14]  eta: 0:00:04  loss: 1.0039 (1.0039)  time: 0.2967  data: 0.2815  max mem: 20571\n",
      "Valid: [epoch:988]  [13/14]  eta: 0:00:00  loss: 1.0074 (1.0214)  time: 0.0377  data: 0.0224  max mem: 20571\n",
      "Valid: [epoch:988] Total time: 0:00:00 (0.0456 s / it)\n",
      "Averaged stats: loss: 1.0074 (1.0214)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_988_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.021%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:989]  [  0/172]  eta: 0:07:39  lr: 0.000005  loss: 1.0962 (1.0962)  time: 2.6729  data: 1.0803  max mem: 20571\n",
      "Train: [epoch:989]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0471 (1.0413)  time: 1.6840  data: 0.0983  max mem: 20571\n",
      "Train: [epoch:989]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0471 (1.0519)  time: 1.5858  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:989]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0648 (1.0607)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0816 (1.0667)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0910 (1.0674)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0831 (1.0732)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0722 (1.0706)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0312 (1.0641)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0449 (1.0663)  time: 1.5878  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0515 (1.0630)  time: 1.5892  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0439 (1.0647)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0607 (1.0671)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0607 (1.0666)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0614 (1.0675)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0623 (1.0679)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0623 (1.0666)  time: 1.5929  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0655 (1.0673)  time: 1.5925  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:989]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0674 (1.0676)  time: 1.5917  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:989] Total time: 0:04:34 (1.5951 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0674 (1.0676)\n",
      "Valid: [epoch:989]  [ 0/14]  eta: 0:00:04  loss: 1.0659 (1.0659)  time: 0.2911  data: 0.2744  max mem: 20571\n",
      "Valid: [epoch:989]  [13/14]  eta: 0:00:00  loss: 1.0072 (1.0220)  time: 0.0436  data: 0.0280  max mem: 20571\n",
      "Valid: [epoch:989] Total time: 0:00:00 (0.0512 s / it)\n",
      "Averaged stats: loss: 1.0072 (1.0220)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_989_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.022%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:990]  [  0/172]  eta: 0:08:12  lr: 0.000005  loss: 1.0339 (1.0339)  time: 2.8612  data: 1.2889  max mem: 20571\n",
      "Train: [epoch:990]  [ 10/172]  eta: 0:04:35  lr: 0.000005  loss: 1.0817 (1.0663)  time: 1.7034  data: 0.1173  max mem: 20571\n",
      "Train: [epoch:990]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0796 (1.0682)  time: 1.5876  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:990]  [ 30/172]  eta: 0:03:51  lr: 0.000005  loss: 1.0530 (1.0589)  time: 1.5871  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:990]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0465 (1.0569)  time: 1.5899  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:990]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0677 (1.0672)  time: 1.5925  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0764 (1.0658)  time: 1.5901  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0420 (1.0642)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0636 (1.0667)  time: 1.5894  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0684 (1.0673)  time: 1.5899  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0656 (1.0689)  time: 1.5908  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0656 (1.0691)  time: 1.5928  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:990]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0614 (1.0710)  time: 1.5906  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:990]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0974 (1.0747)  time: 1.5894  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:990]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0783 (1.0729)  time: 1.5911  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0335 (1.0714)  time: 1.5923  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0664 (1.0712)  time: 1.5921  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0365 (1.0691)  time: 1.5906  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0365 (1.0698)  time: 1.5907  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:990] Total time: 0:04:34 (1.5984 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0365 (1.0698)\n",
      "Valid: [epoch:990]  [ 0/14]  eta: 0:00:05  loss: 1.0643 (1.0643)  time: 0.3925  data: 0.3729  max mem: 20571\n",
      "Valid: [epoch:990]  [13/14]  eta: 0:00:00  loss: 1.0085 (1.0234)  time: 0.0434  data: 0.0280  max mem: 20571\n",
      "Valid: [epoch:990] Total time: 0:00:00 (0.0485 s / it)\n",
      "Averaged stats: loss: 1.0085 (1.0234)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_990_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.023%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:991]  [  0/172]  eta: 0:08:21  lr: 0.000005  loss: 1.0513 (1.0513)  time: 2.9168  data: 1.3379  max mem: 20571\n",
      "Train: [epoch:991]  [ 10/172]  eta: 0:04:36  lr: 0.000005  loss: 1.0513 (1.0561)  time: 1.7079  data: 0.1218  max mem: 20571\n",
      "Train: [epoch:991]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0570 (1.0731)  time: 1.5869  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:991]  [ 30/172]  eta: 0:03:51  lr: 0.000005  loss: 1.0757 (1.0695)  time: 1.5882  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:991]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0490 (1.0646)  time: 1.5902  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:991]  [ 50/172]  eta: 0:03:17  lr: 0.000005  loss: 1.0496 (1.0668)  time: 1.5910  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0435 (1.0613)  time: 1.5899  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0435 (1.0614)  time: 1.5879  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:991]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0624 (1.0643)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0499 (1.0620)  time: 1.5891  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0663 (1.0636)  time: 1.5900  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0710 (1.0622)  time: 1.5903  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0604 (1.0656)  time: 1.5906  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0662 (1.0652)  time: 1.5924  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0589 (1.0655)  time: 1.5902  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0697 (1.0682)  time: 1.5895  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0829 (1.0686)  time: 1.5911  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0780 (1.0703)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0612 (1.0701)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:991] Total time: 0:04:34 (1.5979 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0612 (1.0701)\n",
      "Valid: [epoch:991]  [ 0/14]  eta: 0:00:04  loss: 0.9601 (0.9601)  time: 0.3182  data: 0.3030  max mem: 20571\n",
      "Valid: [epoch:991]  [13/14]  eta: 0:00:00  loss: 1.0097 (1.0240)  time: 0.0487  data: 0.0335  max mem: 20571\n",
      "Valid: [epoch:991] Total time: 0:00:00 (0.0570 s / it)\n",
      "Averaged stats: loss: 1.0097 (1.0240)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_991_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.024%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:992]  [  0/172]  eta: 0:08:18  lr: 0.000005  loss: 1.0102 (1.0102)  time: 2.8958  data: 1.3185  max mem: 20571\n",
      "Train: [epoch:992]  [ 10/172]  eta: 0:04:35  lr: 0.000005  loss: 1.0442 (1.0561)  time: 1.7035  data: 0.1200  max mem: 20571\n",
      "Train: [epoch:992]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0472 (1.0478)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [ 30/172]  eta: 0:03:51  lr: 0.000005  loss: 1.0625 (1.0563)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0603 (1.0542)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0603 (1.0600)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0628 (1.0633)  time: 1.5887  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:992]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0650 (1.0670)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0857 (1.0670)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0548 (1.0644)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0465 (1.0631)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0525 (1.0614)  time: 1.5886  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:992]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0886 (1.0671)  time: 1.5848  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.1179 (1.0687)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0774 (1.0697)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0774 (1.0710)  time: 1.5870  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:992]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0711 (1.0695)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0606 (1.0706)  time: 1.5896  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0606 (1.0707)  time: 1.5894  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:992] Total time: 0:04:34 (1.5957 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0606 (1.0707)\n",
      "Valid: [epoch:992]  [ 0/14]  eta: 0:00:05  loss: 1.0666 (1.0666)  time: 0.4155  data: 0.3983  max mem: 20571\n",
      "Valid: [epoch:992]  [13/14]  eta: 0:00:00  loss: 1.0105 (1.0250)  time: 0.0457  data: 0.0303  max mem: 20571\n",
      "Valid: [epoch:992] Total time: 0:00:00 (0.0509 s / it)\n",
      "Averaged stats: loss: 1.0105 (1.0250)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_992_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.025%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:993]  [  0/172]  eta: 0:07:41  lr: 0.000005  loss: 0.9929 (0.9929)  time: 2.6821  data: 1.0853  max mem: 20571\n",
      "Train: [epoch:993]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0963 (1.0802)  time: 1.6841  data: 0.0988  max mem: 20571\n",
      "Train: [epoch:993]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0963 (1.1013)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0906 (1.0918)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0575 (1.0847)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0589 (1.0821)  time: 1.5890  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0589 (1.0730)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0568 (1.0724)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0652 (1.0752)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0601 (1.0749)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0601 (1.0770)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0610 (1.0736)  time: 1.5915  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0638 (1.0727)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0757 (1.0719)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0559 (1.0701)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0669 (1.0711)  time: 1.5856  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0788 (1.0706)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0853 (1.0724)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0931 (1.0727)  time: 1.5884  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:993] Total time: 0:04:34 (1.5943 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0931 (1.0727)\n",
      "Valid: [epoch:993]  [ 0/14]  eta: 0:00:05  loss: 0.9914 (0.9914)  time: 0.3645  data: 0.3495  max mem: 20571\n",
      "Valid: [epoch:993]  [13/14]  eta: 0:00:00  loss: 1.0118 (1.0266)  time: 0.0422  data: 0.0270  max mem: 20571\n",
      "Valid: [epoch:993] Total time: 0:00:00 (0.0484 s / it)\n",
      "Averaged stats: loss: 1.0118 (1.0266)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_993_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.027%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:994]  [  0/172]  eta: 0:07:53  lr: 0.000005  loss: 0.9827 (0.9827)  time: 2.7537  data: 1.1594  max mem: 20571\n",
      "Train: [epoch:994]  [ 10/172]  eta: 0:04:35  lr: 0.000005  loss: 1.0749 (1.0852)  time: 1.6983  data: 0.1056  max mem: 20571\n",
      "Train: [epoch:994]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0942 (1.0856)  time: 1.5903  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:994]  [ 30/172]  eta: 0:03:51  lr: 0.000005  loss: 1.0589 (1.0750)  time: 1.5901  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:994]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0285 (1.0694)  time: 1.5909  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:994]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0285 (1.0643)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0723 (1.0702)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0657 (1.0676)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0474 (1.0707)  time: 1.5883  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:994]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0707 (1.0736)  time: 1.5900  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:994]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0685 (1.0732)  time: 1.5906  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0668 (1.0730)  time: 1.5922  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0670 (1.0757)  time: 1.5909  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0670 (1.0767)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0627 (1.0762)  time: 1.5882  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0661 (1.0761)  time: 1.5899  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0576 (1.0736)  time: 1.5927  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0576 (1.0729)  time: 1.5912  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0625 (1.0729)  time: 1.5911  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:994] Total time: 0:04:34 (1.5974 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0625 (1.0729)\n",
      "Valid: [epoch:994]  [ 0/14]  eta: 0:00:05  loss: 0.9921 (0.9921)  time: 0.3960  data: 0.3801  max mem: 20571\n",
      "Valid: [epoch:994]  [13/14]  eta: 0:00:00  loss: 1.0130 (1.0271)  time: 0.0582  data: 0.0428  max mem: 20571\n",
      "Valid: [epoch:994] Total time: 0:00:00 (0.0662 s / it)\n",
      "Averaged stats: loss: 1.0130 (1.0271)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_994_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.027%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:995]  [  0/172]  eta: 0:07:53  lr: 0.000005  loss: 1.0689 (1.0689)  time: 2.7504  data: 1.1698  max mem: 20571\n",
      "Train: [epoch:995]  [ 10/172]  eta: 0:04:33  lr: 0.000005  loss: 1.0738 (1.0936)  time: 1.6875  data: 0.1065  max mem: 20571\n",
      "Train: [epoch:995]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0556 (1.0691)  time: 1.5834  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:995]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0377 (1.0608)  time: 1.5871  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0454 (1.0637)  time: 1.5888  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0761 (1.0718)  time: 1.5901  data: 0.0001  max mem: 20571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:995]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0896 (1.0744)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0718 (1.0718)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0435 (1.0706)  time: 1.5898  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:995]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0390 (1.0682)  time: 1.5903  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0347 (1.0674)  time: 1.5902  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0613 (1.0709)  time: 1.5891  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0738 (1.0737)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0738 (1.0738)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0648 (1.0729)  time: 1.5883  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0638 (1.0743)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0692 (1.0744)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0538 (1.0741)  time: 1.5886  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0506 (1.0737)  time: 1.5889  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:995] Total time: 0:04:34 (1.5955 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0506 (1.0737)\n",
      "Valid: [epoch:995]  [ 0/14]  eta: 0:00:05  loss: 0.9426 (0.9426)  time: 0.4070  data: 0.3908  max mem: 20571\n",
      "Valid: [epoch:995]  [13/14]  eta: 0:00:00  loss: 1.0139 (1.0283)  time: 0.0433  data: 0.0281  max mem: 20571\n",
      "Valid: [epoch:995] Total time: 0:00:00 (0.0481 s / it)\n",
      "Averaged stats: loss: 1.0139 (1.0283)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_995_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.028%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:996]  [  0/172]  eta: 0:07:20  lr: 0.000005  loss: 1.1257 (1.1257)  time: 2.5623  data: 0.9769  max mem: 20571\n",
      "Train: [epoch:996]  [ 10/172]  eta: 0:04:31  lr: 0.000005  loss: 1.0726 (1.0879)  time: 1.6758  data: 0.0889  max mem: 20571\n",
      "Train: [epoch:996]  [ 20/172]  eta: 0:04:08  lr: 0.000005  loss: 1.0631 (1.0889)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [ 30/172]  eta: 0:03:49  lr: 0.000005  loss: 1.0549 (1.0790)  time: 1.5881  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [ 40/172]  eta: 0:03:32  lr: 0.000005  loss: 1.0433 (1.0666)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0528 (1.0659)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0671 (1.0677)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0914 (1.0744)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0999 (1.0716)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0489 (1.0707)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [100/172]  eta: 0:01:54  lr: 0.000005  loss: 1.0558 (1.0704)  time: 1.5870  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:996]  [110/172]  eta: 0:01:38  lr: 0.000005  loss: 1.0429 (1.0690)  time: 1.5879  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0742 (1.0718)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [130/172]  eta: 0:01:06  lr: 0.000005  loss: 1.0749 (1.0693)  time: 1.5869  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0461 (1.0698)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0760 (1.0721)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0997 (1.0741)  time: 1.5885  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.1004 (1.0753)  time: 1.5897  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.1091 (1.0761)  time: 1.5891  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:996] Total time: 0:04:34 (1.5935 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.1091 (1.0761)\n",
      "Valid: [epoch:996]  [ 0/14]  eta: 0:00:05  loss: 1.0705 (1.0705)  time: 0.3794  data: 0.3631  max mem: 20571\n",
      "Valid: [epoch:996]  [13/14]  eta: 0:00:00  loss: 1.0152 (1.0289)  time: 0.0412  data: 0.0261  max mem: 20571\n",
      "Valid: [epoch:996] Total time: 0:00:00 (0.0492 s / it)\n",
      "Averaged stats: loss: 1.0152 (1.0289)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_996_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.029%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:997]  [  0/172]  eta: 0:07:57  lr: 0.000005  loss: 1.1108 (1.1108)  time: 2.7789  data: 1.2038  max mem: 20571\n",
      "Train: [epoch:997]  [ 10/172]  eta: 0:04:34  lr: 0.000005  loss: 1.0686 (1.0905)  time: 1.6915  data: 0.1095  max mem: 20571\n",
      "Train: [epoch:997]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0558 (1.0878)  time: 1.5833  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0558 (1.0844)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0326 (1.0723)  time: 1.5876  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0305 (1.0672)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [ 60/172]  eta: 0:02:59  lr: 0.000005  loss: 1.0671 (1.0736)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0778 (1.0723)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0770 (1.0733)  time: 1.5859  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0622 (1.0731)  time: 1.5864  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0552 (1.0732)  time: 1.5877  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0552 (1.0716)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [120/172]  eta: 0:01:22  lr: 0.000005  loss: 1.0981 (1.0761)  time: 1.5841  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.1015 (1.0758)  time: 1.5857  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0738 (1.0759)  time: 1.5865  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0569 (1.0745)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0766 (1.0749)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0766 (1.0759)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0766 (1.0762)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:997] Total time: 0:04:34 (1.5937 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0766 (1.0762)\n",
      "Valid: [epoch:997]  [ 0/14]  eta: 0:00:04  loss: 1.0799 (1.0799)  time: 0.2891  data: 0.2722  max mem: 20571\n",
      "Valid: [epoch:997]  [13/14]  eta: 0:00:00  loss: 1.0157 (1.0299)  time: 0.0380  data: 0.0228  max mem: 20571\n",
      "Valid: [epoch:997] Total time: 0:00:00 (0.0451 s / it)\n",
      "Averaged stats: loss: 1.0157 (1.0299)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_997_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.030%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:998]  [  0/172]  eta: 0:08:12  lr: 0.000005  loss: 1.1658 (1.1658)  time: 2.8623  data: 1.2789  max mem: 20571\n",
      "Train: [epoch:998]  [ 10/172]  eta: 0:04:35  lr: 0.000005  loss: 1.0812 (1.0910)  time: 1.7016  data: 0.1164  max mem: 20571\n",
      "Train: [epoch:998]  [ 20/172]  eta: 0:04:10  lr: 0.000005  loss: 1.0660 (1.0868)  time: 1.5862  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [ 30/172]  eta: 0:03:51  lr: 0.000005  loss: 1.0927 (1.0931)  time: 1.5872  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0767 (1.0827)  time: 1.5868  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0616 (1.0807)  time: 1.5861  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0675 (1.0817)  time: 1.5860  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:998]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0489 (1.0774)  time: 1.5847  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:998]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0275 (1.0790)  time: 1.5852  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0762 (1.0786)  time: 1.5863  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0821 (1.0802)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0887 (1.0801)  time: 1.5893  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0368 (1.0758)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0368 (1.0747)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0504 (1.0721)  time: 1.5866  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0515 (1.0740)  time: 1.5849  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0705 (1.0738)  time: 1.5887  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.1062 (1.0767)  time: 1.5904  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.1062 (1.0769)  time: 1.5904  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:998] Total time: 0:04:34 (1.5951 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.1062 (1.0769)\n",
      "Valid: [epoch:998]  [ 0/14]  eta: 0:00:06  loss: 0.9456 (0.9456)  time: 0.4630  data: 0.4463  max mem: 20571\n",
      "Valid: [epoch:998]  [13/14]  eta: 0:00:00  loss: 1.0170 (1.0315)  time: 0.0484  data: 0.0332  max mem: 20571\n",
      "Valid: [epoch:998] Total time: 0:00:00 (0.0563 s / it)\n",
      "Averaged stats: loss: 1.0170 (1.0315)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_998_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.032%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Train: [epoch:999]  [  0/172]  eta: 0:07:33  lr: 0.000005  loss: 1.0795 (1.0795)  time: 2.6369  data: 1.0583  max mem: 20571\n",
      "Train: [epoch:999]  [ 10/172]  eta: 0:04:32  lr: 0.000005  loss: 1.0696 (1.0663)  time: 1.6796  data: 0.0964  max mem: 20571\n",
      "Train: [epoch:999]  [ 20/172]  eta: 0:04:09  lr: 0.000005  loss: 1.0696 (1.0732)  time: 1.5885  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:999]  [ 30/172]  eta: 0:03:50  lr: 0.000005  loss: 1.0669 (1.0696)  time: 1.5915  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999]  [ 40/172]  eta: 0:03:33  lr: 0.000005  loss: 1.0669 (1.0725)  time: 1.5938  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999]  [ 50/172]  eta: 0:03:16  lr: 0.000005  loss: 1.0761 (1.0792)  time: 1.5945  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999]  [ 60/172]  eta: 0:03:00  lr: 0.000005  loss: 1.0610 (1.0766)  time: 1.5904  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999]  [ 70/172]  eta: 0:02:43  lr: 0.000005  loss: 1.0667 (1.0811)  time: 1.5892  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:999]  [ 80/172]  eta: 0:02:27  lr: 0.000005  loss: 1.0689 (1.0791)  time: 1.5896  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:999]  [ 90/172]  eta: 0:02:11  lr: 0.000005  loss: 1.0528 (1.0769)  time: 1.5880  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:999]  [100/172]  eta: 0:01:55  lr: 0.000005  loss: 1.0703 (1.0778)  time: 1.5873  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:999]  [110/172]  eta: 0:01:39  lr: 0.000005  loss: 1.0704 (1.0785)  time: 1.5890  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:999]  [120/172]  eta: 0:01:23  lr: 0.000005  loss: 1.0657 (1.0782)  time: 1.5877  data: 0.0002  max mem: 20571\n",
      "Train: [epoch:999]  [130/172]  eta: 0:01:07  lr: 0.000005  loss: 1.0645 (1.0781)  time: 1.5874  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999]  [140/172]  eta: 0:00:51  lr: 0.000005  loss: 1.0461 (1.0756)  time: 1.5867  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999]  [150/172]  eta: 0:00:35  lr: 0.000005  loss: 1.0651 (1.0776)  time: 1.5858  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999]  [160/172]  eta: 0:00:19  lr: 0.000005  loss: 1.0913 (1.0790)  time: 1.5873  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999]  [170/172]  eta: 0:00:03  lr: 0.000005  loss: 1.0913 (1.0781)  time: 1.5875  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999]  [171/172]  eta: 0:00:01  lr: 0.000005  loss: 1.0854 (1.0781)  time: 1.5870  data: 0.0001  max mem: 20571\n",
      "Train: [epoch:999] Total time: 0:04:34 (1.5958 s / it)\n",
      "Averaged stats: lr: 0.000005  loss: 1.0854 (1.0781)\n",
      "Valid: [epoch:999]  [ 0/14]  eta: 0:00:04  loss: 1.0835 (1.0835)  time: 0.3429  data: 0.3265  max mem: 20571\n",
      "Valid: [epoch:999]  [13/14]  eta: 0:00:00  loss: 1.0176 (1.0318)  time: 0.0431  data: 0.0279  max mem: 20571\n",
      "Valid: [epoch:999] Total time: 0:00:00 (0.0482 s / it)\n",
      "Averaged stats: loss: 1.0176 (1.0318)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/epoch_999_input_n_20.png\n",
      "loss of the network on the 14 valid images: 1.032%\n",
      "Min loss: 0.000\n",
      "Best Epoch: 10.000\n",
      "Training time 3 days, 4:21:16\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--batch-size 40 \\\n",
    "--epochs 1000 \\\n",
    "--lr_scheduler \"lambda\" \\\n",
    "--lr 1e-4 \\\n",
    "--data-set 'Sinogram_DCM' \\\n",
    "--model-name 'MLPMixer' \\\n",
    "--criterion 'Change L2 L1 Loss' \\\n",
    "--output_dir '/workspace/sunggu/4.Dose_img2img/model/[Ours]MLPMixer_remove_denoiser' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]MLPMixer_remove_denoiser/low2high/' \\\n",
    "--validate-every 2 \\\n",
    "--num_workers 4 \\\n",
    "--criterion_mode 'not balance' \\\n",
    "--multiple_GT \"False\" \\\n",
    "--patch_training \"False\" \\\n",
    "--multi-gpu-mode 'Single' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "import functools\n",
    "import pydicom\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='ignore') \n",
    "\n",
    "\n",
    "def list_sort_nicely(l):   \n",
    "    def tryint(s):        \n",
    "        try:            \n",
    "            return int(s)        \n",
    "        except:            \n",
    "            return s\n",
    "        \n",
    "    def alphanum_key(s):\n",
    "        return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "    l.sort(key=alphanum_key)    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_20_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/20/*/*/*.dcm')) + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/20/*/*/*.dcm'))\n",
    "n_100_imgs  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/X/*/*/*.dcm'))  + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/X/*/*/*.dcm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_hu(path):\n",
    "    # pydicom version...!\n",
    "    # referred from https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial\n",
    "    # ref: pydicom.pixel_data_handlers.util.apply_modality_lut\n",
    "    # '''\n",
    "    # Awesome pydicom lut fuction...!\n",
    "    # ds  = pydicom.dcmread(fname)\n",
    "    # arr = ds.pixel_array\n",
    "    # hu  = apply_modality_lut(arr, ds)\n",
    "    # '''\n",
    "    dcm_image = pydicom.read_file(path)\n",
    "    image = dcm_image.pixel_array\n",
    "    image = image.astype(np.int16)\n",
    "    image[image == -2000] = 0\n",
    "\n",
    "    intercept = dcm_image.RescaleIntercept\n",
    "    slope     = dcm_image.RescaleSlope\n",
    "\n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "\n",
    "    image += np.int16(intercept)\n",
    "    # print(image.shape) # (512, 512)\n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "def dicom_normalize(image, MIN_HU=-1024.0, MAX_HU=3071.0):   # I already check the max value is 3071.0\n",
    "   image = (image - MIN_HU) / (MAX_HU - MIN_HU)   # Range  0.0 ~ 1.0\n",
    "#    image = (image - 0.5) / 0.5                  # Range -1.0 ~ 1.0   @ We do not use -1~1 range becuase there is no Tanh act.\n",
    "   return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from monai.transforms import *\n",
    "from monai.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_20_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/20/*/*/*.dcm')) + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/20/*/*/*.dcm'))\n",
    "n_100_imgs  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/X/*/*/*.dcm'))  + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/X/*/*/*.dcm'))\n",
    "\n",
    "files = [{\"n_20\": n_20, \"n_100\": n_100} for n_20, n_100 in zip(n_20_imgs, n_100_imgs)]            \n",
    "print(\"Train [Total]  number = \", len(n_20_imgs))\n",
    "\n",
    "# CT에 맞는 Augmentation\n",
    "\n",
    "transforms = Compose(\n",
    "    [\n",
    "        Lambdad(keys=[\"n_20\", \"n_100\"], func=get_pixels_hu),\n",
    "        Lambdad(keys=[\"n_20\", \"n_100\"], func=dicom_normalize),\n",
    "        AddChanneld(keys=[\"n_20\", \"n_100\"]),                 \n",
    "\n",
    "        # Crop  \n",
    "        # RandWeightedCropd(keys=[\"image\"], w_key=[\"image\"], spatial_size=(512,512,1), num_samples=1),\n",
    "        # RandSpatialCropd(keys=[\"image\"], roi_size=(512, 512), random_size=False, random_center=True),\n",
    "        # RandSpatialCropd(keys=[\"image\"], roi_size=(512,512,3), random_size=False, random_center=True),\n",
    "#         RandSpatialCropSamplesd(keys=[\"n_20\", \"n_100\"], roi_size=(64, 64), num_samples=8, random_center=True, random_size=False, meta_keys=None, allow_missing_keys=False), \n",
    "            # patch training, next(iter(loader)) output : list로 sample 만큼,,, 그 List 안에 (B, C, H, W)\n",
    "\n",
    "        # (45 degree rotation, vertical & horizontal flip & scaling)\n",
    "#         RandFlipd(keys=[\"n_20\", \"n_100\"], prob=0.1, spatial_axis=[0, 1], allow_missing_keys=False),\n",
    "#         RandRotated(keys=[\"n_20\", \"n_100\"], prob=0.1, range_x=np.pi/4, range_y=np.pi/4, range_z=0.0, keep_size=True, align_corners=False, allow_missing_keys=False),\n",
    "#         RandZoomd(keys=[\"n_20\", \"n_100\"], prob=0.1, min_zoom=0.5, max_zoom=2.0, align_corners=None, keep_size=True, allow_missing_keys=False),\n",
    "        ToTensord(keys=[\"n_20\", \"n_100\"]),\n",
    "    ]\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Dataset(data=files, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_denormalize(image, MIN_HU=-1024.0, MAX_HU=3071.0):\n",
    "    # image = (image - 0.5) / 0.5           # Range -1.0 ~ 1.0   @ We do not use -1~1 range becuase there is no Tanh act.\n",
    "    image = (MAX_HU - MIN_HU)*image + MIN_HU\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(dicom_denormalize(t[470]['n_20'].squeeze()), 'gray', vmin=0, vmax=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dicom_denormalize(t[470]['n_100'].squeeze()), 'gray', vmin=0, vmax=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(t[470]['n_100'], t[470]['n_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCoshLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n",
    "#         return torch.mean(torch.log(torch.cosh(torch.pow(ey_t, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LogCoshLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a(t[470]['n_100'], t[470]['n_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.1081e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a(t[470]['n_100'], t[470]['n_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a(t[470]['n_100'], t[470]['n_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000*4.1081e-06 - 1000*2.1081e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_log(path):\n",
    "    log_list = []\n",
    "    lines = open(path, 'r').read().splitlines() \n",
    "    for i in range(len(lines)):\n",
    "        exec('log_list.append('+lines[i] + ')')\n",
    "    return  log_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = read_log(path = '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/log.txt')\n",
    "\n",
    "train_lr   = [ log_list[i]['train_lr'] for i in range(len(log_list)) ]\n",
    "train_loss = [ log_list[i]['train_loss'] for i in range(len(log_list)) ]\n",
    "valid_loss = [ log_list[i]['valid_loss'] for i in range(len(log_list)) ]\n",
    "epoch      = [ log_list[i]['epoch'] for i in range(len(log_list)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(train_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(valid_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(np.argsort(valid_loss)[:10]) & set(np.argsort(train_loss)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py \\\n",
    "--training-mode 'sinogram' \\\n",
    "--data-set 'TEST_Sinogram_DCM' \\\n",
    "--model-name 'ED_CNN' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Test/png/[Privious]ED_CNN/epoch_999/' \\\n",
    "--num_workers 4 \\\n",
    "--pin-mem \\\n",
    "--range-minus1-plus1 'False' \\\n",
    "--teacher_forcing \"False\" \\\n",
    "--resume '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/epoch_999_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 978 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Original === \n",
    "PSNR avg: 54.4628 \n",
    "SSIM avg: 0.9956 \n",
    "RMSE avg: 7.9607\n",
    "\n",
    "\n",
    "Predictions === \n",
    "PSNR avg: 57.6190 \n",
    "SSIM avg: 0.9980 \n",
    "RMSE avg: 5.5423\n",
    "***********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
