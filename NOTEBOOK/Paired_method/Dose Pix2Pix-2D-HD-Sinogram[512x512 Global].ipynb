{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 31 01:09:55 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "|100%   89C    P2   168W / 280W |  24144MiB / 24220MiB |     39%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:1C:00.0 Off |                  N/A |\n",
      "| 48%   70C    P2   274W / 280W |  19100MiB / 24220MiB |     37%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:1D:00.0 Off |                  N/A |\n",
      "| 81%   86C    P2   109W / 280W |  17202MiB / 24220MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:1E:00.0 Off |                  N/A |\n",
      "|133%   93C    P2   106W / 280W |  17196MiB / 24220MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN RTX           Off  | 00000000:3D:00.0 Off |                  N/A |\n",
      "| 75%   84C    P2   163W / 280W |  24086MiB / 24220MiB |     56%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN RTX           Off  | 00000000:3F:00.0 Off |                  N/A |\n",
      "|100%   87C    P2   141W / 280W |  19102MiB / 24220MiB |     69%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN RTX           Off  | 00000000:40:00.0 Off |                  N/A |\n",
      "| 41%   32C    P8    11W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN RTX           Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "| 41%   41C    P8     3W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6, 7\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/MONAI'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/4.Dose_img2img'))\n",
    "sys.path.append(os.path.abspath('/workspace/sunggu/4.Dose_img2img/pix2pixHD'))\n",
    "\n",
    "from sunggu_utils import check_value, take_list, plot_confusion_matrix, list_sort_nicely, find_dir, plot_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0+unknown\n",
      "Python version: 3.6.9 (default, Jul 17 2020, 12:50:27)  [GCC 8.4.0]\n",
      "OS version: Linux (4.15.0-137-generic)\n",
      "Numpy version: 1.18.5\n",
      "Pytorch version: 1.6.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 3.2.0\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 8.0.1\n",
      "Tensorboard version: 2.3.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.7.0\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.50.2\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import skimage\n",
    "import monai\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss, GeneralizedDiceLoss, FocalLoss, TverskyLoss\n",
    "from monai.metrics import compute_meandice, DiceMetric, ConfusionMatrixMetric \n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet, highresnet\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadNiftid,\n",
    "    LoadNumpyd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Lambdad,\n",
    "    ToTensord,\n",
    "    CastToTyped,\n",
    "    DeleteItemsd,\n",
    "    AsDiscrete,\n",
    "    SpatialPadd,\n",
    "    CenterSpatialCropd,\n",
    "    RandSpatialCropd,\n",
    "    Resized,\n",
    ")\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 시드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "set_determinism(seed=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_low_images  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/sinogram_dataset/2D_dataset/Train/noise20_b50f_5.0/*/*.npy'))\n",
    "train_high_images = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/sinogram_dataset/2D_dataset/Train/noise100_b50f_5.0/*/*.npy'))\n",
    "\n",
    "valid_low_images  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/sinogram_dataset/2D_dataset/Valid/noise20_b50f_5.0/*/*.npy'))\n",
    "valid_high_images = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/sinogram_dataset/2D_dataset/Valid/noise100_b50f_5.0/*/*.npy'))\n",
    "\n",
    "total_low_list  = train_low_images  + valid_low_images\n",
    "total_high_list = train_high_images + valid_high_images\n",
    "\n",
    "train_files = [{\"low\": low_name, \"high\": high_name} for low_name, high_name in zip(total_low_list, total_high_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Compose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-caa5d690577b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# CT에 맞는 Augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_transforms = Compose(\n\u001b[0m\u001b[1;32m      4\u001b[0m     [\n\u001b[1;32m      5\u001b[0m         \u001b[0mLoadNumpyd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"low\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"high\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Compose' is not defined"
     ]
    }
   ],
   "source": [
    "# CT에 맞는 Augmentation\n",
    "from torchvision import transforms\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadNumpyd(keys=[\"low\", \"high\"]),\n",
    "        AddChanneld(keys=[\"low\", \"high\"]), \n",
    "#         Resized(keys=[\"low\", \"high\"], spatial_size=(256, 256), mode='bicubic', align_corners=True),\n",
    "        ToTensord(keys=[\"low\", \"high\"]),\n",
    "        Lambdad(keys=[\"low\", \"high\"], func=transforms.Normalize(mean=(0.5), std=(0.5))),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check transforms in DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_windowing(x):\n",
    "    x = (x * 0.5) + 0.5 \n",
    "    x = np.clip(x, a_min=0.250, a_max=0.270)\n",
    "    x -= x.min()\n",
    "    x /= x.max()  \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "# check_loader = DataLoader(check_ds, batch_size=1, shuffle=False)\n",
    "# check_data = next(iter(check_loader))\n",
    "\n",
    "check_data = check_ds[160]\n",
    "\n",
    "print(check_data['low_meta_dict']['filename_or_obj'])\n",
    "print(check_data['high_meta_dict']['filename_or_obj'])\n",
    "\n",
    "low = (check_data[\"low\"][0])\n",
    "high = (check_data[\"high\"][0])\n",
    "print(f\"image shape: {low.shape}\")\n",
    "\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"low\")\n",
    "plt.imshow(visual_windowing(low), cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"high\")\n",
    "plt.imshow(visual_windowing(high), cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 갯수 =  32\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "# from torchsampler.imbalanced import ImbalancedDatasetSampler, sunggu_ImbalancedDatasetSampler\n",
    "\n",
    "# cf) use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())\n",
    "\n",
    "# Cachedataset 이거 뭔가 문제가 있음...\n",
    "train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=10, shuffle=True, num_workers=12, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer  Only Low -> High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_net_multi_gpu(net):\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    net.to('cuda')        \n",
    "    return net\n",
    "\n",
    "def init_net_sigle_gpu(net):\n",
    "    net.to('cuda')        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pix2pixHD.models import networks\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# 먼저 512x512 모델\n",
    "netG = networks.define_G(input_nc=1, \n",
    "                         output_nc=1, \n",
    "                         ngf=64, \n",
    "                         netG='global', \n",
    "                         n_downsample_global=4, \n",
    "                         n_blocks_global=9, \n",
    "                         n_local_enhancers=1, \n",
    "                         n_blocks_local=3, \n",
    "                         norm='instance')      \n",
    "\n",
    "netD = networks.define_D(input_nc=2, \n",
    "                         ndf=64,\n",
    "                         n_layers_D=3,\n",
    "                         norm='instance',\n",
    "                         use_sigmoid=False, \n",
    "                         num_D=2, \n",
    "                         getIntermFeat=True)\n",
    "\n",
    "# multi-gpu 사용\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    netG  = init_net_multi_gpu(netG)\n",
    "    netD  = init_net_multi_gpu(netD)\n",
    "\n",
    "else :\n",
    "    netG  = init_net_sigle_gpu(netG)\n",
    "    netD  = init_net_sigle_gpu(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# input_size = (1,32,320,320)\n",
    "# summary(model.encoder, input_size, batch_size=-1, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 이어서 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 불러오기\n",
    "checkpoint_dir = '/workspace/sunggu/4.Dose_img2img/model/Pix2Pix_2D_HD_256x256_global/epoch_980_model.pth'\n",
    "checkpoint = torch.load(checkpoint_dir)\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "\n",
    "## multi-gpu 사용\n",
    "if torch.cuda.device_count() > 1:\n",
    "    netG = torch.nn.DataParallel(netG)\n",
    "    netD = torch.nn.DataParallel(netD)\n",
    "    \n",
    "netG.to('cuda')  \n",
    "netD.to('cuda')  \n",
    "\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 필요한 Weight만 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Before\n",
    "# model_dict = model.state_dict()\n",
    "# print(\"이전 weight = \", model_dict['encoder._conv_stem.weight'][0])\n",
    "\n",
    "# load_dir = '/workspace/sunggu/1.Hemorrhage/monai_experiment/model/Efficient3d_conv2d_Aux/'\n",
    "# pretrained_dict =  torch.load(os.path.join(load_dir, \"epoch_0_best_metric_model.pth\")) \n",
    "\n",
    "# # 1. filter out unnecessary keys\n",
    "# pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "# # 2. overwrite entries in the existing state dict\n",
    "# model_dict.update(pretrained_dict) \n",
    "# # 3. load the new state dict\n",
    "# model.load_state_dict(model_dict)\n",
    "\n",
    "# # After\n",
    "# print(\"이후 weight = \", model_dict['encoder._conv_stem.weight'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "GAN_loss           = torch.nn.MSELoss()   # vanila nn.BCELoss()\n",
    "FM_loss            = torch.nn.L1Loss()\n",
    "Perceptual_loss    = networks.VGGLoss(device='cuda')\n",
    "\n",
    "learning_rate = 2e-4\n",
    "max_epochs = 1000\n",
    "\n",
    "# Optimizer 설정하기\n",
    "G_params  = list(netG.parameters())\n",
    "D_params  = list(netD.parameters())    \n",
    "\n",
    "optimizer_G = torch.optim.Adam(G_params, lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(D_params, lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "def lambda_rule(epoch, start_decay_epoch=100, total_epoch=max_epochs):\n",
    "    lr = 1.0 - max(0, epoch - start_decay_epoch) / float(total_epoch)\n",
    "    return lr\n",
    "\n",
    "scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_rule)\n",
    "scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lr_lambda=lambda_rule)\n",
    "\n",
    "# Generated image pool\n",
    "from Cyclegan_sunggu.image_pool import ImagePool\n",
    "num_pool = 0\n",
    "fake_pool = ImagePool(num_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
    "optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
    "\n",
    "scheduler_G.load_state_dict(checkpoint['scheduler_G'])        \n",
    "scheduler_D.load_state_dict(checkpoint['scheduler_D'])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그밖에 부수적인 functions 설정하기\n",
    "fn_tonumpy        = lambda x: x.cpu().detach().numpy().transpose(0, 2, 3, 1)\n",
    "fn_denorm         = lambda x: (x * 0.5) + 0.5\n",
    "fn_denorm_window  = visual_windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "\n",
    "## 네트워크 학습시키기\n",
    "epoch_num = 1000\n",
    "val_interval = 10\n",
    "\n",
    "epoch_train_loss_list = list()\n",
    "epoch_val_loss_list   = list()\n",
    "\n",
    "epoch_train_metric_list = list()\n",
    "epoch_val_metric_list   = list()\n",
    "\n",
    "writer = SummaryWriter(log_dir='/workspace/sunggu/4.Dose_img2img/runs/Pix2Pix_2D_HD_512x512_global')\n",
    "root_dir = '/workspace/sunggu/4.Dose_img2img/model/Pix2Pix_2D_HD_512x512_global/'\n",
    "\n",
    "low2high_png_dir = '/workspace/sunggu/4.Dose_img2img/Predictions/png/'+'Pix2Pix_2D_HD_512x512_global'+'/low2high/'\n",
    "\n",
    "# 모델 save폴더 만들기\n",
    "os.makedirs(root_dir, mode=0o777, exist_ok=True)\n",
    "os.makedirs(low2high_png_dir, mode=0o777, exist_ok=True)\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch}/{epoch_num}\")\n",
    "    \n",
    "    # Model 선언\n",
    "    netG.train()    \n",
    "    netD.train()\n",
    "    \n",
    "    # Loss 선언    \n",
    "    loss_D_real_train = []\n",
    "    loss_D_fake_train = []\n",
    "    loss_G_gan_train         = []\n",
    "    loss_G_fm_train          = []\n",
    "    loss_G_vgg_train  = []    \n",
    "    \n",
    "    train_iterator = tqdm(train_loader, desc='Train', file=sys.stdout)    \n",
    "    for batch_data in train_iterator:\n",
    "        \n",
    "        input_low  = batch_data['low'].to(device)\n",
    "        input_high = batch_data['high'].to(device)\n",
    "        \n",
    "        # Generate fake\n",
    "        output = netG(input_low)\n",
    "        real = torch.cat([input_low, input_high], dim=1)\n",
    "        fake = torch.cat([input_low, output], dim=1)        \n",
    "        \n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        pred_real = netD(real)    \n",
    "        # POOL\n",
    "        fake = fake_pool.query(fake)\n",
    "        pred_fake = netD(fake.detach())  # Detach...!\n",
    "        \n",
    "        loss_D_real = torch.stack([GAN_loss(r_pred[-1], torch.ones_like(r_pred[-1]))  for r_pred in pred_real]).sum()\n",
    "        loss_D_fake = torch.stack([GAN_loss(f_pred[-1], torch.zeros_like(f_pred[-1])) for f_pred in pred_fake]).sum()\n",
    "        \n",
    "        loss_D      = 0.5 * (loss_D_real + loss_D_fake)\n",
    "        \n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        \n",
    "        # Train Generator        \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        pred_fake = netD(fake)        \n",
    "        \n",
    "            # Loss 1\n",
    "        loss_G_gan = torch.stack([GAN_loss(f_pred[-1], torch.ones_like(f_pred[-1])) for f_pred in pred_fake]).sum()\n",
    "        \n",
    "            # Loss 2\n",
    "        loss_G_fm = 0\n",
    "        feat_weights = 4.0 / (netD.n_layers+1)\n",
    "        D_weights = 1.0 / netD.num_D\n",
    "        for i in range(netD.num_D):\n",
    "            for j in range(len(pred_fake[i])-1):\n",
    "                loss_G_fm += D_weights * feat_weights * FM_loss(pred_fake[i][j], pred_real[i][j].detach()) * 10\n",
    "            # Loss 3                       \n",
    "        loss_G_vgg = Perceptual_loss(output.repeat(1,3,1,1), input_high.repeat(1,3,1,1)) * 10\n",
    "\n",
    "        loss_G     = loss_G_gan + loss_G_fm + loss_G_vgg\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # 기록\n",
    "        loss_D_real_train  += [loss_D_real.item()]\n",
    "        loss_D_fake_train  += [loss_D_fake.item()]\n",
    "        loss_G_gan_train   += [loss_G_gan.item()]\n",
    "        loss_G_fm_train    += [loss_G_fm.item()]\n",
    "        loss_G_vgg_train   += [loss_G_vgg.item()]\n",
    "\n",
    "        \n",
    "    print( \"Generator Loss       [Gan Loss]    = %.4f\" %np.mean(loss_G_gan_train) ) \n",
    "    print( \"Generator Loss       [FM  Loss]    = %.4f\" %np.mean(loss_G_fm_train) ) \n",
    "    print( \"Generator Loss       [VGG Loss]    = %.4f\" %np.mean(loss_G_vgg_train) ) \n",
    "    print( \"Discriminator Loss   [Real]        = %.4f\" %np.mean(loss_D_real_train) )\n",
    "    print( \"Discriminator Loss   [Fake]        = %.4f\" %np.mean(loss_D_fake_train) )\n",
    "    \n",
    "    \n",
    "    # Tensorboard 저장하기\n",
    "    input_low   = fn_denorm_window(fn_tonumpy((input_low)))\n",
    "    input_high  = fn_denorm_window(fn_tonumpy((input_high)))\n",
    "    output      = fn_denorm_window(fn_tonumpy((output)))\n",
    "\n",
    "    input_low   = np.clip(input_low, a_min=0, a_max=1)\n",
    "    input_high  = np.clip(input_high, a_min=0, a_max=1)\n",
    "    output      = np.clip(output, a_min=0, a_max=1)\n",
    "\n",
    "    # png Save\n",
    "    plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_input_low.png',   input_low[0].squeeze(),   cmap=\"gray\")\n",
    "    plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_output_high.png', output[0].squeeze(),      cmap=\"gray\")\n",
    "    plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_ground_high.png', input_high[0].squeeze(),  cmap=\"gray\")\n",
    "    \n",
    "    # Loss Write    \n",
    "    writer.add_scalar('Train/loss_G_gan',  np.mean(loss_G_gan_train), epoch)\n",
    "    writer.add_scalar('Train/loss_G_fm',   np.mean(loss_G_fm_train), epoch)\n",
    "    writer.add_scalar('Train/loss_G_vgg',  np.mean(loss_G_vgg_train), epoch)\n",
    "    writer.add_scalar('Train/loss_D_real', np.mean(loss_D_real_train), epoch)\n",
    "    writer.add_scalar('Train/loss_D_fake', np.mean(loss_D_fake_train), epoch)    \n",
    "    \n",
    "    # 저장\n",
    "    if epoch % 5 == 0 or epoch == epoch_num:\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            checkpoint = {'epoch': epoch, \n",
    "                          'netG_state_dict': netG.module.state_dict(), \n",
    "                          'netD_state_dict': netD.module.state_dict(), \n",
    "                          'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                          'optimizer_D_state_dict': optimizer_D.state_dict(),  \n",
    "                          'scheduler_G': scheduler_G.state_dict(),\n",
    "                          'scheduler_D': scheduler_D.state_dict(),\n",
    "                         }                    \n",
    "\n",
    "        else:\n",
    "            checkpoint = {'epoch': epoch, \n",
    "                          'netG_state_dict': netG.state_dict(), \n",
    "                          'netD_state_dict': netD.state_dict(), \n",
    "                          'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                          'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "                          'scheduler_G': scheduler_G.state_dict(),\n",
    "                          'scheduler_D': scheduler_D.state_dict(),\n",
    "                         }                         \n",
    "\n",
    "            torch.save(checkpoint, os.path.join(root_dir, \"epoch_\" + str(epoch) + \"_model.pth\"))        \n",
    "    \n",
    "    # Scheduler\n",
    "    writer.add_scalar('lr', optimizer_G.param_groups[0]['lr'], epoch)\n",
    "    old_lr = optimizer_G.param_groups[0]['lr']\n",
    "    lr = optimizer_G.param_groups[0]['lr']\n",
    "    print('Learning Rate %.10f -> %.10f' % (old_lr, lr))\n",
    "\n",
    "    scheduler_G.step()    \n",
    "    scheduler_D.step()    \n",
    "\n",
    "writer.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    checkpoint = {'epoch': epoch, \n",
    "                  'netG_state_dict': netG.module.state_dict(), \n",
    "                  'netD_state_dict': netD.module.state_dict(), \n",
    "                  'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                  'optimizer_D_state_dict': optimizer_D.state_dict(),  \n",
    "                  'scheduler_G': scheduler_G.state_dict(),\n",
    "                  'scheduler_D': scheduler_D.state_dict(),\n",
    "                 }                    \n",
    "\n",
    "else:\n",
    "    checkpoint = {'epoch': epoch, \n",
    "                  'netG_state_dict': netG.state_dict(), \n",
    "                  'netD_state_dict': netD.state_dict(), \n",
    "                  'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                  'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "                  'scheduler_G': scheduler_G.state_dict(),\n",
    "                  'scheduler_D': scheduler_D.state_dict(),\n",
    "                 }                         \n",
    "\n",
    "    torch.save(checkpoint, os.path.join('/workspace/sunggu/4.Dose_img2img/model/Pix2Pix_2D_HD_512x512_global_1Stage/', \"epoch_\" + str(epoch) + \"_last_model.pth\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#     with torch.no_grad():\n",
    "#         netG.eval()\n",
    "#         netD.eval()\n",
    "\n",
    "#         loss_G_gan_valid  = []\n",
    "#         loss_G_L1_valid   = []\n",
    "#         loss_D_real_valid = []\n",
    "#         loss_D_fake_valid = []\n",
    "        \n",
    "#         valid_iterator = tqdm(valid_loader, desc='Valid', file=sys.stdout)    \n",
    "#         for batch_data in valid_iterator:\n",
    "        \n",
    "#             input_low  = batch_data['low'].to(device)\n",
    "#             input_high = batch_data['high'].to(device)\n",
    "            \n",
    "#             output = netG(input_low)\n",
    "\n",
    "#             real = torch.cat([input_low, input_high], dim=1)\n",
    "#             fake = torch.cat([input_low, output], dim=1)      \n",
    "            \n",
    "#             # D\n",
    "#             pred_real = netD(real)        \n",
    "#             pred_fake = netD(fake.detach())\n",
    "\n",
    "#             loss_D_real = gan_loss(pred_real, torch.ones_like(pred_real))\n",
    "#             loss_D_fake = gan_loss(pred_fake, torch.zeros_like(pred_fake))\n",
    "\n",
    "#             # G\n",
    "#             pred_fake = netD(fake)        \n",
    "            \n",
    "#             loss_G_gan = gan_loss(pred_fake, torch.ones_like(pred_fake))\n",
    "#             loss_G_L1  = L1_loss(output, input_high)\n",
    "\n",
    "#             # 기록\n",
    "#             loss_D_real_valid += [loss_D_real.item()]\n",
    "#             loss_D_fake_valid += [loss_D_fake.item()]\n",
    "#             loss_G_gan_valid  += [loss_G_gan.item()]\n",
    "#             loss_G_L1_valid   += [loss_G_L1.item()]\n",
    "        \n",
    "        \n",
    "#     print( \"Generator Loss       [Gan Loss]    = %.4f\" %np.mean(loss_G_gan_valid) ) \n",
    "#     print( \"Generator Loss       [L1  Loss]    = %.4f\" %np.mean(loss_G_L1_valid) ) \n",
    "#     print( \"Discriminator Loss   [Real]        = %.4f\" %np.mean(loss_D_real_valid) )\n",
    "#     print( \"Discriminator Loss   [Fake]        = %.4f\" %np.mean(loss_D_fake_valid) )\n",
    "\n",
    "    \n",
    "#     # Tensorboard 저장하기\n",
    "#     input_low   = fn_denorm(fn_tonumpy((input_low)))\n",
    "#     input_high  = fn_denorm(fn_tonumpy((input_high)))\n",
    "#     output = fn_denorm(fn_tonumpy((output)))\n",
    "\n",
    "#     input_low   = np.clip(input_low, a_min=0, a_max=1)\n",
    "#     input_high  = np.clip(input_high, a_min=0, a_max=1)\n",
    "#     output = np.clip(output, a_min=0, a_max=1)\n",
    "\n",
    "#     # png Save\n",
    "#     plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_input_low.png',   input_low[0].squeeze(),   cmap=\"gray\")\n",
    "#     plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_output_high.png', output[0].squeeze(), cmap=\"gray\")\n",
    "#     plt.imsave(low2high_png_dir+'epoch_'+str(epoch)+'_ground_high.png', input_high[0].squeeze(),  cmap=\"gray\")\n",
    "    \n",
    "#     # Loss Write    \n",
    "#     writer.add_scalar('Valid/loss_G_gan',  np.mean(loss_G_gan_valid), epoch)\n",
    "#     writer.add_scalar('Valid/loss_G_L1',   np.mean(loss_G_L1_valid), epoch)\n",
    "#     writer.add_scalar('Valid/loss_D_real', np.mean(loss_D_real_valid), epoch)\n",
    "#     writer.add_scalar('Valid/loss_D_fake', np.mean(loss_D_fake_valid), epoch)\n",
    "\n",
    "    \n",
    "#     # 저장\n",
    "#     if epoch % 5 == 0 or epoch == epoch_num:\n",
    "\n",
    "#         if torch.cuda.device_count() > 1:\n",
    "#             checkpoint = {'epoch': epoch, \n",
    "#                           'netG_state_dict': netG.module.state_dict(), \n",
    "#                           'netD_state_dict': netD.module.state_dict(), \n",
    "#                           'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "#                           'optimizer_D_state_dict': optimizer_D.state_dict(),  \n",
    "#                           'scheduler_G': scheduler_G.state_dict(),\n",
    "#                           'scheduler_D': scheduler_D.state_dict(),\n",
    "#                          }                    \n",
    "\n",
    "#         else:\n",
    "#             checkpoint = {'epoch': epoch, \n",
    "#                           'netG_state_dict': netG.state_dict(), \n",
    "#                           'netD_state_dict': netD.state_dict(), \n",
    "#                           'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "#                           'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "#                           'scheduler_G': scheduler_G.state_dict(),\n",
    "#                           'scheduler_D': scheduler_D.state_dict(),\n",
    "#                          }                         \n",
    "\n",
    "#             torch.save(checkpoint, os.path.join(root_dir, \"epoch_\" + str(epoch) + \"_model.pth\"))        \n",
    "    \n",
    "#     # Scheduler\n",
    "#     writer.add_scalar('lr', optimizer_G.param_groups[0]['lr'], epoch)      \n",
    "#     old_lr = optimizer_G.param_groups[0]['lr']\n",
    "#     lr = optimizer_G.param_groups[0]['lr']\n",
    "#     print('Learning Rate %.10f -> %.10f' % (old_lr, lr))\n",
    "\n",
    "#     scheduler_G.step()    \n",
    "#     scheduler_D.step()    \n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_network(net, name='network'):\n",
    "    \"\"\"Calculate and print the mean of average absolute(gradients)\n",
    "    Parameters:\n",
    "        net (torch network) -- Torch network\n",
    "        name (str) -- the name of the network\n",
    "    \"\"\"\n",
    "    mean = 0.0\n",
    "    count = 0\n",
    "    for param in net.parameters():\n",
    "        if param.grad is not None:\n",
    "            mean += torch.mean(torch.abs(param.grad.data))\n",
    "            count += 1\n",
    "    if count > 0:\n",
    "        mean = mean / count\n",
    "    print(name)\n",
    "    print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223.016px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
