{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE -> MAE Loss 꿀팁!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 24 12:42:07 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "| 33%   26C    P8    17W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     Off  | 00000000:1C:00.0 Off |                  Off |\n",
      "| 45%   68C    P2   242W / 260W |  17790MiB / 48601MiB |     96%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     Off  | 00000000:1D:00.0 Off |                  Off |\n",
      "| 33%   27C    P8    17W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     Off  | 00000000:1E:00.0 Off |                  Off |\n",
      "| 33%   27C    P8     7W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 8000     Off  | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   26C    P8    10W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 8000     Off  | 00000000:3F:00.0 Off |                  Off |\n",
      "| 33%   27C    P8     9W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Quadro RTX 8000     Off  | 00000000:40:00.0 Off |                  Off |\n",
      "| 33%   26C    P8    14W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Quadro RTX 8000     Off  | 00000000:41:00.0 Off |                  Off |\n",
      "| 33%   28C    P8    12W / 260W |  48110MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/sunggu/4.Dose_img2img/scripts study\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/sunggu/4.Dose_img2img/scripts study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 갯수 =  64\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2.git.kitware.jobserver-1\r\n"
     ]
    }
   ],
   "source": [
    "!ninja --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python==4.5.5.62\n",
    "!pip install monai pydicom kornia einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ours_GPEN_GAN_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "***********************************************\n",
      "Dataset Name:  Sinogram_DCM\n",
      "---------- Model ----------\n",
      "Resume From:  /workspace/sunggu/4.Dose_img2img/model/[Ours]Ours_GPEN_GAN_lambda/epoch_4_checkpoint.pth\n",
      "Output To:  /workspace/sunggu/4.Dose_img2img/model/[Ours]Ours_GPEN_GAN_lambda\n",
      "Save   To:  /workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/\n",
      "---------- Optimizer ----------\n",
      "Learning Rate:  0.0001\n",
      "Batchsize:  7\n",
      "Loading dataset ....\n",
      "Train [Total]  number =  6899\n",
      "Valid [Total]  number =  14\n",
      "Creating criterion: L1 Loss\n",
      "Creating model: Ours_GPEN_GAN\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /home/sunggu/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|████████████████████████████████████████| 548M/548M [00:14<00:00, 38.5MB/s]\n",
      "Number of Learnable Params: 85712815\n",
      "Ours_GPEN_GAN(\n",
      "  (Generator): Ours_GPEN_FullGenerator(\n",
      "    (encoder): CMT(\n",
      "      (stem): CMTStem(\n",
      "        (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (gelu1): GELU()\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (gelu2): GELU()\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (gelu3): GELU()\n",
      "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (patch1): Patch_Aggregate(\n",
      "        (conv): Conv2x2(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "      )\n",
      "      (patch2): Patch_Aggregate(\n",
      "        (conv): Conv2x2(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "      )\n",
      "      (patch3): Patch_Aggregate(\n",
      "        (conv): Conv2x2(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "      )\n",
      "      (patch4): Patch_Aggregate(\n",
      "        (conv): Conv2x2(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "      )\n",
      "      (stage1): Sequential(\n",
      "        (0): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(8, 8), padding=(1, 1), groups=64)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(8, 8), padding=(1, 1), groups=64)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "              )\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(8, 8), padding=(1, 1), groups=64)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(8, 8), padding=(1, 1), groups=64)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "              )\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(8, 8), padding=(1, 1), groups=64)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(8, 8), padding=(1, 1), groups=64)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
      "            (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "              )\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (stage2): Sequential(\n",
      "        (0): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=128)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=128)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "              )\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=128)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=128)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "              )\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=128)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(4, 4), padding=(1, 1), groups=128)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "              )\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (stage3): Sequential(\n",
      "        (0): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (12): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (13): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (14): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (15): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "              )\n",
      "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (stage4): Sequential(\n",
      "        (0): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "              )\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "              )\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): CMTBlock(\n",
      "          (lpu): LPU(\n",
      "            (DWConv): DWCONV(\n",
      "              (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            )\n",
      "          )\n",
      "          (lmhsa): LMHSA(\n",
      "            (dwconv_k): DWCONV(\n",
      "              (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            )\n",
      "            (dwconv_v): DWCONV(\n",
      "              (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            )\n",
      "            (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (irffn): IRFFN(\n",
      "            (conv1): Sequential(\n",
      "              (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (dwconv): Sequential(\n",
      "              (0): DWCONV(\n",
      "                (depthwise): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "              )\n",
      "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): GELU()\n",
      "            )\n",
      "            (conv2): Sequential(\n",
      "              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_linear): Sequential(\n",
      "      (0): EqualLinear(8192, 512)\n",
      "    )\n",
      "    (generator): Our_Generator(\n",
      "      (style): Sequential(\n",
      "        (0): PixelNorm()\n",
      "        (1): EqualLinear(512, 512)\n",
      "        (2): EqualLinear(512, 512)\n",
      "        (3): EqualLinear(512, 512)\n",
      "        (4): EqualLinear(512, 512)\n",
      "        (5): EqualLinear(512, 512)\n",
      "        (6): EqualLinear(512, 512)\n",
      "        (7): EqualLinear(512, 512)\n",
      "        (8): EqualLinear(512, 512)\n",
      "      )\n",
      "      (input): ConstantInput()\n",
      "      (conv1): StyledConv(\n",
      "        (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
      "        (noise): NoiseInjection()\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (to_gray1): ToGray(\n",
      "        (conv): ModulatedConv2d(512, 1, 1, upsample=False, downsample=False)\n",
      "      )\n",
      "      (convs): ModuleList(\n",
      "        (0): StyledConv(\n",
      "          (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
      "          (noise): NoiseInjection()\n",
      "          (activate): FusedLeakyReLU()\n",
      "        )\n",
      "        (1): StyledConv(\n",
      "          (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
      "          (noise): NoiseInjection()\n",
      "          (activate): FusedLeakyReLU()\n",
      "        )\n",
      "        (2): StyledConv(\n",
      "          (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
      "          (noise): NoiseInjection()\n",
      "          (activate): FusedLeakyReLU()\n",
      "        )\n",
      "        (3): StyledConv(\n",
      "          (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
      "          (noise): NoiseInjection()\n",
      "          (activate): FusedLeakyReLU()\n",
      "        )\n",
      "        (4): StyledConv(\n",
      "          (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
      "          (noise): NoiseInjection()\n",
      "          (activate): FusedLeakyReLU()\n",
      "        )\n",
      "        (5): StyledConv(\n",
      "          (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
      "          (noise): NoiseInjection()\n",
      "          (activate): FusedLeakyReLU()\n",
      "        )\n",
      "        (6): StyledConv(\n",
      "          (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
      "          (noise): NoiseInjection()\n",
      "          (activate): FusedLeakyReLU()\n",
      "        )\n",
      "        (7): StyledConv(\n",
      "          (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
      "          (noise): NoiseInjection()\n",
      "          (activate): FusedLeakyReLU()\n",
      "        )\n",
      "      )\n",
      "      (upsamples): ModuleList()\n",
      "      (to_grays): ModuleList(\n",
      "        (0): ToGray(\n",
      "          (upsample): Upsample()\n",
      "          (conv): ModulatedConv2d(512, 1, 1, upsample=False, downsample=False)\n",
      "        )\n",
      "        (1): ToGray(\n",
      "          (upsample): Upsample()\n",
      "          (conv): ModulatedConv2d(512, 1, 1, upsample=False, downsample=False)\n",
      "        )\n",
      "        (2): ToGray(\n",
      "          (upsample): Upsample()\n",
      "          (conv): ModulatedConv2d(512, 1, 1, upsample=False, downsample=False)\n",
      "        )\n",
      "        (3): ToGray(\n",
      "          (upsample): Upsample()\n",
      "          (conv): ModulatedConv2d(512, 1, 1, upsample=False, downsample=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (condition_scale): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): EqualConv2d(256, 256, 3, stride=1, padding=1)\n",
      "        (1): ScaledLeakyReLU()\n",
      "        (2): EqualConv2d(256, 256, 3, stride=1, padding=1)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): EqualConv2d(128, 128, 3, stride=1, padding=1)\n",
      "        (1): ScaledLeakyReLU()\n",
      "        (2): EqualConv2d(128, 256, 3, stride=1, padding=1)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): EqualConv2d(64, 64, 3, stride=1, padding=1)\n",
      "        (1): ScaledLeakyReLU()\n",
      "        (2): EqualConv2d(64, 256, 3, stride=1, padding=1)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): EqualConv2d(32, 32, 3, stride=1, padding=1)\n",
      "        (1): ScaledLeakyReLU()\n",
      "        (2): EqualConv2d(32, 256, 3, stride=1, padding=1)\n",
      "      )\n",
      "    )\n",
      "    (condition_shift): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): EqualConv2d(256, 256, 3, stride=1, padding=1)\n",
      "        (1): ScaledLeakyReLU()\n",
      "        (2): EqualConv2d(256, 256, 3, stride=1, padding=1)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): EqualConv2d(128, 128, 3, stride=1, padding=1)\n",
      "        (1): ScaledLeakyReLU()\n",
      "        (2): EqualConv2d(128, 256, 3, stride=1, padding=1)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): EqualConv2d(64, 64, 3, stride=1, padding=1)\n",
      "        (1): ScaledLeakyReLU()\n",
      "        (2): EqualConv2d(64, 256, 3, stride=1, padding=1)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): EqualConv2d(32, 32, 3, stride=1, padding=1)\n",
      "        (1): ScaledLeakyReLU()\n",
      "        (2): EqualConv2d(32, 256, 3, stride=1, padding=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (Discriminator): Ours_GPEN_Discriminator(\n",
      "    (convs): Sequential(\n",
      "      (0): ConvLayer(\n",
      "        (0): EqualConv2d(1, 512, 1, stride=1, padding=0)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (1): ResBlock(\n",
      "        (conv1): ConvLayer(\n",
      "          (0): EqualConv2d(512, 512, 3, stride=1, padding=1)\n",
      "          (1): FusedLeakyReLU()\n",
      "        )\n",
      "        (conv2): ConvLayer(\n",
      "          (0): Blur()\n",
      "          (1): EqualConv2d(512, 512, 3, stride=2, padding=0)\n",
      "          (2): FusedLeakyReLU()\n",
      "        )\n",
      "        (skip): ConvLayer(\n",
      "          (0): Blur()\n",
      "          (1): EqualConv2d(512, 512, 1, stride=2, padding=0)\n",
      "        )\n",
      "      )\n",
      "      (2): ResBlock(\n",
      "        (conv1): ConvLayer(\n",
      "          (0): EqualConv2d(512, 512, 3, stride=1, padding=1)\n",
      "          (1): FusedLeakyReLU()\n",
      "        )\n",
      "        (conv2): ConvLayer(\n",
      "          (0): Blur()\n",
      "          (1): EqualConv2d(512, 512, 3, stride=2, padding=0)\n",
      "          (2): FusedLeakyReLU()\n",
      "        )\n",
      "        (skip): ConvLayer(\n",
      "          (0): Blur()\n",
      "          (1): EqualConv2d(512, 512, 1, stride=2, padding=0)\n",
      "        )\n",
      "      )\n",
      "      (3): ResBlock(\n",
      "        (conv1): ConvLayer(\n",
      "          (0): EqualConv2d(512, 512, 3, stride=1, padding=1)\n",
      "          (1): FusedLeakyReLU()\n",
      "        )\n",
      "        (conv2): ConvLayer(\n",
      "          (0): Blur()\n",
      "          (1): EqualConv2d(512, 512, 3, stride=2, padding=0)\n",
      "          (2): FusedLeakyReLU()\n",
      "        )\n",
      "        (skip): ConvLayer(\n",
      "          (0): Blur()\n",
      "          (1): EqualConv2d(512, 512, 1, stride=2, padding=0)\n",
      "        )\n",
      "      )\n",
      "      (4): ResBlock(\n",
      "        (conv1): ConvLayer(\n",
      "          (0): EqualConv2d(512, 512, 3, stride=1, padding=1)\n",
      "          (1): FusedLeakyReLU()\n",
      "        )\n",
      "        (conv2): ConvLayer(\n",
      "          (0): Blur()\n",
      "          (1): EqualConv2d(512, 512, 3, stride=2, padding=0)\n",
      "          (2): FusedLeakyReLU()\n",
      "        )\n",
      "        (skip): ConvLayer(\n",
      "          (0): Blur()\n",
      "          (1): EqualConv2d(512, 512, 1, stride=2, padding=0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): ConvLayer(\n",
      "      (0): EqualConv2d(513, 512, 3, stride=1, padding=1)\n",
      "      (1): FusedLeakyReLU()\n",
      "    )\n",
      "    (final_linear): Sequential(\n",
      "      (0): EqualLinear(8192, 512)\n",
      "      (1): EqualLinear(512, 1)\n",
      "    )\n",
      "  )\n",
      "  (gan_metric): BCEWithLogitsLoss()\n",
      "  (criterion): Perceptual_L1_Loss(\n",
      "    (loss_L1): L1Loss()\n",
      "    (loss_VGG): VGGLoss(\n",
      "      (vgg): Vgg19(\n",
      "        (slice1): Sequential(\n",
      "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "        (slice2): Sequential(\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (6): ReLU(inplace=True)\n",
      "        )\n",
      "        (slice3): Sequential(\n",
      "          (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (8): ReLU(inplace=True)\n",
      "          (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (11): ReLU(inplace=True)\n",
      "        )\n",
      "        (slice4): Sequential(\n",
      "          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (13): ReLU(inplace=True)\n",
      "          (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (15): ReLU(inplace=True)\n",
      "          (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (17): ReLU(inplace=True)\n",
      "          (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (20): ReLU(inplace=True)\n",
      "        )\n",
      "        (slice5): Sequential(\n",
      "          (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (22): ReLU(inplace=True)\n",
      "          (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (24): ReLU(inplace=True)\n",
      "          (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (26): ReLU(inplace=True)\n",
      "          (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (29): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (criterion): L1Loss()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Loading pre-trained Weight...!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 1000 epochs\n",
      "Train: [epoch:5]  [  0/985]  eta: 15:13:40  lr: 0.000030  g_loss: 33.3130 (33.3130)  d_loss: 1.7217 (1.7217)  gan_loss: 1.2910 (1.2910)  pix_loss: 3.2022 (3.2022)  time: 55.6555  data: 1.8207  max mem: 38068\n",
      "Train: [epoch:5]  [ 10/985]  eta: 14:45:04  lr: 0.000030  g_loss: 33.5389 (34.0608)  d_loss: 1.7132 (1.7123)  gan_loss: 1.3277 (1.3269)  pix_loss: 3.2211 (3.2734)  time: 54.4662  data: 0.1657  max mem: 38397\n",
      "Train: [epoch:5]  [ 20/985]  eta: 14:35:43  lr: 0.000030  g_loss: 34.1682 (34.3670)  d_loss: 1.7097 (1.7105)  gan_loss: 1.3219 (1.3249)  pix_loss: 3.2857 (3.3042)  time: 54.3893  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [ 30/985]  eta: 14:26:27  lr: 0.000030  g_loss: 34.2603 (34.4137)  d_loss: 1.7097 (1.7104)  gan_loss: 1.3207 (1.3285)  pix_loss: 3.2936 (3.3085)  time: 54.4206  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [ 40/985]  eta: 14:17:16  lr: 0.000030  g_loss: 34.0582 (34.5640)  d_loss: 1.7093 (1.7100)  gan_loss: 1.3274 (1.3321)  pix_loss: 3.2750 (3.3232)  time: 54.4087  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [ 50/985]  eta: 14:08:07  lr: 0.000030  g_loss: 34.0932 (34.5115)  d_loss: 1.7080 (1.7096)  gan_loss: 1.3245 (1.3289)  pix_loss: 3.2750 (3.3183)  time: 54.4058  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [ 60/985]  eta: 13:59:01  lr: 0.000030  g_loss: 34.0932 (34.5448)  d_loss: 1.7085 (1.7104)  gan_loss: 1.3218 (1.3294)  pix_loss: 3.2764 (3.3215)  time: 54.4095  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [ 70/985]  eta: 13:49:54  lr: 0.000030  g_loss: 33.9283 (34.4588)  d_loss: 1.7105 (1.7106)  gan_loss: 1.3074 (1.3266)  pix_loss: 3.2617 (3.3132)  time: 54.4095  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [ 80/985]  eta: 13:40:49  lr: 0.000030  g_loss: 33.8017 (34.3710)  d_loss: 1.7124 (1.7111)  gan_loss: 1.3031 (1.3254)  pix_loss: 3.2531 (3.3046)  time: 54.4066  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [ 90/985]  eta: 13:31:44  lr: 0.000030  g_loss: 33.5872 (34.3322)  d_loss: 1.7134 (1.7112)  gan_loss: 1.3353 (1.3270)  pix_loss: 3.2230 (3.3005)  time: 54.4099  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [100/985]  eta: 13:22:39  lr: 0.000030  g_loss: 33.4362 (34.1965)  d_loss: 1.7118 (1.7112)  gan_loss: 1.3339 (1.3241)  pix_loss: 3.2162 (3.2872)  time: 54.4096  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [110/985]  eta: 13:13:34  lr: 0.000030  g_loss: 32.4755 (34.0662)  d_loss: 1.7103 (1.7111)  gan_loss: 1.2971 (1.3229)  pix_loss: 3.1154 (3.2743)  time: 54.4114  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [120/985]  eta: 13:04:30  lr: 0.000030  g_loss: 33.0060 (34.0602)  d_loss: 1.7092 (1.7110)  gan_loss: 1.2957 (1.3222)  pix_loss: 3.1741 (3.2738)  time: 54.4121  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [130/985]  eta: 12:55:25  lr: 0.000030  g_loss: 33.5980 (33.9968)  d_loss: 1.7109 (1.7112)  gan_loss: 1.2957 (1.3214)  pix_loss: 3.2325 (3.2675)  time: 54.4126  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [140/985]  eta: 12:46:21  lr: 0.000030  g_loss: 32.9521 (33.9287)  d_loss: 1.7120 (1.7116)  gan_loss: 1.3134 (1.3205)  pix_loss: 3.1596 (3.2608)  time: 54.4129  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [150/985]  eta: 12:37:18  lr: 0.000030  g_loss: 32.0061 (33.7867)  d_loss: 1.7142 (1.7118)  gan_loss: 1.2657 (1.3161)  pix_loss: 3.0709 (3.2471)  time: 54.4216  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [160/985]  eta: 12:28:13  lr: 0.000030  g_loss: 31.7959 (33.6739)  d_loss: 1.7133 (1.7118)  gan_loss: 1.2598 (1.3142)  pix_loss: 3.0577 (3.2360)  time: 54.4221  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [170/985]  eta: 12:19:09  lr: 0.000030  g_loss: 31.4961 (33.5387)  d_loss: 1.7103 (1.7117)  gan_loss: 1.2702 (1.3112)  pix_loss: 3.0226 (3.2227)  time: 54.4133  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [180/985]  eta: 12:10:04  lr: 0.000030  g_loss: 31.4961 (33.4681)  d_loss: 1.7094 (1.7117)  gan_loss: 1.2649 (1.3104)  pix_loss: 3.0226 (3.2158)  time: 54.4097  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [190/985]  eta: 12:01:00  lr: 0.000030  g_loss: 30.6983 (33.3130)  d_loss: 1.7117 (1.7117)  gan_loss: 1.2476 (1.3068)  pix_loss: 2.9424 (3.2006)  time: 54.4076  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [200/985]  eta: 11:51:55  lr: 0.000030  g_loss: 30.7813 (33.2227)  d_loss: 1.7124 (1.7118)  gan_loss: 1.2234 (1.3041)  pix_loss: 2.9567 (3.1919)  time: 54.4097  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [210/985]  eta: 11:42:51  lr: 0.000030  g_loss: 31.2139 (33.1510)  d_loss: 1.7108 (1.7117)  gan_loss: 1.2620 (1.3030)  pix_loss: 2.9952 (3.1848)  time: 54.4089  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [220/985]  eta: 11:33:47  lr: 0.000030  g_loss: 30.5255 (33.0098)  d_loss: 1.7087 (1.7115)  gan_loss: 1.2488 (1.3000)  pix_loss: 2.9277 (3.1710)  time: 54.4152  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [230/985]  eta: 11:24:43  lr: 0.000030  g_loss: 31.2254 (32.9896)  d_loss: 1.7073 (1.7113)  gan_loss: 1.2574 (1.3001)  pix_loss: 2.9926 (3.1689)  time: 54.4229  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [240/985]  eta: 11:15:39  lr: 0.000030  g_loss: 31.6802 (32.9362)  d_loss: 1.7085 (1.7112)  gan_loss: 1.2932 (1.3000)  pix_loss: 3.0407 (3.1636)  time: 54.4188  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [250/985]  eta: 11:06:35  lr: 0.000030  g_loss: 30.6067 (32.8342)  d_loss: 1.7088 (1.7112)  gan_loss: 1.2746 (1.2979)  pix_loss: 2.9329 (3.1536)  time: 54.4177  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [260/985]  eta: 10:57:31  lr: 0.000030  g_loss: 30.3113 (32.7486)  d_loss: 1.7108 (1.7112)  gan_loss: 1.2436 (1.2964)  pix_loss: 2.9074 (3.1452)  time: 54.4176  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [270/985]  eta: 10:48:27  lr: 0.000030  g_loss: 30.4217 (32.6983)  d_loss: 1.7107 (1.7112)  gan_loss: 1.2436 (1.2962)  pix_loss: 2.9187 (3.1402)  time: 54.4139  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [280/985]  eta: 10:39:22  lr: 0.000030  g_loss: 30.8994 (32.6335)  d_loss: 1.7107 (1.7113)  gan_loss: 1.2435 (1.2949)  pix_loss: 2.9602 (3.1339)  time: 54.4109  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [290/985]  eta: 10:30:18  lr: 0.000030  g_loss: 31.0650 (32.5764)  d_loss: 1.7115 (1.7114)  gan_loss: 1.2937 (1.2941)  pix_loss: 2.9849 (3.1282)  time: 54.4095  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [300/985]  eta: 10:21:14  lr: 0.000030  g_loss: 31.5270 (32.6092)  d_loss: 1.7122 (1.7116)  gan_loss: 1.2968 (1.2960)  pix_loss: 3.0210 (3.1313)  time: 54.4130  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [310/985]  eta: 10:12:10  lr: 0.000030  g_loss: 31.6540 (32.5815)  d_loss: 1.7133 (1.7117)  gan_loss: 1.3033 (1.2965)  pix_loss: 3.0336 (3.1285)  time: 54.4154  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [320/985]  eta: 10:03:06  lr: 0.000030  g_loss: 30.4519 (32.4898)  d_loss: 1.7127 (1.7117)  gan_loss: 1.2684 (1.2946)  pix_loss: 2.9195 (3.1195)  time: 54.4221  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [330/985]  eta: 9:54:02  lr: 0.000030  g_loss: 29.9357 (32.4359)  d_loss: 1.7097 (1.7117)  gan_loss: 1.2347 (1.2935)  pix_loss: 2.8681 (3.1142)  time: 54.4203  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [340/985]  eta: 9:44:57  lr: 0.000030  g_loss: 29.9194 (32.3529)  d_loss: 1.7110 (1.7117)  gan_loss: 1.2347 (1.2918)  pix_loss: 2.8721 (3.1061)  time: 54.4125  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [350/985]  eta: 9:35:54  lr: 0.000030  g_loss: 29.4149 (32.2685)  d_loss: 1.7090 (1.7116)  gan_loss: 1.2364 (1.2900)  pix_loss: 2.8192 (3.0978)  time: 54.4241  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [360/985]  eta: 9:26:50  lr: 0.000030  g_loss: 29.5658 (32.2168)  d_loss: 1.7091 (1.7116)  gan_loss: 1.2421 (1.2893)  pix_loss: 2.8340 (3.0927)  time: 54.4376  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [370/985]  eta: 9:17:46  lr: 0.000030  g_loss: 29.5658 (32.1497)  d_loss: 1.7110 (1.7116)  gan_loss: 1.2517 (1.2885)  pix_loss: 2.8340 (3.0861)  time: 54.4261  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [380/985]  eta: 9:08:41  lr: 0.000030  g_loss: 29.1005 (32.0719)  d_loss: 1.7110 (1.7115)  gan_loss: 1.2315 (1.2871)  pix_loss: 2.7882 (3.0785)  time: 54.4082  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [390/985]  eta: 8:59:33  lr: 0.000030  g_loss: 28.4333 (31.9956)  d_loss: 1.7110 (1.7116)  gan_loss: 1.2197 (1.2856)  pix_loss: 2.7233 (3.0710)  time: 54.2791  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [400/985]  eta: 8:50:26  lr: 0.000030  g_loss: 28.4333 (31.9346)  d_loss: 1.7102 (1.7115)  gan_loss: 1.2349 (1.2849)  pix_loss: 2.7233 (3.0650)  time: 54.1636  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [410/985]  eta: 8:41:17  lr: 0.000030  g_loss: 29.4543 (31.8766)  d_loss: 1.7099 (1.7115)  gan_loss: 1.2401 (1.2840)  pix_loss: 2.8211 (3.0593)  time: 54.1193  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [420/985]  eta: 8:32:09  lr: 0.000030  g_loss: 29.5961 (31.8218)  d_loss: 1.7099 (1.7115)  gan_loss: 1.2497 (1.2829)  pix_loss: 2.8365 (3.0539)  time: 54.0689  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [430/985]  eta: 8:23:00  lr: 0.000030  g_loss: 29.7972 (31.7883)  d_loss: 1.7111 (1.7115)  gan_loss: 1.2562 (1.2828)  pix_loss: 2.8508 (3.0506)  time: 54.0668  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [440/985]  eta: 8:13:53  lr: 0.000030  g_loss: 29.3167 (31.7325)  d_loss: 1.7100 (1.7115)  gan_loss: 1.2594 (1.2819)  pix_loss: 2.8045 (3.0451)  time: 54.0679  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [450/985]  eta: 8:04:46  lr: 0.000030  g_loss: 28.6147 (31.6816)  d_loss: 1.7097 (1.7114)  gan_loss: 1.2221 (1.2809)  pix_loss: 2.7406 (3.0401)  time: 54.0697  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [460/985]  eta: 7:55:39  lr: 0.000030  g_loss: 28.7250 (31.6318)  d_loss: 1.7099 (1.7115)  gan_loss: 1.2346 (1.2804)  pix_loss: 2.7490 (3.0351)  time: 54.0766  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [470/985]  eta: 7:46:32  lr: 0.000030  g_loss: 29.0457 (31.5834)  d_loss: 1.7121 (1.7116)  gan_loss: 1.2360 (1.2796)  pix_loss: 2.7827 (3.0304)  time: 54.0723  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [480/985]  eta: 7:37:25  lr: 0.000030  g_loss: 28.8264 (31.5279)  d_loss: 1.7150 (1.7116)  gan_loss: 1.2148 (1.2787)  pix_loss: 2.7591 (3.0249)  time: 54.0611  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [490/985]  eta: 7:28:19  lr: 0.000030  g_loss: 28.4817 (31.4711)  d_loss: 1.7113 (1.7116)  gan_loss: 1.2232 (1.2778)  pix_loss: 2.7234 (3.0193)  time: 54.0621  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [500/985]  eta: 7:19:13  lr: 0.000030  g_loss: 28.4299 (31.4091)  d_loss: 1.7102 (1.7116)  gan_loss: 1.2381 (1.2769)  pix_loss: 2.7214 (3.0132)  time: 54.0606  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [510/985]  eta: 7:10:07  lr: 0.000030  g_loss: 28.5189 (31.3602)  d_loss: 1.7092 (1.7115)  gan_loss: 1.2381 (1.2761)  pix_loss: 2.7328 (3.0084)  time: 54.0640  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [520/985]  eta: 7:01:01  lr: 0.000030  g_loss: 27.6061 (31.2691)  d_loss: 1.7110 (1.7116)  gan_loss: 1.1907 (1.2739)  pix_loss: 2.6386 (2.9995)  time: 54.0641  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [530/985]  eta: 6:51:56  lr: 0.000030  g_loss: 27.0455 (31.2436)  d_loss: 1.7101 (1.7115)  gan_loss: 1.1916 (1.2744)  pix_loss: 2.5873 (2.9969)  time: 54.0641  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [540/985]  eta: 6:42:50  lr: 0.000030  g_loss: 28.4674 (31.1786)  d_loss: 1.7101 (1.7115)  gan_loss: 1.2207 (1.2731)  pix_loss: 2.7247 (2.9906)  time: 54.0647  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [550/985]  eta: 6:33:45  lr: 0.000030  g_loss: 28.4674 (31.1271)  d_loss: 1.7125 (1.7115)  gan_loss: 1.2328 (1.2723)  pix_loss: 2.7247 (2.9855)  time: 54.0635  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [560/985]  eta: 6:24:40  lr: 0.000030  g_loss: 28.1856 (31.0495)  d_loss: 1.7112 (1.7115)  gan_loss: 1.2204 (1.2708)  pix_loss: 2.6985 (2.9779)  time: 54.0636  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [570/985]  eta: 6:15:35  lr: 0.000030  g_loss: 26.5999 (30.9770)  d_loss: 1.7114 (1.7115)  gan_loss: 1.1797 (1.2692)  pix_loss: 2.5458 (2.9708)  time: 54.0683  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [580/985]  eta: 6:06:31  lr: 0.000030  g_loss: 26.5999 (30.9010)  d_loss: 1.7142 (1.7117)  gan_loss: 1.1654 (1.2675)  pix_loss: 2.5458 (2.9634)  time: 54.0717  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [590/985]  eta: 5:57:26  lr: 0.000030  g_loss: 26.2340 (30.8373)  d_loss: 1.7211 (1.7119)  gan_loss: 1.1521 (1.2662)  pix_loss: 2.5104 (2.9571)  time: 54.0722  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [600/985]  eta: 5:48:22  lr: 0.000030  g_loss: 26.7538 (30.7738)  d_loss: 1.7186 (1.7119)  gan_loss: 1.1744 (1.2649)  pix_loss: 2.5583 (2.9509)  time: 54.0738  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [610/985]  eta: 5:39:18  lr: 0.000030  g_loss: 26.9280 (30.7178)  d_loss: 1.7134 (1.7120)  gan_loss: 1.1744 (1.2638)  pix_loss: 2.5754 (2.9454)  time: 54.0740  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [620/985]  eta: 5:30:13  lr: 0.000030  g_loss: 26.7900 (30.6514)  d_loss: 1.7134 (1.7120)  gan_loss: 1.1741 (1.2625)  pix_loss: 2.5619 (2.9389)  time: 54.0758  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [630/985]  eta: 5:21:09  lr: 0.000030  g_loss: 26.9066 (30.5965)  d_loss: 1.7137 (1.7121)  gan_loss: 1.1987 (1.2617)  pix_loss: 2.5692 (2.9335)  time: 54.0716  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [640/985]  eta: 5:12:05  lr: 0.000030  g_loss: 27.1559 (30.5522)  d_loss: 1.7132 (1.7121)  gan_loss: 1.2119 (1.2612)  pix_loss: 2.5957 (2.9291)  time: 54.0680  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [650/985]  eta: 5:03:02  lr: 0.000030  g_loss: 27.1505 (30.4894)  d_loss: 1.7137 (1.7122)  gan_loss: 1.2119 (1.2599)  pix_loss: 2.5929 (2.9229)  time: 54.0672  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [660/985]  eta: 4:53:58  lr: 0.000030  g_loss: 26.4870 (30.4280)  d_loss: 1.7193 (1.7123)  gan_loss: 1.1597 (1.2586)  pix_loss: 2.5284 (2.9169)  time: 54.0682  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [670/985]  eta: 4:44:54  lr: 0.000030  g_loss: 26.2951 (30.3694)  d_loss: 1.7186 (1.7124)  gan_loss: 1.1554 (1.2574)  pix_loss: 2.5140 (2.9112)  time: 54.0715  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [680/985]  eta: 4:35:53  lr: 0.000030  g_loss: 26.7966 (30.3244)  d_loss: 1.7199 (1.7125)  gan_loss: 1.1880 (1.2567)  pix_loss: 2.5581 (2.9068)  time: 54.2937  data: 0.0004  max mem: 38397\n",
      "Train: [epoch:5]  [690/985]  eta: 4:26:49  lr: 0.000030  g_loss: 26.6609 (30.2574)  d_loss: 1.7228 (1.7127)  gan_loss: 1.1831 (1.2554)  pix_loss: 2.5472 (2.9002)  time: 54.2866  data: 0.0004  max mem: 38397\n",
      "Train: [epoch:5]  [700/985]  eta: 4:17:53  lr: 0.000030  g_loss: 26.4837 (30.2056)  d_loss: 1.7220 (1.7128)  gan_loss: 1.1831 (1.2545)  pix_loss: 2.5293 (2.8951)  time: 54.9447  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [710/985]  eta: 4:09:17  lr: 0.000030  g_loss: 26.6192 (30.1516)  d_loss: 1.7156 (1.7128)  gan_loss: 1.1926 (1.2536)  pix_loss: 2.5415 (2.8898)  time: 58.6055  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [720/985]  eta: 4:00:32  lr: 0.000030  g_loss: 26.1451 (30.0933)  d_loss: 1.7122 (1.7128)  gan_loss: 1.1823 (1.2525)  pix_loss: 2.4933 (2.8841)  time: 60.4893  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [730/985]  eta: 3:51:26  lr: 0.000030  g_loss: 26.0791 (30.0391)  d_loss: 1.7110 (1.7128)  gan_loss: 1.1598 (1.2515)  pix_loss: 2.4922 (2.8788)  time: 56.8382  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [740/985]  eta: 3:42:20  lr: 0.000030  g_loss: 25.3612 (29.9893)  d_loss: 1.7124 (1.7128)  gan_loss: 1.1598 (1.2506)  pix_loss: 2.4205 (2.8739)  time: 54.0783  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [750/985]  eta: 3:33:36  lr: 0.000030  g_loss: 25.3285 (29.9304)  d_loss: 1.7124 (1.7128)  gan_loss: 1.1670 (1.2496)  pix_loss: 2.4162 (2.8681)  time: 57.5176  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [760/985]  eta: 3:24:55  lr: 0.000030  g_loss: 25.5037 (29.8708)  d_loss: 1.7098 (1.7128)  gan_loss: 1.1558 (1.2482)  pix_loss: 2.4340 (2.8623)  time: 61.8041  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [770/985]  eta: 3:15:47  lr: 0.000030  g_loss: 25.8737 (29.8203)  d_loss: 1.7147 (1.7128)  gan_loss: 1.1560 (1.2474)  pix_loss: 2.4718 (2.8573)  time: 58.4399  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [780/985]  eta: 3:06:57  lr: 0.000030  g_loss: 25.8857 (29.7696)  d_loss: 1.7162 (1.7129)  gan_loss: 1.1804 (1.2466)  pix_loss: 2.4719 (2.8523)  time: 57.4496  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [790/985]  eta: 2:57:48  lr: 0.000030  g_loss: 25.6054 (29.7200)  d_loss: 1.7154 (1.7129)  gan_loss: 1.1754 (1.2456)  pix_loss: 2.4446 (2.8474)  time: 57.3657  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [800/985]  eta: 2:48:39  lr: 0.000030  g_loss: 25.5934 (29.6658)  d_loss: 1.7163 (1.7130)  gan_loss: 1.1593 (1.2445)  pix_loss: 2.4434 (2.8421)  time: 54.0593  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [810/985]  eta: 2:39:31  lr: 0.000030  g_loss: 25.2788 (29.6123)  d_loss: 1.7159 (1.7130)  gan_loss: 1.1592 (1.2435)  pix_loss: 2.4087 (2.8369)  time: 54.0554  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:5]  [820/985]  eta: 2:30:23  lr: 0.000030  g_loss: 24.9230 (29.5597)  d_loss: 1.7133 (1.7130)  gan_loss: 1.1524 (1.2425)  pix_loss: 2.3777 (2.8317)  time: 54.0585  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [830/985]  eta: 2:21:15  lr: 0.000030  g_loss: 24.6233 (29.5024)  d_loss: 1.7126 (1.7130)  gan_loss: 1.1333 (1.2413)  pix_loss: 2.3481 (2.8261)  time: 54.0607  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [840/985]  eta: 2:12:07  lr: 0.000030  g_loss: 24.6350 (29.4575)  d_loss: 1.7131 (1.7130)  gan_loss: 1.1541 (1.2405)  pix_loss: 2.3497 (2.8217)  time: 54.0596  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [850/985]  eta: 2:02:59  lr: 0.000030  g_loss: 25.6387 (29.4088)  d_loss: 1.7118 (1.7130)  gan_loss: 1.1584 (1.2396)  pix_loss: 2.4449 (2.8169)  time: 54.0633  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [860/985]  eta: 1:53:52  lr: 0.000030  g_loss: 25.0268 (29.3569)  d_loss: 1.7118 (1.7130)  gan_loss: 1.1480 (1.2387)  pix_loss: 2.3877 (2.8118)  time: 54.0627  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [870/985]  eta: 1:44:44  lr: 0.000030  g_loss: 24.6680 (29.3090)  d_loss: 1.7128 (1.7130)  gan_loss: 1.1512 (1.2378)  pix_loss: 2.3519 (2.8071)  time: 54.0636  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [880/985]  eta: 1:35:37  lr: 0.000030  g_loss: 24.6930 (29.2553)  d_loss: 1.7119 (1.7129)  gan_loss: 1.1597 (1.2369)  pix_loss: 2.3542 (2.8018)  time: 54.0630  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [890/985]  eta: 1:26:30  lr: 0.000030  g_loss: 24.8582 (29.2075)  d_loss: 1.7084 (1.7129)  gan_loss: 1.1629 (1.2361)  pix_loss: 2.3699 (2.7971)  time: 54.0665  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [900/985]  eta: 1:17:23  lr: 0.000030  g_loss: 24.3256 (29.1464)  d_loss: 1.7088 (1.7128)  gan_loss: 1.1431 (1.2348)  pix_loss: 2.3175 (2.7912)  time: 54.0747  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [910/985]  eta: 1:08:16  lr: 0.000030  g_loss: 23.8936 (29.0998)  d_loss: 1.7104 (1.7128)  gan_loss: 1.1324 (1.2340)  pix_loss: 2.2771 (2.7866)  time: 54.0669  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [920/985]  eta: 0:59:10  lr: 0.000030  g_loss: 24.0560 (29.0511)  d_loss: 1.7120 (1.7128)  gan_loss: 1.1324 (1.2332)  pix_loss: 2.2913 (2.7818)  time: 54.0575  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [930/985]  eta: 0:50:03  lr: 0.000030  g_loss: 24.0179 (29.0035)  d_loss: 1.7131 (1.7128)  gan_loss: 1.1256 (1.2322)  pix_loss: 2.2934 (2.7771)  time: 54.0574  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [940/985]  eta: 0:40:57  lr: 0.000030  g_loss: 24.0351 (28.9518)  d_loss: 1.7115 (1.7128)  gan_loss: 1.1410 (1.2312)  pix_loss: 2.2934 (2.7721)  time: 54.0574  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [950/985]  eta: 0:31:51  lr: 0.000030  g_loss: 24.0351 (28.8972)  d_loss: 1.7113 (1.7128)  gan_loss: 1.1371 (1.2300)  pix_loss: 2.2889 (2.7667)  time: 54.0603  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [960/985]  eta: 0:22:44  lr: 0.000030  g_loss: 23.9694 (28.8568)  d_loss: 1.7119 (1.7128)  gan_loss: 1.1280 (1.2293)  pix_loss: 2.2807 (2.7627)  time: 54.0581  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [970/985]  eta: 0:13:38  lr: 0.000030  g_loss: 23.4848 (28.7977)  d_loss: 1.7103 (1.7128)  gan_loss: 1.1166 (1.2280)  pix_loss: 2.2355 (2.7570)  time: 54.0539  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [980/985]  eta: 0:04:32  lr: 0.000030  g_loss: 23.1966 (28.7500)  d_loss: 1.7110 (1.7128)  gan_loss: 1.1313 (1.2271)  pix_loss: 2.2104 (2.7523)  time: 54.0570  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5]  [984/985]  eta: 0:00:54  lr: 0.000030  g_loss: 23.7555 (28.7278)  d_loss: 1.7139 (1.7128)  gan_loss: 1.1376 (1.2267)  pix_loss: 2.2612 (2.7501)  time: 54.0579  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:5] Total time: 14:56:03 (54.5821 s / it)\n",
      "Averaged stats: lr: 0.000030  g_loss: 23.7555 (28.7278)  d_loss: 1.7139 (1.7128)  gan_loss: 1.1376 (1.2267)  pix_loss: 2.2612 (2.7501)\n",
      "Valid: [epoch:5]  [ 0/14]  eta: 0:01:33  L1_loss: 0.2940 (0.2940)  time: 6.6808  data: 0.3811  max mem: 38397\n",
      "Valid: [epoch:5]  [13/14]  eta: 0:00:06  L1_loss: 0.3301 (0.3378)  time: 6.1874  data: 0.0273  max mem: 38397\n",
      "Valid: [epoch:5] Total time: 0:01:26 (6.1944 s / it)\n",
      "Averaged stats: L1_loss: 0.3301 (0.3378)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_5_input_n_20.png\n",
      "/home/sunggu/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Train: [epoch:6]  [  0/985]  eta: 15:13:04  lr: 0.000050  g_loss: 22.8069 (22.8069)  d_loss: 1.7093 (1.7093)  gan_loss: 1.1109 (1.1109)  pix_loss: 2.1696 (2.1696)  time: 55.6190  data: 1.4669  max mem: 38397\n",
      "Train: [epoch:6]  [ 10/985]  eta: 14:40:52  lr: 0.000050  g_loss: 22.1253 (22.2305)  d_loss: 1.7132 (1.7142)  gan_loss: 1.1025 (1.0854)  pix_loss: 2.1030 (2.1145)  time: 54.2078  data: 0.1335  max mem: 38397\n",
      "Train: [epoch:6]  [ 20/985]  eta: 14:30:44  lr: 0.000050  g_loss: 22.6137 (23.0888)  d_loss: 1.7140 (1.7162)  gan_loss: 1.1061 (1.1087)  pix_loss: 2.1529 (2.1980)  time: 54.0650  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:6]  [ 30/985]  eta: 14:21:17  lr: 0.000050  g_loss: 23.9856 (23.1895)  d_loss: 1.7239 (1.7208)  gan_loss: 1.1185 (1.1110)  pix_loss: 2.2842 (2.2079)  time: 54.0598  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [ 40/985]  eta: 14:12:06  lr: 0.000050  g_loss: 23.6692 (23.5281)  d_loss: 1.7348 (1.7260)  gan_loss: 1.1436 (1.1266)  pix_loss: 2.2522 (2.2402)  time: 54.0626  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [ 50/985]  eta: 14:02:56  lr: 0.000050  g_loss: 23.5916 (23.3867)  d_loss: 1.7277 (1.7259)  gan_loss: 1.1301 (1.1215)  pix_loss: 2.2462 (2.2265)  time: 54.0630  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [ 60/985]  eta: 13:53:51  lr: 0.000050  g_loss: 22.7637 (23.3600)  d_loss: 1.7211 (1.7250)  gan_loss: 1.1100 (1.1207)  pix_loss: 2.1654 (2.2239)  time: 54.0590  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [ 70/985]  eta: 13:44:46  lr: 0.000050  g_loss: 23.2066 (23.3136)  d_loss: 1.7140 (1.7231)  gan_loss: 1.1099 (1.1196)  pix_loss: 2.2099 (2.2194)  time: 54.0585  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [ 80/985]  eta: 13:35:42  lr: 0.000050  g_loss: 23.2809 (23.2756)  d_loss: 1.7142 (1.7224)  gan_loss: 1.1200 (1.1189)  pix_loss: 2.2158 (2.2157)  time: 54.0568  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [ 90/985]  eta: 13:26:40  lr: 0.000050  g_loss: 22.8103 (23.2421)  d_loss: 1.7189 (1.7223)  gan_loss: 1.1055 (1.1183)  pix_loss: 2.1705 (2.2124)  time: 54.0603  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [100/985]  eta: 13:17:38  lr: 0.000050  g_loss: 22.8103 (23.2522)  d_loss: 1.7222 (1.7226)  gan_loss: 1.1055 (1.1198)  pix_loss: 2.1705 (2.2132)  time: 54.0638  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [110/985]  eta: 13:08:35  lr: 0.000050  g_loss: 22.4102 (23.1629)  d_loss: 1.7270 (1.7232)  gan_loss: 1.0953 (1.1170)  pix_loss: 2.1315 (2.2046)  time: 54.0614  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [120/985]  eta: 12:59:33  lr: 0.000050  g_loss: 21.9917 (23.0929)  d_loss: 1.7345 (1.7243)  gan_loss: 1.0849 (1.1149)  pix_loss: 2.0907 (2.1978)  time: 54.0574  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [130/985]  eta: 12:50:32  lr: 0.000050  g_loss: 22.0178 (23.0489)  d_loss: 1.7280 (1.7242)  gan_loss: 1.0953 (1.1133)  pix_loss: 2.0922 (2.1936)  time: 54.0582  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [140/985]  eta: 12:41:30  lr: 0.000050  g_loss: 22.0324 (22.9859)  d_loss: 1.7209 (1.7239)  gan_loss: 1.0967 (1.1119)  pix_loss: 2.0949 (2.1874)  time: 54.0607  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [150/985]  eta: 12:32:29  lr: 0.000050  g_loss: 21.5527 (22.9009)  d_loss: 1.7169 (1.7234)  gan_loss: 1.0835 (1.1095)  pix_loss: 2.0516 (2.1791)  time: 54.0598  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [160/985]  eta: 12:23:28  lr: 0.000050  g_loss: 21.5003 (22.8259)  d_loss: 1.7167 (1.7235)  gan_loss: 1.0606 (1.1070)  pix_loss: 2.0440 (2.1719)  time: 54.0613  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [170/985]  eta: 12:14:27  lr: 0.000050  g_loss: 21.5529 (22.7837)  d_loss: 1.7194 (1.7233)  gan_loss: 1.0719 (1.1065)  pix_loss: 2.0522 (2.1677)  time: 54.0631  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [180/985]  eta: 12:05:26  lr: 0.000050  g_loss: 22.0864 (22.7440)  d_loss: 1.7186 (1.7229)  gan_loss: 1.0882 (1.1063)  pix_loss: 2.0985 (2.1638)  time: 54.0646  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [190/985]  eta: 11:56:25  lr: 0.000050  g_loss: 21.6342 (22.6694)  d_loss: 1.7176 (1.7228)  gan_loss: 1.0838 (1.1045)  pix_loss: 2.0534 (2.1565)  time: 54.0661  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:6]  [200/985]  eta: 11:47:24  lr: 0.000050  g_loss: 21.2631 (22.6200)  d_loss: 1.7193 (1.7230)  gan_loss: 1.0759 (1.1036)  pix_loss: 2.0175 (2.1516)  time: 54.0642  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [210/985]  eta: 11:38:23  lr: 0.000050  g_loss: 21.0231 (22.5299)  d_loss: 1.7217 (1.7231)  gan_loss: 1.0745 (1.1017)  pix_loss: 1.9951 (2.1428)  time: 54.0638  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [220/985]  eta: 11:29:22  lr: 0.000050  g_loss: 20.6102 (22.4378)  d_loss: 1.7235 (1.7235)  gan_loss: 1.0538 (1.0998)  pix_loss: 1.9553 (2.1338)  time: 54.0684  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [230/985]  eta: 11:20:22  lr: 0.000050  g_loss: 20.8188 (22.4213)  d_loss: 1.7211 (1.7235)  gan_loss: 1.0800 (1.0999)  pix_loss: 1.9765 (2.1321)  time: 54.0727  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [240/985]  eta: 11:11:21  lr: 0.000050  g_loss: 21.3050 (22.3493)  d_loss: 1.7204 (1.7233)  gan_loss: 1.0885 (1.0985)  pix_loss: 2.0211 (2.1251)  time: 54.0678  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [250/985]  eta: 11:02:20  lr: 0.000050  g_loss: 20.9073 (22.3046)  d_loss: 1.7162 (1.7230)  gan_loss: 1.0712 (1.0979)  pix_loss: 1.9847 (2.1207)  time: 54.0658  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [260/985]  eta: 10:53:20  lr: 0.000050  g_loss: 20.3597 (22.2445)  d_loss: 1.7184 (1.7230)  gan_loss: 1.0540 (1.0967)  pix_loss: 1.9323 (2.1148)  time: 54.0687  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [270/985]  eta: 10:44:19  lr: 0.000050  g_loss: 20.4182 (22.2045)  d_loss: 1.7184 (1.7228)  gan_loss: 1.0644 (1.0964)  pix_loss: 1.9373 (2.1108)  time: 54.0688  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [280/985]  eta: 10:35:18  lr: 0.000050  g_loss: 20.9927 (22.1586)  d_loss: 1.7192 (1.7228)  gan_loss: 1.0898 (1.0956)  pix_loss: 1.9915 (2.1063)  time: 54.0681  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [290/985]  eta: 10:26:17  lr: 0.000050  g_loss: 20.7773 (22.1099)  d_loss: 1.7198 (1.7227)  gan_loss: 1.0756 (1.0945)  pix_loss: 1.9720 (2.1015)  time: 54.0631  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [300/985]  eta: 10:17:17  lr: 0.000050  g_loss: 21.0134 (22.0723)  d_loss: 1.7186 (1.7225)  gan_loss: 1.0710 (1.0939)  pix_loss: 1.9943 (2.0978)  time: 54.0661  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [310/985]  eta: 10:08:16  lr: 0.000050  g_loss: 21.1531 (22.0518)  d_loss: 1.7180 (1.7225)  gan_loss: 1.0828 (1.0939)  pix_loss: 2.0060 (2.0958)  time: 54.0699  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [320/985]  eta: 9:59:15  lr: 0.000050  g_loss: 20.0435 (21.9813)  d_loss: 1.7243 (1.7228)  gan_loss: 1.0494 (1.0922)  pix_loss: 1.9029 (2.0889)  time: 54.0656  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [330/985]  eta: 9:50:14  lr: 0.000050  g_loss: 19.5978 (21.9307)  d_loss: 1.7266 (1.7230)  gan_loss: 1.0330 (1.0910)  pix_loss: 1.8587 (2.0840)  time: 54.0683  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [340/985]  eta: 9:41:14  lr: 0.000050  g_loss: 19.5325 (21.8564)  d_loss: 1.7288 (1.7234)  gan_loss: 1.0270 (1.0892)  pix_loss: 1.8493 (2.0767)  time: 54.0683  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [350/985]  eta: 9:32:13  lr: 0.000050  g_loss: 19.4547 (21.7951)  d_loss: 1.7278 (1.7234)  gan_loss: 1.0219 (1.0875)  pix_loss: 1.8429 (2.0708)  time: 54.0625  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [360/985]  eta: 9:23:12  lr: 0.000050  g_loss: 19.3664 (21.7286)  d_loss: 1.7184 (1.7232)  gan_loss: 1.0262 (1.0861)  pix_loss: 1.8362 (2.0642)  time: 54.0647  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [370/985]  eta: 9:14:11  lr: 0.000050  g_loss: 19.3664 (21.6683)  d_loss: 1.7202 (1.7232)  gan_loss: 1.0379 (1.0846)  pix_loss: 1.8362 (2.0584)  time: 54.0668  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [380/985]  eta: 9:05:11  lr: 0.000050  g_loss: 19.7652 (21.6396)  d_loss: 1.7185 (1.7230)  gan_loss: 1.0515 (1.0845)  pix_loss: 1.8720 (2.0555)  time: 54.0603  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [390/985]  eta: 8:56:10  lr: 0.000050  g_loss: 20.0949 (21.6042)  d_loss: 1.7181 (1.7231)  gan_loss: 1.0628 (1.0840)  pix_loss: 1.9032 (2.0520)  time: 54.0593  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [400/985]  eta: 8:47:09  lr: 0.000050  g_loss: 19.8299 (21.5565)  d_loss: 1.7275 (1.7234)  gan_loss: 1.0458 (1.0829)  pix_loss: 1.8796 (2.0474)  time: 54.0655  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [410/985]  eta: 8:38:09  lr: 0.000050  g_loss: 19.6036 (21.5081)  d_loss: 1.7311 (1.7236)  gan_loss: 1.0305 (1.0818)  pix_loss: 1.8559 (2.0426)  time: 54.0712  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [420/985]  eta: 8:29:08  lr: 0.000050  g_loss: 19.1002 (21.4474)  d_loss: 1.7311 (1.7238)  gan_loss: 1.0234 (1.0801)  pix_loss: 1.8074 (2.0367)  time: 54.0682  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [430/985]  eta: 8:20:07  lr: 0.000050  g_loss: 19.2538 (21.4144)  d_loss: 1.7362 (1.7242)  gan_loss: 1.0315 (1.0797)  pix_loss: 1.8204 (2.0335)  time: 54.0667  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [440/985]  eta: 8:11:07  lr: 0.000050  g_loss: 19.5984 (21.3722)  d_loss: 1.7366 (1.7243)  gan_loss: 1.0490 (1.0790)  pix_loss: 1.8547 (2.0293)  time: 54.0692  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [450/985]  eta: 8:02:06  lr: 0.000050  g_loss: 19.2080 (21.3240)  d_loss: 1.7245 (1.7243)  gan_loss: 1.0305 (1.0782)  pix_loss: 1.8181 (2.0246)  time: 54.0681  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [460/985]  eta: 7:53:05  lr: 0.000050  g_loss: 19.1145 (21.2796)  d_loss: 1.7227 (1.7242)  gan_loss: 1.0268 (1.0774)  pix_loss: 1.8088 (2.0202)  time: 54.0692  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [470/985]  eta: 7:44:04  lr: 0.000050  g_loss: 19.0999 (21.2376)  d_loss: 1.7218 (1.7242)  gan_loss: 1.0219 (1.0765)  pix_loss: 1.8082 (2.0161)  time: 54.0638  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [480/985]  eta: 7:35:05  lr: 0.000050  g_loss: 19.0999 (21.1964)  d_loss: 1.7232 (1.7243)  gan_loss: 1.0256 (1.0756)  pix_loss: 1.8082 (2.0121)  time: 54.1445  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [490/985]  eta: 7:26:05  lr: 0.000050  g_loss: 19.2858 (21.1621)  d_loss: 1.7257 (1.7243)  gan_loss: 1.0363 (1.0750)  pix_loss: 1.8263 (2.0087)  time: 54.1514  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [500/985]  eta: 7:17:04  lr: 0.000050  g_loss: 19.0129 (21.1234)  d_loss: 1.7234 (1.7243)  gan_loss: 1.0363 (1.0741)  pix_loss: 1.7988 (2.0049)  time: 54.0676  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [510/985]  eta: 7:08:03  lr: 0.000050  g_loss: 19.1765 (21.0856)  d_loss: 1.7194 (1.7242)  gan_loss: 1.0360 (1.0735)  pix_loss: 1.8145 (2.0012)  time: 54.0693  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [520/985]  eta: 6:59:03  lr: 0.000050  g_loss: 18.7054 (21.0336)  d_loss: 1.7192 (1.7242)  gan_loss: 1.0168 (1.0721)  pix_loss: 1.7701 (1.9961)  time: 54.0701  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [530/985]  eta: 6:50:02  lr: 0.000050  g_loss: 18.5369 (21.0101)  d_loss: 1.7225 (1.7242)  gan_loss: 1.0039 (1.0722)  pix_loss: 1.7520 (1.9938)  time: 54.0690  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [540/985]  eta: 6:41:01  lr: 0.000050  g_loss: 18.4581 (20.9628)  d_loss: 1.7249 (1.7242)  gan_loss: 1.0084 (1.0710)  pix_loss: 1.7425 (1.9892)  time: 54.0655  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [550/985]  eta: 6:32:00  lr: 0.000050  g_loss: 18.1832 (20.9081)  d_loss: 1.7223 (1.7241)  gan_loss: 0.9976 (1.0695)  pix_loss: 1.7175 (1.9839)  time: 54.0668  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [560/985]  eta: 6:23:00  lr: 0.000050  g_loss: 18.2479 (20.8666)  d_loss: 1.7240 (1.7243)  gan_loss: 1.0034 (1.0685)  pix_loss: 1.7242 (1.9798)  time: 54.0746  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [570/985]  eta: 6:13:59  lr: 0.000050  g_loss: 17.9766 (20.8110)  d_loss: 1.7345 (1.7245)  gan_loss: 1.0006 (1.0671)  pix_loss: 1.6961 (1.9744)  time: 54.0700  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [580/985]  eta: 6:04:58  lr: 0.000050  g_loss: 17.9073 (20.7591)  d_loss: 1.7311 (1.7247)  gan_loss: 0.9891 (1.0657)  pix_loss: 1.6902 (1.9693)  time: 54.0654  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [590/985]  eta: 5:55:57  lr: 0.000050  g_loss: 18.0175 (20.7148)  d_loss: 1.7294 (1.7247)  gan_loss: 0.9891 (1.0646)  pix_loss: 1.7049 (1.9650)  time: 54.0628  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [600/985]  eta: 5:46:57  lr: 0.000050  g_loss: 17.6671 (20.6663)  d_loss: 1.7214 (1.7247)  gan_loss: 0.9924 (1.0636)  pix_loss: 1.6679 (1.9603)  time: 54.0679  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [610/985]  eta: 5:37:56  lr: 0.000050  g_loss: 18.3263 (20.6329)  d_loss: 1.7192 (1.7246)  gan_loss: 1.0018 (1.0628)  pix_loss: 1.7303 (1.9570)  time: 54.0655  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [620/985]  eta: 5:28:55  lr: 0.000050  g_loss: 17.9545 (20.5844)  d_loss: 1.7237 (1.7246)  gan_loss: 0.9991 (1.0616)  pix_loss: 1.6955 (1.9523)  time: 54.0583  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [630/985]  eta: 5:19:57  lr: 0.000050  g_loss: 17.7487 (20.5463)  d_loss: 1.7280 (1.7247)  gan_loss: 0.9991 (1.0609)  pix_loss: 1.6745 (1.9485)  time: 54.2636  data: 0.0003  max mem: 38397\n",
      "Train: [epoch:6]  [640/985]  eta: 5:10:58  lr: 0.000050  g_loss: 18.4302 (20.5139)  d_loss: 1.7210 (1.7246)  gan_loss: 1.0123 (1.0603)  pix_loss: 1.7418 (1.9454)  time: 54.4427  data: 0.0003  max mem: 38397\n",
      "Train: [epoch:6]  [650/985]  eta: 5:01:57  lr: 0.000050  g_loss: 18.0158 (20.4689)  d_loss: 1.7199 (1.7245)  gan_loss: 1.0036 (1.0592)  pix_loss: 1.6994 (1.9410)  time: 54.2429  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [660/985]  eta: 4:52:56  lr: 0.000050  g_loss: 17.5603 (20.4345)  d_loss: 1.7228 (1.7246)  gan_loss: 0.9792 (1.0584)  pix_loss: 1.6550 (1.9376)  time: 54.0722  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [670/985]  eta: 4:43:55  lr: 0.000050  g_loss: 17.7589 (20.3924)  d_loss: 1.7326 (1.7248)  gan_loss: 0.9912 (1.0574)  pix_loss: 1.6768 (1.9335)  time: 54.0742  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [680/985]  eta: 4:34:54  lr: 0.000050  g_loss: 17.5076 (20.3521)  d_loss: 1.7331 (1.7250)  gan_loss: 1.0010 (1.0566)  pix_loss: 1.6499 (1.9295)  time: 54.0709  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [690/985]  eta: 4:25:53  lr: 0.000050  g_loss: 17.1644 (20.3151)  d_loss: 1.7312 (1.7251)  gan_loss: 1.0030 (1.0560)  pix_loss: 1.6173 (1.9259)  time: 54.0686  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [700/985]  eta: 4:16:53  lr: 0.000050  g_loss: 17.3304 (20.2763)  d_loss: 1.7257 (1.7251)  gan_loss: 1.0043 (1.0551)  pix_loss: 1.6324 (1.9221)  time: 54.0670  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [710/985]  eta: 4:07:52  lr: 0.000050  g_loss: 17.7477 (20.2446)  d_loss: 1.7245 (1.7250)  gan_loss: 1.0068 (1.0546)  pix_loss: 1.6721 (1.9190)  time: 54.0680  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [720/985]  eta: 3:58:51  lr: 0.000050  g_loss: 17.8681 (20.2090)  d_loss: 1.7273 (1.7251)  gan_loss: 0.9928 (1.0538)  pix_loss: 1.6871 (1.9155)  time: 54.0704  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [730/985]  eta: 3:49:50  lr: 0.000050  g_loss: 17.6328 (20.1752)  d_loss: 1.7278 (1.7251)  gan_loss: 0.9854 (1.0530)  pix_loss: 1.6654 (1.9122)  time: 54.0713  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [740/985]  eta: 3:40:49  lr: 0.000050  g_loss: 17.7454 (20.1470)  d_loss: 1.7258 (1.7251)  gan_loss: 1.0038 (1.0526)  pix_loss: 1.6769 (1.9094)  time: 54.0671  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [750/985]  eta: 3:31:48  lr: 0.000050  g_loss: 17.2050 (20.1037)  d_loss: 1.7282 (1.7253)  gan_loss: 0.9944 (1.0515)  pix_loss: 1.6211 (1.9052)  time: 54.0746  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [760/985]  eta: 3:22:48  lr: 0.000050  g_loss: 17.1687 (20.0684)  d_loss: 1.7284 (1.7252)  gan_loss: 0.9844 (1.0508)  pix_loss: 1.6183 (1.9018)  time: 54.0768  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [770/985]  eta: 3:13:47  lr: 0.000050  g_loss: 17.3384 (20.0308)  d_loss: 1.7223 (1.7252)  gan_loss: 0.9824 (1.0499)  pix_loss: 1.6348 (1.8981)  time: 54.0636  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [780/985]  eta: 3:04:46  lr: 0.000050  g_loss: 17.0906 (19.9964)  d_loss: 1.7238 (1.7252)  gan_loss: 0.9848 (1.0492)  pix_loss: 1.6131 (1.8947)  time: 54.0597  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [790/985]  eta: 2:55:45  lr: 0.000050  g_loss: 17.0407 (19.9561)  d_loss: 1.7218 (1.7251)  gan_loss: 0.9751 (1.0481)  pix_loss: 1.6077 (1.8908)  time: 54.0628  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [800/985]  eta: 2:46:44  lr: 0.000050  g_loss: 16.7745 (19.9212)  d_loss: 1.7209 (1.7250)  gan_loss: 0.9656 (1.0474)  pix_loss: 1.5779 (1.8874)  time: 54.0679  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [810/985]  eta: 2:37:43  lr: 0.000050  g_loss: 16.8740 (19.8902)  d_loss: 1.7178 (1.7250)  gan_loss: 0.9836 (1.0469)  pix_loss: 1.5891 (1.8843)  time: 54.0714  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [820/985]  eta: 2:28:43  lr: 0.000050  g_loss: 16.8630 (19.8475)  d_loss: 1.7259 (1.7251)  gan_loss: 0.9794 (1.0458)  pix_loss: 1.5873 (1.8802)  time: 54.0697  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [830/985]  eta: 2:19:42  lr: 0.000050  g_loss: 16.3929 (19.8066)  d_loss: 1.7302 (1.7251)  gan_loss: 0.9525 (1.0447)  pix_loss: 1.5455 (1.8762)  time: 54.0673  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [840/985]  eta: 2:10:41  lr: 0.000050  g_loss: 16.5322 (19.7678)  d_loss: 1.7292 (1.7252)  gan_loss: 0.9654 (1.0438)  pix_loss: 1.5546 (1.8724)  time: 54.0633  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [850/985]  eta: 2:01:40  lr: 0.000050  g_loss: 16.3338 (19.7306)  d_loss: 1.7270 (1.7252)  gan_loss: 0.9654 (1.0428)  pix_loss: 1.5377 (1.8688)  time: 54.0606  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [860/985]  eta: 1:52:39  lr: 0.000050  g_loss: 16.3611 (19.6949)  d_loss: 1.7245 (1.7252)  gan_loss: 0.9643 (1.0420)  pix_loss: 1.5417 (1.8653)  time: 54.0637  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [870/985]  eta: 1:43:38  lr: 0.000050  g_loss: 16.5934 (19.6574)  d_loss: 1.7234 (1.7252)  gan_loss: 0.9638 (1.0410)  pix_loss: 1.5636 (1.8616)  time: 54.0654  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [880/985]  eta: 1:34:38  lr: 0.000050  g_loss: 16.5934 (19.6201)  d_loss: 1.7268 (1.7253)  gan_loss: 0.9576 (1.0401)  pix_loss: 1.5636 (1.8580)  time: 54.0674  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [890/985]  eta: 1:25:37  lr: 0.000050  g_loss: 16.4025 (19.5882)  d_loss: 1.7328 (1.7255)  gan_loss: 0.9609 (1.0393)  pix_loss: 1.5449 (1.8549)  time: 54.0676  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [900/985]  eta: 1:16:36  lr: 0.000050  g_loss: 16.2624 (19.5533)  d_loss: 1.7494 (1.7258)  gan_loss: 0.9609 (1.0385)  pix_loss: 1.5316 (1.8515)  time: 54.0682  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [910/985]  eta: 1:07:35  lr: 0.000050  g_loss: 16.1987 (19.5193)  d_loss: 1.7531 (1.7261)  gan_loss: 0.9513 (1.0376)  pix_loss: 1.5254 (1.8482)  time: 54.0744  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [920/985]  eta: 0:58:35  lr: 0.000050  g_loss: 16.1484 (19.4835)  d_loss: 1.7473 (1.7263)  gan_loss: 0.9593 (1.0368)  pix_loss: 1.5179 (1.8447)  time: 54.0699  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [930/985]  eta: 0:49:34  lr: 0.000050  g_loss: 15.8571 (19.4426)  d_loss: 1.7421 (1.7265)  gan_loss: 0.9593 (1.0358)  pix_loss: 1.4880 (1.8407)  time: 54.0601  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [940/985]  eta: 0:40:33  lr: 0.000050  g_loss: 15.9120 (19.4080)  d_loss: 1.7334 (1.7265)  gan_loss: 0.9494 (1.0349)  pix_loss: 1.4964 (1.8373)  time: 54.0607  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [950/985]  eta: 0:31:32  lr: 0.000050  g_loss: 15.9828 (19.3730)  d_loss: 1.7262 (1.7265)  gan_loss: 0.9522 (1.0340)  pix_loss: 1.5071 (1.8339)  time: 54.0665  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [960/985]  eta: 0:22:31  lr: 0.000050  g_loss: 15.9309 (19.3420)  d_loss: 1.7256 (1.7265)  gan_loss: 0.9588 (1.0333)  pix_loss: 1.4961 (1.8309)  time: 54.0663  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [970/985]  eta: 0:13:31  lr: 0.000050  g_loss: 16.0252 (19.3084)  d_loss: 1.7248 (1.7264)  gan_loss: 0.9612 (1.0325)  pix_loss: 1.5073 (1.8276)  time: 54.0621  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:6]  [980/985]  eta: 0:04:30  lr: 0.000050  g_loss: 15.9553 (19.2748)  d_loss: 1.7261 (1.7264)  gan_loss: 0.9527 (1.0317)  pix_loss: 1.4983 (1.8243)  time: 54.0635  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:6]  [984/985]  eta: 0:00:54  lr: 0.000050  g_loss: 15.6294 (19.2623)  d_loss: 1.7268 (1.7264)  gan_loss: 0.9458 (1.0315)  pix_loss: 1.4681 (1.8231)  time: 54.0694  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:6] Total time: 14:47:45 (54.0771 s / it)\n",
      "Averaged stats: lr: 0.000050  g_loss: 15.6294 (19.2623)  d_loss: 1.7268 (1.7264)  gan_loss: 0.9458 (1.0315)  pix_loss: 1.4681 (1.8231)\n",
      "Valid: [epoch:6]  [ 0/14]  eta: 0:01:33  L1_loss: 0.1738 (0.1738)  time: 6.6489  data: 0.3906  max mem: 38397\n",
      "Valid: [epoch:6]  [13/14]  eta: 0:00:06  L1_loss: 0.1845 (0.1875)  time: 6.1916  data: 0.0280  max mem: 38397\n",
      "Valid: [epoch:6] Total time: 0:01:26 (6.1979 s / it)\n",
      "Averaged stats: L1_loss: 0.1845 (0.1875)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_6_input_n_20.png\n",
      "Train: [epoch:7]  [  0/985]  eta: 15:05:36  lr: 0.000060  g_loss: 15.4021 (15.4021)  d_loss: 1.7264 (1.7264)  gan_loss: 0.9287 (0.9287)  pix_loss: 1.4473 (1.4473)  time: 55.1639  data: 1.0330  max mem: 38397\n",
      "Train: [epoch:7]  [ 10/985]  eta: 14:40:17  lr: 0.000060  g_loss: 15.6591 (15.5280)  d_loss: 1.7331 (1.7375)  gan_loss: 0.9367 (0.9342)  pix_loss: 1.4718 (1.4594)  time: 54.1720  data: 0.0940  max mem: 38397\n",
      "Train: [epoch:7]  [ 20/985]  eta: 14:30:28  lr: 0.000060  g_loss: 15.8765 (15.7959)  d_loss: 1.7375 (1.7393)  gan_loss: 0.9441 (0.9486)  pix_loss: 1.4926 (1.4847)  time: 54.0708  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [ 30/985]  eta: 14:21:09  lr: 0.000060  g_loss: 15.8822 (15.7408)  d_loss: 1.7375 (1.7387)  gan_loss: 0.9470 (0.9454)  pix_loss: 1.4926 (1.4795)  time: 54.0664  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [ 40/985]  eta: 14:11:58  lr: 0.000060  g_loss: 15.4787 (15.7340)  d_loss: 1.7397 (1.7402)  gan_loss: 0.9367 (0.9464)  pix_loss: 1.4530 (1.4788)  time: 54.0640  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [ 50/985]  eta: 14:02:52  lr: 0.000060  g_loss: 15.8213 (15.6992)  d_loss: 1.7411 (1.7403)  gan_loss: 0.9403 (0.9438)  pix_loss: 1.4876 (1.4755)  time: 54.0634  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:7]  [ 60/985]  eta: 13:53:47  lr: 0.000060  g_loss: 15.5342 (15.7175)  d_loss: 1.7393 (1.7400)  gan_loss: 0.9403 (0.9455)  pix_loss: 1.4609 (1.4772)  time: 54.0635  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:7]  [ 70/985]  eta: 13:44:44  lr: 0.000060  g_loss: 15.5189 (15.6960)  d_loss: 1.7431 (1.7406)  gan_loss: 0.9444 (0.9449)  pix_loss: 1.4574 (1.4751)  time: 54.0653  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [ 80/985]  eta: 13:35:42  lr: 0.000060  g_loss: 15.5189 (15.6985)  d_loss: 1.7369 (1.7396)  gan_loss: 0.9444 (0.9446)  pix_loss: 1.4574 (1.4754)  time: 54.0685  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [ 90/985]  eta: 13:26:39  lr: 0.000060  g_loss: 15.4272 (15.6484)  d_loss: 1.7294 (1.7384)  gan_loss: 0.9363 (0.9434)  pix_loss: 1.4477 (1.4705)  time: 54.0660  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:7]  [100/985]  eta: 13:17:38  lr: 0.000060  g_loss: 15.3840 (15.6500)  d_loss: 1.7283 (1.7371)  gan_loss: 0.9330 (0.9440)  pix_loss: 1.4451 (1.4706)  time: 54.0641  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [110/985]  eta: 13:08:36  lr: 0.000060  g_loss: 15.4539 (15.6493)  d_loss: 1.7257 (1.7358)  gan_loss: 0.9330 (0.9446)  pix_loss: 1.4510 (1.4705)  time: 54.0664  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [120/985]  eta: 12:59:35  lr: 0.000060  g_loss: 15.9188 (15.6973)  d_loss: 1.7228 (1.7347)  gan_loss: 0.9551 (0.9467)  pix_loss: 1.4935 (1.4751)  time: 54.0715  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [130/985]  eta: 12:50:34  lr: 0.000060  g_loss: 15.7409 (15.6611)  d_loss: 1.7228 (1.7339)  gan_loss: 0.9518 (0.9458)  pix_loss: 1.4781 (1.4715)  time: 54.0690  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [140/985]  eta: 12:41:33  lr: 0.000060  g_loss: 15.0126 (15.6551)  d_loss: 1.7245 (1.7335)  gan_loss: 0.9347 (0.9453)  pix_loss: 1.4077 (1.4710)  time: 54.0652  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [150/985]  eta: 12:32:31  lr: 0.000060  g_loss: 15.0126 (15.6108)  d_loss: 1.7254 (1.7328)  gan_loss: 0.9349 (0.9445)  pix_loss: 1.4077 (1.4666)  time: 54.0675  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [160/985]  eta: 12:23:30  lr: 0.000060  g_loss: 14.8254 (15.6020)  d_loss: 1.7227 (1.7320)  gan_loss: 0.9182 (0.9442)  pix_loss: 1.3913 (1.4658)  time: 54.0624  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [170/985]  eta: 12:14:29  lr: 0.000060  g_loss: 15.1256 (15.5830)  d_loss: 1.7230 (1.7318)  gan_loss: 0.9234 (0.9434)  pix_loss: 1.4196 (1.4640)  time: 54.0605  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [180/985]  eta: 12:05:28  lr: 0.000060  g_loss: 15.2808 (15.5697)  d_loss: 1.7321 (1.7318)  gan_loss: 0.9276 (0.9428)  pix_loss: 1.4355 (1.4627)  time: 54.0680  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [190/985]  eta: 11:56:27  lr: 0.000060  g_loss: 15.2992 (15.5604)  d_loss: 1.7330 (1.7321)  gan_loss: 0.9212 (0.9426)  pix_loss: 1.4336 (1.4618)  time: 54.0685  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [200/985]  eta: 11:47:25  lr: 0.000060  g_loss: 15.2420 (15.5411)  d_loss: 1.7330 (1.7321)  gan_loss: 0.9179 (0.9424)  pix_loss: 1.4307 (1.4599)  time: 54.0608  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [210/985]  eta: 11:38:25  lr: 0.000060  g_loss: 14.6509 (15.5027)  d_loss: 1.7303 (1.7320)  gan_loss: 0.9171 (0.9412)  pix_loss: 1.3733 (1.4561)  time: 54.0630  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [220/985]  eta: 11:29:24  lr: 0.000060  g_loss: 14.5670 (15.4665)  d_loss: 1.7290 (1.7318)  gan_loss: 0.9176 (0.9408)  pix_loss: 1.3655 (1.4526)  time: 54.0692  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [230/985]  eta: 11:20:23  lr: 0.000060  g_loss: 14.8403 (15.4626)  d_loss: 1.7289 (1.7316)  gan_loss: 0.9404 (0.9409)  pix_loss: 1.3890 (1.4522)  time: 54.0698  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [240/985]  eta: 11:11:22  lr: 0.000060  g_loss: 15.2206 (15.4317)  d_loss: 1.7294 (1.7315)  gan_loss: 0.9334 (0.9399)  pix_loss: 1.4290 (1.4492)  time: 54.0691  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [250/985]  eta: 11:02:22  lr: 0.000060  g_loss: 14.5367 (15.4031)  d_loss: 1.7315 (1.7318)  gan_loss: 0.9303 (0.9393)  pix_loss: 1.3635 (1.4464)  time: 54.0722  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [260/985]  eta: 10:53:21  lr: 0.000060  g_loss: 14.8816 (15.3828)  d_loss: 1.7357 (1.7319)  gan_loss: 0.9330 (0.9392)  pix_loss: 1.3952 (1.4444)  time: 54.0742  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [270/985]  eta: 10:44:21  lr: 0.000060  g_loss: 14.8671 (15.3638)  d_loss: 1.7266 (1.7316)  gan_loss: 0.9321 (0.9390)  pix_loss: 1.3917 (1.4425)  time: 54.0752  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [280/985]  eta: 10:35:20  lr: 0.000060  g_loss: 14.2393 (15.3257)  d_loss: 1.7248 (1.7316)  gan_loss: 0.9161 (0.9381)  pix_loss: 1.3320 (1.4388)  time: 54.0754  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [290/985]  eta: 10:26:19  lr: 0.000060  g_loss: 14.1692 (15.3072)  d_loss: 1.7329 (1.7316)  gan_loss: 0.9096 (0.9378)  pix_loss: 1.3271 (1.4369)  time: 54.0714  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:7]  [300/985]  eta: 10:17:18  lr: 0.000060  g_loss: 14.5197 (15.2941)  d_loss: 1.7306 (1.7316)  gan_loss: 0.9154 (0.9376)  pix_loss: 1.3604 (1.4356)  time: 54.0713  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [310/985]  eta: 10:08:18  lr: 0.000060  g_loss: 15.0459 (15.3080)  d_loss: 1.7251 (1.7313)  gan_loss: 0.9341 (0.9382)  pix_loss: 1.4132 (1.4370)  time: 54.0771  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [320/985]  eta: 9:59:17  lr: 0.000060  g_loss: 14.6186 (15.2803)  d_loss: 1.7247 (1.7312)  gan_loss: 0.9151 (0.9372)  pix_loss: 1.3704 (1.4343)  time: 54.0778  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [330/985]  eta: 9:50:17  lr: 0.000060  g_loss: 14.3096 (15.2494)  d_loss: 1.7258 (1.7311)  gan_loss: 0.9120 (0.9364)  pix_loss: 1.3367 (1.4313)  time: 54.0778  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [340/985]  eta: 9:41:16  lr: 0.000060  g_loss: 14.0790 (15.2252)  d_loss: 1.7265 (1.7310)  gan_loss: 0.9127 (0.9357)  pix_loss: 1.3167 (1.4289)  time: 54.0770  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [350/985]  eta: 9:32:15  lr: 0.000060  g_loss: 14.4604 (15.2077)  d_loss: 1.7277 (1.7310)  gan_loss: 0.9208 (0.9353)  pix_loss: 1.3547 (1.4272)  time: 54.0720  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [360/985]  eta: 9:23:14  lr: 0.000060  g_loss: 14.4604 (15.1862)  d_loss: 1.7273 (1.7309)  gan_loss: 0.9173 (0.9346)  pix_loss: 1.3547 (1.4252)  time: 54.0672  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [370/985]  eta: 9:14:14  lr: 0.000060  g_loss: 14.0212 (15.1606)  d_loss: 1.7285 (1.7309)  gan_loss: 0.9085 (0.9341)  pix_loss: 1.3124 (1.4227)  time: 54.0693  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [380/985]  eta: 9:05:13  lr: 0.000060  g_loss: 14.3621 (15.1425)  d_loss: 1.7291 (1.7309)  gan_loss: 0.9066 (0.9335)  pix_loss: 1.3456 (1.4209)  time: 54.0675  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [390/985]  eta: 8:56:12  lr: 0.000060  g_loss: 14.0178 (15.1131)  d_loss: 1.7353 (1.7314)  gan_loss: 0.9059 (0.9329)  pix_loss: 1.3116 (1.4180)  time: 54.0653  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [400/985]  eta: 8:47:11  lr: 0.000060  g_loss: 13.9437 (15.0826)  d_loss: 1.7451 (1.7316)  gan_loss: 0.9020 (0.9323)  pix_loss: 1.3028 (1.4150)  time: 54.0709  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [410/985]  eta: 8:38:11  lr: 0.000060  g_loss: 14.0219 (15.0692)  d_loss: 1.7330 (1.7316)  gan_loss: 0.9083 (0.9321)  pix_loss: 1.3122 (1.4137)  time: 54.0667  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [420/985]  eta: 8:29:10  lr: 0.000060  g_loss: 13.9159 (15.0428)  d_loss: 1.7330 (1.7317)  gan_loss: 0.9110 (0.9313)  pix_loss: 1.3024 (1.4111)  time: 54.0611  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [430/985]  eta: 8:20:09  lr: 0.000060  g_loss: 13.8822 (15.0242)  d_loss: 1.7342 (1.7318)  gan_loss: 0.9110 (0.9312)  pix_loss: 1.2990 (1.4093)  time: 54.0619  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [440/985]  eta: 8:11:08  lr: 0.000060  g_loss: 14.1201 (15.0059)  d_loss: 1.7342 (1.7320)  gan_loss: 0.9215 (0.9309)  pix_loss: 1.3224 (1.4075)  time: 54.0617  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [450/985]  eta: 8:02:07  lr: 0.000060  g_loss: 14.0532 (14.9892)  d_loss: 1.7342 (1.7321)  gan_loss: 0.9176 (0.9308)  pix_loss: 1.3160 (1.4058)  time: 54.0670  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [460/985]  eta: 7:53:07  lr: 0.000060  g_loss: 14.0187 (14.9686)  d_loss: 1.7279 (1.7319)  gan_loss: 0.9176 (0.9305)  pix_loss: 1.3109 (1.4038)  time: 54.0660  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [470/985]  eta: 7:44:06  lr: 0.000060  g_loss: 13.9291 (14.9411)  d_loss: 1.7271 (1.7319)  gan_loss: 0.9125 (0.9298)  pix_loss: 1.3023 (1.4011)  time: 54.0675  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [480/985]  eta: 7:35:05  lr: 0.000060  g_loss: 13.6717 (14.9126)  d_loss: 1.7280 (1.7318)  gan_loss: 0.8926 (0.9291)  pix_loss: 1.2785 (1.3983)  time: 54.0780  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [490/985]  eta: 7:26:05  lr: 0.000060  g_loss: 13.6717 (14.8885)  d_loss: 1.7268 (1.7317)  gan_loss: 0.8990 (0.9286)  pix_loss: 1.2785 (1.3960)  time: 54.0739  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:7]  [500/985]  eta: 7:17:04  lr: 0.000060  g_loss: 13.8415 (14.8683)  d_loss: 1.7300 (1.7317)  gan_loss: 0.9031 (0.9281)  pix_loss: 1.2920 (1.3940)  time: 54.0740  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:7]  [510/985]  eta: 7:08:03  lr: 0.000060  g_loss: 13.6462 (14.8515)  d_loss: 1.7297 (1.7316)  gan_loss: 0.9036 (0.9279)  pix_loss: 1.2736 (1.3924)  time: 54.0742  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [520/985]  eta: 6:59:02  lr: 0.000060  g_loss: 13.5802 (14.8248)  d_loss: 1.7293 (1.7317)  gan_loss: 0.8924 (0.9270)  pix_loss: 1.2689 (1.3898)  time: 54.0692  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [530/985]  eta: 6:50:02  lr: 0.000060  g_loss: 13.6457 (14.8064)  d_loss: 1.7327 (1.7317)  gan_loss: 0.8965 (0.9268)  pix_loss: 1.2725 (1.3880)  time: 54.0678  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [540/985]  eta: 6:41:01  lr: 0.000060  g_loss: 13.8077 (14.7887)  d_loss: 1.7271 (1.7316)  gan_loss: 0.9106 (0.9264)  pix_loss: 1.2911 (1.3862)  time: 54.0684  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [550/985]  eta: 6:32:00  lr: 0.000060  g_loss: 13.8674 (14.7673)  d_loss: 1.7258 (1.7315)  gan_loss: 0.9093 (0.9260)  pix_loss: 1.2958 (1.3841)  time: 54.0720  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [560/985]  eta: 6:23:00  lr: 0.000060  g_loss: 13.1396 (14.7388)  d_loss: 1.7286 (1.7316)  gan_loss: 0.8858 (0.9253)  pix_loss: 1.2240 (1.3813)  time: 54.0778  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [570/985]  eta: 6:13:59  lr: 0.000060  g_loss: 12.9942 (14.7123)  d_loss: 1.7380 (1.7317)  gan_loss: 0.8860 (0.9248)  pix_loss: 1.2106 (1.3788)  time: 54.0733  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [580/985]  eta: 6:04:58  lr: 0.000060  g_loss: 13.1002 (14.6878)  d_loss: 1.7297 (1.7316)  gan_loss: 0.8892 (0.9242)  pix_loss: 1.2195 (1.3764)  time: 54.0650  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [590/985]  eta: 5:55:57  lr: 0.000060  g_loss: 13.2506 (14.6646)  d_loss: 1.7267 (1.7315)  gan_loss: 0.8983 (0.9237)  pix_loss: 1.2338 (1.3741)  time: 54.0689  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [600/985]  eta: 5:46:57  lr: 0.000060  g_loss: 13.1996 (14.6403)  d_loss: 1.7267 (1.7314)  gan_loss: 0.8938 (0.9232)  pix_loss: 1.2298 (1.3717)  time: 54.0665  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [610/985]  eta: 5:37:56  lr: 0.000060  g_loss: 13.3833 (14.6236)  d_loss: 1.7260 (1.7314)  gan_loss: 0.8938 (0.9229)  pix_loss: 1.2483 (1.3701)  time: 54.0627  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [620/985]  eta: 5:28:55  lr: 0.000060  g_loss: 13.3462 (14.6052)  d_loss: 1.7261 (1.7313)  gan_loss: 0.8973 (0.9225)  pix_loss: 1.2452 (1.3683)  time: 54.0603  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [630/985]  eta: 5:19:54  lr: 0.000060  g_loss: 13.3064 (14.5873)  d_loss: 1.7286 (1.7312)  gan_loss: 0.8973 (0.9221)  pix_loss: 1.2437 (1.3665)  time: 54.0603  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [640/985]  eta: 5:10:54  lr: 0.000060  g_loss: 13.5934 (14.5736)  d_loss: 1.7289 (1.7312)  gan_loss: 0.8994 (0.9218)  pix_loss: 1.2703 (1.3652)  time: 54.0675  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [650/985]  eta: 5:01:53  lr: 0.000060  g_loss: 13.8879 (14.5664)  d_loss: 1.7277 (1.7311)  gan_loss: 0.9058 (0.9217)  pix_loss: 1.3003 (1.3645)  time: 54.0654  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [660/985]  eta: 4:52:52  lr: 0.000060  g_loss: 13.7107 (14.5548)  d_loss: 1.7306 (1.7312)  gan_loss: 0.9023 (0.9214)  pix_loss: 1.2818 (1.3633)  time: 54.0631  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [670/985]  eta: 4:43:52  lr: 0.000060  g_loss: 13.1542 (14.5346)  d_loss: 1.7403 (1.7316)  gan_loss: 0.8881 (0.9210)  pix_loss: 1.2263 (1.3614)  time: 54.0698  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [680/985]  eta: 4:34:51  lr: 0.000060  g_loss: 12.9591 (14.5162)  d_loss: 1.7621 (1.7322)  gan_loss: 0.8819 (0.9204)  pix_loss: 1.2095 (1.3596)  time: 54.0718  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [690/985]  eta: 4:25:50  lr: 0.000060  g_loss: 12.9280 (14.4996)  d_loss: 1.7583 (1.7324)  gan_loss: 0.8796 (0.9200)  pix_loss: 1.2042 (1.3580)  time: 54.0685  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [700/985]  eta: 4:16:49  lr: 0.000060  g_loss: 13.0051 (14.4789)  d_loss: 1.7392 (1.7325)  gan_loss: 0.8844 (0.9196)  pix_loss: 1.2091 (1.3559)  time: 54.0691  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [710/985]  eta: 4:07:49  lr: 0.000060  g_loss: 13.0097 (14.4590)  d_loss: 1.7289 (1.7325)  gan_loss: 0.8838 (0.9192)  pix_loss: 1.2125 (1.3540)  time: 54.0700  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [720/985]  eta: 3:58:48  lr: 0.000060  g_loss: 13.1844 (14.4417)  d_loss: 1.7279 (1.7324)  gan_loss: 0.8838 (0.9187)  pix_loss: 1.2282 (1.3523)  time: 54.0714  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [730/985]  eta: 3:49:47  lr: 0.000060  g_loss: 13.1844 (14.4248)  d_loss: 1.7278 (1.7324)  gan_loss: 0.8854 (0.9184)  pix_loss: 1.2282 (1.3506)  time: 54.0713  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [740/985]  eta: 3:40:47  lr: 0.000060  g_loss: 13.4982 (14.4213)  d_loss: 1.7295 (1.7323)  gan_loss: 0.8886 (0.9184)  pix_loss: 1.2611 (1.3503)  time: 54.0677  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [750/985]  eta: 3:31:46  lr: 0.000060  g_loss: 13.4982 (14.4017)  d_loss: 1.7355 (1.7324)  gan_loss: 0.8886 (0.9179)  pix_loss: 1.2611 (1.3484)  time: 54.0648  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [760/985]  eta: 3:22:45  lr: 0.000060  g_loss: 12.8420 (14.3812)  d_loss: 1.7351 (1.7324)  gan_loss: 0.8816 (0.9175)  pix_loss: 1.1959 (1.3464)  time: 54.0628  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [770/985]  eta: 3:13:45  lr: 0.000060  g_loss: 12.7868 (14.3620)  d_loss: 1.7322 (1.7324)  gan_loss: 0.8816 (0.9171)  pix_loss: 1.1930 (1.3445)  time: 54.0634  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [780/985]  eta: 3:04:44  lr: 0.000060  g_loss: 12.6725 (14.3426)  d_loss: 1.7327 (1.7324)  gan_loss: 0.8826 (0.9167)  pix_loss: 1.1802 (1.3426)  time: 54.0649  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [790/985]  eta: 2:55:43  lr: 0.000060  g_loss: 12.6534 (14.3237)  d_loss: 1.7281 (1.7324)  gan_loss: 0.8824 (0.9163)  pix_loss: 1.1758 (1.3407)  time: 54.0697  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [800/985]  eta: 2:46:42  lr: 0.000060  g_loss: 12.6858 (14.3062)  d_loss: 1.7248 (1.7323)  gan_loss: 0.8765 (0.9159)  pix_loss: 1.1809 (1.3390)  time: 54.0671  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [810/985]  eta: 2:37:42  lr: 0.000060  g_loss: 12.9833 (14.2920)  d_loss: 1.7249 (1.7322)  gan_loss: 0.8840 (0.9156)  pix_loss: 1.2077 (1.3376)  time: 54.0653  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [820/985]  eta: 2:28:41  lr: 0.000060  g_loss: 12.9833 (14.2760)  d_loss: 1.7311 (1.7322)  gan_loss: 0.8876 (0.9153)  pix_loss: 1.2077 (1.3361)  time: 54.0679  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [830/985]  eta: 2:19:40  lr: 0.000060  g_loss: 12.7462 (14.2567)  d_loss: 1.7326 (1.7322)  gan_loss: 0.8821 (0.9149)  pix_loss: 1.1870 (1.3342)  time: 54.0758  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [840/985]  eta: 2:10:40  lr: 0.000060  g_loss: 12.5152 (14.2349)  d_loss: 1.7310 (1.7322)  gan_loss: 0.8725 (0.9144)  pix_loss: 1.1633 (1.3320)  time: 54.0752  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [850/985]  eta: 2:01:39  lr: 0.000060  g_loss: 12.8108 (14.2219)  d_loss: 1.7327 (1.7323)  gan_loss: 0.8818 (0.9141)  pix_loss: 1.1952 (1.3308)  time: 54.0671  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [860/985]  eta: 1:52:38  lr: 0.000060  g_loss: 13.0806 (14.2080)  d_loss: 1.7321 (1.7323)  gan_loss: 0.8918 (0.9138)  pix_loss: 1.2183 (1.3294)  time: 54.0705  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [870/985]  eta: 1:43:38  lr: 0.000060  g_loss: 12.8027 (14.1906)  d_loss: 1.7294 (1.7322)  gan_loss: 0.8881 (0.9134)  pix_loss: 1.1925 (1.3277)  time: 54.0674  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [880/985]  eta: 1:34:37  lr: 0.000060  g_loss: 12.6698 (14.1727)  d_loss: 1.7287 (1.7322)  gan_loss: 0.8859 (0.9130)  pix_loss: 1.1795 (1.3260)  time: 54.0702  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [890/985]  eta: 1:25:36  lr: 0.000060  g_loss: 12.2778 (14.1552)  d_loss: 1.7351 (1.7323)  gan_loss: 0.8745 (0.9127)  pix_loss: 1.1416 (1.3243)  time: 54.0756  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [900/985]  eta: 1:16:35  lr: 0.000060  g_loss: 12.1268 (14.1339)  d_loss: 1.7363 (1.7323)  gan_loss: 0.8741 (0.9122)  pix_loss: 1.1268 (1.3222)  time: 54.0664  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [910/985]  eta: 1:07:35  lr: 0.000060  g_loss: 12.1353 (14.1207)  d_loss: 1.7339 (1.7323)  gan_loss: 0.8741 (0.9119)  pix_loss: 1.1287 (1.3209)  time: 54.0709  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [920/985]  eta: 0:58:34  lr: 0.000060  g_loss: 12.1442 (14.0991)  d_loss: 1.7309 (1.7323)  gan_loss: 0.8736 (0.9115)  pix_loss: 1.1287 (1.3188)  time: 54.0771  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [930/985]  eta: 0:49:33  lr: 0.000060  g_loss: 12.1013 (14.0827)  d_loss: 1.7309 (1.7323)  gan_loss: 0.8676 (0.9111)  pix_loss: 1.1228 (1.3172)  time: 54.0693  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [940/985]  eta: 0:40:33  lr: 0.000060  g_loss: 12.5851 (14.0674)  d_loss: 1.7308 (1.7322)  gan_loss: 0.8762 (0.9108)  pix_loss: 1.1693 (1.3157)  time: 54.0664  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [950/985]  eta: 0:31:32  lr: 0.000060  g_loss: 12.5207 (14.0504)  d_loss: 1.7294 (1.7322)  gan_loss: 0.8765 (0.9104)  pix_loss: 1.1639 (1.3140)  time: 54.0759  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [960/985]  eta: 0:22:31  lr: 0.000060  g_loss: 12.4070 (14.0355)  d_loss: 1.7294 (1.7322)  gan_loss: 0.8743 (0.9101)  pix_loss: 1.1533 (1.3125)  time: 54.0790  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [970/985]  eta: 0:13:31  lr: 0.000060  g_loss: 12.3420 (14.0174)  d_loss: 1.7294 (1.7322)  gan_loss: 0.8720 (0.9097)  pix_loss: 1.1451 (1.3108)  time: 54.0669  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:7]  [980/985]  eta: 0:04:30  lr: 0.000060  g_loss: 12.2581 (13.9981)  d_loss: 1.7334 (1.7322)  gan_loss: 0.8670 (0.9092)  pix_loss: 1.1382 (1.3089)  time: 54.0686  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:7]  [984/985]  eta: 0:00:54  lr: 0.000060  g_loss: 12.2421 (13.9896)  d_loss: 1.7334 (1.7322)  gan_loss: 0.8670 (0.9091)  pix_loss: 1.1375 (1.3081)  time: 54.0694  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:7] Total time: 14:47:39 (54.0702 s / it)\n",
      "Averaged stats: lr: 0.000060  g_loss: 12.2421 (13.9896)  d_loss: 1.7334 (1.7322)  gan_loss: 0.8670 (0.9091)  pix_loss: 1.1375 (1.3081)\n",
      "Valid: [epoch:7]  [ 0/14]  eta: 0:01:33  L1_loss: 0.1200 (0.1200)  time: 6.6731  data: 0.3384  max mem: 38397\n",
      "Valid: [epoch:7]  [13/14]  eta: 0:00:06  L1_loss: 0.0974 (0.1015)  time: 6.2188  data: 0.0243  max mem: 38397\n",
      "Valid: [epoch:7] Total time: 0:01:27 (6.2245 s / it)\n",
      "Averaged stats: L1_loss: 0.0974 (0.1015)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_7_input_n_20.png\n",
      "Train: [epoch:8]  [  0/985]  eta: 15:05:31  lr: 0.000070  g_loss: 11.6415 (11.6415)  d_loss: 1.7329 (1.7329)  gan_loss: 0.8728 (0.8728)  pix_loss: 1.0769 (1.0769)  time: 55.1591  data: 1.0877  max mem: 38397\n",
      "Train: [epoch:8]  [ 10/985]  eta: 14:40:05  lr: 0.000070  g_loss: 12.1536 (12.3864)  d_loss: 1.7329 (1.7332)  gan_loss: 0.8760 (0.8783)  pix_loss: 1.1283 (1.1508)  time: 54.1600  data: 0.0990  max mem: 38397\n",
      "Train: [epoch:8]  [ 20/985]  eta: 14:30:22  lr: 0.000070  g_loss: 12.4257 (12.4441)  d_loss: 1.7310 (1.7322)  gan_loss: 0.8754 (0.8756)  pix_loss: 1.1537 (1.1569)  time: 54.0649  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [ 30/985]  eta: 14:21:03  lr: 0.000070  g_loss: 12.3637 (12.4716)  d_loss: 1.7314 (1.7339)  gan_loss: 0.8754 (0.8765)  pix_loss: 1.1506 (1.1595)  time: 54.0643  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [ 40/985]  eta: 14:11:56  lr: 0.000070  g_loss: 12.2803 (12.4234)  d_loss: 1.7324 (1.7331)  gan_loss: 0.8766 (0.8768)  pix_loss: 1.1392 (1.1547)  time: 54.0642  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [ 50/985]  eta: 14:02:52  lr: 0.000070  g_loss: 12.1132 (12.3925)  d_loss: 1.7354 (1.7342)  gan_loss: 0.8740 (0.8751)  pix_loss: 1.1265 (1.1517)  time: 54.0717  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [ 60/985]  eta: 13:53:47  lr: 0.000070  g_loss: 12.5159 (12.4373)  d_loss: 1.7369 (1.7343)  gan_loss: 0.8611 (0.8767)  pix_loss: 1.1649 (1.1561)  time: 54.0676  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [ 70/985]  eta: 13:44:43  lr: 0.000070  g_loss: 12.5159 (12.4498)  d_loss: 1.7358 (1.7347)  gan_loss: 0.8675 (0.8762)  pix_loss: 1.1655 (1.1574)  time: 54.0615  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [ 80/985]  eta: 13:35:41  lr: 0.000070  g_loss: 12.3721 (12.4105)  d_loss: 1.7324 (1.7344)  gan_loss: 0.8686 (0.8754)  pix_loss: 1.1490 (1.1535)  time: 54.0648  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [ 90/985]  eta: 13:26:39  lr: 0.000070  g_loss: 12.0983 (12.4209)  d_loss: 1.7351 (1.7345)  gan_loss: 0.8712 (0.8761)  pix_loss: 1.1242 (1.1545)  time: 54.0680  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [100/985]  eta: 13:17:37  lr: 0.000070  g_loss: 12.0955 (12.4008)  d_loss: 1.7318 (1.7339)  gan_loss: 0.8713 (0.8757)  pix_loss: 1.1232 (1.1525)  time: 54.0672  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [110/985]  eta: 13:08:36  lr: 0.000070  g_loss: 12.0531 (12.3883)  d_loss: 1.7304 (1.7339)  gan_loss: 0.8686 (0.8757)  pix_loss: 1.1181 (1.1513)  time: 54.0692  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [120/985]  eta: 12:59:34  lr: 0.000070  g_loss: 12.1185 (12.3847)  d_loss: 1.7334 (1.7337)  gan_loss: 0.8726 (0.8759)  pix_loss: 1.1258 (1.1509)  time: 54.0675  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [130/985]  eta: 12:50:33  lr: 0.000070  g_loss: 12.1185 (12.3729)  d_loss: 1.7310 (1.7333)  gan_loss: 0.8708 (0.8762)  pix_loss: 1.1255 (1.1497)  time: 54.0628  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [140/985]  eta: 12:41:31  lr: 0.000070  g_loss: 12.1417 (12.3807)  d_loss: 1.7313 (1.7331)  gan_loss: 0.8709 (0.8768)  pix_loss: 1.1255 (1.1504)  time: 54.0609  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [150/985]  eta: 12:32:30  lr: 0.000070  g_loss: 11.8452 (12.3287)  d_loss: 1.7305 (1.7329)  gan_loss: 0.8689 (0.8759)  pix_loss: 1.0980 (1.1453)  time: 54.0642  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [160/985]  eta: 12:23:29  lr: 0.000070  g_loss: 11.6827 (12.3117)  d_loss: 1.7313 (1.7330)  gan_loss: 0.8607 (0.8753)  pix_loss: 1.0837 (1.1436)  time: 54.0672  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [170/985]  eta: 12:14:28  lr: 0.000070  g_loss: 12.1324 (12.2950)  d_loss: 1.7329 (1.7329)  gan_loss: 0.8623 (0.8749)  pix_loss: 1.1270 (1.1420)  time: 54.0613  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [180/985]  eta: 12:05:27  lr: 0.000070  g_loss: 11.9594 (12.2742)  d_loss: 1.7326 (1.7330)  gan_loss: 0.8623 (0.8743)  pix_loss: 1.1106 (1.1400)  time: 54.0605  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [190/985]  eta: 11:56:26  lr: 0.000070  g_loss: 11.7416 (12.2525)  d_loss: 1.7325 (1.7331)  gan_loss: 0.8596 (0.8737)  pix_loss: 1.0871 (1.1379)  time: 54.0627  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [200/985]  eta: 11:47:24  lr: 0.000070  g_loss: 11.6774 (12.2282)  d_loss: 1.7313 (1.7330)  gan_loss: 0.8579 (0.8735)  pix_loss: 1.0819 (1.1355)  time: 54.0613  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [210/985]  eta: 11:38:24  lr: 0.000070  g_loss: 11.7333 (12.2131)  d_loss: 1.7313 (1.7330)  gan_loss: 0.8580 (0.8730)  pix_loss: 1.0850 (1.1340)  time: 54.0630  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [220/985]  eta: 11:29:23  lr: 0.000070  g_loss: 11.7293 (12.1960)  d_loss: 1.7357 (1.7333)  gan_loss: 0.8668 (0.8725)  pix_loss: 1.0882 (1.1323)  time: 54.0629  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [230/985]  eta: 11:20:22  lr: 0.000070  g_loss: 11.7293 (12.1910)  d_loss: 1.7292 (1.7330)  gan_loss: 0.8668 (0.8726)  pix_loss: 1.0882 (1.1318)  time: 54.0618  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [240/985]  eta: 11:11:21  lr: 0.000070  g_loss: 11.7206 (12.1745)  d_loss: 1.7282 (1.7329)  gan_loss: 0.8655 (0.8722)  pix_loss: 1.0855 (1.1302)  time: 54.0637  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [250/985]  eta: 11:02:20  lr: 0.000070  g_loss: 11.4188 (12.1451)  d_loss: 1.7303 (1.7328)  gan_loss: 0.8546 (0.8715)  pix_loss: 1.0573 (1.1274)  time: 54.0677  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [260/985]  eta: 10:53:19  lr: 0.000070  g_loss: 11.2981 (12.1261)  d_loss: 1.7317 (1.7328)  gan_loss: 0.8565 (0.8711)  pix_loss: 1.0442 (1.1255)  time: 54.0651  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [270/985]  eta: 10:44:18  lr: 0.000070  g_loss: 11.8709 (12.1294)  d_loss: 1.7322 (1.7327)  gan_loss: 0.8608 (0.8711)  pix_loss: 1.1004 (1.1258)  time: 54.0592  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [280/985]  eta: 10:35:17  lr: 0.000070  g_loss: 11.9730 (12.1178)  d_loss: 1.7328 (1.7327)  gan_loss: 0.8698 (0.8710)  pix_loss: 1.1091 (1.1247)  time: 54.0607  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [290/985]  eta: 10:26:17  lr: 0.000070  g_loss: 11.6915 (12.0994)  d_loss: 1.7329 (1.7328)  gan_loss: 0.8590 (0.8705)  pix_loss: 1.0822 (1.1229)  time: 54.0600  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [300/985]  eta: 10:17:16  lr: 0.000070  g_loss: 11.7356 (12.1059)  d_loss: 1.7348 (1.7330)  gan_loss: 0.8590 (0.8708)  pix_loss: 1.0868 (1.1235)  time: 54.0594  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [310/985]  eta: 10:08:15  lr: 0.000070  g_loss: 11.8167 (12.0976)  d_loss: 1.7366 (1.7332)  gan_loss: 0.8673 (0.8706)  pix_loss: 1.0930 (1.1227)  time: 54.0598  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [320/985]  eta: 9:59:14  lr: 0.000070  g_loss: 11.6642 (12.0854)  d_loss: 1.7366 (1.7332)  gan_loss: 0.8651 (0.8705)  pix_loss: 1.0799 (1.1215)  time: 54.0602  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [330/985]  eta: 9:50:13  lr: 0.000070  g_loss: 11.6642 (12.0716)  d_loss: 1.7377 (1.7333)  gan_loss: 0.8635 (0.8702)  pix_loss: 1.0799 (1.1201)  time: 54.0608  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [340/985]  eta: 9:41:12  lr: 0.000070  g_loss: 11.4421 (12.0543)  d_loss: 1.7339 (1.7333)  gan_loss: 0.8617 (0.8698)  pix_loss: 1.0591 (1.1184)  time: 54.0591  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [350/985]  eta: 9:32:12  lr: 0.000070  g_loss: 11.3200 (12.0362)  d_loss: 1.7320 (1.7334)  gan_loss: 0.8579 (0.8695)  pix_loss: 1.0469 (1.1167)  time: 54.0575  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [360/985]  eta: 9:23:11  lr: 0.000070  g_loss: 11.4045 (12.0291)  d_loss: 1.7367 (1.7335)  gan_loss: 0.8595 (0.8695)  pix_loss: 1.0545 (1.1160)  time: 54.0596  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [370/985]  eta: 9:14:10  lr: 0.000070  g_loss: 11.4102 (12.0127)  d_loss: 1.7367 (1.7336)  gan_loss: 0.8540 (0.8692)  pix_loss: 1.0556 (1.1144)  time: 54.0623  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [380/985]  eta: 9:05:09  lr: 0.000070  g_loss: 11.3857 (12.0055)  d_loss: 1.7345 (1.7335)  gan_loss: 0.8556 (0.8692)  pix_loss: 1.0518 (1.1136)  time: 54.0638  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [390/985]  eta: 8:56:09  lr: 0.000070  g_loss: 11.3857 (11.9903)  d_loss: 1.7296 (1.7334)  gan_loss: 0.8564 (0.8691)  pix_loss: 1.0518 (1.1121)  time: 54.0666  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [400/985]  eta: 8:47:08  lr: 0.000070  g_loss: 11.3615 (11.9822)  d_loss: 1.7328 (1.7335)  gan_loss: 0.8604 (0.8690)  pix_loss: 1.0507 (1.1113)  time: 54.0647  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [410/985]  eta: 8:38:07  lr: 0.000070  g_loss: 11.3957 (11.9705)  d_loss: 1.7370 (1.7336)  gan_loss: 0.8620 (0.8689)  pix_loss: 1.0535 (1.1102)  time: 54.0632  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [420/985]  eta: 8:29:07  lr: 0.000070  g_loss: 11.3578 (11.9596)  d_loss: 1.7357 (1.7337)  gan_loss: 0.8612 (0.8687)  pix_loss: 1.0499 (1.1091)  time: 54.0659  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [430/985]  eta: 8:20:06  lr: 0.000070  g_loss: 11.2472 (11.9494)  d_loss: 1.7337 (1.7337)  gan_loss: 0.8605 (0.8686)  pix_loss: 1.0385 (1.1081)  time: 54.0669  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [440/985]  eta: 8:11:05  lr: 0.000070  g_loss: 11.2472 (11.9363)  d_loss: 1.7342 (1.7337)  gan_loss: 0.8595 (0.8685)  pix_loss: 1.0385 (1.1068)  time: 54.0639  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [450/985]  eta: 8:02:05  lr: 0.000070  g_loss: 11.0027 (11.9179)  d_loss: 1.7339 (1.7336)  gan_loss: 0.8539 (0.8681)  pix_loss: 1.0154 (1.1050)  time: 54.0613  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [460/985]  eta: 7:53:04  lr: 0.000070  g_loss: 11.1998 (11.9081)  d_loss: 1.7320 (1.7336)  gan_loss: 0.8559 (0.8681)  pix_loss: 1.0343 (1.1040)  time: 54.0646  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [470/985]  eta: 7:44:03  lr: 0.000070  g_loss: 11.2881 (11.8938)  d_loss: 1.7320 (1.7336)  gan_loss: 0.8657 (0.8679)  pix_loss: 1.0416 (1.1026)  time: 54.0685  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [480/985]  eta: 7:35:03  lr: 0.000070  g_loss: 11.2715 (11.8802)  d_loss: 1.7356 (1.7337)  gan_loss: 0.8552 (0.8676)  pix_loss: 1.0413 (1.1013)  time: 54.0666  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [490/985]  eta: 7:26:02  lr: 0.000070  g_loss: 10.9696 (11.8640)  d_loss: 1.7373 (1.7337)  gan_loss: 0.8507 (0.8673)  pix_loss: 1.0110 (1.0997)  time: 54.0656  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [500/985]  eta: 7:17:01  lr: 0.000070  g_loss: 11.2768 (11.8652)  d_loss: 1.7354 (1.7338)  gan_loss: 0.8532 (0.8673)  pix_loss: 1.0431 (1.0998)  time: 54.0656  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [510/985]  eta: 7:08:01  lr: 0.000070  g_loss: 11.4147 (11.8577)  d_loss: 1.7320 (1.7337)  gan_loss: 0.8628 (0.8672)  pix_loss: 1.0552 (1.0990)  time: 54.0689  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [520/985]  eta: 6:59:00  lr: 0.000070  g_loss: 11.4871 (11.8500)  d_loss: 1.7317 (1.7338)  gan_loss: 0.8622 (0.8670)  pix_loss: 1.0638 (1.0983)  time: 54.0736  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [530/985]  eta: 6:50:00  lr: 0.000070  g_loss: 11.3812 (11.8388)  d_loss: 1.7318 (1.7337)  gan_loss: 0.8563 (0.8669)  pix_loss: 1.0520 (1.0972)  time: 54.0695  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [540/985]  eta: 6:40:59  lr: 0.000070  g_loss: 11.3185 (11.8309)  d_loss: 1.7310 (1.7336)  gan_loss: 0.8611 (0.8669)  pix_loss: 1.0464 (1.0964)  time: 54.0645  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [550/985]  eta: 6:31:58  lr: 0.000070  g_loss: 11.0510 (11.8211)  d_loss: 1.7346 (1.7337)  gan_loss: 0.8569 (0.8666)  pix_loss: 1.0198 (1.0955)  time: 54.0656  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [560/985]  eta: 6:22:58  lr: 0.000070  g_loss: 10.9832 (11.8038)  d_loss: 1.7352 (1.7337)  gan_loss: 0.8532 (0.8663)  pix_loss: 1.0140 (1.0938)  time: 54.0709  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [570/985]  eta: 6:13:57  lr: 0.000070  g_loss: 10.8465 (11.7899)  d_loss: 1.7352 (1.7338)  gan_loss: 0.8406 (0.8660)  pix_loss: 1.0014 (1.0924)  time: 54.0728  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [580/985]  eta: 6:04:56  lr: 0.000070  g_loss: 10.8767 (11.7733)  d_loss: 1.7342 (1.7338)  gan_loss: 0.8486 (0.8656)  pix_loss: 1.0036 (1.0908)  time: 54.0699  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [590/985]  eta: 5:55:56  lr: 0.000070  g_loss: 10.7466 (11.7573)  d_loss: 1.7340 (1.7338)  gan_loss: 0.8486 (0.8653)  pix_loss: 0.9884 (1.0892)  time: 54.0692  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [600/985]  eta: 5:46:55  lr: 0.000070  g_loss: 10.8363 (11.7438)  d_loss: 1.7345 (1.7339)  gan_loss: 0.8497 (0.8651)  pix_loss: 0.9992 (1.0879)  time: 54.0745  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [610/985]  eta: 5:37:55  lr: 0.000070  g_loss: 10.8716 (11.7338)  d_loss: 1.7334 (1.7338)  gan_loss: 0.8541 (0.8649)  pix_loss: 1.0018 (1.0869)  time: 54.0741  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [620/985]  eta: 5:28:54  lr: 0.000070  g_loss: 10.9881 (11.7254)  d_loss: 1.7324 (1.7338)  gan_loss: 0.8555 (0.8648)  pix_loss: 1.0127 (1.0861)  time: 54.0704  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [630/985]  eta: 5:19:53  lr: 0.000070  g_loss: 10.9881 (11.7164)  d_loss: 1.7346 (1.7339)  gan_loss: 0.8591 (0.8646)  pix_loss: 1.0127 (1.0852)  time: 54.0669  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [640/985]  eta: 5:10:53  lr: 0.000070  g_loss: 10.8224 (11.7032)  d_loss: 1.7347 (1.7339)  gan_loss: 0.8454 (0.8644)  pix_loss: 0.9967 (1.0839)  time: 54.0667  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [650/985]  eta: 5:01:52  lr: 0.000070  g_loss: 10.8116 (11.6957)  d_loss: 1.7366 (1.7339)  gan_loss: 0.8476 (0.8642)  pix_loss: 0.9963 (1.0831)  time: 54.0679  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [660/985]  eta: 4:52:51  lr: 0.000070  g_loss: 11.4268 (11.6954)  d_loss: 1.7358 (1.7339)  gan_loss: 0.8513 (0.8642)  pix_loss: 1.0583 (1.0831)  time: 54.0602  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [670/985]  eta: 4:43:50  lr: 0.000070  g_loss: 11.0882 (11.6819)  d_loss: 1.7358 (1.7340)  gan_loss: 0.8506 (0.8639)  pix_loss: 1.0224 (1.0818)  time: 54.0624  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [680/985]  eta: 4:34:50  lr: 0.000070  g_loss: 10.8234 (11.6694)  d_loss: 1.7379 (1.7341)  gan_loss: 0.8445 (0.8637)  pix_loss: 0.9976 (1.0806)  time: 54.0686  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [690/985]  eta: 4:25:49  lr: 0.000070  g_loss: 10.7571 (11.6559)  d_loss: 1.7403 (1.7342)  gan_loss: 0.8433 (0.8634)  pix_loss: 0.9913 (1.0793)  time: 54.0644  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [700/985]  eta: 4:16:49  lr: 0.000070  g_loss: 10.7557 (11.6442)  d_loss: 1.7395 (1.7343)  gan_loss: 0.8472 (0.8632)  pix_loss: 0.9907 (1.0781)  time: 54.0701  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [710/985]  eta: 4:07:48  lr: 0.000070  g_loss: 10.8403 (11.6371)  d_loss: 1.7368 (1.7343)  gan_loss: 0.8492 (0.8630)  pix_loss: 0.9991 (1.0774)  time: 54.0701  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [720/985]  eta: 3:58:47  lr: 0.000070  g_loss: 10.9594 (11.6291)  d_loss: 1.7368 (1.7344)  gan_loss: 0.8485 (0.8629)  pix_loss: 1.0113 (1.0766)  time: 54.0622  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [730/985]  eta: 3:49:46  lr: 0.000070  g_loss: 10.9750 (11.6220)  d_loss: 1.7395 (1.7344)  gan_loss: 0.8485 (0.8628)  pix_loss: 1.0135 (1.0759)  time: 54.0603  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [740/985]  eta: 3:40:46  lr: 0.000070  g_loss: 10.9591 (11.6162)  d_loss: 1.7390 (1.7345)  gan_loss: 0.8503 (0.8626)  pix_loss: 1.0092 (1.0754)  time: 54.0624  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [750/985]  eta: 3:31:45  lr: 0.000070  g_loss: 10.9394 (11.6059)  d_loss: 1.7366 (1.7345)  gan_loss: 0.8484 (0.8624)  pix_loss: 1.0091 (1.0743)  time: 54.0688  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [760/985]  eta: 3:22:44  lr: 0.000070  g_loss: 10.7730 (11.5974)  d_loss: 1.7338 (1.7344)  gan_loss: 0.8497 (0.8623)  pix_loss: 0.9910 (1.0735)  time: 54.0654  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [770/985]  eta: 3:13:44  lr: 0.000070  g_loss: 10.9565 (11.5903)  d_loss: 1.7386 (1.7346)  gan_loss: 0.8473 (0.8621)  pix_loss: 1.0112 (1.0728)  time: 54.0590  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [780/985]  eta: 3:04:43  lr: 0.000070  g_loss: 10.8995 (11.5810)  d_loss: 1.7389 (1.7346)  gan_loss: 0.8456 (0.8621)  pix_loss: 1.0045 (1.0719)  time: 54.0619  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [790/985]  eta: 2:55:42  lr: 0.000070  g_loss: 10.8555 (11.5717)  d_loss: 1.7389 (1.7347)  gan_loss: 0.8505 (0.8619)  pix_loss: 1.0003 (1.0710)  time: 54.0666  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [800/985]  eta: 2:46:42  lr: 0.000070  g_loss: 10.7792 (11.5609)  d_loss: 1.7389 (1.7347)  gan_loss: 0.8474 (0.8617)  pix_loss: 0.9941 (1.0699)  time: 54.0626  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [810/985]  eta: 2:37:41  lr: 0.000070  g_loss: 10.6785 (11.5512)  d_loss: 1.7334 (1.7347)  gan_loss: 0.8469 (0.8616)  pix_loss: 0.9839 (1.0690)  time: 54.0565  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [820/985]  eta: 2:28:40  lr: 0.000070  g_loss: 10.6185 (11.5398)  d_loss: 1.7354 (1.7348)  gan_loss: 0.8461 (0.8614)  pix_loss: 0.9765 (1.0678)  time: 54.0585  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [830/985]  eta: 2:19:40  lr: 0.000070  g_loss: 10.5723 (11.5295)  d_loss: 1.7370 (1.7348)  gan_loss: 0.8422 (0.8612)  pix_loss: 0.9729 (1.0668)  time: 54.0601  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [840/985]  eta: 2:10:39  lr: 0.000070  g_loss: 10.5723 (11.5185)  d_loss: 1.7387 (1.7349)  gan_loss: 0.8429 (0.8610)  pix_loss: 0.9729 (1.0657)  time: 54.0602  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [850/985]  eta: 2:01:38  lr: 0.000070  g_loss: 10.5012 (11.5071)  d_loss: 1.7406 (1.7350)  gan_loss: 0.8406 (0.8608)  pix_loss: 0.9662 (1.0646)  time: 54.0620  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [860/985]  eta: 1:52:38  lr: 0.000070  g_loss: 10.6827 (11.5016)  d_loss: 1.7377 (1.7350)  gan_loss: 0.8406 (0.8608)  pix_loss: 0.9849 (1.0641)  time: 54.0648  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [870/985]  eta: 1:43:37  lr: 0.000070  g_loss: 10.5337 (11.4898)  d_loss: 1.7383 (1.7351)  gan_loss: 0.8393 (0.8605)  pix_loss: 0.9693 (1.0629)  time: 54.0684  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [880/985]  eta: 1:34:36  lr: 0.000070  g_loss: 10.4544 (11.4789)  d_loss: 1.7383 (1.7351)  gan_loss: 0.8385 (0.8603)  pix_loss: 0.9619 (1.0619)  time: 54.0654  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [890/985]  eta: 1:25:36  lr: 0.000070  g_loss: 10.6417 (11.4702)  d_loss: 1.7388 (1.7352)  gan_loss: 0.8424 (0.8601)  pix_loss: 0.9789 (1.0610)  time: 54.0605  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [900/985]  eta: 1:16:35  lr: 0.000070  g_loss: 10.5191 (11.4589)  d_loss: 1.7402 (1.7352)  gan_loss: 0.8429 (0.8599)  pix_loss: 0.9675 (1.0599)  time: 54.0595  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [910/985]  eta: 1:07:34  lr: 0.000070  g_loss: 10.3858 (11.4502)  d_loss: 1.7381 (1.7352)  gan_loss: 0.8429 (0.8598)  pix_loss: 0.9546 (1.0590)  time: 54.0604  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [920/985]  eta: 0:58:34  lr: 0.000070  g_loss: 10.5274 (11.4417)  d_loss: 1.7386 (1.7353)  gan_loss: 0.8461 (0.8596)  pix_loss: 0.9676 (1.0582)  time: 54.0645  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [930/985]  eta: 0:49:33  lr: 0.000070  g_loss: 10.5274 (11.4321)  d_loss: 1.7394 (1.7353)  gan_loss: 0.8461 (0.8595)  pix_loss: 0.9676 (1.0573)  time: 54.0660  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [940/985]  eta: 0:40:32  lr: 0.000070  g_loss: 10.7135 (11.4237)  d_loss: 1.7374 (1.7353)  gan_loss: 0.8420 (0.8593)  pix_loss: 0.9873 (1.0564)  time: 54.0645  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [950/985]  eta: 0:31:32  lr: 0.000070  g_loss: 10.4334 (11.4114)  d_loss: 1.7356 (1.7354)  gan_loss: 0.8423 (0.8592)  pix_loss: 0.9566 (1.0552)  time: 54.0679  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [960/985]  eta: 0:22:31  lr: 0.000070  g_loss: 10.5594 (11.4045)  d_loss: 1.7412 (1.7355)  gan_loss: 0.8457 (0.8590)  pix_loss: 0.9717 (1.0546)  time: 54.0691  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [970/985]  eta: 0:13:30  lr: 0.000070  g_loss: 10.5459 (11.3953)  d_loss: 1.7405 (1.7355)  gan_loss: 0.8397 (0.8589)  pix_loss: 0.9693 (1.0536)  time: 54.0717  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:8]  [980/985]  eta: 0:04:30  lr: 0.000070  g_loss: 10.4555 (11.3872)  d_loss: 1.7383 (1.7355)  gan_loss: 0.8377 (0.8587)  pix_loss: 0.9619 (1.0529)  time: 54.0985  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8]  [984/985]  eta: 0:00:54  lr: 0.000070  g_loss: 10.4782 (11.3855)  d_loss: 1.7384 (1.7355)  gan_loss: 0.8385 (0.8586)  pix_loss: 0.9639 (1.0527)  time: 54.1209  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:8] Total time: 14:47:36 (54.0672 s / it)\n",
      "Averaged stats: lr: 0.000070  g_loss: 10.4782 (11.3855)  d_loss: 1.7384 (1.7355)  gan_loss: 0.8385 (0.8586)  pix_loss: 0.9639 (1.0527)\n",
      "Valid: [epoch:8]  [ 0/14]  eta: 0:01:35  L1_loss: 0.0710 (0.0710)  time: 6.8245  data: 0.3227  max mem: 38397\n",
      "Valid: [epoch:8]  [13/14]  eta: 0:00:06  L1_loss: 0.0634 (0.0661)  time: 6.4387  data: 0.0231  max mem: 38397\n",
      "Valid: [epoch:8] Total time: 0:01:30 (6.4442 s / it)\n",
      "Averaged stats: L1_loss: 0.0634 (0.0661)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_8_input_n_20.png\n",
      "Train: [epoch:9]  [  0/985]  eta: 15:06:11  lr: 0.000080  g_loss: 10.2320 (10.2320)  d_loss: 1.7276 (1.7276)  gan_loss: 0.8503 (0.8503)  pix_loss: 0.9382 (0.9382)  time: 55.1997  data: 1.1023  max mem: 38397\n",
      "Train: [epoch:9]  [ 10/985]  eta: 14:40:18  lr: 0.000080  g_loss: 10.3838 (10.3482)  d_loss: 1.7417 (1.7378)  gan_loss: 0.8426 (0.8402)  pix_loss: 0.9534 (0.9508)  time: 54.1726  data: 0.1004  max mem: 38397\n",
      "Train: [epoch:9]  [ 20/985]  eta: 14:30:28  lr: 0.000080  g_loss: 10.3208 (10.3993)  d_loss: 1.7385 (1.7384)  gan_loss: 0.8394 (0.8414)  pix_loss: 0.9490 (0.9558)  time: 54.0692  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [ 30/985]  eta: 14:21:10  lr: 0.000080  g_loss: 10.3208 (10.4397)  d_loss: 1.7425 (1.7407)  gan_loss: 0.8432 (0.8417)  pix_loss: 0.9490 (0.9598)  time: 54.0686  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [ 40/985]  eta: 14:11:59  lr: 0.000080  g_loss: 10.4191 (10.4277)  d_loss: 1.7446 (1.7413)  gan_loss: 0.8439 (0.8421)  pix_loss: 0.9575 (0.9586)  time: 54.0648  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [ 50/985]  eta: 14:02:51  lr: 0.000080  g_loss: 10.2879 (10.3814)  d_loss: 1.7421 (1.7419)  gan_loss: 0.8404 (0.8408)  pix_loss: 0.9447 (0.9541)  time: 54.0596  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [ 60/985]  eta: 13:53:47  lr: 0.000080  g_loss: 10.2879 (10.3925)  d_loss: 1.7428 (1.7425)  gan_loss: 0.8366 (0.8411)  pix_loss: 0.9447 (0.9551)  time: 54.0620  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [ 70/985]  eta: 13:44:43  lr: 0.000080  g_loss: 10.4161 (10.4001)  d_loss: 1.7428 (1.7425)  gan_loss: 0.8415 (0.8416)  pix_loss: 0.9579 (0.9558)  time: 54.0638  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [ 80/985]  eta: 13:35:41  lr: 0.000080  g_loss: 10.2066 (10.3778)  d_loss: 1.7426 (1.7425)  gan_loss: 0.8408 (0.8412)  pix_loss: 0.9370 (0.9537)  time: 54.0641  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [ 90/985]  eta: 13:26:40  lr: 0.000080  g_loss: 10.1772 (10.3809)  d_loss: 1.7418 (1.7423)  gan_loss: 0.8386 (0.8411)  pix_loss: 0.9341 (0.9540)  time: 54.0691  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [100/985]  eta: 13:17:39  lr: 0.000080  g_loss: 10.3474 (10.3895)  d_loss: 1.7418 (1.7425)  gan_loss: 0.8391 (0.8411)  pix_loss: 0.9508 (0.9548)  time: 54.0761  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [110/985]  eta: 13:08:37  lr: 0.000080  g_loss: 10.3370 (10.3848)  d_loss: 1.7386 (1.7420)  gan_loss: 0.8394 (0.8415)  pix_loss: 0.9482 (0.9543)  time: 54.0747  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [120/985]  eta: 12:59:37  lr: 0.000080  g_loss: 10.3370 (10.4016)  d_loss: 1.7386 (1.7419)  gan_loss: 0.8419 (0.8418)  pix_loss: 0.9482 (0.9560)  time: 54.0750  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [130/985]  eta: 12:50:35  lr: 0.000080  g_loss: 10.5298 (10.4191)  d_loss: 1.7422 (1.7421)  gan_loss: 0.8419 (0.8421)  pix_loss: 0.9696 (0.9577)  time: 54.0750  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [140/985]  eta: 12:41:34  lr: 0.000080  g_loss: 10.6789 (10.4538)  d_loss: 1.7445 (1.7428)  gan_loss: 0.8475 (0.8426)  pix_loss: 0.9829 (0.9611)  time: 54.0710  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [150/985]  eta: 12:32:33  lr: 0.000080  g_loss: 10.4299 (10.4446)  d_loss: 1.7481 (1.7430)  gan_loss: 0.8453 (0.8427)  pix_loss: 0.9578 (0.9602)  time: 54.0698  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [160/985]  eta: 12:23:32  lr: 0.000080  g_loss: 10.2880 (10.4417)  d_loss: 1.7451 (1.7429)  gan_loss: 0.8418 (0.8431)  pix_loss: 0.9458 (0.9599)  time: 54.0698  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [170/985]  eta: 12:14:32  lr: 0.000080  g_loss: 10.1917 (10.4222)  d_loss: 1.7404 (1.7430)  gan_loss: 0.8407 (0.8427)  pix_loss: 0.9358 (0.9579)  time: 54.0750  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [180/985]  eta: 12:05:31  lr: 0.000080  g_loss: 10.1917 (10.4289)  d_loss: 1.7402 (1.7426)  gan_loss: 0.8409 (0.8433)  pix_loss: 0.9358 (0.9586)  time: 54.0754  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [190/985]  eta: 11:56:30  lr: 0.000080  g_loss: 10.1588 (10.4132)  d_loss: 1.7392 (1.7426)  gan_loss: 0.8468 (0.8432)  pix_loss: 0.9311 (0.9570)  time: 54.0755  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [200/985]  eta: 11:47:29  lr: 0.000080  g_loss: 10.1237 (10.4008)  d_loss: 1.7416 (1.7427)  gan_loss: 0.8410 (0.8431)  pix_loss: 0.9280 (0.9558)  time: 54.0762  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [210/985]  eta: 11:38:28  lr: 0.000080  g_loss: 10.1237 (10.3830)  d_loss: 1.7446 (1.7429)  gan_loss: 0.8390 (0.8428)  pix_loss: 0.9280 (0.9540)  time: 54.0733  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [220/985]  eta: 11:29:27  lr: 0.000080  g_loss: 10.1414 (10.3728)  d_loss: 1.7472 (1.7431)  gan_loss: 0.8390 (0.8428)  pix_loss: 0.9308 (0.9530)  time: 54.0732  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [230/985]  eta: 11:20:26  lr: 0.000080  g_loss: 10.1524 (10.3694)  d_loss: 1.7490 (1.7432)  gan_loss: 0.8435 (0.8429)  pix_loss: 0.9308 (0.9527)  time: 54.0717  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [240/985]  eta: 11:11:25  lr: 0.000080  g_loss: 10.2297 (10.3563)  d_loss: 1.7463 (1.7432)  gan_loss: 0.8435 (0.8429)  pix_loss: 0.9404 (0.9513)  time: 54.0682  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [250/985]  eta: 11:02:24  lr: 0.000080  g_loss: 9.9389 (10.3461)  d_loss: 1.7442 (1.7433)  gan_loss: 0.8408 (0.8429)  pix_loss: 0.9115 (0.9503)  time: 54.0668  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [260/985]  eta: 10:53:23  lr: 0.000080  g_loss: 9.9287 (10.3322)  d_loss: 1.7419 (1.7433)  gan_loss: 0.8431 (0.8430)  pix_loss: 0.9091 (0.9489)  time: 54.0622  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [270/985]  eta: 10:44:22  lr: 0.000080  g_loss: 10.1072 (10.3347)  d_loss: 1.7426 (1.7434)  gan_loss: 0.8455 (0.8430)  pix_loss: 0.9256 (0.9492)  time: 54.0626  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [280/985]  eta: 10:35:21  lr: 0.000080  g_loss: 10.1808 (10.3243)  d_loss: 1.7444 (1.7434)  gan_loss: 0.8426 (0.8429)  pix_loss: 0.9346 (0.9481)  time: 54.0658  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [290/985]  eta: 10:26:20  lr: 0.000080  g_loss: 9.8247 (10.3111)  d_loss: 1.7427 (1.7433)  gan_loss: 0.8405 (0.8428)  pix_loss: 0.9004 (0.9468)  time: 54.0668  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [300/985]  eta: 10:17:19  lr: 0.000080  g_loss: 10.1599 (10.3108)  d_loss: 1.7432 (1.7435)  gan_loss: 0.8439 (0.8430)  pix_loss: 0.9313 (0.9468)  time: 54.0644  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [310/985]  eta: 10:08:19  lr: 0.000080  g_loss: 10.2375 (10.3120)  d_loss: 1.7461 (1.7437)  gan_loss: 0.8439 (0.8431)  pix_loss: 0.9401 (0.9469)  time: 54.0670  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [320/985]  eta: 9:59:18  lr: 0.000080  g_loss: 10.2084 (10.3026)  d_loss: 1.7473 (1.7439)  gan_loss: 0.8433 (0.8431)  pix_loss: 0.9365 (0.9459)  time: 54.0669  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [330/985]  eta: 9:50:17  lr: 0.000080  g_loss: 9.8205 (10.2918)  d_loss: 1.7497 (1.7440)  gan_loss: 0.8404 (0.8430)  pix_loss: 0.8987 (0.9449)  time: 54.0681  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [340/985]  eta: 9:41:16  lr: 0.000080  g_loss: 9.7714 (10.2820)  d_loss: 1.7490 (1.7442)  gan_loss: 0.8395 (0.8428)  pix_loss: 0.8931 (0.9439)  time: 54.0708  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [350/985]  eta: 9:32:15  lr: 0.000080  g_loss: 9.7781 (10.2668)  d_loss: 1.7462 (1.7443)  gan_loss: 0.8311 (0.8425)  pix_loss: 0.8947 (0.9424)  time: 54.0686  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [360/985]  eta: 9:23:15  lr: 0.000080  g_loss: 9.7849 (10.2567)  d_loss: 1.7465 (1.7444)  gan_loss: 0.8338 (0.8426)  pix_loss: 0.8942 (0.9414)  time: 54.0665  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [370/985]  eta: 9:14:14  lr: 0.000080  g_loss: 9.8143 (10.2496)  d_loss: 1.7434 (1.7444)  gan_loss: 0.8451 (0.8427)  pix_loss: 0.8974 (0.9407)  time: 54.0665  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [380/985]  eta: 9:05:13  lr: 0.000080  g_loss: 9.8552 (10.2417)  d_loss: 1.7430 (1.7445)  gan_loss: 0.8443 (0.8426)  pix_loss: 0.8999 (0.9399)  time: 54.0686  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [390/985]  eta: 8:56:12  lr: 0.000080  g_loss: 9.8274 (10.2304)  d_loss: 1.7470 (1.7445)  gan_loss: 0.8400 (0.8426)  pix_loss: 0.8982 (0.9388)  time: 54.0689  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [400/985]  eta: 8:47:12  lr: 0.000080  g_loss: 9.8180 (10.2233)  d_loss: 1.7419 (1.7445)  gan_loss: 0.8400 (0.8426)  pix_loss: 0.8989 (0.9381)  time: 54.0698  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [410/985]  eta: 8:38:11  lr: 0.000080  g_loss: 9.8778 (10.2156)  d_loss: 1.7473 (1.7446)  gan_loss: 0.8392 (0.8425)  pix_loss: 0.9035 (0.9373)  time: 54.0704  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [420/985]  eta: 8:29:10  lr: 0.000080  g_loss: 9.8337 (10.2051)  d_loss: 1.7462 (1.7446)  gan_loss: 0.8365 (0.8423)  pix_loss: 0.9008 (0.9363)  time: 54.0711  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [430/985]  eta: 8:20:09  lr: 0.000080  g_loss: 9.8337 (10.2052)  d_loss: 1.7446 (1.7445)  gan_loss: 0.8366 (0.8423)  pix_loss: 0.9008 (0.9363)  time: 54.0690  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [440/985]  eta: 8:11:09  lr: 0.000080  g_loss: 9.9497 (10.1992)  d_loss: 1.7451 (1.7446)  gan_loss: 0.8424 (0.8422)  pix_loss: 0.9129 (0.9357)  time: 54.0679  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [450/985]  eta: 8:02:08  lr: 0.000080  g_loss: 9.6615 (10.1866)  d_loss: 1.7454 (1.7447)  gan_loss: 0.8347 (0.8421)  pix_loss: 0.8836 (0.9345)  time: 54.0676  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [460/985]  eta: 7:53:07  lr: 0.000080  g_loss: 9.5651 (10.1747)  d_loss: 1.7501 (1.7449)  gan_loss: 0.8316 (0.8419)  pix_loss: 0.8744 (0.9333)  time: 54.0660  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [470/985]  eta: 7:44:06  lr: 0.000080  g_loss: 9.7817 (10.1682)  d_loss: 1.7499 (1.7450)  gan_loss: 0.8430 (0.8419)  pix_loss: 0.8940 (0.9326)  time: 54.0668  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [480/985]  eta: 7:35:06  lr: 0.000080  g_loss: 9.7967 (10.1620)  d_loss: 1.7499 (1.7452)  gan_loss: 0.8430 (0.8418)  pix_loss: 0.8974 (0.9320)  time: 54.0699  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [490/985]  eta: 7:26:05  lr: 0.000080  g_loss: 9.7846 (10.1559)  d_loss: 1.7520 (1.7453)  gan_loss: 0.8315 (0.8416)  pix_loss: 0.8974 (0.9314)  time: 54.0691  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [500/985]  eta: 7:17:04  lr: 0.000080  g_loss: 9.8328 (10.1595)  d_loss: 1.7509 (1.7453)  gan_loss: 0.8405 (0.8417)  pix_loss: 0.9012 (0.9318)  time: 54.0706  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [510/985]  eta: 7:08:03  lr: 0.000080  g_loss: 9.9489 (10.1548)  d_loss: 1.7469 (1.7454)  gan_loss: 0.8488 (0.8418)  pix_loss: 0.9083 (0.9313)  time: 54.0758  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [520/985]  eta: 6:59:03  lr: 0.000080  g_loss: 9.8485 (10.1513)  d_loss: 1.7524 (1.7455)  gan_loss: 0.8399 (0.8417)  pix_loss: 0.9020 (0.9310)  time: 54.0725  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [530/985]  eta: 6:50:02  lr: 0.000080  g_loss: 9.6942 (10.1437)  d_loss: 1.7516 (1.7456)  gan_loss: 0.8395 (0.8417)  pix_loss: 0.8856 (0.9302)  time: 54.0671  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [540/985]  eta: 6:41:01  lr: 0.000080  g_loss: 9.7203 (10.1376)  d_loss: 1.7482 (1.7457)  gan_loss: 0.8362 (0.8417)  pix_loss: 0.8876 (0.9296)  time: 54.0669  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [550/985]  eta: 6:32:00  lr: 0.000080  g_loss: 9.8248 (10.1305)  d_loss: 1.7506 (1.7458)  gan_loss: 0.8346 (0.8416)  pix_loss: 0.8985 (0.9289)  time: 54.0653  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [560/985]  eta: 6:23:00  lr: 0.000080  g_loss: 9.6039 (10.1177)  d_loss: 1.7580 (1.7461)  gan_loss: 0.8363 (0.8414)  pix_loss: 0.8757 (0.9276)  time: 54.0676  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:9]  [570/985]  eta: 6:13:59  lr: 0.000080  g_loss: 9.4988 (10.1087)  d_loss: 1.7580 (1.7462)  gan_loss: 0.8328 (0.8413)  pix_loss: 0.8671 (0.9267)  time: 54.0711  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [580/985]  eta: 6:04:58  lr: 0.000080  g_loss: 9.5027 (10.1026)  d_loss: 1.7512 (1.7462)  gan_loss: 0.8328 (0.8413)  pix_loss: 0.8676 (0.9261)  time: 54.0690  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [590/985]  eta: 5:55:58  lr: 0.000080  g_loss: 9.5027 (10.0960)  d_loss: 1.7527 (1.7464)  gan_loss: 0.8327 (0.8412)  pix_loss: 0.8676 (0.9255)  time: 54.0668  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [600/985]  eta: 5:46:57  lr: 0.000080  g_loss: 9.5455 (10.0920)  d_loss: 1.7519 (1.7464)  gan_loss: 0.8345 (0.8412)  pix_loss: 0.8699 (0.9251)  time: 54.0704  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [610/985]  eta: 5:37:56  lr: 0.000080  g_loss: 9.8912 (10.0892)  d_loss: 1.7505 (1.7466)  gan_loss: 0.8376 (0.8412)  pix_loss: 0.9057 (0.9248)  time: 54.0721  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [620/985]  eta: 5:28:55  lr: 0.000080  g_loss: 9.8287 (10.0840)  d_loss: 1.7507 (1.7467)  gan_loss: 0.8418 (0.8412)  pix_loss: 0.8994 (0.9243)  time: 54.0714  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [630/985]  eta: 5:19:55  lr: 0.000080  g_loss: 9.6367 (10.0761)  d_loss: 1.7507 (1.7468)  gan_loss: 0.8418 (0.8412)  pix_loss: 0.8789 (0.9235)  time: 54.0714  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [640/985]  eta: 5:10:54  lr: 0.000080  g_loss: 9.4896 (10.0686)  d_loss: 1.7490 (1.7467)  gan_loss: 0.8348 (0.8412)  pix_loss: 0.8638 (0.9227)  time: 54.0697  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [650/985]  eta: 5:01:53  lr: 0.000080  g_loss: 9.6755 (10.0615)  d_loss: 1.7483 (1.7468)  gan_loss: 0.8342 (0.8411)  pix_loss: 0.8841 (0.9220)  time: 54.0703  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [660/985]  eta: 4:52:53  lr: 0.000080  g_loss: 9.6650 (10.0558)  d_loss: 1.7511 (1.7469)  gan_loss: 0.8351 (0.8410)  pix_loss: 0.8830 (0.9215)  time: 54.0685  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [670/985]  eta: 4:43:52  lr: 0.000080  g_loss: 9.5437 (10.0475)  d_loss: 1.7541 (1.7470)  gan_loss: 0.8343 (0.8410)  pix_loss: 0.8703 (0.9206)  time: 54.0648  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [680/985]  eta: 4:34:51  lr: 0.000080  g_loss: 9.5594 (10.0408)  d_loss: 1.7557 (1.7471)  gan_loss: 0.8336 (0.8409)  pix_loss: 0.8731 (0.9200)  time: 54.0670  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [690/985]  eta: 4:25:50  lr: 0.000080  g_loss: 9.6104 (10.0360)  d_loss: 1.7565 (1.7472)  gan_loss: 0.8337 (0.8408)  pix_loss: 0.8784 (0.9195)  time: 54.0682  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [700/985]  eta: 4:16:50  lr: 0.000080  g_loss: 9.6102 (10.0283)  d_loss: 1.7566 (1.7473)  gan_loss: 0.8368 (0.8408)  pix_loss: 0.8775 (0.9187)  time: 54.0679  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [710/985]  eta: 4:07:49  lr: 0.000080  g_loss: 9.6618 (10.0223)  d_loss: 1.7513 (1.7473)  gan_loss: 0.8365 (0.8407)  pix_loss: 0.8826 (0.9182)  time: 54.0689  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [720/985]  eta: 3:58:48  lr: 0.000080  g_loss: 9.7448 (10.0211)  d_loss: 1.7507 (1.7474)  gan_loss: 0.8343 (0.8406)  pix_loss: 0.8894 (0.9180)  time: 54.0644  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [730/985]  eta: 3:49:47  lr: 0.000080  g_loss: 9.5859 (10.0158)  d_loss: 1.7584 (1.7475)  gan_loss: 0.8344 (0.8405)  pix_loss: 0.8757 (0.9175)  time: 54.0683  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [740/985]  eta: 3:40:47  lr: 0.000080  g_loss: 9.6541 (10.0135)  d_loss: 1.7584 (1.7476)  gan_loss: 0.8376 (0.8405)  pix_loss: 0.8817 (0.9173)  time: 54.0706  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [750/985]  eta: 3:31:46  lr: 0.000080  g_loss: 9.6088 (10.0046)  d_loss: 1.7543 (1.7477)  gan_loss: 0.8363 (0.8404)  pix_loss: 0.8755 (0.9164)  time: 54.0611  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [760/985]  eta: 3:22:45  lr: 0.000080  g_loss: 9.3248 (9.9960)  d_loss: 1.7573 (1.7478)  gan_loss: 0.8364 (0.8404)  pix_loss: 0.8462 (0.9156)  time: 54.0578  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [770/985]  eta: 3:13:45  lr: 0.000080  g_loss: 9.3941 (9.9898)  d_loss: 1.7573 (1.7479)  gan_loss: 0.8364 (0.8403)  pix_loss: 0.8557 (0.9150)  time: 54.0585  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [780/985]  eta: 3:04:44  lr: 0.000080  g_loss: 9.4366 (9.9832)  d_loss: 1.7508 (1.7479)  gan_loss: 0.8355 (0.8403)  pix_loss: 0.8598 (0.9143)  time: 54.0569  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [790/985]  eta: 2:55:43  lr: 0.000080  g_loss: 9.3790 (9.9772)  d_loss: 1.7509 (1.7481)  gan_loss: 0.8355 (0.8402)  pix_loss: 0.8545 (0.9137)  time: 54.0603  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [800/985]  eta: 2:46:42  lr: 0.000080  g_loss: 9.5083 (9.9721)  d_loss: 1.7520 (1.7481)  gan_loss: 0.8358 (0.8402)  pix_loss: 0.8674 (0.9132)  time: 54.0689  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [810/985]  eta: 2:37:42  lr: 0.000080  g_loss: 9.5269 (9.9646)  d_loss: 1.7517 (1.7482)  gan_loss: 0.8364 (0.8401)  pix_loss: 0.8676 (0.9124)  time: 54.0691  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [820/985]  eta: 2:28:41  lr: 0.000080  g_loss: 9.1579 (9.9573)  d_loss: 1.7534 (1.7483)  gan_loss: 0.8307 (0.8400)  pix_loss: 0.8331 (0.9117)  time: 54.0667  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [830/985]  eta: 2:19:40  lr: 0.000080  g_loss: 9.1877 (9.9490)  d_loss: 1.7553 (1.7484)  gan_loss: 0.8272 (0.8399)  pix_loss: 0.8343 (0.9109)  time: 54.0685  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [840/985]  eta: 2:10:40  lr: 0.000080  g_loss: 9.4075 (9.9438)  d_loss: 1.7530 (1.7485)  gan_loss: 0.8316 (0.8398)  pix_loss: 0.8569 (0.9104)  time: 54.1282  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [850/985]  eta: 2:01:40  lr: 0.000080  g_loss: 9.3973 (9.9358)  d_loss: 1.7530 (1.7486)  gan_loss: 0.8323 (0.8397)  pix_loss: 0.8554 (0.9096)  time: 54.3385  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [860/985]  eta: 1:52:39  lr: 0.000080  g_loss: 9.2677 (9.9290)  d_loss: 1.7572 (1.7487)  gan_loss: 0.8263 (0.8396)  pix_loss: 0.8445 (0.9089)  time: 54.4444  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [870/985]  eta: 1:43:39  lr: 0.000080  g_loss: 9.3016 (9.9227)  d_loss: 1.7572 (1.7488)  gan_loss: 0.8344 (0.8396)  pix_loss: 0.8479 (0.9083)  time: 54.4167  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [880/985]  eta: 1:34:39  lr: 0.000080  g_loss: 9.3764 (9.9161)  d_loss: 1.7559 (1.7490)  gan_loss: 0.8344 (0.8394)  pix_loss: 0.8550 (0.9077)  time: 54.4209  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [890/985]  eta: 1:25:38  lr: 0.000080  g_loss: 9.2615 (9.9079)  d_loss: 1.7607 (1.7491)  gan_loss: 0.8204 (0.8393)  pix_loss: 0.8415 (0.9069)  time: 54.4028  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [900/985]  eta: 1:16:38  lr: 0.000080  g_loss: 9.2615 (9.9007)  d_loss: 1.7539 (1.7491)  gan_loss: 0.8299 (0.8392)  pix_loss: 0.8415 (0.9062)  time: 54.3894  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [910/985]  eta: 1:07:37  lr: 0.000080  g_loss: 9.1663 (9.8929)  d_loss: 1.7582 (1.7493)  gan_loss: 0.8299 (0.8391)  pix_loss: 0.8336 (0.9054)  time: 54.3842  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [920/985]  eta: 0:58:36  lr: 0.000080  g_loss: 9.1663 (9.8856)  d_loss: 1.7652 (1.7494)  gan_loss: 0.8297 (0.8390)  pix_loss: 0.8336 (0.9047)  time: 54.3977  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [930/985]  eta: 0:49:35  lr: 0.000080  g_loss: 9.1428 (9.8791)  d_loss: 1.7614 (1.7495)  gan_loss: 0.8277 (0.8389)  pix_loss: 0.8318 (0.9040)  time: 54.4002  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [940/985]  eta: 0:40:34  lr: 0.000080  g_loss: 9.2478 (9.8730)  d_loss: 1.7569 (1.7496)  gan_loss: 0.8311 (0.8388)  pix_loss: 0.8412 (0.9034)  time: 54.3933  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [950/985]  eta: 0:31:33  lr: 0.000080  g_loss: 9.1256 (9.8643)  d_loss: 1.7569 (1.7497)  gan_loss: 0.8291 (0.8387)  pix_loss: 0.8290 (0.9026)  time: 54.3878  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [960/985]  eta: 0:22:32  lr: 0.000080  g_loss: 9.1034 (9.8604)  d_loss: 1.7593 (1.7498)  gan_loss: 0.8311 (0.8387)  pix_loss: 0.8278 (0.9022)  time: 54.2294  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [970/985]  eta: 0:13:31  lr: 0.000080  g_loss: 9.1616 (9.8529)  d_loss: 1.7599 (1.7499)  gan_loss: 0.8291 (0.8385)  pix_loss: 0.8337 (0.9014)  time: 54.0760  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [980/985]  eta: 0:04:30  lr: 0.000080  g_loss: 8.9246 (9.8417)  d_loss: 1.7599 (1.7500)  gan_loss: 0.8264 (0.8384)  pix_loss: 0.8090 (0.9003)  time: 54.0780  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9]  [984/985]  eta: 0:00:54  lr: 0.000080  g_loss: 8.7965 (9.8376)  d_loss: 1.7596 (1.7500)  gan_loss: 0.8264 (0.8384)  pix_loss: 0.7982 (0.8999)  time: 54.0766  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:9] Total time: 14:48:17 (54.1090 s / it)\n",
      "Averaged stats: lr: 0.000080  g_loss: 8.7965 (9.8376)  d_loss: 1.7596 (1.7500)  gan_loss: 0.8264 (0.8384)  pix_loss: 0.7982 (0.8999)\n",
      "Valid: [epoch:9]  [ 0/14]  eta: 0:01:37  L1_loss: 0.0372 (0.0372)  time: 6.9372  data: 0.3747  max mem: 38397\n",
      "Valid: [epoch:9]  [13/14]  eta: 0:00:06  L1_loss: 0.0405 (0.0421)  time: 6.6480  data: 0.0269  max mem: 38397\n",
      "Valid: [epoch:9] Total time: 0:01:33 (6.6539 s / it)\n",
      "Averaged stats: L1_loss: 0.0405 (0.0421)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_9_input_n_20.png\n",
      "Train: [epoch:10]  [  0/985]  eta: 15:02:30  lr: 0.000090  g_loss: 9.1337 (9.1337)  d_loss: 1.7356 (1.7356)  gan_loss: 0.8535 (0.8535)  pix_loss: 0.8280 (0.8280)  time: 54.9747  data: 0.9061  max mem: 38397\n",
      "Train: [epoch:10]  [ 10/985]  eta: 14:39:22  lr: 0.000090  g_loss: 9.1337 (9.1915)  d_loss: 1.7537 (1.7589)  gan_loss: 0.8409 (0.8356)  pix_loss: 0.8280 (0.8356)  time: 54.1157  data: 0.0826  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [ 20/985]  eta: 14:29:40  lr: 0.000090  g_loss: 9.2631 (9.4017)  d_loss: 1.7601 (1.7599)  gan_loss: 0.8332 (0.8327)  pix_loss: 0.8445 (0.8569)  time: 54.0279  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [ 30/985]  eta: 14:20:34  lr: 0.000090  g_loss: 9.4089 (9.3669)  d_loss: 1.7625 (1.7606)  gan_loss: 0.8277 (0.8328)  pix_loss: 0.8579 (0.8534)  time: 54.0407  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [ 40/985]  eta: 14:11:30  lr: 0.000090  g_loss: 9.2679 (9.3361)  d_loss: 1.7584 (1.7598)  gan_loss: 0.8340 (0.8338)  pix_loss: 0.8434 (0.8502)  time: 54.0548  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [ 50/985]  eta: 14:02:27  lr: 0.000090  g_loss: 9.2451 (9.3471)  d_loss: 1.7670 (1.7641)  gan_loss: 0.8341 (0.8330)  pix_loss: 0.8406 (0.8514)  time: 54.0526  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [ 60/985]  eta: 13:53:25  lr: 0.000090  g_loss: 9.2572 (9.3415)  d_loss: 1.7636 (1.7626)  gan_loss: 0.8343 (0.8336)  pix_loss: 0.8412 (0.8508)  time: 54.0504  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [ 70/985]  eta: 13:44:23  lr: 0.000090  g_loss: 9.1704 (9.3229)  d_loss: 1.7522 (1.7609)  gan_loss: 0.8413 (0.8340)  pix_loss: 0.8339 (0.8489)  time: 54.0516  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [ 80/985]  eta: 13:35:22  lr: 0.000090  g_loss: 9.2797 (9.3318)  d_loss: 1.7503 (1.7605)  gan_loss: 0.8376 (0.8334)  pix_loss: 0.8461 (0.8498)  time: 54.0552  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [ 90/985]  eta: 13:26:22  lr: 0.000090  g_loss: 9.2623 (9.3087)  d_loss: 1.7555 (1.7604)  gan_loss: 0.8278 (0.8330)  pix_loss: 0.8427 (0.8476)  time: 54.0567  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [100/985]  eta: 13:17:21  lr: 0.000090  g_loss: 9.1607 (9.3139)  d_loss: 1.7569 (1.7604)  gan_loss: 0.8244 (0.8327)  pix_loss: 0.8308 (0.8481)  time: 54.0547  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [110/985]  eta: 13:08:20  lr: 0.000090  g_loss: 9.3349 (9.3223)  d_loss: 1.7582 (1.7607)  gan_loss: 0.8308 (0.8330)  pix_loss: 0.8482 (0.8489)  time: 54.0544  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [120/985]  eta: 12:59:19  lr: 0.000090  g_loss: 9.1041 (9.2911)  d_loss: 1.7661 (1.7609)  gan_loss: 0.8307 (0.8325)  pix_loss: 0.8268 (0.8459)  time: 54.0548  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [130/985]  eta: 12:50:18  lr: 0.000090  g_loss: 8.9425 (9.2909)  d_loss: 1.7651 (1.7617)  gan_loss: 0.8305 (0.8322)  pix_loss: 0.8089 (0.8459)  time: 54.0552  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [140/985]  eta: 12:41:18  lr: 0.000090  g_loss: 9.1816 (9.2852)  d_loss: 1.7646 (1.7616)  gan_loss: 0.8305 (0.8322)  pix_loss: 0.8361 (0.8453)  time: 54.0555  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [150/985]  eta: 12:32:17  lr: 0.000090  g_loss: 9.1882 (9.2771)  d_loss: 1.7620 (1.7618)  gan_loss: 0.8274 (0.8318)  pix_loss: 0.8358 (0.8445)  time: 54.0556  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [160/985]  eta: 12:23:17  lr: 0.000090  g_loss: 9.1446 (9.2746)  d_loss: 1.7602 (1.7612)  gan_loss: 0.8264 (0.8318)  pix_loss: 0.8322 (0.8443)  time: 54.0628  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [170/985]  eta: 12:14:16  lr: 0.000090  g_loss: 9.1419 (9.2589)  d_loss: 1.7572 (1.7614)  gan_loss: 0.8254 (0.8316)  pix_loss: 0.8316 (0.8427)  time: 54.0621  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [180/985]  eta: 12:05:16  lr: 0.000090  g_loss: 8.9997 (9.2553)  d_loss: 1.7602 (1.7613)  gan_loss: 0.8281 (0.8317)  pix_loss: 0.8174 (0.8424)  time: 54.0538  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [190/985]  eta: 11:56:15  lr: 0.000090  g_loss: 8.9997 (9.2425)  d_loss: 1.7602 (1.7615)  gan_loss: 0.8281 (0.8314)  pix_loss: 0.8174 (0.8411)  time: 54.0541  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [200/985]  eta: 11:47:14  lr: 0.000090  g_loss: 8.9827 (9.2329)  d_loss: 1.7662 (1.7615)  gan_loss: 0.8280 (0.8315)  pix_loss: 0.8140 (0.8401)  time: 54.0552  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [210/985]  eta: 11:38:14  lr: 0.000090  g_loss: 8.9494 (9.2152)  d_loss: 1.7650 (1.7615)  gan_loss: 0.8236 (0.8312)  pix_loss: 0.8133 (0.8384)  time: 54.0578  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [220/985]  eta: 11:29:13  lr: 0.000090  g_loss: 8.7777 (9.1910)  d_loss: 1.7648 (1.7618)  gan_loss: 0.8210 (0.8309)  pix_loss: 0.7963 (0.8360)  time: 54.0608  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [230/985]  eta: 11:20:13  lr: 0.000090  g_loss: 8.8849 (9.2073)  d_loss: 1.7598 (1.7616)  gan_loss: 0.8264 (0.8309)  pix_loss: 0.8072 (0.8376)  time: 54.0603  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [240/985]  eta: 11:11:13  lr: 0.000090  g_loss: 9.2733 (9.2017)  d_loss: 1.7540 (1.7615)  gan_loss: 0.8328 (0.8311)  pix_loss: 0.8451 (0.8371)  time: 54.0615  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [250/985]  eta: 11:02:12  lr: 0.000090  g_loss: 9.1275 (9.1987)  d_loss: 1.7643 (1.7618)  gan_loss: 0.8307 (0.8310)  pix_loss: 0.8266 (0.8368)  time: 54.0614  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [260/985]  eta: 10:53:11  lr: 0.000090  g_loss: 9.1068 (9.2044)  d_loss: 1.7698 (1.7619)  gan_loss: 0.8303 (0.8314)  pix_loss: 0.8253 (0.8373)  time: 54.0587  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [270/985]  eta: 10:44:11  lr: 0.000090  g_loss: 9.0816 (9.2036)  d_loss: 1.7731 (1.7621)  gan_loss: 0.8326 (0.8317)  pix_loss: 0.8267 (0.8372)  time: 54.0592  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [280/985]  eta: 10:35:10  lr: 0.000090  g_loss: 8.8371 (9.1867)  d_loss: 1.7748 (1.7629)  gan_loss: 0.8321 (0.8314)  pix_loss: 0.8030 (0.8355)  time: 54.0609  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [290/985]  eta: 10:26:10  lr: 0.000090  g_loss: 8.8045 (9.1811)  d_loss: 1.7775 (1.7632)  gan_loss: 0.8285 (0.8315)  pix_loss: 0.7976 (0.8350)  time: 54.0568  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [300/985]  eta: 10:17:09  lr: 0.000090  g_loss: 9.1533 (9.1907)  d_loss: 1.7695 (1.7631)  gan_loss: 0.8354 (0.8316)  pix_loss: 0.8311 (0.8359)  time: 54.0609  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [310/985]  eta: 10:08:09  lr: 0.000090  g_loss: 9.1323 (9.1902)  d_loss: 1.7667 (1.7634)  gan_loss: 0.8346 (0.8318)  pix_loss: 0.8298 (0.8358)  time: 54.0608  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [320/985]  eta: 9:59:08  lr: 0.000090  g_loss: 8.8620 (9.1784)  d_loss: 1.7724 (1.7639)  gan_loss: 0.8250 (0.8315)  pix_loss: 0.8019 (0.8347)  time: 54.0629  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [330/985]  eta: 9:50:08  lr: 0.000090  g_loss: 8.7616 (9.1649)  d_loss: 1.7705 (1.7641)  gan_loss: 0.8267 (0.8314)  pix_loss: 0.7931 (0.8334)  time: 54.0707  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [340/985]  eta: 9:41:07  lr: 0.000090  g_loss: 8.8031 (9.1574)  d_loss: 1.7670 (1.7641)  gan_loss: 0.8267 (0.8312)  pix_loss: 0.7990 (0.8326)  time: 54.0648  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [350/985]  eta: 9:32:07  lr: 0.000090  g_loss: 8.7573 (9.1432)  d_loss: 1.7689 (1.7644)  gan_loss: 0.8248 (0.8312)  pix_loss: 0.7918 (0.8312)  time: 54.0625  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [360/985]  eta: 9:23:06  lr: 0.000090  g_loss: 8.7573 (9.1435)  d_loss: 1.7702 (1.7644)  gan_loss: 0.8298 (0.8311)  pix_loss: 0.7918 (0.8312)  time: 54.0638  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [370/985]  eta: 9:14:06  lr: 0.000090  g_loss: 8.9394 (9.1350)  d_loss: 1.7686 (1.7646)  gan_loss: 0.8308 (0.8312)  pix_loss: 0.8097 (0.8304)  time: 54.0647  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [380/985]  eta: 9:05:05  lr: 0.000090  g_loss: 8.8906 (9.1284)  d_loss: 1.7618 (1.7645)  gan_loss: 0.8351 (0.8313)  pix_loss: 0.8040 (0.8297)  time: 54.0614  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [390/985]  eta: 8:56:05  lr: 0.000090  g_loss: 8.8269 (9.1227)  d_loss: 1.7603 (1.7644)  gan_loss: 0.8351 (0.8314)  pix_loss: 0.8007 (0.8291)  time: 54.0575  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [400/985]  eta: 8:47:04  lr: 0.000090  g_loss: 8.8210 (9.1177)  d_loss: 1.7604 (1.7643)  gan_loss: 0.8335 (0.8316)  pix_loss: 0.7980 (0.8286)  time: 54.0657  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [410/985]  eta: 8:38:04  lr: 0.000090  g_loss: 8.8570 (9.1106)  d_loss: 1.7672 (1.7644)  gan_loss: 0.8314 (0.8315)  pix_loss: 0.8034 (0.8279)  time: 54.0713  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [420/985]  eta: 8:29:03  lr: 0.000090  g_loss: 8.8570 (9.1090)  d_loss: 1.7688 (1.7644)  gan_loss: 0.8280 (0.8315)  pix_loss: 0.8034 (0.8277)  time: 54.0633  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [430/985]  eta: 8:20:03  lr: 0.000090  g_loss: 8.9147 (9.1082)  d_loss: 1.7693 (1.7645)  gan_loss: 0.8273 (0.8314)  pix_loss: 0.8093 (0.8277)  time: 54.0600  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [440/985]  eta: 8:11:02  lr: 0.000090  g_loss: 8.9849 (9.1050)  d_loss: 1.7682 (1.7646)  gan_loss: 0.8269 (0.8314)  pix_loss: 0.8162 (0.8274)  time: 54.0604  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [450/985]  eta: 8:02:01  lr: 0.000090  g_loss: 8.9551 (9.1009)  d_loss: 1.7725 (1.7648)  gan_loss: 0.8296 (0.8313)  pix_loss: 0.8122 (0.8270)  time: 54.0557  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [460/985]  eta: 7:53:01  lr: 0.000090  g_loss: 8.9137 (9.0957)  d_loss: 1.7733 (1.7650)  gan_loss: 0.8296 (0.8314)  pix_loss: 0.8086 (0.8264)  time: 54.0540  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [470/985]  eta: 7:44:00  lr: 0.000090  g_loss: 8.8191 (9.0930)  d_loss: 1.7675 (1.7650)  gan_loss: 0.8270 (0.8312)  pix_loss: 0.7967 (0.8262)  time: 54.0564  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [480/985]  eta: 7:34:59  lr: 0.000090  g_loss: 8.8755 (9.0934)  d_loss: 1.7675 (1.7650)  gan_loss: 0.8216 (0.8310)  pix_loss: 0.8044 (0.8262)  time: 54.0542  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [490/985]  eta: 7:25:59  lr: 0.000090  g_loss: 9.0174 (9.0938)  d_loss: 1.7631 (1.7650)  gan_loss: 0.8255 (0.8310)  pix_loss: 0.8174 (0.8263)  time: 54.0522  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [500/985]  eta: 7:16:58  lr: 0.000090  g_loss: 8.9521 (9.0891)  d_loss: 1.7622 (1.7649)  gan_loss: 0.8289 (0.8311)  pix_loss: 0.8142 (0.8258)  time: 54.0579  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [510/985]  eta: 7:07:58  lr: 0.000090  g_loss: 8.8485 (9.0850)  d_loss: 1.7642 (1.7650)  gan_loss: 0.8289 (0.8311)  pix_loss: 0.7999 (0.8254)  time: 54.0578  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [520/985]  eta: 6:58:57  lr: 0.000090  g_loss: 8.7662 (9.0804)  d_loss: 1.7767 (1.7652)  gan_loss: 0.8254 (0.8309)  pix_loss: 0.7958 (0.8249)  time: 54.0562  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [530/985]  eta: 6:49:56  lr: 0.000090  g_loss: 8.7596 (9.0772)  d_loss: 1.7761 (1.7652)  gan_loss: 0.8261 (0.8310)  pix_loss: 0.7921 (0.8246)  time: 54.0602  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [540/985]  eta: 6:40:56  lr: 0.000090  g_loss: 8.7019 (9.0667)  d_loss: 1.7687 (1.7654)  gan_loss: 0.8272 (0.8309)  pix_loss: 0.7860 (0.8236)  time: 54.0608  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [550/985]  eta: 6:31:55  lr: 0.000090  g_loss: 8.6562 (9.0626)  d_loss: 1.7707 (1.7655)  gan_loss: 0.8272 (0.8309)  pix_loss: 0.7821 (0.8232)  time: 54.0583  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [560/985]  eta: 6:22:55  lr: 0.000090  g_loss: 8.6244 (9.0536)  d_loss: 1.7730 (1.7657)  gan_loss: 0.8256 (0.8307)  pix_loss: 0.7794 (0.8223)  time: 54.0594  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [570/985]  eta: 6:13:54  lr: 0.000090  g_loss: 8.3781 (9.0443)  d_loss: 1.7740 (1.7659)  gan_loss: 0.8228 (0.8306)  pix_loss: 0.7565 (0.8214)  time: 54.0574  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [580/985]  eta: 6:04:53  lr: 0.000090  g_loss: 8.4323 (9.0327)  d_loss: 1.7740 (1.7661)  gan_loss: 0.8238 (0.8306)  pix_loss: 0.7589 (0.8202)  time: 54.0537  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [590/985]  eta: 5:55:53  lr: 0.000090  g_loss: 8.4404 (9.0234)  d_loss: 1.7718 (1.7662)  gan_loss: 0.8248 (0.8305)  pix_loss: 0.7589 (0.8193)  time: 54.0524  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [600/985]  eta: 5:46:52  lr: 0.000090  g_loss: 8.4816 (9.0142)  d_loss: 1.7718 (1.7662)  gan_loss: 0.8248 (0.8305)  pix_loss: 0.7644 (0.8184)  time: 54.0494  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [610/985]  eta: 5:37:52  lr: 0.000090  g_loss: 8.6724 (9.0150)  d_loss: 1.7633 (1.7662)  gan_loss: 0.8303 (0.8304)  pix_loss: 0.7854 (0.8185)  time: 54.0686  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [620/985]  eta: 5:28:51  lr: 0.000090  g_loss: 8.8229 (9.0105)  d_loss: 1.7634 (1.7663)  gan_loss: 0.8318 (0.8305)  pix_loss: 0.7990 (0.8180)  time: 54.0758  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [630/985]  eta: 5:19:51  lr: 0.000090  g_loss: 8.5807 (9.0035)  d_loss: 1.7637 (1.7662)  gan_loss: 0.8291 (0.8305)  pix_loss: 0.7782 (0.8173)  time: 54.0632  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [640/985]  eta: 5:10:50  lr: 0.000090  g_loss: 8.6418 (9.0013)  d_loss: 1.7638 (1.7663)  gan_loss: 0.8245 (0.8305)  pix_loss: 0.7801 (0.8171)  time: 54.0649  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [650/985]  eta: 5:01:49  lr: 0.000090  g_loss: 8.6765 (8.9946)  d_loss: 1.7724 (1.7665)  gan_loss: 0.8231 (0.8303)  pix_loss: 0.7839 (0.8164)  time: 54.0643  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [660/985]  eta: 4:52:49  lr: 0.000090  g_loss: 8.8040 (8.9975)  d_loss: 1.7707 (1.7665)  gan_loss: 0.8230 (0.8303)  pix_loss: 0.7984 (0.8167)  time: 54.0631  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [670/985]  eta: 4:43:48  lr: 0.000090  g_loss: 8.9824 (8.9952)  d_loss: 1.7728 (1.7667)  gan_loss: 0.8241 (0.8302)  pix_loss: 0.8180 (0.8165)  time: 54.0626  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [680/985]  eta: 4:34:48  lr: 0.000090  g_loss: 8.7126 (8.9893)  d_loss: 1.7763 (1.7666)  gan_loss: 0.8222 (0.8301)  pix_loss: 0.7888 (0.8159)  time: 54.0600  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [690/985]  eta: 4:25:47  lr: 0.000090  g_loss: 8.5057 (8.9827)  d_loss: 1.7686 (1.7667)  gan_loss: 0.8222 (0.8300)  pix_loss: 0.7648 (0.8153)  time: 54.0609  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [700/985]  eta: 4:16:47  lr: 0.000090  g_loss: 8.5015 (8.9765)  d_loss: 1.7753 (1.7669)  gan_loss: 0.8207 (0.8299)  pix_loss: 0.7671 (0.8147)  time: 54.0639  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [710/985]  eta: 4:07:46  lr: 0.000090  g_loss: 8.5015 (8.9722)  d_loss: 1.7750 (1.7669)  gan_loss: 0.8192 (0.8299)  pix_loss: 0.7671 (0.8142)  time: 54.0630  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [720/985]  eta: 3:58:45  lr: 0.000090  g_loss: 8.3703 (8.9655)  d_loss: 1.7730 (1.7670)  gan_loss: 0.8191 (0.8297)  pix_loss: 0.7551 (0.8136)  time: 54.0612  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [730/985]  eta: 3:49:45  lr: 0.000090  g_loss: 8.4900 (8.9613)  d_loss: 1.7725 (1.7671)  gan_loss: 0.8193 (0.8296)  pix_loss: 0.7659 (0.8132)  time: 54.0589  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [740/985]  eta: 3:40:44  lr: 0.000090  g_loss: 8.7707 (8.9619)  d_loss: 1.7702 (1.7670)  gan_loss: 0.8250 (0.8298)  pix_loss: 0.7946 (0.8132)  time: 54.0576  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [750/985]  eta: 3:31:44  lr: 0.000090  g_loss: 8.4797 (8.9529)  d_loss: 1.7738 (1.7672)  gan_loss: 0.8227 (0.8297)  pix_loss: 0.7657 (0.8123)  time: 54.0575  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [760/985]  eta: 3:22:43  lr: 0.000090  g_loss: 8.2536 (8.9465)  d_loss: 1.7757 (1.7673)  gan_loss: 0.8227 (0.8296)  pix_loss: 0.7416 (0.8117)  time: 54.0566  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [770/985]  eta: 3:13:42  lr: 0.000090  g_loss: 8.5186 (8.9426)  d_loss: 1.7738 (1.7673)  gan_loss: 0.8210 (0.8296)  pix_loss: 0.7693 (0.8113)  time: 54.0565  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [780/985]  eta: 3:04:42  lr: 0.000090  g_loss: 8.5186 (8.9378)  d_loss: 1.7724 (1.7673)  gan_loss: 0.8192 (0.8295)  pix_loss: 0.7693 (0.8108)  time: 54.0587  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [790/985]  eta: 2:55:41  lr: 0.000090  g_loss: 8.5791 (8.9348)  d_loss: 1.7719 (1.7674)  gan_loss: 0.8225 (0.8294)  pix_loss: 0.7753 (0.8105)  time: 54.0639  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [800/985]  eta: 2:46:41  lr: 0.000090  g_loss: 8.5864 (8.9290)  d_loss: 1.7734 (1.7674)  gan_loss: 0.8199 (0.8293)  pix_loss: 0.7766 (0.8100)  time: 54.0645  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [810/985]  eta: 2:37:40  lr: 0.000090  g_loss: 8.3711 (8.9244)  d_loss: 1.7752 (1.7675)  gan_loss: 0.8181 (0.8293)  pix_loss: 0.7552 (0.8095)  time: 54.0670  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [820/985]  eta: 2:28:39  lr: 0.000090  g_loss: 8.4589 (8.9190)  d_loss: 1.7755 (1.7677)  gan_loss: 0.8188 (0.8291)  pix_loss: 0.7616 (0.8090)  time: 54.0677  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [830/985]  eta: 2:19:39  lr: 0.000090  g_loss: 8.4895 (8.9133)  d_loss: 1.7777 (1.7678)  gan_loss: 0.8145 (0.8290)  pix_loss: 0.7685 (0.8084)  time: 54.0635  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [840/985]  eta: 2:10:38  lr: 0.000090  g_loss: 8.3654 (8.9080)  d_loss: 1.7766 (1.7679)  gan_loss: 0.8188 (0.8290)  pix_loss: 0.7551 (0.8079)  time: 54.0622  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [850/985]  eta: 2:01:38  lr: 0.000090  g_loss: 8.5150 (8.9049)  d_loss: 1.7772 (1.7681)  gan_loss: 0.8230 (0.8289)  pix_loss: 0.7684 (0.8076)  time: 54.0602  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [860/985]  eta: 1:52:37  lr: 0.000090  g_loss: 8.5331 (8.8999)  d_loss: 1.7775 (1.7682)  gan_loss: 0.8169 (0.8289)  pix_loss: 0.7717 (0.8071)  time: 54.0601  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [870/985]  eta: 1:43:36  lr: 0.000090  g_loss: 8.3113 (8.8915)  d_loss: 1.7799 (1.7683)  gan_loss: 0.8178 (0.8287)  pix_loss: 0.7491 (0.8063)  time: 54.0598  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [880/985]  eta: 1:34:36  lr: 0.000090  g_loss: 8.1888 (8.8855)  d_loss: 1.7799 (1.7684)  gan_loss: 0.8185 (0.8287)  pix_loss: 0.7370 (0.8057)  time: 54.0585  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [890/985]  eta: 1:25:35  lr: 0.000090  g_loss: 8.2076 (8.8803)  d_loss: 1.7809 (1.7686)  gan_loss: 0.8228 (0.8287)  pix_loss: 0.7366 (0.8052)  time: 54.0621  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [900/985]  eta: 1:16:35  lr: 0.000090  g_loss: 8.2271 (8.8748)  d_loss: 1.7900 (1.7690)  gan_loss: 0.8249 (0.8287)  pix_loss: 0.7397 (0.8046)  time: 54.0636  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [910/985]  eta: 1:07:34  lr: 0.000090  g_loss: 8.2271 (8.8679)  d_loss: 1.7901 (1.7693)  gan_loss: 0.8258 (0.8287)  pix_loss: 0.7397 (0.8039)  time: 54.0613  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [920/985]  eta: 0:58:33  lr: 0.000090  g_loss: 8.2699 (8.8610)  d_loss: 1.7930 (1.7695)  gan_loss: 0.8240 (0.8286)  pix_loss: 0.7450 (0.8032)  time: 54.0640  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [930/985]  eta: 0:49:33  lr: 0.000090  g_loss: 8.2975 (8.8562)  d_loss: 1.7930 (1.7697)  gan_loss: 0.8229 (0.8285)  pix_loss: 0.7482 (0.8028)  time: 54.0672  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [940/985]  eta: 0:40:32  lr: 0.000090  g_loss: 8.6750 (8.8559)  d_loss: 1.7803 (1.7698)  gan_loss: 0.8155 (0.8284)  pix_loss: 0.7877 (0.8028)  time: 54.0696  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [950/985]  eta: 0:31:32  lr: 0.000090  g_loss: 8.7025 (8.8515)  d_loss: 1.7792 (1.7699)  gan_loss: 0.8129 (0.8283)  pix_loss: 0.7877 (0.8023)  time: 54.0708  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [960/985]  eta: 0:22:31  lr: 0.000090  g_loss: 8.3553 (8.8478)  d_loss: 1.7899 (1.7702)  gan_loss: 0.8165 (0.8282)  pix_loss: 0.7522 (0.8020)  time: 54.0696  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [970/985]  eta: 0:13:30  lr: 0.000090  g_loss: 8.2268 (8.8398)  d_loss: 1.7932 (1.7704)  gan_loss: 0.8305 (0.8282)  pix_loss: 0.7410 (0.8012)  time: 54.0652  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [980/985]  eta: 0:04:30  lr: 0.000090  g_loss: 8.1581 (8.8349)  d_loss: 1.7925 (1.7706)  gan_loss: 0.8199 (0.8281)  pix_loss: 0.7316 (0.8007)  time: 54.0604  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10]  [984/985]  eta: 0:00:54  lr: 0.000090  g_loss: 8.1581 (8.8323)  d_loss: 1.7903 (1.7706)  gan_loss: 0.8199 (0.8281)  pix_loss: 0.7334 (0.8004)  time: 54.0619  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:10] Total time: 14:47:29 (54.0608 s / it)\n",
      "Averaged stats: lr: 0.000090  g_loss: 8.1581 (8.8323)  d_loss: 1.7903 (1.7706)  gan_loss: 0.8199 (0.8281)  pix_loss: 0.7334 (0.8004)\n",
      "Valid: [epoch:10]  [ 0/14]  eta: 0:01:38  L1_loss: 0.0548 (0.0548)  time: 7.0575  data: 0.3565  max mem: 38397\n",
      "Valid: [epoch:10]  [13/14]  eta: 0:00:06  L1_loss: 0.0521 (0.0525)  time: 6.4831  data: 0.0256  max mem: 38397\n",
      "Valid: [epoch:10] Total time: 0:01:30 (6.4907 s / it)\n",
      "Averaged stats: L1_loss: 0.0521 (0.0525)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_10_input_n_20.png\n",
      "Train: [epoch:11]  [  0/985]  eta: 15:09:08  lr: 0.000100  g_loss: 7.9630 (7.9630)  d_loss: 1.8026 (1.8026)  gan_loss: 0.7896 (0.7896)  pix_loss: 0.7173 (0.7173)  time: 55.3790  data: 1.2147  max mem: 38397\n",
      "Train: [epoch:11]  [ 10/985]  eta: 14:40:27  lr: 0.000100  g_loss: 8.3783 (8.5288)  d_loss: 1.7745 (1.7742)  gan_loss: 0.8195 (0.8150)  pix_loss: 0.7518 (0.7714)  time: 54.1825  data: 0.1106  max mem: 38397\n",
      "Train: [epoch:11]  [ 20/985]  eta: 14:30:33  lr: 0.000100  g_loss: 8.6605 (8.6574)  d_loss: 1.7809 (1.7777)  gan_loss: 0.8199 (0.8195)  pix_loss: 0.7858 (0.7838)  time: 54.0653  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [ 30/985]  eta: 14:21:11  lr: 0.000100  g_loss: 8.8748 (8.7778)  d_loss: 1.7855 (1.7802)  gan_loss: 0.8281 (0.8211)  pix_loss: 0.8046 (0.7957)  time: 54.0645  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [ 40/985]  eta: 14:11:59  lr: 0.000100  g_loss: 8.9102 (8.8111)  d_loss: 1.7895 (1.7834)  gan_loss: 0.8333 (0.8277)  pix_loss: 0.8059 (0.7983)  time: 54.0598  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [ 50/985]  eta: 14:02:52  lr: 0.000100  g_loss: 8.7207 (8.7840)  d_loss: 1.7871 (1.7820)  gan_loss: 0.8383 (0.8275)  pix_loss: 0.7881 (0.7957)  time: 54.0592  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [ 60/985]  eta: 13:53:47  lr: 0.000100  g_loss: 8.6603 (8.7861)  d_loss: 1.7768 (1.7805)  gan_loss: 0.8287 (0.8274)  pix_loss: 0.7845 (0.7959)  time: 54.0616  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [ 70/985]  eta: 13:44:45  lr: 0.000100  g_loss: 8.6094 (8.7414)  d_loss: 1.7772 (1.7805)  gan_loss: 0.8313 (0.8287)  pix_loss: 0.7753 (0.7913)  time: 54.0669  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [ 80/985]  eta: 13:35:41  lr: 0.000100  g_loss: 8.4695 (8.7097)  d_loss: 1.7788 (1.7798)  gan_loss: 0.8288 (0.8278)  pix_loss: 0.7616 (0.7882)  time: 54.0658  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [ 90/985]  eta: 13:26:39  lr: 0.000100  g_loss: 8.5129 (8.6968)  d_loss: 1.7793 (1.7798)  gan_loss: 0.8230 (0.8270)  pix_loss: 0.7701 (0.7870)  time: 54.0614  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [100/985]  eta: 13:17:36  lr: 0.000100  g_loss: 8.4454 (8.6825)  d_loss: 1.7793 (1.7793)  gan_loss: 0.8230 (0.8277)  pix_loss: 0.7612 (0.7855)  time: 54.0577  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [110/985]  eta: 13:08:34  lr: 0.000100  g_loss: 8.3645 (8.6429)  d_loss: 1.7873 (1.7797)  gan_loss: 0.8258 (0.8278)  pix_loss: 0.7509 (0.7815)  time: 54.0547  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [120/985]  eta: 12:59:32  lr: 0.000100  g_loss: 8.2380 (8.6276)  d_loss: 1.7810 (1.7797)  gan_loss: 0.8194 (0.8274)  pix_loss: 0.7408 (0.7800)  time: 54.0593  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [130/985]  eta: 12:50:31  lr: 0.000100  g_loss: 8.2726 (8.6114)  d_loss: 1.7797 (1.7794)  gan_loss: 0.8275 (0.8275)  pix_loss: 0.7450 (0.7784)  time: 54.0649  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [140/985]  eta: 12:41:29  lr: 0.000100  g_loss: 8.3514 (8.5995)  d_loss: 1.7803 (1.7797)  gan_loss: 0.8264 (0.8271)  pix_loss: 0.7509 (0.7772)  time: 54.0604  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [150/985]  eta: 12:32:28  lr: 0.000100  g_loss: 8.0962 (8.5564)  d_loss: 1.7861 (1.7804)  gan_loss: 0.8219 (0.8267)  pix_loss: 0.7295 (0.7730)  time: 54.0596  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [160/985]  eta: 12:23:27  lr: 0.000100  g_loss: 8.0566 (8.5381)  d_loss: 1.7898 (1.7803)  gan_loss: 0.8198 (0.8266)  pix_loss: 0.7243 (0.7712)  time: 54.0645  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [170/985]  eta: 12:14:26  lr: 0.000100  g_loss: 8.3181 (8.5247)  d_loss: 1.7888 (1.7808)  gan_loss: 0.8191 (0.8261)  pix_loss: 0.7497 (0.7699)  time: 54.0610  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [180/985]  eta: 12:05:25  lr: 0.000100  g_loss: 8.3181 (8.5196)  d_loss: 1.7849 (1.7805)  gan_loss: 0.8210 (0.8261)  pix_loss: 0.7502 (0.7694)  time: 54.0581  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [190/985]  eta: 11:56:24  lr: 0.000100  g_loss: 8.4557 (8.5099)  d_loss: 1.7785 (1.7804)  gan_loss: 0.8223 (0.8261)  pix_loss: 0.7604 (0.7684)  time: 54.0618  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [200/985]  eta: 11:47:23  lr: 0.000100  g_loss: 8.0886 (8.4923)  d_loss: 1.7785 (1.7803)  gan_loss: 0.8198 (0.8259)  pix_loss: 0.7258 (0.7666)  time: 54.0645  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [210/985]  eta: 11:38:22  lr: 0.000100  g_loss: 8.0394 (8.4719)  d_loss: 1.7787 (1.7803)  gan_loss: 0.8208 (0.8259)  pix_loss: 0.7199 (0.7646)  time: 54.0608  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [220/985]  eta: 11:29:21  lr: 0.000100  g_loss: 8.0554 (8.4649)  d_loss: 1.7787 (1.7802)  gan_loss: 0.8208 (0.8256)  pix_loss: 0.7237 (0.7639)  time: 54.0649  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [230/985]  eta: 11:20:21  lr: 0.000100  g_loss: 8.3154 (8.4694)  d_loss: 1.7826 (1.7803)  gan_loss: 0.8217 (0.8256)  pix_loss: 0.7515 (0.7644)  time: 54.0657  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [240/985]  eta: 11:11:20  lr: 0.000100  g_loss: 8.2028 (8.4586)  d_loss: 1.7870 (1.7811)  gan_loss: 0.8255 (0.8258)  pix_loss: 0.7381 (0.7633)  time: 54.0657  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [250/985]  eta: 11:02:19  lr: 0.000100  g_loss: 8.0182 (8.4452)  d_loss: 1.8022 (1.7820)  gan_loss: 0.8258 (0.8258)  pix_loss: 0.7208 (0.7619)  time: 54.0705  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [260/985]  eta: 10:53:18  lr: 0.000100  g_loss: 8.0420 (8.4253)  d_loss: 1.8031 (1.7829)  gan_loss: 0.8193 (0.8257)  pix_loss: 0.7217 (0.7600)  time: 54.0619  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [270/985]  eta: 10:44:17  lr: 0.000100  g_loss: 8.0358 (8.4177)  d_loss: 1.7963 (1.7830)  gan_loss: 0.8193 (0.8257)  pix_loss: 0.7217 (0.7592)  time: 54.0575  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [280/985]  eta: 10:35:17  lr: 0.000100  g_loss: 8.1733 (8.4038)  d_loss: 1.7877 (1.7831)  gan_loss: 0.8199 (0.8256)  pix_loss: 0.7313 (0.7578)  time: 54.0608  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [290/985]  eta: 10:26:16  lr: 0.000100  g_loss: 8.1827 (8.4022)  d_loss: 1.7885 (1.7833)  gan_loss: 0.8184 (0.8252)  pix_loss: 0.7381 (0.7577)  time: 54.0621  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [300/985]  eta: 10:17:15  lr: 0.000100  g_loss: 8.3792 (8.4086)  d_loss: 1.7810 (1.7833)  gan_loss: 0.8208 (0.8252)  pix_loss: 0.7558 (0.7583)  time: 54.0635  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [310/985]  eta: 10:08:14  lr: 0.000100  g_loss: 8.3424 (8.4193)  d_loss: 1.7836 (1.7835)  gan_loss: 0.8194 (0.8250)  pix_loss: 0.7516 (0.7594)  time: 54.0648  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [320/985]  eta: 9:59:14  lr: 0.000100  g_loss: 8.1997 (8.4045)  d_loss: 1.7965 (1.7839)  gan_loss: 0.8133 (0.8245)  pix_loss: 0.7371 (0.7580)  time: 54.0628  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [330/985]  eta: 9:50:13  lr: 0.000100  g_loss: 7.9044 (8.3942)  d_loss: 1.8003 (1.7844)  gan_loss: 0.8168 (0.8244)  pix_loss: 0.7122 (0.7570)  time: 54.0639  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [340/985]  eta: 9:41:12  lr: 0.000100  g_loss: 7.9736 (8.3869)  d_loss: 1.7916 (1.7845)  gan_loss: 0.8161 (0.8240)  pix_loss: 0.7149 (0.7563)  time: 54.0703  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [350/985]  eta: 9:32:12  lr: 0.000100  g_loss: 8.0583 (8.3770)  d_loss: 1.7918 (1.7849)  gan_loss: 0.8151 (0.8240)  pix_loss: 0.7247 (0.7553)  time: 54.0690  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [360/985]  eta: 9:23:11  lr: 0.000100  g_loss: 8.0583 (8.3691)  d_loss: 1.7940 (1.7852)  gan_loss: 0.8149 (0.8236)  pix_loss: 0.7247 (0.7546)  time: 54.0652  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [370/985]  eta: 9:14:10  lr: 0.000100  g_loss: 7.9592 (8.3554)  d_loss: 1.7957 (1.7853)  gan_loss: 0.8142 (0.8233)  pix_loss: 0.7144 (0.7532)  time: 54.0666  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [380/985]  eta: 9:05:10  lr: 0.000100  g_loss: 7.9122 (8.3546)  d_loss: 1.7882 (1.7853)  gan_loss: 0.8133 (0.8232)  pix_loss: 0.7087 (0.7531)  time: 54.0647  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [390/985]  eta: 8:56:09  lr: 0.000100  g_loss: 8.0394 (8.3489)  d_loss: 1.7863 (1.7853)  gan_loss: 0.8194 (0.8230)  pix_loss: 0.7237 (0.7526)  time: 54.0617  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [400/985]  eta: 8:47:08  lr: 0.000100  g_loss: 8.0394 (8.3469)  d_loss: 1.7794 (1.7852)  gan_loss: 0.8194 (0.8229)  pix_loss: 0.7237 (0.7524)  time: 54.0650  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [410/985]  eta: 8:38:08  lr: 0.000100  g_loss: 8.1883 (8.3479)  d_loss: 1.7789 (1.7849)  gan_loss: 0.8194 (0.8231)  pix_loss: 0.7386 (0.7525)  time: 54.0664  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [420/985]  eta: 8:29:07  lr: 0.000100  g_loss: 8.1883 (8.3410)  d_loss: 1.7870 (1.7852)  gan_loss: 0.8129 (0.8228)  pix_loss: 0.7386 (0.7518)  time: 54.0623  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [430/985]  eta: 8:20:06  lr: 0.000100  g_loss: 8.2589 (8.3442)  d_loss: 1.7850 (1.7851)  gan_loss: 0.8186 (0.8228)  pix_loss: 0.7427 (0.7521)  time: 54.0638  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [440/985]  eta: 8:11:06  lr: 0.000100  g_loss: 8.5497 (8.3461)  d_loss: 1.7829 (1.7850)  gan_loss: 0.8250 (0.8228)  pix_loss: 0.7727 (0.7523)  time: 54.0665  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [450/985]  eta: 8:02:05  lr: 0.000100  g_loss: 8.2588 (8.3484)  d_loss: 1.7803 (1.7848)  gan_loss: 0.8229 (0.8228)  pix_loss: 0.7437 (0.7526)  time: 54.0623  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [460/985]  eta: 7:53:04  lr: 0.000100  g_loss: 8.2013 (8.3422)  d_loss: 1.7803 (1.7848)  gan_loss: 0.8214 (0.8228)  pix_loss: 0.7378 (0.7519)  time: 54.0586  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [470/985]  eta: 7:44:03  lr: 0.000100  g_loss: 7.9289 (8.3339)  d_loss: 1.7883 (1.7849)  gan_loss: 0.8164 (0.8227)  pix_loss: 0.7127 (0.7511)  time: 54.0620  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [480/985]  eta: 7:35:03  lr: 0.000100  g_loss: 7.9923 (8.3302)  d_loss: 1.7891 (1.7848)  gan_loss: 0.8164 (0.8226)  pix_loss: 0.7173 (0.7508)  time: 54.0632  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [490/985]  eta: 7:26:02  lr: 0.000100  g_loss: 8.0047 (8.3240)  d_loss: 1.7841 (1.7849)  gan_loss: 0.8164 (0.8225)  pix_loss: 0.7193 (0.7501)  time: 54.0619  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [500/985]  eta: 7:17:01  lr: 0.000100  g_loss: 8.1272 (8.3219)  d_loss: 1.7906 (1.7850)  gan_loss: 0.8047 (0.8222)  pix_loss: 0.7281 (0.7500)  time: 54.0648  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [510/985]  eta: 7:08:01  lr: 0.000100  g_loss: 8.1572 (8.3184)  d_loss: 1.7861 (1.7850)  gan_loss: 0.8036 (0.8221)  pix_loss: 0.7356 (0.7496)  time: 54.0654  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [520/985]  eta: 6:59:00  lr: 0.000100  g_loss: 8.0843 (8.3169)  d_loss: 1.7932 (1.7853)  gan_loss: 0.8104 (0.8222)  pix_loss: 0.7279 (0.7495)  time: 54.0660  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [530/985]  eta: 6:49:59  lr: 0.000100  g_loss: 8.1159 (8.3161)  d_loss: 1.8068 (1.7857)  gan_loss: 0.8603 (0.8232)  pix_loss: 0.7279 (0.7493)  time: 54.0675  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [540/985]  eta: 6:40:59  lr: 0.000100  g_loss: 8.2812 (8.3144)  d_loss: 1.8076 (1.7861)  gan_loss: 0.8360 (0.8230)  pix_loss: 0.7488 (0.7491)  time: 54.0691  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [550/985]  eta: 6:31:58  lr: 0.000100  g_loss: 8.2812 (8.3117)  d_loss: 1.7987 (1.7863)  gan_loss: 0.8116 (0.8228)  pix_loss: 0.7488 (0.7489)  time: 54.0662  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [560/985]  eta: 6:22:57  lr: 0.000100  g_loss: 7.8935 (8.3021)  d_loss: 1.7958 (1.7865)  gan_loss: 0.8116 (0.8225)  pix_loss: 0.7082 (0.7480)  time: 54.0658  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [570/985]  eta: 6:13:57  lr: 0.000100  g_loss: 7.7675 (8.2933)  d_loss: 1.7970 (1.7867)  gan_loss: 0.8048 (0.8222)  pix_loss: 0.6966 (0.7471)  time: 54.0680  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [580/985]  eta: 6:04:56  lr: 0.000100  g_loss: 7.7077 (8.2818)  d_loss: 1.7977 (1.7869)  gan_loss: 0.8048 (0.8220)  pix_loss: 0.6889 (0.7460)  time: 54.0673  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [590/985]  eta: 5:55:56  lr: 0.000100  g_loss: 7.7125 (8.2750)  d_loss: 1.7982 (1.7871)  gan_loss: 0.8053 (0.8218)  pix_loss: 0.6908 (0.7453)  time: 54.0694  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [600/985]  eta: 5:46:55  lr: 0.000100  g_loss: 7.9885 (8.2690)  d_loss: 1.7984 (1.7873)  gan_loss: 0.8107 (0.8217)  pix_loss: 0.7196 (0.7447)  time: 54.0669  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [610/985]  eta: 5:37:54  lr: 0.000100  g_loss: 8.1075 (8.2689)  d_loss: 1.7897 (1.7872)  gan_loss: 0.8118 (0.8215)  pix_loss: 0.7268 (0.7447)  time: 54.0677  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [620/985]  eta: 5:28:54  lr: 0.000100  g_loss: 8.0713 (8.2659)  d_loss: 1.7896 (1.7873)  gan_loss: 0.8104 (0.8214)  pix_loss: 0.7260 (0.7445)  time: 54.0725  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [630/985]  eta: 5:19:53  lr: 0.000100  g_loss: 8.0676 (8.2657)  d_loss: 1.7944 (1.7874)  gan_loss: 0.8093 (0.8212)  pix_loss: 0.7261 (0.7445)  time: 54.0663  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [640/985]  eta: 5:10:52  lr: 0.000100  g_loss: 8.0237 (8.2588)  d_loss: 1.7930 (1.7875)  gan_loss: 0.8020 (0.8210)  pix_loss: 0.7188 (0.7438)  time: 54.0637  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [650/985]  eta: 5:01:52  lr: 0.000100  g_loss: 7.8608 (8.2533)  d_loss: 1.7948 (1.7876)  gan_loss: 0.8081 (0.8208)  pix_loss: 0.7067 (0.7433)  time: 54.0660  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [660/985]  eta: 4:52:51  lr: 0.000100  g_loss: 7.8761 (8.2507)  d_loss: 1.7948 (1.7876)  gan_loss: 0.8081 (0.8205)  pix_loss: 0.7070 (0.7430)  time: 54.0619  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [670/985]  eta: 4:43:50  lr: 0.000100  g_loss: 7.7449 (8.2432)  d_loss: 1.7962 (1.7878)  gan_loss: 0.8052 (0.8204)  pix_loss: 0.6917 (0.7423)  time: 54.0605  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [680/985]  eta: 4:34:50  lr: 0.000100  g_loss: 7.8650 (8.2405)  d_loss: 1.7962 (1.7878)  gan_loss: 0.8084 (0.8203)  pix_loss: 0.7047 (0.7420)  time: 54.0572  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:11]  [690/985]  eta: 4:25:49  lr: 0.000100  g_loss: 7.8650 (8.2337)  d_loss: 1.7937 (1.7880)  gan_loss: 0.8112 (0.8201)  pix_loss: 0.7047 (0.7414)  time: 54.0530  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [700/985]  eta: 4:16:48  lr: 0.000100  g_loss: 7.6879 (8.2255)  d_loss: 1.7946 (1.7881)  gan_loss: 0.8051 (0.8199)  pix_loss: 0.6897 (0.7406)  time: 54.0547  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [710/985]  eta: 4:07:47  lr: 0.000100  g_loss: 7.7268 (8.2227)  d_loss: 1.7935 (1.7880)  gan_loss: 0.8054 (0.8199)  pix_loss: 0.6912 (0.7403)  time: 54.0568  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [720/985]  eta: 3:58:47  lr: 0.000100  g_loss: 7.9378 (8.2174)  d_loss: 1.7947 (1.7883)  gan_loss: 0.8091 (0.8197)  pix_loss: 0.7148 (0.7398)  time: 54.0598  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [730/985]  eta: 3:49:46  lr: 0.000100  g_loss: 7.8507 (8.2147)  d_loss: 1.8092 (1.7886)  gan_loss: 0.8091 (0.8198)  pix_loss: 0.7019 (0.7395)  time: 54.0627  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [740/985]  eta: 3:40:45  lr: 0.000100  g_loss: 8.2709 (8.2180)  d_loss: 1.7982 (1.7888)  gan_loss: 0.8224 (0.8197)  pix_loss: 0.7441 (0.7398)  time: 54.0633  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [750/985]  eta: 3:31:45  lr: 0.000100  g_loss: 7.9577 (8.2122)  d_loss: 1.7969 (1.7890)  gan_loss: 0.8035 (0.8195)  pix_loss: 0.7156 (0.7393)  time: 54.0595  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [760/985]  eta: 3:22:44  lr: 0.000100  g_loss: 7.8108 (8.2080)  d_loss: 1.8071 (1.7891)  gan_loss: 0.8088 (0.8194)  pix_loss: 0.7002 (0.7389)  time: 54.0593  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [770/985]  eta: 3:13:43  lr: 0.000100  g_loss: 7.7653 (8.2009)  d_loss: 1.7985 (1.7892)  gan_loss: 0.8081 (0.8192)  pix_loss: 0.6957 (0.7382)  time: 54.0595  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [780/985]  eta: 3:04:43  lr: 0.000100  g_loss: 7.6524 (8.1939)  d_loss: 1.7941 (1.7893)  gan_loss: 0.8031 (0.8190)  pix_loss: 0.6853 (0.7375)  time: 54.0579  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [790/985]  eta: 2:55:42  lr: 0.000100  g_loss: 7.6800 (8.1897)  d_loss: 1.7988 (1.7895)  gan_loss: 0.8063 (0.8190)  pix_loss: 0.6876 (0.7371)  time: 54.0620  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [800/985]  eta: 2:46:41  lr: 0.000100  g_loss: 7.8332 (8.1873)  d_loss: 1.7898 (1.7895)  gan_loss: 0.8131 (0.8189)  pix_loss: 0.7015 (0.7368)  time: 54.0628  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [810/985]  eta: 2:37:41  lr: 0.000100  g_loss: 7.7842 (8.1830)  d_loss: 1.7909 (1.7896)  gan_loss: 0.8149 (0.8189)  pix_loss: 0.6969 (0.7364)  time: 54.0649  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [820/985]  eta: 2:28:40  lr: 0.000100  g_loss: 7.7711 (8.1779)  d_loss: 1.8043 (1.7898)  gan_loss: 0.8165 (0.8188)  pix_loss: 0.6955 (0.7359)  time: 54.0818  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [830/985]  eta: 2:19:40  lr: 0.000100  g_loss: 7.7733 (8.1741)  d_loss: 1.8151 (1.7901)  gan_loss: 0.8183 (0.8189)  pix_loss: 0.6960 (0.7355)  time: 54.1691  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [840/985]  eta: 2:10:39  lr: 0.000100  g_loss: 7.6722 (8.1669)  d_loss: 1.8162 (1.7904)  gan_loss: 0.8194 (0.8188)  pix_loss: 0.6879 (0.7348)  time: 54.1564  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [850/985]  eta: 2:01:39  lr: 0.000100  g_loss: 7.6995 (8.1668)  d_loss: 1.8025 (1.7904)  gan_loss: 0.8061 (0.8187)  pix_loss: 0.6883 (0.7348)  time: 54.0659  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [860/985]  eta: 1:52:38  lr: 0.000100  g_loss: 8.0818 (8.1649)  d_loss: 1.7953 (1.7905)  gan_loss: 0.8082 (0.8186)  pix_loss: 0.7273 (0.7346)  time: 54.0636  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [870/985]  eta: 1:43:37  lr: 0.000100  g_loss: 7.8634 (8.1593)  d_loss: 1.7980 (1.7906)  gan_loss: 0.8058 (0.8184)  pix_loss: 0.7057 (0.7341)  time: 54.0678  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [880/985]  eta: 1:34:37  lr: 0.000100  g_loss: 7.6056 (8.1542)  d_loss: 1.7970 (1.7906)  gan_loss: 0.8020 (0.8182)  pix_loss: 0.6788 (0.7336)  time: 54.0732  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [890/985]  eta: 1:25:36  lr: 0.000100  g_loss: 7.7355 (8.1497)  d_loss: 1.7926 (1.7906)  gan_loss: 0.8036 (0.8181)  pix_loss: 0.6947 (0.7332)  time: 54.0681  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [900/985]  eta: 1:16:35  lr: 0.000100  g_loss: 7.6879 (8.1459)  d_loss: 1.7926 (1.7907)  gan_loss: 0.8078 (0.8180)  pix_loss: 0.6875 (0.7328)  time: 54.0649  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [910/985]  eta: 1:07:35  lr: 0.000100  g_loss: 7.6240 (8.1393)  d_loss: 1.8002 (1.7908)  gan_loss: 0.8078 (0.8178)  pix_loss: 0.6828 (0.7322)  time: 54.0667  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [920/985]  eta: 0:58:34  lr: 0.000100  g_loss: 7.6360 (8.1357)  d_loss: 1.8012 (1.7909)  gan_loss: 0.8048 (0.8177)  pix_loss: 0.6818 (0.7318)  time: 54.0718  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [930/985]  eta: 0:49:33  lr: 0.000100  g_loss: 7.8276 (8.1333)  d_loss: 1.7967 (1.7910)  gan_loss: 0.8052 (0.8176)  pix_loss: 0.6993 (0.7316)  time: 54.0725  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [940/985]  eta: 0:40:33  lr: 0.000100  g_loss: 7.8331 (8.1290)  d_loss: 1.7967 (1.7910)  gan_loss: 0.8051 (0.8175)  pix_loss: 0.7040 (0.7311)  time: 54.0666  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [950/985]  eta: 0:31:32  lr: 0.000100  g_loss: 7.8066 (8.1261)  d_loss: 1.7952 (1.7910)  gan_loss: 0.8013 (0.8173)  pix_loss: 0.6991 (0.7309)  time: 54.0649  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [960/985]  eta: 0:22:31  lr: 0.000100  g_loss: 7.7671 (8.1229)  d_loss: 1.7987 (1.7910)  gan_loss: 0.7979 (0.8172)  pix_loss: 0.6951 (0.7306)  time: 54.0727  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [970/985]  eta: 0:13:31  lr: 0.000100  g_loss: 7.4205 (8.1145)  d_loss: 1.8022 (1.7912)  gan_loss: 0.7969 (0.8170)  pix_loss: 0.6628 (0.7297)  time: 54.0795  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:11]  [980/985]  eta: 0:04:30  lr: 0.000100  g_loss: 7.3642 (8.1080)  d_loss: 1.8097 (1.7914)  gan_loss: 0.7934 (0.8168)  pix_loss: 0.6575 (0.7291)  time: 54.0723  data: 0.0003  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 7.3590 (8.1043)  d_loss: 1.8115 (1.7915)  gan_loss: 0.7934 (0.8167)  pix_loss: 0.6568 (0.7288)  time: 54.0683  data: 0.0003  max mem: 38397\n",
      "Train: [epoch:11] Total time: 14:47:36 (54.0680 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 7.3590 (8.1043)  d_loss: 1.8115 (1.7915)  gan_loss: 0.7934 (0.8167)  pix_loss: 0.6568 (0.7288)\n",
      "Valid: [epoch:11]  [ 0/14]  eta: 0:01:42  L1_loss: 0.0216 (0.0216)  time: 7.3072  data: 0.3930  max mem: 38397\n",
      "Valid: [epoch:11]  [13/14]  eta: 0:00:07  L1_loss: 0.0222 (0.0230)  time: 7.2119  data: 0.0282  max mem: 38397\n",
      "Valid: [epoch:11] Total time: 0:01:41 (7.2199 s / it)\n",
      "Averaged stats: L1_loss: 0.0222 (0.0230)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_11_input_n_20.png\n",
      "Train: [epoch:12]  [  0/985]  eta: 15:02:48  lr: 0.000100  g_loss: 7.1258 (7.1258)  d_loss: 1.8041 (1.8041)  gan_loss: 0.8049 (0.8049)  pix_loss: 0.6321 (0.6321)  time: 54.9931  data: 0.9261  max mem: 38397\n",
      "Train: [epoch:12]  [ 10/985]  eta: 14:40:04  lr: 0.000100  g_loss: 7.3139 (7.3762)  d_loss: 1.8083 (1.8058)  gan_loss: 0.7921 (0.7977)  pix_loss: 0.6522 (0.6578)  time: 54.1590  data: 0.0844  max mem: 38397\n",
      "Train: [epoch:12]  [ 20/985]  eta: 14:30:31  lr: 0.000100  g_loss: 7.5424 (7.4654)  d_loss: 1.8078 (1.8042)  gan_loss: 0.7927 (0.7971)  pix_loss: 0.6727 (0.6668)  time: 54.0827  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [ 30/985]  eta: 14:21:13  lr: 0.000100  g_loss: 7.5613 (7.4468)  d_loss: 1.8006 (1.8030)  gan_loss: 0.7963 (0.7972)  pix_loss: 0.6753 (0.6650)  time: 54.0798  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [ 40/985]  eta: 14:12:05  lr: 0.000100  g_loss: 7.6791 (7.6061)  d_loss: 1.7998 (1.8016)  gan_loss: 0.8002 (0.8025)  pix_loss: 0.6880 (0.6804)  time: 54.0755  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [ 50/985]  eta: 14:03:01  lr: 0.000100  g_loss: 7.8685 (7.6224)  d_loss: 1.8106 (1.8059)  gan_loss: 0.8062 (0.8038)  pix_loss: 0.7054 (0.6819)  time: 54.0820  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [ 60/985]  eta: 13:53:55  lr: 0.000100  g_loss: 7.7178 (7.6467)  d_loss: 1.8195 (1.8059)  gan_loss: 0.8159 (0.8059)  pix_loss: 0.6912 (0.6841)  time: 54.0751  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [ 70/985]  eta: 13:44:52  lr: 0.000100  g_loss: 7.4621 (7.6070)  d_loss: 1.8099 (1.8066)  gan_loss: 0.8057 (0.8055)  pix_loss: 0.6652 (0.6801)  time: 54.0711  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [ 80/985]  eta: 13:36:11  lr: 0.000100  g_loss: 7.4615 (7.6064)  d_loss: 1.8099 (1.8071)  gan_loss: 0.7996 (0.8052)  pix_loss: 0.6652 (0.6801)  time: 54.1708  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [ 90/985]  eta: 13:27:07  lr: 0.000100  g_loss: 7.5007 (7.6002)  d_loss: 1.8065 (1.8062)  gan_loss: 0.8133 (0.8061)  pix_loss: 0.6706 (0.6794)  time: 54.1778  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [100/985]  eta: 13:18:05  lr: 0.000100  g_loss: 7.5410 (7.6017)  d_loss: 1.7970 (1.8051)  gan_loss: 0.8050 (0.8056)  pix_loss: 0.6745 (0.6796)  time: 54.0892  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [110/985]  eta: 13:09:02  lr: 0.000100  g_loss: 7.5621 (7.6034)  d_loss: 1.7947 (1.8042)  gan_loss: 0.7967 (0.8054)  pix_loss: 0.6765 (0.6798)  time: 54.0866  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [120/985]  eta: 12:59:59  lr: 0.000100  g_loss: 7.6967 (7.6310)  d_loss: 1.7939 (1.8034)  gan_loss: 0.7989 (0.8051)  pix_loss: 0.6881 (0.6826)  time: 54.0822  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [130/985]  eta: 12:50:57  lr: 0.000100  g_loss: 7.7902 (7.6458)  d_loss: 1.7970 (1.8031)  gan_loss: 0.8017 (0.8063)  pix_loss: 0.6974 (0.6839)  time: 54.0819  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [140/985]  eta: 12:41:54  lr: 0.000100  g_loss: 7.6080 (7.6390)  d_loss: 1.8014 (1.8035)  gan_loss: 0.7949 (0.8053)  pix_loss: 0.6831 (0.6834)  time: 54.0800  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [150/985]  eta: 12:32:52  lr: 0.000100  g_loss: 7.6080 (7.6456)  d_loss: 1.7995 (1.8025)  gan_loss: 0.7981 (0.8055)  pix_loss: 0.6831 (0.6840)  time: 54.0804  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [160/985]  eta: 12:23:51  lr: 0.000100  g_loss: 7.7711 (7.6547)  d_loss: 1.7977 (1.8023)  gan_loss: 0.7993 (0.8049)  pix_loss: 0.6983 (0.6850)  time: 54.0881  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [170/985]  eta: 12:14:49  lr: 0.000100  g_loss: 7.6790 (7.6593)  d_loss: 1.7986 (1.8019)  gan_loss: 0.7981 (0.8048)  pix_loss: 0.6888 (0.6855)  time: 54.0883  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [180/985]  eta: 12:05:48  lr: 0.000100  g_loss: 7.6790 (7.6652)  d_loss: 1.7961 (1.8012)  gan_loss: 0.7970 (0.8046)  pix_loss: 0.6870 (0.6861)  time: 54.0887  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [190/985]  eta: 11:56:47  lr: 0.000100  g_loss: 7.7744 (7.6719)  d_loss: 1.7953 (1.8011)  gan_loss: 0.7970 (0.8046)  pix_loss: 0.6972 (0.6867)  time: 54.0929  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [200/985]  eta: 11:47:45  lr: 0.000100  g_loss: 7.6552 (7.6685)  d_loss: 1.7990 (1.8012)  gan_loss: 0.7964 (0.8041)  pix_loss: 0.6869 (0.6864)  time: 54.0900  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [210/985]  eta: 11:38:45  lr: 0.000100  g_loss: 7.5409 (7.6668)  d_loss: 1.8000 (1.8011)  gan_loss: 0.7980 (0.8042)  pix_loss: 0.6719 (0.6863)  time: 54.0939  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [220/985]  eta: 11:29:50  lr: 0.000100  g_loss: 7.4337 (7.6485)  d_loss: 1.8032 (1.8013)  gan_loss: 0.7958 (0.8037)  pix_loss: 0.6641 (0.6845)  time: 54.1920  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [230/985]  eta: 11:20:48  lr: 0.000100  g_loss: 7.4331 (7.6471)  d_loss: 1.8040 (1.8014)  gan_loss: 0.7920 (0.8032)  pix_loss: 0.6640 (0.6844)  time: 54.1858  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [240/985]  eta: 11:11:48  lr: 0.000100  g_loss: 7.4331 (7.6344)  d_loss: 1.8030 (1.8015)  gan_loss: 0.7920 (0.8029)  pix_loss: 0.6640 (0.6831)  time: 54.1074  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [250/985]  eta: 11:02:47  lr: 0.000100  g_loss: 7.4059 (7.6328)  d_loss: 1.8006 (1.8014)  gan_loss: 0.7905 (0.8026)  pix_loss: 0.6628 (0.6830)  time: 54.1110  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [260/985]  eta: 10:53:45  lr: 0.000100  g_loss: 7.3742 (7.6228)  d_loss: 1.8013 (1.8014)  gan_loss: 0.7883 (0.8026)  pix_loss: 0.6572 (0.6820)  time: 54.0964  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [270/985]  eta: 10:44:44  lr: 0.000100  g_loss: 7.3460 (7.6200)  d_loss: 1.8014 (1.8013)  gan_loss: 0.7970 (0.8024)  pix_loss: 0.6545 (0.6818)  time: 54.0949  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [280/985]  eta: 10:35:43  lr: 0.000100  g_loss: 7.3886 (7.6124)  d_loss: 1.8021 (1.8014)  gan_loss: 0.7942 (0.8021)  pix_loss: 0.6601 (0.6810)  time: 54.0893  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [290/985]  eta: 10:26:41  lr: 0.000100  g_loss: 7.3886 (7.6068)  d_loss: 1.8067 (1.8017)  gan_loss: 0.7918 (0.8020)  pix_loss: 0.6601 (0.6805)  time: 54.0890  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [300/985]  eta: 10:17:40  lr: 0.000100  g_loss: 7.5312 (7.6159)  d_loss: 1.8137 (1.8025)  gan_loss: 0.8092 (0.8025)  pix_loss: 0.6745 (0.6813)  time: 54.0876  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [310/985]  eta: 10:08:38  lr: 0.000100  g_loss: 7.5065 (7.6121)  d_loss: 1.8148 (1.8029)  gan_loss: 0.8048 (0.8024)  pix_loss: 0.6723 (0.6810)  time: 54.0839  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [320/985]  eta: 9:59:37  lr: 0.000100  g_loss: 7.5823 (7.6181)  d_loss: 1.8100 (1.8030)  gan_loss: 0.7987 (0.8022)  pix_loss: 0.6777 (0.6816)  time: 54.0809  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [330/985]  eta: 9:50:35  lr: 0.000100  g_loss: 7.7939 (7.6308)  d_loss: 1.8061 (1.8032)  gan_loss: 0.8032 (0.8023)  pix_loss: 0.7009 (0.6829)  time: 54.0792  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [340/985]  eta: 9:41:34  lr: 0.000100  g_loss: 8.0359 (7.6477)  d_loss: 1.8180 (1.8040)  gan_loss: 0.8317 (0.8045)  pix_loss: 0.7194 (0.6843)  time: 54.0860  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [350/985]  eta: 9:32:33  lr: 0.000100  g_loss: 8.1508 (7.6624)  d_loss: 1.8229 (1.8045)  gan_loss: 0.8667 (0.8057)  pix_loss: 0.7287 (0.6857)  time: 54.0940  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [360/985]  eta: 9:23:32  lr: 0.000100  g_loss: 7.9089 (7.6619)  d_loss: 1.8114 (1.8047)  gan_loss: 0.8143 (0.8055)  pix_loss: 0.7100 (0.6856)  time: 54.0894  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [370/985]  eta: 9:14:31  lr: 0.000100  g_loss: 7.6693 (7.6611)  d_loss: 1.8079 (1.8044)  gan_loss: 0.7987 (0.8055)  pix_loss: 0.6859 (0.6856)  time: 54.0830  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [380/985]  eta: 9:05:29  lr: 0.000100  g_loss: 7.4967 (7.6529)  d_loss: 1.8009 (1.8043)  gan_loss: 0.7964 (0.8053)  pix_loss: 0.6678 (0.6848)  time: 54.0849  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [390/985]  eta: 8:56:27  lr: 0.000100  g_loss: 7.3295 (7.6478)  d_loss: 1.8009 (1.8042)  gan_loss: 0.7951 (0.8052)  pix_loss: 0.6531 (0.6843)  time: 54.0546  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [400/985]  eta: 8:47:27  lr: 0.000100  g_loss: 7.3659 (7.6442)  d_loss: 1.7992 (1.8041)  gan_loss: 0.8006 (0.8052)  pix_loss: 0.6554 (0.6839)  time: 54.0810  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [410/985]  eta: 8:38:26  lr: 0.000100  g_loss: 7.4673 (7.6409)  d_loss: 1.8022 (1.8042)  gan_loss: 0.8016 (0.8052)  pix_loss: 0.6661 (0.6836)  time: 54.1300  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [420/985]  eta: 8:29:25  lr: 0.000100  g_loss: 7.4006 (7.6356)  d_loss: 1.8075 (1.8043)  gan_loss: 0.8061 (0.8053)  pix_loss: 0.6613 (0.6830)  time: 54.1044  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [430/985]  eta: 8:20:24  lr: 0.000100  g_loss: 7.4974 (7.6322)  d_loss: 1.8122 (1.8046)  gan_loss: 0.8029 (0.8051)  pix_loss: 0.6683 (0.6827)  time: 54.0746  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [440/985]  eta: 8:11:22  lr: 0.000100  g_loss: 7.5275 (7.6292)  d_loss: 1.8169 (1.8049)  gan_loss: 0.8015 (0.8050)  pix_loss: 0.6725 (0.6824)  time: 54.0623  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [450/985]  eta: 8:02:21  lr: 0.000100  g_loss: 7.5127 (7.6263)  d_loss: 1.8145 (1.8050)  gan_loss: 0.8003 (0.8048)  pix_loss: 0.6720 (0.6822)  time: 54.0588  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [460/985]  eta: 7:53:19  lr: 0.000100  g_loss: 7.5127 (7.6247)  d_loss: 1.8050 (1.8049)  gan_loss: 0.8003 (0.8049)  pix_loss: 0.6720 (0.6820)  time: 54.0602  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [470/985]  eta: 7:44:18  lr: 0.000100  g_loss: 7.3879 (7.6198)  d_loss: 1.8080 (1.8050)  gan_loss: 0.7983 (0.8047)  pix_loss: 0.6587 (0.6815)  time: 54.0639  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [480/985]  eta: 7:35:17  lr: 0.000100  g_loss: 7.3420 (7.6166)  d_loss: 1.8052 (1.8050)  gan_loss: 0.7918 (0.8044)  pix_loss: 0.6549 (0.6812)  time: 54.0654  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [490/985]  eta: 7:26:16  lr: 0.000100  g_loss: 7.4453 (7.6120)  d_loss: 1.8038 (1.8049)  gan_loss: 0.7896 (0.8042)  pix_loss: 0.6656 (0.6808)  time: 54.0775  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [500/985]  eta: 7:17:15  lr: 0.000100  g_loss: 7.3449 (7.6063)  d_loss: 1.8074 (1.8049)  gan_loss: 0.7895 (0.8040)  pix_loss: 0.6547 (0.6802)  time: 54.0731  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [510/985]  eta: 7:08:13  lr: 0.000100  g_loss: 7.2441 (7.5977)  d_loss: 1.8081 (1.8049)  gan_loss: 0.7964 (0.8040)  pix_loss: 0.6460 (0.6794)  time: 54.0627  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [520/985]  eta: 6:59:12  lr: 0.000100  g_loss: 6.9711 (7.5836)  d_loss: 1.8158 (1.8053)  gan_loss: 0.7948 (0.8037)  pix_loss: 0.6177 (0.6780)  time: 54.0652  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [530/985]  eta: 6:50:11  lr: 0.000100  g_loss: 7.0820 (7.5772)  d_loss: 1.8121 (1.8053)  gan_loss: 0.7921 (0.8036)  pix_loss: 0.6299 (0.6774)  time: 54.0683  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [540/985]  eta: 6:41:10  lr: 0.000100  g_loss: 7.1763 (7.5685)  d_loss: 1.8111 (1.8054)  gan_loss: 0.7876 (0.8033)  pix_loss: 0.6375 (0.6765)  time: 54.0670  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [550/985]  eta: 6:32:09  lr: 0.000100  g_loss: 7.1478 (7.5607)  d_loss: 1.8172 (1.8057)  gan_loss: 0.7928 (0.8031)  pix_loss: 0.6362 (0.6758)  time: 54.0612  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [560/985]  eta: 6:23:08  lr: 0.000100  g_loss: 7.1092 (7.5534)  d_loss: 1.8261 (1.8062)  gan_loss: 0.7978 (0.8032)  pix_loss: 0.6331 (0.6750)  time: 54.0587  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [570/985]  eta: 6:14:08  lr: 0.000100  g_loss: 7.1426 (7.5465)  d_loss: 1.8456 (1.8070)  gan_loss: 0.8257 (0.8039)  pix_loss: 0.6338 (0.6743)  time: 54.1231  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [580/985]  eta: 6:05:06  lr: 0.000100  g_loss: 7.1505 (7.5383)  d_loss: 1.8456 (1.8075)  gan_loss: 0.8257 (0.8038)  pix_loss: 0.6358 (0.6734)  time: 54.1237  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [590/985]  eta: 5:56:06  lr: 0.000100  g_loss: 7.0837 (7.5323)  d_loss: 1.8418 (1.8082)  gan_loss: 0.8141 (0.8043)  pix_loss: 0.6231 (0.6728)  time: 54.0903  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [600/985]  eta: 5:47:05  lr: 0.000100  g_loss: 7.2704 (7.5290)  d_loss: 1.8301 (1.8084)  gan_loss: 0.8079 (0.8041)  pix_loss: 0.6432 (0.6725)  time: 54.0954  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [610/985]  eta: 5:38:04  lr: 0.000100  g_loss: 7.3049 (7.5286)  d_loss: 1.8160 (1.8084)  gan_loss: 0.7920 (0.8041)  pix_loss: 0.6519 (0.6725)  time: 54.0705  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [620/985]  eta: 5:29:03  lr: 0.000100  g_loss: 7.3655 (7.5255)  d_loss: 1.8283 (1.8088)  gan_loss: 0.8016 (0.8041)  pix_loss: 0.6565 (0.6721)  time: 54.0698  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [630/985]  eta: 5:20:02  lr: 0.000100  g_loss: 7.5412 (7.5281)  d_loss: 1.8229 (1.8088)  gan_loss: 0.8075 (0.8041)  pix_loss: 0.6754 (0.6724)  time: 54.0677  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [640/985]  eta: 5:11:00  lr: 0.000100  g_loss: 7.5412 (7.5262)  d_loss: 1.8075 (1.8087)  gan_loss: 0.7950 (0.8039)  pix_loss: 0.6754 (0.6722)  time: 54.0665  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [650/985]  eta: 5:01:59  lr: 0.000100  g_loss: 7.2060 (7.5195)  d_loss: 1.8125 (1.8088)  gan_loss: 0.7872 (0.8036)  pix_loss: 0.6409 (0.6716)  time: 54.0646  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [660/985]  eta: 4:52:59  lr: 0.000100  g_loss: 7.0264 (7.5148)  d_loss: 1.8164 (1.8090)  gan_loss: 0.7917 (0.8034)  pix_loss: 0.6252 (0.6711)  time: 54.0802  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [670/985]  eta: 4:43:58  lr: 0.000100  g_loss: 7.0549 (7.5100)  d_loss: 1.8060 (1.8087)  gan_loss: 0.7928 (0.8034)  pix_loss: 0.6257 (0.6707)  time: 54.1030  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [680/985]  eta: 4:34:57  lr: 0.000100  g_loss: 7.2424 (7.5035)  d_loss: 1.8055 (1.8088)  gan_loss: 0.7923 (0.8031)  pix_loss: 0.6450 (0.6700)  time: 54.0890  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [690/985]  eta: 4:25:56  lr: 0.000100  g_loss: 7.0252 (7.4992)  d_loss: 1.8118 (1.8089)  gan_loss: 0.7869 (0.8030)  pix_loss: 0.6240 (0.6696)  time: 54.0643  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [700/985]  eta: 4:16:55  lr: 0.000100  g_loss: 7.1973 (7.4964)  d_loss: 1.8063 (1.8088)  gan_loss: 0.7876 (0.8028)  pix_loss: 0.6393 (0.6694)  time: 54.0659  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [710/985]  eta: 4:07:54  lr: 0.000100  g_loss: 7.2352 (7.4930)  d_loss: 1.8056 (1.8087)  gan_loss: 0.7908 (0.8026)  pix_loss: 0.6453 (0.6690)  time: 54.0676  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [720/985]  eta: 3:58:53  lr: 0.000100  g_loss: 7.2822 (7.4888)  d_loss: 1.8088 (1.8088)  gan_loss: 0.7896 (0.8025)  pix_loss: 0.6486 (0.6686)  time: 54.1139  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [730/985]  eta: 3:49:52  lr: 0.000100  g_loss: 6.9797 (7.4820)  d_loss: 1.8151 (1.8089)  gan_loss: 0.7896 (0.8023)  pix_loss: 0.6188 (0.6680)  time: 54.1314  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [740/985]  eta: 3:40:52  lr: 0.000100  g_loss: 7.0263 (7.4799)  d_loss: 1.8142 (1.8089)  gan_loss: 0.7879 (0.8021)  pix_loss: 0.6231 (0.6678)  time: 54.1413  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [750/985]  eta: 3:31:52  lr: 0.000100  g_loss: 7.2172 (7.4770)  d_loss: 1.8144 (1.8091)  gan_loss: 0.7991 (0.8023)  pix_loss: 0.6411 (0.6675)  time: 54.2864  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [760/985]  eta: 3:22:51  lr: 0.000100  g_loss: 7.3128 (7.4774)  d_loss: 1.8183 (1.8092)  gan_loss: 0.8183 (0.8024)  pix_loss: 0.6484 (0.6675)  time: 54.2868  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [770/985]  eta: 3:13:50  lr: 0.000100  g_loss: 7.4126 (7.4776)  d_loss: 1.8212 (1.8097)  gan_loss: 0.8145 (0.8027)  pix_loss: 0.6606 (0.6675)  time: 54.1440  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [780/985]  eta: 3:04:49  lr: 0.000100  g_loss: 7.3226 (7.4747)  d_loss: 1.8349 (1.8099)  gan_loss: 0.8063 (0.8026)  pix_loss: 0.6521 (0.6672)  time: 54.0548  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [790/985]  eta: 2:55:48  lr: 0.000100  g_loss: 7.2349 (7.4744)  d_loss: 1.8242 (1.8101)  gan_loss: 0.7937 (0.8026)  pix_loss: 0.6454 (0.6672)  time: 54.0168  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [800/985]  eta: 2:46:47  lr: 0.000100  g_loss: 7.2362 (7.4701)  d_loss: 1.8238 (1.8102)  gan_loss: 0.7960 (0.8025)  pix_loss: 0.6453 (0.6668)  time: 54.0617  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [810/985]  eta: 2:37:46  lr: 0.000100  g_loss: 7.0991 (7.4649)  d_loss: 1.8235 (1.8103)  gan_loss: 0.7979 (0.8024)  pix_loss: 0.6298 (0.6663)  time: 54.1417  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [820/985]  eta: 2:28:45  lr: 0.000100  g_loss: 7.1693 (7.4628)  d_loss: 1.8235 (1.8105)  gan_loss: 0.8027 (0.8025)  pix_loss: 0.6336 (0.6660)  time: 54.1300  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [830/985]  eta: 2:19:44  lr: 0.000100  g_loss: 7.1693 (7.4576)  d_loss: 1.8277 (1.8108)  gan_loss: 0.8080 (0.8025)  pix_loss: 0.6336 (0.6655)  time: 54.1216  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [840/985]  eta: 2:10:43  lr: 0.000100  g_loss: 6.8965 (7.4516)  d_loss: 1.8293 (1.8109)  gan_loss: 0.7919 (0.8024)  pix_loss: 0.6114 (0.6649)  time: 54.1187  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [850/985]  eta: 2:01:42  lr: 0.000100  g_loss: 6.9592 (7.4474)  d_loss: 1.8290 (1.8111)  gan_loss: 0.7888 (0.8022)  pix_loss: 0.6169 (0.6645)  time: 54.0658  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [860/985]  eta: 1:52:41  lr: 0.000100  g_loss: 6.9659 (7.4416)  d_loss: 1.8260 (1.8113)  gan_loss: 0.7876 (0.8020)  pix_loss: 0.6182 (0.6640)  time: 54.0666  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [870/985]  eta: 1:43:40  lr: 0.000100  g_loss: 7.0702 (7.4391)  d_loss: 1.8183 (1.8113)  gan_loss: 0.7850 (0.8019)  pix_loss: 0.6272 (0.6637)  time: 54.0672  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [880/985]  eta: 1:34:39  lr: 0.000100  g_loss: 7.0718 (7.4337)  d_loss: 1.8156 (1.8113)  gan_loss: 0.7861 (0.8018)  pix_loss: 0.6272 (0.6632)  time: 54.0709  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [890/985]  eta: 1:25:38  lr: 0.000100  g_loss: 7.1132 (7.4323)  d_loss: 1.8115 (1.8113)  gan_loss: 0.7881 (0.8016)  pix_loss: 0.6318 (0.6631)  time: 54.0701  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [900/985]  eta: 1:16:37  lr: 0.000100  g_loss: 7.2189 (7.4299)  d_loss: 1.8021 (1.8112)  gan_loss: 0.7881 (0.8016)  pix_loss: 0.6423 (0.6628)  time: 54.0662  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [910/985]  eta: 1:07:37  lr: 0.000100  g_loss: 6.9976 (7.4259)  d_loss: 1.8074 (1.8111)  gan_loss: 0.7863 (0.8014)  pix_loss: 0.6202 (0.6625)  time: 54.0625  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [920/985]  eta: 0:58:36  lr: 0.000100  g_loss: 6.8534 (7.4197)  d_loss: 1.8167 (1.8112)  gan_loss: 0.7801 (0.8012)  pix_loss: 0.6082 (0.6619)  time: 54.0599  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [930/985]  eta: 0:49:35  lr: 0.000100  g_loss: 6.7728 (7.4128)  d_loss: 1.8187 (1.8113)  gan_loss: 0.7846 (0.8010)  pix_loss: 0.5986 (0.6612)  time: 54.0585  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [940/985]  eta: 0:40:34  lr: 0.000100  g_loss: 6.8197 (7.4092)  d_loss: 1.8188 (1.8114)  gan_loss: 0.7762 (0.8008)  pix_loss: 0.6046 (0.6608)  time: 54.0906  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [950/985]  eta: 0:31:33  lr: 0.000100  g_loss: 6.9535 (7.4033)  d_loss: 1.8179 (1.8115)  gan_loss: 0.7786 (0.8006)  pix_loss: 0.6173 (0.6603)  time: 54.2537  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [960/985]  eta: 0:22:32  lr: 0.000100  g_loss: 6.7748 (7.3981)  d_loss: 1.8203 (1.8116)  gan_loss: 0.7805 (0.8004)  pix_loss: 0.5986 (0.6598)  time: 54.2202  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [970/985]  eta: 0:13:31  lr: 0.000100  g_loss: 6.7814 (7.3913)  d_loss: 1.8224 (1.8117)  gan_loss: 0.7853 (0.8002)  pix_loss: 0.5993 (0.6591)  time: 54.1128  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [980/985]  eta: 0:04:30  lr: 0.000100  g_loss: 6.7494 (7.3854)  d_loss: 1.8220 (1.8118)  gan_loss: 0.7841 (0.8000)  pix_loss: 0.5985 (0.6585)  time: 54.1192  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 6.7494 (7.3855)  d_loss: 1.8220 (1.8117)  gan_loss: 0.7828 (0.8000)  pix_loss: 0.5985 (0.6585)  time: 54.1128  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:12] Total time: 14:48:04 (54.0964 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 6.7494 (7.3855)  d_loss: 1.8220 (1.8117)  gan_loss: 0.7828 (0.8000)  pix_loss: 0.5985 (0.6585)\n",
      "Valid: [epoch:12]  [ 0/14]  eta: 0:01:47  L1_loss: 0.0274 (0.0274)  time: 7.6901  data: 0.4055  max mem: 38397\n",
      "Valid: [epoch:12]  [13/14]  eta: 0:00:07  L1_loss: 0.0280 (0.0281)  time: 7.0890  data: 0.0291  max mem: 38397\n",
      "Valid: [epoch:12] Total time: 0:01:39 (7.0980 s / it)\n",
      "Averaged stats: L1_loss: 0.0280 (0.0281)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_12_input_n_20.png\n",
      "Train: [epoch:13]  [  0/985]  eta: 15:13:21  lr: 0.000100  g_loss: 6.8588 (6.8588)  d_loss: 1.8150 (1.8150)  gan_loss: 0.7800 (0.7800)  pix_loss: 0.6079 (0.6079)  time: 55.6363  data: 1.5314  max mem: 38397\n",
      "Train: [epoch:13]  [ 10/985]  eta: 14:40:55  lr: 0.000100  g_loss: 6.9998 (7.0447)  d_loss: 1.8161 (1.8124)  gan_loss: 0.7852 (0.7879)  pix_loss: 0.6211 (0.6257)  time: 54.2108  data: 0.1394  max mem: 38397\n",
      "Train: [epoch:13]  [ 20/985]  eta: 14:32:34  lr: 0.000100  g_loss: 7.0914 (7.1338)  d_loss: 1.8142 (1.8103)  gan_loss: 0.7857 (0.7878)  pix_loss: 0.6295 (0.6346)  time: 54.1845  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [ 30/985]  eta: 14:22:36  lr: 0.000100  g_loss: 7.2631 (7.1974)  d_loss: 1.8068 (1.8098)  gan_loss: 0.7866 (0.7876)  pix_loss: 0.6471 (0.6410)  time: 54.1860  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [ 40/985]  eta: 14:13:19  lr: 0.000100  g_loss: 7.1831 (7.1925)  d_loss: 1.8069 (1.8092)  gan_loss: 0.7868 (0.7880)  pix_loss: 0.6389 (0.6405)  time: 54.1012  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [ 50/985]  eta: 14:03:58  lr: 0.000100  g_loss: 6.9392 (7.1279)  d_loss: 1.8154 (1.8120)  gan_loss: 0.7762 (0.7853)  pix_loss: 0.6162 (0.6343)  time: 54.1040  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [ 60/985]  eta: 13:54:43  lr: 0.000100  g_loss: 7.0412 (7.1550)  d_loss: 1.8185 (1.8105)  gan_loss: 0.7754 (0.7860)  pix_loss: 0.6266 (0.6369)  time: 54.0715  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [ 70/985]  eta: 13:45:30  lr: 0.000100  g_loss: 7.0897 (7.1263)  d_loss: 1.8079 (1.8099)  gan_loss: 0.7833 (0.7863)  pix_loss: 0.6322 (0.6340)  time: 54.0609  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [ 80/985]  eta: 13:36:29  lr: 0.000100  g_loss: 6.9152 (7.1196)  d_loss: 1.8112 (1.8103)  gan_loss: 0.7877 (0.7874)  pix_loss: 0.6132 (0.6332)  time: 54.0966  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [ 90/985]  eta: 13:27:26  lr: 0.000100  g_loss: 7.1838 (7.1418)  d_loss: 1.8169 (1.8109)  gan_loss: 0.7809 (0.7866)  pix_loss: 0.6391 (0.6355)  time: 54.1259  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [100/985]  eta: 13:18:20  lr: 0.000100  g_loss: 7.1188 (7.1338)  d_loss: 1.8096 (1.8102)  gan_loss: 0.7817 (0.7865)  pix_loss: 0.6334 (0.6347)  time: 54.0925  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [110/985]  eta: 13:09:14  lr: 0.000100  g_loss: 6.9654 (7.1166)  d_loss: 1.8071 (1.8104)  gan_loss: 0.7850 (0.7869)  pix_loss: 0.6149 (0.6330)  time: 54.0715  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [120/985]  eta: 13:00:09  lr: 0.000100  g_loss: 6.9654 (7.1134)  d_loss: 1.8209 (1.8122)  gan_loss: 0.7892 (0.7875)  pix_loss: 0.6149 (0.6326)  time: 54.0659  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [130/985]  eta: 12:51:04  lr: 0.000100  g_loss: 7.0042 (7.1043)  d_loss: 1.8319 (1.8132)  gan_loss: 0.7936 (0.7887)  pix_loss: 0.6211 (0.6316)  time: 54.0619  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [140/985]  eta: 12:42:00  lr: 0.000100  g_loss: 6.8917 (7.0892)  d_loss: 1.8369 (1.8143)  gan_loss: 0.8063 (0.7895)  pix_loss: 0.6078 (0.6300)  time: 54.0644  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [150/985]  eta: 12:32:57  lr: 0.000100  g_loss: 6.9017 (7.0731)  d_loss: 1.8173 (1.8141)  gan_loss: 0.8011 (0.7899)  pix_loss: 0.6087 (0.6283)  time: 54.0679  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [160/985]  eta: 12:23:54  lr: 0.000100  g_loss: 6.9026 (7.0673)  d_loss: 1.8145 (1.8142)  gan_loss: 0.7916 (0.7900)  pix_loss: 0.6107 (0.6277)  time: 54.0691  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [170/985]  eta: 12:14:51  lr: 0.000100  g_loss: 6.8930 (7.0533)  d_loss: 1.8232 (1.8151)  gan_loss: 0.7834 (0.7891)  pix_loss: 0.6107 (0.6264)  time: 54.0640  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [180/985]  eta: 12:05:52  lr: 0.000100  g_loss: 6.6665 (7.0238)  d_loss: 1.8308 (1.8161)  gan_loss: 0.7741 (0.7884)  pix_loss: 0.5902 (0.6235)  time: 54.0952  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [190/985]  eta: 11:56:49  lr: 0.000100  g_loss: 6.4357 (6.9907)  d_loss: 1.8354 (1.8170)  gan_loss: 0.7723 (0.7877)  pix_loss: 0.5658 (0.6203)  time: 54.1001  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [200/985]  eta: 11:48:03  lr: 0.000100  g_loss: 6.4513 (6.9755)  d_loss: 1.8225 (1.8170)  gan_loss: 0.7727 (0.7873)  pix_loss: 0.5687 (0.6188)  time: 54.2781  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [210/985]  eta: 11:39:12  lr: 0.000100  g_loss: 6.6895 (6.9655)  d_loss: 1.8187 (1.8166)  gan_loss: 0.7746 (0.7870)  pix_loss: 0.5917 (0.6179)  time: 54.4391  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [220/985]  eta: 11:30:15  lr: 0.000100  g_loss: 6.7107 (6.9624)  d_loss: 1.8141 (1.8163)  gan_loss: 0.7777 (0.7868)  pix_loss: 0.5922 (0.6176)  time: 54.3270  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [230/985]  eta: 11:21:12  lr: 0.000100  g_loss: 6.7984 (6.9589)  d_loss: 1.8078 (1.8161)  gan_loss: 0.7836 (0.7868)  pix_loss: 0.6014 (0.6172)  time: 54.1740  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [240/985]  eta: 11:12:17  lr: 0.000100  g_loss: 6.7984 (6.9515)  d_loss: 1.8154 (1.8162)  gan_loss: 0.7848 (0.7868)  pix_loss: 0.6014 (0.6165)  time: 54.2147  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [250/985]  eta: 11:03:18  lr: 0.000100  g_loss: 6.7049 (6.9485)  d_loss: 1.8213 (1.8164)  gan_loss: 0.7830 (0.7865)  pix_loss: 0.5920 (0.6162)  time: 54.2850  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [260/985]  eta: 10:54:11  lr: 0.000100  g_loss: 6.8004 (6.9470)  d_loss: 1.8160 (1.8163)  gan_loss: 0.7862 (0.7872)  pix_loss: 0.6014 (0.6160)  time: 54.0799  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [270/985]  eta: 10:45:14  lr: 0.000100  g_loss: 7.2357 (6.9644)  d_loss: 1.8054 (1.8156)  gan_loss: 0.8050 (0.7876)  pix_loss: 0.6463 (0.6177)  time: 54.1319  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [280/985]  eta: 10:36:14  lr: 0.000100  g_loss: 7.2899 (6.9650)  d_loss: 1.8108 (1.8157)  gan_loss: 0.7868 (0.7874)  pix_loss: 0.6481 (0.6178)  time: 54.2584  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [290/985]  eta: 10:27:11  lr: 0.000100  g_loss: 6.8853 (6.9641)  d_loss: 1.8175 (1.8159)  gan_loss: 0.7860 (0.7875)  pix_loss: 0.6113 (0.6177)  time: 54.1263  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [300/985]  eta: 10:18:15  lr: 0.000100  g_loss: 7.1221 (6.9811)  d_loss: 1.8157 (1.8156)  gan_loss: 0.7895 (0.7873)  pix_loss: 0.6366 (0.6194)  time: 54.2289  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [310/985]  eta: 10:09:19  lr: 0.000100  g_loss: 7.1746 (6.9796)  d_loss: 1.8139 (1.8157)  gan_loss: 0.7814 (0.7873)  pix_loss: 0.6402 (0.6192)  time: 54.4030  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [320/985]  eta: 10:00:18  lr: 0.000100  g_loss: 7.1025 (6.9919)  d_loss: 1.8051 (1.8151)  gan_loss: 0.7893 (0.7874)  pix_loss: 0.6313 (0.6204)  time: 54.3141  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [330/985]  eta: 9:51:14  lr: 0.000100  g_loss: 7.1984 (6.9939)  d_loss: 1.8017 (1.8147)  gan_loss: 0.7887 (0.7874)  pix_loss: 0.6404 (0.6207)  time: 54.1308  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [340/985]  eta: 9:42:11  lr: 0.000100  g_loss: 7.0008 (6.9939)  d_loss: 1.8057 (1.8146)  gan_loss: 0.7828 (0.7873)  pix_loss: 0.6220 (0.6207)  time: 54.0523  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [350/985]  eta: 9:33:07  lr: 0.000100  g_loss: 6.8738 (6.9881)  d_loss: 1.8142 (1.8148)  gan_loss: 0.7824 (0.7873)  pix_loss: 0.6104 (0.6201)  time: 54.0525  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [360/985]  eta: 9:24:04  lr: 0.000100  g_loss: 6.7528 (6.9905)  d_loss: 1.8170 (1.8146)  gan_loss: 0.7827 (0.7873)  pix_loss: 0.5957 (0.6203)  time: 54.0520  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [370/985]  eta: 9:15:01  lr: 0.000100  g_loss: 6.7027 (6.9797)  d_loss: 1.8170 (1.8147)  gan_loss: 0.7822 (0.7872)  pix_loss: 0.5916 (0.6193)  time: 54.0584  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [380/985]  eta: 9:05:58  lr: 0.000100  g_loss: 6.7065 (6.9817)  d_loss: 1.8190 (1.8148)  gan_loss: 0.7810 (0.7871)  pix_loss: 0.5921 (0.6195)  time: 54.0621  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [390/985]  eta: 8:56:55  lr: 0.000100  g_loss: 6.7788 (6.9787)  d_loss: 1.8190 (1.8148)  gan_loss: 0.7880 (0.7874)  pix_loss: 0.5998 (0.6191)  time: 54.0612  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [400/985]  eta: 8:47:53  lr: 0.000100  g_loss: 6.7412 (6.9735)  d_loss: 1.8174 (1.8150)  gan_loss: 0.8021 (0.7877)  pix_loss: 0.5934 (0.6186)  time: 54.0605  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [410/985]  eta: 8:38:50  lr: 0.000100  g_loss: 6.6768 (6.9662)  d_loss: 1.8220 (1.8151)  gan_loss: 0.7874 (0.7876)  pix_loss: 0.5902 (0.6179)  time: 54.0556  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [420/985]  eta: 8:29:47  lr: 0.000100  g_loss: 6.6768 (6.9637)  d_loss: 1.8164 (1.8149)  gan_loss: 0.7799 (0.7875)  pix_loss: 0.5902 (0.6176)  time: 54.0521  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [430/985]  eta: 8:20:45  lr: 0.000100  g_loss: 6.8809 (6.9689)  d_loss: 1.8114 (1.8148)  gan_loss: 0.7763 (0.7874)  pix_loss: 0.6093 (0.6181)  time: 54.0698  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [440/985]  eta: 8:11:47  lr: 0.000100  g_loss: 7.2539 (6.9750)  d_loss: 1.8101 (1.8146)  gan_loss: 0.7873 (0.7874)  pix_loss: 0.6467 (0.6188)  time: 54.2423  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [450/985]  eta: 8:02:49  lr: 0.000100  g_loss: 7.0116 (6.9721)  d_loss: 1.8120 (1.8145)  gan_loss: 0.7828 (0.7872)  pix_loss: 0.6229 (0.6185)  time: 54.4007  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [460/985]  eta: 7:53:50  lr: 0.000100  g_loss: 6.6471 (6.9618)  d_loss: 1.8181 (1.8146)  gan_loss: 0.7797 (0.7871)  pix_loss: 0.5874 (0.6175)  time: 54.3977  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [470/985]  eta: 7:44:51  lr: 0.000100  g_loss: 6.4860 (6.9548)  d_loss: 1.8243 (1.8149)  gan_loss: 0.7738 (0.7868)  pix_loss: 0.5696 (0.6168)  time: 54.3966  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [480/985]  eta: 7:35:52  lr: 0.000100  g_loss: 6.6375 (6.9521)  d_loss: 1.8241 (1.8150)  gan_loss: 0.7690 (0.7865)  pix_loss: 0.5871 (0.6166)  time: 54.3999  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [490/985]  eta: 7:26:53  lr: 0.000100  g_loss: 6.7431 (6.9448)  d_loss: 1.8282 (1.8155)  gan_loss: 0.7704 (0.7863)  pix_loss: 0.5971 (0.6159)  time: 54.4020  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [500/985]  eta: 7:17:54  lr: 0.000100  g_loss: 6.5953 (6.9375)  d_loss: 1.8356 (1.8158)  gan_loss: 0.7716 (0.7860)  pix_loss: 0.5817 (0.6152)  time: 54.4011  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [510/985]  eta: 7:08:54  lr: 0.000100  g_loss: 6.4710 (6.9258)  d_loss: 1.8291 (1.8159)  gan_loss: 0.7716 (0.7858)  pix_loss: 0.5686 (0.6140)  time: 54.4010  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [520/985]  eta: 6:59:54  lr: 0.000100  g_loss: 6.2802 (6.9121)  d_loss: 1.8353 (1.8165)  gan_loss: 0.7763 (0.7856)  pix_loss: 0.5492 (0.6126)  time: 54.4046  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [530/985]  eta: 6:50:54  lr: 0.000100  g_loss: 6.4213 (6.9069)  d_loss: 1.8312 (1.8165)  gan_loss: 0.7788 (0.7856)  pix_loss: 0.5651 (0.6121)  time: 54.4061  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [540/985]  eta: 6:41:54  lr: 0.000100  g_loss: 6.5350 (6.8997)  d_loss: 1.8251 (1.8167)  gan_loss: 0.7757 (0.7854)  pix_loss: 0.5752 (0.6114)  time: 54.4063  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [550/985]  eta: 6:32:54  lr: 0.000100  g_loss: 6.4047 (6.8888)  d_loss: 1.8324 (1.8171)  gan_loss: 0.7728 (0.7851)  pix_loss: 0.5628 (0.6104)  time: 54.4053  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [560/985]  eta: 6:23:54  lr: 0.000100  g_loss: 6.3476 (6.8786)  d_loss: 1.8398 (1.8175)  gan_loss: 0.7763 (0.7850)  pix_loss: 0.5564 (0.6094)  time: 54.4083  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [570/985]  eta: 6:14:53  lr: 0.000100  g_loss: 6.3142 (6.8679)  d_loss: 1.8388 (1.8178)  gan_loss: 0.7727 (0.7848)  pix_loss: 0.5550 (0.6083)  time: 54.4094  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [580/985]  eta: 6:05:53  lr: 0.000100  g_loss: 6.2889 (6.8586)  d_loss: 1.8357 (1.8181)  gan_loss: 0.7747 (0.7847)  pix_loss: 0.5522 (0.6074)  time: 54.4068  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [590/985]  eta: 5:56:52  lr: 0.000100  g_loss: 6.5700 (6.8585)  d_loss: 1.8305 (1.8182)  gan_loss: 0.7808 (0.7846)  pix_loss: 0.5778 (0.6074)  time: 54.4064  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [600/985]  eta: 5:47:51  lr: 0.000100  g_loss: 6.7549 (6.8569)  d_loss: 1.8214 (1.8183)  gan_loss: 0.7835 (0.7846)  pix_loss: 0.5965 (0.6072)  time: 54.4103  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [610/985]  eta: 5:38:50  lr: 0.000100  g_loss: 6.6852 (6.8534)  d_loss: 1.8259 (1.8184)  gan_loss: 0.7840 (0.7847)  pix_loss: 0.5896 (0.6069)  time: 54.4113  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [620/985]  eta: 5:29:49  lr: 0.000100  g_loss: 6.4951 (6.8483)  d_loss: 1.8265 (1.8186)  gan_loss: 0.7811 (0.7845)  pix_loss: 0.5728 (0.6064)  time: 54.4072  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [630/985]  eta: 5:20:48  lr: 0.000100  g_loss: 6.4474 (6.8420)  d_loss: 1.8340 (1.8190)  gan_loss: 0.7861 (0.7847)  pix_loss: 0.5665 (0.6057)  time: 54.4030  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [640/985]  eta: 5:11:47  lr: 0.000100  g_loss: 6.5025 (6.8400)  d_loss: 1.8340 (1.8191)  gan_loss: 0.7862 (0.7846)  pix_loss: 0.5691 (0.6055)  time: 54.4024  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [650/985]  eta: 5:02:46  lr: 0.000100  g_loss: 6.5946 (6.8375)  d_loss: 1.8276 (1.8192)  gan_loss: 0.7714 (0.7844)  pix_loss: 0.5831 (0.6053)  time: 54.4001  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [660/985]  eta: 4:53:44  lr: 0.000100  g_loss: 6.5837 (6.8342)  d_loss: 1.8285 (1.8194)  gan_loss: 0.7708 (0.7842)  pix_loss: 0.5808 (0.6050)  time: 54.3989  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [670/985]  eta: 4:44:43  lr: 0.000100  g_loss: 6.3382 (6.8281)  d_loss: 1.8316 (1.8194)  gan_loss: 0.7733 (0.7842)  pix_loss: 0.5574 (0.6044)  time: 54.4022  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [680/985]  eta: 4:35:41  lr: 0.000100  g_loss: 6.3357 (6.8245)  d_loss: 1.8285 (1.8195)  gan_loss: 0.7701 (0.7840)  pix_loss: 0.5554 (0.6040)  time: 54.4008  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [690/985]  eta: 4:26:39  lr: 0.000100  g_loss: 6.4187 (6.8196)  d_loss: 1.8277 (1.8197)  gan_loss: 0.7707 (0.7839)  pix_loss: 0.5637 (0.6036)  time: 54.4007  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [700/985]  eta: 4:17:38  lr: 0.000100  g_loss: 6.2707 (6.8115)  d_loss: 1.8364 (1.8199)  gan_loss: 0.7721 (0.7837)  pix_loss: 0.5493 (0.6028)  time: 54.4038  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [710/985]  eta: 4:08:36  lr: 0.000100  g_loss: 6.2707 (6.8048)  d_loss: 1.8355 (1.8201)  gan_loss: 0.7722 (0.7836)  pix_loss: 0.5493 (0.6021)  time: 54.4036  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [720/985]  eta: 3:59:34  lr: 0.000100  g_loss: 6.3773 (6.8005)  d_loss: 1.8411 (1.8206)  gan_loss: 0.7927 (0.7839)  pix_loss: 0.5600 (0.6017)  time: 54.4005  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [730/985]  eta: 3:50:32  lr: 0.000100  g_loss: 6.2107 (6.7923)  d_loss: 1.8560 (1.8211)  gan_loss: 0.8027 (0.7840)  pix_loss: 0.5436 (0.6008)  time: 54.3988  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [740/985]  eta: 3:41:30  lr: 0.000100  g_loss: 6.2031 (6.7853)  d_loss: 1.8558 (1.8216)  gan_loss: 0.7986 (0.7843)  pix_loss: 0.5402 (0.6001)  time: 54.4009  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [750/985]  eta: 3:32:28  lr: 0.000100  g_loss: 6.4101 (6.7813)  d_loss: 1.8478 (1.8219)  gan_loss: 0.7891 (0.7842)  pix_loss: 0.5621 (0.5997)  time: 54.4025  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [760/985]  eta: 3:23:26  lr: 0.000100  g_loss: 6.5298 (6.7788)  d_loss: 1.8457 (1.8223)  gan_loss: 0.7923 (0.7847)  pix_loss: 0.5691 (0.5994)  time: 54.4026  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [770/985]  eta: 3:14:24  lr: 0.000100  g_loss: 6.5768 (6.7784)  d_loss: 1.8579 (1.8229)  gan_loss: 0.8533 (0.7857)  pix_loss: 0.5718 (0.5993)  time: 54.4041  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [780/985]  eta: 3:05:22  lr: 0.000100  g_loss: 6.4794 (6.7729)  d_loss: 1.8688 (1.8235)  gan_loss: 0.8582 (0.7865)  pix_loss: 0.5618 (0.5986)  time: 54.4039  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [790/985]  eta: 2:56:20  lr: 0.000100  g_loss: 6.1597 (6.7662)  d_loss: 1.8688 (1.8241)  gan_loss: 0.8272 (0.7869)  pix_loss: 0.5319 (0.5979)  time: 54.4004  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [800/985]  eta: 2:47:18  lr: 0.000100  g_loss: 6.1867 (6.7596)  d_loss: 1.8552 (1.8245)  gan_loss: 0.8052 (0.7870)  pix_loss: 0.5413 (0.5973)  time: 54.4004  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [810/985]  eta: 2:38:15  lr: 0.000100  g_loss: 6.2564 (6.7577)  d_loss: 1.8552 (1.8250)  gan_loss: 0.8679 (0.7883)  pix_loss: 0.5465 (0.5969)  time: 54.4013  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [820/985]  eta: 2:29:13  lr: 0.000100  g_loss: 6.3794 (6.7545)  d_loss: 1.8782 (1.8256)  gan_loss: 0.8973 (0.7898)  pix_loss: 0.5498 (0.5965)  time: 54.3997  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [830/985]  eta: 2:20:11  lr: 0.000100  g_loss: 6.3794 (6.7483)  d_loss: 1.8837 (1.8263)  gan_loss: 0.9183 (0.7914)  pix_loss: 0.5451 (0.5957)  time: 54.4013  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [840/985]  eta: 2:11:08  lr: 0.000100  g_loss: 6.2649 (6.7422)  d_loss: 1.8858 (1.8269)  gan_loss: 0.9228 (0.7930)  pix_loss: 0.5310 (0.5949)  time: 54.4007  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [850/985]  eta: 2:02:06  lr: 0.000100  g_loss: 6.3598 (6.7403)  d_loss: 1.8793 (1.8275)  gan_loss: 0.9204 (0.7944)  pix_loss: 0.5441 (0.5946)  time: 54.3994  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [860/985]  eta: 1:53:03  lr: 0.000100  g_loss: 6.5219 (6.7382)  d_loss: 1.8817 (1.8281)  gan_loss: 0.9136 (0.7958)  pix_loss: 0.5603 (0.5942)  time: 54.4175  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [870/985]  eta: 1:44:01  lr: 0.000100  g_loss: 6.4082 (6.7324)  d_loss: 1.8800 (1.8286)  gan_loss: 0.9045 (0.7969)  pix_loss: 0.5516 (0.5935)  time: 54.4232  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [880/985]  eta: 1:34:58  lr: 0.000100  g_loss: 6.2970 (6.7269)  d_loss: 1.8747 (1.8292)  gan_loss: 0.8899 (0.7980)  pix_loss: 0.5397 (0.5929)  time: 54.5342  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [890/985]  eta: 1:25:56  lr: 0.000100  g_loss: 6.1736 (6.7214)  d_loss: 1.8795 (1.8297)  gan_loss: 0.8844 (0.7990)  pix_loss: 0.5270 (0.5922)  time: 54.8048  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:13]  [900/985]  eta: 1:16:54  lr: 0.000100  g_loss: 6.2880 (6.7187)  d_loss: 1.8765 (1.8301)  gan_loss: 0.8798 (0.7998)  pix_loss: 0.5424 (0.5919)  time: 54.7506  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:13]  [910/985]  eta: 1:07:51  lr: 0.000100  g_loss: 6.2880 (6.7149)  d_loss: 1.8729 (1.8306)  gan_loss: 0.8656 (0.8005)  pix_loss: 0.5424 (0.5914)  time: 54.4747  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:13]  [920/985]  eta: 0:58:48  lr: 0.000100  g_loss: 6.1394 (6.7081)  d_loss: 1.8676 (1.8310)  gan_loss: 0.8587 (0.8010)  pix_loss: 0.5273 (0.5907)  time: 54.3996  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [930/985]  eta: 0:49:46  lr: 0.000100  g_loss: 6.1256 (6.7057)  d_loss: 1.8642 (1.8312)  gan_loss: 0.8307 (0.8012)  pix_loss: 0.5312 (0.5905)  time: 54.7843  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [940/985]  eta: 0:40:43  lr: 0.000100  g_loss: 6.5741 (6.7062)  d_loss: 1.8368 (1.8312)  gan_loss: 0.7933 (0.8009)  pix_loss: 0.5796 (0.5905)  time: 55.1178  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [950/985]  eta: 0:31:40  lr: 0.000100  g_loss: 6.6289 (6.7035)  d_loss: 1.8303 (1.8311)  gan_loss: 0.7701 (0.8006)  pix_loss: 0.5870 (0.5903)  time: 55.0221  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [960/985]  eta: 0:22:37  lr: 0.000100  g_loss: 6.6728 (6.7007)  d_loss: 1.8222 (1.8310)  gan_loss: 0.7745 (0.8004)  pix_loss: 0.5898 (0.5900)  time: 54.6961  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [970/985]  eta: 0:13:34  lr: 0.000100  g_loss: 6.1854 (6.6957)  d_loss: 1.8322 (1.8311)  gan_loss: 0.7753 (0.8001)  pix_loss: 0.5404 (0.5896)  time: 54.7918  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [980/985]  eta: 0:04:31  lr: 0.000100  g_loss: 6.0588 (6.6883)  d_loss: 1.8387 (1.8312)  gan_loss: 0.7668 (0.7998)  pix_loss: 0.5300 (0.5889)  time: 54.7876  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 6.0343 (6.6843)  d_loss: 1.8385 (1.8313)  gan_loss: 0.7650 (0.7996)  pix_loss: 0.5274 (0.5885)  time: 54.7893  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:13] Total time: 14:51:50 (54.3250 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 6.0343 (6.6843)  d_loss: 1.8385 (1.8313)  gan_loss: 0.7650 (0.7996)  pix_loss: 0.5274 (0.5885)\n",
      "Valid: [epoch:13]  [ 0/14]  eta: 0:01:34  L1_loss: 0.0129 (0.0129)  time: 6.7495  data: 0.4693  max mem: 38397\n",
      "Valid: [epoch:13]  [13/14]  eta: 0:00:06  L1_loss: 0.0129 (0.0134)  time: 6.3346  data: 0.0336  max mem: 38397\n",
      "Valid: [epoch:13] Total time: 0:01:28 (6.3408 s / it)\n",
      "Averaged stats: L1_loss: 0.0129 (0.0134)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_13_input_n_20.png\n",
      "Train: [epoch:14]  [  0/985]  eta: 15:16:32  lr: 0.000100  g_loss: 5.7848 (5.7848)  d_loss: 1.8488 (1.8488)  gan_loss: 0.7925 (0.7925)  pix_loss: 0.4992 (0.4992)  time: 55.8305  data: 1.3857  max mem: 38397\n",
      "Train: [epoch:14]  [ 10/985]  eta: 14:46:13  lr: 0.000100  g_loss: 6.0045 (5.9706)  d_loss: 1.8390 (1.8383)  gan_loss: 0.7710 (0.7770)  pix_loss: 0.5230 (0.5194)  time: 54.5367  data: 0.1261  max mem: 38397\n",
      "Train: [epoch:14]  [ 20/985]  eta: 14:36:02  lr: 0.000100  g_loss: 6.0732 (6.1064)  d_loss: 1.8386 (1.8344)  gan_loss: 0.7698 (0.7778)  pix_loss: 0.5296 (0.5329)  time: 54.4011  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [ 30/985]  eta: 14:26:38  lr: 0.000100  g_loss: 5.8698 (6.0778)  d_loss: 1.8435 (1.8421)  gan_loss: 0.7806 (0.7838)  pix_loss: 0.5028 (0.5294)  time: 54.4007  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [ 40/985]  eta: 14:17:24  lr: 0.000100  g_loss: 5.9307 (6.1374)  d_loss: 1.8549 (1.8462)  gan_loss: 0.8417 (0.8015)  pix_loss: 0.5077 (0.5336)  time: 54.4057  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [ 50/985]  eta: 14:08:13  lr: 0.000100  g_loss: 6.2506 (6.1749)  d_loss: 1.8599 (1.8493)  gan_loss: 0.8461 (0.8089)  pix_loss: 0.5412 (0.5366)  time: 54.4052  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [ 60/985]  eta: 13:59:05  lr: 0.000100  g_loss: 6.1879 (6.2234)  d_loss: 1.8615 (1.8506)  gan_loss: 0.8208 (0.8053)  pix_loss: 0.5387 (0.5418)  time: 54.4051  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:14]  [ 70/985]  eta: 13:49:58  lr: 0.000100  g_loss: 6.1879 (6.2248)  d_loss: 1.8686 (1.8558)  gan_loss: 0.8181 (0.8121)  pix_loss: 0.5387 (0.5413)  time: 54.4050  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [ 80/985]  eta: 13:40:51  lr: 0.000100  g_loss: 6.2424 (6.2348)  d_loss: 1.8860 (1.8587)  gan_loss: 0.8600 (0.8174)  pix_loss: 0.5410 (0.5417)  time: 54.4043  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [ 90/985]  eta: 13:31:45  lr: 0.000100  g_loss: 6.2424 (6.2316)  d_loss: 1.8822 (1.8613)  gan_loss: 0.8529 (0.8209)  pix_loss: 0.5403 (0.5411)  time: 54.4048  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [100/985]  eta: 13:22:40  lr: 0.000100  g_loss: 6.2278 (6.2441)  d_loss: 1.8752 (1.8607)  gan_loss: 0.8389 (0.8212)  pix_loss: 0.5384 (0.5423)  time: 54.4046  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [110/985]  eta: 13:13:34  lr: 0.000100  g_loss: 6.2428 (6.2427)  d_loss: 1.8444 (1.8591)  gan_loss: 0.8027 (0.8178)  pix_loss: 0.5468 (0.5425)  time: 54.4030  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [120/985]  eta: 13:04:29  lr: 0.000100  g_loss: 6.0661 (6.2248)  d_loss: 1.8444 (1.8579)  gan_loss: 0.7831 (0.8153)  pix_loss: 0.5281 (0.5410)  time: 54.4048  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [130/985]  eta: 12:55:24  lr: 0.000100  g_loss: 5.9864 (6.2309)  d_loss: 1.8499 (1.8574)  gan_loss: 0.7922 (0.8139)  pix_loss: 0.5189 (0.5417)  time: 54.4015  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [140/985]  eta: 12:46:19  lr: 0.000100  g_loss: 6.3372 (6.2407)  d_loss: 1.8399 (1.8558)  gan_loss: 0.7901 (0.8113)  pix_loss: 0.5577 (0.5429)  time: 54.3995  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [150/985]  eta: 12:37:14  lr: 0.000100  g_loss: 6.1965 (6.2324)  d_loss: 1.8447 (1.8565)  gan_loss: 0.7952 (0.8129)  pix_loss: 0.5433 (0.5420)  time: 54.3977  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:14]  [160/985]  eta: 12:28:09  lr: 0.000100  g_loss: 6.1965 (6.2360)  d_loss: 1.8690 (1.8568)  gan_loss: 0.8317 (0.8140)  pix_loss: 0.5343 (0.5422)  time: 54.3958  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:14]  [170/985]  eta: 12:19:02  lr: 0.000100  g_loss: 6.1218 (6.2317)  d_loss: 1.8508 (1.8564)  gan_loss: 0.8167 (0.8125)  pix_loss: 0.5321 (0.5419)  time: 54.3706  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [180/985]  eta: 12:09:42  lr: 0.000100  g_loss: 6.0925 (6.2226)  d_loss: 1.8678 (1.8579)  gan_loss: 0.8147 (0.8132)  pix_loss: 0.5298 (0.5409)  time: 54.2005  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [190/985]  eta: 12:00:24  lr: 0.000100  g_loss: 6.1060 (6.2199)  d_loss: 1.8764 (1.8587)  gan_loss: 0.8245 (0.8135)  pix_loss: 0.5304 (0.5406)  time: 54.0588  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [200/985]  eta: 11:51:08  lr: 0.000100  g_loss: 6.1060 (6.2136)  d_loss: 1.8594 (1.8584)  gan_loss: 0.7949 (0.8116)  pix_loss: 0.5304 (0.5402)  time: 54.0589  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [210/985]  eta: 11:41:54  lr: 0.000100  g_loss: 5.8604 (6.2011)  d_loss: 1.8574 (1.8589)  gan_loss: 0.7922 (0.8112)  pix_loss: 0.5065 (0.5390)  time: 54.0614  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [220/985]  eta: 11:32:41  lr: 0.000100  g_loss: 5.9728 (6.1905)  d_loss: 1.8636 (1.8590)  gan_loss: 0.7886 (0.8097)  pix_loss: 0.5184 (0.5381)  time: 54.0625  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [230/985]  eta: 11:23:29  lr: 0.000100  g_loss: 6.0270 (6.1880)  d_loss: 1.8518 (1.8581)  gan_loss: 0.7716 (0.8081)  pix_loss: 0.5239 (0.5380)  time: 54.0588  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [240/985]  eta: 11:14:18  lr: 0.000100  g_loss: 5.8772 (6.1757)  d_loss: 1.8339 (1.8569)  gan_loss: 0.7726 (0.8069)  pix_loss: 0.5090 (0.5369)  time: 54.0584  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [250/985]  eta: 11:05:08  lr: 0.000100  g_loss: 5.8485 (6.1703)  d_loss: 1.8392 (1.8563)  gan_loss: 0.7705 (0.8055)  pix_loss: 0.5070 (0.5365)  time: 54.0597  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [260/985]  eta: 10:55:58  lr: 0.000100  g_loss: 5.8757 (6.1610)  d_loss: 1.8440 (1.8558)  gan_loss: 0.7750 (0.8045)  pix_loss: 0.5096 (0.5357)  time: 54.0600  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [270/985]  eta: 10:46:49  lr: 0.000100  g_loss: 5.8846 (6.1513)  d_loss: 1.8449 (1.8555)  gan_loss: 0.7791 (0.8035)  pix_loss: 0.5106 (0.5348)  time: 54.0586  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [280/985]  eta: 10:37:41  lr: 0.000100  g_loss: 5.9198 (6.1469)  d_loss: 1.8470 (1.8549)  gan_loss: 0.7790 (0.8027)  pix_loss: 0.5142 (0.5344)  time: 54.0610  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [290/985]  eta: 10:28:33  lr: 0.000100  g_loss: 6.1825 (6.1514)  d_loss: 1.8369 (1.8539)  gan_loss: 0.7802 (0.8021)  pix_loss: 0.5399 (0.5349)  time: 54.0629  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [300/985]  eta: 10:19:26  lr: 0.000100  g_loss: 6.5702 (6.1772)  d_loss: 1.8203 (1.8527)  gan_loss: 0.7757 (0.8010)  pix_loss: 0.5779 (0.5376)  time: 54.0603  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:14]  [310/985]  eta: 10:10:19  lr: 0.000100  g_loss: 6.8872 (6.2062)  d_loss: 1.8188 (1.8513)  gan_loss: 0.7757 (0.8004)  pix_loss: 0.6099 (0.5406)  time: 54.0600  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:14]  [320/985]  eta: 10:01:13  lr: 0.000100  g_loss: 6.7876 (6.2219)  d_loss: 1.8138 (1.8502)  gan_loss: 0.7787 (0.7998)  pix_loss: 0.5982 (0.5422)  time: 54.0607  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [330/985]  eta: 9:52:06  lr: 0.000100  g_loss: 6.4974 (6.2313)  d_loss: 1.8237 (1.8497)  gan_loss: 0.7825 (0.7994)  pix_loss: 0.5735 (0.5432)  time: 54.0628  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [340/985]  eta: 9:43:01  lr: 0.000100  g_loss: 6.3615 (6.2319)  d_loss: 1.8375 (1.8496)  gan_loss: 0.7836 (0.7989)  pix_loss: 0.5574 (0.5433)  time: 54.0643  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [350/985]  eta: 9:33:55  lr: 0.000100  g_loss: 5.9688 (6.2215)  d_loss: 1.8653 (1.8507)  gan_loss: 0.8220 (0.8004)  pix_loss: 0.5219 (0.5421)  time: 54.0638  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [360/985]  eta: 9:24:50  lr: 0.000100  g_loss: 5.9412 (6.2216)  d_loss: 1.8849 (1.8514)  gan_loss: 0.8595 (0.8021)  pix_loss: 0.5082 (0.5419)  time: 54.0597  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [370/985]  eta: 9:15:45  lr: 0.000100  g_loss: 5.9832 (6.2145)  d_loss: 1.8777 (1.8519)  gan_loss: 0.8520 (0.8033)  pix_loss: 0.5131 (0.5411)  time: 54.0606  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [380/985]  eta: 9:06:40  lr: 0.000100  g_loss: 6.0239 (6.2120)  d_loss: 1.8646 (1.8521)  gan_loss: 0.8369 (0.8038)  pix_loss: 0.5169 (0.5408)  time: 54.0637  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [390/985]  eta: 8:57:36  lr: 0.000100  g_loss: 6.2003 (6.2199)  d_loss: 1.8497 (1.8515)  gan_loss: 0.8073 (0.8036)  pix_loss: 0.5390 (0.5416)  time: 54.0620  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [400/985]  eta: 8:48:32  lr: 0.000100  g_loss: 6.2465 (6.2147)  d_loss: 1.8347 (1.8514)  gan_loss: 0.7862 (0.8028)  pix_loss: 0.5476 (0.5412)  time: 54.0614  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:14]  [410/985]  eta: 8:39:27  lr: 0.000100  g_loss: 5.8529 (6.2043)  d_loss: 1.8629 (1.8519)  gan_loss: 0.7853 (0.8026)  pix_loss: 0.5057 (0.5402)  time: 54.0606  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:14]  [420/985]  eta: 8:30:23  lr: 0.000100  g_loss: 5.7981 (6.1975)  d_loss: 1.8616 (1.8518)  gan_loss: 0.7814 (0.8019)  pix_loss: 0.5006 (0.5396)  time: 54.0603  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [430/985]  eta: 8:21:20  lr: 0.000100  g_loss: 6.1128 (6.1985)  d_loss: 1.8409 (1.8514)  gan_loss: 0.7672 (0.8011)  pix_loss: 0.5343 (0.5397)  time: 54.0639  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [440/985]  eta: 8:12:16  lr: 0.000100  g_loss: 6.3101 (6.2053)  d_loss: 1.8266 (1.8505)  gan_loss: 0.7688 (0.8005)  pix_loss: 0.5546 (0.5405)  time: 54.0637  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [450/985]  eta: 8:03:12  lr: 0.000100  g_loss: 6.5100 (6.2092)  d_loss: 1.8176 (1.8498)  gan_loss: 0.7739 (0.8000)  pix_loss: 0.5726 (0.5409)  time: 54.0605  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [460/985]  eta: 7:54:09  lr: 0.000100  g_loss: 6.5498 (6.2263)  d_loss: 1.8176 (1.8488)  gan_loss: 0.7776 (0.7997)  pix_loss: 0.5773 (0.5427)  time: 54.0609  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [470/985]  eta: 7:45:06  lr: 0.000100  g_loss: 7.3089 (6.2520)  d_loss: 1.8151 (1.8480)  gan_loss: 0.7899 (0.7995)  pix_loss: 0.6495 (0.5453)  time: 54.0595  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [480/985]  eta: 7:36:02  lr: 0.000100  g_loss: 7.0622 (6.2651)  d_loss: 1.8195 (1.8475)  gan_loss: 0.7886 (0.7994)  pix_loss: 0.6301 (0.5466)  time: 54.0596  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [490/985]  eta: 7:26:59  lr: 0.000100  g_loss: 6.3822 (6.2598)  d_loss: 1.8343 (1.8474)  gan_loss: 0.7833 (0.7990)  pix_loss: 0.5622 (0.5461)  time: 54.0625  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [500/985]  eta: 7:17:56  lr: 0.000100  g_loss: 5.9323 (6.2548)  d_loss: 1.8452 (1.8474)  gan_loss: 0.7778 (0.7986)  pix_loss: 0.5134 (0.5456)  time: 54.0590  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [510/985]  eta: 7:08:53  lr: 0.000100  g_loss: 5.9740 (6.2512)  d_loss: 1.8444 (1.8472)  gan_loss: 0.7825 (0.7983)  pix_loss: 0.5203 (0.5453)  time: 54.0576  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [520/985]  eta: 6:59:51  lr: 0.000100  g_loss: 5.8087 (6.2408)  d_loss: 1.8444 (1.8473)  gan_loss: 0.7706 (0.7978)  pix_loss: 0.5013 (0.5443)  time: 54.0620  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [530/985]  eta: 6:50:48  lr: 0.000100  g_loss: 5.7124 (6.2337)  d_loss: 1.8635 (1.8477)  gan_loss: 0.7918 (0.7981)  pix_loss: 0.4924 (0.5436)  time: 54.0591  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [540/985]  eta: 6:41:45  lr: 0.000100  g_loss: 5.6526 (6.2235)  d_loss: 1.8673 (1.8481)  gan_loss: 0.8133 (0.7983)  pix_loss: 0.4850 (0.5425)  time: 54.0593  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [550/985]  eta: 6:32:43  lr: 0.000100  g_loss: 5.8035 (6.2214)  d_loss: 1.8476 (1.8479)  gan_loss: 0.7841 (0.7978)  pix_loss: 0.5019 (0.5424)  time: 54.0598  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [560/985]  eta: 6:23:40  lr: 0.000100  g_loss: 5.9431 (6.2140)  d_loss: 1.8433 (1.8479)  gan_loss: 0.7694 (0.7975)  pix_loss: 0.5171 (0.5416)  time: 54.0566  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [570/985]  eta: 6:14:38  lr: 0.000100  g_loss: 5.6579 (6.2011)  d_loss: 1.8672 (1.8484)  gan_loss: 0.8034 (0.7978)  pix_loss: 0.4887 (0.5403)  time: 54.0586  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [580/985]  eta: 6:05:35  lr: 0.000100  g_loss: 5.4144 (6.1897)  d_loss: 1.8780 (1.8488)  gan_loss: 0.7989 (0.7974)  pix_loss: 0.4629 (0.5392)  time: 54.0602  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [590/985]  eta: 5:56:33  lr: 0.000100  g_loss: 5.5512 (6.1853)  d_loss: 1.8802 (1.8493)  gan_loss: 0.7970 (0.7988)  pix_loss: 0.4774 (0.5387)  time: 54.0568  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [600/985]  eta: 5:47:31  lr: 0.000100  g_loss: 5.8707 (6.1809)  d_loss: 1.8840 (1.8500)  gan_loss: 0.9000 (0.8010)  pix_loss: 0.4973 (0.5380)  time: 54.0566  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [610/985]  eta: 5:38:29  lr: 0.000100  g_loss: 5.9094 (6.1815)  d_loss: 1.8840 (1.8505)  gan_loss: 0.9529 (0.8037)  pix_loss: 0.5009 (0.5378)  time: 54.0626  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [620/985]  eta: 5:29:26  lr: 0.000100  g_loss: 6.0993 (6.1822)  d_loss: 1.8776 (1.8509)  gan_loss: 0.9574 (0.8061)  pix_loss: 0.5150 (0.5376)  time: 54.0624  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [630/985]  eta: 5:20:24  lr: 0.000100  g_loss: 6.0993 (6.1815)  d_loss: 1.8729 (1.8512)  gan_loss: 0.9444 (0.8084)  pix_loss: 0.5157 (0.5373)  time: 54.0596  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [640/985]  eta: 5:11:22  lr: 0.000100  g_loss: 6.2236 (6.1803)  d_loss: 1.8716 (1.8516)  gan_loss: 0.9399 (0.8104)  pix_loss: 0.5245 (0.5370)  time: 54.0583  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [650/985]  eta: 5:02:20  lr: 0.000100  g_loss: 6.0734 (6.1777)  d_loss: 1.8792 (1.8520)  gan_loss: 0.9378 (0.8124)  pix_loss: 0.5136 (0.5365)  time: 54.0535  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [660/985]  eta: 4:53:18  lr: 0.000100  g_loss: 6.1420 (6.1817)  d_loss: 1.8792 (1.8523)  gan_loss: 0.9271 (0.8140)  pix_loss: 0.5213 (0.5368)  time: 54.0577  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:14]  [670/985]  eta: 4:44:16  lr: 0.000100  g_loss: 6.2139 (6.1780)  d_loss: 1.8833 (1.8527)  gan_loss: 0.9160 (0.8154)  pix_loss: 0.5274 (0.5363)  time: 54.0646  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [680/985]  eta: 4:35:14  lr: 0.000100  g_loss: 5.9807 (6.1761)  d_loss: 1.8881 (1.8531)  gan_loss: 0.8899 (0.8165)  pix_loss: 0.5096 (0.5360)  time: 54.0600  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [690/985]  eta: 4:26:13  lr: 0.000100  g_loss: 6.0349 (6.1767)  d_loss: 1.8773 (1.8531)  gan_loss: 0.8805 (0.8174)  pix_loss: 0.5150 (0.5359)  time: 54.0587  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [700/985]  eta: 4:17:11  lr: 0.000100  g_loss: 6.0373 (6.1734)  d_loss: 1.8704 (1.8534)  gan_loss: 0.8656 (0.8180)  pix_loss: 0.5156 (0.5355)  time: 54.0588  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [710/985]  eta: 4:08:09  lr: 0.000100  g_loss: 5.8862 (6.1671)  d_loss: 1.8719 (1.8537)  gan_loss: 0.8494 (0.8183)  pix_loss: 0.5037 (0.5349)  time: 54.0586  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [720/985]  eta: 3:59:07  lr: 0.000100  g_loss: 5.8609 (6.1640)  d_loss: 1.8719 (1.8539)  gan_loss: 0.8380 (0.8186)  pix_loss: 0.5017 (0.5345)  time: 54.0624  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [730/985]  eta: 3:50:06  lr: 0.000100  g_loss: 5.8562 (6.1597)  d_loss: 1.8699 (1.8540)  gan_loss: 0.8295 (0.8185)  pix_loss: 0.5015 (0.5341)  time: 54.0601  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [740/985]  eta: 3:41:04  lr: 0.000100  g_loss: 5.7965 (6.1561)  d_loss: 1.8637 (1.8540)  gan_loss: 0.7999 (0.8181)  pix_loss: 0.4978 (0.5338)  time: 54.0552  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [750/985]  eta: 3:32:02  lr: 0.000100  g_loss: 5.7530 (6.1520)  d_loss: 1.8524 (1.8540)  gan_loss: 0.7817 (0.8175)  pix_loss: 0.4973 (0.5334)  time: 54.0552  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [760/985]  eta: 3:23:01  lr: 0.000100  g_loss: 5.6836 (6.1432)  d_loss: 1.8541 (1.8541)  gan_loss: 0.7745 (0.8170)  pix_loss: 0.4907 (0.5326)  time: 54.0617  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [770/985]  eta: 3:13:59  lr: 0.000100  g_loss: 5.5758 (6.1383)  d_loss: 1.8630 (1.8542)  gan_loss: 0.7603 (0.8162)  pix_loss: 0.4819 (0.5322)  time: 54.0671  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [780/985]  eta: 3:04:57  lr: 0.000100  g_loss: 5.7706 (6.1320)  d_loss: 1.8564 (1.8540)  gan_loss: 0.7598 (0.8156)  pix_loss: 0.4987 (0.5316)  time: 54.0626  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [790/985]  eta: 2:55:56  lr: 0.000100  g_loss: 5.6876 (6.1247)  d_loss: 1.8486 (1.8540)  gan_loss: 0.7653 (0.8150)  pix_loss: 0.4913 (0.5310)  time: 54.0603  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [800/985]  eta: 2:46:54  lr: 0.000100  g_loss: 5.3423 (6.1140)  d_loss: 1.8601 (1.8542)  gan_loss: 0.7710 (0.8146)  pix_loss: 0.4556 (0.5299)  time: 54.0613  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [810/985]  eta: 2:37:53  lr: 0.000100  g_loss: 5.2075 (6.1046)  d_loss: 1.8872 (1.8546)  gan_loss: 0.8433 (0.8155)  pix_loss: 0.4411 (0.5289)  time: 54.0634  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [820/985]  eta: 2:28:51  lr: 0.000100  g_loss: 5.2855 (6.0978)  d_loss: 1.8926 (1.8551)  gan_loss: 0.9009 (0.8168)  pix_loss: 0.4352 (0.5281)  time: 54.0675  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [830/985]  eta: 2:19:50  lr: 0.000100  g_loss: 5.2855 (6.0894)  d_loss: 1.8922 (1.8555)  gan_loss: 0.9297 (0.8182)  pix_loss: 0.4352 (0.5271)  time: 54.0625  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [840/985]  eta: 2:10:49  lr: 0.000100  g_loss: 5.6967 (6.0877)  d_loss: 1.8841 (1.8557)  gan_loss: 0.9212 (0.8195)  pix_loss: 0.4784 (0.5268)  time: 54.0604  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [850/985]  eta: 2:01:47  lr: 0.000100  g_loss: 5.9328 (6.0862)  d_loss: 1.8808 (1.8560)  gan_loss: 0.9140 (0.8206)  pix_loss: 0.5019 (0.5266)  time: 54.0661  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [860/985]  eta: 1:52:46  lr: 0.000100  g_loss: 5.9214 (6.0830)  d_loss: 1.8801 (1.8562)  gan_loss: 0.9048 (0.8215)  pix_loss: 0.5005 (0.5262)  time: 54.0694  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [870/985]  eta: 1:43:44  lr: 0.000100  g_loss: 5.6714 (6.0774)  d_loss: 1.8796 (1.8565)  gan_loss: 0.8868 (0.8223)  pix_loss: 0.4785 (0.5255)  time: 54.0711  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [880/985]  eta: 1:34:43  lr: 0.000100  g_loss: 5.6690 (6.0757)  d_loss: 1.8770 (1.8567)  gan_loss: 0.8841 (0.8229)  pix_loss: 0.4772 (0.5253)  time: 54.0662  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [890/985]  eta: 1:25:42  lr: 0.000100  g_loss: 5.8538 (6.0737)  d_loss: 1.8770 (1.8569)  gan_loss: 0.8676 (0.8234)  pix_loss: 0.4972 (0.5250)  time: 54.0597  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [900/985]  eta: 1:16:40  lr: 0.000100  g_loss: 5.4310 (6.0659)  d_loss: 1.8809 (1.8572)  gan_loss: 0.8540 (0.8237)  pix_loss: 0.4584 (0.5242)  time: 54.0575  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [910/985]  eta: 1:07:39  lr: 0.000100  g_loss: 5.3181 (6.0582)  d_loss: 1.8788 (1.8574)  gan_loss: 0.8442 (0.8238)  pix_loss: 0.4472 (0.5234)  time: 54.0534  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [920/985]  eta: 0:58:38  lr: 0.000100  g_loss: 5.2476 (6.0508)  d_loss: 1.8788 (1.8577)  gan_loss: 0.8272 (0.8236)  pix_loss: 0.4446 (0.5227)  time: 54.0514  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [930/985]  eta: 0:49:36  lr: 0.000100  g_loss: 5.1989 (6.0453)  d_loss: 1.8763 (1.8578)  gan_loss: 0.7901 (0.8231)  pix_loss: 0.4390 (0.5222)  time: 54.0518  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [940/985]  eta: 0:40:35  lr: 0.000100  g_loss: 5.5178 (6.0402)  d_loss: 1.8644 (1.8578)  gan_loss: 0.7715 (0.8225)  pix_loss: 0.4740 (0.5218)  time: 54.0524  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [950/985]  eta: 0:31:34  lr: 0.000100  g_loss: 5.5544 (6.0342)  d_loss: 1.8550 (1.8578)  gan_loss: 0.7652 (0.8219)  pix_loss: 0.4773 (0.5212)  time: 54.0571  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [960/985]  eta: 0:22:33  lr: 0.000100  g_loss: 5.4861 (6.0290)  d_loss: 1.8574 (1.8578)  gan_loss: 0.7655 (0.8214)  pix_loss: 0.4709 (0.5208)  time: 54.0589  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [970/985]  eta: 0:13:31  lr: 0.000100  g_loss: 5.4193 (6.0227)  d_loss: 1.8574 (1.8578)  gan_loss: 0.7677 (0.8208)  pix_loss: 0.4666 (0.5202)  time: 54.0606  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [980/985]  eta: 0:04:30  lr: 0.000100  g_loss: 5.3033 (6.0153)  d_loss: 1.8602 (1.8578)  gan_loss: 0.7645 (0.8202)  pix_loss: 0.4542 (0.5195)  time: 54.0620  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 5.2768 (6.0124)  d_loss: 1.8605 (1.8578)  gan_loss: 0.7684 (0.8200)  pix_loss: 0.4510 (0.5192)  time: 54.0622  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:14] Total time: 14:48:29 (54.1209 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 5.2768 (6.0124)  d_loss: 1.8605 (1.8578)  gan_loss: 0.7684 (0.8200)  pix_loss: 0.4510 (0.5192)\n",
      "Valid: [epoch:14]  [ 0/14]  eta: 0:01:33  L1_loss: 0.0116 (0.0116)  time: 6.6869  data: 0.3848  max mem: 38397\n",
      "Valid: [epoch:14]  [13/14]  eta: 0:00:06  L1_loss: 0.0121 (0.0126)  time: 6.3802  data: 0.0276  max mem: 38397\n",
      "Valid: [epoch:14] Total time: 0:01:29 (6.3890 s / it)\n",
      "Averaged stats: L1_loss: 0.0121 (0.0126)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_14_input_n_20.png\n",
      "Train: [epoch:15]  [  0/985]  eta: 15:11:00  lr: 0.000100  g_loss: 4.8835 (4.8835)  d_loss: 1.8887 (1.8887)  gan_loss: 0.7758 (0.7758)  pix_loss: 0.4108 (0.4108)  time: 55.4933  data: 1.3876  max mem: 38397\n",
      "Train: [epoch:15]  [ 10/985]  eta: 14:40:40  lr: 0.000100  g_loss: 5.4116 (5.4776)  d_loss: 1.8579 (1.8564)  gan_loss: 0.7763 (0.7733)  pix_loss: 0.4642 (0.4704)  time: 54.1959  data: 0.1263  max mem: 38397\n",
      "Train: [epoch:15]  [ 20/985]  eta: 14:30:39  lr: 0.000100  g_loss: 5.3915 (5.4036)  d_loss: 1.8530 (1.8589)  gan_loss: 0.7763 (0.7723)  pix_loss: 0.4609 (0.4631)  time: 54.0664  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [ 30/985]  eta: 14:21:16  lr: 0.000100  g_loss: 5.3915 (5.4365)  d_loss: 1.8588 (1.8623)  gan_loss: 0.7861 (0.7827)  pix_loss: 0.4609 (0.4654)  time: 54.0643  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [ 40/985]  eta: 14:12:04  lr: 0.000100  g_loss: 5.5966 (5.5005)  d_loss: 1.8636 (1.8622)  gan_loss: 0.7966 (0.7838)  pix_loss: 0.4800 (0.4717)  time: 54.0645  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [ 50/985]  eta: 14:02:56  lr: 0.000100  g_loss: 5.5966 (5.5053)  d_loss: 1.8613 (1.8622)  gan_loss: 0.7848 (0.7826)  pix_loss: 0.4806 (0.4723)  time: 54.0651  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [ 60/985]  eta: 13:53:51  lr: 0.000100  g_loss: 6.0139 (5.6387)  d_loss: 1.8424 (1.8564)  gan_loss: 0.7826 (0.7838)  pix_loss: 0.5206 (0.4855)  time: 54.0630  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [ 70/985]  eta: 13:44:47  lr: 0.000100  g_loss: 6.0367 (5.6656)  d_loss: 1.8474 (1.8582)  gan_loss: 0.8185 (0.7900)  pix_loss: 0.5206 (0.4876)  time: 54.0637  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [ 80/985]  eta: 13:35:44  lr: 0.000100  g_loss: 5.7877 (5.6723)  d_loss: 1.8654 (1.8589)  gan_loss: 0.8172 (0.7916)  pix_loss: 0.4977 (0.4881)  time: 54.0651  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [ 90/985]  eta: 13:26:42  lr: 0.000100  g_loss: 5.6491 (5.6839)  d_loss: 1.8662 (1.8599)  gan_loss: 0.8074 (0.7970)  pix_loss: 0.4873 (0.4887)  time: 54.0665  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [100/985]  eta: 13:17:39  lr: 0.000100  g_loss: 5.8954 (5.7258)  d_loss: 1.8828 (1.8629)  gan_loss: 0.9664 (0.8195)  pix_loss: 0.5016 (0.4906)  time: 54.0605  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [110/985]  eta: 13:08:36  lr: 0.000100  g_loss: 6.0582 (5.7584)  d_loss: 1.8893 (1.8651)  gan_loss: 1.0088 (0.8362)  pix_loss: 0.5043 (0.4922)  time: 54.0524  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [120/985]  eta: 12:59:34  lr: 0.000100  g_loss: 6.0318 (5.7825)  d_loss: 1.8886 (1.8672)  gan_loss: 1.0067 (0.8508)  pix_loss: 0.4983 (0.4932)  time: 54.0561  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [130/985]  eta: 12:50:32  lr: 0.000100  g_loss: 5.9778 (5.7985)  d_loss: 1.8829 (1.8681)  gan_loss: 1.0100 (0.8626)  pix_loss: 0.4972 (0.4936)  time: 54.0580  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [140/985]  eta: 12:41:30  lr: 0.000100  g_loss: 5.9771 (5.8196)  d_loss: 1.8801 (1.8687)  gan_loss: 1.0100 (0.8731)  pix_loss: 0.4975 (0.4946)  time: 54.0568  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [150/985]  eta: 12:32:29  lr: 0.000100  g_loss: 5.6873 (5.8062)  d_loss: 1.8844 (1.8698)  gan_loss: 1.0005 (0.8811)  pix_loss: 0.4698 (0.4925)  time: 54.0574  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [160/985]  eta: 12:23:27  lr: 0.000100  g_loss: 5.4638 (5.7855)  d_loss: 1.8844 (1.8706)  gan_loss: 0.9764 (0.8877)  pix_loss: 0.4458 (0.4898)  time: 54.0549  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [170/985]  eta: 12:14:26  lr: 0.000100  g_loss: 5.5402 (5.7870)  d_loss: 1.8765 (1.8709)  gan_loss: 0.9744 (0.8931)  pix_loss: 0.4571 (0.4894)  time: 54.0546  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [180/985]  eta: 12:05:24  lr: 0.000100  g_loss: 5.7836 (5.7931)  d_loss: 1.8696 (1.8709)  gan_loss: 0.9765 (0.8979)  pix_loss: 0.4810 (0.4895)  time: 54.0545  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [190/985]  eta: 11:56:23  lr: 0.000100  g_loss: 5.9208 (5.8130)  d_loss: 1.8734 (1.8706)  gan_loss: 0.9740 (0.9015)  pix_loss: 0.4927 (0.4912)  time: 54.0560  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [200/985]  eta: 11:47:22  lr: 0.000100  g_loss: 5.9478 (5.8226)  d_loss: 1.8591 (1.8700)  gan_loss: 0.9402 (0.9033)  pix_loss: 0.4962 (0.4919)  time: 54.0560  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [210/985]  eta: 11:38:21  lr: 0.000100  g_loss: 5.9254 (5.8293)  d_loss: 1.8619 (1.8700)  gan_loss: 0.9363 (0.9049)  pix_loss: 0.5014 (0.4924)  time: 54.0567  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [220/985]  eta: 11:29:20  lr: 0.000100  g_loss: 5.8982 (5.8311)  d_loss: 1.8662 (1.8698)  gan_loss: 0.9317 (0.9059)  pix_loss: 0.4976 (0.4925)  time: 54.0533  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [230/985]  eta: 11:20:19  lr: 0.000100  g_loss: 6.1804 (5.8533)  d_loss: 1.8566 (1.8693)  gan_loss: 0.9130 (0.9057)  pix_loss: 0.5247 (0.4948)  time: 54.0529  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [240/985]  eta: 11:11:18  lr: 0.000100  g_loss: 6.2522 (5.8645)  d_loss: 1.8578 (1.8690)  gan_loss: 0.8882 (0.9049)  pix_loss: 0.5367 (0.4960)  time: 54.0602  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [250/985]  eta: 11:02:17  lr: 0.000100  g_loss: 5.8408 (5.8581)  d_loss: 1.8595 (1.8690)  gan_loss: 0.8811 (0.9038)  pix_loss: 0.4955 (0.4954)  time: 54.0557  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [260/985]  eta: 10:53:16  lr: 0.000100  g_loss: 5.6880 (5.8503)  d_loss: 1.8626 (1.8688)  gan_loss: 0.8697 (0.9023)  pix_loss: 0.4789 (0.4948)  time: 54.0534  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [270/985]  eta: 10:44:15  lr: 0.000100  g_loss: 5.6566 (5.8458)  d_loss: 1.8679 (1.8687)  gan_loss: 0.8551 (0.9004)  pix_loss: 0.4810 (0.4945)  time: 54.0586  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [280/985]  eta: 10:35:14  lr: 0.000100  g_loss: 5.7068 (5.8490)  d_loss: 1.8683 (1.8684)  gan_loss: 0.8470 (0.8983)  pix_loss: 0.4865 (0.4951)  time: 54.0571  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [290/985]  eta: 10:26:14  lr: 0.000100  g_loss: 5.5840 (5.8362)  d_loss: 1.8731 (1.8687)  gan_loss: 0.8276 (0.8958)  pix_loss: 0.4761 (0.4940)  time: 54.0550  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [300/985]  eta: 10:17:13  lr: 0.000100  g_loss: 5.6489 (5.8419)  d_loss: 1.8715 (1.8686)  gan_loss: 0.8193 (0.8927)  pix_loss: 0.4830 (0.4949)  time: 54.0606  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [310/985]  eta: 10:08:12  lr: 0.000100  g_loss: 5.6489 (5.8368)  d_loss: 1.8594 (1.8682)  gan_loss: 0.7922 (0.8889)  pix_loss: 0.4846 (0.4948)  time: 54.0624  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [320/985]  eta: 9:59:12  lr: 0.000100  g_loss: 5.3926 (5.8207)  d_loss: 1.8681 (1.8682)  gan_loss: 0.7922 (0.8863)  pix_loss: 0.4623 (0.4934)  time: 54.0602  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [330/985]  eta: 9:50:11  lr: 0.000100  g_loss: 5.2345 (5.8069)  d_loss: 1.8734 (1.8683)  gan_loss: 0.8002 (0.8835)  pix_loss: 0.4486 (0.4923)  time: 54.0583  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [340/985]  eta: 9:41:10  lr: 0.000100  g_loss: 5.4339 (5.8002)  d_loss: 1.8828 (1.8687)  gan_loss: 0.8789 (0.8849)  pix_loss: 0.4547 (0.4915)  time: 54.0571  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [350/985]  eta: 9:32:09  lr: 0.000100  g_loss: 5.5074 (5.7997)  d_loss: 1.8831 (1.8692)  gan_loss: 0.9244 (0.8860)  pix_loss: 0.4607 (0.4914)  time: 54.0600  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [360/985]  eta: 9:23:09  lr: 0.000100  g_loss: 5.6039 (5.7958)  d_loss: 1.8848 (1.8696)  gan_loss: 0.9365 (0.8877)  pix_loss: 0.4658 (0.4908)  time: 54.0617  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [370/985]  eta: 9:14:08  lr: 0.000100  g_loss: 5.7040 (5.7987)  d_loss: 1.8768 (1.8694)  gan_loss: 0.9363 (0.8887)  pix_loss: 0.4790 (0.4910)  time: 54.0621  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [380/985]  eta: 9:05:07  lr: 0.000100  g_loss: 5.7424 (5.7947)  d_loss: 1.8671 (1.8695)  gan_loss: 0.9095 (0.8891)  pix_loss: 0.4818 (0.4906)  time: 54.0600  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [390/985]  eta: 8:56:07  lr: 0.000100  g_loss: 5.5081 (5.7818)  d_loss: 1.8778 (1.8698)  gan_loss: 0.8932 (0.8891)  pix_loss: 0.4596 (0.4893)  time: 54.0579  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [400/985]  eta: 8:47:06  lr: 0.000100  g_loss: 5.2136 (5.7708)  d_loss: 1.8846 (1.8704)  gan_loss: 0.8827 (0.8890)  pix_loss: 0.4325 (0.4882)  time: 54.0586  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [410/985]  eta: 8:38:05  lr: 0.000100  g_loss: 5.1072 (5.7564)  d_loss: 1.8904 (1.8706)  gan_loss: 0.8715 (0.8885)  pix_loss: 0.4227 (0.4868)  time: 54.0589  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [420/985]  eta: 8:29:05  lr: 0.000100  g_loss: 5.0907 (5.7462)  d_loss: 1.8861 (1.8710)  gan_loss: 0.8610 (0.8877)  pix_loss: 0.4226 (0.4859)  time: 54.0570  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [430/985]  eta: 8:20:04  lr: 0.000100  g_loss: 5.3512 (5.7439)  d_loss: 1.8814 (1.8711)  gan_loss: 0.8415 (0.8862)  pix_loss: 0.4515 (0.4858)  time: 54.0594  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [440/985]  eta: 8:11:03  lr: 0.000100  g_loss: 5.3816 (5.7350)  d_loss: 1.8787 (1.8713)  gan_loss: 0.8095 (0.8843)  pix_loss: 0.4576 (0.4851)  time: 54.0614  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [450/985]  eta: 8:02:03  lr: 0.000100  g_loss: 5.2521 (5.7239)  d_loss: 1.8773 (1.8711)  gan_loss: 0.7862 (0.8819)  pix_loss: 0.4443 (0.4842)  time: 54.0633  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [460/985]  eta: 7:53:03  lr: 0.000100  g_loss: 5.1321 (5.7126)  d_loss: 1.8622 (1.8708)  gan_loss: 0.7813 (0.8798)  pix_loss: 0.4360 (0.4833)  time: 54.1086  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [470/985]  eta: 7:44:03  lr: 0.000100  g_loss: 5.3170 (5.7039)  d_loss: 1.8568 (1.8704)  gan_loss: 0.7690 (0.8773)  pix_loss: 0.4550 (0.4827)  time: 54.1286  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [480/985]  eta: 7:35:02  lr: 0.000100  g_loss: 5.3570 (5.6975)  d_loss: 1.8739 (1.8707)  gan_loss: 0.7868 (0.8776)  pix_loss: 0.4548 (0.4820)  time: 54.0806  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [490/985]  eta: 7:26:02  lr: 0.000100  g_loss: 5.3946 (5.6913)  d_loss: 1.8860 (1.8711)  gan_loss: 0.9080 (0.8786)  pix_loss: 0.4488 (0.4813)  time: 54.0572  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [500/985]  eta: 7:17:01  lr: 0.000100  g_loss: 5.3812 (5.6865)  d_loss: 1.8871 (1.8714)  gan_loss: 0.9434 (0.8802)  pix_loss: 0.4431 (0.4806)  time: 54.0632  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [510/985]  eta: 7:08:00  lr: 0.000100  g_loss: 5.3579 (5.6784)  d_loss: 1.8935 (1.8718)  gan_loss: 0.9434 (0.8813)  pix_loss: 0.4385 (0.4797)  time: 54.0661  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [520/985]  eta: 6:59:06  lr: 0.000100  g_loss: 4.9166 (5.6682)  d_loss: 1.8956 (1.8723)  gan_loss: 0.9506 (0.8829)  pix_loss: 0.3987 (0.4785)  time: 54.3922  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [530/985]  eta: 6:50:13  lr: 0.000100  g_loss: 5.1233 (5.6631)  d_loss: 1.8955 (1.8727)  gan_loss: 0.9506 (0.8837)  pix_loss: 0.4174 (0.4779)  time: 54.8550  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [540/985]  eta: 6:41:11  lr: 0.000100  g_loss: 5.1266 (5.6551)  d_loss: 1.8929 (1.8731)  gan_loss: 0.9268 (0.8850)  pix_loss: 0.4196 (0.4770)  time: 54.5263  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [550/985]  eta: 6:32:10  lr: 0.000100  g_loss: 5.0450 (5.6467)  d_loss: 1.8935 (1.8734)  gan_loss: 0.9259 (0.8856)  pix_loss: 0.4106 (0.4761)  time: 54.0595  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [560/985]  eta: 6:23:09  lr: 0.000100  g_loss: 5.0450 (5.6364)  d_loss: 1.8920 (1.8737)  gan_loss: 0.9139 (0.8862)  pix_loss: 0.4106 (0.4750)  time: 54.0576  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [570/985]  eta: 6:14:08  lr: 0.000100  g_loss: 5.0642 (5.6269)  d_loss: 1.8843 (1.8737)  gan_loss: 0.9042 (0.8863)  pix_loss: 0.4165 (0.4741)  time: 54.0601  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [580/985]  eta: 6:05:07  lr: 0.000100  g_loss: 5.0806 (5.6173)  d_loss: 1.8765 (1.8738)  gan_loss: 0.8850 (0.8862)  pix_loss: 0.4188 (0.4731)  time: 54.0610  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [590/985]  eta: 5:56:06  lr: 0.000100  g_loss: 5.0159 (5.6085)  d_loss: 1.8854 (1.8740)  gan_loss: 0.8807 (0.8862)  pix_loss: 0.4167 (0.4722)  time: 54.0611  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [600/985]  eta: 5:47:04  lr: 0.000100  g_loss: 5.2693 (5.6067)  d_loss: 1.8777 (1.8740)  gan_loss: 0.8719 (0.8859)  pix_loss: 0.4408 (0.4721)  time: 54.0592  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [610/985]  eta: 5:38:03  lr: 0.000100  g_loss: 5.5450 (5.6067)  d_loss: 1.8777 (1.8742)  gan_loss: 0.8546 (0.8851)  pix_loss: 0.4692 (0.4722)  time: 54.0569  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [620/985]  eta: 5:29:02  lr: 0.000100  g_loss: 5.1253 (5.5938)  d_loss: 1.8894 (1.8744)  gan_loss: 0.8268 (0.8842)  pix_loss: 0.4271 (0.4710)  time: 54.0638  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [630/985]  eta: 5:20:01  lr: 0.000100  g_loss: 4.9263 (5.5857)  d_loss: 1.8850 (1.8745)  gan_loss: 0.8178 (0.8828)  pix_loss: 0.4144 (0.4703)  time: 54.0646  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [640/985]  eta: 5:11:00  lr: 0.000100  g_loss: 5.0327 (5.5761)  d_loss: 1.8828 (1.8745)  gan_loss: 0.7954 (0.8815)  pix_loss: 0.4244 (0.4695)  time: 54.0586  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [650/985]  eta: 5:01:59  lr: 0.000100  g_loss: 4.9062 (5.5717)  d_loss: 1.8732 (1.8744)  gan_loss: 0.7739 (0.8797)  pix_loss: 0.4136 (0.4692)  time: 54.0620  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [660/985]  eta: 4:52:58  lr: 0.000100  g_loss: 5.1886 (5.5687)  d_loss: 1.8673 (1.8742)  gan_loss: 0.7571 (0.8779)  pix_loss: 0.4422 (0.4691)  time: 54.0674  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [670/985]  eta: 4:43:57  lr: 0.000100  g_loss: 5.0558 (5.5592)  d_loss: 1.8714 (1.8742)  gan_loss: 0.7572 (0.8762)  pix_loss: 0.4287 (0.4683)  time: 54.0664  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [680/985]  eta: 4:34:56  lr: 0.000100  g_loss: 4.8769 (5.5471)  d_loss: 1.8748 (1.8743)  gan_loss: 0.7725 (0.8752)  pix_loss: 0.4114 (0.4672)  time: 54.0644  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [690/985]  eta: 4:25:55  lr: 0.000100  g_loss: 4.8982 (5.5458)  d_loss: 1.8801 (1.8744)  gan_loss: 0.8161 (0.8743)  pix_loss: 0.4090 (0.4671)  time: 54.0659  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [700/985]  eta: 4:16:54  lr: 0.000100  g_loss: 5.2682 (5.5408)  d_loss: 1.8769 (1.8743)  gan_loss: 0.8066 (0.8730)  pix_loss: 0.4457 (0.4668)  time: 54.0661  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [710/985]  eta: 4:07:53  lr: 0.000100  g_loss: 5.0735 (5.5343)  d_loss: 1.8667 (1.8741)  gan_loss: 0.7802 (0.8717)  pix_loss: 0.4306 (0.4663)  time: 54.0647  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [720/985]  eta: 3:58:52  lr: 0.000100  g_loss: 4.9749 (5.5279)  d_loss: 1.8675 (1.8742)  gan_loss: 0.7806 (0.8704)  pix_loss: 0.4180 (0.4657)  time: 54.0641  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [730/985]  eta: 3:49:51  lr: 0.000100  g_loss: 4.8101 (5.5189)  d_loss: 1.8851 (1.8743)  gan_loss: 0.7912 (0.8693)  pix_loss: 0.4002 (0.4650)  time: 54.0640  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [740/985]  eta: 3:40:50  lr: 0.000100  g_loss: 5.1826 (5.5177)  d_loss: 1.8826 (1.8744)  gan_loss: 0.8091 (0.8694)  pix_loss: 0.4301 (0.4648)  time: 54.0660  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [750/985]  eta: 3:31:50  lr: 0.000100  g_loss: 5.3188 (5.5145)  d_loss: 1.8967 (1.8747)  gan_loss: 0.9452 (0.8708)  pix_loss: 0.4369 (0.4644)  time: 54.0680  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [760/985]  eta: 3:22:49  lr: 0.000100  g_loss: 5.3341 (5.5123)  d_loss: 1.8922 (1.8749)  gan_loss: 0.9649 (0.8719)  pix_loss: 0.4369 (0.4640)  time: 54.0678  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [770/985]  eta: 3:13:48  lr: 0.000100  g_loss: 5.2855 (5.5116)  d_loss: 1.8915 (1.8752)  gan_loss: 0.9690 (0.8734)  pix_loss: 0.4351 (0.4638)  time: 54.0646  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [780/985]  eta: 3:04:47  lr: 0.000100  g_loss: 5.4128 (5.5102)  d_loss: 1.8955 (1.8754)  gan_loss: 0.9745 (0.8748)  pix_loss: 0.4440 (0.4635)  time: 54.0644  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [790/985]  eta: 2:55:46  lr: 0.000100  g_loss: 5.2683 (5.5060)  d_loss: 1.8921 (1.8755)  gan_loss: 0.9607 (0.8757)  pix_loss: 0.4320 (0.4630)  time: 54.0611  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [800/985]  eta: 2:46:45  lr: 0.000100  g_loss: 5.1947 (5.5028)  d_loss: 1.8772 (1.8754)  gan_loss: 0.9401 (0.8765)  pix_loss: 0.4262 (0.4626)  time: 54.0605  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [810/985]  eta: 2:37:44  lr: 0.000100  g_loss: 5.2218 (5.5003)  d_loss: 1.8772 (1.8755)  gan_loss: 0.9367 (0.8773)  pix_loss: 0.4304 (0.4623)  time: 54.0665  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [820/985]  eta: 2:28:43  lr: 0.000100  g_loss: 5.2593 (5.4961)  d_loss: 1.8916 (1.8757)  gan_loss: 0.9354 (0.8780)  pix_loss: 0.4344 (0.4618)  time: 54.0647  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [830/985]  eta: 2:19:42  lr: 0.000100  g_loss: 5.0607 (5.4910)  d_loss: 1.8962 (1.8759)  gan_loss: 0.9267 (0.8786)  pix_loss: 0.4148 (0.4612)  time: 54.0580  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [840/985]  eta: 2:10:42  lr: 0.000100  g_loss: 5.0461 (5.4838)  d_loss: 1.8924 (1.8762)  gan_loss: 0.9134 (0.8789)  pix_loss: 0.4119 (0.4605)  time: 54.0588  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [850/985]  eta: 2:01:41  lr: 0.000100  g_loss: 4.9028 (5.4779)  d_loss: 1.8973 (1.8764)  gan_loss: 0.9036 (0.8792)  pix_loss: 0.3999 (0.4599)  time: 54.0605  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [860/985]  eta: 1:52:40  lr: 0.000100  g_loss: 4.9059 (5.4706)  d_loss: 1.8949 (1.8765)  gan_loss: 0.8885 (0.8791)  pix_loss: 0.4037 (0.4591)  time: 54.0610  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [870/985]  eta: 1:43:39  lr: 0.000100  g_loss: 4.6613 (5.4630)  d_loss: 1.8931 (1.8767)  gan_loss: 0.8668 (0.8790)  pix_loss: 0.3816 (0.4584)  time: 54.0630  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [880/985]  eta: 1:34:38  lr: 0.000100  g_loss: 4.6438 (5.4541)  d_loss: 1.8954 (1.8769)  gan_loss: 0.8581 (0.8786)  pix_loss: 0.3782 (0.4576)  time: 54.0612  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [890/985]  eta: 1:25:37  lr: 0.000100  g_loss: 4.6542 (5.4495)  d_loss: 1.8864 (1.8769)  gan_loss: 0.8393 (0.8781)  pix_loss: 0.3845 (0.4571)  time: 54.0607  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [900/985]  eta: 1:16:36  lr: 0.000100  g_loss: 4.8740 (5.4430)  d_loss: 1.8842 (1.8770)  gan_loss: 0.8225 (0.8775)  pix_loss: 0.4056 (0.4566)  time: 54.0604  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [910/985]  eta: 1:07:36  lr: 0.000100  g_loss: 4.8645 (5.4365)  d_loss: 1.8802 (1.8769)  gan_loss: 0.8120 (0.8767)  pix_loss: 0.4056 (0.4560)  time: 54.0567  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [920/985]  eta: 0:58:35  lr: 0.000100  g_loss: 4.8176 (5.4284)  d_loss: 1.8816 (1.8770)  gan_loss: 0.8040 (0.8759)  pix_loss: 0.4018 (0.4553)  time: 54.0586  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [930/985]  eta: 0:49:34  lr: 0.000100  g_loss: 4.7116 (5.4223)  d_loss: 1.8863 (1.8771)  gan_loss: 0.7904 (0.8749)  pix_loss: 0.3927 (0.4547)  time: 54.0611  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [940/985]  eta: 0:40:33  lr: 0.000100  g_loss: 4.9320 (5.4189)  d_loss: 1.8849 (1.8771)  gan_loss: 0.7816 (0.8739)  pix_loss: 0.4145 (0.4545)  time: 54.0584  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [950/985]  eta: 0:31:32  lr: 0.000100  g_loss: 4.7331 (5.4111)  d_loss: 1.8812 (1.8771)  gan_loss: 0.7694 (0.8727)  pix_loss: 0.3984 (0.4538)  time: 54.0577  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [960/985]  eta: 0:22:32  lr: 0.000100  g_loss: 4.6805 (5.4033)  d_loss: 1.8853 (1.8773)  gan_loss: 0.7619 (0.8717)  pix_loss: 0.3933 (0.4532)  time: 54.0586  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [970/985]  eta: 0:13:31  lr: 0.000100  g_loss: 4.7279 (5.3956)  d_loss: 1.8886 (1.8774)  gan_loss: 0.7829 (0.8708)  pix_loss: 0.3945 (0.4525)  time: 54.0590  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:15]  [980/985]  eta: 0:04:30  lr: 0.000100  g_loss: 4.6576 (5.3885)  d_loss: 1.8933 (1.8775)  gan_loss: 0.7861 (0.8699)  pix_loss: 0.3847 (0.4519)  time: 54.0568  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 4.6012 (5.3850)  d_loss: 1.8933 (1.8775)  gan_loss: 0.7769 (0.8694)  pix_loss: 0.3833 (0.4516)  time: 54.0576  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:15] Total time: 14:47:48 (54.0798 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 4.6012 (5.3850)  d_loss: 1.8933 (1.8775)  gan_loss: 0.7769 (0.8694)  pix_loss: 0.3833 (0.4516)\n",
      "Valid: [epoch:15]  [ 0/14]  eta: 0:01:32  L1_loss: 0.0118 (0.0118)  time: 6.6305  data: 0.4237  max mem: 38397\n",
      "Valid: [epoch:15]  [13/14]  eta: 0:00:06  L1_loss: 0.0119 (0.0122)  time: 6.1615  data: 0.0303  max mem: 38397\n",
      "Valid: [epoch:15] Total time: 0:01:26 (6.1684 s / it)\n",
      "Averaged stats: L1_loss: 0.0119 (0.0122)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_15_input_n_20.png\n",
      "Train: [epoch:16]  [  0/985]  eta: 15:06:31  lr: 0.000100  g_loss: 5.0843 (5.0843)  d_loss: 1.8813 (1.8813)  gan_loss: 0.7490 (0.7490)  pix_loss: 0.4335 (0.4335)  time: 55.2200  data: 1.1622  max mem: 38397\n",
      "Train: [epoch:16]  [ 10/985]  eta: 14:40:18  lr: 0.000100  g_loss: 4.6106 (4.6342)  d_loss: 1.8804 (1.8728)  gan_loss: 0.7613 (0.7608)  pix_loss: 0.3856 (0.3873)  time: 54.1732  data: 0.1058  max mem: 38397\n",
      "Train: [epoch:16]  [ 20/985]  eta: 14:30:28  lr: 0.000100  g_loss: 4.6373 (4.7475)  d_loss: 1.8672 (1.8691)  gan_loss: 0.7647 (0.7671)  pix_loss: 0.3857 (0.3980)  time: 54.0676  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [ 30/985]  eta: 14:21:09  lr: 0.000100  g_loss: 4.6373 (4.7078)  d_loss: 1.8862 (1.8771)  gan_loss: 0.7743 (0.7764)  pix_loss: 0.3857 (0.3931)  time: 54.0664  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [ 40/985]  eta: 14:11:59  lr: 0.000100  g_loss: 4.6541 (4.7472)  d_loss: 1.8963 (1.8817)  gan_loss: 0.8336 (0.7931)  pix_loss: 0.3826 (0.3954)  time: 54.0653  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [ 50/985]  eta: 14:02:51  lr: 0.000100  g_loss: 4.7760 (4.7660)  d_loss: 1.9031 (1.8874)  gan_loss: 0.8361 (0.8009)  pix_loss: 0.3936 (0.3965)  time: 54.0606  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [ 60/985]  eta: 13:53:46  lr: 0.000100  g_loss: 4.8659 (4.7790)  d_loss: 1.9065 (1.8895)  gan_loss: 0.8340 (0.8072)  pix_loss: 0.4038 (0.3972)  time: 54.0590  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [ 70/985]  eta: 13:44:43  lr: 0.000100  g_loss: 4.7099 (4.7824)  d_loss: 1.8987 (1.8884)  gan_loss: 0.8201 (0.8076)  pix_loss: 0.3894 (0.3975)  time: 54.0613  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [ 80/985]  eta: 13:35:39  lr: 0.000100  g_loss: 4.7153 (4.7925)  d_loss: 1.8687 (1.8855)  gan_loss: 0.8014 (0.8036)  pix_loss: 0.3925 (0.3989)  time: 54.0600  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [ 90/985]  eta: 13:26:37  lr: 0.000100  g_loss: 4.7923 (4.7992)  d_loss: 1.8687 (1.8839)  gan_loss: 0.7675 (0.7991)  pix_loss: 0.4022 (0.4000)  time: 54.0588  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [100/985]  eta: 13:17:34  lr: 0.000100  g_loss: 5.0199 (4.8494)  d_loss: 1.8726 (1.8823)  gan_loss: 0.7639 (0.7968)  pix_loss: 0.4258 (0.4053)  time: 54.0575  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [110/985]  eta: 13:08:33  lr: 0.000100  g_loss: 4.9339 (4.8459)  d_loss: 1.8726 (1.8817)  gan_loss: 0.7701 (0.7943)  pix_loss: 0.4159 (0.4052)  time: 54.0573  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [120/985]  eta: 12:59:30  lr: 0.000100  g_loss: 4.7076 (4.8372)  d_loss: 1.8798 (1.8821)  gan_loss: 0.7750 (0.7944)  pix_loss: 0.3887 (0.4043)  time: 54.0549  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [130/985]  eta: 12:50:29  lr: 0.000100  g_loss: 4.6302 (4.8195)  d_loss: 1.8965 (1.8837)  gan_loss: 0.8149 (0.7962)  pix_loss: 0.3831 (0.4023)  time: 54.0552  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [140/985]  eta: 12:41:28  lr: 0.000100  g_loss: 4.6455 (4.8202)  d_loss: 1.8965 (1.8842)  gan_loss: 0.8200 (0.7984)  pix_loss: 0.3831 (0.4022)  time: 54.0618  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [150/985]  eta: 12:32:27  lr: 0.000100  g_loss: 4.6990 (4.8144)  d_loss: 1.8869 (1.8842)  gan_loss: 0.8183 (0.7993)  pix_loss: 0.3869 (0.4015)  time: 54.0635  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [160/985]  eta: 12:23:26  lr: 0.000100  g_loss: 4.7538 (4.8233)  d_loss: 1.8788 (1.8835)  gan_loss: 0.8061 (0.7988)  pix_loss: 0.3984 (0.4025)  time: 54.0641  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [170/985]  eta: 12:14:25  lr: 0.000100  g_loss: 4.6589 (4.8039)  d_loss: 1.8802 (1.8835)  gan_loss: 0.7782 (0.7968)  pix_loss: 0.3873 (0.4007)  time: 54.0669  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [180/985]  eta: 12:05:24  lr: 0.000100  g_loss: 4.6180 (4.8188)  d_loss: 1.8834 (1.8829)  gan_loss: 0.7827 (0.7968)  pix_loss: 0.3821 (0.4022)  time: 54.0671  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [190/985]  eta: 11:56:24  lr: 0.000100  g_loss: 5.3039 (4.8494)  d_loss: 1.8669 (1.8817)  gan_loss: 0.7965 (0.7967)  pix_loss: 0.4505 (0.4053)  time: 54.0651  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [200/985]  eta: 11:47:23  lr: 0.000100  g_loss: 5.1483 (4.8560)  d_loss: 1.8654 (1.8810)  gan_loss: 0.7705 (0.7948)  pix_loss: 0.4353 (0.4061)  time: 54.0620  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [210/985]  eta: 11:38:22  lr: 0.000100  g_loss: 4.7731 (4.8440)  d_loss: 1.8657 (1.8807)  gan_loss: 0.7611 (0.7935)  pix_loss: 0.3995 (0.4051)  time: 54.0581  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [220/985]  eta: 11:29:21  lr: 0.000100  g_loss: 4.5702 (4.8339)  d_loss: 1.8724 (1.8802)  gan_loss: 0.7675 (0.7922)  pix_loss: 0.3797 (0.4042)  time: 54.0606  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [230/985]  eta: 11:20:20  lr: 0.000100  g_loss: 4.7927 (4.8366)  d_loss: 1.8665 (1.8797)  gan_loss: 0.7674 (0.7912)  pix_loss: 0.4032 (0.4045)  time: 54.0620  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [240/985]  eta: 11:11:19  lr: 0.000100  g_loss: 4.9503 (4.8453)  d_loss: 1.8771 (1.8796)  gan_loss: 0.7726 (0.7928)  pix_loss: 0.4167 (0.4053)  time: 54.0562  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [250/985]  eta: 11:02:18  lr: 0.000100  g_loss: 5.0097 (4.8577)  d_loss: 1.8914 (1.8801)  gan_loss: 0.8601 (0.7959)  pix_loss: 0.4167 (0.4062)  time: 54.0533  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [260/985]  eta: 10:53:17  lr: 0.000100  g_loss: 5.0169 (4.8652)  d_loss: 1.8896 (1.8802)  gan_loss: 0.8784 (0.7995)  pix_loss: 0.4125 (0.4066)  time: 54.0600  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [270/985]  eta: 10:44:16  lr: 0.000100  g_loss: 5.0934 (4.8774)  d_loss: 1.8771 (1.8798)  gan_loss: 0.8792 (0.8020)  pix_loss: 0.4237 (0.4075)  time: 54.0618  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [280/985]  eta: 10:35:15  lr: 0.000100  g_loss: 5.1138 (4.8821)  d_loss: 1.8803 (1.8800)  gan_loss: 0.8500 (0.8035)  pix_loss: 0.4250 (0.4079)  time: 54.0573  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [290/985]  eta: 10:26:23  lr: 0.000100  g_loss: 5.1419 (4.9092)  d_loss: 1.8803 (1.8794)  gan_loss: 0.8301 (0.8040)  pix_loss: 0.4296 (0.4105)  time: 54.2290  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [300/985]  eta: 10:17:23  lr: 0.000100  g_loss: 6.1142 (4.9676)  d_loss: 1.8563 (1.8781)  gan_loss: 0.7964 (0.8036)  pix_loss: 0.5336 (0.4164)  time: 54.2640  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [310/985]  eta: 10:08:22  lr: 0.000100  g_loss: 6.4437 (5.0074)  d_loss: 1.8487 (1.8771)  gan_loss: 0.7840 (0.8032)  pix_loss: 0.5655 (0.4204)  time: 54.0963  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [320/985]  eta: 9:59:21  lr: 0.000100  g_loss: 5.8451 (5.0258)  d_loss: 1.8765 (1.8776)  gan_loss: 0.8708 (0.8063)  pix_loss: 0.4996 (0.4219)  time: 54.0620  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [330/985]  eta: 9:50:24  lr: 0.000100  g_loss: 5.4610 (5.0297)  d_loss: 1.8985 (1.8783)  gan_loss: 0.9124 (0.8100)  pix_loss: 0.4560 (0.4220)  time: 54.1585  data: 0.0003  max mem: 38397\n",
      "Train: [epoch:16]  [340/985]  eta: 9:41:22  lr: 0.000100  g_loss: 5.3232 (5.0430)  d_loss: 1.9016 (1.8787)  gan_loss: 0.9205 (0.8133)  pix_loss: 0.4392 (0.4230)  time: 54.1585  data: 0.0003  max mem: 38397\n",
      "Train: [epoch:16]  [350/985]  eta: 9:32:21  lr: 0.000100  g_loss: 5.4360 (5.0575)  d_loss: 1.8978 (1.8791)  gan_loss: 0.9050 (0.8160)  pix_loss: 0.4542 (0.4242)  time: 54.0636  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [360/985]  eta: 9:23:20  lr: 0.000100  g_loss: 5.2341 (5.0571)  d_loss: 1.8928 (1.8795)  gan_loss: 0.9031 (0.8185)  pix_loss: 0.4331 (0.4239)  time: 54.0654  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [370/985]  eta: 9:14:28  lr: 0.000100  g_loss: 4.9820 (5.0568)  d_loss: 1.8893 (1.8795)  gan_loss: 0.8963 (0.8202)  pix_loss: 0.4088 (0.4237)  time: 54.3251  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [380/985]  eta: 9:06:18  lr: 0.000100  g_loss: 4.9432 (5.0499)  d_loss: 1.8898 (1.8799)  gan_loss: 0.8679 (0.8213)  pix_loss: 0.4088 (0.4229)  time: 55.9621  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [390/985]  eta: 8:57:15  lr: 0.000100  g_loss: 4.7568 (5.0495)  d_loss: 1.8892 (1.8797)  gan_loss: 0.8558 (0.8222)  pix_loss: 0.3913 (0.4227)  time: 55.6937  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [400/985]  eta: 8:48:16  lr: 0.000100  g_loss: 5.0373 (5.0502)  d_loss: 1.8682 (1.8794)  gan_loss: 0.8335 (0.8223)  pix_loss: 0.4204 (0.4228)  time: 54.2397  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [410/985]  eta: 8:39:13  lr: 0.000100  g_loss: 5.0492 (5.0468)  d_loss: 1.8715 (1.8795)  gan_loss: 0.8137 (0.8217)  pix_loss: 0.4252 (0.4225)  time: 54.2443  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [420/985]  eta: 8:30:09  lr: 0.000100  g_loss: 4.5281 (5.0308)  d_loss: 1.8865 (1.8796)  gan_loss: 0.7860 (0.8206)  pix_loss: 0.3760 (0.4210)  time: 54.0547  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [430/985]  eta: 8:21:06  lr: 0.000100  g_loss: 4.3984 (5.0181)  d_loss: 1.8866 (1.8798)  gan_loss: 0.7774 (0.8197)  pix_loss: 0.3609 (0.4198)  time: 54.0508  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [440/985]  eta: 8:12:03  lr: 0.000100  g_loss: 4.4151 (5.0068)  d_loss: 1.8824 (1.8798)  gan_loss: 0.7732 (0.8185)  pix_loss: 0.3640 (0.4188)  time: 54.0536  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [450/985]  eta: 8:03:00  lr: 0.000100  g_loss: 4.4143 (4.9912)  d_loss: 1.8809 (1.8798)  gan_loss: 0.7635 (0.8172)  pix_loss: 0.3651 (0.4174)  time: 54.0526  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [460/985]  eta: 7:53:57  lr: 0.000100  g_loss: 4.4346 (4.9793)  d_loss: 1.8798 (1.8797)  gan_loss: 0.7620 (0.8161)  pix_loss: 0.3669 (0.4163)  time: 54.0530  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [470/985]  eta: 7:44:54  lr: 0.000100  g_loss: 4.4921 (4.9762)  d_loss: 1.8671 (1.8793)  gan_loss: 0.7605 (0.8149)  pix_loss: 0.3732 (0.4161)  time: 54.0577  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [480/985]  eta: 7:35:51  lr: 0.000100  g_loss: 4.4921 (4.9694)  d_loss: 1.8670 (1.8791)  gan_loss: 0.7588 (0.8137)  pix_loss: 0.3741 (0.4156)  time: 54.0545  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [490/985]  eta: 7:26:48  lr: 0.000100  g_loss: 4.4104 (4.9604)  d_loss: 1.8778 (1.8791)  gan_loss: 0.7582 (0.8126)  pix_loss: 0.3648 (0.4148)  time: 54.0545  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [500/985]  eta: 7:17:46  lr: 0.000100  g_loss: 4.4104 (4.9535)  d_loss: 1.8885 (1.8793)  gan_loss: 0.7628 (0.8117)  pix_loss: 0.3640 (0.4142)  time: 54.0583  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [510/985]  eta: 7:08:43  lr: 0.000100  g_loss: 4.4687 (4.9424)  d_loss: 1.8862 (1.8794)  gan_loss: 0.7623 (0.8106)  pix_loss: 0.3709 (0.4132)  time: 54.0591  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [520/985]  eta: 6:59:41  lr: 0.000100  g_loss: 4.2304 (4.9277)  d_loss: 1.8862 (1.8795)  gan_loss: 0.7534 (0.8095)  pix_loss: 0.3468 (0.4118)  time: 54.0634  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [530/985]  eta: 6:50:39  lr: 0.000100  g_loss: 4.2341 (4.9203)  d_loss: 1.8799 (1.8794)  gan_loss: 0.7535 (0.8086)  pix_loss: 0.3469 (0.4112)  time: 54.0652  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [540/985]  eta: 6:41:38  lr: 0.000100  g_loss: 4.3376 (4.9126)  d_loss: 1.8768 (1.8794)  gan_loss: 0.7582 (0.8079)  pix_loss: 0.3590 (0.4105)  time: 54.1731  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [550/985]  eta: 6:32:36  lr: 0.000100  g_loss: 4.5826 (4.9093)  d_loss: 1.8932 (1.8798)  gan_loss: 0.8605 (0.8108)  pix_loss: 0.3654 (0.4099)  time: 54.1740  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [560/985]  eta: 6:23:34  lr: 0.000100  g_loss: 4.5826 (4.9036)  d_loss: 1.9086 (1.8803)  gan_loss: 0.9899 (0.8141)  pix_loss: 0.3631 (0.4090)  time: 54.0614  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [570/985]  eta: 6:14:32  lr: 0.000100  g_loss: 4.5472 (4.8984)  d_loss: 1.9070 (1.8806)  gan_loss: 1.0046 (0.8173)  pix_loss: 0.3570 (0.4081)  time: 54.0570  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [580/985]  eta: 6:05:29  lr: 0.000100  g_loss: 4.7808 (4.8997)  d_loss: 1.8966 (1.8807)  gan_loss: 0.9955 (0.8204)  pix_loss: 0.3761 (0.4079)  time: 54.0523  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [590/985]  eta: 5:56:27  lr: 0.000100  g_loss: 5.0624 (4.9040)  d_loss: 1.8966 (1.8810)  gan_loss: 0.9955 (0.8234)  pix_loss: 0.4007 (0.4081)  time: 54.0517  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [600/985]  eta: 5:47:25  lr: 0.000100  g_loss: 4.9815 (4.9036)  d_loss: 1.8983 (1.8811)  gan_loss: 0.9755 (0.8260)  pix_loss: 0.4006 (0.4078)  time: 54.0590  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [610/985]  eta: 5:38:23  lr: 0.000100  g_loss: 4.9623 (4.9077)  d_loss: 1.8895 (1.8812)  gan_loss: 0.9755 (0.8285)  pix_loss: 0.3997 (0.4079)  time: 54.0612  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [620/985]  eta: 5:29:21  lr: 0.000100  g_loss: 5.1547 (4.9129)  d_loss: 1.8862 (1.8812)  gan_loss: 0.9663 (0.8307)  pix_loss: 0.4173 (0.4082)  time: 54.0591  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [630/985]  eta: 5:20:19  lr: 0.000100  g_loss: 5.1100 (4.9151)  d_loss: 1.8799 (1.8811)  gan_loss: 0.9508 (0.8325)  pix_loss: 0.4128 (0.4083)  time: 54.0604  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [640/985]  eta: 5:11:18  lr: 0.000100  g_loss: 5.0867 (4.9218)  d_loss: 1.8797 (1.8809)  gan_loss: 0.9347 (0.8341)  pix_loss: 0.4128 (0.4088)  time: 54.0642  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [650/985]  eta: 5:02:16  lr: 0.000100  g_loss: 5.0865 (4.9223)  d_loss: 1.8846 (1.8812)  gan_loss: 0.9289 (0.8357)  pix_loss: 0.4151 (0.4087)  time: 54.0653  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [660/985]  eta: 4:53:14  lr: 0.000100  g_loss: 4.8887 (4.9258)  d_loss: 1.8977 (1.8814)  gan_loss: 0.9198 (0.8369)  pix_loss: 0.3977 (0.4089)  time: 54.0654  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [670/985]  eta: 4:44:12  lr: 0.000100  g_loss: 4.8168 (4.9198)  d_loss: 1.9007 (1.8817)  gan_loss: 0.9045 (0.8379)  pix_loss: 0.3893 (0.4082)  time: 54.0650  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [680/985]  eta: 4:35:11  lr: 0.000100  g_loss: 4.4752 (4.9181)  d_loss: 1.9026 (1.8820)  gan_loss: 0.8936 (0.8383)  pix_loss: 0.3576 (0.4080)  time: 54.0637  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [690/985]  eta: 4:26:09  lr: 0.000100  g_loss: 4.4396 (4.9139)  d_loss: 1.8998 (1.8821)  gan_loss: 0.8434 (0.8383)  pix_loss: 0.3596 (0.4076)  time: 54.0640  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [700/985]  eta: 4:17:07  lr: 0.000100  g_loss: 4.6923 (4.9138)  d_loss: 1.8874 (1.8821)  gan_loss: 0.8161 (0.8377)  pix_loss: 0.3853 (0.4076)  time: 54.0645  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [710/985]  eta: 4:08:06  lr: 0.000100  g_loss: 4.6923 (4.9099)  d_loss: 1.8804 (1.8821)  gan_loss: 0.7877 (0.8370)  pix_loss: 0.3901 (0.4073)  time: 54.0666  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [720/985]  eta: 3:59:04  lr: 0.000100  g_loss: 4.5851 (4.9070)  d_loss: 1.8927 (1.8823)  gan_loss: 0.7672 (0.8359)  pix_loss: 0.3792 (0.4071)  time: 54.0707  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [730/985]  eta: 3:50:03  lr: 0.000100  g_loss: 4.5377 (4.9043)  d_loss: 1.8927 (1.8823)  gan_loss: 0.7595 (0.8349)  pix_loss: 0.3778 (0.4069)  time: 54.0648  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [740/985]  eta: 3:41:01  lr: 0.000100  g_loss: 4.5377 (4.9003)  d_loss: 1.8866 (1.8824)  gan_loss: 0.7642 (0.8340)  pix_loss: 0.3778 (0.4066)  time: 54.0593  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [750/985]  eta: 3:32:00  lr: 0.000100  g_loss: 4.5209 (4.8936)  d_loss: 1.8866 (1.8824)  gan_loss: 0.7636 (0.8330)  pix_loss: 0.3749 (0.4061)  time: 54.0642  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [760/985]  eta: 3:22:58  lr: 0.000100  g_loss: 4.5328 (4.8903)  d_loss: 1.8796 (1.8822)  gan_loss: 0.7625 (0.8322)  pix_loss: 0.3763 (0.4058)  time: 54.0659  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [770/985]  eta: 3:13:57  lr: 0.000100  g_loss: 4.6657 (4.8892)  d_loss: 1.8843 (1.8824)  gan_loss: 0.8389 (0.8331)  pix_loss: 0.3793 (0.4056)  time: 54.0638  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [780/985]  eta: 3:04:55  lr: 0.000100  g_loss: 4.7210 (4.8884)  d_loss: 1.8846 (1.8824)  gan_loss: 0.9267 (0.8346)  pix_loss: 0.3752 (0.4054)  time: 54.0629  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [790/985]  eta: 2:55:54  lr: 0.000100  g_loss: 4.7279 (4.8874)  d_loss: 1.8892 (1.8825)  gan_loss: 0.9651 (0.8364)  pix_loss: 0.3803 (0.4051)  time: 54.0603  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [800/985]  eta: 2:46:53  lr: 0.000100  g_loss: 4.8217 (4.8849)  d_loss: 1.8977 (1.8827)  gan_loss: 0.9713 (0.8380)  pix_loss: 0.3857 (0.4047)  time: 54.0623  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [810/985]  eta: 2:37:51  lr: 0.000100  g_loss: 4.5999 (4.8812)  d_loss: 1.8977 (1.8829)  gan_loss: 0.9526 (0.8394)  pix_loss: 0.3618 (0.4042)  time: 54.0680  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [820/985]  eta: 2:28:50  lr: 0.000100  g_loss: 4.6718 (4.8801)  d_loss: 1.8949 (1.8830)  gan_loss: 0.9482 (0.8407)  pix_loss: 0.3691 (0.4039)  time: 54.0659  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [830/985]  eta: 2:19:48  lr: 0.000100  g_loss: 4.7794 (4.8814)  d_loss: 1.8947 (1.8831)  gan_loss: 0.9345 (0.8418)  pix_loss: 0.3858 (0.4040)  time: 54.0596  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [840/985]  eta: 2:10:47  lr: 0.000100  g_loss: 4.7478 (4.8788)  d_loss: 1.8916 (1.8832)  gan_loss: 0.9210 (0.8427)  pix_loss: 0.3786 (0.4036)  time: 54.0580  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [850/985]  eta: 2:01:46  lr: 0.000100  g_loss: 4.4757 (4.8756)  d_loss: 1.8938 (1.8833)  gan_loss: 0.9100 (0.8435)  pix_loss: 0.3558 (0.4032)  time: 54.0585  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [860/985]  eta: 1:52:45  lr: 0.000100  g_loss: 4.7559 (4.8762)  d_loss: 1.8894 (1.8832)  gan_loss: 0.8847 (0.8439)  pix_loss: 0.3861 (0.4032)  time: 54.0625  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [870/985]  eta: 1:43:43  lr: 0.000100  g_loss: 4.8265 (4.8730)  d_loss: 1.8917 (1.8834)  gan_loss: 0.8767 (0.8443)  pix_loss: 0.3909 (0.4029)  time: 54.0642  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [880/985]  eta: 1:34:42  lr: 0.000100  g_loss: 4.3716 (4.8669)  d_loss: 1.8917 (1.8834)  gan_loss: 0.8560 (0.8442)  pix_loss: 0.3507 (0.4023)  time: 54.0631  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [890/985]  eta: 1:25:41  lr: 0.000100  g_loss: 4.6096 (4.8669)  d_loss: 1.8855 (1.8834)  gan_loss: 0.8383 (0.8442)  pix_loss: 0.3761 (0.4023)  time: 54.0645  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [900/985]  eta: 1:16:40  lr: 0.000100  g_loss: 4.8116 (4.8658)  d_loss: 1.8776 (1.8833)  gan_loss: 0.8295 (0.8439)  pix_loss: 0.3988 (0.4022)  time: 54.0665  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [910/985]  eta: 1:07:38  lr: 0.000100  g_loss: 4.5993 (4.8599)  d_loss: 1.8810 (1.8833)  gan_loss: 0.7990 (0.8433)  pix_loss: 0.3814 (0.4017)  time: 54.0649  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [920/985]  eta: 0:58:37  lr: 0.000100  g_loss: 4.2067 (4.8547)  d_loss: 1.8899 (1.8834)  gan_loss: 0.7869 (0.8427)  pix_loss: 0.3440 (0.4012)  time: 54.0595  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [930/985]  eta: 0:49:36  lr: 0.000100  g_loss: 4.2304 (4.8511)  d_loss: 1.8855 (1.8834)  gan_loss: 0.7727 (0.8419)  pix_loss: 0.3465 (0.4009)  time: 54.0644  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [940/985]  eta: 0:40:35  lr: 0.000100  g_loss: 4.2741 (4.8459)  d_loss: 1.8844 (1.8834)  gan_loss: 0.7691 (0.8412)  pix_loss: 0.3517 (0.4005)  time: 54.0641  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [950/985]  eta: 0:31:34  lr: 0.000100  g_loss: 4.2551 (4.8393)  d_loss: 1.8882 (1.8834)  gan_loss: 0.7651 (0.8403)  pix_loss: 0.3470 (0.3999)  time: 54.0595  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [960/985]  eta: 0:22:32  lr: 0.000100  g_loss: 4.2620 (4.8340)  d_loss: 1.8882 (1.8835)  gan_loss: 0.7651 (0.8396)  pix_loss: 0.3504 (0.3994)  time: 54.0632  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [970/985]  eta: 0:13:31  lr: 0.000100  g_loss: 4.2465 (4.8273)  d_loss: 1.8860 (1.8835)  gan_loss: 0.7696 (0.8389)  pix_loss: 0.3483 (0.3988)  time: 54.0639  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:16]  [980/985]  eta: 0:04:30  lr: 0.000100  g_loss: 4.0685 (4.8198)  d_loss: 1.8774 (1.8834)  gan_loss: 0.7615 (0.8380)  pix_loss: 0.3309 (0.3982)  time: 54.0639  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 4.1570 (4.8183)  d_loss: 1.8759 (1.8834)  gan_loss: 0.7616 (0.8377)  pix_loss: 0.3422 (0.3981)  time: 54.0640  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:16] Total time: 14:48:21 (54.1134 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 4.1570 (4.8183)  d_loss: 1.8759 (1.8834)  gan_loss: 0.7616 (0.8377)  pix_loss: 0.3422 (0.3981)\n",
      "Valid: [epoch:16]  [ 0/14]  eta: 0:01:35  L1_loss: 0.0261 (0.0261)  time: 6.8444  data: 0.4594  max mem: 38397\n",
      "Valid: [epoch:16]  [13/14]  eta: 0:00:06  L1_loss: 0.0262 (0.0264)  time: 6.3173  data: 0.0329  max mem: 38397\n",
      "Valid: [epoch:16] Total time: 0:01:28 (6.3251 s / it)\n",
      "Averaged stats: L1_loss: 0.0262 (0.0264)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_16_input_n_20.png\n",
      "Train: [epoch:17]  [  0/985]  eta: 15:08:30  lr: 0.000100  g_loss: 4.5541 (4.5541)  d_loss: 1.8522 (1.8522)  gan_loss: 0.7831 (0.7831)  pix_loss: 0.3771 (0.3771)  time: 55.3403  data: 1.2290  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [ 10/985]  eta: 14:40:30  lr: 0.000100  g_loss: 4.1792 (4.2824)  d_loss: 1.8826 (1.8811)  gan_loss: 0.7620 (0.7646)  pix_loss: 0.3436 (0.3518)  time: 54.1851  data: 0.1119  max mem: 38397\n",
      "Train: [epoch:17]  [ 20/985]  eta: 14:30:31  lr: 0.000100  g_loss: 4.1805 (4.2991)  d_loss: 1.8955 (1.8887)  gan_loss: 0.7730 (0.7771)  pix_loss: 0.3392 (0.3522)  time: 54.0653  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [ 30/985]  eta: 14:21:11  lr: 0.000100  g_loss: 4.3389 (4.3711)  d_loss: 1.9002 (1.8941)  gan_loss: 0.8088 (0.8239)  pix_loss: 0.3435 (0.3547)  time: 54.0627  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [ 40/985]  eta: 14:11:59  lr: 0.000100  g_loss: 4.7179 (4.5595)  d_loss: 1.9076 (1.8958)  gan_loss: 0.9589 (0.8646)  pix_loss: 0.3790 (0.3695)  time: 54.0622  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [ 50/985]  eta: 14:02:53  lr: 0.000100  g_loss: 4.7426 (4.5929)  d_loss: 1.9076 (1.8997)  gan_loss: 0.9749 (0.8867)  pix_loss: 0.3790 (0.3706)  time: 54.0622  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [ 60/985]  eta: 13:53:48  lr: 0.000100  g_loss: 4.6389 (4.6229)  d_loss: 1.9098 (1.9011)  gan_loss: 0.9979 (0.9081)  pix_loss: 0.3634 (0.3715)  time: 54.0647  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [ 70/985]  eta: 13:44:44  lr: 0.000100  g_loss: 4.6054 (4.6065)  d_loss: 1.9065 (1.9012)  gan_loss: 1.0038 (0.9188)  pix_loss: 0.3593 (0.3688)  time: 54.0632  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [ 80/985]  eta: 13:35:41  lr: 0.000100  g_loss: 4.4020 (4.5969)  d_loss: 1.9028 (1.9003)  gan_loss: 0.9635 (0.9226)  pix_loss: 0.3461 (0.3674)  time: 54.0611  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [ 90/985]  eta: 13:26:43  lr: 0.000100  g_loss: 4.5630 (4.6000)  d_loss: 1.8909 (1.8990)  gan_loss: 0.9457 (0.9256)  pix_loss: 0.3630 (0.3674)  time: 54.0824  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [100/985]  eta: 13:17:41  lr: 0.000100  g_loss: 4.7159 (4.6244)  d_loss: 1.8845 (1.8970)  gan_loss: 0.9340 (0.9259)  pix_loss: 0.3794 (0.3699)  time: 54.0862  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [110/985]  eta: 13:08:38  lr: 0.000100  g_loss: 4.7498 (4.6489)  d_loss: 1.8845 (1.8955)  gan_loss: 0.9297 (0.9261)  pix_loss: 0.3819 (0.3723)  time: 54.0647  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [120/985]  eta: 12:59:37  lr: 0.000100  g_loss: 4.8849 (4.6739)  d_loss: 1.8822 (1.8938)  gan_loss: 0.9142 (0.9242)  pix_loss: 0.3945 (0.3750)  time: 54.0622  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [130/985]  eta: 12:50:35  lr: 0.000100  g_loss: 4.7655 (4.6681)  d_loss: 1.8838 (1.8935)  gan_loss: 0.8985 (0.9223)  pix_loss: 0.3857 (0.3746)  time: 54.0622  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [140/985]  eta: 12:41:33  lr: 0.000100  g_loss: 4.4533 (4.6378)  d_loss: 1.8949 (1.8937)  gan_loss: 0.8886 (0.9196)  pix_loss: 0.3552 (0.3718)  time: 54.0594  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [150/985]  eta: 12:32:31  lr: 0.000100  g_loss: 4.1351 (4.6124)  d_loss: 1.8970 (1.8938)  gan_loss: 0.8720 (0.9154)  pix_loss: 0.3286 (0.3697)  time: 54.0570  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [160/985]  eta: 12:23:30  lr: 0.000100  g_loss: 4.1129 (4.5805)  d_loss: 1.8970 (1.8939)  gan_loss: 0.8448 (0.9103)  pix_loss: 0.3268 (0.3670)  time: 54.0589  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [170/985]  eta: 12:14:28  lr: 0.000100  g_loss: 4.1172 (4.5659)  d_loss: 1.8916 (1.8932)  gan_loss: 0.8199 (0.9046)  pix_loss: 0.3312 (0.3661)  time: 54.0587  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [180/985]  eta: 12:05:27  lr: 0.000100  g_loss: 4.1657 (4.5548)  d_loss: 1.8914 (1.8933)  gan_loss: 0.7992 (0.8984)  pix_loss: 0.3368 (0.3656)  time: 54.0575  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [190/985]  eta: 11:56:26  lr: 0.000100  g_loss: 4.2290 (4.5529)  d_loss: 1.8914 (1.8926)  gan_loss: 0.7863 (0.8923)  pix_loss: 0.3449 (0.3661)  time: 54.0582  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [200/985]  eta: 11:47:25  lr: 0.000100  g_loss: 4.4936 (4.5514)  d_loss: 1.8785 (1.8919)  gan_loss: 0.7768 (0.8865)  pix_loss: 0.3704 (0.3665)  time: 54.0602  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [210/985]  eta: 11:38:23  lr: 0.000100  g_loss: 4.3549 (4.5385)  d_loss: 1.8764 (1.8911)  gan_loss: 0.7717 (0.8806)  pix_loss: 0.3601 (0.3658)  time: 54.0610  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [220/985]  eta: 11:29:22  lr: 0.000100  g_loss: 4.3059 (4.5309)  d_loss: 1.8793 (1.8906)  gan_loss: 0.7611 (0.8755)  pix_loss: 0.3553 (0.3655)  time: 54.0579  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [230/985]  eta: 11:20:21  lr: 0.000100  g_loss: 4.2552 (4.5129)  d_loss: 1.8887 (1.8907)  gan_loss: 0.7676 (0.8711)  pix_loss: 0.3484 (0.3642)  time: 54.0559  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [240/985]  eta: 11:11:20  lr: 0.000100  g_loss: 3.9918 (4.4972)  d_loss: 1.8909 (1.8907)  gan_loss: 0.7676 (0.8667)  pix_loss: 0.3227 (0.3631)  time: 54.0593  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [250/985]  eta: 11:02:19  lr: 0.000100  g_loss: 3.9519 (4.4747)  d_loss: 1.8892 (1.8905)  gan_loss: 0.7630 (0.8626)  pix_loss: 0.3193 (0.3612)  time: 54.0609  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [260/985]  eta: 10:53:18  lr: 0.000100  g_loss: 3.7614 (4.4503)  d_loss: 1.8929 (1.8906)  gan_loss: 0.7636 (0.8592)  pix_loss: 0.2997 (0.3591)  time: 54.0584  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [270/985]  eta: 10:44:17  lr: 0.000100  g_loss: 3.7779 (4.4353)  d_loss: 1.8897 (1.8903)  gan_loss: 0.7636 (0.8556)  pix_loss: 0.3033 (0.3580)  time: 54.0576  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [280/985]  eta: 10:35:17  lr: 0.000100  g_loss: 4.0145 (4.4216)  d_loss: 1.8826 (1.8901)  gan_loss: 0.7674 (0.8526)  pix_loss: 0.3269 (0.3569)  time: 54.0576  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [290/985]  eta: 10:26:16  lr: 0.000100  g_loss: 4.1051 (4.4219)  d_loss: 1.8886 (1.8902)  gan_loss: 0.7725 (0.8499)  pix_loss: 0.3333 (0.3572)  time: 54.0552  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [300/985]  eta: 10:17:15  lr: 0.000100  g_loss: 4.1606 (4.4216)  d_loss: 1.8877 (1.8900)  gan_loss: 0.7604 (0.8468)  pix_loss: 0.3402 (0.3575)  time: 54.0548  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [310/985]  eta: 10:08:14  lr: 0.000100  g_loss: 4.1638 (4.4222)  d_loss: 1.8846 (1.8896)  gan_loss: 0.7621 (0.8442)  pix_loss: 0.3402 (0.3578)  time: 54.0634  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [320/985]  eta: 9:59:17  lr: 0.000100  g_loss: 4.3388 (4.4219)  d_loss: 1.8820 (1.8893)  gan_loss: 0.7703 (0.8428)  pix_loss: 0.3580 (0.3579)  time: 54.1655  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [330/985]  eta: 9:50:26  lr: 0.000100  g_loss: 4.5969 (4.4348)  d_loss: 1.8858 (1.8894)  gan_loss: 0.8056 (0.8414)  pix_loss: 0.3773 (0.3593)  time: 54.3896  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [340/985]  eta: 9:41:33  lr: 0.000100  g_loss: 4.6213 (4.4357)  d_loss: 1.8858 (1.8891)  gan_loss: 0.7823 (0.8397)  pix_loss: 0.3825 (0.3596)  time: 54.5173  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [350/985]  eta: 9:32:39  lr: 0.000100  g_loss: 4.4129 (4.4383)  d_loss: 1.9005 (1.8897)  gan_loss: 0.8656 (0.8440)  pix_loss: 0.3622 (0.3594)  time: 54.5171  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [360/985]  eta: 9:23:45  lr: 0.000100  g_loss: 4.7191 (4.4525)  d_loss: 1.9043 (1.8898)  gan_loss: 1.0040 (0.8481)  pix_loss: 0.3686 (0.3604)  time: 54.5190  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [370/985]  eta: 9:14:51  lr: 0.000100  g_loss: 4.7424 (4.4577)  d_loss: 1.8988 (1.8902)  gan_loss: 0.9927 (0.8512)  pix_loss: 0.3738 (0.3606)  time: 54.5159  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [380/985]  eta: 9:05:56  lr: 0.000100  g_loss: 4.5159 (4.4620)  d_loss: 1.9023 (1.8904)  gan_loss: 0.9791 (0.8550)  pix_loss: 0.3567 (0.3607)  time: 54.5158  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [390/985]  eta: 8:57:00  lr: 0.000100  g_loss: 4.4165 (4.4576)  d_loss: 1.9023 (1.8908)  gan_loss: 0.9666 (0.8573)  pix_loss: 0.3453 (0.3600)  time: 54.5223  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [400/985]  eta: 8:48:04  lr: 0.000100  g_loss: 4.1155 (4.4487)  d_loss: 1.9024 (1.8909)  gan_loss: 0.9433 (0.8596)  pix_loss: 0.3182 (0.3589)  time: 54.5222  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [410/985]  eta: 8:39:07  lr: 0.000100  g_loss: 4.1249 (4.4436)  d_loss: 1.9024 (1.8911)  gan_loss: 0.9461 (0.8617)  pix_loss: 0.3194 (0.3582)  time: 54.5206  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [420/985]  eta: 8:30:10  lr: 0.000100  g_loss: 4.1562 (4.4413)  d_loss: 1.8986 (1.8910)  gan_loss: 0.9318 (0.8634)  pix_loss: 0.3204 (0.3578)  time: 54.5202  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [430/985]  eta: 8:21:13  lr: 0.000100  g_loss: 4.3695 (4.4431)  d_loss: 1.8836 (1.8908)  gan_loss: 0.9207 (0.8646)  pix_loss: 0.3424 (0.3578)  time: 54.5199  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [440/985]  eta: 8:12:15  lr: 0.000100  g_loss: 4.3416 (4.4383)  d_loss: 1.8841 (1.8909)  gan_loss: 0.9021 (0.8654)  pix_loss: 0.3394 (0.3573)  time: 54.5191  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [450/985]  eta: 8:03:17  lr: 0.000100  g_loss: 4.1168 (4.4372)  d_loss: 1.8920 (1.8908)  gan_loss: 0.8943 (0.8659)  pix_loss: 0.3232 (0.3571)  time: 54.5225  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [460/985]  eta: 7:54:19  lr: 0.000100  g_loss: 3.8976 (4.4247)  d_loss: 1.8919 (1.8909)  gan_loss: 0.8772 (0.8659)  pix_loss: 0.3032 (0.3559)  time: 54.5303  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [470/985]  eta: 7:45:20  lr: 0.000100  g_loss: 3.8804 (4.4163)  d_loss: 1.8901 (1.8910)  gan_loss: 0.8634 (0.8658)  pix_loss: 0.3015 (0.3551)  time: 54.5301  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [480/985]  eta: 7:36:21  lr: 0.000100  g_loss: 4.1010 (4.4116)  d_loss: 1.8845 (1.8906)  gan_loss: 0.8361 (0.8649)  pix_loss: 0.3264 (0.3547)  time: 54.5257  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [490/985]  eta: 7:27:22  lr: 0.000100  g_loss: 4.1353 (4.4061)  d_loss: 1.8777 (1.8904)  gan_loss: 0.8136 (0.8637)  pix_loss: 0.3321 (0.3542)  time: 54.5267  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [500/985]  eta: 7:18:23  lr: 0.000100  g_loss: 4.1038 (4.4015)  d_loss: 1.8814 (1.8902)  gan_loss: 0.7984 (0.8622)  pix_loss: 0.3313 (0.3539)  time: 54.5222  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [510/985]  eta: 7:09:23  lr: 0.000100  g_loss: 4.0832 (4.3974)  d_loss: 1.8872 (1.8901)  gan_loss: 0.7740 (0.8605)  pix_loss: 0.3298 (0.3537)  time: 54.5224  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [520/985]  eta: 7:00:23  lr: 0.000100  g_loss: 3.9908 (4.3886)  d_loss: 1.8894 (1.8901)  gan_loss: 0.7697 (0.8588)  pix_loss: 0.3219 (0.3530)  time: 54.5300  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [530/985]  eta: 6:51:23  lr: 0.000100  g_loss: 3.8757 (4.3844)  d_loss: 1.8826 (1.8896)  gan_loss: 0.7780 (0.8576)  pix_loss: 0.3093 (0.3527)  time: 54.5290  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [540/985]  eta: 6:42:23  lr: 0.000100  g_loss: 4.3530 (4.3850)  d_loss: 1.8716 (1.8894)  gan_loss: 0.7755 (0.8559)  pix_loss: 0.3578 (0.3529)  time: 54.5300  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [550/985]  eta: 6:33:23  lr: 0.000100  g_loss: 4.3763 (4.3848)  d_loss: 1.8873 (1.8894)  gan_loss: 0.7592 (0.8542)  pix_loss: 0.3621 (0.3531)  time: 54.5290  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [560/985]  eta: 6:24:22  lr: 0.000100  g_loss: 4.3763 (4.3866)  d_loss: 1.8889 (1.8892)  gan_loss: 0.7555 (0.8527)  pix_loss: 0.3624 (0.3534)  time: 54.5210  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [570/985]  eta: 6:15:21  lr: 0.000100  g_loss: 4.5442 (4.3932)  d_loss: 1.8929 (1.8893)  gan_loss: 0.8687 (0.8546)  pix_loss: 0.3678 (0.3539)  time: 54.5181  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [580/985]  eta: 6:06:20  lr: 0.000100  g_loss: 4.4858 (4.3917)  d_loss: 1.9033 (1.8896)  gan_loss: 0.9664 (0.8565)  pix_loss: 0.3549 (0.3535)  time: 54.5241  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:17]  [590/985]  eta: 5:57:19  lr: 0.000100  g_loss: 4.1615 (4.3879)  d_loss: 1.9082 (1.8898)  gan_loss: 0.9737 (0.8592)  pix_loss: 0.3147 (0.3529)  time: 54.5302  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [600/985]  eta: 5:48:18  lr: 0.000100  g_loss: 4.1200 (4.3847)  d_loss: 1.9023 (1.8899)  gan_loss: 1.0091 (0.8614)  pix_loss: 0.3106 (0.3523)  time: 54.5273  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [610/985]  eta: 5:39:17  lr: 0.000100  g_loss: 4.3089 (4.3875)  d_loss: 1.8918 (1.8899)  gan_loss: 0.9864 (0.8635)  pix_loss: 0.3320 (0.3524)  time: 54.5248  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [620/985]  eta: 5:30:15  lr: 0.000100  g_loss: 4.5402 (4.3933)  d_loss: 1.8962 (1.8900)  gan_loss: 0.9913 (0.8656)  pix_loss: 0.3541 (0.3528)  time: 54.5234  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [630/985]  eta: 5:21:14  lr: 0.000100  g_loss: 4.5195 (4.3931)  d_loss: 1.8996 (1.8902)  gan_loss: 0.9786 (0.8672)  pix_loss: 0.3541 (0.3526)  time: 54.5067  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [640/985]  eta: 5:12:11  lr: 0.000100  g_loss: 4.2499 (4.3934)  d_loss: 1.8996 (1.8903)  gan_loss: 0.9629 (0.8687)  pix_loss: 0.3290 (0.3525)  time: 54.4524  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [650/985]  eta: 5:03:09  lr: 0.000100  g_loss: 4.2414 (4.3943)  d_loss: 1.9025 (1.8905)  gan_loss: 0.9580 (0.8701)  pix_loss: 0.3288 (0.3524)  time: 54.4132  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [660/985]  eta: 4:54:07  lr: 0.000100  g_loss: 4.3763 (4.3975)  d_loss: 1.9068 (1.8908)  gan_loss: 0.9633 (0.8715)  pix_loss: 0.3437 (0.3526)  time: 54.4124  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [670/985]  eta: 4:45:04  lr: 0.000100  g_loss: 4.2823 (4.3940)  d_loss: 1.9068 (1.8910)  gan_loss: 0.9482 (0.8724)  pix_loss: 0.3334 (0.3522)  time: 54.4124  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [680/985]  eta: 4:36:02  lr: 0.000100  g_loss: 4.1364 (4.3938)  d_loss: 1.8993 (1.8910)  gan_loss: 0.9169 (0.8731)  pix_loss: 0.3200 (0.3521)  time: 54.4117  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [690/985]  eta: 4:26:59  lr: 0.000100  g_loss: 4.1683 (4.3932)  d_loss: 1.8935 (1.8911)  gan_loss: 0.8982 (0.8734)  pix_loss: 0.3265 (0.3520)  time: 54.4260  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [700/985]  eta: 4:17:57  lr: 0.000100  g_loss: 4.1085 (4.3884)  d_loss: 1.8972 (1.8911)  gan_loss: 0.8865 (0.8735)  pix_loss: 0.3244 (0.3515)  time: 54.4849  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [710/985]  eta: 4:08:55  lr: 0.000100  g_loss: 4.0984 (4.3862)  d_loss: 1.8990 (1.8912)  gan_loss: 0.8641 (0.8730)  pix_loss: 0.3244 (0.3513)  time: 54.5277  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [720/985]  eta: 3:59:53  lr: 0.000100  g_loss: 4.0866 (4.3810)  d_loss: 1.9054 (1.8914)  gan_loss: 0.8522 (0.8730)  pix_loss: 0.3220 (0.3508)  time: 54.5263  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [730/985]  eta: 3:50:50  lr: 0.000100  g_loss: 3.8692 (4.3743)  d_loss: 1.9042 (1.8915)  gan_loss: 0.8575 (0.8725)  pix_loss: 0.3012 (0.3502)  time: 54.5269  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [740/985]  eta: 3:41:48  lr: 0.000100  g_loss: 3.8271 (4.3693)  d_loss: 1.9016 (1.8915)  gan_loss: 0.8051 (0.8713)  pix_loss: 0.3015 (0.3498)  time: 54.5314  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [750/985]  eta: 3:32:45  lr: 0.000100  g_loss: 3.7569 (4.3602)  d_loss: 1.8918 (1.8915)  gan_loss: 0.7935 (0.8703)  pix_loss: 0.2955 (0.3490)  time: 54.5369  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [760/985]  eta: 3:23:43  lr: 0.000100  g_loss: 3.7076 (4.3553)  d_loss: 1.8904 (1.8915)  gan_loss: 0.7923 (0.8691)  pix_loss: 0.2932 (0.3486)  time: 54.5411  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [770/985]  eta: 3:14:40  lr: 0.000100  g_loss: 3.7689 (4.3497)  d_loss: 1.8938 (1.8915)  gan_loss: 0.7778 (0.8679)  pix_loss: 0.2990 (0.3482)  time: 54.5395  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [780/985]  eta: 3:05:37  lr: 0.000100  g_loss: 3.8231 (4.3440)  d_loss: 1.8899 (1.8913)  gan_loss: 0.7771 (0.8668)  pix_loss: 0.3039 (0.3477)  time: 54.5344  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [790/985]  eta: 2:56:34  lr: 0.000100  g_loss: 4.0028 (4.3436)  d_loss: 1.8834 (1.8911)  gan_loss: 0.7852 (0.8658)  pix_loss: 0.3240 (0.3478)  time: 54.5345  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [800/985]  eta: 2:47:32  lr: 0.000100  g_loss: 4.1173 (4.3399)  d_loss: 1.8764 (1.8909)  gan_loss: 0.7852 (0.8647)  pix_loss: 0.3344 (0.3475)  time: 54.5307  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [810/985]  eta: 2:38:29  lr: 0.000100  g_loss: 3.9301 (4.3339)  d_loss: 1.8735 (1.8907)  gan_loss: 0.7728 (0.8635)  pix_loss: 0.3147 (0.3470)  time: 54.5345  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [820/985]  eta: 2:29:26  lr: 0.000100  g_loss: 3.8820 (4.3287)  d_loss: 1.8810 (1.8906)  gan_loss: 0.7697 (0.8624)  pix_loss: 0.3108 (0.3466)  time: 54.5461  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [830/985]  eta: 2:20:23  lr: 0.000100  g_loss: 3.8879 (4.3238)  d_loss: 1.8798 (1.8905)  gan_loss: 0.7758 (0.8614)  pix_loss: 0.3108 (0.3462)  time: 54.5449  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [840/985]  eta: 2:11:20  lr: 0.000100  g_loss: 3.8811 (4.3190)  d_loss: 1.8916 (1.8905)  gan_loss: 0.7792 (0.8603)  pix_loss: 0.3103 (0.3459)  time: 54.5346  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [850/985]  eta: 2:02:16  lr: 0.000100  g_loss: 3.8811 (4.3156)  d_loss: 1.8946 (1.8905)  gan_loss: 0.7647 (0.8592)  pix_loss: 0.3130 (0.3456)  time: 54.4813  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [860/985]  eta: 1:53:13  lr: 0.000100  g_loss: 3.9711 (4.3120)  d_loss: 1.8946 (1.8906)  gan_loss: 0.7709 (0.8583)  pix_loss: 0.3201 (0.3454)  time: 54.4255  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [870/985]  eta: 1:44:09  lr: 0.000100  g_loss: 3.9149 (4.3058)  d_loss: 1.8953 (1.8906)  gan_loss: 0.7732 (0.8573)  pix_loss: 0.3151 (0.3448)  time: 54.4150  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [880/985]  eta: 1:35:06  lr: 0.000100  g_loss: 3.8564 (4.3017)  d_loss: 1.8894 (1.8905)  gan_loss: 0.7635 (0.8563)  pix_loss: 0.3085 (0.3445)  time: 54.4503  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [890/985]  eta: 1:26:03  lr: 0.000100  g_loss: 3.8564 (4.2965)  d_loss: 1.8905 (1.8906)  gan_loss: 0.7604 (0.8552)  pix_loss: 0.3098 (0.3441)  time: 54.4812  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [900/985]  eta: 1:16:59  lr: 0.000100  g_loss: 3.7259 (4.2904)  d_loss: 1.8928 (1.8905)  gan_loss: 0.7590 (0.8542)  pix_loss: 0.2969 (0.3436)  time: 54.5036  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [910/985]  eta: 1:07:56  lr: 0.000100  g_loss: 3.6771 (4.2841)  d_loss: 1.8905 (1.8905)  gan_loss: 0.7574 (0.8531)  pix_loss: 0.2911 (0.3431)  time: 54.4638  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [920/985]  eta: 0:58:53  lr: 0.000100  g_loss: 3.5621 (4.2782)  d_loss: 1.8958 (1.8907)  gan_loss: 0.7896 (0.8529)  pix_loss: 0.2796 (0.3425)  time: 54.4195  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [930/985]  eta: 0:49:49  lr: 0.000100  g_loss: 3.7311 (4.2739)  d_loss: 1.9003 (1.8908)  gan_loss: 0.8183 (0.8523)  pix_loss: 0.2900 (0.3422)  time: 54.4173  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [940/985]  eta: 0:40:45  lr: 0.000100  g_loss: 3.8671 (4.2715)  d_loss: 1.8923 (1.8907)  gan_loss: 0.7808 (0.8514)  pix_loss: 0.3074 (0.3420)  time: 54.4006  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [950/985]  eta: 0:31:42  lr: 0.000100  g_loss: 4.2476 (4.2732)  d_loss: 1.8865 (1.8906)  gan_loss: 0.7754 (0.8508)  pix_loss: 0.3467 (0.3422)  time: 54.4047  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [960/985]  eta: 0:22:38  lr: 0.000100  g_loss: 4.2484 (4.2718)  d_loss: 1.8865 (1.8906)  gan_loss: 0.7754 (0.8499)  pix_loss: 0.3480 (0.3422)  time: 54.3946  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [970/985]  eta: 0:13:35  lr: 0.000100  g_loss: 3.9717 (4.2660)  d_loss: 1.8983 (1.8907)  gan_loss: 0.7690 (0.8491)  pix_loss: 0.3201 (0.3417)  time: 54.3949  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [980/985]  eta: 0:04:31  lr: 0.000100  g_loss: 3.5443 (4.2581)  d_loss: 1.9010 (1.8908)  gan_loss: 0.7723 (0.8484)  pix_loss: 0.2779 (0.3410)  time: 54.3991  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 3.4295 (4.2537)  d_loss: 1.9051 (1.8909)  gan_loss: 0.7776 (0.8482)  pix_loss: 0.2658 (0.3406)  time: 54.3986  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:17] Total time: 14:52:21 (54.3573 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 3.4295 (4.2537)  d_loss: 1.9051 (1.8909)  gan_loss: 0.7776 (0.8482)  pix_loss: 0.2658 (0.3406)\n",
      "Valid: [epoch:17]  [ 0/14]  eta: 0:01:39  L1_loss: 0.0066 (0.0066)  time: 7.0987  data: 0.3657  max mem: 38397\n",
      "Valid: [epoch:17]  [13/14]  eta: 0:00:06  L1_loss: 0.0070 (0.0073)  time: 6.4980  data: 0.0262  max mem: 38397\n",
      "Valid: [epoch:17] Total time: 0:01:31 (6.5039 s / it)\n",
      "Averaged stats: L1_loss: 0.0070 (0.0073)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_17_input_n_20.png\n",
      "Train: [epoch:18]  [  0/985]  eta: 15:19:03  lr: 0.000100  g_loss: 3.7058 (3.7058)  d_loss: 1.9032 (1.9032)  gan_loss: 0.7773 (0.7773)  pix_loss: 0.2929 (0.2929)  time: 55.9828  data: 1.4211  max mem: 38397\n",
      "Train: [epoch:18]  [ 10/985]  eta: 14:46:14  lr: 0.000100  g_loss: 3.4580 (3.5177)  d_loss: 1.8967 (1.8970)  gan_loss: 0.7707 (0.7690)  pix_loss: 0.2692 (0.2749)  time: 54.5375  data: 0.1294  max mem: 38397\n",
      "Train: [epoch:18]  [ 20/985]  eta: 14:36:02  lr: 0.000100  g_loss: 3.6043 (3.6256)  d_loss: 1.8933 (1.8897)  gan_loss: 0.7707 (0.7712)  pix_loss: 0.2816 (0.2854)  time: 54.3935  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [ 30/985]  eta: 14:26:37  lr: 0.000100  g_loss: 4.0084 (3.8780)  d_loss: 1.8696 (1.8814)  gan_loss: 0.7652 (0.7689)  pix_loss: 0.3226 (0.3109)  time: 54.3975  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [ 40/985]  eta: 14:16:17  lr: 0.000100  g_loss: 4.2360 (3.9249)  d_loss: 1.8696 (1.8828)  gan_loss: 0.7667 (0.7718)  pix_loss: 0.3466 (0.3153)  time: 54.2617  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [ 50/985]  eta: 14:06:19  lr: 0.000100  g_loss: 3.9618 (3.9389)  d_loss: 1.8990 (1.8859)  gan_loss: 0.8102 (0.7824)  pix_loss: 0.3132 (0.3156)  time: 54.0967  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [ 60/985]  eta: 13:56:38  lr: 0.000100  g_loss: 3.9498 (3.9613)  d_loss: 1.8976 (1.8872)  gan_loss: 0.8102 (0.7854)  pix_loss: 0.3140 (0.3176)  time: 54.0640  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [ 70/985]  eta: 13:47:07  lr: 0.000100  g_loss: 3.8948 (3.9284)  d_loss: 1.8863 (1.8874)  gan_loss: 0.7930 (0.7837)  pix_loss: 0.3075 (0.3145)  time: 54.0549  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [ 80/985]  eta: 13:37:45  lr: 0.000100  g_loss: 3.6504 (3.9000)  d_loss: 1.8963 (1.8891)  gan_loss: 0.7913 (0.7869)  pix_loss: 0.2874 (0.3113)  time: 54.0553  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [ 90/985]  eta: 13:28:27  lr: 0.000100  g_loss: 3.5908 (3.8683)  d_loss: 1.8987 (1.8892)  gan_loss: 0.8056 (0.7876)  pix_loss: 0.2803 (0.3081)  time: 54.0588  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [100/985]  eta: 13:19:13  lr: 0.000100  g_loss: 3.5905 (3.8453)  d_loss: 1.8999 (1.8905)  gan_loss: 0.7989 (0.7883)  pix_loss: 0.2803 (0.3057)  time: 54.0594  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [110/985]  eta: 13:10:01  lr: 0.000100  g_loss: 3.5755 (3.8186)  d_loss: 1.9017 (1.8915)  gan_loss: 0.8016 (0.7902)  pix_loss: 0.2802 (0.3028)  time: 54.0585  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [120/985]  eta: 13:00:51  lr: 0.000100  g_loss: 3.4926 (3.8008)  d_loss: 1.8929 (1.8913)  gan_loss: 0.7843 (0.7890)  pix_loss: 0.2709 (0.3012)  time: 54.0544  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [130/985]  eta: 12:51:43  lr: 0.000100  g_loss: 3.5606 (3.7830)  d_loss: 1.8913 (1.8912)  gan_loss: 0.7694 (0.7870)  pix_loss: 0.2797 (0.2996)  time: 54.0586  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [140/985]  eta: 12:42:35  lr: 0.000100  g_loss: 3.4993 (3.7591)  d_loss: 1.8961 (1.8917)  gan_loss: 0.7679 (0.7859)  pix_loss: 0.2722 (0.2973)  time: 54.0620  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [150/985]  eta: 12:33:32  lr: 0.000100  g_loss: 3.4976 (3.7475)  d_loss: 1.8950 (1.8915)  gan_loss: 0.7753 (0.7855)  pix_loss: 0.2719 (0.2962)  time: 54.0861  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [160/985]  eta: 12:24:43  lr: 0.000100  g_loss: 3.6109 (3.7434)  d_loss: 1.8918 (1.8916)  gan_loss: 0.7741 (0.7844)  pix_loss: 0.2821 (0.2959)  time: 54.2557  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [170/985]  eta: 12:15:53  lr: 0.000100  g_loss: 3.7519 (3.7471)  d_loss: 1.8933 (1.8914)  gan_loss: 0.7707 (0.7834)  pix_loss: 0.2975 (0.2964)  time: 54.3989  data: 0.0001  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [180/985]  eta: 12:07:01  lr: 0.000100  g_loss: 3.9455 (3.7620)  d_loss: 1.8951 (1.8919)  gan_loss: 0.7663 (0.7825)  pix_loss: 0.3176 (0.2980)  time: 54.4023  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [190/985]  eta: 11:58:08  lr: 0.000100  g_loss: 3.6832 (3.7533)  d_loss: 1.8993 (1.8921)  gan_loss: 0.7657 (0.7820)  pix_loss: 0.2883 (0.2971)  time: 54.4023  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [200/985]  eta: 11:49:14  lr: 0.000100  g_loss: 3.6832 (3.7601)  d_loss: 1.8983 (1.8922)  gan_loss: 0.7762 (0.7817)  pix_loss: 0.2883 (0.2978)  time: 54.4036  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [210/985]  eta: 11:40:19  lr: 0.000100  g_loss: 3.7424 (3.7573)  d_loss: 1.8999 (1.8926)  gan_loss: 0.7790 (0.7817)  pix_loss: 0.2971 (0.2976)  time: 54.4032  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [220/985]  eta: 11:31:23  lr: 0.000100  g_loss: 3.6767 (3.7539)  d_loss: 1.8971 (1.8926)  gan_loss: 0.7711 (0.7807)  pix_loss: 0.2886 (0.2973)  time: 54.3994  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [230/985]  eta: 11:22:27  lr: 0.000100  g_loss: 3.6097 (3.7464)  d_loss: 1.8952 (1.8926)  gan_loss: 0.7687 (0.7805)  pix_loss: 0.2843 (0.2966)  time: 54.4026  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [240/985]  eta: 11:13:30  lr: 0.000100  g_loss: 3.3914 (3.7311)  d_loss: 1.8980 (1.8928)  gan_loss: 0.7688 (0.7798)  pix_loss: 0.2633 (0.2951)  time: 54.4096  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [250/985]  eta: 11:04:33  lr: 0.000100  g_loss: 3.7222 (3.7372)  d_loss: 1.8973 (1.8926)  gan_loss: 0.7670 (0.7798)  pix_loss: 0.2940 (0.2957)  time: 54.4136  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [260/985]  eta: 10:55:35  lr: 0.000100  g_loss: 3.7628 (3.7365)  d_loss: 1.8973 (1.8931)  gan_loss: 0.7917 (0.7806)  pix_loss: 0.2980 (0.2956)  time: 54.4117  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [270/985]  eta: 10:46:36  lr: 0.000100  g_loss: 3.8108 (3.7441)  d_loss: 1.8997 (1.8931)  gan_loss: 0.8022 (0.7814)  pix_loss: 0.2999 (0.2963)  time: 54.4104  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [280/985]  eta: 10:37:37  lr: 0.000100  g_loss: 3.9240 (3.7625)  d_loss: 1.8834 (1.8921)  gan_loss: 0.7879 (0.7811)  pix_loss: 0.3142 (0.2981)  time: 54.4119  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [290/985]  eta: 10:28:38  lr: 0.000100  g_loss: 3.8878 (3.7646)  d_loss: 1.8834 (1.8921)  gan_loss: 0.7736 (0.7810)  pix_loss: 0.3117 (0.2984)  time: 54.4141  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [300/985]  eta: 10:19:39  lr: 0.000100  g_loss: 3.8636 (3.7746)  d_loss: 1.8946 (1.8923)  gan_loss: 0.7816 (0.7812)  pix_loss: 0.3093 (0.2993)  time: 54.4176  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [310/985]  eta: 10:10:39  lr: 0.000100  g_loss: 4.0224 (3.7923)  d_loss: 1.8914 (1.8920)  gan_loss: 0.7690 (0.7806)  pix_loss: 0.3254 (0.3012)  time: 54.4142  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [320/985]  eta: 10:01:37  lr: 0.000100  g_loss: 3.9576 (3.7926)  d_loss: 1.8798 (1.8915)  gan_loss: 0.7566 (0.7798)  pix_loss: 0.3194 (0.3013)  time: 54.3726  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [330/985]  eta: 9:52:31  lr: 0.000100  g_loss: 3.8383 (3.7990)  d_loss: 1.8831 (1.8912)  gan_loss: 0.7559 (0.7791)  pix_loss: 0.3084 (0.3020)  time: 54.2142  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [340/985]  eta: 9:43:24  lr: 0.000100  g_loss: 3.7356 (3.7937)  d_loss: 1.8905 (1.8914)  gan_loss: 0.7603 (0.7787)  pix_loss: 0.2969 (0.3015)  time: 54.0857  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [350/985]  eta: 9:34:18  lr: 0.000100  g_loss: 3.6073 (3.7900)  d_loss: 1.8944 (1.8912)  gan_loss: 0.7645 (0.7784)  pix_loss: 0.2843 (0.3012)  time: 54.0723  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [360/985]  eta: 9:25:12  lr: 0.000100  g_loss: 3.6146 (3.7890)  d_loss: 1.8928 (1.8911)  gan_loss: 0.7612 (0.7778)  pix_loss: 0.2855 (0.3011)  time: 54.0694  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [370/985]  eta: 9:16:06  lr: 0.000100  g_loss: 3.5622 (3.7834)  d_loss: 1.8955 (1.8914)  gan_loss: 0.7635 (0.7822)  pix_loss: 0.2745 (0.3001)  time: 54.0744  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [380/985]  eta: 9:07:01  lr: 0.000100  g_loss: 4.0125 (3.7965)  d_loss: 1.9161 (1.8921)  gan_loss: 1.2058 (0.7949)  pix_loss: 0.2777 (0.3002)  time: 54.0744  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [390/985]  eta: 8:57:55  lr: 0.000100  g_loss: 4.2480 (3.8127)  d_loss: 1.9181 (1.8928)  gan_loss: 1.2953 (0.8084)  pix_loss: 0.2937 (0.3004)  time: 54.0696  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [400/985]  eta: 8:48:50  lr: 0.000100  g_loss: 4.2480 (3.8302)  d_loss: 1.9201 (1.8935)  gan_loss: 1.3326 (0.8217)  pix_loss: 0.2937 (0.3008)  time: 54.0634  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [410/985]  eta: 8:39:46  lr: 0.000100  g_loss: 4.2448 (3.8399)  d_loss: 1.9199 (1.8941)  gan_loss: 1.3336 (0.8338)  pix_loss: 0.2874 (0.3006)  time: 54.0666  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [420/985]  eta: 8:30:42  lr: 0.000100  g_loss: 4.1618 (3.8471)  d_loss: 1.9171 (1.8946)  gan_loss: 1.3040 (0.8451)  pix_loss: 0.2857 (0.3002)  time: 54.0995  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [430/985]  eta: 8:21:38  lr: 0.000100  g_loss: 4.2702 (3.8626)  d_loss: 1.9165 (1.8952)  gan_loss: 1.2958 (0.8554)  pix_loss: 0.3003 (0.3007)  time: 54.1167  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [440/985]  eta: 8:12:34  lr: 0.000100  g_loss: 4.3824 (3.8751)  d_loss: 1.9146 (1.8956)  gan_loss: 1.2536 (0.8640)  pix_loss: 0.3080 (0.3011)  time: 54.0911  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [450/985]  eta: 8:03:29  lr: 0.000100  g_loss: 4.2717 (3.8849)  d_loss: 1.9165 (1.8960)  gan_loss: 1.2429 (0.8720)  pix_loss: 0.3044 (0.3013)  time: 54.0755  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [460/985]  eta: 7:54:26  lr: 0.000100  g_loss: 4.4461 (3.8989)  d_loss: 1.9118 (1.8963)  gan_loss: 1.1647 (0.8779)  pix_loss: 0.3231 (0.3021)  time: 54.0789  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [470/985]  eta: 7:45:22  lr: 0.000100  g_loss: 4.2142 (3.9049)  d_loss: 1.9117 (1.8966)  gan_loss: 1.1293 (0.8830)  pix_loss: 0.3080 (0.3022)  time: 54.0761  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [480/985]  eta: 7:36:18  lr: 0.000100  g_loss: 4.0769 (3.9085)  d_loss: 1.9157 (1.8970)  gan_loss: 1.0781 (0.8869)  pix_loss: 0.2938 (0.3022)  time: 54.0738  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [490/985]  eta: 7:27:15  lr: 0.000100  g_loss: 3.9471 (3.9062)  d_loss: 1.9157 (1.8973)  gan_loss: 1.0676 (0.8905)  pix_loss: 0.2858 (0.3016)  time: 54.0777  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [500/985]  eta: 7:18:11  lr: 0.000100  g_loss: 3.6569 (3.8987)  d_loss: 1.9167 (1.8978)  gan_loss: 1.0571 (0.8937)  pix_loss: 0.2605 (0.3005)  time: 54.0820  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [510/985]  eta: 7:09:08  lr: 0.000100  g_loss: 3.6980 (3.9093)  d_loss: 1.9074 (1.8979)  gan_loss: 1.0157 (0.8953)  pix_loss: 0.2654 (0.3014)  time: 54.0821  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [520/985]  eta: 7:00:05  lr: 0.000100  g_loss: 4.1459 (3.9133)  d_loss: 1.9059 (1.8982)  gan_loss: 1.0050 (0.8979)  pix_loss: 0.3108 (0.3015)  time: 54.1244  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [530/985]  eta: 6:51:02  lr: 0.000100  g_loss: 4.0080 (3.9150)  d_loss: 1.9135 (1.8985)  gan_loss: 1.0088 (0.8994)  pix_loss: 0.2997 (0.3016)  time: 54.1231  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [540/985]  eta: 6:41:59  lr: 0.000100  g_loss: 3.9432 (3.9166)  d_loss: 1.9160 (1.8988)  gan_loss: 0.9864 (0.9014)  pix_loss: 0.2978 (0.3015)  time: 54.0798  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [550/985]  eta: 6:32:56  lr: 0.000100  g_loss: 3.8801 (3.9121)  d_loss: 1.9137 (1.8991)  gan_loss: 0.9975 (0.9031)  pix_loss: 0.2873 (0.3009)  time: 54.0836  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [560/985]  eta: 6:23:53  lr: 0.000100  g_loss: 3.5023 (3.9040)  d_loss: 1.9131 (1.8993)  gan_loss: 0.9906 (0.9045)  pix_loss: 0.2550 (0.3000)  time: 54.0863  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [570/985]  eta: 6:14:51  lr: 0.000100  g_loss: 3.3902 (3.8950)  d_loss: 1.9116 (1.8996)  gan_loss: 0.9588 (0.9054)  pix_loss: 0.2431 (0.2990)  time: 54.0811  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [580/985]  eta: 6:05:48  lr: 0.000100  g_loss: 3.3139 (3.8865)  d_loss: 1.9118 (1.8998)  gan_loss: 0.9352 (0.9057)  pix_loss: 0.2406 (0.2981)  time: 54.0715  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [590/985]  eta: 5:56:45  lr: 0.000100  g_loss: 3.4134 (3.8824)  d_loss: 1.9108 (1.8999)  gan_loss: 0.9055 (0.9053)  pix_loss: 0.2574 (0.2977)  time: 54.0737  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [600/985]  eta: 5:47:42  lr: 0.000100  g_loss: 3.5616 (3.8794)  d_loss: 1.9061 (1.9000)  gan_loss: 0.8611 (0.9045)  pix_loss: 0.2712 (0.2975)  time: 54.0741  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [610/985]  eta: 5:38:40  lr: 0.000100  g_loss: 3.6328 (3.8762)  d_loss: 1.9073 (1.9002)  gan_loss: 0.8453 (0.9034)  pix_loss: 0.2772 (0.2973)  time: 54.0758  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [620/985]  eta: 5:29:38  lr: 0.000100  g_loss: 3.3643 (3.8639)  d_loss: 1.9090 (1.9003)  gan_loss: 0.8302 (0.9021)  pix_loss: 0.2540 (0.2962)  time: 54.1151  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [630/985]  eta: 5:20:35  lr: 0.000100  g_loss: 3.2179 (3.8607)  d_loss: 1.9058 (1.9003)  gan_loss: 0.8217 (0.9010)  pix_loss: 0.2400 (0.2960)  time: 54.1227  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [640/985]  eta: 5:11:33  lr: 0.000100  g_loss: 3.6037 (3.8582)  d_loss: 1.9022 (1.9003)  gan_loss: 0.8118 (0.8994)  pix_loss: 0.2768 (0.2959)  time: 54.0891  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [650/985]  eta: 5:02:31  lr: 0.000100  g_loss: 3.5096 (3.8550)  d_loss: 1.9027 (1.9003)  gan_loss: 0.7973 (0.8978)  pix_loss: 0.2710 (0.2957)  time: 54.0881  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:18]  [660/985]  eta: 4:53:28  lr: 0.000100  g_loss: 3.5336 (3.8570)  d_loss: 1.9027 (1.9002)  gan_loss: 0.7873 (0.8960)  pix_loss: 0.2743 (0.2961)  time: 54.0946  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [670/985]  eta: 4:44:26  lr: 0.000100  g_loss: 3.6265 (3.8545)  d_loss: 1.9013 (1.9003)  gan_loss: 0.7885 (0.8946)  pix_loss: 0.2825 (0.2960)  time: 54.0947  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [680/985]  eta: 4:35:24  lr: 0.000100  g_loss: 3.6143 (3.8524)  d_loss: 1.9023 (1.9003)  gan_loss: 0.8027 (0.8944)  pix_loss: 0.2762 (0.2958)  time: 54.0958  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [690/985]  eta: 4:26:23  lr: 0.000100  g_loss: 3.6225 (3.8504)  d_loss: 1.9046 (1.9004)  gan_loss: 0.9583 (0.8957)  pix_loss: 0.2645 (0.2955)  time: 54.1740  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [700/985]  eta: 4:17:20  lr: 0.000100  g_loss: 3.6132 (3.8478)  d_loss: 1.9038 (1.9004)  gan_loss: 0.9724 (0.8964)  pix_loss: 0.2628 (0.2951)  time: 54.1629  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [710/985]  eta: 4:08:18  lr: 0.000100  g_loss: 3.6306 (3.8466)  d_loss: 1.9020 (1.9004)  gan_loss: 0.9441 (0.8972)  pix_loss: 0.2686 (0.2949)  time: 54.0845  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [720/985]  eta: 3:59:16  lr: 0.000100  g_loss: 3.6934 (3.8460)  d_loss: 1.9098 (1.9006)  gan_loss: 0.9481 (0.8979)  pix_loss: 0.2758 (0.2948)  time: 54.0284  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [730/985]  eta: 3:50:14  lr: 0.000100  g_loss: 3.6300 (3.8434)  d_loss: 1.9084 (1.9006)  gan_loss: 0.9196 (0.8981)  pix_loss: 0.2708 (0.2945)  time: 54.0692  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [740/985]  eta: 3:41:12  lr: 0.000100  g_loss: 3.6526 (3.8409)  d_loss: 1.9011 (1.9006)  gan_loss: 0.8692 (0.8974)  pix_loss: 0.2762 (0.2944)  time: 54.1162  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [750/985]  eta: 3:32:10  lr: 0.000100  g_loss: 3.5874 (3.8371)  d_loss: 1.9003 (1.9006)  gan_loss: 0.8239 (0.8962)  pix_loss: 0.2740 (0.2941)  time: 54.0612  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [760/985]  eta: 3:23:08  lr: 0.000100  g_loss: 3.4438 (3.8303)  d_loss: 1.8968 (1.9005)  gan_loss: 0.8034 (0.8950)  pix_loss: 0.2633 (0.2935)  time: 54.0627  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [770/985]  eta: 3:14:06  lr: 0.000100  g_loss: 3.4438 (3.8291)  d_loss: 1.8941 (1.9004)  gan_loss: 0.8034 (0.8938)  pix_loss: 0.2639 (0.2935)  time: 54.0650  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [780/985]  eta: 3:05:04  lr: 0.000100  g_loss: 3.4925 (3.8244)  d_loss: 1.8993 (1.9004)  gan_loss: 0.7887 (0.8924)  pix_loss: 0.2689 (0.2932)  time: 54.0656  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [790/985]  eta: 2:56:02  lr: 0.000100  g_loss: 3.5064 (3.8240)  d_loss: 1.8947 (1.9003)  gan_loss: 0.7941 (0.8914)  pix_loss: 0.2715 (0.2933)  time: 54.0632  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [800/985]  eta: 2:47:00  lr: 0.000100  g_loss: 3.5410 (3.8211)  d_loss: 1.8874 (1.9001)  gan_loss: 0.8080 (0.8903)  pix_loss: 0.2719 (0.2931)  time: 54.0688  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [810/985]  eta: 2:37:58  lr: 0.000100  g_loss: 3.7347 (3.8224)  d_loss: 1.8876 (1.9000)  gan_loss: 0.8275 (0.8908)  pix_loss: 0.2850 (0.2932)  time: 54.0671  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [820/985]  eta: 2:28:56  lr: 0.000100  g_loss: 4.1637 (3.8288)  d_loss: 1.8910 (1.8998)  gan_loss: 1.0182 (0.8928)  pix_loss: 0.3122 (0.2936)  time: 54.0644  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [830/985]  eta: 2:19:55  lr: 0.000100  g_loss: 4.2827 (3.8347)  d_loss: 1.8955 (1.8998)  gan_loss: 1.0814 (0.8956)  pix_loss: 0.3166 (0.2939)  time: 54.1344  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [840/985]  eta: 2:10:53  lr: 0.000100  g_loss: 4.2757 (3.8400)  d_loss: 1.8965 (1.8997)  gan_loss: 1.1096 (0.8980)  pix_loss: 0.3168 (0.2942)  time: 54.1350  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [850/985]  eta: 2:01:51  lr: 0.000100  g_loss: 4.3725 (3.8461)  d_loss: 1.8951 (1.8997)  gan_loss: 1.0951 (0.9003)  pix_loss: 0.3288 (0.2946)  time: 54.0671  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [860/985]  eta: 1:52:49  lr: 0.000100  g_loss: 4.0929 (3.8483)  d_loss: 1.9003 (1.8997)  gan_loss: 1.0951 (0.9026)  pix_loss: 0.2999 (0.2946)  time: 54.0668  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [870/985]  eta: 1:43:48  lr: 0.000100  g_loss: 4.0128 (3.8497)  d_loss: 1.9030 (1.8998)  gan_loss: 1.0933 (0.9048)  pix_loss: 0.2924 (0.2945)  time: 54.0689  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [880/985]  eta: 1:34:46  lr: 0.000100  g_loss: 3.8166 (3.8497)  d_loss: 1.9085 (1.8998)  gan_loss: 1.0827 (0.9068)  pix_loss: 0.2733 (0.2943)  time: 54.0694  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [890/985]  eta: 1:25:44  lr: 0.000100  g_loss: 3.8166 (3.8498)  d_loss: 1.9103 (1.8999)  gan_loss: 1.0795 (0.9088)  pix_loss: 0.2733 (0.2941)  time: 54.0699  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [900/985]  eta: 1:16:43  lr: 0.000100  g_loss: 3.7906 (3.8484)  d_loss: 1.9103 (1.9000)  gan_loss: 1.0867 (0.9107)  pix_loss: 0.2700 (0.2938)  time: 54.0701  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [910/985]  eta: 1:07:41  lr: 0.000100  g_loss: 3.5905 (3.8468)  d_loss: 1.9088 (1.9001)  gan_loss: 1.0623 (0.9123)  pix_loss: 0.2560 (0.2935)  time: 54.0674  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [920/985]  eta: 0:58:39  lr: 0.000100  g_loss: 3.8535 (3.8502)  d_loss: 1.8963 (1.8999)  gan_loss: 1.0543 (0.9137)  pix_loss: 0.2814 (0.2936)  time: 54.0759  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [930/985]  eta: 0:49:38  lr: 0.000100  g_loss: 4.5837 (3.8601)  d_loss: 1.8902 (1.8998)  gan_loss: 0.9897 (0.9145)  pix_loss: 0.3597 (0.2946)  time: 54.0950  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [940/985]  eta: 0:40:36  lr: 0.000100  g_loss: 4.4766 (3.8619)  d_loss: 1.9056 (1.8999)  gan_loss: 0.9897 (0.9155)  pix_loss: 0.3414 (0.2946)  time: 54.0889  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [950/985]  eta: 0:31:35  lr: 0.000100  g_loss: 3.9613 (3.8606)  d_loss: 1.9049 (1.8998)  gan_loss: 0.9997 (0.9163)  pix_loss: 0.2944 (0.2944)  time: 54.0718  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [960/985]  eta: 0:22:33  lr: 0.000100  g_loss: 3.7996 (3.8609)  d_loss: 1.9041 (1.8999)  gan_loss: 0.9693 (0.9166)  pix_loss: 0.2833 (0.2944)  time: 54.0690  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [970/985]  eta: 0:13:32  lr: 0.000100  g_loss: 3.7636 (3.8573)  d_loss: 1.9057 (1.8999)  gan_loss: 0.9320 (0.9169)  pix_loss: 0.2833 (0.2940)  time: 54.0723  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [980/985]  eta: 0:04:30  lr: 0.000100  g_loss: 3.4340 (3.8540)  d_loss: 1.9054 (1.8999)  gan_loss: 0.9344 (0.9170)  pix_loss: 0.2504 (0.2937)  time: 54.0806  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 3.5196 (3.8540)  d_loss: 1.9054 (1.8999)  gan_loss: 0.9329 (0.9169)  pix_loss: 0.2544 (0.2937)  time: 54.0827  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:18] Total time: 14:48:56 (54.1490 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 3.5196 (3.8540)  d_loss: 1.9054 (1.8999)  gan_loss: 0.9329 (0.9169)  pix_loss: 0.2544 (0.2937)\n",
      "Valid: [epoch:18]  [ 0/14]  eta: 0:01:34  L1_loss: 0.0108 (0.0108)  time: 6.7593  data: 0.3919  max mem: 38397\n",
      "Valid: [epoch:18]  [13/14]  eta: 0:00:06  L1_loss: 0.0099 (0.0102)  time: 6.2976  data: 0.0281  max mem: 38397\n",
      "Valid: [epoch:18] Total time: 0:01:28 (6.3053 s / it)\n",
      "Averaged stats: L1_loss: 0.0099 (0.0102)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_18_input_n_20.png\n",
      "Train: [epoch:19]  [  0/985]  eta: 15:08:32  lr: 0.000100  g_loss: 3.4986 (3.4986)  d_loss: 1.8980 (1.8980)  gan_loss: 0.8680 (0.8680)  pix_loss: 0.2631 (0.2631)  time: 55.3423  data: 1.2229  max mem: 38397\n",
      "Train: [epoch:19]  [ 10/985]  eta: 14:40:31  lr: 0.000100  g_loss: 3.6142 (3.6129)  d_loss: 1.8980 (1.8956)  gan_loss: 0.8831 (0.8763)  pix_loss: 0.2730 (0.2737)  time: 54.1865  data: 0.1113  max mem: 38397\n",
      "Train: [epoch:19]  [ 20/985]  eta: 14:30:39  lr: 0.000100  g_loss: 3.6283 (3.6784)  d_loss: 1.8927 (1.8934)  gan_loss: 0.8622 (0.8630)  pix_loss: 0.2756 (0.2815)  time: 54.0742  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [ 30/985]  eta: 14:21:21  lr: 0.000100  g_loss: 3.8453 (3.7347)  d_loss: 1.8903 (1.8914)  gan_loss: 0.8331 (0.8466)  pix_loss: 0.3031 (0.2888)  time: 54.0791  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [ 40/985]  eta: 14:12:56  lr: 0.000100  g_loss: 3.8451 (3.7731)  d_loss: 1.8921 (1.8919)  gan_loss: 0.8362 (0.8460)  pix_loss: 0.3033 (0.2927)  time: 54.1758  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [ 50/985]  eta: 14:03:39  lr: 0.000100  g_loss: 3.7727 (3.7725)  d_loss: 1.9006 (1.8940)  gan_loss: 0.8368 (0.8410)  pix_loss: 0.2935 (0.2931)  time: 54.1727  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [ 60/985]  eta: 13:54:29  lr: 0.000100  g_loss: 3.5521 (3.7322)  d_loss: 1.9027 (1.8944)  gan_loss: 0.8135 (0.8353)  pix_loss: 0.2731 (0.2897)  time: 54.0767  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [ 70/985]  eta: 13:45:21  lr: 0.000100  g_loss: 3.7052 (3.7815)  d_loss: 1.8924 (1.8926)  gan_loss: 0.8014 (0.8313)  pix_loss: 0.2908 (0.2950)  time: 54.0778  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [ 80/985]  eta: 13:36:15  lr: 0.000100  g_loss: 4.1063 (3.8255)  d_loss: 1.8875 (1.8929)  gan_loss: 0.8178 (0.8312)  pix_loss: 0.3273 (0.2994)  time: 54.0771  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:19]  [ 90/985]  eta: 13:27:10  lr: 0.000100  g_loss: 3.8672 (3.8257)  d_loss: 1.8992 (1.8937)  gan_loss: 0.8707 (0.8368)  pix_loss: 0.2992 (0.2989)  time: 54.0795  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [100/985]  eta: 13:18:06  lr: 0.000100  g_loss: 3.5906 (3.7908)  d_loss: 1.8992 (1.8942)  gan_loss: 0.8683 (0.8352)  pix_loss: 0.2772 (0.2956)  time: 54.0816  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [110/985]  eta: 13:09:02  lr: 0.000100  g_loss: 3.4251 (3.7550)  d_loss: 1.8989 (1.8947)  gan_loss: 0.8104 (0.8330)  pix_loss: 0.2606 (0.2922)  time: 54.0760  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [120/985]  eta: 12:59:59  lr: 0.000100  g_loss: 3.4251 (3.7487)  d_loss: 1.8962 (1.8942)  gan_loss: 0.8028 (0.8301)  pix_loss: 0.2606 (0.2919)  time: 54.0703  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [130/985]  eta: 12:50:56  lr: 0.000100  g_loss: 3.4555 (3.7269)  d_loss: 1.8912 (1.8942)  gan_loss: 0.7970 (0.8275)  pix_loss: 0.2669 (0.2899)  time: 54.0717  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [140/985]  eta: 12:42:05  lr: 0.000100  g_loss: 3.4391 (3.7013)  d_loss: 1.8955 (1.8945)  gan_loss: 0.7948 (0.8251)  pix_loss: 0.2660 (0.2876)  time: 54.1751  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [150/985]  eta: 12:33:02  lr: 0.000100  g_loss: 3.1685 (3.6615)  d_loss: 1.8994 (1.8949)  gan_loss: 0.7962 (0.8233)  pix_loss: 0.2371 (0.2838)  time: 54.1786  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [160/985]  eta: 12:23:59  lr: 0.000100  g_loss: 3.1543 (3.6277)  d_loss: 1.9001 (1.8950)  gan_loss: 0.8012 (0.8221)  pix_loss: 0.2337 (0.2806)  time: 54.0783  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [170/985]  eta: 12:14:57  lr: 0.000100  g_loss: 3.2539 (3.6186)  d_loss: 1.8988 (1.8952)  gan_loss: 0.7985 (0.8205)  pix_loss: 0.2446 (0.2798)  time: 54.0800  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [180/985]  eta: 12:05:54  lr: 0.000100  g_loss: 3.4081 (3.6060)  d_loss: 1.9003 (1.8953)  gan_loss: 0.7963 (0.8194)  pix_loss: 0.2612 (0.2787)  time: 54.0789  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [190/985]  eta: 11:56:52  lr: 0.000100  g_loss: 3.3025 (3.5922)  d_loss: 1.8925 (1.8949)  gan_loss: 0.7964 (0.8188)  pix_loss: 0.2468 (0.2773)  time: 54.0722  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [200/985]  eta: 11:47:50  lr: 0.000100  g_loss: 3.2757 (3.5837)  d_loss: 1.8927 (1.8950)  gan_loss: 0.8226 (0.8195)  pix_loss: 0.2446 (0.2764)  time: 54.0721  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [210/985]  eta: 11:38:48  lr: 0.000100  g_loss: 3.4431 (3.5789)  d_loss: 1.8949 (1.8947)  gan_loss: 0.8274 (0.8195)  pix_loss: 0.2626 (0.2759)  time: 54.0751  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [220/985]  eta: 11:29:46  lr: 0.000100  g_loss: 3.4431 (3.5719)  d_loss: 1.8904 (1.8945)  gan_loss: 0.8200 (0.8189)  pix_loss: 0.2627 (0.2753)  time: 54.0735  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [230/985]  eta: 11:20:44  lr: 0.000100  g_loss: 3.4916 (3.5728)  d_loss: 1.8855 (1.8940)  gan_loss: 0.7992 (0.8179)  pix_loss: 0.2653 (0.2755)  time: 54.0680  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [240/985]  eta: 11:11:45  lr: 0.000100  g_loss: 3.5829 (3.5744)  d_loss: 1.8908 (1.8939)  gan_loss: 0.7947 (0.8170)  pix_loss: 0.2812 (0.2757)  time: 54.1129  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [250/985]  eta: 11:02:43  lr: 0.000100  g_loss: 3.5107 (3.5708)  d_loss: 1.8927 (1.8936)  gan_loss: 0.7989 (0.8161)  pix_loss: 0.2707 (0.2755)  time: 54.1165  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [260/985]  eta: 10:53:41  lr: 0.000100  g_loss: 3.3864 (3.5576)  d_loss: 1.8931 (1.8936)  gan_loss: 0.8008 (0.8154)  pix_loss: 0.2587 (0.2742)  time: 54.0744  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [270/985]  eta: 10:44:39  lr: 0.000100  g_loss: 3.3696 (3.5596)  d_loss: 1.8964 (1.8934)  gan_loss: 0.8020 (0.8153)  pix_loss: 0.2551 (0.2744)  time: 54.0730  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [280/985]  eta: 10:35:38  lr: 0.000100  g_loss: 3.3788 (3.5548)  d_loss: 1.8886 (1.8929)  gan_loss: 0.8014 (0.8146)  pix_loss: 0.2585 (0.2740)  time: 54.0760  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [290/985]  eta: 10:26:36  lr: 0.000100  g_loss: 3.4197 (3.5572)  d_loss: 1.8893 (1.8929)  gan_loss: 0.8065 (0.8153)  pix_loss: 0.2585 (0.2742)  time: 54.0759  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [300/985]  eta: 10:17:35  lr: 0.000100  g_loss: 3.5621 (3.5632)  d_loss: 1.9001 (1.8932)  gan_loss: 0.8476 (0.8164)  pix_loss: 0.2733 (0.2747)  time: 54.0694  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [310/985]  eta: 10:08:33  lr: 0.000100  g_loss: 3.5621 (3.5639)  d_loss: 1.9012 (1.8932)  gan_loss: 0.8229 (0.8155)  pix_loss: 0.2714 (0.2748)  time: 54.0681  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [320/985]  eta: 9:59:32  lr: 0.000100  g_loss: 3.5248 (3.5604)  d_loss: 1.8956 (1.8932)  gan_loss: 0.8043 (0.8156)  pix_loss: 0.2685 (0.2745)  time: 54.0704  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [330/985]  eta: 9:50:30  lr: 0.000100  g_loss: 3.2937 (3.5500)  d_loss: 1.8963 (1.8934)  gan_loss: 0.8043 (0.8149)  pix_loss: 0.2507 (0.2735)  time: 54.0709  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [340/985]  eta: 9:41:30  lr: 0.000100  g_loss: 3.3019 (3.5463)  d_loss: 1.8943 (1.8933)  gan_loss: 0.7951 (0.8146)  pix_loss: 0.2507 (0.2732)  time: 54.1018  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:19]  [350/985]  eta: 9:32:29  lr: 0.000100  g_loss: 3.4687 (3.5452)  d_loss: 1.8892 (1.8932)  gan_loss: 0.7979 (0.8138)  pix_loss: 0.2671 (0.2731)  time: 54.1052  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [360/985]  eta: 9:23:28  lr: 0.000100  g_loss: 3.5055 (3.5456)  d_loss: 1.8867 (1.8931)  gan_loss: 0.8147 (0.8151)  pix_loss: 0.2644 (0.2730)  time: 54.0782  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [370/985]  eta: 9:14:27  lr: 0.000100  g_loss: 3.4545 (3.5437)  d_loss: 1.8915 (1.8932)  gan_loss: 0.8680 (0.8170)  pix_loss: 0.2550 (0.2727)  time: 54.0795  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [380/985]  eta: 9:05:25  lr: 0.000100  g_loss: 3.4167 (3.5398)  d_loss: 1.8940 (1.8934)  gan_loss: 0.8769 (0.8185)  pix_loss: 0.2536 (0.2721)  time: 54.0764  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [390/985]  eta: 8:56:24  lr: 0.000100  g_loss: 3.3108 (3.5346)  d_loss: 1.8999 (1.8936)  gan_loss: 0.8595 (0.8194)  pix_loss: 0.2451 (0.2715)  time: 54.0768  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [400/985]  eta: 8:47:23  lr: 0.000100  g_loss: 3.3570 (3.5361)  d_loss: 1.8960 (1.8933)  gan_loss: 0.8367 (0.8192)  pix_loss: 0.2512 (0.2717)  time: 54.0774  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [410/985]  eta: 8:38:22  lr: 0.000100  g_loss: 3.4636 (3.5374)  d_loss: 1.8929 (1.8934)  gan_loss: 0.8087 (0.8193)  pix_loss: 0.2633 (0.2718)  time: 54.0741  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:19]  [420/985]  eta: 8:29:21  lr: 0.000100  g_loss: 3.5353 (3.5383)  d_loss: 1.8952 (1.8933)  gan_loss: 0.8551 (0.8203)  pix_loss: 0.2706 (0.2718)  time: 54.0717  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:19]  [430/985]  eta: 8:20:20  lr: 0.000100  g_loss: 3.5787 (3.5401)  d_loss: 1.8914 (1.8935)  gan_loss: 0.8228 (0.8197)  pix_loss: 0.2726 (0.2720)  time: 54.0792  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:19]  [440/985]  eta: 8:11:20  lr: 0.000100  g_loss: 3.5824 (3.5409)  d_loss: 1.9074 (1.8938)  gan_loss: 0.8640 (0.8223)  pix_loss: 0.2689 (0.2719)  time: 54.1191  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [450/985]  eta: 8:02:18  lr: 0.000100  g_loss: 3.4614 (3.5430)  d_loss: 1.9045 (1.8939)  gan_loss: 0.9232 (0.8245)  pix_loss: 0.2514 (0.2719)  time: 54.1118  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [460/985]  eta: 7:53:17  lr: 0.000100  g_loss: 3.7623 (3.5506)  d_loss: 1.8951 (1.8939)  gan_loss: 0.8831 (0.8256)  pix_loss: 0.2806 (0.2725)  time: 54.0744  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [470/985]  eta: 7:44:16  lr: 0.000100  g_loss: 3.6046 (3.5521)  d_loss: 1.8997 (1.8939)  gan_loss: 0.8399 (0.8257)  pix_loss: 0.2765 (0.2726)  time: 54.0773  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [480/985]  eta: 7:35:15  lr: 0.000100  g_loss: 3.4420 (3.5498)  d_loss: 1.9024 (1.8940)  gan_loss: 0.8177 (0.8252)  pix_loss: 0.2628 (0.2725)  time: 54.0727  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [490/985]  eta: 7:26:14  lr: 0.000100  g_loss: 3.4021 (3.5453)  d_loss: 1.9019 (1.8941)  gan_loss: 0.8043 (0.8247)  pix_loss: 0.2592 (0.2721)  time: 54.0750  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [500/985]  eta: 7:17:13  lr: 0.000100  g_loss: 3.3327 (3.5423)  d_loss: 1.9014 (1.8941)  gan_loss: 0.8031 (0.8242)  pix_loss: 0.2534 (0.2718)  time: 54.0825  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [510/985]  eta: 7:08:12  lr: 0.000100  g_loss: 3.1576 (3.5369)  d_loss: 1.9017 (1.8943)  gan_loss: 0.8032 (0.8238)  pix_loss: 0.2352 (0.2713)  time: 54.0793  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [520/985]  eta: 6:59:11  lr: 0.000100  g_loss: 3.1576 (3.5312)  d_loss: 1.8980 (1.8943)  gan_loss: 0.7981 (0.8232)  pix_loss: 0.2352 (0.2708)  time: 54.0744  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [530/985]  eta: 6:50:10  lr: 0.000100  g_loss: 3.2611 (3.5328)  d_loss: 1.8904 (1.8940)  gan_loss: 0.8075 (0.8234)  pix_loss: 0.2459 (0.2709)  time: 54.0757  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [540/985]  eta: 6:41:10  lr: 0.000100  g_loss: 3.6972 (3.5379)  d_loss: 1.8874 (1.8938)  gan_loss: 0.8075 (0.8227)  pix_loss: 0.2888 (0.2715)  time: 54.1227  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [550/985]  eta: 6:32:09  lr: 0.000100  g_loss: 3.5126 (3.5344)  d_loss: 1.8924 (1.8938)  gan_loss: 0.7807 (0.8221)  pix_loss: 0.2744 (0.2712)  time: 54.1310  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [560/985]  eta: 6:23:08  lr: 0.000100  g_loss: 3.1481 (3.5303)  d_loss: 1.9048 (1.8941)  gan_loss: 0.8344 (0.8239)  pix_loss: 0.2293 (0.2706)  time: 54.0933  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [570/985]  eta: 6:14:07  lr: 0.000100  g_loss: 3.1481 (3.5244)  d_loss: 1.9105 (1.8943)  gan_loss: 0.9489 (0.8262)  pix_loss: 0.2225 (0.2698)  time: 54.0937  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [580/985]  eta: 6:05:06  lr: 0.000100  g_loss: 3.2511 (3.5191)  d_loss: 1.9071 (1.8945)  gan_loss: 0.9415 (0.8280)  pix_loss: 0.2326 (0.2691)  time: 54.0939  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [590/985]  eta: 5:56:05  lr: 0.000100  g_loss: 3.2511 (3.5170)  d_loss: 1.9088 (1.8948)  gan_loss: 0.9115 (0.8290)  pix_loss: 0.2328 (0.2688)  time: 54.0912  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [600/985]  eta: 5:47:05  lr: 0.000100  g_loss: 3.5139 (3.5195)  d_loss: 1.8948 (1.8946)  gan_loss: 0.8806 (0.8296)  pix_loss: 0.2611 (0.2690)  time: 54.0913  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [610/985]  eta: 5:38:04  lr: 0.000100  g_loss: 3.8386 (3.5276)  d_loss: 1.8876 (1.8945)  gan_loss: 0.8346 (0.8296)  pix_loss: 0.2982 (0.2698)  time: 54.0926  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [620/985]  eta: 5:29:03  lr: 0.000100  g_loss: 3.8039 (3.5323)  d_loss: 1.8889 (1.8944)  gan_loss: 0.8105 (0.8290)  pix_loss: 0.3020 (0.2703)  time: 54.0935  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [630/985]  eta: 5:20:02  lr: 0.000100  g_loss: 3.6801 (3.5336)  d_loss: 1.8895 (1.8944)  gan_loss: 0.7900 (0.8284)  pix_loss: 0.2893 (0.2705)  time: 54.0935  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [640/985]  eta: 5:11:02  lr: 0.000100  g_loss: 3.6744 (3.5343)  d_loss: 1.8958 (1.8944)  gan_loss: 0.7907 (0.8279)  pix_loss: 0.2859 (0.2706)  time: 54.1672  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [650/985]  eta: 5:02:01  lr: 0.000100  g_loss: 3.4369 (3.5316)  d_loss: 1.8958 (1.8944)  gan_loss: 0.7983 (0.8275)  pix_loss: 0.2633 (0.2704)  time: 54.1687  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [660/985]  eta: 4:53:00  lr: 0.000100  g_loss: 3.3245 (3.5315)  d_loss: 1.8970 (1.8945)  gan_loss: 0.7950 (0.8269)  pix_loss: 0.2532 (0.2705)  time: 54.0995  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [670/985]  eta: 4:43:59  lr: 0.000100  g_loss: 3.3843 (3.5303)  d_loss: 1.8954 (1.8943)  gan_loss: 0.7950 (0.8268)  pix_loss: 0.2587 (0.2704)  time: 54.0971  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [680/985]  eta: 4:34:58  lr: 0.000100  g_loss: 3.4716 (3.5295)  d_loss: 1.8900 (1.8944)  gan_loss: 0.8075 (0.8264)  pix_loss: 0.2639 (0.2703)  time: 54.0910  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:19]  [690/985]  eta: 4:25:57  lr: 0.000100  g_loss: 3.4967 (3.5297)  d_loss: 1.8865 (1.8942)  gan_loss: 0.7937 (0.8260)  pix_loss: 0.2669 (0.2704)  time: 54.0914  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:19]  [700/985]  eta: 4:16:56  lr: 0.000100  g_loss: 3.3650 (3.5280)  d_loss: 1.8873 (1.8942)  gan_loss: 0.7817 (0.8254)  pix_loss: 0.2587 (0.2703)  time: 54.0896  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [710/985]  eta: 4:07:55  lr: 0.000100  g_loss: 3.3151 (3.5242)  d_loss: 1.8944 (1.8942)  gan_loss: 0.7890 (0.8250)  pix_loss: 0.2521 (0.2699)  time: 54.0877  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [720/985]  eta: 3:58:54  lr: 0.000100  g_loss: 3.2870 (3.5244)  d_loss: 1.8886 (1.8940)  gan_loss: 0.8070 (0.8250)  pix_loss: 0.2495 (0.2699)  time: 54.0879  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [730/985]  eta: 3:49:53  lr: 0.000100  g_loss: 3.5672 (3.5254)  d_loss: 1.8912 (1.8940)  gan_loss: 0.8028 (0.8244)  pix_loss: 0.2790 (0.2701)  time: 54.0872  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [740/985]  eta: 3:40:53  lr: 0.000100  g_loss: 3.5672 (3.5262)  d_loss: 1.8973 (1.8941)  gan_loss: 0.8067 (0.8246)  pix_loss: 0.2746 (0.2702)  time: 54.1229  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:19]  [750/985]  eta: 3:31:52  lr: 0.000100  g_loss: 3.5897 (3.5282)  d_loss: 1.8919 (1.8939)  gan_loss: 0.8299 (0.8246)  pix_loss: 0.2776 (0.2704)  time: 54.1279  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [760/985]  eta: 3:22:51  lr: 0.000100  g_loss: 3.6243 (3.5290)  d_loss: 1.8919 (1.8939)  gan_loss: 0.8180 (0.8246)  pix_loss: 0.2783 (0.2704)  time: 54.0935  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [770/985]  eta: 3:13:50  lr: 0.000100  g_loss: 3.4232 (3.5281)  d_loss: 1.9016 (1.8940)  gan_loss: 0.8537 (0.8255)  pix_loss: 0.2613 (0.2703)  time: 54.0887  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [780/985]  eta: 3:04:49  lr: 0.000100  g_loss: 3.3608 (3.5284)  d_loss: 1.8979 (1.8940)  gan_loss: 0.8756 (0.8258)  pix_loss: 0.2526 (0.2703)  time: 54.0887  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [790/985]  eta: 2:55:48  lr: 0.000100  g_loss: 3.5244 (3.5310)  d_loss: 1.8853 (1.8938)  gan_loss: 0.8162 (0.8253)  pix_loss: 0.2649 (0.2706)  time: 54.0910  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:19]  [800/985]  eta: 2:46:47  lr: 0.000100  g_loss: 3.5254 (3.5291)  d_loss: 1.8902 (1.8938)  gan_loss: 0.8005 (0.8255)  pix_loss: 0.2643 (0.2704)  time: 54.0915  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [810/985]  eta: 2:37:46  lr: 0.000100  g_loss: 3.3522 (3.5266)  d_loss: 1.8918 (1.8937)  gan_loss: 0.8298 (0.8255)  pix_loss: 0.2526 (0.2701)  time: 54.0870  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [820/985]  eta: 2:28:45  lr: 0.000100  g_loss: 3.3643 (3.5256)  d_loss: 1.8787 (1.8935)  gan_loss: 0.8052 (0.8250)  pix_loss: 0.2564 (0.2701)  time: 54.0843  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [830/985]  eta: 2:19:44  lr: 0.000100  g_loss: 3.5551 (3.5281)  d_loss: 1.8787 (1.8933)  gan_loss: 0.7900 (0.8248)  pix_loss: 0.2741 (0.2703)  time: 54.0864  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [840/985]  eta: 2:10:43  lr: 0.000100  g_loss: 3.6259 (3.5290)  d_loss: 1.8826 (1.8933)  gan_loss: 0.8186 (0.8248)  pix_loss: 0.2803 (0.2704)  time: 54.1094  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [850/985]  eta: 2:01:42  lr: 0.000100  g_loss: 3.4955 (3.5281)  d_loss: 1.8997 (1.8933)  gan_loss: 0.8082 (0.8246)  pix_loss: 0.2669 (0.2704)  time: 54.1129  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [860/985]  eta: 1:52:41  lr: 0.000100  g_loss: 3.4228 (3.5265)  d_loss: 1.8929 (1.8933)  gan_loss: 0.8036 (0.8243)  pix_loss: 0.2609 (0.2702)  time: 54.0926  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [870/985]  eta: 1:43:40  lr: 0.000100  g_loss: 3.4228 (3.5240)  d_loss: 1.8913 (1.8933)  gan_loss: 0.8026 (0.8241)  pix_loss: 0.2603 (0.2700)  time: 54.0917  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [880/985]  eta: 1:34:39  lr: 0.000100  g_loss: 3.0215 (3.5172)  d_loss: 1.8960 (1.8933)  gan_loss: 0.8050 (0.8239)  pix_loss: 0.2213 (0.2693)  time: 54.0870  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [890/985]  eta: 1:25:38  lr: 0.000100  g_loss: 2.9352 (3.5119)  d_loss: 1.9008 (1.8934)  gan_loss: 0.8060 (0.8241)  pix_loss: 0.2130 (0.2688)  time: 54.0897  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [900/985]  eta: 1:16:37  lr: 0.000100  g_loss: 3.0304 (3.5085)  d_loss: 1.8985 (1.8934)  gan_loss: 0.8821 (0.8250)  pix_loss: 0.2217 (0.2683)  time: 54.0932  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [910/985]  eta: 1:07:37  lr: 0.000100  g_loss: 3.1755 (3.5056)  d_loss: 1.8979 (1.8935)  gan_loss: 0.8753 (0.8250)  pix_loss: 0.2277 (0.2681)  time: 54.0899  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [920/985]  eta: 0:58:36  lr: 0.000100  g_loss: 3.1968 (3.5040)  d_loss: 1.8941 (1.8934)  gan_loss: 0.8142 (0.8247)  pix_loss: 0.2392 (0.2679)  time: 54.0868  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [930/985]  eta: 0:49:35  lr: 0.000100  g_loss: 3.2913 (3.5026)  d_loss: 1.8874 (1.8934)  gan_loss: 0.7958 (0.8244)  pix_loss: 0.2503 (0.2678)  time: 54.1096  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [940/985]  eta: 0:40:34  lr: 0.000100  g_loss: 3.1789 (3.4983)  d_loss: 1.8989 (1.8935)  gan_loss: 0.8087 (0.8243)  pix_loss: 0.2370 (0.2674)  time: 54.1185  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [950/985]  eta: 0:31:33  lr: 0.000100  g_loss: 2.9452 (3.4935)  d_loss: 1.9022 (1.8935)  gan_loss: 0.8126 (0.8241)  pix_loss: 0.2166 (0.2669)  time: 54.0968  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [960/985]  eta: 0:22:32  lr: 0.000100  g_loss: 3.1571 (3.4922)  d_loss: 1.8971 (1.8935)  gan_loss: 0.8119 (0.8241)  pix_loss: 0.2341 (0.2668)  time: 54.0368  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [970/985]  eta: 0:13:31  lr: 0.000100  g_loss: 3.4458 (3.4916)  d_loss: 1.8893 (1.8934)  gan_loss: 0.7985 (0.8237)  pix_loss: 0.2636 (0.2668)  time: 54.0168  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [980/985]  eta: 0:04:30  lr: 0.000100  g_loss: 3.2174 (3.4876)  d_loss: 1.9023 (1.8936)  gan_loss: 0.7894 (0.8234)  pix_loss: 0.2427 (0.2664)  time: 54.0164  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 3.1416 (3.4852)  d_loss: 1.9037 (1.8936)  gan_loss: 0.7921 (0.8236)  pix_loss: 0.2335 (0.2662)  time: 53.9970  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:19] Total time: 14:47:59 (54.0909 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 3.1416 (3.4852)  d_loss: 1.9037 (1.8936)  gan_loss: 0.7921 (0.8236)  pix_loss: 0.2335 (0.2662)\n",
      "Valid: [epoch:19]  [ 0/14]  eta: 0:01:35  L1_loss: 0.0068 (0.0068)  time: 6.7957  data: 0.3471  max mem: 38397\n",
      "Valid: [epoch:19]  [13/14]  eta: 0:00:06  L1_loss: 0.0068 (0.0069)  time: 6.4004  data: 0.0249  max mem: 38397\n",
      "Valid: [epoch:19] Total time: 0:01:29 (6.4088 s / it)\n",
      "Averaged stats: L1_loss: 0.0068 (0.0069)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_19_input_n_20.png\n",
      "Train: [epoch:20]  [  0/985]  eta: 15:09:24  lr: 0.000100  g_loss: 2.9091 (2.9091)  d_loss: 1.9053 (1.9053)  gan_loss: 0.8715 (0.8715)  pix_loss: 0.2038 (0.2038)  time: 55.3949  data: 1.2650  max mem: 38397\n",
      "Train: [epoch:20]  [ 10/985]  eta: 14:40:31  lr: 0.000100  g_loss: 2.9091 (2.9083)  d_loss: 1.9065 (1.9081)  gan_loss: 0.8537 (0.8577)  pix_loss: 0.2049 (0.2051)  time: 54.1865  data: 0.1151  max mem: 38397\n",
      "Train: [epoch:20]  [ 20/985]  eta: 14:30:34  lr: 0.000100  g_loss: 3.0193 (3.0516)  d_loss: 1.9059 (1.9032)  gan_loss: 0.8532 (0.8670)  pix_loss: 0.2190 (0.2185)  time: 54.0660  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [ 30/985]  eta: 14:21:13  lr: 0.000100  g_loss: 3.2298 (3.1472)  d_loss: 1.9117 (1.9064)  gan_loss: 0.9900 (0.9343)  pix_loss: 0.2273 (0.2213)  time: 54.0650  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [ 40/985]  eta: 14:12:02  lr: 0.000100  g_loss: 3.3233 (3.2211)  d_loss: 1.9117 (1.9072)  gan_loss: 1.0853 (0.9769)  pix_loss: 0.2222 (0.2244)  time: 54.0641  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [ 50/985]  eta: 14:03:09  lr: 0.000100  g_loss: 3.3547 (3.2872)  d_loss: 1.9124 (1.9091)  gan_loss: 1.1093 (1.0065)  pix_loss: 0.2245 (0.2281)  time: 54.1035  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [ 60/985]  eta: 13:54:03  lr: 0.000100  g_loss: 3.4715 (3.3169)  d_loss: 1.9172 (1.9103)  gan_loss: 1.1391 (1.0273)  pix_loss: 0.2326 (0.2290)  time: 54.1076  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [ 70/985]  eta: 13:44:58  lr: 0.000100  g_loss: 3.3491 (3.3068)  d_loss: 1.9162 (1.9109)  gan_loss: 1.1402 (1.0430)  pix_loss: 0.2221 (0.2264)  time: 54.0733  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [ 80/985]  eta: 13:35:54  lr: 0.000100  g_loss: 3.2648 (3.3104)  d_loss: 1.9091 (1.9101)  gan_loss: 1.1308 (1.0529)  pix_loss: 0.2148 (0.2258)  time: 54.0705  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [ 90/985]  eta: 13:26:51  lr: 0.000100  g_loss: 3.2648 (3.3102)  d_loss: 1.9079 (1.9103)  gan_loss: 1.0979 (1.0537)  pix_loss: 0.2174 (0.2257)  time: 54.0688  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [100/985]  eta: 13:17:48  lr: 0.000100  g_loss: 3.2181 (3.2991)  d_loss: 1.9133 (1.9107)  gan_loss: 1.0593 (1.0557)  pix_loss: 0.2145 (0.2243)  time: 54.0699  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [110/985]  eta: 13:08:46  lr: 0.000100  g_loss: 3.2074 (3.3241)  d_loss: 1.9107 (1.9099)  gan_loss: 1.0739 (1.0566)  pix_loss: 0.2144 (0.2267)  time: 54.0720  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [120/985]  eta: 12:59:43  lr: 0.000100  g_loss: 3.3624 (3.3286)  d_loss: 1.9064 (1.9097)  gan_loss: 1.0219 (1.0523)  pix_loss: 0.2264 (0.2276)  time: 54.0687  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [130/985]  eta: 12:50:41  lr: 0.000100  g_loss: 3.2604 (3.3172)  d_loss: 1.9046 (1.9093)  gan_loss: 0.9845 (1.0465)  pix_loss: 0.2251 (0.2271)  time: 54.0620  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [140/985]  eta: 12:41:39  lr: 0.000100  g_loss: 3.2562 (3.3192)  d_loss: 1.9020 (1.9085)  gan_loss: 0.9731 (1.0419)  pix_loss: 0.2276 (0.2277)  time: 54.0615  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [150/985]  eta: 12:32:49  lr: 0.000100  g_loss: 3.2562 (3.3137)  d_loss: 1.9020 (1.9081)  gan_loss: 0.9706 (1.0366)  pix_loss: 0.2280 (0.2277)  time: 54.1695  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [160/985]  eta: 12:23:46  lr: 0.000100  g_loss: 3.1354 (3.3137)  d_loss: 1.9038 (1.9079)  gan_loss: 0.9569 (1.0313)  pix_loss: 0.2178 (0.2282)  time: 54.1722  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [170/985]  eta: 12:14:44  lr: 0.000100  g_loss: 3.1736 (3.3051)  d_loss: 1.9060 (1.9075)  gan_loss: 0.9437 (1.0259)  pix_loss: 0.2216 (0.2279)  time: 54.0671  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [180/985]  eta: 12:05:42  lr: 0.000100  g_loss: 3.1236 (3.2969)  d_loss: 1.9068 (1.9074)  gan_loss: 0.9068 (1.0181)  pix_loss: 0.2215 (0.2279)  time: 54.0650  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [190/985]  eta: 11:56:40  lr: 0.000100  g_loss: 3.3492 (3.3164)  d_loss: 1.8970 (1.9058)  gan_loss: 0.8812 (1.0114)  pix_loss: 0.2402 (0.2305)  time: 54.0655  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [200/985]  eta: 11:47:38  lr: 0.000100  g_loss: 3.5530 (3.3260)  d_loss: 1.8860 (1.9053)  gan_loss: 0.8436 (1.0023)  pix_loss: 0.2700 (0.2324)  time: 54.0636  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [210/985]  eta: 11:38:36  lr: 0.000100  g_loss: 3.3660 (3.3259)  d_loss: 1.8956 (1.9049)  gan_loss: 0.8323 (0.9960)  pix_loss: 0.2534 (0.2330)  time: 54.0576  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [220/985]  eta: 11:29:34  lr: 0.000100  g_loss: 3.3816 (3.3340)  d_loss: 1.8903 (1.9038)  gan_loss: 0.8418 (0.9882)  pix_loss: 0.2525 (0.2346)  time: 54.0593  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [230/985]  eta: 11:20:33  lr: 0.000100  g_loss: 3.4732 (3.3418)  d_loss: 1.8903 (1.9034)  gan_loss: 0.8332 (0.9827)  pix_loss: 0.2630 (0.2359)  time: 54.0650  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [240/985]  eta: 11:11:31  lr: 0.000100  g_loss: 3.4288 (3.3448)  d_loss: 1.8961 (1.9032)  gan_loss: 0.8707 (0.9783)  pix_loss: 0.2579 (0.2367)  time: 54.0606  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [250/985]  eta: 11:02:37  lr: 0.000100  g_loss: 3.2634 (3.3400)  d_loss: 1.9031 (1.9032)  gan_loss: 0.8750 (0.9743)  pix_loss: 0.2381 (0.2366)  time: 54.1834  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [260/985]  eta: 10:53:36  lr: 0.000100  g_loss: 3.0154 (3.3210)  d_loss: 1.9037 (1.9033)  gan_loss: 0.8640 (0.9694)  pix_loss: 0.2150 (0.2352)  time: 54.1902  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [270/985]  eta: 10:44:34  lr: 0.000100  g_loss: 2.9656 (3.3121)  d_loss: 1.9024 (1.9031)  gan_loss: 0.8370 (0.9644)  pix_loss: 0.2129 (0.2348)  time: 54.0672  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [280/985]  eta: 10:35:32  lr: 0.000100  g_loss: 3.0239 (3.3042)  d_loss: 1.8976 (1.9027)  gan_loss: 0.8271 (0.9594)  pix_loss: 0.2198 (0.2345)  time: 54.0610  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [290/985]  eta: 10:26:31  lr: 0.000100  g_loss: 3.0006 (3.2945)  d_loss: 1.8992 (1.9028)  gan_loss: 0.8156 (0.9543)  pix_loss: 0.2185 (0.2340)  time: 54.0632  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [300/985]  eta: 10:17:30  lr: 0.000100  g_loss: 3.2530 (3.3209)  d_loss: 1.8969 (1.9019)  gan_loss: 0.8108 (0.9500)  pix_loss: 0.2421 (0.2371)  time: 54.0740  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [310/985]  eta: 10:08:28  lr: 0.000100  g_loss: 3.4985 (3.3238)  d_loss: 1.8917 (1.9017)  gan_loss: 0.8023 (0.9449)  pix_loss: 0.2731 (0.2379)  time: 54.0715  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [320/985]  eta: 9:59:27  lr: 0.000100  g_loss: 3.4644 (3.3312)  d_loss: 1.8898 (1.9012)  gan_loss: 0.8023 (0.9412)  pix_loss: 0.2632 (0.2390)  time: 54.0679  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [330/985]  eta: 9:50:26  lr: 0.000100  g_loss: 3.6829 (3.3487)  d_loss: 1.8898 (1.9011)  gan_loss: 0.8321 (0.9382)  pix_loss: 0.2854 (0.2411)  time: 54.0692  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [340/985]  eta: 9:41:25  lr: 0.000100  g_loss: 3.7150 (3.3567)  d_loss: 1.8939 (1.9007)  gan_loss: 0.8314 (0.9353)  pix_loss: 0.2877 (0.2421)  time: 54.0683  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [350/985]  eta: 9:32:26  lr: 0.000100  g_loss: 3.3549 (3.3538)  d_loss: 1.8900 (1.9005)  gan_loss: 0.8161 (0.9315)  pix_loss: 0.2539 (0.2422)  time: 54.1450  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [360/985]  eta: 9:23:27  lr: 0.000100  g_loss: 3.1358 (3.3412)  d_loss: 1.8941 (1.9003)  gan_loss: 0.8159 (0.9289)  pix_loss: 0.2344 (0.2412)  time: 54.2125  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [370/985]  eta: 9:14:27  lr: 0.000100  g_loss: 3.1846 (3.3390)  d_loss: 1.9002 (1.9003)  gan_loss: 0.8333 (0.9262)  pix_loss: 0.2339 (0.2413)  time: 54.1483  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [380/985]  eta: 9:05:26  lr: 0.000100  g_loss: 3.2206 (3.3349)  d_loss: 1.9001 (1.9003)  gan_loss: 0.8277 (0.9236)  pix_loss: 0.2392 (0.2411)  time: 54.0948  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [390/985]  eta: 8:56:25  lr: 0.000100  g_loss: 3.1837 (3.3318)  d_loss: 1.8972 (1.9000)  gan_loss: 0.8238 (0.9212)  pix_loss: 0.2368 (0.2411)  time: 54.0949  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [400/985]  eta: 8:47:24  lr: 0.000100  g_loss: 3.4124 (3.3396)  d_loss: 1.8916 (1.8995)  gan_loss: 0.8107 (0.9182)  pix_loss: 0.2592 (0.2421)  time: 54.0972  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [410/985]  eta: 8:38:23  lr: 0.000100  g_loss: 3.8134 (3.3585)  d_loss: 1.8764 (1.8989)  gan_loss: 0.8000 (0.9160)  pix_loss: 0.3046 (0.2443)  time: 54.0953  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [420/985]  eta: 8:29:22  lr: 0.000100  g_loss: 3.6715 (3.3628)  d_loss: 1.8846 (1.8987)  gan_loss: 0.8183 (0.9138)  pix_loss: 0.2833 (0.2449)  time: 54.0925  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [430/985]  eta: 8:20:21  lr: 0.000100  g_loss: 3.4874 (3.3675)  d_loss: 1.8937 (1.8985)  gan_loss: 0.8112 (0.9112)  pix_loss: 0.2642 (0.2456)  time: 54.0939  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [440/985]  eta: 8:11:20  lr: 0.000100  g_loss: 3.3456 (3.3674)  d_loss: 1.8964 (1.8985)  gan_loss: 0.8002 (0.9090)  pix_loss: 0.2561 (0.2458)  time: 54.0910  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [450/985]  eta: 8:02:19  lr: 0.000100  g_loss: 3.2858 (3.3642)  d_loss: 1.8958 (1.8984)  gan_loss: 0.8245 (0.9074)  pix_loss: 0.2452 (0.2457)  time: 54.1037  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [460/985]  eta: 7:53:21  lr: 0.000100  g_loss: 3.3165 (3.3660)  d_loss: 1.8914 (1.8981)  gan_loss: 0.8285 (0.9058)  pix_loss: 0.2479 (0.2460)  time: 54.2001  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [470/985]  eta: 7:44:19  lr: 0.000100  g_loss: 3.3737 (3.3652)  d_loss: 1.9031 (1.8983)  gan_loss: 0.8407 (0.9050)  pix_loss: 0.2532 (0.2460)  time: 54.1696  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [480/985]  eta: 7:35:17  lr: 0.000100  g_loss: 3.2163 (3.3603)  d_loss: 1.9096 (1.8986)  gan_loss: 0.8953 (0.9049)  pix_loss: 0.2325 (0.2455)  time: 54.0314  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:20]  [490/985]  eta: 7:26:16  lr: 0.000100  g_loss: 3.2459 (3.3619)  d_loss: 1.9120 (1.8986)  gan_loss: 0.9034 (0.9050)  pix_loss: 0.2301 (0.2457)  time: 54.0335  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:20]  [500/985]  eta: 7:17:15  lr: 0.000100  g_loss: 3.4276 (3.3649)  d_loss: 1.9051 (1.8988)  gan_loss: 0.8734 (0.9040)  pix_loss: 0.2571 (0.2461)  time: 54.0634  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [510/985]  eta: 7:08:14  lr: 0.000100  g_loss: 3.3564 (3.3637)  d_loss: 1.9043 (1.8988)  gan_loss: 0.8604 (0.9036)  pix_loss: 0.2503 (0.2460)  time: 54.0625  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [520/985]  eta: 6:59:12  lr: 0.000100  g_loss: 3.1835 (3.3589)  d_loss: 1.8987 (1.8987)  gan_loss: 0.8477 (0.9017)  pix_loss: 0.2325 (0.2457)  time: 54.0610  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [530/985]  eta: 6:50:11  lr: 0.000100  g_loss: 3.0065 (3.3568)  d_loss: 1.8933 (1.8986)  gan_loss: 0.8276 (0.9007)  pix_loss: 0.2159 (0.2456)  time: 54.0582  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [540/985]  eta: 6:41:10  lr: 0.000100  g_loss: 2.9573 (3.3497)  d_loss: 1.8946 (1.8986)  gan_loss: 0.8277 (0.8992)  pix_loss: 0.2110 (0.2450)  time: 54.0565  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [550/985]  eta: 6:32:09  lr: 0.000100  g_loss: 3.0163 (3.3473)  d_loss: 1.8937 (1.8985)  gan_loss: 0.8312 (0.8984)  pix_loss: 0.2221 (0.2449)  time: 54.0596  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [560/985]  eta: 6:23:09  lr: 0.000100  g_loss: 3.0870 (3.3403)  d_loss: 1.8998 (1.8986)  gan_loss: 0.8231 (0.8965)  pix_loss: 0.2226 (0.2444)  time: 54.1476  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [570/985]  eta: 6:14:08  lr: 0.000100  g_loss: 2.9120 (3.3361)  d_loss: 1.9010 (1.8984)  gan_loss: 0.8063 (0.8955)  pix_loss: 0.2118 (0.2441)  time: 54.1487  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [580/985]  eta: 6:05:07  lr: 0.000100  g_loss: 3.0779 (3.3325)  d_loss: 1.8944 (1.8984)  gan_loss: 0.8194 (0.8940)  pix_loss: 0.2248 (0.2439)  time: 54.0675  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [590/985]  eta: 5:56:06  lr: 0.000100  g_loss: 3.0614 (3.3269)  d_loss: 1.8950 (1.8983)  gan_loss: 0.8136 (0.8927)  pix_loss: 0.2251 (0.2434)  time: 54.0710  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [600/985]  eta: 5:47:05  lr: 0.000100  g_loss: 3.1630 (3.3250)  d_loss: 1.8926 (1.8982)  gan_loss: 0.8173 (0.8916)  pix_loss: 0.2337 (0.2433)  time: 54.0686  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [610/985]  eta: 5:38:04  lr: 0.000100  g_loss: 3.1933 (3.3229)  d_loss: 1.8940 (1.8982)  gan_loss: 0.8224 (0.8904)  pix_loss: 0.2372 (0.2432)  time: 54.0671  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [620/985]  eta: 5:29:03  lr: 0.000100  g_loss: 3.1871 (3.3216)  d_loss: 1.8950 (1.8981)  gan_loss: 0.8251 (0.8895)  pix_loss: 0.2360 (0.2432)  time: 54.0643  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [630/985]  eta: 5:20:01  lr: 0.000100  g_loss: 3.1878 (3.3199)  d_loss: 1.8950 (1.8981)  gan_loss: 0.8821 (0.8902)  pix_loss: 0.2315 (0.2430)  time: 54.0606  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [640/985]  eta: 5:11:00  lr: 0.000100  g_loss: 3.1904 (3.3175)  d_loss: 1.9075 (1.8984)  gan_loss: 0.9264 (0.8909)  pix_loss: 0.2286 (0.2427)  time: 54.0585  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [650/985]  eta: 5:01:59  lr: 0.000100  g_loss: 3.1388 (3.3126)  d_loss: 1.9142 (1.8986)  gan_loss: 0.9655 (0.8923)  pix_loss: 0.2178 (0.2420)  time: 54.0568  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [660/985]  eta: 4:52:59  lr: 0.000100  g_loss: 3.0675 (3.3108)  d_loss: 1.9135 (1.8988)  gan_loss: 0.9773 (0.8934)  pix_loss: 0.2073 (0.2417)  time: 54.1699  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [670/985]  eta: 4:43:58  lr: 0.000100  g_loss: 2.9333 (3.3047)  d_loss: 1.9129 (1.8990)  gan_loss: 0.9409 (0.8939)  pix_loss: 0.1958 (0.2411)  time: 54.1751  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [680/985]  eta: 4:34:57  lr: 0.000100  g_loss: 2.8688 (3.3005)  d_loss: 1.9100 (1.8992)  gan_loss: 0.9192 (0.8942)  pix_loss: 0.1953 (0.2406)  time: 54.0609  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [690/985]  eta: 4:25:56  lr: 0.000100  g_loss: 3.0600 (3.3017)  d_loss: 1.9071 (1.8991)  gan_loss: 0.8997 (0.8937)  pix_loss: 0.2144 (0.2408)  time: 54.0556  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [700/985]  eta: 4:16:55  lr: 0.000100  g_loss: 3.4272 (3.3036)  d_loss: 1.8934 (1.8989)  gan_loss: 0.8092 (0.8924)  pix_loss: 0.2641 (0.2411)  time: 54.0651  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:20]  [710/985]  eta: 4:07:54  lr: 0.000100  g_loss: 3.4117 (3.3050)  d_loss: 1.8932 (1.8989)  gan_loss: 0.8225 (0.8918)  pix_loss: 0.2608 (0.2413)  time: 54.0677  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:20]  [720/985]  eta: 3:58:53  lr: 0.000100  g_loss: 3.1360 (3.3018)  d_loss: 1.8979 (1.8989)  gan_loss: 0.8491 (0.8912)  pix_loss: 0.2294 (0.2411)  time: 54.0615  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [730/985]  eta: 3:49:52  lr: 0.000100  g_loss: 2.9210 (3.2965)  d_loss: 1.9025 (1.8989)  gan_loss: 0.8361 (0.8902)  pix_loss: 0.2120 (0.2406)  time: 54.0620  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [740/985]  eta: 3:40:51  lr: 0.000100  g_loss: 2.8981 (3.2921)  d_loss: 1.9033 (1.8989)  gan_loss: 0.8027 (0.8891)  pix_loss: 0.2065 (0.2403)  time: 54.0609  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [750/985]  eta: 3:31:50  lr: 0.000100  g_loss: 2.9583 (3.2897)  d_loss: 1.8972 (1.8989)  gan_loss: 0.8059 (0.8883)  pix_loss: 0.2162 (0.2401)  time: 54.0594  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [760/985]  eta: 3:22:50  lr: 0.000100  g_loss: 3.3459 (3.2927)  d_loss: 1.8938 (1.8988)  gan_loss: 0.8741 (0.8887)  pix_loss: 0.2469 (0.2404)  time: 54.1219  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [770/985]  eta: 3:13:49  lr: 0.000100  g_loss: 3.4407 (3.2943)  d_loss: 1.9080 (1.8990)  gan_loss: 0.9038 (0.8886)  pix_loss: 0.2536 (0.2406)  time: 54.1827  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [780/985]  eta: 3:04:48  lr: 0.000100  g_loss: 3.3998 (3.2964)  d_loss: 1.9070 (1.8990)  gan_loss: 0.9298 (0.8897)  pix_loss: 0.2421 (0.2407)  time: 54.1178  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [790/985]  eta: 2:55:47  lr: 0.000100  g_loss: 3.2015 (3.2945)  d_loss: 1.9035 (1.8991)  gan_loss: 0.9504 (0.8898)  pix_loss: 0.2277 (0.2405)  time: 54.0733  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [800/985]  eta: 2:46:46  lr: 0.000100  g_loss: 3.1580 (3.2929)  d_loss: 1.9062 (1.8991)  gan_loss: 0.8920 (0.8899)  pix_loss: 0.2217 (0.2403)  time: 54.0403  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [810/985]  eta: 2:37:45  lr: 0.000100  g_loss: 3.2257 (3.2916)  d_loss: 1.8957 (1.8990)  gan_loss: 0.8705 (0.8894)  pix_loss: 0.2362 (0.2402)  time: 53.9415  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [820/985]  eta: 2:28:43  lr: 0.000100  g_loss: 3.0852 (3.2889)  d_loss: 1.8940 (1.8989)  gan_loss: 0.8308 (0.8886)  pix_loss: 0.2261 (0.2400)  time: 53.9062  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [830/985]  eta: 2:19:42  lr: 0.000100  g_loss: 2.9534 (3.2842)  d_loss: 1.8962 (1.8989)  gan_loss: 0.8150 (0.8877)  pix_loss: 0.2155 (0.2397)  time: 53.9113  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:20]  [840/985]  eta: 2:10:41  lr: 0.000100  g_loss: 2.8730 (3.2781)  d_loss: 1.9001 (1.8989)  gan_loss: 0.8110 (0.8868)  pix_loss: 0.2055 (0.2391)  time: 53.9050  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [850/985]  eta: 2:01:40  lr: 0.000100  g_loss: 2.7733 (3.2723)  d_loss: 1.9041 (1.8990)  gan_loss: 0.8223 (0.8862)  pix_loss: 0.1939 (0.2386)  time: 53.9057  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [860/985]  eta: 1:52:39  lr: 0.000100  g_loss: 2.8023 (3.2674)  d_loss: 1.9027 (1.8990)  gan_loss: 0.8275 (0.8856)  pix_loss: 0.1977 (0.2382)  time: 53.9116  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [870/985]  eta: 1:43:38  lr: 0.000100  g_loss: 2.9678 (3.2684)  d_loss: 1.8959 (1.8988)  gan_loss: 0.8386 (0.8850)  pix_loss: 0.2161 (0.2383)  time: 54.0569  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [880/985]  eta: 1:34:38  lr: 0.000100  g_loss: 3.0053 (3.2655)  d_loss: 1.8964 (1.8989)  gan_loss: 0.8044 (0.8840)  pix_loss: 0.2208 (0.2382)  time: 54.1286  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [890/985]  eta: 1:25:37  lr: 0.000100  g_loss: 2.8933 (3.2615)  d_loss: 1.9035 (1.8989)  gan_loss: 0.8044 (0.8834)  pix_loss: 0.2096 (0.2378)  time: 54.0611  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [900/985]  eta: 1:16:36  lr: 0.000100  g_loss: 2.8933 (3.2586)  d_loss: 1.8980 (1.8988)  gan_loss: 0.8413 (0.8830)  pix_loss: 0.2074 (0.2376)  time: 54.0614  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [910/985]  eta: 1:07:35  lr: 0.000100  g_loss: 2.7403 (3.2515)  d_loss: 1.9031 (1.8990)  gan_loss: 0.8095 (0.8821)  pix_loss: 0.1938 (0.2369)  time: 54.0633  data: 0.0002  max mem: 38397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [920/985]  eta: 0:58:34  lr: 0.000100  g_loss: 2.6386 (3.2454)  d_loss: 1.9072 (1.8990)  gan_loss: 0.8062 (0.8817)  pix_loss: 0.1821 (0.2364)  time: 54.0626  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [930/985]  eta: 0:49:34  lr: 0.000100  g_loss: 2.6158 (3.2391)  d_loss: 1.9027 (1.8990)  gan_loss: 0.8460 (0.8813)  pix_loss: 0.1768 (0.2358)  time: 54.0637  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [940/985]  eta: 0:40:33  lr: 0.000100  g_loss: 2.7909 (3.2371)  d_loss: 1.9011 (1.8990)  gan_loss: 0.8343 (0.8808)  pix_loss: 0.1959 (0.2356)  time: 54.0643  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [950/985]  eta: 0:31:32  lr: 0.000100  g_loss: 2.9003 (3.2327)  d_loss: 1.9011 (1.8990)  gan_loss: 0.8048 (0.8799)  pix_loss: 0.2081 (0.2353)  time: 54.0640  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [960/985]  eta: 0:22:31  lr: 0.000100  g_loss: 2.7653 (3.2284)  d_loss: 1.9020 (1.8990)  gan_loss: 0.8208 (0.8796)  pix_loss: 0.1911 (0.2349)  time: 54.0647  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [970/985]  eta: 0:13:31  lr: 0.000100  g_loss: 2.7292 (3.2230)  d_loss: 1.9006 (1.8991)  gan_loss: 0.8297 (0.8790)  pix_loss: 0.1888 (0.2344)  time: 54.1674  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [980/985]  eta: 0:04:30  lr: 0.000100  g_loss: 2.6810 (3.2177)  d_loss: 1.9024 (1.8991)  gan_loss: 0.8234 (0.8785)  pix_loss: 0.1836 (0.2339)  time: 54.1670  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20]  [984/985]  eta: 0:00:54  lr: 0.000100  g_loss: 2.7151 (3.2165)  d_loss: 1.8992 (1.8990)  gan_loss: 0.8275 (0.8783)  pix_loss: 0.1880 (0.2338)  time: 54.1427  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:20] Total time: 14:47:47 (54.0784 s / it)\n",
      "Averaged stats: lr: 0.000100  g_loss: 2.7151 (3.2165)  d_loss: 1.8992 (1.8990)  gan_loss: 0.8275 (0.8783)  pix_loss: 0.1880 (0.2338)\n",
      "Valid: [epoch:20]  [ 0/14]  eta: 0:01:34  L1_loss: 0.0187 (0.0187)  time: 6.7195  data: 0.3108  max mem: 38397\n",
      "Valid: [epoch:20]  [13/14]  eta: 0:00:06  L1_loss: 0.0188 (0.0197)  time: 6.3107  data: 0.0223  max mem: 38397\n",
      "Valid: [epoch:20] Total time: 0:01:28 (6.3177 s / it)\n",
      "Averaged stats: L1_loss: 0.0188 (0.0197)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/epoch_20_input_n_20.png\n",
      "Train: [epoch:21]  [  0/985]  eta: 15:09:00  lr: 0.000100  g_loss: 2.6751 (2.6751)  d_loss: 1.8739 (1.8739)  gan_loss: 0.8660 (0.8660)  pix_loss: 0.1809 (0.1809)  time: 55.3707  data: 1.2532  max mem: 38397\n",
      "Train: [epoch:21]  [ 10/985]  eta: 14:40:32  lr: 0.000100  g_loss: 2.8255 (2.8870)  d_loss: 1.8824 (1.8819)  gan_loss: 0.7885 (0.8023)  pix_loss: 0.2040 (0.2085)  time: 54.1871  data: 0.1141  max mem: 38397\n",
      "Train: [epoch:21]  [ 20/985]  eta: 14:30:38  lr: 0.000100  g_loss: 3.1439 (3.0740)  d_loss: 1.8912 (1.8881)  gan_loss: 0.8214 (0.8483)  pix_loss: 0.2259 (0.2226)  time: 54.0714  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [ 30/985]  eta: 14:21:18  lr: 0.000100  g_loss: 3.1564 (3.0757)  d_loss: 1.9025 (1.8955)  gan_loss: 0.9440 (0.8930)  pix_loss: 0.2218 (0.2183)  time: 54.0726  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [ 40/985]  eta: 14:12:05  lr: 0.000100  g_loss: 2.9953 (3.0579)  d_loss: 1.9122 (1.8990)  gan_loss: 0.9997 (0.9228)  pix_loss: 0.2011 (0.2135)  time: 54.0676  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [ 50/985]  eta: 14:03:01  lr: 0.000100  g_loss: 2.8963 (3.0476)  d_loss: 1.9102 (1.9016)  gan_loss: 1.0024 (0.9392)  pix_loss: 0.1868 (0.2108)  time: 54.0729  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [ 60/985]  eta: 13:53:54  lr: 0.000100  g_loss: 2.8647 (3.0643)  d_loss: 1.9105 (1.9028)  gan_loss: 0.9800 (0.9424)  pix_loss: 0.1926 (0.2122)  time: 54.0724  data: 0.0001  max mem: 38397\n",
      "Train: [epoch:21]  [ 70/985]  eta: 13:44:50  lr: 0.000100  g_loss: 2.9669 (3.0425)  d_loss: 1.9113 (1.9042)  gan_loss: 0.9344 (0.9393)  pix_loss: 0.2049 (0.2103)  time: 54.0633  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [ 80/985]  eta: 13:35:47  lr: 0.000100  g_loss: 2.8504 (3.0108)  d_loss: 1.9081 (1.9036)  gan_loss: 0.9117 (0.9354)  pix_loss: 0.1930 (0.2075)  time: 54.0656  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [ 90/985]  eta: 13:27:07  lr: 0.000100  g_loss: 2.7832 (2.9911)  d_loss: 1.9019 (1.9033)  gan_loss: 0.8765 (0.9257)  pix_loss: 0.1884 (0.2065)  time: 54.1832  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [100/985]  eta: 13:18:03  lr: 0.000100  g_loss: 2.7913 (2.9772)  d_loss: 1.9041 (1.9034)  gan_loss: 0.8322 (0.9164)  pix_loss: 0.1948 (0.2061)  time: 54.1870  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [110/985]  eta: 13:08:59  lr: 0.000100  g_loss: 2.8647 (2.9791)  d_loss: 1.8939 (1.9019)  gan_loss: 0.8270 (0.9098)  pix_loss: 0.2046 (0.2069)  time: 54.0739  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [120/985]  eta: 12:59:57  lr: 0.000100  g_loss: 3.0181 (2.9929)  d_loss: 1.8902 (1.9011)  gan_loss: 0.8192 (0.9013)  pix_loss: 0.2170 (0.2092)  time: 54.0782  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [130/985]  eta: 12:50:55  lr: 0.000100  g_loss: 3.2904 (3.0307)  d_loss: 1.8937 (1.9005)  gan_loss: 0.8320 (0.8991)  pix_loss: 0.2401 (0.2132)  time: 54.0829  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [140/985]  eta: 12:41:52  lr: 0.000100  g_loss: 3.5722 (3.0854)  d_loss: 1.8915 (1.8997)  gan_loss: 0.8392 (0.8938)  pix_loss: 0.2735 (0.2192)  time: 54.0774  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [150/985]  eta: 12:32:49  lr: 0.000100  g_loss: 3.6141 (3.1179)  d_loss: 1.8895 (1.8987)  gan_loss: 0.8492 (0.8922)  pix_loss: 0.2755 (0.2226)  time: 54.0700  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [160/985]  eta: 12:23:47  lr: 0.000100  g_loss: 3.5442 (3.1438)  d_loss: 1.8983 (1.8991)  gan_loss: 0.8876 (0.8937)  pix_loss: 0.2638 (0.2250)  time: 54.0720  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [170/985]  eta: 12:14:45  lr: 0.000100  g_loss: 3.3949 (3.1596)  d_loss: 1.9022 (1.8989)  gan_loss: 0.9292 (0.8966)  pix_loss: 0.2502 (0.2263)  time: 54.0721  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [180/985]  eta: 12:05:43  lr: 0.000100  g_loss: 3.3008 (3.1604)  d_loss: 1.9022 (1.8991)  gan_loss: 0.9065 (0.8967)  pix_loss: 0.2340 (0.2264)  time: 54.0707  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [190/985]  eta: 11:56:49  lr: 0.000100  g_loss: 3.0492 (3.1537)  d_loss: 1.9017 (1.8990)  gan_loss: 0.8816 (0.8952)  pix_loss: 0.2176 (0.2258)  time: 54.1661  data: 0.0002  max mem: 38397\n",
      "Train: [epoch:21]  [200/985]  eta: 11:47:59  lr: 0.000100  g_loss: 2.9941 (3.1494)  d_loss: 1.8994 (1.8987)  gan_loss: 0.8591 (0.8929)  pix_loss: 0.2158 (0.2256)  time: 54.3096  data: 0.0002  max mem: 38397\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--batch-size 7 \\\n",
    "--epochs 1000 \\\n",
    "--lr_scheduler \"lambda\" \\\n",
    "--lr 1e-4 \\\n",
    "--data-set 'Sinogram_DCM' \\\n",
    "--model-name 'Ours_GPEN_GAN' \\\n",
    "--criterion 'L1 Loss' \\\n",
    "--output_dir '/workspace/sunggu/4.Dose_img2img/model/[Ours]Ours_GPEN_GAN_lambda' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]Ours_GPEN_GAN_lambda/low2high/' \\\n",
    "--validate-every 2 \\\n",
    "--num_workers 4 \\\n",
    "--criterion_mode 'single label' \\\n",
    "--multiple_GT \"False\" \\\n",
    "--patch_training \"True\" \\\n",
    "--multi-gpu-mode 'Single' \\\n",
    "--resume '/workspace/sunggu/4.Dose_img2img/model/[Ours]Ours_GPEN_GAN_lambda/epoch_4_checkpoint.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_log(path):\n",
    "    log_list = []\n",
    "    lines = open(path, 'r').read().splitlines() \n",
    "    for i in range(len(lines)):\n",
    "        exec('log_list.append('+lines[i] + ')')\n",
    "    return  log_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = read_log(path = '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/log.txt')\n",
    "\n",
    "train_lr   = [ log_list[i]['train_lr'] for i in range(len(log_list)) ]\n",
    "train_loss = [ log_list[i]['train_loss'] for i in range(len(log_list)) ]\n",
    "valid_loss = [ log_list[i]['valid_loss'] for i in range(len(log_list)) ]\n",
    "epoch      = [ log_list[i]['epoch'] for i in range(len(log_list)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(train_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(valid_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(np.argsort(valid_loss)[:10]) & set(np.argsort(train_loss)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py \\\n",
    "--training-mode 'sinogram' \\\n",
    "--data-set 'TEST_Sinogram_DCM' \\\n",
    "--model-name 'ED_CNN' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Test/png/[Privious]ED_CNN/epoch_999/' \\\n",
    "--num_workers 4 \\\n",
    "--pin-mem \\\n",
    "--range-minus1-plus1 'False' \\\n",
    "--teacher_forcing \"False\" \\\n",
    "--resume '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/epoch_999_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 978 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Original === \n",
    "PSNR avg: 54.4628 \n",
    "SSIM avg: 0.9956 \n",
    "RMSE avg: 7.9607\n",
    "\n",
    "\n",
    "Predictions === \n",
    "PSNR avg: 57.6190 \n",
    "SSIM avg: 0.9980 \n",
    "RMSE avg: 5.5423\n",
    "***********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "int(math.log(64, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 7):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
