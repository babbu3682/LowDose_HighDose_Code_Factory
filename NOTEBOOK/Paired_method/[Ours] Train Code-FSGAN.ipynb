{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CUDA 11.1\n",
    "# !pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE -> MAE Loss 꿀팁!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 16 13:09:24 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:18:00.0 Off |                  Off |\r\n",
      "| 30%   28C    P8    17W / 300W |      1MiB / 48685MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:3B:00.0 Off |                  Off |\r\n",
      "| 30%   29C    P8    18W / 300W |      1MiB / 48685MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA RTX A6000    Off  | 00000000:86:00.0 Off |                  Off |\r\n",
      "| 30%   30C    P8    24W / 300W |      1MiB / 48685MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA RTX A6000    Off  | 00000000:AF:00.0 Off |                  Off |\r\n",
      "| 49%   74C    P2   294W / 300W |  44026MiB / 48685MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/sunggu/4.Dose_img2img/scripts study\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/sunggu/4.Dose_img2img/scripts study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 갯수 =  64\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections.abc as container_abcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "***********************************************\n",
      "Dataset Name:  Sinogram_DCM\n",
      "---------- Model ----------\n",
      "Resume From:  \n",
      "Output To:  /workspace/sunggu/4.Dose_img2img/model/[Ours]FSGAN\n",
      "Save   To:  /workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/\n",
      "---------- Optimizer ----------\n",
      "Learning Rate:  0.0001\n",
      "Batchsize:  8\n",
      "Loading dataset ....\n",
      "Train [Total]  number =  6899\n",
      "Valid [Total]  number =  14\n",
      "Creating criterion: L1 Loss\n",
      "Creating model: FSGAN\n",
      "Number of Learnable Params: 196962403\n",
      "FSGAN(\n",
      "  (Generator): ConvMixer_Generator(\n",
      "    (img_encoder): ConvEncoder(\n",
      "      (layer1): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (layer2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (layer3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm3): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (layer4): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (layer5): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (fc_mu): Linear(in_features=2048, out_features=64, bias=True)\n",
      "      (fc_var): Linear(in_features=2048, out_features=64, bias=True)\n",
      "      (actvn): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (noise_embed): Linear(in_features=64, out_features=1048576, bias=True)\n",
      "    (mixer_block1): SPADE_ConvMixer_Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
      "      (gelu1): GELU()\n",
      "      (norm1): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gelu2): GELU()\n",
      "      (norm2): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (mixer_block2): SPADE_ConvMixer_Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
      "      (gelu1): GELU()\n",
      "      (norm1): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gelu2): GELU()\n",
      "      (norm2): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (mixer_block3): SPADE_ConvMixer_Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
      "      (gelu1): GELU()\n",
      "      (norm1): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gelu2): GELU()\n",
      "      (norm2): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (mixer_block4): SPADE_ConvMixer_Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
      "      (gelu1): GELU()\n",
      "      (norm1): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gelu2): GELU()\n",
      "      (norm2): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (mixer_block5): SPADE_ConvMixer_Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
      "      (gelu1): GELU()\n",
      "      (norm1): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gelu2): GELU()\n",
      "      (norm2): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (mixer_block6): SPADE_ConvMixer_Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
      "      (gelu1): GELU()\n",
      "      (norm1): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gelu2): GELU()\n",
      "      (norm2): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (mixer_block7): SPADE_ConvMixer_Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
      "      (gelu1): GELU()\n",
      "      (norm1): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gelu2): GELU()\n",
      "      (norm2): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (mixer_block8): SPADE_ConvMixer_Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(9, 9), stride=(1, 1), padding=same, groups=256)\n",
      "      (gelu1): GELU()\n",
      "      (norm1): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (gelu2): GELU()\n",
      "      (norm2): SPADE(\n",
      "        (param_free_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (mlp_shared): Sequential(\n",
      "          (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): ReLU()\n",
      "        )\n",
      "        (mlp_gamma): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (mlp_beta): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (head): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (Low_discriminator): Low_UNet(\n",
      "    (down_blocks): ModuleList(\n",
      "      (0): DownBlock(\n",
      "        (conv_res): Conv2d(3, 64, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (1): DownBlock(\n",
      "        (conv_res): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (2): DownBlock(\n",
      "        (conv_res): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (3): DownBlock(\n",
      "        (conv_res): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (4): DownBlock(\n",
      "        (conv_res): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (5): DownBlock(\n",
      "        (conv_res): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (6): DownBlock(\n",
      "        (conv_res): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (to_logit): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (1): AdaptiveAvgPool2d(output_size=1)\n",
      "      (2): Flatten(start_dim=1, end_dim=-1)\n",
      "      (3): Linear(in_features=512, out_features=1, bias=True)\n",
      "    )\n",
      "    (up_blocks): ModuleList(\n",
      "      (0): UpBlock(\n",
      "        (shortcut): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (1): UpBlock(\n",
      "        (shortcut): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (2): UpBlock(\n",
      "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (3): UpBlock(\n",
      "        (shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (4): UpBlock(\n",
      "        (shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (5): UpBlock(\n",
      "        (shortcut): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "    )\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (conv_out): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (lf_conv): LF_Conv()\n",
      "  )\n",
      "  (High_discriminator): High_UNet(\n",
      "    (down_blocks): ModuleList(\n",
      "      (0): DownBlock(\n",
      "        (conv_res): Conv2d(21, 64, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(21, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (1): DownBlock(\n",
      "        (conv_res): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (2): DownBlock(\n",
      "        (conv_res): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (3): DownBlock(\n",
      "        (conv_res): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (4): DownBlock(\n",
      "        (conv_res): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (5): DownBlock(\n",
      "        (conv_res): Conv2d(512, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (down): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (6): DownBlock(\n",
      "        (conv_res): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (to_logit): Sequential(\n",
      "      (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (1): AdaptiveAvgPool2d(output_size=1)\n",
      "      (2): Flatten(start_dim=1, end_dim=-1)\n",
      "      (3): Linear(in_features=512, out_features=1, bias=True)\n",
      "    )\n",
      "    (up_blocks): ModuleList(\n",
      "      (0): UpBlock(\n",
      "        (shortcut): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (1): UpBlock(\n",
      "        (shortcut): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (2): UpBlock(\n",
      "        (shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (3): UpBlock(\n",
      "        (shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (4): UpBlock(\n",
      "        (shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "      (5): UpBlock(\n",
      "        (shortcut): Conv2d(64, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "          (2): Conv2d(21, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        )\n",
      "        (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "      )\n",
      "    )\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (conv_out): Conv2d(21, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (hf_conv): HF_Conv()\n",
      "  )\n",
      "  (KLDLoss): KLDLoss()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for 1000 epochs\n",
      "/home/sunggu/.local/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/home/sunggu/.local/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Train: [epoch:0]  [  0/862]  eta: 1:18:11  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3267 (0.3267)  loss/enc_loss: 26.3196 (26.3196)  time: 5.4431  data: 1.2463  max mem: 29671\n",
      "Train: [epoch:0]  [ 10/862]  eta: 1:00:34  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3283 (0.3301)  loss/enc_loss: 26.2347 (26.0225)  time: 4.2655  data: 0.1134  max mem: 31350\n",
      "Train: [epoch:0]  [ 20/862]  eta: 0:59:09  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3314 (0.3313)  loss/enc_loss: 26.0429 (26.0245)  time: 4.1541  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [ 30/862]  eta: 0:58:16  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3253 (0.3272)  loss/enc_loss: 26.1777 (26.1199)  time: 4.1675  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [ 40/862]  eta: 0:57:31  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3211 (0.3271)  loss/enc_loss: 26.2559 (26.1583)  time: 4.1819  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [ 50/862]  eta: 0:56:49  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3260 (0.3271)  loss/enc_loss: 26.1767 (26.1407)  time: 4.1925  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [ 60/862]  eta: 0:56:08  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3267 (0.3263)  loss/enc_loss: 26.1367 (26.1465)  time: 4.2017  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [ 70/862]  eta: 0:55:27  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3285 (0.3270)  loss/enc_loss: 26.0928 (26.1293)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [ 80/862]  eta: 0:54:46  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3280 (0.3264)  loss/enc_loss: 26.1214 (26.1433)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [ 90/862]  eta: 0:54:04  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3219 (0.3256)  loss/enc_loss: 26.0948 (26.1109)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [100/862]  eta: 0:53:23  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3190 (0.3253)  loss/enc_loss: 26.0615 (26.1092)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [110/862]  eta: 0:52:41  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3157 (0.3247)  loss/enc_loss: 26.1849 (26.0942)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [120/862]  eta: 0:51:59  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3182 (0.3247)  loss/enc_loss: 26.1930 (26.1031)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [130/862]  eta: 0:51:18  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3176 (0.3241)  loss/enc_loss: 25.9921 (26.0900)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [140/862]  eta: 0:50:36  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3203 (0.3242)  loss/enc_loss: 25.8278 (26.0793)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [150/862]  eta: 0:49:54  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3243 (0.3244)  loss/enc_loss: 25.8826 (26.0695)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [160/862]  eta: 0:49:12  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3263 (0.3244)  loss/enc_loss: 25.9711 (26.0664)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [170/862]  eta: 0:48:30  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3246 (0.3241)  loss/enc_loss: 25.9516 (26.0556)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [180/862]  eta: 0:47:48  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3279 (0.3246)  loss/enc_loss: 25.8357 (26.0406)  time: 4.2113  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [190/862]  eta: 0:47:06  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3305 (0.3251)  loss/enc_loss: 25.7811 (26.0334)  time: 4.2117  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [200/862]  eta: 0:46:24  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3313 (0.3254)  loss/enc_loss: 25.8277 (26.0285)  time: 4.2111  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [210/862]  eta: 0:45:43  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3311 (0.3255)  loss/enc_loss: 25.8288 (26.0171)  time: 4.2114  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [220/862]  eta: 0:45:01  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3215 (0.3252)  loss/enc_loss: 25.9975 (26.0168)  time: 4.2124  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [230/862]  eta: 0:44:19  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3212 (0.3250)  loss/enc_loss: 25.8024 (26.0026)  time: 4.2144  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [240/862]  eta: 0:43:37  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3240 (0.3250)  loss/enc_loss: 25.8068 (25.9961)  time: 4.2127  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [250/862]  eta: 0:42:55  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3251 (0.3249)  loss/enc_loss: 25.8068 (25.9793)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [260/862]  eta: 0:42:13  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3251 (0.3247)  loss/enc_loss: 25.6468 (25.9750)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [270/862]  eta: 0:41:31  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3256 (0.3248)  loss/enc_loss: 25.6468 (25.9633)  time: 4.2227  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [280/862]  eta: 0:40:50  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3223 (0.3246)  loss/enc_loss: 25.6294 (25.9555)  time: 4.2444  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [290/862]  eta: 0:40:09  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3189 (0.3246)  loss/enc_loss: 25.6294 (25.9440)  time: 4.2524  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [300/862]  eta: 0:39:27  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3176 (0.3241)  loss/enc_loss: 25.7157 (25.9374)  time: 4.2564  data: 0.0002  max mem: 31350\n",
      "Train: [epoch:0]  [310/862]  eta: 0:38:45  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3158 (0.3239)  loss/enc_loss: 25.8951 (25.9426)  time: 4.2353  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [320/862]  eta: 0:38:03  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3201 (0.3238)  loss/enc_loss: 25.7881 (25.9350)  time: 4.2107  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [330/862]  eta: 0:37:21  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3202 (0.3237)  loss/enc_loss: 25.6308 (25.9247)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [340/862]  eta: 0:36:39  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3211 (0.3235)  loss/enc_loss: 25.4562 (25.9105)  time: 4.2105  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [350/862]  eta: 0:35:57  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3226 (0.3235)  loss/enc_loss: 25.5251 (25.9080)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [360/862]  eta: 0:35:14  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3269 (0.3237)  loss/enc_loss: 25.6851 (25.8978)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [370/862]  eta: 0:34:32  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3279 (0.3238)  loss/enc_loss: 25.5325 (25.8865)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [380/862]  eta: 0:33:50  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3199 (0.3237)  loss/enc_loss: 25.6249 (25.8818)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [390/862]  eta: 0:33:08  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3197 (0.3236)  loss/enc_loss: 25.5355 (25.8722)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [400/862]  eta: 0:32:26  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3199 (0.3234)  loss/enc_loss: 25.5355 (25.8652)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [410/862]  eta: 0:31:44  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3254 (0.3235)  loss/enc_loss: 25.5399 (25.8578)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [420/862]  eta: 0:31:01  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3255 (0.3234)  loss/enc_loss: 25.4579 (25.8484)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [430/862]  eta: 0:30:19  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3215 (0.3234)  loss/enc_loss: 25.5732 (25.8452)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [440/862]  eta: 0:29:37  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3239 (0.3233)  loss/enc_loss: 25.5028 (25.8358)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [450/862]  eta: 0:28:55  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3178 (0.3233)  loss/enc_loss: 25.3083 (25.8248)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [460/862]  eta: 0:28:13  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3182 (0.3233)  loss/enc_loss: 25.3083 (25.8192)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [470/862]  eta: 0:27:31  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3184 (0.3231)  loss/enc_loss: 25.5898 (25.8147)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [480/862]  eta: 0:26:48  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3160 (0.3230)  loss/enc_loss: 25.3240 (25.8013)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [490/862]  eta: 0:26:06  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3119 (0.3228)  loss/enc_loss: 25.3293 (25.7972)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [500/862]  eta: 0:25:24  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3120 (0.3227)  loss/enc_loss: 25.4925 (25.7878)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [510/862]  eta: 0:24:42  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3205 (0.3227)  loss/enc_loss: 25.2664 (25.7766)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [520/862]  eta: 0:24:00  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3265 (0.3228)  loss/enc_loss: 25.2664 (25.7673)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [530/862]  eta: 0:23:18  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3144 (0.3226)  loss/enc_loss: 25.1470 (25.7537)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [540/862]  eta: 0:22:36  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3171 (0.3226)  loss/enc_loss: 25.0011 (25.7428)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [550/862]  eta: 0:21:54  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3237 (0.3227)  loss/enc_loss: 25.0806 (25.7335)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [560/862]  eta: 0:21:11  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3246 (0.3226)  loss/enc_loss: 25.4420 (25.7270)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [570/862]  eta: 0:20:29  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3182 (0.3226)  loss/enc_loss: 25.4068 (25.7197)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [580/862]  eta: 0:19:47  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3148 (0.3225)  loss/enc_loss: 25.2025 (25.7087)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [590/862]  eta: 0:19:05  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3130 (0.3223)  loss/enc_loss: 25.0115 (25.7023)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [600/862]  eta: 0:18:23  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3138 (0.3223)  loss/enc_loss: 25.2753 (25.6972)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [610/862]  eta: 0:17:41  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3227 (0.3224)  loss/enc_loss: 25.2753 (25.6917)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [620/862]  eta: 0:16:59  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3232 (0.3224)  loss/enc_loss: 25.2178 (25.6849)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [630/862]  eta: 0:16:17  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3235 (0.3224)  loss/enc_loss: 25.1832 (25.6782)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [640/862]  eta: 0:15:34  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3182 (0.3223)  loss/enc_loss: 25.2333 (25.6732)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [650/862]  eta: 0:14:52  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3171 (0.3223)  loss/enc_loss: 25.0942 (25.6628)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [660/862]  eta: 0:14:10  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3173 (0.3223)  loss/enc_loss: 24.9198 (25.6531)  time: 4.2095  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:0]  [670/862]  eta: 0:13:28  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3173 (0.3222)  loss/enc_loss: 25.1933 (25.6457)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [680/862]  eta: 0:12:46  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3163 (0.3222)  loss/enc_loss: 25.3117 (25.6444)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [690/862]  eta: 0:12:04  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3246 (0.3222)  loss/enc_loss: 25.1637 (25.6334)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [700/862]  eta: 0:11:22  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3220 (0.3222)  loss/enc_loss: 24.9500 (25.6260)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [710/862]  eta: 0:10:40  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3190 (0.3222)  loss/enc_loss: 24.9781 (25.6161)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [720/862]  eta: 0:09:57  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3200 (0.3223)  loss/enc_loss: 24.8199 (25.6069)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [730/862]  eta: 0:09:15  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3234 (0.3222)  loss/enc_loss: 24.9821 (25.5982)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [740/862]  eta: 0:08:33  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3260 (0.3223)  loss/enc_loss: 24.9034 (25.5894)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [750/862]  eta: 0:07:51  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3247 (0.3222)  loss/enc_loss: 24.7795 (25.5794)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [760/862]  eta: 0:07:09  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3195 (0.3222)  loss/enc_loss: 25.0194 (25.5731)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [770/862]  eta: 0:06:27  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3195 (0.3221)  loss/enc_loss: 25.2322 (25.5654)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [780/862]  eta: 0:05:45  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3197 (0.3222)  loss/enc_loss: 24.7084 (25.5547)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [790/862]  eta: 0:05:03  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3263 (0.3221)  loss/enc_loss: 24.7945 (25.5464)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [800/862]  eta: 0:04:21  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3196 (0.3222)  loss/enc_loss: 24.7219 (25.5371)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [810/862]  eta: 0:03:38  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3204 (0.3222)  loss/enc_loss: 24.7219 (25.5272)  time: 4.2113  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [820/862]  eta: 0:02:56  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3214 (0.3221)  loss/enc_loss: 24.7509 (25.5171)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [830/862]  eta: 0:02:14  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3191 (0.3221)  loss/enc_loss: 24.7347 (25.5069)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [840/862]  eta: 0:01:32  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3191 (0.3220)  loss/enc_loss: 24.7528 (25.4999)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [850/862]  eta: 0:00:50  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3200 (0.3220)  loss/enc_loss: 24.8691 (25.4921)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [860/862]  eta: 0:00:08  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3206 (0.3220)  loss/enc_loss: 24.7895 (25.4836)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0]  [861/862]  eta: 0:00:04  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3218 (0.3220)  loss/enc_loss: 24.7849 (25.4822)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:0] Total time: 1:00:29 (4.2110 s / it)\n",
      "Averaged stats: lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3218 (0.3220)  loss/enc_loss: 24.7849 (25.4822)\n",
      "Valid: [epoch:0]  [ 0/14]  eta: 0:00:43  L1_loss: 0.2453 (0.2453)  time: 3.0917  data: 0.4236  max mem: 31350\n",
      "Valid: [epoch:0]  [13/14]  eta: 0:00:02  L1_loss: 0.2409 (0.2421)  time: 2.6632  data: 0.0303  max mem: 31350\n",
      "Valid: [epoch:0] Total time: 0:00:37 (2.6721 s / it)\n",
      "Averaged stats: L1_loss: 0.2409 (0.2421)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_0_input_n_20.png\n",
      "/home/sunggu/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Train: [epoch:1]  [  0/862]  eta: 1:17:39  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3294 (0.3294)  loss/enc_loss: 25.0267 (25.0267)  time: 5.4050  data: 1.2149  max mem: 31350\n",
      "Train: [epoch:1]  [ 10/862]  eta: 1:00:55  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3173 (0.3199)  loss/enc_loss: 25.0267 (24.9942)  time: 4.2908  data: 0.1105  max mem: 31350\n",
      "Train: [epoch:1]  [ 20/862]  eta: 0:59:32  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3173 (0.3195)  loss/enc_loss: 24.8783 (24.9148)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [ 30/862]  eta: 0:58:36  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3141 (0.3187)  loss/enc_loss: 24.8780 (24.8564)  time: 4.1921  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [ 40/862]  eta: 0:57:48  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3206 (0.3206)  loss/enc_loss: 24.6478 (24.8060)  time: 4.1941  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [ 50/862]  eta: 0:57:04  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3206 (0.3205)  loss/enc_loss: 24.6478 (24.7798)  time: 4.2010  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [ 60/862]  eta: 0:56:20  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3159 (0.3196)  loss/enc_loss: 24.7016 (24.7893)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [ 70/862]  eta: 0:55:38  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3198 (0.3203)  loss/enc_loss: 24.7774 (24.7975)  time: 4.2123  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [ 80/862]  eta: 0:54:56  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3232 (0.3199)  loss/enc_loss: 24.7282 (24.7812)  time: 4.2137  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [ 90/862]  eta: 0:54:14  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3138 (0.3191)  loss/enc_loss: 24.4167 (24.7361)  time: 4.2156  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [100/862]  eta: 0:53:34  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3133 (0.3183)  loss/enc_loss: 24.5206 (24.7222)  time: 4.2342  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [110/862]  eta: 0:52:53  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3157 (0.3184)  loss/enc_loss: 24.5737 (24.7127)  time: 4.2420  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [120/862]  eta: 0:52:11  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3171 (0.3181)  loss/enc_loss: 24.5962 (24.7094)  time: 4.2237  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [130/862]  eta: 0:51:28  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3172 (0.3185)  loss/enc_loss: 24.5962 (24.6996)  time: 4.2130  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [140/862]  eta: 0:50:45  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3172 (0.3182)  loss/enc_loss: 24.4177 (24.6708)  time: 4.2128  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [150/862]  eta: 0:50:03  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3191 (0.3182)  loss/enc_loss: 24.3077 (24.6516)  time: 4.2132  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [160/862]  eta: 0:49:21  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3168 (0.3180)  loss/enc_loss: 24.4063 (24.6524)  time: 4.2139  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [170/862]  eta: 0:48:38  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3096 (0.3177)  loss/enc_loss: 24.6053 (24.6511)  time: 4.2143  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [180/862]  eta: 0:47:56  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3186 (0.3181)  loss/enc_loss: 24.4573 (24.6370)  time: 4.2131  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [190/862]  eta: 0:47:14  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3192 (0.3183)  loss/enc_loss: 24.4287 (24.6317)  time: 4.2116  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [200/862]  eta: 0:46:31  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3244 (0.3187)  loss/enc_loss: 24.3291 (24.6169)  time: 4.2116  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [210/862]  eta: 0:45:49  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3229 (0.3186)  loss/enc_loss: 24.5096 (24.6166)  time: 4.2116  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [220/862]  eta: 0:45:06  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3119 (0.3181)  loss/enc_loss: 24.5944 (24.6156)  time: 4.2115  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [230/862]  eta: 0:44:24  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3131 (0.3182)  loss/enc_loss: 24.3422 (24.6029)  time: 4.2112  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [240/862]  eta: 0:43:42  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3171 (0.3182)  loss/enc_loss: 24.2575 (24.6032)  time: 4.2109  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [250/862]  eta: 0:43:00  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3178 (0.3183)  loss/enc_loss: 24.6142 (24.5983)  time: 4.2108  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [260/862]  eta: 0:42:17  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3160 (0.3183)  loss/enc_loss: 24.5271 (24.5918)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [270/862]  eta: 0:41:35  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3179 (0.3185)  loss/enc_loss: 24.3724 (24.5872)  time: 4.2108  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [280/862]  eta: 0:40:53  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3242 (0.3187)  loss/enc_loss: 24.0481 (24.5671)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [290/862]  eta: 0:40:11  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3205 (0.3186)  loss/enc_loss: 23.9789 (24.5599)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [300/862]  eta: 0:39:28  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3099 (0.3181)  loss/enc_loss: 24.4563 (24.5577)  time: 4.2106  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [310/862]  eta: 0:38:46  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3034 (0.3177)  loss/enc_loss: 24.5321 (24.5568)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [320/862]  eta: 0:38:04  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 2.0000 (2.0000)  loss/pix_loss: 0.3099 (0.3178)  loss/enc_loss: 24.4421 (24.5479)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [330/862]  eta: 0:37:22  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3179 (0.3179)  loss/enc_loss: 24.2847 (24.5376)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [340/862]  eta: 0:36:39  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3189 (0.3178)  loss/enc_loss: 24.2863 (24.5368)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [350/862]  eta: 0:35:57  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3161 (0.3177)  loss/enc_loss: 24.4770 (24.5323)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [360/862]  eta: 0:35:15  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3195 (0.3178)  loss/enc_loss: 24.2596 (24.5234)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [370/862]  eta: 0:34:33  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3217 (0.3180)  loss/enc_loss: 24.2191 (24.5123)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [380/862]  eta: 0:33:51  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3212 (0.3180)  loss/enc_loss: 24.2191 (24.5040)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [390/862]  eta: 0:33:08  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3212 (0.3181)  loss/enc_loss: 24.1735 (24.4956)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [400/862]  eta: 0:32:26  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3195 (0.3181)  loss/enc_loss: 23.9844 (24.4848)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [410/862]  eta: 0:31:44  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3199 (0.3182)  loss/enc_loss: 24.0884 (24.4795)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [420/862]  eta: 0:31:02  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3200 (0.3182)  loss/enc_loss: 24.1702 (24.4699)  time: 4.2115  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [430/862]  eta: 0:30:20  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3210 (0.3183)  loss/enc_loss: 23.9528 (24.4575)  time: 4.2149  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [440/862]  eta: 0:29:38  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3208 (0.3182)  loss/enc_loss: 23.8854 (24.4494)  time: 4.2141  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [450/862]  eta: 0:28:55  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3127 (0.3182)  loss/enc_loss: 24.2003 (24.4479)  time: 4.2112  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [460/862]  eta: 0:28:13  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3127 (0.3181)  loss/enc_loss: 24.3019 (24.4465)  time: 4.2122  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [470/862]  eta: 0:27:31  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3053 (0.3179)  loss/enc_loss: 24.1405 (24.4371)  time: 4.2130  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [480/862]  eta: 0:26:49  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3139 (0.3179)  loss/enc_loss: 24.0053 (24.4252)  time: 4.2120  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [490/862]  eta: 0:26:07  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3139 (0.3177)  loss/enc_loss: 24.0200 (24.4155)  time: 4.2116  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [500/862]  eta: 0:25:25  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3094 (0.3176)  loss/enc_loss: 24.0411 (24.4080)  time: 4.2129  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [510/862]  eta: 0:24:43  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3174 (0.3177)  loss/enc_loss: 23.9608 (24.3967)  time: 4.2115  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [520/862]  eta: 0:24:00  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3159 (0.3176)  loss/enc_loss: 24.0244 (24.3932)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [530/862]  eta: 0:23:18  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3131 (0.3176)  loss/enc_loss: 24.0732 (24.3852)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [540/862]  eta: 0:22:36  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3155 (0.3177)  loss/enc_loss: 23.9686 (24.3784)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [550/862]  eta: 0:21:54  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3268 (0.3179)  loss/enc_loss: 23.8992 (24.3643)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [560/862]  eta: 0:21:12  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3251 (0.3179)  loss/enc_loss: 23.8359 (24.3580)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [570/862]  eta: 0:20:30  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3233 (0.3180)  loss/enc_loss: 23.8269 (24.3484)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [580/862]  eta: 0:19:48  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (2.0000)  loss/pix_loss: 0.3223 (0.3180)  loss/enc_loss: 23.7953 (24.3385)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [590/862]  eta: 0:19:05  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3113 (0.3178)  loss/enc_loss: 23.8981 (24.3343)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [600/862]  eta: 0:18:23  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3113 (0.3178)  loss/enc_loss: 24.0353 (24.3286)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [610/862]  eta: 0:17:41  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3200 (0.3178)  loss/enc_loss: 23.9766 (24.3239)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [620/862]  eta: 0:16:59  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3209 (0.3179)  loss/enc_loss: 23.8493 (24.3144)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [630/862]  eta: 0:16:17  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3142 (0.3177)  loss/enc_loss: 23.7491 (24.3066)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [640/862]  eta: 0:15:35  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3061 (0.3176)  loss/enc_loss: 23.7592 (24.2987)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [650/862]  eta: 0:14:53  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3143 (0.3176)  loss/enc_loss: 23.7829 (24.2904)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [660/862]  eta: 0:14:10  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3143 (0.3175)  loss/enc_loss: 23.7829 (24.2826)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [670/862]  eta: 0:13:28  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3199 (0.3176)  loss/enc_loss: 23.7549 (24.2732)  time: 4.2108  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [680/862]  eta: 0:12:46  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3196 (0.3176)  loss/enc_loss: 23.7549 (24.2689)  time: 4.2113  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [690/862]  eta: 0:12:04  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3191 (0.3176)  loss/enc_loss: 23.8406 (24.2633)  time: 4.2109  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [700/862]  eta: 0:11:22  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3175 (0.3175)  loss/enc_loss: 23.8406 (24.2582)  time: 4.2105  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [710/862]  eta: 0:10:40  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3173 (0.3176)  loss/enc_loss: 23.7122 (24.2496)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [720/862]  eta: 0:09:58  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3228 (0.3176)  loss/enc_loss: 23.6807 (24.2436)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [730/862]  eta: 0:09:16  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3119 (0.3175)  loss/enc_loss: 23.9725 (24.2408)  time: 4.2107  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [740/862]  eta: 0:08:33  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3130 (0.3175)  loss/enc_loss: 23.6980 (24.2326)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [750/862]  eta: 0:07:51  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3209 (0.3175)  loss/enc_loss: 23.6652 (24.2264)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [760/862]  eta: 0:07:09  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3192 (0.3175)  loss/enc_loss: 23.8244 (24.2243)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [770/862]  eta: 0:06:27  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3156 (0.3174)  loss/enc_loss: 23.8244 (24.2180)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [780/862]  eta: 0:05:45  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3159 (0.3173)  loss/enc_loss: 23.7215 (24.2115)  time: 4.2091  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [790/862]  eta: 0:05:03  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3159 (0.3172)  loss/enc_loss: 23.5191 (24.2044)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [800/862]  eta: 0:04:21  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3152 (0.3172)  loss/enc_loss: 23.6754 (24.1975)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [810/862]  eta: 0:03:39  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3095 (0.3172)  loss/enc_loss: 23.6656 (24.1893)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [820/862]  eta: 0:02:56  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3162 (0.3173)  loss/enc_loss: 23.4074 (24.1800)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [830/862]  eta: 0:02:14  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3161 (0.3172)  loss/enc_loss: 23.5294 (24.1736)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [840/862]  eta: 0:01:32  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3124 (0.3172)  loss/enc_loss: 23.5252 (24.1642)  time: 4.2113  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [850/862]  eta: 0:00:50  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3208 (0.3172)  loss/enc_loss: 23.4350 (24.1574)  time: 4.2119  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [860/862]  eta: 0:00:08  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3199 (0.3172)  loss/enc_loss: 23.5389 (24.1505)  time: 4.2118  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1]  [861/862]  eta: 0:00:04  lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3199 (0.3172)  loss/enc_loss: 23.5389 (24.1497)  time: 4.2119  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:1] Total time: 1:00:30 (4.2121 s / it)\n",
      "Averaged stats: lr: 0.000000  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3199 (0.3172)  loss/enc_loss: 23.5389 (24.1497)\n",
      "Valid: [epoch:1]  [ 0/14]  eta: 0:00:40  L1_loss: 0.2342 (0.2342)  time: 2.9283  data: 0.3718  max mem: 31350\n",
      "Valid: [epoch:1]  [13/14]  eta: 0:00:02  L1_loss: 0.2367 (0.2375)  time: 2.5551  data: 0.0266  max mem: 31350\n",
      "Valid: [epoch:1] Total time: 0:00:35 (2.5649 s / it)\n",
      "Averaged stats: L1_loss: 0.2367 (0.2375)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_1_input_n_20.png\n",
      "Train: [epoch:2]  [  0/862]  eta: 1:13:16  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9999 (1.9999)  loss/pix_loss: 0.3158 (0.3158)  loss/enc_loss: 23.3852 (23.3852)  time: 5.1006  data: 0.8689  max mem: 31350\n",
      "Train: [epoch:2]  [ 10/862]  eta: 1:00:57  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9986 (1.9987)  loss/pix_loss: 0.2892 (0.2933)  loss/enc_loss: 18.0100 (18.5828)  time: 4.2926  data: 0.0791  max mem: 31350\n",
      "Train: [epoch:2]  [ 20/862]  eta: 0:59:42  lr: 0.000010  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9977 (1.9980)  loss/pix_loss: 0.2652 (0.2757)  loss/enc_loss: 15.9837 (16.8833)  time: 4.2118  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [ 30/862]  eta: 0:58:48  lr: 0.000010  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9968 (1.9976)  loss/pix_loss: 0.2482 (0.2628)  loss/enc_loss: 13.9706 (15.7030)  time: 4.2129  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [ 40/862]  eta: 0:58:00  lr: 0.000010  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9966 (1.9973)  loss/pix_loss: 0.2292 (0.2536)  loss/enc_loss: 12.9915 (14.8988)  time: 4.2137  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [ 50/862]  eta: 0:57:14  lr: 0.000010  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9965 (1.9972)  loss/pix_loss: 0.2208 (0.2463)  loss/enc_loss: 11.7500 (14.2325)  time: 4.2117  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [ 60/862]  eta: 0:56:29  lr: 0.000010  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9965 (1.9971)  loss/pix_loss: 0.2152 (0.2408)  loss/enc_loss: 11.2168 (13.6764)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [ 70/862]  eta: 0:55:45  lr: 0.000010  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9965 (1.9970)  loss/pix_loss: 0.2107 (0.2364)  loss/enc_loss: 10.3328 (13.1603)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [ 80/862]  eta: 0:55:02  lr: 0.000010  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9964 (1.9969)  loss/pix_loss: 0.2060 (0.2321)  loss/enc_loss: 9.6353 (12.7366)  time: 4.2105  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [ 90/862]  eta: 0:54:18  lr: 0.000010  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9964 (1.9969)  loss/pix_loss: 0.2016 (0.2291)  loss/enc_loss: 9.0591 (12.3220)  time: 4.2105  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [100/862]  eta: 0:53:35  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9968)  loss/pix_loss: 0.2035 (0.2263)  loss/enc_loss: 8.4028 (11.9206)  time: 4.2114  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [110/862]  eta: 0:52:52  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9968)  loss/pix_loss: 0.2002 (0.2239)  loss/enc_loss: 8.1985 (11.5911)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [120/862]  eta: 0:52:10  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9967)  loss/pix_loss: 0.1969 (0.2215)  loss/enc_loss: 7.9757 (11.2656)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [130/862]  eta: 0:51:27  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9967)  loss/pix_loss: 0.1899 (0.2190)  loss/enc_loss: 7.7203 (10.9697)  time: 4.2107  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [140/862]  eta: 0:50:45  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9967)  loss/pix_loss: 0.1883 (0.2168)  loss/enc_loss: 7.3096 (10.6931)  time: 4.2107  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [150/862]  eta: 0:50:02  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9967)  loss/pix_loss: 0.1873 (0.2147)  loss/enc_loss: 6.8918 (10.4252)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [160/862]  eta: 0:49:20  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9967)  loss/pix_loss: 0.1841 (0.2126)  loss/enc_loss: 6.2622 (10.1727)  time: 4.2106  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [170/862]  eta: 0:48:37  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9966)  loss/pix_loss: 0.1789 (0.2105)  loss/enc_loss: 6.0252 (9.9173)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [180/862]  eta: 0:47:55  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9966)  loss/pix_loss: 0.1764 (0.2086)  loss/enc_loss: 5.7001 (9.6810)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [190/862]  eta: 0:47:12  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9966)  loss/pix_loss: 0.1733 (0.2067)  loss/enc_loss: 5.2703 (9.4418)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [200/862]  eta: 0:46:30  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9966)  loss/pix_loss: 0.1688 (0.2047)  loss/enc_loss: 4.9781 (9.2293)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [210/862]  eta: 0:45:47  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9966)  loss/pix_loss: 0.1644 (0.2027)  loss/enc_loss: 5.2633 (9.0431)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [220/862]  eta: 0:45:05  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9966)  loss/pix_loss: 0.1616 (0.2007)  loss/enc_loss: 4.9793 (8.8498)  time: 4.2068  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [230/862]  eta: 0:44:23  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9966)  loss/pix_loss: 0.1544 (0.1986)  loss/enc_loss: 4.8248 (8.6761)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [240/862]  eta: 0:43:40  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9966)  loss/pix_loss: 0.1506 (0.1965)  loss/enc_loss: 4.5171 (8.4892)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [250/862]  eta: 0:42:58  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1469 (0.1945)  loss/enc_loss: 4.0865 (8.3083)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [260/862]  eta: 0:42:16  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1405 (0.1924)  loss/enc_loss: 3.8946 (8.1422)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [270/862]  eta: 0:41:34  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1364 (0.1903)  loss/enc_loss: 3.7151 (7.9732)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [280/862]  eta: 0:40:51  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1321 (0.1881)  loss/enc_loss: 3.5291 (7.8163)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [290/862]  eta: 0:40:09  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1263 (0.1859)  loss/enc_loss: 3.3123 (7.6588)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [300/862]  eta: 0:39:27  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1251 (0.1838)  loss/enc_loss: 3.3123 (7.5208)  time: 4.2125  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [310/862]  eta: 0:38:45  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1205 (0.1818)  loss/enc_loss: 3.4121 (7.3878)  time: 4.2126  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [320/862]  eta: 0:38:03  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1185 (0.1797)  loss/enc_loss: 3.1485 (7.2553)  time: 4.2108  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [330/862]  eta: 0:37:21  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1091 (0.1775)  loss/enc_loss: 2.8850 (7.1180)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [340/862]  eta: 0:36:38  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1045 (0.1753)  loss/enc_loss: 2.7817 (6.9960)  time: 4.2061  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [350/862]  eta: 0:35:56  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1020 (0.1733)  loss/enc_loss: 2.7794 (6.8755)  time: 4.2056  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [360/862]  eta: 0:35:14  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.1013 (0.1713)  loss/enc_loss: 2.6061 (6.7568)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [370/862]  eta: 0:34:32  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.0998 (0.1693)  loss/enc_loss: 2.5520 (6.6418)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [380/862]  eta: 0:33:50  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.0979 (0.1674)  loss/enc_loss: 2.4912 (6.5346)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [390/862]  eta: 0:33:07  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9965)  loss/pix_loss: 0.0945 (0.1655)  loss/enc_loss: 2.5329 (6.4317)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [400/862]  eta: 0:32:25  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9965)  loss/pix_loss: 0.0893 (0.1636)  loss/enc_loss: 2.3249 (6.3261)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [410/862]  eta: 0:31:43  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9964)  loss/pix_loss: 0.0831 (0.1616)  loss/enc_loss: 2.1820 (6.2266)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [420/862]  eta: 0:31:01  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9964)  loss/pix_loss: 0.0803 (0.1597)  loss/enc_loss: 2.0090 (6.1243)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [430/862]  eta: 0:30:19  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9964)  loss/pix_loss: 0.0796 (0.1578)  loss/enc_loss: 1.9122 (6.0298)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [440/862]  eta: 0:29:37  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9964)  loss/pix_loss: 0.0786 (0.1560)  loss/enc_loss: 1.9424 (5.9373)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [450/862]  eta: 0:28:54  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9964)  loss/pix_loss: 0.0777 (0.1543)  loss/enc_loss: 1.8632 (5.8453)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [460/862]  eta: 0:28:12  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9964)  loss/pix_loss: 0.0757 (0.1526)  loss/enc_loss: 1.7929 (5.7595)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [470/862]  eta: 0:27:30  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9964)  loss/pix_loss: 0.0730 (0.1509)  loss/enc_loss: 1.7818 (5.6737)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [480/862]  eta: 0:26:48  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9964)  loss/pix_loss: 0.0703 (0.1492)  loss/enc_loss: 1.6620 (5.5926)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [490/862]  eta: 0:26:06  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9964)  loss/pix_loss: 0.0693 (0.1476)  loss/enc_loss: 1.6354 (5.5127)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [500/862]  eta: 0:25:24  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9964)  loss/pix_loss: 0.0683 (0.1460)  loss/enc_loss: 1.6148 (5.4345)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [510/862]  eta: 0:24:42  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9964)  loss/pix_loss: 0.0658 (0.1444)  loss/enc_loss: 1.4585 (5.3572)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [520/862]  eta: 0:24:00  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9964)  loss/pix_loss: 0.0617 (0.1428)  loss/enc_loss: 1.3912 (5.2812)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [530/862]  eta: 0:23:17  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9964)  loss/pix_loss: 0.0608 (0.1413)  loss/enc_loss: 1.4275 (5.2093)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [540/862]  eta: 0:22:35  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9964)  loss/pix_loss: 0.0590 (0.1397)  loss/enc_loss: 1.3506 (5.1368)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [550/862]  eta: 0:21:53  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9964)  loss/pix_loss: 0.0577 (0.1382)  loss/enc_loss: 1.2982 (5.0681)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [560/862]  eta: 0:21:11  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9964)  loss/pix_loss: 0.0554 (0.1368)  loss/enc_loss: 1.3201 (5.0013)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [570/862]  eta: 0:20:29  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9964)  loss/pix_loss: 0.0545 (0.1353)  loss/enc_loss: 1.2674 (4.9356)  time: 4.2083  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:2]  [580/862]  eta: 0:19:47  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9964)  loss/pix_loss: 0.0537 (0.1339)  loss/enc_loss: 1.2581 (4.8719)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [590/862]  eta: 0:19:05  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0510 (0.1325)  loss/enc_loss: 1.2245 (4.8098)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [600/862]  eta: 0:18:23  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0508 (0.1312)  loss/enc_loss: 1.1790 (4.7495)  time: 4.2064  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [610/862]  eta: 0:17:40  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0491 (0.1298)  loss/enc_loss: 1.1677 (4.6907)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [620/862]  eta: 0:16:58  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0491 (0.1285)  loss/enc_loss: 1.1350 (4.6317)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [630/862]  eta: 0:16:16  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0471 (0.1272)  loss/enc_loss: 1.0066 (4.5758)  time: 4.2064  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [640/862]  eta: 0:15:34  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0461 (0.1259)  loss/enc_loss: 1.0639 (4.5214)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [650/862]  eta: 0:14:52  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0440 (0.1247)  loss/enc_loss: 1.0231 (4.4661)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [660/862]  eta: 0:14:10  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0439 (0.1234)  loss/enc_loss: 0.9806 (4.4139)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [670/862]  eta: 0:13:28  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9959 (1.9963)  loss/pix_loss: 0.0417 (0.1222)  loss/enc_loss: 0.9983 (4.3635)  time: 4.2074  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [680/862]  eta: 0:12:46  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9959 (1.9963)  loss/pix_loss: 0.0404 (0.1210)  loss/enc_loss: 0.9854 (4.3137)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [690/862]  eta: 0:12:04  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9959 (1.9963)  loss/pix_loss: 0.0403 (0.1198)  loss/enc_loss: 0.9322 (4.2643)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [700/862]  eta: 0:11:22  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9959 (1.9963)  loss/pix_loss: 0.0408 (0.1187)  loss/enc_loss: 0.9364 (4.2171)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [710/862]  eta: 0:10:39  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0398 (0.1176)  loss/enc_loss: 0.9364 (4.1697)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [720/862]  eta: 0:09:57  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0382 (0.1165)  loss/enc_loss: 0.8395 (4.1236)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [730/862]  eta: 0:09:15  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0364 (0.1154)  loss/enc_loss: 0.8463 (4.0792)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [740/862]  eta: 0:08:33  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0349 (0.1143)  loss/enc_loss: 0.8468 (4.0358)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [750/862]  eta: 0:07:51  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0346 (0.1132)  loss/enc_loss: 0.8242 (3.9927)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [760/862]  eta: 0:07:09  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0346 (0.1122)  loss/enc_loss: 0.7903 (3.9506)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [770/862]  eta: 0:06:27  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0333 (0.1112)  loss/enc_loss: 0.7873 (3.9098)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [780/862]  eta: 0:05:45  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0324 (0.1102)  loss/enc_loss: 0.7569 (3.8692)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [790/862]  eta: 0:05:03  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0324 (0.1092)  loss/enc_loss: 0.7400 (3.8296)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [800/862]  eta: 0:04:21  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9963)  loss/pix_loss: 0.0313 (0.1082)  loss/enc_loss: 0.7025 (3.7905)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [810/862]  eta: 0:03:38  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0308 (0.1073)  loss/enc_loss: 0.7148 (3.7530)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [820/862]  eta: 0:02:56  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0301 (0.1063)  loss/enc_loss: 0.7183 (3.7159)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [830/862]  eta: 0:02:14  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0290 (0.1054)  loss/enc_loss: 0.6816 (3.6795)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [840/862]  eta: 0:01:32  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0292 (0.1045)  loss/enc_loss: 0.6800 (3.6442)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [850/862]  eta: 0:00:50  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0288 (0.1036)  loss/enc_loss: 0.6695 (3.6091)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [860/862]  eta: 0:00:08  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0274 (0.1027)  loss/enc_loss: 0.6742 (3.5750)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2]  [861/862]  eta: 0:00:04  lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0274 (0.1026)  loss/enc_loss: 0.6695 (3.5716)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:2] Total time: 1:00:28 (4.2099 s / it)\n",
      "Averaged stats: lr: 0.000010  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0274 (0.1026)  loss/enc_loss: 0.6695 (3.5716)\n",
      "Valid: [epoch:2]  [ 0/14]  eta: 0:00:41  L1_loss: 0.0237 (0.0237)  time: 2.9962  data: 0.3657  max mem: 31350\n",
      "Valid: [epoch:2]  [13/14]  eta: 0:00:02  L1_loss: 0.0216 (0.0224)  time: 2.6280  data: 0.0262  max mem: 31350\n",
      "Valid: [epoch:2] Total time: 0:00:36 (2.6377 s / it)\n",
      "Averaged stats: L1_loss: 0.0216 (0.0224)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_2_input_n_20.png\n",
      "Train: [epoch:3]  [  0/862]  eta: 1:17:19  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9958 (1.9958)  loss/pix_loss: 0.0302 (0.0302)  loss/enc_loss: 0.6764 (0.6764)  time: 5.3819  data: 1.1165  max mem: 31350\n",
      "Train: [epoch:3]  [ 10/862]  eta: 1:00:53  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0280 (0.0282)  loss/enc_loss: 0.6113 (0.6425)  time: 4.2882  data: 0.1016  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [ 20/862]  eta: 0:59:32  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0274 (0.0273)  loss/enc_loss: 0.5994 (0.6179)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [ 30/862]  eta: 0:58:39  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0258 (0.0267)  loss/enc_loss: 0.5844 (0.6031)  time: 4.1979  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [ 40/862]  eta: 0:57:53  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0246 (0.0260)  loss/enc_loss: 0.5598 (0.5879)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [ 50/862]  eta: 0:57:09  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0243 (0.0258)  loss/enc_loss: 0.5226 (0.5806)  time: 4.2134  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [ 60/862]  eta: 0:56:25  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0243 (0.0255)  loss/enc_loss: 0.5204 (0.5703)  time: 4.2127  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [ 70/862]  eta: 0:55:42  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9959 (1.9960)  loss/pix_loss: 0.0231 (0.0250)  loss/enc_loss: 0.5126 (0.5617)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [ 80/862]  eta: 0:54:59  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0216 (0.0245)  loss/enc_loss: 0.5072 (0.5558)  time: 4.2120  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [ 90/862]  eta: 0:54:16  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0209 (0.0242)  loss/enc_loss: 0.4761 (0.5473)  time: 4.2129  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [100/862]  eta: 0:53:33  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0212 (0.0239)  loss/enc_loss: 0.4656 (0.5394)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [110/862]  eta: 0:52:50  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0208 (0.0236)  loss/enc_loss: 0.4653 (0.5320)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [120/862]  eta: 0:52:08  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0202 (0.0233)  loss/enc_loss: 0.4412 (0.5242)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [130/862]  eta: 0:51:25  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0187 (0.0230)  loss/enc_loss: 0.4349 (0.5163)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [140/862]  eta: 0:50:43  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0186 (0.0227)  loss/enc_loss: 0.4220 (0.5114)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [150/862]  eta: 0:50:00  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0188 (0.0224)  loss/enc_loss: 0.4047 (0.5037)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [160/862]  eta: 0:49:18  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9959 (1.9960)  loss/pix_loss: 0.0182 (0.0221)  loss/enc_loss: 0.3903 (0.4970)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [170/862]  eta: 0:48:36  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0180 (0.0219)  loss/enc_loss: 0.3890 (0.4914)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [180/862]  eta: 0:47:53  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0179 (0.0216)  loss/enc_loss: 0.3525 (0.4829)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [190/862]  eta: 0:47:11  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0180 (0.0215)  loss/enc_loss: 0.3119 (0.4740)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [200/862]  eta: 0:46:29  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0174 (0.0213)  loss/enc_loss: 0.3186 (0.4669)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [210/862]  eta: 0:45:47  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0170 (0.0210)  loss/enc_loss: 0.3428 (0.4609)  time: 4.2126  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [220/862]  eta: 0:45:05  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0158 (0.0208)  loss/enc_loss: 0.3367 (0.4561)  time: 4.2134  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [230/862]  eta: 0:44:22  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0156 (0.0206)  loss/enc_loss: 0.3313 (0.4510)  time: 4.2136  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [240/862]  eta: 0:43:40  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0166 (0.0204)  loss/enc_loss: 0.3197 (0.4458)  time: 4.2134  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [250/862]  eta: 0:42:58  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0162 (0.0202)  loss/enc_loss: 0.3154 (0.4404)  time: 4.2127  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [260/862]  eta: 0:42:16  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0157 (0.0201)  loss/enc_loss: 0.3068 (0.4355)  time: 4.2131  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [270/862]  eta: 0:41:34  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0156 (0.0199)  loss/enc_loss: 0.2832 (0.4296)  time: 4.2124  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [280/862]  eta: 0:40:52  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0154 (0.0197)  loss/enc_loss: 0.2689 (0.4240)  time: 4.2111  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [290/862]  eta: 0:40:09  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0154 (0.0196)  loss/enc_loss: 0.2689 (0.4194)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [300/862]  eta: 0:39:27  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0155 (0.0195)  loss/enc_loss: 0.2932 (0.4154)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [310/862]  eta: 0:38:45  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0149 (0.0193)  loss/enc_loss: 0.2884 (0.4113)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [320/862]  eta: 0:38:03  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0149 (0.0192)  loss/enc_loss: 0.2830 (0.4074)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [330/862]  eta: 0:37:21  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9960)  loss/pix_loss: 0.0150 (0.0191)  loss/enc_loss: 0.2655 (0.4027)  time: 4.2106  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [340/862]  eta: 0:36:39  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0144 (0.0189)  loss/enc_loss: 0.2538 (0.3989)  time: 4.2118  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [350/862]  eta: 0:35:56  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0142 (0.0188)  loss/enc_loss: 0.2600 (0.3944)  time: 4.2107  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [360/862]  eta: 0:35:14  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0146 (0.0187)  loss/enc_loss: 0.2375 (0.3905)  time: 4.2113  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [370/862]  eta: 0:34:32  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0139 (0.0185)  loss/enc_loss: 0.2366 (0.3864)  time: 4.2107  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [380/862]  eta: 0:33:50  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0134 (0.0184)  loss/enc_loss: 0.2424 (0.3827)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [390/862]  eta: 0:33:08  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0138 (0.0183)  loss/enc_loss: 0.2435 (0.3794)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [400/862]  eta: 0:32:26  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0140 (0.0182)  loss/enc_loss: 0.2400 (0.3758)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [410/862]  eta: 0:31:43  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0135 (0.0181)  loss/enc_loss: 0.2255 (0.3721)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [420/862]  eta: 0:31:01  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0132 (0.0179)  loss/enc_loss: 0.2255 (0.3691)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [430/862]  eta: 0:30:19  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0132 (0.0178)  loss/enc_loss: 0.2338 (0.3656)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [440/862]  eta: 0:29:37  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0133 (0.0177)  loss/enc_loss: 0.2355 (0.3628)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [450/862]  eta: 0:28:55  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0136 (0.0177)  loss/enc_loss: 0.2173 (0.3594)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [460/862]  eta: 0:28:13  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0135 (0.0176)  loss/enc_loss: 0.2144 (0.3565)  time: 4.2150  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [470/862]  eta: 0:27:31  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0134 (0.0175)  loss/enc_loss: 0.2253 (0.3537)  time: 4.2147  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [480/862]  eta: 0:26:49  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0133 (0.0174)  loss/enc_loss: 0.2142 (0.3506)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [490/862]  eta: 0:26:06  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0133 (0.0173)  loss/enc_loss: 0.2057 (0.3475)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [500/862]  eta: 0:25:24  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0128 (0.0172)  loss/enc_loss: 0.2060 (0.3446)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [510/862]  eta: 0:24:42  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0129 (0.0171)  loss/enc_loss: 0.1915 (0.3415)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [520/862]  eta: 0:24:00  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0126 (0.0170)  loss/enc_loss: 0.1915 (0.3390)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [530/862]  eta: 0:23:18  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0124 (0.0170)  loss/enc_loss: 0.1838 (0.3361)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [540/862]  eta: 0:22:36  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0123 (0.0169)  loss/enc_loss: 0.1755 (0.3331)  time: 4.2131  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [550/862]  eta: 0:21:54  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0121 (0.0168)  loss/enc_loss: 0.1710 (0.3303)  time: 4.2143  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [560/862]  eta: 0:21:12  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0121 (0.0167)  loss/enc_loss: 0.1815 (0.3280)  time: 4.2106  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [570/862]  eta: 0:20:29  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9960)  loss/pix_loss: 0.0122 (0.0166)  loss/enc_loss: 0.1807 (0.3253)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [580/862]  eta: 0:19:47  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0117 (0.0165)  loss/enc_loss: 0.1707 (0.3226)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [590/862]  eta: 0:19:05  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9960)  loss/pix_loss: 0.0118 (0.0165)  loss/enc_loss: 0.1675 (0.3200)  time: 4.2114  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [600/862]  eta: 0:18:23  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0121 (0.0164)  loss/enc_loss: 0.1689 (0.3175)  time: 4.2109  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [610/862]  eta: 0:17:41  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9960)  loss/pix_loss: 0.0120 (0.0163)  loss/enc_loss: 0.1608 (0.3148)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [620/862]  eta: 0:16:59  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9960)  loss/pix_loss: 0.0121 (0.0163)  loss/enc_loss: 0.1521 (0.3122)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [630/862]  eta: 0:16:17  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9960)  loss/pix_loss: 0.0121 (0.0162)  loss/enc_loss: 0.1520 (0.3098)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [640/862]  eta: 0:15:35  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9960)  loss/pix_loss: 0.0121 (0.0161)  loss/enc_loss: 0.1602 (0.3076)  time: 4.2107  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [650/862]  eta: 0:14:52  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0121 (0.0161)  loss/enc_loss: 0.1575 (0.3052)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [660/862]  eta: 0:14:10  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0116 (0.0160)  loss/enc_loss: 0.1526 (0.3029)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [670/862]  eta: 0:13:28  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0114 (0.0159)  loss/enc_loss: 0.1555 (0.3008)  time: 4.2109  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [680/862]  eta: 0:12:46  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0114 (0.0159)  loss/enc_loss: 0.1565 (0.2988)  time: 4.2118  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [690/862]  eta: 0:12:04  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0115 (0.0158)  loss/enc_loss: 0.1487 (0.2966)  time: 4.2119  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [700/862]  eta: 0:11:22  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0117 (0.0157)  loss/enc_loss: 0.1471 (0.2945)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [710/862]  eta: 0:10:40  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0116 (0.0157)  loss/enc_loss: 0.1320 (0.2922)  time: 4.2113  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:3]  [720/862]  eta: 0:09:58  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0117 (0.0156)  loss/enc_loss: 0.1268 (0.2900)  time: 4.2117  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [730/862]  eta: 0:09:15  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0115 (0.0156)  loss/enc_loss: 0.1292 (0.2880)  time: 4.2118  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [740/862]  eta: 0:08:33  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0110 (0.0155)  loss/enc_loss: 0.1370 (0.2860)  time: 4.2111  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [750/862]  eta: 0:07:51  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0111 (0.0155)  loss/enc_loss: 0.1381 (0.2840)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [760/862]  eta: 0:07:09  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0114 (0.0154)  loss/enc_loss: 0.1388 (0.2821)  time: 4.2124  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [770/862]  eta: 0:06:27  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0114 (0.0153)  loss/enc_loss: 0.1369 (0.2802)  time: 4.2123  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [780/862]  eta: 0:05:45  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0108 (0.0153)  loss/enc_loss: 0.1332 (0.2784)  time: 4.2105  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [790/862]  eta: 0:05:03  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0108 (0.0152)  loss/enc_loss: 0.1269 (0.2765)  time: 4.2119  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [800/862]  eta: 0:04:21  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0109 (0.0152)  loss/enc_loss: 0.1198 (0.2747)  time: 4.2112  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [810/862]  eta: 0:03:39  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9961)  loss/pix_loss: 0.0111 (0.0151)  loss/enc_loss: 0.1196 (0.2728)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [820/862]  eta: 0:02:56  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0111 (0.0151)  loss/enc_loss: 0.1230 (0.2710)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [830/862]  eta: 0:02:14  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0110 (0.0150)  loss/enc_loss: 0.1308 (0.2695)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [840/862]  eta: 0:01:32  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0111 (0.0150)  loss/enc_loss: 0.1337 (0.2678)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [850/862]  eta: 0:00:50  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0110 (0.0149)  loss/enc_loss: 0.1248 (0.2662)  time: 4.2117  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [860/862]  eta: 0:00:08  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0109 (0.0149)  loss/enc_loss: 0.1201 (0.2646)  time: 4.2132  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3]  [861/862]  eta: 0:00:04  lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0109 (0.0149)  loss/enc_loss: 0.1201 (0.2645)  time: 4.2132  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:3] Total time: 1:00:30 (4.2118 s / it)\n",
      "Averaged stats: lr: 0.000020  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9961)  loss/pix_loss: 0.0109 (0.0149)  loss/enc_loss: 0.1201 (0.2645)\n",
      "Valid: [epoch:3]  [ 0/14]  eta: 0:00:42  L1_loss: 0.0107 (0.0107)  time: 3.0345  data: 0.4273  max mem: 31350\n",
      "Valid: [epoch:3]  [13/14]  eta: 0:00:02  L1_loss: 0.0100 (0.0102)  time: 2.6147  data: 0.0306  max mem: 31350\n",
      "Valid: [epoch:3] Total time: 0:00:36 (2.6236 s / it)\n",
      "Averaged stats: L1_loss: 0.0100 (0.0102)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_3_input_n_20.png\n",
      "Train: [epoch:4]  [  0/862]  eta: 1:16:02  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0118 (0.0118)  loss/enc_loss: 0.1288 (0.1288)  time: 5.2931  data: 1.0804  max mem: 31350\n",
      "Train: [epoch:4]  [ 10/862]  eta: 1:01:13  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9963)  loss/pix_loss: 0.0115 (0.0114)  loss/enc_loss: 0.1120 (0.1122)  time: 4.3112  data: 0.0983  max mem: 31350\n",
      "Train: [epoch:4]  [ 20/862]  eta: 0:59:49  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0110 (0.0111)  loss/enc_loss: 0.1140 (0.1154)  time: 4.2121  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [ 30/862]  eta: 0:58:52  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0106 (0.0110)  loss/enc_loss: 0.1170 (0.1145)  time: 4.2105  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [ 40/862]  eta: 0:58:03  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0106 (0.0109)  loss/enc_loss: 0.1139 (0.1167)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [ 50/862]  eta: 0:57:16  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0108 (0.0110)  loss/enc_loss: 0.1139 (0.1152)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [ 60/862]  eta: 0:56:30  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0115 (0.0112)  loss/enc_loss: 0.1129 (0.1151)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [ 70/862]  eta: 0:55:46  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9962)  loss/pix_loss: 0.0121 (0.0115)  loss/enc_loss: 0.1097 (0.1136)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [ 80/862]  eta: 0:55:02  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9962)  loss/pix_loss: 0.0136 (0.0118)  loss/enc_loss: 0.1054 (0.1134)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [ 90/862]  eta: 0:54:18  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9962)  loss/pix_loss: 0.0134 (0.0120)  loss/enc_loss: 0.1054 (0.1131)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [100/862]  eta: 0:53:35  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9962)  loss/pix_loss: 0.0129 (0.0120)  loss/enc_loss: 0.1024 (0.1117)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [110/862]  eta: 0:52:52  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9962)  loss/pix_loss: 0.0120 (0.0120)  loss/enc_loss: 0.1018 (0.1117)  time: 4.2063  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [120/862]  eta: 0:52:09  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9962)  loss/pix_loss: 0.0120 (0.0121)  loss/enc_loss: 0.0989 (0.1103)  time: 4.2063  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [130/862]  eta: 0:51:26  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9963)  loss/pix_loss: 0.0114 (0.0120)  loss/enc_loss: 0.0952 (0.1097)  time: 4.2055  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [140/862]  eta: 0:50:43  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9963)  loss/pix_loss: 0.0104 (0.0119)  loss/enc_loss: 0.1024 (0.1089)  time: 4.2064  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [150/862]  eta: 0:50:01  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9963)  loss/pix_loss: 0.0100 (0.0117)  loss/enc_loss: 0.0942 (0.1081)  time: 4.2063  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [160/862]  eta: 0:49:18  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9963)  loss/pix_loss: 0.0095 (0.0116)  loss/enc_loss: 0.0983 (0.1077)  time: 4.2062  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [170/862]  eta: 0:48:36  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9963)  loss/pix_loss: 0.0096 (0.0115)  loss/enc_loss: 0.1029 (0.1074)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [180/862]  eta: 0:47:53  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0099 (0.0114)  loss/enc_loss: 0.0898 (0.1058)  time: 4.2062  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [190/862]  eta: 0:47:11  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0102 (0.0114)  loss/enc_loss: 0.0766 (0.1043)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [200/862]  eta: 0:46:29  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0101 (0.0113)  loss/enc_loss: 0.0830 (0.1036)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [210/862]  eta: 0:45:46  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0101 (0.0113)  loss/enc_loss: 0.0866 (0.1030)  time: 4.2063  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [220/862]  eta: 0:45:04  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0102 (0.0112)  loss/enc_loss: 0.0877 (0.1024)  time: 4.2059  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [230/862]  eta: 0:44:22  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0098 (0.0112)  loss/enc_loss: 0.0892 (0.1017)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [240/862]  eta: 0:43:39  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0095 (0.0111)  loss/enc_loss: 0.0868 (0.1010)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [250/862]  eta: 0:42:57  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0099 (0.0111)  loss/enc_loss: 0.0867 (0.1004)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [260/862]  eta: 0:42:15  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0099 (0.0110)  loss/enc_loss: 0.0858 (0.0999)  time: 4.2064  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [270/862]  eta: 0:41:33  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0095 (0.0110)  loss/enc_loss: 0.0798 (0.0989)  time: 4.2060  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [280/862]  eta: 0:40:50  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9962)  loss/pix_loss: 0.0093 (0.0109)  loss/enc_loss: 0.0738 (0.0982)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [290/862]  eta: 0:40:08  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0098 (0.0109)  loss/enc_loss: 0.0758 (0.0974)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [300/862]  eta: 0:39:26  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9962)  loss/pix_loss: 0.0101 (0.0108)  loss/enc_loss: 0.0814 (0.0971)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [310/862]  eta: 0:38:44  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0100 (0.0108)  loss/enc_loss: 0.0840 (0.0966)  time: 4.2061  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [320/862]  eta: 0:38:02  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0096 (0.0108)  loss/enc_loss: 0.0791 (0.0960)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [330/862]  eta: 0:37:20  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0096 (0.0107)  loss/enc_loss: 0.0731 (0.0954)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [340/862]  eta: 0:36:37  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9962)  loss/pix_loss: 0.0096 (0.0107)  loss/enc_loss: 0.0731 (0.0947)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [350/862]  eta: 0:35:55  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9962)  loss/pix_loss: 0.0094 (0.0107)  loss/enc_loss: 0.0737 (0.0943)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [360/862]  eta: 0:35:13  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9962)  loss/pix_loss: 0.0094 (0.0106)  loss/enc_loss: 0.0786 (0.0938)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [370/862]  eta: 0:34:31  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9964 (1.9962)  loss/pix_loss: 0.0094 (0.0106)  loss/enc_loss: 0.0692 (0.0931)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [380/862]  eta: 0:33:49  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0096 (0.0106)  loss/enc_loss: 0.0702 (0.0926)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [390/862]  eta: 0:33:07  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0095 (0.0106)  loss/enc_loss: 0.0714 (0.0924)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [400/862]  eta: 0:32:25  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0097 (0.0105)  loss/enc_loss: 0.0709 (0.0918)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [410/862]  eta: 0:31:42  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9962 (1.9962)  loss/pix_loss: 0.0094 (0.0105)  loss/enc_loss: 0.0703 (0.0913)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [420/862]  eta: 0:31:00  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9962)  loss/pix_loss: 0.0089 (0.0105)  loss/enc_loss: 0.0664 (0.0908)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [430/862]  eta: 0:30:18  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9959 (1.9962)  loss/pix_loss: 0.0095 (0.0105)  loss/enc_loss: 0.0656 (0.0903)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [440/862]  eta: 0:29:36  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9956 (1.9962)  loss/pix_loss: 0.0095 (0.0104)  loss/enc_loss: 0.0694 (0.0899)  time: 4.2056  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [450/862]  eta: 0:28:54  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9954 (1.9962)  loss/pix_loss: 0.0093 (0.0104)  loss/enc_loss: 0.0658 (0.0893)  time: 4.2063  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [460/862]  eta: 0:28:12  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9952 (1.9961)  loss/pix_loss: 0.0094 (0.0104)  loss/enc_loss: 0.0673 (0.0890)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [470/862]  eta: 0:27:30  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9952 (1.9961)  loss/pix_loss: 0.0094 (0.0104)  loss/enc_loss: 0.0637 (0.0884)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [480/862]  eta: 0:26:48  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9954 (1.9961)  loss/pix_loss: 0.0092 (0.0103)  loss/enc_loss: 0.0611 (0.0880)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [490/862]  eta: 0:26:05  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9954 (1.9961)  loss/pix_loss: 0.0092 (0.0103)  loss/enc_loss: 0.0627 (0.0875)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [500/862]  eta: 0:25:23  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9954 (1.9961)  loss/pix_loss: 0.0096 (0.0103)  loss/enc_loss: 0.0632 (0.0871)  time: 4.2069  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [510/862]  eta: 0:24:41  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9955 (1.9961)  loss/pix_loss: 0.0098 (0.0103)  loss/enc_loss: 0.0592 (0.0865)  time: 4.2062  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [520/862]  eta: 0:23:59  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9960 (1.9961)  loss/pix_loss: 0.0100 (0.0103)  loss/enc_loss: 0.0592 (0.0860)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [530/862]  eta: 0:23:17  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9959 (1.9961)  loss/pix_loss: 0.0104 (0.0103)  loss/enc_loss: 0.0612 (0.0855)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [540/862]  eta: 0:22:35  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9959 (1.9961)  loss/pix_loss: 0.0096 (0.0103)  loss/enc_loss: 0.0581 (0.0850)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [550/862]  eta: 0:21:53  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9956 (1.9961)  loss/pix_loss: 0.0090 (0.0103)  loss/enc_loss: 0.0540 (0.0844)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [560/862]  eta: 0:21:11  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9953 (1.9960)  loss/pix_loss: 0.0092 (0.0103)  loss/enc_loss: 0.0564 (0.0840)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [570/862]  eta: 0:20:29  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9947 (1.9960)  loss/pix_loss: 0.0091 (0.0102)  loss/enc_loss: 0.0631 (0.0837)  time: 4.2062  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [580/862]  eta: 0:19:46  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9940 (1.9960)  loss/pix_loss: 0.0088 (0.0102)  loss/enc_loss: 0.0603 (0.0832)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [590/862]  eta: 0:19:04  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9930 (1.9959)  loss/pix_loss: 0.0091 (0.0102)  loss/enc_loss: 0.0583 (0.0829)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [600/862]  eta: 0:18:22  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9923 (1.9958)  loss/pix_loss: 0.0095 (0.0102)  loss/enc_loss: 0.0547 (0.0824)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [610/862]  eta: 0:17:40  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9910 (1.9957)  loss/pix_loss: 0.0091 (0.0102)  loss/enc_loss: 0.0530 (0.0820)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [620/862]  eta: 0:16:58  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9895 (1.9956)  loss/pix_loss: 0.0093 (0.0102)  loss/enc_loss: 0.0540 (0.0815)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [630/862]  eta: 0:16:16  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9896 (1.9955)  loss/pix_loss: 0.0110 (0.0102)  loss/enc_loss: 0.0510 (0.0811)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [640/862]  eta: 0:15:34  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9891 (1.9954)  loss/pix_loss: 0.0133 (0.0103)  loss/enc_loss: 0.0561 (0.0807)  time: 4.2059  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [650/862]  eta: 0:14:52  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9853 (1.9952)  loss/pix_loss: 0.0149 (0.0104)  loss/enc_loss: 0.0497 (0.0802)  time: 4.2055  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [660/862]  eta: 0:14:10  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9843 (1.9951)  loss/pix_loss: 0.0139 (0.0104)  loss/enc_loss: 0.0497 (0.0798)  time: 4.2062  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [670/862]  eta: 0:13:28  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9851 (1.9949)  loss/pix_loss: 0.0117 (0.0104)  loss/enc_loss: 0.0537 (0.0794)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [680/862]  eta: 0:12:45  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9847 (1.9948)  loss/pix_loss: 0.0104 (0.0104)  loss/enc_loss: 0.0519 (0.0790)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [690/862]  eta: 0:12:03  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9852 (1.9946)  loss/pix_loss: 0.0097 (0.0104)  loss/enc_loss: 0.0519 (0.0787)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [700/862]  eta: 0:11:21  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9881 (1.9946)  loss/pix_loss: 0.0096 (0.0104)  loss/enc_loss: 0.0498 (0.0783)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [710/862]  eta: 0:10:39  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9945 (1.9946)  loss/pix_loss: 0.0101 (0.0104)  loss/enc_loss: 0.0473 (0.0778)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [720/862]  eta: 0:09:57  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9888 (1.9945)  loss/pix_loss: 0.0099 (0.0104)  loss/enc_loss: 0.0473 (0.0775)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [730/862]  eta: 0:09:15  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9868 (1.9944)  loss/pix_loss: 0.0093 (0.0104)  loss/enc_loss: 0.0511 (0.0771)  time: 4.2063  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [740/862]  eta: 0:08:33  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9951 (1.9945)  loss/pix_loss: 0.0091 (0.0104)  loss/enc_loss: 0.0499 (0.0767)  time: 4.2064  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [750/862]  eta: 0:07:51  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9978 (1.9945)  loss/pix_loss: 0.0090 (0.0104)  loss/enc_loss: 0.0483 (0.0763)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [760/862]  eta: 0:07:09  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9981 (1.9946)  loss/pix_loss: 0.0092 (0.0103)  loss/enc_loss: 0.0455 (0.0759)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [770/862]  eta: 0:06:27  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9983 (1.9946)  loss/pix_loss: 0.0095 (0.0103)  loss/enc_loss: 0.0474 (0.0756)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [780/862]  eta: 0:05:45  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9983 (1.9947)  loss/pix_loss: 0.0095 (0.0103)  loss/enc_loss: 0.0486 (0.0753)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [790/862]  eta: 0:05:03  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9972 (1.9947)  loss/pix_loss: 0.0095 (0.0103)  loss/enc_loss: 0.0452 (0.0750)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [800/862]  eta: 0:04:20  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9947)  loss/pix_loss: 0.0095 (0.0103)  loss/enc_loss: 0.0445 (0.0746)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [810/862]  eta: 0:03:38  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9957 (1.9947)  loss/pix_loss: 0.0097 (0.0103)  loss/enc_loss: 0.0448 (0.0743)  time: 4.2059  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [820/862]  eta: 0:02:56  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9961 (1.9947)  loss/pix_loss: 0.0091 (0.0103)  loss/enc_loss: 0.0443 (0.0739)  time: 4.2064  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [830/862]  eta: 0:02:14  lr: 0.000030  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9963 (1.9948)  loss/pix_loss: 0.0087 (0.0103)  loss/enc_loss: 0.0443 (0.0736)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [840/862]  eta: 0:01:32  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9965 (1.9948)  loss/pix_loss: 0.0089 (0.0103)  loss/enc_loss: 0.0473 (0.0733)  time: 4.2064  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [850/862]  eta: 0:00:50  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9969 (1.9948)  loss/pix_loss: 0.0090 (0.0102)  loss/enc_loss: 0.0453 (0.0730)  time: 4.2059  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [860/862]  eta: 0:00:08  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9970 (1.9948)  loss/pix_loss: 0.0089 (0.0102)  loss/enc_loss: 0.0434 (0.0727)  time: 4.2060  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4]  [861/862]  eta: 0:00:04  lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9970 (1.9948)  loss/pix_loss: 0.0089 (0.0102)  loss/enc_loss: 0.0434 (0.0726)  time: 4.2061  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:4] Total time: 1:00:27 (4.2085 s / it)\n",
      "Averaged stats: lr: 0.000030  loss/low_gen_loss: 1.9999 (2.0000)  loss/high_gen_loss: 1.9970 (1.9948)  loss/pix_loss: 0.0089 (0.0102)  loss/enc_loss: 0.0434 (0.0726)\n",
      "Valid: [epoch:4]  [ 0/14]  eta: 0:00:42  L1_loss: 0.0105 (0.0105)  time: 3.0064  data: 0.4478  max mem: 31350\n",
      "Valid: [epoch:4]  [13/14]  eta: 0:00:02  L1_loss: 0.0095 (0.0100)  time: 2.5668  data: 0.0321  max mem: 31350\n",
      "Valid: [epoch:4] Total time: 0:00:36 (2.5764 s / it)\n",
      "Averaged stats: L1_loss: 0.0095 (0.0100)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_4_input_n_20.png\n",
      "Train: [epoch:5]  [  0/862]  eta: 1:16:31  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9970 (1.9970)  loss/pix_loss: 0.0098 (0.0098)  loss/enc_loss: 0.0465 (0.0465)  time: 5.3264  data: 1.1397  max mem: 31350\n",
      "Train: [epoch:5]  [ 10/862]  eta: 1:00:41  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9973 (1.9972)  loss/pix_loss: 0.0097 (0.0097)  loss/enc_loss: 0.0426 (0.0425)  time: 4.2738  data: 0.1037  max mem: 31350\n",
      "Train: [epoch:5]  [ 20/862]  eta: 0:59:23  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9973 (1.9973)  loss/pix_loss: 0.0095 (0.0093)  loss/enc_loss: 0.0407 (0.0428)  time: 4.1778  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [ 30/862]  eta: 0:58:30  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9974 (1.9973)  loss/pix_loss: 0.0085 (0.0091)  loss/enc_loss: 0.0407 (0.0420)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [ 40/862]  eta: 0:57:43  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9974 (1.9973)  loss/pix_loss: 0.0084 (0.0089)  loss/enc_loss: 0.0407 (0.0415)  time: 4.1935  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [ 50/862]  eta: 0:57:00  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9975 (1.9974)  loss/pix_loss: 0.0085 (0.0089)  loss/enc_loss: 0.0386 (0.0418)  time: 4.2018  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [ 60/862]  eta: 0:56:17  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9976 (1.9974)  loss/pix_loss: 0.0090 (0.0089)  loss/enc_loss: 0.0391 (0.0415)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [ 70/862]  eta: 0:55:35  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9976 (1.9975)  loss/pix_loss: 0.0089 (0.0089)  loss/enc_loss: 0.0407 (0.0416)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [ 80/862]  eta: 0:54:52  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9976 (1.9975)  loss/pix_loss: 0.0089 (0.0089)  loss/enc_loss: 0.0412 (0.0415)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [ 90/862]  eta: 0:54:10  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9976 (1.9975)  loss/pix_loss: 0.0090 (0.0090)  loss/enc_loss: 0.0412 (0.0418)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [100/862]  eta: 0:53:27  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9977 (1.9975)  loss/pix_loss: 0.0089 (0.0090)  loss/enc_loss: 0.0405 (0.0416)  time: 4.2051  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [110/862]  eta: 0:52:45  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9978 (1.9976)  loss/pix_loss: 0.0088 (0.0090)  loss/enc_loss: 0.0397 (0.0414)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [120/862]  eta: 0:52:03  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9980 (1.9976)  loss/pix_loss: 0.0090 (0.0090)  loss/enc_loss: 0.0397 (0.0412)  time: 4.2118  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [130/862]  eta: 0:51:21  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9981 (1.9976)  loss/pix_loss: 0.0093 (0.0091)  loss/enc_loss: 0.0367 (0.0411)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [140/862]  eta: 0:50:39  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9978 (1.9976)  loss/pix_loss: 0.0092 (0.0090)  loss/enc_loss: 0.0369 (0.0410)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [150/862]  eta: 0:49:57  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9976 (1.9976)  loss/pix_loss: 0.0087 (0.0090)  loss/enc_loss: 0.0391 (0.0410)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [160/862]  eta: 0:49:15  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9977 (1.9976)  loss/pix_loss: 0.0085 (0.0090)  loss/enc_loss: 0.0367 (0.0407)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [170/862]  eta: 0:48:33  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9977 (1.9976)  loss/pix_loss: 0.0090 (0.0090)  loss/enc_loss: 0.0357 (0.0406)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [180/862]  eta: 0:47:50  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9976 (1.9976)  loss/pix_loss: 0.0099 (0.0091)  loss/enc_loss: 0.0333 (0.0401)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [190/862]  eta: 0:47:08  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9976 (1.9976)  loss/pix_loss: 0.0102 (0.0092)  loss/enc_loss: 0.0330 (0.0398)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [200/862]  eta: 0:46:26  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9974 (1.9976)  loss/pix_loss: 0.0096 (0.0092)  loss/enc_loss: 0.0310 (0.0393)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [210/862]  eta: 0:45:44  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9972 (1.9976)  loss/pix_loss: 0.0090 (0.0092)  loss/enc_loss: 0.0321 (0.0391)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [220/862]  eta: 0:45:02  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9970 (1.9975)  loss/pix_loss: 0.0083 (0.0091)  loss/enc_loss: 0.0336 (0.0389)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [230/862]  eta: 0:44:20  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9968 (1.9975)  loss/pix_loss: 0.0083 (0.0091)  loss/enc_loss: 0.0341 (0.0387)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [240/862]  eta: 0:43:38  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9975 (1.9975)  loss/pix_loss: 0.0093 (0.0091)  loss/enc_loss: 0.0335 (0.0385)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [250/862]  eta: 0:42:56  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9976 (1.9975)  loss/pix_loss: 0.0094 (0.0091)  loss/enc_loss: 0.0314 (0.0382)  time: 4.2099  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [260/862]  eta: 0:42:14  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9969 (1.9975)  loss/pix_loss: 0.0084 (0.0091)  loss/enc_loss: 0.0331 (0.0381)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [270/862]  eta: 0:41:32  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9967 (1.9974)  loss/pix_loss: 0.0083 (0.0091)  loss/enc_loss: 0.0329 (0.0378)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [280/862]  eta: 0:40:49  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9965 (1.9974)  loss/pix_loss: 0.0091 (0.0091)  loss/enc_loss: 0.0308 (0.0376)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [290/862]  eta: 0:40:07  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9964 (1.9974)  loss/pix_loss: 0.0094 (0.0091)  loss/enc_loss: 0.0308 (0.0374)  time: 4.2097  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [300/862]  eta: 0:39:25  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9963 (1.9973)  loss/pix_loss: 0.0099 (0.0092)  loss/enc_loss: 0.0315 (0.0373)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [310/862]  eta: 0:38:43  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9957 (1.9968)  loss/pix_loss: 0.0094 (0.0092)  loss/enc_loss: 0.0334 (0.0372)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [320/862]  eta: 0:38:01  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9735 (1.9960)  loss/pix_loss: 0.0093 (0.0092)  loss/enc_loss: 0.0324 (0.0371)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [330/862]  eta: 0:37:19  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9790 (1.9956)  loss/pix_loss: 0.0096 (0.0093)  loss/enc_loss: 0.0315 (0.0369)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [340/862]  eta: 0:36:37  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9862 (1.9954)  loss/pix_loss: 0.0137 (0.0094)  loss/enc_loss: 0.0309 (0.0368)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [350/862]  eta: 0:35:55  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9891 (1.9952)  loss/pix_loss: 0.0114 (0.0094)  loss/enc_loss: 0.0309 (0.0366)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [360/862]  eta: 0:35:13  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9897 (1.9951)  loss/pix_loss: 0.0096 (0.0094)  loss/enc_loss: 0.0298 (0.0364)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [370/862]  eta: 0:34:30  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9912 (1.9950)  loss/pix_loss: 0.0093 (0.0094)  loss/enc_loss: 0.0274 (0.0362)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [380/862]  eta: 0:33:48  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9919 (1.9949)  loss/pix_loss: 0.0086 (0.0094)  loss/enc_loss: 0.0285 (0.0360)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [390/862]  eta: 0:33:06  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9924 (1.9949)  loss/pix_loss: 0.0082 (0.0094)  loss/enc_loss: 0.0286 (0.0359)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [400/862]  eta: 0:32:24  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9930 (1.9948)  loss/pix_loss: 0.0079 (0.0093)  loss/enc_loss: 0.0310 (0.0357)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [410/862]  eta: 0:31:42  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9930 (1.9948)  loss/pix_loss: 0.0074 (0.0093)  loss/enc_loss: 0.0282 (0.0356)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [420/862]  eta: 0:31:00  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9931 (1.9947)  loss/pix_loss: 0.0074 (0.0093)  loss/enc_loss: 0.0275 (0.0354)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [430/862]  eta: 0:30:18  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9936 (1.9947)  loss/pix_loss: 0.0077 (0.0092)  loss/enc_loss: 0.0282 (0.0353)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [440/862]  eta: 0:29:36  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9942 (1.9947)  loss/pix_loss: 0.0081 (0.0092)  loss/enc_loss: 0.0282 (0.0351)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [450/862]  eta: 0:28:54  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9947 (1.9947)  loss/pix_loss: 0.0087 (0.0092)  loss/enc_loss: 0.0278 (0.0349)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [460/862]  eta: 0:28:12  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9953 (1.9947)  loss/pix_loss: 0.0093 (0.0092)  loss/enc_loss: 0.0278 (0.0348)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [470/862]  eta: 0:27:30  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9956 (1.9948)  loss/pix_loss: 0.0093 (0.0092)  loss/enc_loss: 0.0281 (0.0347)  time: 4.2134  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [480/862]  eta: 0:26:48  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9965 (1.9948)  loss/pix_loss: 0.0089 (0.0092)  loss/enc_loss: 0.0279 (0.0345)  time: 4.2134  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [490/862]  eta: 0:26:05  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9960 (1.9948)  loss/pix_loss: 0.0089 (0.0092)  loss/enc_loss: 0.0281 (0.0344)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [500/862]  eta: 0:25:23  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9957 (1.9949)  loss/pix_loss: 0.0109 (0.0093)  loss/enc_loss: 0.0283 (0.0343)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [510/862]  eta: 0:24:41  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9965 (1.9949)  loss/pix_loss: 0.0105 (0.0093)  loss/enc_loss: 0.0265 (0.0341)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [520/862]  eta: 0:23:59  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9970 (1.9949)  loss/pix_loss: 0.0081 (0.0092)  loss/enc_loss: 0.0260 (0.0339)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [530/862]  eta: 0:23:17  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9967 (1.9950)  loss/pix_loss: 0.0081 (0.0092)  loss/enc_loss: 0.0272 (0.0339)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [540/862]  eta: 0:22:35  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9963 (1.9950)  loss/pix_loss: 0.0081 (0.0092)  loss/enc_loss: 0.0240 (0.0337)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [550/862]  eta: 0:21:53  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9955 (1.9950)  loss/pix_loss: 0.0075 (0.0092)  loss/enc_loss: 0.0225 (0.0335)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [560/862]  eta: 0:21:11  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9946 (1.9950)  loss/pix_loss: 0.0078 (0.0091)  loss/enc_loss: 0.0247 (0.0334)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [570/862]  eta: 0:20:29  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9938 (1.9950)  loss/pix_loss: 0.0087 (0.0091)  loss/enc_loss: 0.0252 (0.0332)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [580/862]  eta: 0:19:47  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9944 (1.9949)  loss/pix_loss: 0.0092 (0.0091)  loss/enc_loss: 0.0252 (0.0331)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [590/862]  eta: 0:19:04  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9944 (1.9949)  loss/pix_loss: 0.0087 (0.0091)  loss/enc_loss: 0.0262 (0.0330)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [600/862]  eta: 0:18:22  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9943 (1.9949)  loss/pix_loss: 0.0085 (0.0091)  loss/enc_loss: 0.0236 (0.0328)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [610/862]  eta: 0:17:40  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9936 (1.9949)  loss/pix_loss: 0.0079 (0.0091)  loss/enc_loss: 0.0236 (0.0327)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [620/862]  eta: 0:16:58  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9922 (1.9948)  loss/pix_loss: 0.0075 (0.0091)  loss/enc_loss: 0.0236 (0.0325)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [630/862]  eta: 0:16:16  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9922 (1.9948)  loss/pix_loss: 0.0080 (0.0091)  loss/enc_loss: 0.0238 (0.0324)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [640/862]  eta: 0:15:34  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9928 (1.9948)  loss/pix_loss: 0.0084 (0.0091)  loss/enc_loss: 0.0252 (0.0323)  time: 4.2088  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:5]  [650/862]  eta: 0:14:52  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9932 (1.9947)  loss/pix_loss: 0.0075 (0.0090)  loss/enc_loss: 0.0248 (0.0322)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [660/862]  eta: 0:14:10  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9929 (1.9947)  loss/pix_loss: 0.0075 (0.0090)  loss/enc_loss: 0.0235 (0.0321)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [670/862]  eta: 0:13:28  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9925 (1.9947)  loss/pix_loss: 0.0077 (0.0090)  loss/enc_loss: 0.0243 (0.0320)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [680/862]  eta: 0:12:46  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9920 (1.9946)  loss/pix_loss: 0.0076 (0.0090)  loss/enc_loss: 0.0228 (0.0318)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [690/862]  eta: 0:12:03  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9921 (1.9946)  loss/pix_loss: 0.0076 (0.0090)  loss/enc_loss: 0.0212 (0.0317)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [700/862]  eta: 0:11:21  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9918 (1.9945)  loss/pix_loss: 0.0077 (0.0089)  loss/enc_loss: 0.0212 (0.0315)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [710/862]  eta: 0:10:39  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9919 (1.9945)  loss/pix_loss: 0.0079 (0.0089)  loss/enc_loss: 0.0212 (0.0314)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [720/862]  eta: 0:09:57  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9882 (1.9944)  loss/pix_loss: 0.0084 (0.0089)  loss/enc_loss: 0.0196 (0.0312)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [730/862]  eta: 0:09:15  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9873 (1.9943)  loss/pix_loss: 0.0089 (0.0089)  loss/enc_loss: 0.0211 (0.0311)  time: 4.2108  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [740/862]  eta: 0:08:33  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9869 (1.9942)  loss/pix_loss: 0.0084 (0.0089)  loss/enc_loss: 0.0213 (0.0310)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [750/862]  eta: 0:07:51  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9873 (1.9941)  loss/pix_loss: 0.0086 (0.0089)  loss/enc_loss: 0.0208 (0.0309)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [760/862]  eta: 0:07:09  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9879 (1.9940)  loss/pix_loss: 0.0096 (0.0089)  loss/enc_loss: 0.0205 (0.0307)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [770/862]  eta: 0:06:27  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9873 (1.9939)  loss/pix_loss: 0.0089 (0.0089)  loss/enc_loss: 0.0205 (0.0306)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [780/862]  eta: 0:05:45  lr: 0.000040  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9827 (1.9937)  loss/pix_loss: 0.0085 (0.0089)  loss/enc_loss: 0.0207 (0.0305)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [790/862]  eta: 0:05:03  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9818 (1.9936)  loss/pix_loss: 0.0090 (0.0089)  loss/enc_loss: 0.0204 (0.0304)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [800/862]  eta: 0:04:20  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9843 (1.9935)  loss/pix_loss: 0.0088 (0.0089)  loss/enc_loss: 0.0209 (0.0303)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [810/862]  eta: 0:03:38  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9856 (1.9934)  loss/pix_loss: 0.0084 (0.0089)  loss/enc_loss: 0.0206 (0.0302)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [820/862]  eta: 0:02:56  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9835 (1.9932)  loss/pix_loss: 0.0083 (0.0089)  loss/enc_loss: 0.0190 (0.0301)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [830/862]  eta: 0:02:14  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9803 (1.9931)  loss/pix_loss: 0.0083 (0.0089)  loss/enc_loss: 0.0189 (0.0299)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [840/862]  eta: 0:01:32  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9787 (1.9929)  loss/pix_loss: 0.0099 (0.0089)  loss/enc_loss: 0.0194 (0.0298)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [850/862]  eta: 0:00:50  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9787 (1.9927)  loss/pix_loss: 0.0106 (0.0090)  loss/enc_loss: 0.0196 (0.0297)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [860/862]  eta: 0:00:08  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9748 (1.9925)  loss/pix_loss: 0.0095 (0.0090)  loss/enc_loss: 0.0195 (0.0296)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5]  [861/862]  eta: 0:00:04  lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9748 (1.9925)  loss/pix_loss: 0.0095 (0.0090)  loss/enc_loss: 0.0195 (0.0296)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:5] Total time: 1:00:28 (4.2091 s / it)\n",
      "Averaged stats: lr: 0.000040  loss/low_gen_loss: 2.0000 (1.9999)  loss/high_gen_loss: 1.9748 (1.9925)  loss/pix_loss: 0.0095 (0.0090)  loss/enc_loss: 0.0195 (0.0296)\n",
      "Valid: [epoch:5]  [ 0/14]  eta: 0:00:41  L1_loss: 0.0090 (0.0090)  time: 2.9499  data: 0.3994  max mem: 31350\n",
      "Valid: [epoch:5]  [13/14]  eta: 0:00:02  L1_loss: 0.0090 (0.0093)  time: 2.5558  data: 0.0286  max mem: 31350\n",
      "Valid: [epoch:5] Total time: 0:00:35 (2.5655 s / it)\n",
      "Averaged stats: L1_loss: 0.0090 (0.0093)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_5_input_n_20.png\n",
      "Train: [epoch:6]  [  0/862]  eta: 1:14:58  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9768 (1.9768)  loss/pix_loss: 0.0088 (0.0088)  loss/enc_loss: 0.0282 (0.0282)  time: 5.2182  data: 1.0081  max mem: 31350\n",
      "Train: [epoch:6]  [ 10/862]  eta: 1:01:03  lr: 0.000050  loss/low_gen_loss: 2.0000 (2.0000)  loss/high_gen_loss: 1.9715 (1.9712)  loss/pix_loss: 0.0090 (0.0093)  loss/enc_loss: 0.0185 (0.0193)  time: 4.2997  data: 0.0917  max mem: 31350\n",
      "Train: [epoch:6]  [ 20/862]  eta: 0:59:43  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9692 (1.9690)  loss/pix_loss: 0.0088 (0.0091)  loss/enc_loss: 0.0180 (0.0193)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [ 30/862]  eta: 0:58:48  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9694 (1.9698)  loss/pix_loss: 0.0090 (0.0092)  loss/enc_loss: 0.0174 (0.0191)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [ 40/862]  eta: 0:57:59  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9710 (1.9701)  loss/pix_loss: 0.0090 (0.0091)  loss/enc_loss: 0.0173 (0.0187)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [ 50/862]  eta: 0:57:12  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9789 (1.9731)  loss/pix_loss: 0.0090 (0.0092)  loss/enc_loss: 0.0175 (0.0187)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [ 60/862]  eta: 0:56:27  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9904 (1.9762)  loss/pix_loss: 0.0095 (0.0092)  loss/enc_loss: 0.0177 (0.0186)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [ 70/862]  eta: 0:55:44  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9921 (1.9785)  loss/pix_loss: 0.0093 (0.0092)  loss/enc_loss: 0.0176 (0.0187)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [ 80/862]  eta: 0:55:00  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9925 (1.9800)  loss/pix_loss: 0.0086 (0.0091)  loss/enc_loss: 0.0194 (0.0189)  time: 4.2085  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [ 90/862]  eta: 0:54:17  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9862 (1.9803)  loss/pix_loss: 0.0084 (0.0091)  loss/enc_loss: 0.0186 (0.0189)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [100/862]  eta: 0:53:34  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9819 (1.9805)  loss/pix_loss: 0.0092 (0.0091)  loss/enc_loss: 0.0186 (0.0189)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [110/862]  eta: 0:52:51  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9830 (1.9809)  loss/pix_loss: 0.0088 (0.0090)  loss/enc_loss: 0.0181 (0.0189)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [120/862]  eta: 0:52:08  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9871 (1.9815)  loss/pix_loss: 0.0083 (0.0090)  loss/enc_loss: 0.0181 (0.0188)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [130/862]  eta: 0:51:25  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9905 (1.9823)  loss/pix_loss: 0.0083 (0.0089)  loss/enc_loss: 0.0175 (0.0188)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [140/862]  eta: 0:50:43  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9910 (1.9829)  loss/pix_loss: 0.0081 (0.0089)  loss/enc_loss: 0.0176 (0.0188)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [150/862]  eta: 0:50:00  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9893 (1.9832)  loss/pix_loss: 0.0098 (0.0090)  loss/enc_loss: 0.0180 (0.0187)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [160/862]  eta: 0:49:18  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9884 (1.9834)  loss/pix_loss: 0.0115 (0.0092)  loss/enc_loss: 0.0182 (0.0187)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [170/862]  eta: 0:48:35  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9886 (1.9838)  loss/pix_loss: 0.0106 (0.0092)  loss/enc_loss: 0.0176 (0.0187)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [180/862]  eta: 0:47:53  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9886 (1.9840)  loss/pix_loss: 0.0096 (0.0092)  loss/enc_loss: 0.0160 (0.0185)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [190/862]  eta: 0:47:11  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9880 (1.9842)  loss/pix_loss: 0.0096 (0.0093)  loss/enc_loss: 0.0145 (0.0183)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [200/862]  eta: 0:46:29  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9874 (1.9844)  loss/pix_loss: 0.0089 (0.0092)  loss/enc_loss: 0.0145 (0.0182)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [210/862]  eta: 0:45:46  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9869 (1.9845)  loss/pix_loss: 0.0082 (0.0092)  loss/enc_loss: 0.0165 (0.0182)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [220/862]  eta: 0:45:04  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9869 (1.9846)  loss/pix_loss: 0.0078 (0.0091)  loss/enc_loss: 0.0183 (0.0182)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [230/862]  eta: 0:44:22  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9884 (1.9848)  loss/pix_loss: 0.0079 (0.0091)  loss/enc_loss: 0.0183 (0.0182)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [240/862]  eta: 0:43:40  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9901 (1.9851)  loss/pix_loss: 0.0081 (0.0091)  loss/enc_loss: 0.0175 (0.0181)  time: 4.2128  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [250/862]  eta: 0:42:57  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9908 (1.9852)  loss/pix_loss: 0.0090 (0.0091)  loss/enc_loss: 0.0157 (0.0180)  time: 4.2129  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [260/862]  eta: 0:42:15  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9908 (1.9854)  loss/pix_loss: 0.0100 (0.0091)  loss/enc_loss: 0.0157 (0.0180)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [270/862]  eta: 0:41:33  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9887 (1.9854)  loss/pix_loss: 0.0100 (0.0091)  loss/enc_loss: 0.0158 (0.0179)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [280/862]  eta: 0:40:51  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9851 (1.9854)  loss/pix_loss: 0.0091 (0.0091)  loss/enc_loss: 0.0154 (0.0178)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [290/862]  eta: 0:40:09  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9881 (1.9855)  loss/pix_loss: 0.0093 (0.0092)  loss/enc_loss: 0.0148 (0.0177)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [300/862]  eta: 0:39:26  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9912 (1.9857)  loss/pix_loss: 0.0108 (0.0093)  loss/enc_loss: 0.0152 (0.0177)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [310/862]  eta: 0:38:44  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9923 (1.9859)  loss/pix_loss: 0.0124 (0.0094)  loss/enc_loss: 0.0169 (0.0177)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [320/862]  eta: 0:38:02  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9907 (1.9860)  loss/pix_loss: 0.0124 (0.0095)  loss/enc_loss: 0.0174 (0.0177)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [330/862]  eta: 0:37:20  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9864 (1.9858)  loss/pix_loss: 0.0132 (0.0096)  loss/enc_loss: 0.0159 (0.0176)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [340/862]  eta: 0:36:38  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9751 (1.9854)  loss/pix_loss: 0.0102 (0.0096)  loss/enc_loss: 0.0143 (0.0176)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [350/862]  eta: 0:35:56  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9716 (1.9850)  loss/pix_loss: 0.0099 (0.0096)  loss/enc_loss: 0.0148 (0.0175)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [360/862]  eta: 0:35:14  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9749 (1.9848)  loss/pix_loss: 0.0101 (0.0096)  loss/enc_loss: 0.0154 (0.0175)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [370/862]  eta: 0:34:31  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9764 (1.9846)  loss/pix_loss: 0.0097 (0.0096)  loss/enc_loss: 0.0142 (0.0174)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [380/862]  eta: 0:33:49  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9762 (1.9843)  loss/pix_loss: 0.0099 (0.0097)  loss/enc_loss: 0.0146 (0.0173)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [390/862]  eta: 0:33:07  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9730 (1.9840)  loss/pix_loss: 0.0099 (0.0097)  loss/enc_loss: 0.0145 (0.0172)  time: 4.2091  data: 0.0002  max mem: 31350\n",
      "Train: [epoch:6]  [400/862]  eta: 0:32:25  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9678 (1.9835)  loss/pix_loss: 0.0092 (0.0096)  loss/enc_loss: 0.0145 (0.0172)  time: 4.2091  data: 0.0002  max mem: 31350\n",
      "Train: [epoch:6]  [410/862]  eta: 0:31:43  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9647 (1.9831)  loss/pix_loss: 0.0086 (0.0096)  loss/enc_loss: 0.0154 (0.0171)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [420/862]  eta: 0:31:01  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9608 (1.9825)  loss/pix_loss: 0.0082 (0.0096)  loss/enc_loss: 0.0145 (0.0171)  time: 4.2108  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [430/862]  eta: 0:30:19  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9629 (1.9822)  loss/pix_loss: 0.0083 (0.0096)  loss/enc_loss: 0.0145 (0.0170)  time: 4.2103  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [440/862]  eta: 0:29:36  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9792 (1.9823)  loss/pix_loss: 0.0086 (0.0095)  loss/enc_loss: 0.0147 (0.0170)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [450/862]  eta: 0:28:54  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9909 (1.9825)  loss/pix_loss: 0.0084 (0.0095)  loss/enc_loss: 0.0130 (0.0169)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [460/862]  eta: 0:28:12  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9920 (1.9827)  loss/pix_loss: 0.0084 (0.0095)  loss/enc_loss: 0.0133 (0.0168)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [470/862]  eta: 0:27:30  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9920 (1.9829)  loss/pix_loss: 0.0085 (0.0095)  loss/enc_loss: 0.0141 (0.0168)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [480/862]  eta: 0:26:48  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9998)  loss/high_gen_loss: 1.9922 (1.9831)  loss/pix_loss: 0.0081 (0.0094)  loss/enc_loss: 0.0140 (0.0167)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [490/862]  eta: 0:26:06  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9998)  loss/high_gen_loss: 1.9931 (1.9833)  loss/pix_loss: 0.0081 (0.0094)  loss/enc_loss: 0.0133 (0.0167)  time: 4.2060  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [500/862]  eta: 0:25:24  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9998)  loss/high_gen_loss: 1.9944 (1.9835)  loss/pix_loss: 0.0082 (0.0094)  loss/enc_loss: 0.0125 (0.0166)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [510/862]  eta: 0:24:42  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9998)  loss/high_gen_loss: 1.9941 (1.9837)  loss/pix_loss: 0.0080 (0.0094)  loss/enc_loss: 0.0128 (0.0165)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [520/862]  eta: 0:23:59  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9998)  loss/high_gen_loss: 1.9933 (1.9839)  loss/pix_loss: 0.0080 (0.0093)  loss/enc_loss: 0.0138 (0.0165)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [530/862]  eta: 0:23:17  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9998)  loss/high_gen_loss: 1.9925 (1.9840)  loss/pix_loss: 0.0078 (0.0093)  loss/enc_loss: 0.0133 (0.0164)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [540/862]  eta: 0:22:35  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9926 (1.9842)  loss/pix_loss: 0.0078 (0.0093)  loss/enc_loss: 0.0131 (0.0164)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [550/862]  eta: 0:21:53  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9928 (1.9844)  loss/pix_loss: 0.0074 (0.0092)  loss/enc_loss: 0.0126 (0.0163)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [560/862]  eta: 0:21:11  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9926 (1.9845)  loss/pix_loss: 0.0071 (0.0092)  loss/enc_loss: 0.0131 (0.0163)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [570/862]  eta: 0:20:29  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9930 (1.9847)  loss/pix_loss: 0.0073 (0.0092)  loss/enc_loss: 0.0122 (0.0162)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [580/862]  eta: 0:19:47  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9945 (1.9849)  loss/pix_loss: 0.0071 (0.0091)  loss/enc_loss: 0.0113 (0.0161)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [590/862]  eta: 0:19:05  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9944 (1.9850)  loss/pix_loss: 0.0072 (0.0091)  loss/enc_loss: 0.0125 (0.0161)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [600/862]  eta: 0:18:23  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9927 (1.9851)  loss/pix_loss: 0.0073 (0.0091)  loss/enc_loss: 0.0129 (0.0160)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [610/862]  eta: 0:17:40  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9909 (1.9852)  loss/pix_loss: 0.0074 (0.0090)  loss/enc_loss: 0.0126 (0.0159)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [620/862]  eta: 0:16:58  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9907 (1.9853)  loss/pix_loss: 0.0076 (0.0090)  loss/enc_loss: 0.0113 (0.0159)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [630/862]  eta: 0:16:16  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9790 (1.9851)  loss/pix_loss: 0.0077 (0.0090)  loss/enc_loss: 0.0113 (0.0158)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [640/862]  eta: 0:15:34  lr: 0.000050  loss/low_gen_loss: 1.9999 (1.9999)  loss/high_gen_loss: 1.9790 (1.9851)  loss/pix_loss: 0.0082 (0.0090)  loss/enc_loss: 0.0115 (0.0157)  time: 4.2064  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [650/862]  eta: 0:14:52  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9902 (1.9852)  loss/pix_loss: 0.0083 (0.0090)  loss/enc_loss: 0.0119 (0.0157)  time: 4.2060  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [660/862]  eta: 0:14:10  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9914 (1.9853)  loss/pix_loss: 0.0081 (0.0090)  loss/enc_loss: 0.0115 (0.0156)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [670/862]  eta: 0:13:28  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9999)  loss/high_gen_loss: 1.9911 (1.9853)  loss/pix_loss: 0.0076 (0.0089)  loss/enc_loss: 0.0114 (0.0156)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [680/862]  eta: 0:12:46  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9908 (1.9854)  loss/pix_loss: 0.0078 (0.0089)  loss/enc_loss: 0.0114 (0.0155)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [690/862]  eta: 0:12:04  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9903 (1.9854)  loss/pix_loss: 0.0089 (0.0089)  loss/enc_loss: 0.0109 (0.0154)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [700/862]  eta: 0:11:21  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9901 (1.9855)  loss/pix_loss: 0.0086 (0.0089)  loss/enc_loss: 0.0112 (0.0154)  time: 4.2113  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [710/862]  eta: 0:10:39  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9901 (1.9855)  loss/pix_loss: 0.0076 (0.0089)  loss/enc_loss: 0.0114 (0.0153)  time: 4.2111  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [720/862]  eta: 0:09:57  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9896 (1.9856)  loss/pix_loss: 0.0074 (0.0089)  loss/enc_loss: 0.0105 (0.0153)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [730/862]  eta: 0:09:15  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9867 (1.9856)  loss/pix_loss: 0.0080 (0.0089)  loss/enc_loss: 0.0113 (0.0152)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [740/862]  eta: 0:08:33  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9833 (1.9855)  loss/pix_loss: 0.0088 (0.0089)  loss/enc_loss: 0.0115 (0.0152)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [750/862]  eta: 0:07:51  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9806 (1.9854)  loss/pix_loss: 0.0079 (0.0089)  loss/enc_loss: 0.0106 (0.0151)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [760/862]  eta: 0:07:09  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9771 (1.9852)  loss/pix_loss: 0.0076 (0.0089)  loss/enc_loss: 0.0099 (0.0151)  time: 4.2074  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [770/862]  eta: 0:06:27  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9759 (1.9851)  loss/pix_loss: 0.0080 (0.0089)  loss/enc_loss: 0.0096 (0.0150)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [780/862]  eta: 0:05:45  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9840 (1.9851)  loss/pix_loss: 0.0083 (0.0089)  loss/enc_loss: 0.0107 (0.0150)  time: 4.2059  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [790/862]  eta: 0:05:03  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.9574 (1.9832)  loss/pix_loss: 0.0096 (0.0089)  loss/enc_loss: 0.0112 (0.0149)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [800/862]  eta: 0:04:20  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.7627 (1.9798)  loss/pix_loss: 0.0105 (0.0089)  loss/enc_loss: 0.0108 (0.0149)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [810/862]  eta: 0:03:38  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.6840 (1.9760)  loss/pix_loss: 0.0115 (0.0090)  loss/enc_loss: 0.0104 (0.0148)  time: 4.2060  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [820/862]  eta: 0:02:56  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.6974 (1.9730)  loss/pix_loss: 0.0141 (0.0090)  loss/enc_loss: 0.0102 (0.0148)  time: 4.2063  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [830/862]  eta: 0:02:14  lr: 0.000050  loss/low_gen_loss: 1.9998 (1.9998)  loss/high_gen_loss: 1.7441 (1.9705)  loss/pix_loss: 0.0172 (0.0092)  loss/enc_loss: 0.0104 (0.0147)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [840/862]  eta: 0:01:32  lr: 0.000050  loss/low_gen_loss: 1.9997 (1.9998)  loss/high_gen_loss: 1.8380 (1.9696)  loss/pix_loss: 0.0187 (0.0093)  loss/enc_loss: 0.0099 (0.0147)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [850/862]  eta: 0:00:50  lr: 0.000050  loss/low_gen_loss: 1.9997 (1.9998)  loss/high_gen_loss: 1.8743 (1.9684)  loss/pix_loss: 0.0169 (0.0093)  loss/enc_loss: 0.0099 (0.0146)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [860/862]  eta: 0:00:08  lr: 0.000050  loss/low_gen_loss: 1.9997 (1.9998)  loss/high_gen_loss: 1.8807 (1.9681)  loss/pix_loss: 0.0154 (0.0094)  loss/enc_loss: 0.0100 (0.0146)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6]  [861/862]  eta: 0:00:04  lr: 0.000050  loss/low_gen_loss: 1.9997 (1.9998)  loss/high_gen_loss: 1.8956 (1.9681)  loss/pix_loss: 0.0154 (0.0094)  loss/enc_loss: 0.0100 (0.0146)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:6] Total time: 1:00:28 (4.2096 s / it)\n",
      "Averaged stats: lr: 0.000050  loss/low_gen_loss: 1.9997 (1.9998)  loss/high_gen_loss: 1.8956 (1.9681)  loss/pix_loss: 0.0154 (0.0094)  loss/enc_loss: 0.0100 (0.0146)\n",
      "Valid: [epoch:6]  [ 0/14]  eta: 0:00:42  L1_loss: 0.0136 (0.0136)  time: 3.0226  data: 0.3821  max mem: 31350\n",
      "Valid: [epoch:6]  [13/14]  eta: 0:00:02  L1_loss: 0.0139 (0.0137)  time: 2.6276  data: 0.0274  max mem: 31350\n",
      "Valid: [epoch:6] Total time: 0:00:36 (2.6371 s / it)\n",
      "Averaged stats: L1_loss: 0.0139 (0.0137)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_6_input_n_20.png\n",
      "Train: [epoch:7]  [  0/862]  eta: 1:16:32  lr: 0.000060  loss/low_gen_loss: 1.9997 (1.9997)  loss/high_gen_loss: 1.9923 (1.9923)  loss/pix_loss: 0.0145 (0.0145)  loss/enc_loss: 0.0091 (0.0091)  time: 5.3280  data: 1.1449  max mem: 31350\n",
      "Train: [epoch:7]  [ 10/862]  eta: 1:00:44  lr: 0.000060  loss/low_gen_loss: 1.9997 (1.9997)  loss/high_gen_loss: 1.9696 (1.9719)  loss/pix_loss: 0.0149 (0.0149)  loss/enc_loss: 0.0098 (0.0099)  time: 4.2775  data: 0.1042  max mem: 31350\n",
      "Train: [epoch:7]  [ 20/862]  eta: 0:59:25  lr: 0.000060  loss/low_gen_loss: 1.9997 (1.9997)  loss/high_gen_loss: 1.9730 (1.9758)  loss/pix_loss: 0.0145 (0.0147)  loss/enc_loss: 0.0092 (0.0099)  time: 4.1797  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [ 30/862]  eta: 0:58:33  lr: 0.000060  loss/low_gen_loss: 1.9996 (1.9996)  loss/high_gen_loss: 1.9832 (1.9467)  loss/pix_loss: 0.0138 (0.0140)  loss/enc_loss: 0.0092 (0.0100)  time: 4.1926  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [ 40/862]  eta: 0:57:47  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9996)  loss/high_gen_loss: 1.7572 (1.8835)  loss/pix_loss: 0.0118 (0.0135)  loss/enc_loss: 0.0099 (0.0101)  time: 4.2006  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [ 50/862]  eta: 0:57:03  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9996)  loss/high_gen_loss: 1.6243 (1.8270)  loss/pix_loss: 0.0153 (0.0151)  loss/enc_loss: 0.0112 (0.0107)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [ 60/862]  eta: 0:56:21  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9995)  loss/high_gen_loss: 1.6266 (1.8040)  loss/pix_loss: 0.0228 (0.0167)  loss/enc_loss: 0.0112 (0.0106)  time: 4.2125  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [ 70/862]  eta: 0:55:38  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9995)  loss/high_gen_loss: 1.7218 (1.7929)  loss/pix_loss: 0.0227 (0.0173)  loss/enc_loss: 0.0122 (0.0111)  time: 4.2130  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [ 80/862]  eta: 0:54:56  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9995)  loss/high_gen_loss: 1.7940 (1.7980)  loss/pix_loss: 0.0205 (0.0177)  loss/enc_loss: 0.0125 (0.0112)  time: 4.2139  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [ 90/862]  eta: 0:54:14  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9995)  loss/high_gen_loss: 1.8666 (1.8068)  loss/pix_loss: 0.0183 (0.0176)  loss/enc_loss: 0.0109 (0.0112)  time: 4.2139  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [100/862]  eta: 0:53:31  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9995)  loss/high_gen_loss: 1.8902 (1.8172)  loss/pix_loss: 0.0161 (0.0174)  loss/enc_loss: 0.0104 (0.0112)  time: 4.2127  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [110/862]  eta: 0:52:49  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9995)  loss/high_gen_loss: 1.9336 (1.8288)  loss/pix_loss: 0.0141 (0.0170)  loss/enc_loss: 0.0098 (0.0110)  time: 4.2119  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [120/862]  eta: 0:52:07  lr: 0.000060  loss/low_gen_loss: 1.9996 (1.9995)  loss/high_gen_loss: 1.9462 (1.8385)  loss/pix_loss: 0.0130 (0.0167)  loss/enc_loss: 0.0091 (0.0109)  time: 4.2121  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [130/862]  eta: 0:51:24  lr: 0.000060  loss/low_gen_loss: 1.9996 (1.9995)  loss/high_gen_loss: 1.9337 (1.8438)  loss/pix_loss: 0.0125 (0.0164)  loss/enc_loss: 0.0092 (0.0108)  time: 4.2121  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [140/862]  eta: 0:50:42  lr: 0.000060  loss/low_gen_loss: 1.9996 (1.9995)  loss/high_gen_loss: 1.8694 (1.8444)  loss/pix_loss: 0.0142 (0.0163)  loss/enc_loss: 0.0098 (0.0108)  time: 4.2107  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [150/862]  eta: 0:50:00  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9995)  loss/high_gen_loss: 1.8843 (1.8512)  loss/pix_loss: 0.0153 (0.0162)  loss/enc_loss: 0.0098 (0.0108)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [160/862]  eta: 0:49:17  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9995)  loss/high_gen_loss: 1.9483 (1.8501)  loss/pix_loss: 0.0145 (0.0161)  loss/enc_loss: 0.0095 (0.0107)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [170/862]  eta: 0:48:35  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9995)  loss/high_gen_loss: 1.9909 (1.8585)  loss/pix_loss: 0.0132 (0.0159)  loss/enc_loss: 0.0093 (0.0106)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [180/862]  eta: 0:47:52  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9995)  loss/high_gen_loss: 1.9907 (1.8653)  loss/pix_loss: 0.0127 (0.0157)  loss/enc_loss: 0.0084 (0.0105)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [190/862]  eta: 0:47:10  lr: 0.000060  loss/low_gen_loss: 1.9996 (1.9995)  loss/high_gen_loss: 1.9879 (1.8719)  loss/pix_loss: 0.0124 (0.0156)  loss/enc_loss: 0.0074 (0.0103)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [200/862]  eta: 0:46:28  lr: 0.000060  loss/low_gen_loss: 1.9996 (1.9995)  loss/high_gen_loss: 1.9335 (1.8605)  loss/pix_loss: 0.0152 (0.0157)  loss/enc_loss: 0.0083 (0.0103)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [210/862]  eta: 0:45:46  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9995)  loss/high_gen_loss: 1.6137 (1.8490)  loss/pix_loss: 0.0152 (0.0156)  loss/enc_loss: 0.0090 (0.0103)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [220/862]  eta: 0:45:03  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9995)  loss/high_gen_loss: 1.6137 (1.8376)  loss/pix_loss: 0.0153 (0.0157)  loss/enc_loss: 0.0104 (0.0103)  time: 4.2069  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [230/862]  eta: 0:44:21  lr: 0.000060  loss/low_gen_loss: 1.9996 (1.9995)  loss/high_gen_loss: 1.6178 (1.8288)  loss/pix_loss: 0.0188 (0.0158)  loss/enc_loss: 0.0128 (0.0104)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [240/862]  eta: 0:43:39  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9995)  loss/high_gen_loss: 1.6940 (1.8268)  loss/pix_loss: 0.0189 (0.0159)  loss/enc_loss: 0.0137 (0.0106)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [250/862]  eta: 0:42:57  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9995)  loss/high_gen_loss: 1.8195 (1.8285)  loss/pix_loss: 0.0180 (0.0160)  loss/enc_loss: 0.0128 (0.0106)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [260/862]  eta: 0:42:14  lr: 0.000060  loss/low_gen_loss: 1.9984 (1.9994)  loss/high_gen_loss: 1.8610 (1.8292)  loss/pix_loss: 0.0167 (0.0160)  loss/enc_loss: 0.0115 (0.0106)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [270/862]  eta: 0:41:32  lr: 0.000060  loss/low_gen_loss: 1.9983 (1.9993)  loss/high_gen_loss: 1.8580 (1.8307)  loss/pix_loss: 0.0175 (0.0161)  loss/enc_loss: 0.0099 (0.0106)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [280/862]  eta: 0:40:50  lr: 0.000060  loss/low_gen_loss: 1.9989 (1.9993)  loss/high_gen_loss: 1.8989 (1.8340)  loss/pix_loss: 0.0181 (0.0162)  loss/enc_loss: 0.0090 (0.0105)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [290/862]  eta: 0:40:08  lr: 0.000060  loss/low_gen_loss: 1.9991 (1.9993)  loss/high_gen_loss: 1.9394 (1.8380)  loss/pix_loss: 0.0197 (0.0163)  loss/enc_loss: 0.0085 (0.0105)  time: 4.2061  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [300/862]  eta: 0:39:26  lr: 0.000060  loss/low_gen_loss: 1.9992 (1.9993)  loss/high_gen_loss: 1.9553 (1.8421)  loss/pix_loss: 0.0174 (0.0163)  loss/enc_loss: 0.0085 (0.0104)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [310/862]  eta: 0:38:44  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9993)  loss/high_gen_loss: 1.9626 (1.8460)  loss/pix_loss: 0.0146 (0.0162)  loss/enc_loss: 0.0090 (0.0104)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [320/862]  eta: 0:38:01  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9993)  loss/high_gen_loss: 1.9477 (1.8485)  loss/pix_loss: 0.0142 (0.0162)  loss/enc_loss: 0.0092 (0.0103)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [330/862]  eta: 0:37:19  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9993)  loss/high_gen_loss: 1.9253 (1.8511)  loss/pix_loss: 0.0142 (0.0162)  loss/enc_loss: 0.0088 (0.0103)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [340/862]  eta: 0:36:37  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9993)  loss/high_gen_loss: 1.9346 (1.8537)  loss/pix_loss: 0.0138 (0.0161)  loss/enc_loss: 0.0085 (0.0102)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [350/862]  eta: 0:35:55  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9993)  loss/high_gen_loss: 1.9346 (1.8554)  loss/pix_loss: 0.0135 (0.0160)  loss/enc_loss: 0.0085 (0.0102)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [360/862]  eta: 0:35:13  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9993)  loss/high_gen_loss: 1.9368 (1.8585)  loss/pix_loss: 0.0137 (0.0160)  loss/enc_loss: 0.0077 (0.0101)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [370/862]  eta: 0:34:31  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9993)  loss/high_gen_loss: 1.9895 (1.8622)  loss/pix_loss: 0.0132 (0.0159)  loss/enc_loss: 0.0082 (0.0101)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [380/862]  eta: 0:33:49  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9993)  loss/high_gen_loss: 1.9928 (1.8656)  loss/pix_loss: 0.0122 (0.0158)  loss/enc_loss: 0.0083 (0.0101)  time: 4.2120  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [390/862]  eta: 0:33:07  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9993)  loss/high_gen_loss: 1.9861 (1.8683)  loss/pix_loss: 0.0127 (0.0157)  loss/enc_loss: 0.0085 (0.0100)  time: 4.2121  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [400/862]  eta: 0:32:25  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9993)  loss/high_gen_loss: 1.9732 (1.8709)  loss/pix_loss: 0.0148 (0.0157)  loss/enc_loss: 0.0083 (0.0100)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [410/862]  eta: 0:31:42  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9993)  loss/high_gen_loss: 1.9848 (1.8739)  loss/pix_loss: 0.0118 (0.0156)  loss/enc_loss: 0.0074 (0.0099)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [420/862]  eta: 0:31:00  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9993)  loss/high_gen_loss: 1.9970 (1.8768)  loss/pix_loss: 0.0106 (0.0155)  loss/enc_loss: 0.0071 (0.0099)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [430/862]  eta: 0:30:18  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9993)  loss/high_gen_loss: 1.9946 (1.8795)  loss/pix_loss: 0.0104 (0.0154)  loss/enc_loss: 0.0084 (0.0098)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [440/862]  eta: 0:29:36  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9993)  loss/high_gen_loss: 1.9936 (1.8821)  loss/pix_loss: 0.0103 (0.0152)  loss/enc_loss: 0.0080 (0.0098)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [450/862]  eta: 0:28:54  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9993)  loss/high_gen_loss: 1.9929 (1.8845)  loss/pix_loss: 0.0100 (0.0151)  loss/enc_loss: 0.0072 (0.0097)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [460/862]  eta: 0:28:12  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9994)  loss/high_gen_loss: 1.9868 (1.8867)  loss/pix_loss: 0.0099 (0.0150)  loss/enc_loss: 0.0069 (0.0097)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [470/862]  eta: 0:27:30  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9994)  loss/high_gen_loss: 1.9865 (1.8889)  loss/pix_loss: 0.0098 (0.0149)  loss/enc_loss: 0.0074 (0.0097)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [480/862]  eta: 0:26:48  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9994)  loss/high_gen_loss: 1.9889 (1.8910)  loss/pix_loss: 0.0096 (0.0148)  loss/enc_loss: 0.0075 (0.0096)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [490/862]  eta: 0:26:05  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9994)  loss/high_gen_loss: 1.9894 (1.8930)  loss/pix_loss: 0.0095 (0.0147)  loss/enc_loss: 0.0075 (0.0096)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [500/862]  eta: 0:25:23  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9894 (1.8949)  loss/pix_loss: 0.0100 (0.0146)  loss/enc_loss: 0.0070 (0.0095)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [510/862]  eta: 0:24:41  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9912 (1.8968)  loss/pix_loss: 0.0103 (0.0145)  loss/enc_loss: 0.0064 (0.0095)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [520/862]  eta: 0:23:59  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9913 (1.8986)  loss/pix_loss: 0.0101 (0.0144)  loss/enc_loss: 0.0069 (0.0094)  time: 4.2074  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [530/862]  eta: 0:23:17  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9913 (1.9004)  loss/pix_loss: 0.0100 (0.0143)  loss/enc_loss: 0.0074 (0.0094)  time: 4.2063  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [540/862]  eta: 0:22:35  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9994)  loss/high_gen_loss: 1.9925 (1.9021)  loss/pix_loss: 0.0094 (0.0143)  loss/enc_loss: 0.0069 (0.0094)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [550/862]  eta: 0:21:53  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9994)  loss/high_gen_loss: 1.9930 (1.9037)  loss/pix_loss: 0.0091 (0.0142)  loss/enc_loss: 0.0069 (0.0093)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [560/862]  eta: 0:21:11  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9994)  loss/high_gen_loss: 1.9928 (1.9053)  loss/pix_loss: 0.0091 (0.0141)  loss/enc_loss: 0.0070 (0.0093)  time: 4.2062  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [570/862]  eta: 0:20:29  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9994)  loss/high_gen_loss: 1.9929 (1.9069)  loss/pix_loss: 0.0091 (0.0140)  loss/enc_loss: 0.0065 (0.0092)  time: 4.2047  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [580/862]  eta: 0:19:46  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9994)  loss/high_gen_loss: 1.9936 (1.9083)  loss/pix_loss: 0.0101 (0.0139)  loss/enc_loss: 0.0065 (0.0092)  time: 4.2043  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [590/862]  eta: 0:19:04  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9994)  loss/high_gen_loss: 1.9927 (1.9098)  loss/pix_loss: 0.0105 (0.0139)  loss/enc_loss: 0.0069 (0.0092)  time: 4.2055  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [600/862]  eta: 0:18:22  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9994)  loss/high_gen_loss: 1.9928 (1.9112)  loss/pix_loss: 0.0094 (0.0138)  loss/enc_loss: 0.0070 (0.0091)  time: 4.2064  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [610/862]  eta: 0:17:40  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9994)  loss/high_gen_loss: 1.9925 (1.9125)  loss/pix_loss: 0.0089 (0.0137)  loss/enc_loss: 0.0070 (0.0091)  time: 4.2057  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [620/862]  eta: 0:16:58  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9928 (1.9138)  loss/pix_loss: 0.0087 (0.0136)  loss/enc_loss: 0.0064 (0.0091)  time: 4.2045  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [630/862]  eta: 0:16:16  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9939 (1.9151)  loss/pix_loss: 0.0086 (0.0136)  loss/enc_loss: 0.0064 (0.0090)  time: 4.2041  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [640/862]  eta: 0:15:34  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9994)  loss/high_gen_loss: 1.9939 (1.9163)  loss/pix_loss: 0.0087 (0.0135)  loss/enc_loss: 0.0068 (0.0090)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [650/862]  eta: 0:14:52  lr: 0.000060  loss/low_gen_loss: 1.9995 (1.9994)  loss/high_gen_loss: 1.9940 (1.9175)  loss/pix_loss: 0.0087 (0.0134)  loss/enc_loss: 0.0068 (0.0090)  time: 4.2173  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [660/862]  eta: 0:14:10  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9941 (1.9186)  loss/pix_loss: 0.0084 (0.0133)  loss/enc_loss: 0.0070 (0.0089)  time: 4.2222  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [670/862]  eta: 0:13:28  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9944 (1.9198)  loss/pix_loss: 0.0085 (0.0133)  loss/enc_loss: 0.0071 (0.0089)  time: 4.2185  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [680/862]  eta: 0:12:46  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9946 (1.9209)  loss/pix_loss: 0.0085 (0.0132)  loss/enc_loss: 0.0071 (0.0089)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [690/862]  eta: 0:12:03  lr: 0.000060  loss/low_gen_loss: 1.9994 (1.9994)  loss/high_gen_loss: 1.9947 (1.9219)  loss/pix_loss: 0.0083 (0.0131)  loss/enc_loss: 0.0064 (0.0089)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [700/862]  eta: 0:11:21  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9994)  loss/high_gen_loss: 1.9950 (1.9230)  loss/pix_loss: 0.0084 (0.0131)  loss/enc_loss: 0.0064 (0.0088)  time: 4.2106  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [710/862]  eta: 0:10:39  lr: 0.000060  loss/low_gen_loss: 1.9986 (1.9993)  loss/high_gen_loss: 1.9970 (1.9241)  loss/pix_loss: 0.0087 (0.0130)  loss/enc_loss: 0.0059 (0.0088)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [720/862]  eta: 0:09:57  lr: 0.000060  loss/low_gen_loss: 1.9984 (1.9993)  loss/high_gen_loss: 1.9965 (1.9251)  loss/pix_loss: 0.0086 (0.0130)  loss/enc_loss: 0.0055 (0.0088)  time: 4.2108  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [730/862]  eta: 0:09:15  lr: 0.000060  loss/low_gen_loss: 1.9987 (1.9993)  loss/high_gen_loss: 1.9954 (1.9260)  loss/pix_loss: 0.0083 (0.0129)  loss/enc_loss: 0.0063 (0.0087)  time: 4.2108  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [740/862]  eta: 0:08:33  lr: 0.000060  loss/low_gen_loss: 1.9988 (1.9993)  loss/high_gen_loss: 1.9953 (1.9270)  loss/pix_loss: 0.0079 (0.0128)  loss/enc_loss: 0.0063 (0.0087)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [750/862]  eta: 0:07:51  lr: 0.000060  loss/low_gen_loss: 1.9989 (1.9993)  loss/high_gen_loss: 1.9952 (1.9279)  loss/pix_loss: 0.0082 (0.0128)  loss/enc_loss: 0.0057 (0.0087)  time: 4.2105  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [760/862]  eta: 0:07:09  lr: 0.000060  loss/low_gen_loss: 1.9991 (1.9993)  loss/high_gen_loss: 1.9947 (1.9287)  loss/pix_loss: 0.0089 (0.0127)  loss/enc_loss: 0.0067 (0.0086)  time: 4.2109  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [770/862]  eta: 0:06:27  lr: 0.000060  loss/low_gen_loss: 1.9992 (1.9993)  loss/high_gen_loss: 1.9948 (1.9296)  loss/pix_loss: 0.0089 (0.0127)  loss/enc_loss: 0.0066 (0.0086)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [780/862]  eta: 0:05:45  lr: 0.000060  loss/low_gen_loss: 1.9991 (1.9993)  loss/high_gen_loss: 1.9948 (1.9304)  loss/pix_loss: 0.0090 (0.0126)  loss/enc_loss: 0.0064 (0.0086)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [790/862]  eta: 0:05:03  lr: 0.000060  loss/low_gen_loss: 1.9991 (1.9993)  loss/high_gen_loss: 1.9946 (1.9312)  loss/pix_loss: 0.0098 (0.0126)  loss/enc_loss: 0.0063 (0.0086)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [800/862]  eta: 0:04:20  lr: 0.000060  loss/low_gen_loss: 1.9992 (1.9993)  loss/high_gen_loss: 1.9947 (1.9320)  loss/pix_loss: 0.0083 (0.0125)  loss/enc_loss: 0.0062 (0.0085)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [810/862]  eta: 0:03:38  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9993)  loss/high_gen_loss: 1.9943 (1.9328)  loss/pix_loss: 0.0086 (0.0125)  loss/enc_loss: 0.0062 (0.0085)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [820/862]  eta: 0:02:56  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9993)  loss/high_gen_loss: 1.9934 (1.9334)  loss/pix_loss: 0.0098 (0.0125)  loss/enc_loss: 0.0059 (0.0085)  time: 4.2111  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [830/862]  eta: 0:02:14  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9993)  loss/high_gen_loss: 1.9790 (1.9339)  loss/pix_loss: 0.0107 (0.0125)  loss/enc_loss: 0.0059 (0.0084)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [840/862]  eta: 0:01:32  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9993)  loss/high_gen_loss: 1.9705 (1.9343)  loss/pix_loss: 0.0104 (0.0124)  loss/enc_loss: 0.0061 (0.0084)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [850/862]  eta: 0:00:50  lr: 0.000060  loss/low_gen_loss: 1.9993 (1.9993)  loss/high_gen_loss: 1.9622 (1.9345)  loss/pix_loss: 0.0089 (0.0124)  loss/enc_loss: 0.0061 (0.0084)  time: 4.2113  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [860/862]  eta: 0:00:08  lr: 0.000060  loss/low_gen_loss: 1.9992 (1.9993)  loss/high_gen_loss: 1.9501 (1.9346)  loss/pix_loss: 0.0080 (0.0123)  loss/enc_loss: 0.0062 (0.0084)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7]  [861/862]  eta: 0:00:04  lr: 0.000060  loss/low_gen_loss: 1.9992 (1.9993)  loss/high_gen_loss: 1.9499 (1.9346)  loss/pix_loss: 0.0080 (0.0123)  loss/enc_loss: 0.0062 (0.0084)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:7] Total time: 1:00:28 (4.2097 s / it)\n",
      "Averaged stats: lr: 0.000060  loss/low_gen_loss: 1.9992 (1.9993)  loss/high_gen_loss: 1.9499 (1.9346)  loss/pix_loss: 0.0080 (0.0123)  loss/enc_loss: 0.0062 (0.0084)\n",
      "Valid: [epoch:7]  [ 0/14]  eta: 0:00:42  L1_loss: 0.0087 (0.0087)  time: 3.0264  data: 0.3874  max mem: 31350\n",
      "Valid: [epoch:7]  [13/14]  eta: 0:00:02  L1_loss: 0.0089 (0.0093)  time: 2.6392  data: 0.0278  max mem: 31350\n",
      "Valid: [epoch:7] Total time: 0:00:37 (2.6489 s / it)\n",
      "Averaged stats: L1_loss: 0.0089 (0.0093)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_7_input_n_20.png\n",
      "Train: [epoch:8]  [  0/862]  eta: 1:14:28  lr: 0.000070  loss/low_gen_loss: 1.9993 (1.9993)  loss/high_gen_loss: 1.9345 (1.9345)  loss/pix_loss: 0.0090 (0.0090)  loss/enc_loss: 0.0057 (0.0057)  time: 5.1836  data: 0.9777  max mem: 31350\n",
      "Train: [epoch:8]  [ 10/862]  eta: 1:00:49  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9992)  loss/high_gen_loss: 1.9311 (1.9257)  loss/pix_loss: 0.0101 (0.0102)  loss/enc_loss: 0.0062 (0.0063)  time: 4.2838  data: 0.0890  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [ 20/862]  eta: 0:59:31  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9992)  loss/high_gen_loss: 1.9170 (1.9163)  loss/pix_loss: 0.0110 (0.0115)  loss/enc_loss: 0.0062 (0.0062)  time: 4.1944  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [ 30/862]  eta: 0:58:36  lr: 0.000070  loss/low_gen_loss: 1.9993 (1.9992)  loss/high_gen_loss: 1.8954 (1.9094)  loss/pix_loss: 0.0136 (0.0125)  loss/enc_loss: 0.0061 (0.0062)  time: 4.1953  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [ 40/862]  eta: 0:57:47  lr: 0.000070  loss/low_gen_loss: 1.9993 (1.9992)  loss/high_gen_loss: 1.9034 (1.9101)  loss/pix_loss: 0.0148 (0.0132)  loss/enc_loss: 0.0062 (0.0062)  time: 4.1948  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [ 50/862]  eta: 0:57:01  lr: 0.000070  loss/low_gen_loss: 1.9993 (1.9992)  loss/high_gen_loss: 1.9295 (1.9154)  loss/pix_loss: 0.0149 (0.0136)  loss/enc_loss: 0.0067 (0.0064)  time: 4.1946  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [ 60/862]  eta: 0:56:17  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9992)  loss/high_gen_loss: 1.9390 (1.9191)  loss/pix_loss: 0.0145 (0.0136)  loss/enc_loss: 0.0071 (0.0070)  time: 4.1956  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [ 70/862]  eta: 0:55:33  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9992)  loss/high_gen_loss: 1.9398 (1.9223)  loss/pix_loss: 0.0145 (0.0138)  loss/enc_loss: 0.0094 (0.0074)  time: 4.1958  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [ 80/862]  eta: 0:54:49  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9992)  loss/high_gen_loss: 1.9428 (1.9249)  loss/pix_loss: 0.0155 (0.0141)  loss/enc_loss: 0.0084 (0.0074)  time: 4.1939  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [ 90/862]  eta: 0:54:06  lr: 0.000070  loss/low_gen_loss: 1.9989 (1.9992)  loss/high_gen_loss: 1.9428 (1.9270)  loss/pix_loss: 0.0175 (0.0147)  loss/enc_loss: 0.0077 (0.0074)  time: 4.1930  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [100/862]  eta: 0:53:23  lr: 0.000070  loss/low_gen_loss: 1.9989 (1.9992)  loss/high_gen_loss: 1.9476 (1.9294)  loss/pix_loss: 0.0131 (0.0145)  loss/enc_loss: 0.0072 (0.0074)  time: 4.1926  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [110/862]  eta: 0:52:40  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9991)  loss/high_gen_loss: 1.9438 (1.9306)  loss/pix_loss: 0.0099 (0.0140)  loss/enc_loss: 0.0068 (0.0073)  time: 4.1915  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [120/862]  eta: 0:51:57  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9567 (1.9334)  loss/pix_loss: 0.0096 (0.0137)  loss/enc_loss: 0.0064 (0.0072)  time: 4.1908  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [130/862]  eta: 0:51:15  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9647 (1.9360)  loss/pix_loss: 0.0110 (0.0139)  loss/enc_loss: 0.0055 (0.0070)  time: 4.1908  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [140/862]  eta: 0:50:32  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9626 (1.9378)  loss/pix_loss: 0.0148 (0.0138)  loss/enc_loss: 0.0053 (0.0070)  time: 4.1934  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [150/862]  eta: 0:49:50  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9991)  loss/high_gen_loss: 1.9605 (1.9392)  loss/pix_loss: 0.0136 (0.0138)  loss/enc_loss: 0.0056 (0.0069)  time: 4.1931  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [160/862]  eta: 0:49:07  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9991)  loss/high_gen_loss: 1.9597 (1.9405)  loss/pix_loss: 0.0117 (0.0136)  loss/enc_loss: 0.0058 (0.0068)  time: 4.1906  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [170/862]  eta: 0:48:25  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9991)  loss/high_gen_loss: 1.9604 (1.9419)  loss/pix_loss: 0.0103 (0.0134)  loss/enc_loss: 0.0058 (0.0068)  time: 4.1904  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [180/862]  eta: 0:47:43  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9621 (1.9431)  loss/pix_loss: 0.0091 (0.0131)  loss/enc_loss: 0.0052 (0.0067)  time: 4.1902  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [190/862]  eta: 0:47:01  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9617 (1.9441)  loss/pix_loss: 0.0085 (0.0129)  loss/enc_loss: 0.0050 (0.0066)  time: 4.1911  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [200/862]  eta: 0:46:19  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9623 (1.9450)  loss/pix_loss: 0.0092 (0.0128)  loss/enc_loss: 0.0049 (0.0065)  time: 4.1946  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [210/862]  eta: 0:45:36  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9580 (1.9453)  loss/pix_loss: 0.0100 (0.0126)  loss/enc_loss: 0.0052 (0.0065)  time: 4.1938  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [220/862]  eta: 0:44:54  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9436 (1.9450)  loss/pix_loss: 0.0100 (0.0125)  loss/enc_loss: 0.0061 (0.0065)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [230/862]  eta: 0:44:12  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9343 (1.9441)  loss/pix_loss: 0.0093 (0.0123)  loss/enc_loss: 0.0060 (0.0065)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [240/862]  eta: 0:43:30  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9219 (1.9431)  loss/pix_loss: 0.0096 (0.0122)  loss/enc_loss: 0.0063 (0.0066)  time: 4.1907  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [250/862]  eta: 0:42:48  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9209 (1.9421)  loss/pix_loss: 0.0100 (0.0122)  loss/enc_loss: 0.0070 (0.0066)  time: 4.1916  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [260/862]  eta: 0:42:06  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9991)  loss/high_gen_loss: 1.9264 (1.9418)  loss/pix_loss: 0.0102 (0.0121)  loss/enc_loss: 0.0073 (0.0068)  time: 4.1913  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [270/862]  eta: 0:41:24  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9991)  loss/high_gen_loss: 1.9353 (1.9418)  loss/pix_loss: 0.0092 (0.0120)  loss/enc_loss: 0.0087 (0.0068)  time: 4.1901  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [280/862]  eta: 0:40:41  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9991)  loss/high_gen_loss: 1.9459 (1.9421)  loss/pix_loss: 0.0092 (0.0119)  loss/enc_loss: 0.0061 (0.0068)  time: 4.1901  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [290/862]  eta: 0:39:59  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9991)  loss/high_gen_loss: 1.9554 (1.9428)  loss/pix_loss: 0.0099 (0.0119)  loss/enc_loss: 0.0054 (0.0068)  time: 4.1912  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [300/862]  eta: 0:39:17  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9991)  loss/high_gen_loss: 1.9635 (1.9435)  loss/pix_loss: 0.0093 (0.0118)  loss/enc_loss: 0.0051 (0.0067)  time: 4.1905  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [310/862]  eta: 0:38:35  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9991)  loss/high_gen_loss: 1.9651 (1.9442)  loss/pix_loss: 0.0088 (0.0117)  loss/enc_loss: 0.0052 (0.0067)  time: 4.1915  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [320/862]  eta: 0:37:53  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9666 (1.9450)  loss/pix_loss: 0.0084 (0.0116)  loss/enc_loss: 0.0055 (0.0066)  time: 4.1940  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [330/862]  eta: 0:37:11  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9686 (1.9456)  loss/pix_loss: 0.0086 (0.0115)  loss/enc_loss: 0.0051 (0.0066)  time: 4.1937  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [340/862]  eta: 0:36:29  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9698 (1.9464)  loss/pix_loss: 0.0117 (0.0116)  loss/enc_loss: 0.0049 (0.0065)  time: 4.1918  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [350/862]  eta: 0:35:47  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9688 (1.9470)  loss/pix_loss: 0.0167 (0.0118)  loss/enc_loss: 0.0048 (0.0065)  time: 4.1928  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [360/862]  eta: 0:35:05  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9683 (1.9476)  loss/pix_loss: 0.0162 (0.0119)  loss/enc_loss: 0.0047 (0.0064)  time: 4.1941  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [370/862]  eta: 0:34:24  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9747 (1.9484)  loss/pix_loss: 0.0123 (0.0119)  loss/enc_loss: 0.0048 (0.0064)  time: 4.1940  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [380/862]  eta: 0:33:42  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9763 (1.9491)  loss/pix_loss: 0.0105 (0.0119)  loss/enc_loss: 0.0050 (0.0064)  time: 4.1935  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [390/862]  eta: 0:33:00  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9755 (1.9498)  loss/pix_loss: 0.0093 (0.0118)  loss/enc_loss: 0.0047 (0.0063)  time: 4.1916  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [400/862]  eta: 0:32:18  lr: 0.000070  loss/low_gen_loss: 1.9992 (1.9991)  loss/high_gen_loss: 1.9753 (1.9505)  loss/pix_loss: 0.0085 (0.0117)  loss/enc_loss: 0.0047 (0.0063)  time: 4.1919  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [410/862]  eta: 0:31:36  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9711 (1.9509)  loss/pix_loss: 0.0079 (0.0116)  loss/enc_loss: 0.0048 (0.0063)  time: 4.1975  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [420/862]  eta: 0:30:54  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9719 (1.9515)  loss/pix_loss: 0.0077 (0.0115)  loss/enc_loss: 0.0048 (0.0062)  time: 4.1973  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [430/862]  eta: 0:30:12  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9726 (1.9519)  loss/pix_loss: 0.0079 (0.0115)  loss/enc_loss: 0.0046 (0.0062)  time: 4.1930  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [440/862]  eta: 0:29:30  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9712 (1.9523)  loss/pix_loss: 0.0105 (0.0115)  loss/enc_loss: 0.0053 (0.0062)  time: 4.1929  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [450/862]  eta: 0:28:48  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9991)  loss/high_gen_loss: 1.9680 (1.9527)  loss/pix_loss: 0.0131 (0.0116)  loss/enc_loss: 0.0050 (0.0062)  time: 4.1936  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [460/862]  eta: 0:28:06  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9991)  loss/high_gen_loss: 1.9709 (1.9531)  loss/pix_loss: 0.0130 (0.0115)  loss/enc_loss: 0.0047 (0.0061)  time: 4.1938  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [470/862]  eta: 0:27:24  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9745 (1.9536)  loss/pix_loss: 0.0107 (0.0115)  loss/enc_loss: 0.0046 (0.0061)  time: 4.1920  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [480/862]  eta: 0:26:42  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9785 (1.9542)  loss/pix_loss: 0.0107 (0.0115)  loss/enc_loss: 0.0045 (0.0061)  time: 4.1923  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [490/862]  eta: 0:26:00  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9800 (1.9547)  loss/pix_loss: 0.0101 (0.0115)  loss/enc_loss: 0.0045 (0.0060)  time: 4.1929  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [500/862]  eta: 0:25:18  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9787 (1.9552)  loss/pix_loss: 0.0096 (0.0115)  loss/enc_loss: 0.0043 (0.0060)  time: 4.1934  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [510/862]  eta: 0:24:36  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9763 (1.9556)  loss/pix_loss: 0.0108 (0.0115)  loss/enc_loss: 0.0042 (0.0060)  time: 4.1931  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [520/862]  eta: 0:23:54  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9724 (1.9558)  loss/pix_loss: 0.0115 (0.0115)  loss/enc_loss: 0.0042 (0.0059)  time: 4.1926  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [530/862]  eta: 0:23:12  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9717 (1.9563)  loss/pix_loss: 0.0103 (0.0115)  loss/enc_loss: 0.0043 (0.0059)  time: 4.1926  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [540/862]  eta: 0:22:30  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9832 (1.9568)  loss/pix_loss: 0.0092 (0.0114)  loss/enc_loss: 0.0043 (0.0059)  time: 4.1924  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [550/862]  eta: 0:21:48  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9894 (1.9574)  loss/pix_loss: 0.0098 (0.0114)  loss/enc_loss: 0.0044 (0.0059)  time: 4.1919  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [560/862]  eta: 0:21:06  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9899 (1.9580)  loss/pix_loss: 0.0102 (0.0114)  loss/enc_loss: 0.0042 (0.0058)  time: 4.1915  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [570/862]  eta: 0:20:24  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9807 (1.9583)  loss/pix_loss: 0.0121 (0.0115)  loss/enc_loss: 0.0041 (0.0058)  time: 4.1939  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [580/862]  eta: 0:19:42  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9797 (1.9587)  loss/pix_loss: 0.0113 (0.0115)  loss/enc_loss: 0.0040 (0.0058)  time: 4.1963  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [590/862]  eta: 0:19:00  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9851 (1.9592)  loss/pix_loss: 0.0089 (0.0114)  loss/enc_loss: 0.0042 (0.0058)  time: 4.1951  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [600/862]  eta: 0:18:18  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9846 (1.9596)  loss/pix_loss: 0.0088 (0.0114)  loss/enc_loss: 0.0041 (0.0057)  time: 4.1928  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [610/862]  eta: 0:17:36  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9839 (1.9600)  loss/pix_loss: 0.0090 (0.0113)  loss/enc_loss: 0.0043 (0.0057)  time: 4.1915  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [620/862]  eta: 0:16:55  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9812 (1.9603)  loss/pix_loss: 0.0081 (0.0113)  loss/enc_loss: 0.0043 (0.0057)  time: 4.1925  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [630/862]  eta: 0:16:13  lr: 0.000070  loss/low_gen_loss: 1.9991 (1.9991)  loss/high_gen_loss: 1.9714 (1.9591)  loss/pix_loss: 0.0081 (0.0112)  loss/enc_loss: 0.0042 (0.0057)  time: 4.1934  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [640/862]  eta: 0:15:31  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9991)  loss/high_gen_loss: 1.6373 (1.9522)  loss/pix_loss: 0.0086 (0.0112)  loss/enc_loss: 0.0064 (0.0059)  time: 4.1944  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [650/862]  eta: 0:14:49  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9991)  loss/high_gen_loss: 1.4679 (1.9446)  loss/pix_loss: 0.0129 (0.0113)  loss/enc_loss: 0.0157 (0.0061)  time: 4.1958  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [660/862]  eta: 0:14:07  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9991)  loss/high_gen_loss: 1.5433 (1.9412)  loss/pix_loss: 0.0143 (0.0113)  loss/enc_loss: 0.0105 (0.0062)  time: 4.1943  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [670/862]  eta: 0:13:25  lr: 0.000070  loss/low_gen_loss: 1.9985 (1.9991)  loss/high_gen_loss: 1.7778 (1.9394)  loss/pix_loss: 0.0160 (0.0114)  loss/enc_loss: 0.0119 (0.0063)  time: 4.1950  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [680/862]  eta: 0:12:43  lr: 0.000070  loss/low_gen_loss: 1.9976 (1.9991)  loss/high_gen_loss: 1.8380 (1.9381)  loss/pix_loss: 0.0155 (0.0115)  loss/enc_loss: 0.0125 (0.0064)  time: 4.1951  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [690/862]  eta: 0:12:01  lr: 0.000070  loss/low_gen_loss: 1.9976 (1.9990)  loss/high_gen_loss: 1.8841 (1.9380)  loss/pix_loss: 0.0149 (0.0115)  loss/enc_loss: 0.0078 (0.0064)  time: 4.1940  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [700/862]  eta: 0:11:19  lr: 0.000070  loss/low_gen_loss: 1.9985 (1.9990)  loss/high_gen_loss: 1.9389 (1.9382)  loss/pix_loss: 0.0124 (0.0115)  loss/enc_loss: 0.0055 (0.0064)  time: 4.1941  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [710/862]  eta: 0:10:37  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9521 (1.9384)  loss/pix_loss: 0.0113 (0.0115)  loss/enc_loss: 0.0042 (0.0063)  time: 4.1939  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:8]  [720/862]  eta: 0:09:55  lr: 0.000070  loss/low_gen_loss: 1.9988 (1.9990)  loss/high_gen_loss: 1.9759 (1.9390)  loss/pix_loss: 0.0100 (0.0115)  loss/enc_loss: 0.0040 (0.0063)  time: 4.1937  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [730/862]  eta: 0:09:13  lr: 0.000070  loss/low_gen_loss: 1.9987 (1.9990)  loss/high_gen_loss: 1.9772 (1.9395)  loss/pix_loss: 0.0092 (0.0114)  loss/enc_loss: 0.0041 (0.0063)  time: 4.1950  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [740/862]  eta: 0:08:31  lr: 0.000070  loss/low_gen_loss: 1.9987 (1.9990)  loss/high_gen_loss: 1.9751 (1.9400)  loss/pix_loss: 0.0085 (0.0114)  loss/enc_loss: 0.0041 (0.0062)  time: 4.1982  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [750/862]  eta: 0:07:49  lr: 0.000070  loss/low_gen_loss: 1.9987 (1.9990)  loss/high_gen_loss: 1.9755 (1.9405)  loss/pix_loss: 0.0084 (0.0114)  loss/enc_loss: 0.0039 (0.0062)  time: 4.1981  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [760/862]  eta: 0:07:07  lr: 0.000070  loss/low_gen_loss: 1.9988 (1.9990)  loss/high_gen_loss: 1.9763 (1.9409)  loss/pix_loss: 0.0088 (0.0113)  loss/enc_loss: 0.0037 (0.0062)  time: 4.1956  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [770/862]  eta: 0:06:25  lr: 0.000070  loss/low_gen_loss: 1.9988 (1.9990)  loss/high_gen_loss: 1.9756 (1.9414)  loss/pix_loss: 0.0084 (0.0113)  loss/enc_loss: 0.0038 (0.0062)  time: 4.1932  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [780/862]  eta: 0:05:43  lr: 0.000070  loss/low_gen_loss: 1.9988 (1.9990)  loss/high_gen_loss: 1.9715 (1.9415)  loss/pix_loss: 0.0082 (0.0113)  loss/enc_loss: 0.0037 (0.0061)  time: 4.1918  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [790/862]  eta: 0:05:01  lr: 0.000070  loss/low_gen_loss: 1.9988 (1.9990)  loss/high_gen_loss: 1.9516 (1.9417)  loss/pix_loss: 0.0103 (0.0113)  loss/enc_loss: 0.0037 (0.0061)  time: 4.1917  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [800/862]  eta: 0:04:20  lr: 0.000070  loss/low_gen_loss: 1.9989 (1.9990)  loss/high_gen_loss: 1.9316 (1.9412)  loss/pix_loss: 0.0121 (0.0113)  loss/enc_loss: 0.0037 (0.0061)  time: 4.1924  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [810/862]  eta: 0:03:38  lr: 0.000070  loss/low_gen_loss: 1.9989 (1.9990)  loss/high_gen_loss: 1.7388 (1.9347)  loss/pix_loss: 0.0120 (0.0113)  loss/enc_loss: 0.0039 (0.0060)  time: 4.1924  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [820/862]  eta: 0:02:56  lr: 0.000070  loss/low_gen_loss: 1.9989 (1.9990)  loss/high_gen_loss: 1.7305 (1.9328)  loss/pix_loss: 0.0098 (0.0113)  loss/enc_loss: 0.0041 (0.0060)  time: 4.1917  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [830/862]  eta: 0:02:14  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.8105 (1.9322)  loss/pix_loss: 0.0098 (0.0112)  loss/enc_loss: 0.0043 (0.0060)  time: 4.1917  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [840/862]  eta: 0:01:32  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9219 (1.9322)  loss/pix_loss: 0.0100 (0.0112)  loss/enc_loss: 0.0040 (0.0060)  time: 4.1918  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [850/862]  eta: 0:00:50  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9371 (1.9322)  loss/pix_loss: 0.0090 (0.0112)  loss/enc_loss: 0.0037 (0.0060)  time: 4.1917  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [860/862]  eta: 0:00:08  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9419 (1.9324)  loss/pix_loss: 0.0081 (0.0112)  loss/enc_loss: 0.0037 (0.0059)  time: 4.1914  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8]  [861/862]  eta: 0:00:04  lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9428 (1.9324)  loss/pix_loss: 0.0081 (0.0112)  loss/enc_loss: 0.0037 (0.0059)  time: 4.1913  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:8] Total time: 1:00:15 (4.1944 s / it)\n",
      "Averaged stats: lr: 0.000070  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9428 (1.9324)  loss/pix_loss: 0.0081 (0.0112)  loss/enc_loss: 0.0037 (0.0059)\n",
      "Valid: [epoch:8]  [ 0/14]  eta: 0:00:41  L1_loss: 0.0074 (0.0074)  time: 2.9575  data: 0.3597  max mem: 31350\n",
      "Valid: [epoch:8]  [13/14]  eta: 0:00:02  L1_loss: 0.0075 (0.0077)  time: 2.6034  data: 0.0258  max mem: 31350\n",
      "Valid: [epoch:8] Total time: 0:00:36 (2.6113 s / it)\n",
      "Averaged stats: L1_loss: 0.0075 (0.0077)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_8_input_n_20.png\n",
      "Train: [epoch:9]  [  0/862]  eta: 1:16:44  lr: 0.000080  loss/low_gen_loss: 1.9989 (1.9989)  loss/high_gen_loss: 1.9576 (1.9576)  loss/pix_loss: 0.0079 (0.0079)  loss/enc_loss: 0.0039 (0.0039)  time: 5.3416  data: 1.0566  max mem: 31350\n",
      "Train: [epoch:9]  [ 10/862]  eta: 1:00:37  lr: 0.000080  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9506 (1.9507)  loss/pix_loss: 0.0084 (0.0084)  loss/enc_loss: 0.0037 (0.0038)  time: 4.2689  data: 0.0961  max mem: 31350\n",
      "Train: [epoch:9]  [ 20/862]  eta: 0:59:17  lr: 0.000080  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9481 (1.9488)  loss/pix_loss: 0.0083 (0.0083)  loss/enc_loss: 0.0037 (0.0038)  time: 4.1690  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [ 30/862]  eta: 0:58:24  lr: 0.000080  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9490 (1.9494)  loss/pix_loss: 0.0083 (0.0086)  loss/enc_loss: 0.0037 (0.0039)  time: 4.1813  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [ 40/862]  eta: 0:57:37  lr: 0.000080  loss/low_gen_loss: 1.9990 (1.9990)  loss/high_gen_loss: 1.9511 (1.9498)  loss/pix_loss: 0.0094 (0.0088)  loss/enc_loss: 0.0037 (0.0039)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [ 50/862]  eta: 0:56:53  lr: 0.000080  loss/low_gen_loss: 1.9990 (1.9988)  loss/high_gen_loss: 1.9487 (1.9476)  loss/pix_loss: 0.0084 (0.0087)  loss/enc_loss: 0.0036 (0.0038)  time: 4.1921  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [ 60/862]  eta: 0:56:10  lr: 0.000080  loss/low_gen_loss: 1.9989 (1.9988)  loss/high_gen_loss: 1.9363 (1.9457)  loss/pix_loss: 0.0082 (0.0086)  loss/enc_loss: 0.0037 (0.0038)  time: 4.1926  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [ 70/862]  eta: 0:55:26  lr: 0.000080  loss/low_gen_loss: 1.9990 (1.9988)  loss/high_gen_loss: 1.9368 (1.9445)  loss/pix_loss: 0.0080 (0.0085)  loss/enc_loss: 0.0038 (0.0038)  time: 4.1910  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [ 80/862]  eta: 0:54:43  lr: 0.000080  loss/low_gen_loss: 1.9980 (1.9986)  loss/high_gen_loss: 1.9379 (1.9437)  loss/pix_loss: 0.0080 (0.0084)  loss/enc_loss: 0.0036 (0.0038)  time: 4.1901  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [ 90/862]  eta: 0:54:01  lr: 0.000080  loss/low_gen_loss: 1.9978 (1.9986)  loss/high_gen_loss: 1.9402 (1.9436)  loss/pix_loss: 0.0084 (0.0086)  loss/enc_loss: 0.0039 (0.0038)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [100/862]  eta: 0:53:18  lr: 0.000080  loss/low_gen_loss: 1.9979 (1.9985)  loss/high_gen_loss: 1.9417 (1.9435)  loss/pix_loss: 0.0127 (0.0093)  loss/enc_loss: 0.0039 (0.0038)  time: 4.1905  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [110/862]  eta: 0:52:36  lr: 0.000080  loss/low_gen_loss: 1.9979 (1.9984)  loss/high_gen_loss: 1.9437 (1.9437)  loss/pix_loss: 0.0145 (0.0097)  loss/enc_loss: 0.0036 (0.0038)  time: 4.1904  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [120/862]  eta: 0:51:53  lr: 0.000080  loss/low_gen_loss: 1.9980 (1.9984)  loss/high_gen_loss: 1.9459 (1.9442)  loss/pix_loss: 0.0121 (0.0098)  loss/enc_loss: 0.0035 (0.0038)  time: 4.1905  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [130/862]  eta: 0:51:11  lr: 0.000080  loss/low_gen_loss: 1.9980 (1.9984)  loss/high_gen_loss: 1.9530 (1.9450)  loss/pix_loss: 0.0115 (0.0098)  loss/enc_loss: 0.0034 (0.0038)  time: 4.1909  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [140/862]  eta: 0:50:29  lr: 0.000080  loss/low_gen_loss: 1.9981 (1.9984)  loss/high_gen_loss: 1.9548 (1.9457)  loss/pix_loss: 0.0116 (0.0101)  loss/enc_loss: 0.0036 (0.0038)  time: 4.1910  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [150/862]  eta: 0:49:46  lr: 0.000080  loss/low_gen_loss: 1.9981 (1.9983)  loss/high_gen_loss: 1.9558 (1.9464)  loss/pix_loss: 0.0137 (0.0103)  loss/enc_loss: 0.0037 (0.0038)  time: 4.1896  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [160/862]  eta: 0:49:04  lr: 0.000080  loss/low_gen_loss: 1.9982 (1.9983)  loss/high_gen_loss: 1.9571 (1.9472)  loss/pix_loss: 0.0138 (0.0105)  loss/enc_loss: 0.0037 (0.0038)  time: 4.1904  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [170/862]  eta: 0:48:22  lr: 0.000080  loss/low_gen_loss: 1.9981 (1.9983)  loss/high_gen_loss: 1.9580 (1.9478)  loss/pix_loss: 0.0138 (0.0107)  loss/enc_loss: 0.0035 (0.0038)  time: 4.1928  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [180/862]  eta: 0:47:40  lr: 0.000080  loss/low_gen_loss: 1.9982 (1.9983)  loss/high_gen_loss: 1.9545 (1.9481)  loss/pix_loss: 0.0139 (0.0109)  loss/enc_loss: 0.0034 (0.0037)  time: 4.1923  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [190/862]  eta: 0:46:58  lr: 0.000080  loss/low_gen_loss: 1.9982 (1.9983)  loss/high_gen_loss: 1.9524 (1.9482)  loss/pix_loss: 0.0139 (0.0111)  loss/enc_loss: 0.0032 (0.0037)  time: 4.1898  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [200/862]  eta: 0:46:16  lr: 0.000080  loss/low_gen_loss: 1.9982 (1.9983)  loss/high_gen_loss: 1.9529 (1.9485)  loss/pix_loss: 0.0128 (0.0112)  loss/enc_loss: 0.0033 (0.0037)  time: 4.1894  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [210/862]  eta: 0:45:34  lr: 0.000080  loss/low_gen_loss: 1.9982 (1.9983)  loss/high_gen_loss: 1.9526 (1.9487)  loss/pix_loss: 0.0124 (0.0112)  loss/enc_loss: 0.0034 (0.0037)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [220/862]  eta: 0:44:52  lr: 0.000080  loss/low_gen_loss: 1.9982 (1.9983)  loss/high_gen_loss: 1.9525 (1.9490)  loss/pix_loss: 0.0102 (0.0111)  loss/enc_loss: 0.0035 (0.0037)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [230/862]  eta: 0:44:10  lr: 0.000080  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9550 (1.9493)  loss/pix_loss: 0.0097 (0.0110)  loss/enc_loss: 0.0033 (0.0037)  time: 4.1898  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [240/862]  eta: 0:43:28  lr: 0.000080  loss/low_gen_loss: 1.9984 (1.9983)  loss/high_gen_loss: 1.9539 (1.9493)  loss/pix_loss: 0.0090 (0.0109)  loss/enc_loss: 0.0032 (0.0037)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [250/862]  eta: 0:42:46  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9983)  loss/high_gen_loss: 1.9483 (1.9493)  loss/pix_loss: 0.0080 (0.0108)  loss/enc_loss: 0.0032 (0.0037)  time: 4.1900  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [260/862]  eta: 0:42:04  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9983)  loss/high_gen_loss: 1.9483 (1.9492)  loss/pix_loss: 0.0082 (0.0108)  loss/enc_loss: 0.0034 (0.0036)  time: 4.1926  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [270/862]  eta: 0:41:22  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9983)  loss/high_gen_loss: 1.9433 (1.9489)  loss/pix_loss: 0.0093 (0.0107)  loss/enc_loss: 0.0034 (0.0036)  time: 4.1925  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [280/862]  eta: 0:40:40  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9983)  loss/high_gen_loss: 1.9407 (1.9486)  loss/pix_loss: 0.0093 (0.0107)  loss/enc_loss: 0.0034 (0.0036)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [290/862]  eta: 0:39:58  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9983)  loss/high_gen_loss: 1.9409 (1.9483)  loss/pix_loss: 0.0094 (0.0106)  loss/enc_loss: 0.0035 (0.0036)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [300/862]  eta: 0:39:16  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9983)  loss/high_gen_loss: 1.9410 (1.9481)  loss/pix_loss: 0.0100 (0.0106)  loss/enc_loss: 0.0033 (0.0036)  time: 4.1909  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [310/862]  eta: 0:38:34  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9984)  loss/high_gen_loss: 1.9446 (1.9481)  loss/pix_loss: 0.0100 (0.0106)  loss/enc_loss: 0.0034 (0.0036)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [320/862]  eta: 0:37:52  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9984)  loss/high_gen_loss: 1.9585 (1.9487)  loss/pix_loss: 0.0092 (0.0105)  loss/enc_loss: 0.0036 (0.0036)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [330/862]  eta: 0:37:10  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9984)  loss/high_gen_loss: 1.9698 (1.9495)  loss/pix_loss: 0.0085 (0.0105)  loss/enc_loss: 0.0035 (0.0036)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [340/862]  eta: 0:36:28  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9984)  loss/high_gen_loss: 1.9774 (1.9503)  loss/pix_loss: 0.0088 (0.0105)  loss/enc_loss: 0.0035 (0.0036)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [350/862]  eta: 0:35:46  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9984)  loss/high_gen_loss: 1.9802 (1.9513)  loss/pix_loss: 0.0090 (0.0105)  loss/enc_loss: 0.0033 (0.0036)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [360/862]  eta: 0:35:04  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9984)  loss/high_gen_loss: 1.9876 (1.9523)  loss/pix_loss: 0.0085 (0.0104)  loss/enc_loss: 0.0033 (0.0036)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [370/862]  eta: 0:34:22  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9984)  loss/high_gen_loss: 1.9890 (1.9533)  loss/pix_loss: 0.0093 (0.0104)  loss/enc_loss: 0.0031 (0.0036)  time: 4.1906  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [380/862]  eta: 0:33:40  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9984)  loss/high_gen_loss: 1.9884 (1.9542)  loss/pix_loss: 0.0092 (0.0104)  loss/enc_loss: 0.0030 (0.0036)  time: 4.1909  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [390/862]  eta: 0:32:58  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9984)  loss/high_gen_loss: 1.9883 (1.9551)  loss/pix_loss: 0.0087 (0.0103)  loss/enc_loss: 0.0030 (0.0036)  time: 4.1912  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [400/862]  eta: 0:32:16  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9984)  loss/high_gen_loss: 1.9871 (1.9558)  loss/pix_loss: 0.0074 (0.0102)  loss/enc_loss: 0.0030 (0.0035)  time: 4.1987  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [410/862]  eta: 0:31:35  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9984)  loss/high_gen_loss: 1.9811 (1.9564)  loss/pix_loss: 0.0069 (0.0102)  loss/enc_loss: 0.0029 (0.0035)  time: 4.2074  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [420/862]  eta: 0:30:53  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9984)  loss/high_gen_loss: 1.9820 (1.9571)  loss/pix_loss: 0.0075 (0.0102)  loss/enc_loss: 0.0031 (0.0035)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [430/862]  eta: 0:30:11  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9984)  loss/high_gen_loss: 1.9868 (1.9578)  loss/pix_loss: 0.0083 (0.0101)  loss/enc_loss: 0.0031 (0.0035)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [440/862]  eta: 0:29:29  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9984)  loss/high_gen_loss: 1.9864 (1.9583)  loss/pix_loss: 0.0082 (0.0101)  loss/enc_loss: 0.0035 (0.0035)  time: 4.2114  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [450/862]  eta: 0:28:48  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9984)  loss/high_gen_loss: 1.9766 (1.9587)  loss/pix_loss: 0.0099 (0.0101)  loss/enc_loss: 0.0035 (0.0035)  time: 4.2107  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [460/862]  eta: 0:28:06  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9984)  loss/high_gen_loss: 1.9725 (1.9589)  loss/pix_loss: 0.0094 (0.0101)  loss/enc_loss: 0.0032 (0.0035)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [470/862]  eta: 0:27:24  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9984)  loss/high_gen_loss: 1.9727 (1.9593)  loss/pix_loss: 0.0089 (0.0100)  loss/enc_loss: 0.0032 (0.0035)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [480/862]  eta: 0:26:42  lr: 0.000080  loss/low_gen_loss: 1.9989 (1.9984)  loss/high_gen_loss: 1.9799 (1.9598)  loss/pix_loss: 0.0087 (0.0100)  loss/enc_loss: 0.0032 (0.0035)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [490/862]  eta: 0:26:00  lr: 0.000080  loss/low_gen_loss: 1.9989 (1.9985)  loss/high_gen_loss: 1.9806 (1.9602)  loss/pix_loss: 0.0108 (0.0100)  loss/enc_loss: 0.0033 (0.0035)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [500/862]  eta: 0:25:18  lr: 0.000080  loss/low_gen_loss: 1.9988 (1.9985)  loss/high_gen_loss: 1.9787 (1.9605)  loss/pix_loss: 0.0086 (0.0100)  loss/enc_loss: 0.0032 (0.0035)  time: 4.2095  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [510/862]  eta: 0:24:37  lr: 0.000080  loss/low_gen_loss: 1.9988 (1.9985)  loss/high_gen_loss: 1.9742 (1.9608)  loss/pix_loss: 0.0086 (0.0100)  loss/enc_loss: 0.0028 (0.0035)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [520/862]  eta: 0:23:55  lr: 0.000080  loss/low_gen_loss: 1.9988 (1.9985)  loss/high_gen_loss: 1.9725 (1.9610)  loss/pix_loss: 0.0093 (0.0100)  loss/enc_loss: 0.0028 (0.0035)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [530/862]  eta: 0:23:13  lr: 0.000080  loss/low_gen_loss: 1.9988 (1.9985)  loss/high_gen_loss: 1.9723 (1.9612)  loss/pix_loss: 0.0091 (0.0100)  loss/enc_loss: 0.0033 (0.0035)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [540/862]  eta: 0:22:31  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9736 (1.9614)  loss/pix_loss: 0.0092 (0.0100)  loss/enc_loss: 0.0033 (0.0035)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [550/862]  eta: 0:21:49  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9736 (1.9617)  loss/pix_loss: 0.0096 (0.0100)  loss/enc_loss: 0.0028 (0.0035)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [560/862]  eta: 0:21:07  lr: 0.000080  loss/low_gen_loss: 1.9988 (1.9985)  loss/high_gen_loss: 1.9728 (1.9618)  loss/pix_loss: 0.0111 (0.0101)  loss/enc_loss: 0.0028 (0.0035)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [570/862]  eta: 0:20:25  lr: 0.000080  loss/low_gen_loss: 1.9988 (1.9985)  loss/high_gen_loss: 1.9707 (1.9620)  loss/pix_loss: 0.0111 (0.0101)  loss/enc_loss: 0.0029 (0.0035)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [580/862]  eta: 0:19:43  lr: 0.000080  loss/low_gen_loss: 1.9988 (1.9985)  loss/high_gen_loss: 1.9694 (1.9621)  loss/pix_loss: 0.0106 (0.0101)  loss/enc_loss: 0.0031 (0.0035)  time: 4.2094  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [590/862]  eta: 0:19:01  lr: 0.000080  loss/low_gen_loss: 1.9988 (1.9985)  loss/high_gen_loss: 1.9707 (1.9623)  loss/pix_loss: 0.0098 (0.0101)  loss/enc_loss: 0.0031 (0.0035)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [600/862]  eta: 0:18:19  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9742 (1.9625)  loss/pix_loss: 0.0093 (0.0100)  loss/enc_loss: 0.0028 (0.0034)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [610/862]  eta: 0:17:37  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9757 (1.9627)  loss/pix_loss: 0.0085 (0.0100)  loss/enc_loss: 0.0028 (0.0034)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [620/862]  eta: 0:16:56  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9764 (1.9630)  loss/pix_loss: 0.0078 (0.0100)  loss/enc_loss: 0.0029 (0.0034)  time: 4.2088  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [630/862]  eta: 0:16:14  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9778 (1.9632)  loss/pix_loss: 0.0071 (0.0099)  loss/enc_loss: 0.0029 (0.0034)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [640/862]  eta: 0:15:32  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9806 (1.9635)  loss/pix_loss: 0.0068 (0.0099)  loss/enc_loss: 0.0030 (0.0034)  time: 4.2113  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [650/862]  eta: 0:14:50  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9815 (1.9638)  loss/pix_loss: 0.0069 (0.0098)  loss/enc_loss: 0.0028 (0.0034)  time: 4.2116  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [660/862]  eta: 0:14:08  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9816 (1.9640)  loss/pix_loss: 0.0068 (0.0098)  loss/enc_loss: 0.0028 (0.0034)  time: 4.2100  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [670/862]  eta: 0:13:26  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9821 (1.9643)  loss/pix_loss: 0.0067 (0.0098)  loss/enc_loss: 0.0029 (0.0034)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [680/862]  eta: 0:12:44  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9985)  loss/high_gen_loss: 1.9821 (1.9646)  loss/pix_loss: 0.0069 (0.0097)  loss/enc_loss: 0.0026 (0.0034)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [690/862]  eta: 0:12:02  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9985)  loss/high_gen_loss: 1.9815 (1.9648)  loss/pix_loss: 0.0071 (0.0097)  loss/enc_loss: 0.0025 (0.0034)  time: 4.2115  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [700/862]  eta: 0:11:20  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9985)  loss/high_gen_loss: 1.9798 (1.9650)  loss/pix_loss: 0.0071 (0.0096)  loss/enc_loss: 0.0027 (0.0034)  time: 4.2113  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [710/862]  eta: 0:10:38  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9985)  loss/high_gen_loss: 1.9784 (1.9651)  loss/pix_loss: 0.0070 (0.0096)  loss/enc_loss: 0.0027 (0.0034)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [720/862]  eta: 0:09:56  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9985)  loss/high_gen_loss: 1.9785 (1.9654)  loss/pix_loss: 0.0067 (0.0096)  loss/enc_loss: 0.0027 (0.0033)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [730/862]  eta: 0:09:14  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9985)  loss/high_gen_loss: 1.9804 (1.9656)  loss/pix_loss: 0.0069 (0.0095)  loss/enc_loss: 0.0028 (0.0033)  time: 4.2108  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [740/862]  eta: 0:08:32  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9985)  loss/high_gen_loss: 1.9783 (1.9657)  loss/pix_loss: 0.0071 (0.0095)  loss/enc_loss: 0.0028 (0.0033)  time: 4.2110  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [750/862]  eta: 0:07:50  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9771 (1.9659)  loss/pix_loss: 0.0069 (0.0095)  loss/enc_loss: 0.0027 (0.0033)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [760/862]  eta: 0:07:08  lr: 0.000080  loss/low_gen_loss: 1.9987 (1.9985)  loss/high_gen_loss: 1.9781 (1.9660)  loss/pix_loss: 0.0080 (0.0095)  loss/enc_loss: 0.0029 (0.0033)  time: 4.2092  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [770/862]  eta: 0:06:26  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9985)  loss/high_gen_loss: 1.9792 (1.9662)  loss/pix_loss: 0.0131 (0.0096)  loss/enc_loss: 0.0029 (0.0033)  time: 4.2096  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [780/862]  eta: 0:05:44  lr: 0.000080  loss/low_gen_loss: 1.9986 (1.9985)  loss/high_gen_loss: 1.9809 (1.9664)  loss/pix_loss: 0.0158 (0.0096)  loss/enc_loss: 0.0029 (0.0033)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [790/862]  eta: 0:05:02  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9985)  loss/high_gen_loss: 1.9816 (1.9666)  loss/pix_loss: 0.0127 (0.0097)  loss/enc_loss: 0.0028 (0.0033)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [800/862]  eta: 0:04:20  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9985)  loss/high_gen_loss: 1.9819 (1.9668)  loss/pix_loss: 0.0123 (0.0097)  loss/enc_loss: 0.0027 (0.0033)  time: 4.2087  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [810/862]  eta: 0:03:38  lr: 0.000080  loss/low_gen_loss: 1.9985 (1.9985)  loss/high_gen_loss: 1.9812 (1.9670)  loss/pix_loss: 0.0137 (0.0097)  loss/enc_loss: 0.0025 (0.0033)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [820/862]  eta: 0:02:56  lr: 0.000080  loss/low_gen_loss: 1.9984 (1.9985)  loss/high_gen_loss: 1.9785 (1.9671)  loss/pix_loss: 0.0109 (0.0098)  loss/enc_loss: 0.0024 (0.0033)  time: 4.2104  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [830/862]  eta: 0:02:14  lr: 0.000080  loss/low_gen_loss: 1.9984 (1.9985)  loss/high_gen_loss: 1.9772 (1.9672)  loss/pix_loss: 0.0093 (0.0097)  loss/enc_loss: 0.0025 (0.0033)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [840/862]  eta: 0:01:32  lr: 0.000080  loss/low_gen_loss: 1.9983 (1.9985)  loss/high_gen_loss: 1.9769 (1.9673)  loss/pix_loss: 0.0079 (0.0097)  loss/enc_loss: 0.0025 (0.0033)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [850/862]  eta: 0:00:50  lr: 0.000080  loss/low_gen_loss: 1.9983 (1.9985)  loss/high_gen_loss: 1.9760 (1.9674)  loss/pix_loss: 0.0080 (0.0097)  loss/enc_loss: 0.0026 (0.0033)  time: 4.2091  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [860/862]  eta: 0:00:08  lr: 0.000080  loss/low_gen_loss: 1.9983 (1.9985)  loss/high_gen_loss: 1.9748 (1.9675)  loss/pix_loss: 0.0089 (0.0097)  loss/enc_loss: 0.0026 (0.0033)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9]  [861/862]  eta: 0:00:04  lr: 0.000080  loss/low_gen_loss: 1.9983 (1.9985)  loss/high_gen_loss: 1.9745 (1.9675)  loss/pix_loss: 0.0089 (0.0097)  loss/enc_loss: 0.0026 (0.0033)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:9] Total time: 1:00:22 (4.2020 s / it)\n",
      "Averaged stats: lr: 0.000080  loss/low_gen_loss: 1.9983 (1.9985)  loss/high_gen_loss: 1.9745 (1.9675)  loss/pix_loss: 0.0089 (0.0097)  loss/enc_loss: 0.0026 (0.0033)\n",
      "Valid: [epoch:9]  [ 0/14]  eta: 0:00:42  L1_loss: 0.0073 (0.0073)  time: 3.0244  data: 0.3886  max mem: 31350\n",
      "Valid: [epoch:9]  [13/14]  eta: 0:00:02  L1_loss: 0.0066 (0.0069)  time: 2.6418  data: 0.0278  max mem: 31350\n",
      "Valid: [epoch:9] Total time: 0:00:37 (2.6515 s / it)\n",
      "Averaged stats: L1_loss: 0.0066 (0.0069)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_9_input_n_20.png\n",
      "Train: [epoch:10]  [  0/862]  eta: 1:20:07  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9729 (1.9729)  loss/pix_loss: 0.0082 (0.0082)  loss/enc_loss: 0.0029 (0.0029)  time: 5.5766  data: 1.3700  max mem: 31350\n",
      "Train: [epoch:10]  [ 10/862]  eta: 1:01:18  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9735 (1.9730)  loss/pix_loss: 0.0136 (0.0133)  loss/enc_loss: 0.0028 (0.0028)  time: 4.3176  data: 0.1246  max mem: 31350\n",
      "Train: [epoch:10]  [ 20/862]  eta: 0:59:45  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9736 (1.9732)  loss/pix_loss: 0.0136 (0.0137)  loss/enc_loss: 0.0028 (0.0029)  time: 4.1921  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [ 30/862]  eta: 0:58:45  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9711 (1.9717)  loss/pix_loss: 0.0156 (0.0154)  loss/enc_loss: 0.0028 (0.0029)  time: 4.1941  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [ 40/862]  eta: 0:57:54  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9697 (1.9712)  loss/pix_loss: 0.0126 (0.0142)  loss/enc_loss: 0.0029 (0.0029)  time: 4.1934  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [ 50/862]  eta: 0:57:06  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9699 (1.9707)  loss/pix_loss: 0.0118 (0.0139)  loss/enc_loss: 0.0030 (0.0030)  time: 4.1912  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [ 60/862]  eta: 0:56:20  lr: 0.000090  loss/low_gen_loss: 1.9984 (1.9983)  loss/high_gen_loss: 1.9706 (1.9708)  loss/pix_loss: 0.0121 (0.0135)  loss/enc_loss: 0.0030 (0.0029)  time: 4.1914  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [ 70/862]  eta: 0:55:35  lr: 0.000090  loss/low_gen_loss: 1.9984 (1.9984)  loss/high_gen_loss: 1.9706 (1.9709)  loss/pix_loss: 0.0121 (0.0133)  loss/enc_loss: 0.0028 (0.0029)  time: 4.1919  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [ 80/862]  eta: 0:54:51  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9798 (1.9733)  loss/pix_loss: 0.0128 (0.0131)  loss/enc_loss: 0.0030 (0.0030)  time: 4.1927  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [ 90/862]  eta: 0:54:08  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9880 (1.9748)  loss/pix_loss: 0.0123 (0.0129)  loss/enc_loss: 0.0030 (0.0030)  time: 4.1935  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [100/862]  eta: 0:53:25  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9862 (1.9759)  loss/pix_loss: 0.0124 (0.0129)  loss/enc_loss: 0.0030 (0.0030)  time: 4.1924  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [110/862]  eta: 0:52:42  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9825 (1.9764)  loss/pix_loss: 0.0135 (0.0130)  loss/enc_loss: 0.0030 (0.0030)  time: 4.1918  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [120/862]  eta: 0:51:59  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9820 (1.9769)  loss/pix_loss: 0.0112 (0.0129)  loss/enc_loss: 0.0029 (0.0030)  time: 4.1935  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [130/862]  eta: 0:51:17  lr: 0.000090  loss/low_gen_loss: 1.9982 (1.9983)  loss/high_gen_loss: 1.9829 (1.9774)  loss/pix_loss: 0.0097 (0.0126)  loss/enc_loss: 0.0029 (0.0030)  time: 4.1970  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [140/862]  eta: 0:50:34  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9818 (1.9776)  loss/pix_loss: 0.0084 (0.0122)  loss/enc_loss: 0.0029 (0.0030)  time: 4.1961  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [150/862]  eta: 0:49:51  lr: 0.000090  loss/low_gen_loss: 1.9985 (1.9983)  loss/high_gen_loss: 1.9788 (1.9775)  loss/pix_loss: 0.0076 (0.0119)  loss/enc_loss: 0.0029 (0.0030)  time: 4.1925  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [160/862]  eta: 0:49:09  lr: 0.000090  loss/low_gen_loss: 1.9984 (1.9983)  loss/high_gen_loss: 1.9741 (1.9771)  loss/pix_loss: 0.0079 (0.0117)  loss/enc_loss: 0.0030 (0.0030)  time: 4.1928  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [170/862]  eta: 0:48:27  lr: 0.000090  loss/low_gen_loss: 1.9983 (1.9983)  loss/high_gen_loss: 1.9680 (1.9764)  loss/pix_loss: 0.0079 (0.0115)  loss/enc_loss: 0.0028 (0.0030)  time: 4.1925  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [180/862]  eta: 0:47:44  lr: 0.000090  loss/low_gen_loss: 1.9975 (1.9982)  loss/high_gen_loss: 1.9564 (1.9746)  loss/pix_loss: 0.0091 (0.0114)  loss/enc_loss: 0.0027 (0.0030)  time: 4.1923  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [190/862]  eta: 0:47:02  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9982)  loss/high_gen_loss: 1.8904 (1.9672)  loss/pix_loss: 0.0101 (0.0115)  loss/enc_loss: 0.0030 (0.0030)  time: 4.1925  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [200/862]  eta: 0:46:20  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9982)  loss/high_gen_loss: 1.8835 (1.9661)  loss/pix_loss: 0.0165 (0.0119)  loss/enc_loss: 0.0033 (0.0030)  time: 4.1926  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [210/862]  eta: 0:45:37  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9982)  loss/high_gen_loss: 1.9748 (1.9667)  loss/pix_loss: 0.0171 (0.0120)  loss/enc_loss: 0.0035 (0.0030)  time: 4.1911  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [220/862]  eta: 0:44:55  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9982)  loss/high_gen_loss: 1.9576 (1.9654)  loss/pix_loss: 0.0146 (0.0122)  loss/enc_loss: 0.0033 (0.0030)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [230/862]  eta: 0:44:13  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9981)  loss/high_gen_loss: 1.9540 (1.9654)  loss/pix_loss: 0.0121 (0.0121)  loss/enc_loss: 0.0030 (0.0030)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [240/862]  eta: 0:43:31  lr: 0.000090  loss/low_gen_loss: 1.9975 (1.9981)  loss/high_gen_loss: 1.9697 (1.9656)  loss/pix_loss: 0.0119 (0.0121)  loss/enc_loss: 0.0028 (0.0030)  time: 4.1920  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [250/862]  eta: 0:42:49  lr: 0.000090  loss/low_gen_loss: 1.9972 (1.9981)  loss/high_gen_loss: 1.9763 (1.9662)  loss/pix_loss: 0.0138 (0.0122)  loss/enc_loss: 0.0028 (0.0030)  time: 4.2010  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [260/862]  eta: 0:42:07  lr: 0.000090  loss/low_gen_loss: 1.9972 (1.9980)  loss/high_gen_loss: 1.9778 (1.9666)  loss/pix_loss: 0.0141 (0.0122)  loss/enc_loss: 0.0028 (0.0030)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [270/862]  eta: 0:41:25  lr: 0.000090  loss/low_gen_loss: 1.9973 (1.9980)  loss/high_gen_loss: 1.9772 (1.9670)  loss/pix_loss: 0.0141 (0.0124)  loss/enc_loss: 0.0026 (0.0030)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [280/862]  eta: 0:40:44  lr: 0.000090  loss/low_gen_loss: 1.9976 (1.9980)  loss/high_gen_loss: 1.9784 (1.9674)  loss/pix_loss: 0.0162 (0.0126)  loss/enc_loss: 0.0026 (0.0030)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [290/862]  eta: 0:40:02  lr: 0.000090  loss/low_gen_loss: 1.9976 (1.9980)  loss/high_gen_loss: 1.9780 (1.9677)  loss/pix_loss: 0.0184 (0.0128)  loss/enc_loss: 0.0025 (0.0030)  time: 4.2081  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [300/862]  eta: 0:39:20  lr: 0.000090  loss/low_gen_loss: 1.9976 (1.9980)  loss/high_gen_loss: 1.9761 (1.9680)  loss/pix_loss: 0.0185 (0.0129)  loss/enc_loss: 0.0025 (0.0029)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [310/862]  eta: 0:38:38  lr: 0.000090  loss/low_gen_loss: 1.9975 (1.9980)  loss/high_gen_loss: 1.9764 (1.9683)  loss/pix_loss: 0.0169 (0.0130)  loss/enc_loss: 0.0026 (0.0029)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [320/862]  eta: 0:37:56  lr: 0.000090  loss/low_gen_loss: 1.9974 (1.9979)  loss/high_gen_loss: 1.9790 (1.9687)  loss/pix_loss: 0.0108 (0.0129)  loss/enc_loss: 0.0025 (0.0029)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [330/862]  eta: 0:37:14  lr: 0.000090  loss/low_gen_loss: 1.9973 (1.9979)  loss/high_gen_loss: 1.9810 (1.9691)  loss/pix_loss: 0.0074 (0.0127)  loss/enc_loss: 0.0026 (0.0029)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [340/862]  eta: 0:36:32  lr: 0.000090  loss/low_gen_loss: 1.9972 (1.9979)  loss/high_gen_loss: 1.9819 (1.9695)  loss/pix_loss: 0.0066 (0.0125)  loss/enc_loss: 0.0026 (0.0029)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [350/862]  eta: 0:35:51  lr: 0.000090  loss/low_gen_loss: 1.9973 (1.9979)  loss/high_gen_loss: 1.9827 (1.9698)  loss/pix_loss: 0.0059 (0.0124)  loss/enc_loss: 0.0026 (0.0029)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [360/862]  eta: 0:35:09  lr: 0.000090  loss/low_gen_loss: 1.9974 (1.9979)  loss/high_gen_loss: 1.9831 (1.9702)  loss/pix_loss: 0.0064 (0.0122)  loss/enc_loss: 0.0026 (0.0029)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [370/862]  eta: 0:34:27  lr: 0.000090  loss/low_gen_loss: 1.9976 (1.9979)  loss/high_gen_loss: 1.9840 (1.9706)  loss/pix_loss: 0.0061 (0.0120)  loss/enc_loss: 0.0026 (0.0029)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [380/862]  eta: 0:33:45  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9979)  loss/high_gen_loss: 1.9846 (1.9710)  loss/pix_loss: 0.0059 (0.0119)  loss/enc_loss: 0.0024 (0.0029)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [390/862]  eta: 0:33:03  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9979)  loss/high_gen_loss: 1.9859 (1.9714)  loss/pix_loss: 0.0059 (0.0117)  loss/enc_loss: 0.0025 (0.0029)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [400/862]  eta: 0:32:21  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9979)  loss/high_gen_loss: 1.9869 (1.9718)  loss/pix_loss: 0.0058 (0.0116)  loss/enc_loss: 0.0027 (0.0029)  time: 4.2086  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [410/862]  eta: 0:31:39  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9979)  loss/high_gen_loss: 1.9863 (1.9721)  loss/pix_loss: 0.0057 (0.0114)  loss/enc_loss: 0.0027 (0.0029)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [420/862]  eta: 0:30:57  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9979)  loss/high_gen_loss: 1.9821 (1.9722)  loss/pix_loss: 0.0058 (0.0113)  loss/enc_loss: 0.0029 (0.0029)  time: 4.2083  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [430/862]  eta: 0:30:15  lr: 0.000090  loss/low_gen_loss: 1.9980 (1.9979)  loss/high_gen_loss: 1.9773 (1.9723)  loss/pix_loss: 0.0068 (0.0113)  loss/enc_loss: 0.0029 (0.0029)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [440/862]  eta: 0:29:33  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9779 (1.9725)  loss/pix_loss: 0.0080 (0.0112)  loss/enc_loss: 0.0027 (0.0029)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [450/862]  eta: 0:28:51  lr: 0.000090  loss/low_gen_loss: 1.9974 (1.9978)  loss/high_gen_loss: 1.9779 (1.9726)  loss/pix_loss: 0.0068 (0.0111)  loss/enc_loss: 0.0025 (0.0029)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [460/862]  eta: 0:28:09  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9785 (1.9727)  loss/pix_loss: 0.0088 (0.0111)  loss/enc_loss: 0.0023 (0.0028)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [470/862]  eta: 0:27:27  lr: 0.000090  loss/low_gen_loss: 1.9980 (1.9978)  loss/high_gen_loss: 1.9820 (1.9729)  loss/pix_loss: 0.0088 (0.0110)  loss/enc_loss: 0.0024 (0.0028)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [480/862]  eta: 0:26:45  lr: 0.000090  loss/low_gen_loss: 1.9980 (1.9978)  loss/high_gen_loss: 1.9833 (1.9732)  loss/pix_loss: 0.0080 (0.0110)  loss/enc_loss: 0.0024 (0.0028)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [490/862]  eta: 0:26:03  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9822 (1.9733)  loss/pix_loss: 0.0092 (0.0110)  loss/enc_loss: 0.0025 (0.0028)  time: 4.2065  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [500/862]  eta: 0:25:21  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9766 (1.9733)  loss/pix_loss: 0.0108 (0.0110)  loss/enc_loss: 0.0026 (0.0028)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [510/862]  eta: 0:24:39  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9711 (1.9732)  loss/pix_loss: 0.0083 (0.0109)  loss/enc_loss: 0.0025 (0.0028)  time: 4.2128  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [520/862]  eta: 0:23:57  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9746 (1.9732)  loss/pix_loss: 0.0066 (0.0108)  loss/enc_loss: 0.0025 (0.0028)  time: 4.2132  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [530/862]  eta: 0:23:15  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9759 (1.9733)  loss/pix_loss: 0.0061 (0.0107)  loss/enc_loss: 0.0027 (0.0028)  time: 4.2084  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [540/862]  eta: 0:22:33  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9760 (1.9733)  loss/pix_loss: 0.0062 (0.0107)  loss/enc_loss: 0.0025 (0.0028)  time: 4.2085  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [550/862]  eta: 0:21:51  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9978)  loss/high_gen_loss: 1.9764 (1.9733)  loss/pix_loss: 0.0062 (0.0106)  loss/enc_loss: 0.0023 (0.0028)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [560/862]  eta: 0:21:09  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9978)  loss/high_gen_loss: 1.9741 (1.9732)  loss/pix_loss: 0.0070 (0.0105)  loss/enc_loss: 0.0024 (0.0028)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [570/862]  eta: 0:20:27  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9978)  loss/high_gen_loss: 1.9759 (1.9732)  loss/pix_loss: 0.0070 (0.0105)  loss/enc_loss: 0.0025 (0.0028)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [580/862]  eta: 0:19:45  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9978)  loss/high_gen_loss: 1.9807 (1.9733)  loss/pix_loss: 0.0064 (0.0104)  loss/enc_loss: 0.0025 (0.0028)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [590/862]  eta: 0:19:03  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9748 (1.9731)  loss/pix_loss: 0.0068 (0.0103)  loss/enc_loss: 0.0025 (0.0028)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [600/862]  eta: 0:18:21  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9491 (1.9726)  loss/pix_loss: 0.0083 (0.0104)  loss/enc_loss: 0.0027 (0.0028)  time: 4.2074  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [610/862]  eta: 0:17:39  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9091 (1.9710)  loss/pix_loss: 0.0135 (0.0104)  loss/enc_loss: 0.0034 (0.0028)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [620/862]  eta: 0:16:57  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9978)  loss/high_gen_loss: 1.8847 (1.9700)  loss/pix_loss: 0.0143 (0.0105)  loss/enc_loss: 0.0034 (0.0028)  time: 4.2098  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [630/862]  eta: 0:16:15  lr: 0.000090  loss/low_gen_loss: 1.9976 (1.9978)  loss/high_gen_loss: 1.9642 (1.9701)  loss/pix_loss: 0.0147 (0.0106)  loss/enc_loss: 0.0030 (0.0028)  time: 4.2090  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [640/862]  eta: 0:15:33  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9873 (1.9704)  loss/pix_loss: 0.0116 (0.0106)  loss/enc_loss: 0.0025 (0.0028)  time: 4.2083  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:10]  [650/862]  eta: 0:14:51  lr: 0.000090  loss/low_gen_loss: 1.9981 (1.9978)  loss/high_gen_loss: 1.9876 (1.9706)  loss/pix_loss: 0.0091 (0.0105)  loss/enc_loss: 0.0025 (0.0028)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [660/862]  eta: 0:14:09  lr: 0.000090  loss/low_gen_loss: 1.9982 (1.9978)  loss/high_gen_loss: 1.9883 (1.9709)  loss/pix_loss: 0.0080 (0.0105)  loss/enc_loss: 0.0026 (0.0028)  time: 4.2075  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [670/862]  eta: 0:13:27  lr: 0.000090  loss/low_gen_loss: 1.9981 (1.9978)  loss/high_gen_loss: 1.9864 (1.9711)  loss/pix_loss: 0.0101 (0.0105)  loss/enc_loss: 0.0026 (0.0028)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [680/862]  eta: 0:12:45  lr: 0.000090  loss/low_gen_loss: 1.9981 (1.9978)  loss/high_gen_loss: 1.9833 (1.9712)  loss/pix_loss: 0.0082 (0.0105)  loss/enc_loss: 0.0024 (0.0028)  time: 4.2081  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [690/862]  eta: 0:12:03  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9823 (1.9714)  loss/pix_loss: 0.0082 (0.0105)  loss/enc_loss: 0.0023 (0.0028)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [700/862]  eta: 0:11:21  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9854 (1.9716)  loss/pix_loss: 0.0095 (0.0105)  loss/enc_loss: 0.0024 (0.0028)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [710/862]  eta: 0:10:39  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9876 (1.9719)  loss/pix_loss: 0.0093 (0.0105)  loss/enc_loss: 0.0024 (0.0028)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [720/862]  eta: 0:09:57  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9978)  loss/high_gen_loss: 1.9873 (1.9721)  loss/pix_loss: 0.0102 (0.0105)  loss/enc_loss: 0.0022 (0.0028)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [730/862]  eta: 0:09:15  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9978)  loss/high_gen_loss: 1.9866 (1.9723)  loss/pix_loss: 0.0094 (0.0105)  loss/enc_loss: 0.0022 (0.0028)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [740/862]  eta: 0:08:32  lr: 0.000090  loss/low_gen_loss: 1.9977 (1.9978)  loss/high_gen_loss: 1.9856 (1.9724)  loss/pix_loss: 0.0069 (0.0104)  loss/enc_loss: 0.0023 (0.0028)  time: 4.2082  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [750/862]  eta: 0:07:50  lr: 0.000090  loss/low_gen_loss: 1.9976 (1.9978)  loss/high_gen_loss: 1.9849 (1.9726)  loss/pix_loss: 0.0067 (0.0104)  loss/enc_loss: 0.0022 (0.0027)  time: 4.2077  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [760/862]  eta: 0:07:08  lr: 0.000090  loss/low_gen_loss: 1.9976 (1.9978)  loss/high_gen_loss: 1.9849 (1.9728)  loss/pix_loss: 0.0068 (0.0103)  loss/enc_loss: 0.0022 (0.0027)  time: 4.2074  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [770/862]  eta: 0:06:26  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9846 (1.9729)  loss/pix_loss: 0.0063 (0.0103)  loss/enc_loss: 0.0022 (0.0027)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [780/862]  eta: 0:05:44  lr: 0.000090  loss/low_gen_loss: 1.9980 (1.9978)  loss/high_gen_loss: 1.9845 (1.9731)  loss/pix_loss: 0.0057 (0.0102)  loss/enc_loss: 0.0022 (0.0027)  time: 4.2058  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [790/862]  eta: 0:05:02  lr: 0.000090  loss/low_gen_loss: 1.9980 (1.9978)  loss/high_gen_loss: 1.9845 (1.9732)  loss/pix_loss: 0.0057 (0.0101)  loss/enc_loss: 0.0021 (0.0027)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [800/862]  eta: 0:04:20  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9847 (1.9734)  loss/pix_loss: 0.0058 (0.0101)  loss/enc_loss: 0.0023 (0.0027)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [810/862]  eta: 0:03:38  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9847 (1.9735)  loss/pix_loss: 0.0057 (0.0100)  loss/enc_loss: 0.0024 (0.0027)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [820/862]  eta: 0:02:56  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9824 (1.9735)  loss/pix_loss: 0.0055 (0.0100)  loss/enc_loss: 0.0025 (0.0027)  time: 4.2072  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [830/862]  eta: 0:02:14  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9576 (1.9732)  loss/pix_loss: 0.0056 (0.0099)  loss/enc_loss: 0.0025 (0.0027)  time: 4.2067  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [840/862]  eta: 0:01:32  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9710 (1.9733)  loss/pix_loss: 0.0066 (0.0099)  loss/enc_loss: 0.0023 (0.0027)  time: 4.2071  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [850/862]  eta: 0:00:50  lr: 0.000090  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.9847 (1.9735)  loss/pix_loss: 0.0077 (0.0099)  loss/enc_loss: 0.0024 (0.0027)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [860/862]  eta: 0:00:08  lr: 0.000090  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.9852 (1.9736)  loss/pix_loss: 0.0074 (0.0099)  loss/enc_loss: 0.0024 (0.0027)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10]  [861/862]  eta: 0:00:04  lr: 0.000090  loss/low_gen_loss: 1.9980 (1.9978)  loss/high_gen_loss: 1.9849 (1.9736)  loss/pix_loss: 0.0075 (0.0099)  loss/enc_loss: 0.0024 (0.0027)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:10] Total time: 1:00:25 (4.2054 s / it)\n",
      "Averaged stats: lr: 0.000090  loss/low_gen_loss: 1.9980 (1.9978)  loss/high_gen_loss: 1.9849 (1.9736)  loss/pix_loss: 0.0075 (0.0099)  loss/enc_loss: 0.0024 (0.0027)\n",
      "Valid: [epoch:10]  [ 0/14]  eta: 0:00:42  L1_loss: 0.0059 (0.0059)  time: 3.0478  data: 0.3846  max mem: 31350\n",
      "Valid: [epoch:10]  [13/14]  eta: 0:00:02  L1_loss: 0.0057 (0.0057)  time: 2.6480  data: 0.0276  max mem: 31350\n",
      "Valid: [epoch:10] Total time: 0:00:37 (2.6574 s / it)\n",
      "Averaged stats: L1_loss: 0.0057 (0.0057)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_10_input_n_20.png\n",
      "Train: [epoch:11]  [  0/862]  eta: 1:15:34  lr: 0.000100  loss/low_gen_loss: 1.9981 (1.9981)  loss/high_gen_loss: 1.9759 (1.9759)  loss/pix_loss: 0.0065 (0.0065)  loss/enc_loss: 0.0021 (0.0021)  time: 5.2607  data: 1.0537  max mem: 31350\n",
      "Train: [epoch:11]  [ 10/862]  eta: 1:00:34  lr: 0.000100  loss/low_gen_loss: 1.9980 (1.9980)  loss/high_gen_loss: 1.9795 (1.9789)  loss/pix_loss: 0.0114 (0.0102)  loss/enc_loss: 0.0033 (0.0033)  time: 4.2654  data: 0.0959  max mem: 31350\n",
      "Train: [epoch:11]  [ 20/862]  eta: 0:59:19  lr: 0.000100  loss/low_gen_loss: 1.9979 (1.9979)  loss/high_gen_loss: 1.9846 (1.9809)  loss/pix_loss: 0.0116 (0.0102)  loss/enc_loss: 0.0033 (0.0033)  time: 4.1754  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [ 30/862]  eta: 0:58:27  lr: 0.000100  loss/low_gen_loss: 1.9978 (1.9979)  loss/high_gen_loss: 1.9611 (1.9472)  loss/pix_loss: 0.0092 (0.0100)  loss/enc_loss: 0.0039 (0.0036)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [ 40/862]  eta: 0:57:41  lr: 0.000100  loss/low_gen_loss: 1.9977 (1.9978)  loss/high_gen_loss: 1.7394 (1.8575)  loss/pix_loss: 0.0109 (0.0106)  loss/enc_loss: 0.0057 (0.0052)  time: 4.1940  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [ 50/862]  eta: 0:56:58  lr: 0.000100  loss/low_gen_loss: 1.9978 (1.9978)  loss/high_gen_loss: 1.7097 (1.8343)  loss/pix_loss: 0.0112 (0.0107)  loss/enc_loss: 0.0097 (0.0062)  time: 4.2015  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [ 60/862]  eta: 0:56:16  lr: 0.000100  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.8041 (1.8422)  loss/pix_loss: 0.0107 (0.0107)  loss/enc_loss: 0.0092 (0.0070)  time: 4.2076  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [ 70/862]  eta: 0:55:33  lr: 0.000100  loss/low_gen_loss: 1.9979 (1.9978)  loss/high_gen_loss: 1.8513 (1.8387)  loss/pix_loss: 0.0106 (0.0107)  loss/enc_loss: 0.0136 (0.0084)  time: 4.2070  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [ 80/862]  eta: 0:54:51  lr: 0.000100  loss/low_gen_loss: 1.9979 (1.9979)  loss/high_gen_loss: 1.7480 (1.8143)  loss/pix_loss: 0.0108 (0.0107)  loss/enc_loss: 0.0205 (0.0112)  time: 4.2067  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [ 90/862]  eta: 0:54:09  lr: 0.000100  loss/low_gen_loss: 1.9981 (1.9979)  loss/high_gen_loss: 1.6687 (1.7990)  loss/pix_loss: 0.0103 (0.0106)  loss/enc_loss: 0.0212 (0.0118)  time: 4.2079  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [100/862]  eta: 0:53:27  lr: 0.000100  loss/low_gen_loss: 1.9982 (1.9979)  loss/high_gen_loss: 1.6862 (1.7884)  loss/pix_loss: 0.0103 (0.0107)  loss/enc_loss: 0.0109 (0.0115)  time: 4.2095  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [110/862]  eta: 0:52:45  lr: 0.000100  loss/low_gen_loss: 1.9981 (1.9979)  loss/high_gen_loss: 1.6227 (1.7689)  loss/pix_loss: 0.0130 (0.0110)  loss/enc_loss: 0.0071 (0.0111)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [120/862]  eta: 0:52:03  lr: 0.000100  loss/low_gen_loss: 1.9980 (1.9980)  loss/high_gen_loss: 1.6490 (1.7789)  loss/pix_loss: 0.0139 (0.0112)  loss/enc_loss: 0.0052 (0.0105)  time: 4.2093  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [130/862]  eta: 0:51:21  lr: 0.000100  loss/low_gen_loss: 1.9982 (1.9980)  loss/high_gen_loss: 1.9552 (1.7917)  loss/pix_loss: 0.0118 (0.0112)  loss/enc_loss: 0.0035 (0.0099)  time: 4.2097  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [140/862]  eta: 0:50:39  lr: 0.000100  loss/low_gen_loss: 1.9983 (1.9980)  loss/high_gen_loss: 1.9306 (1.8011)  loss/pix_loss: 0.0108 (0.0112)  loss/enc_loss: 0.0026 (0.0094)  time: 4.2101  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [150/862]  eta: 0:49:57  lr: 0.000100  loss/low_gen_loss: 1.9966 (1.9970)  loss/high_gen_loss: 1.9141 (1.8063)  loss/pix_loss: 0.0099 (0.0110)  loss/enc_loss: 0.0024 (0.0089)  time: 4.2103  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [160/862]  eta: 0:49:15  lr: 0.000100  loss/low_gen_loss: 1.9781 (1.9958)  loss/high_gen_loss: 1.7815 (1.7980)  loss/pix_loss: 0.0084 (0.0108)  loss/enc_loss: 0.0023 (0.0085)  time: 4.2109  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [170/862]  eta: 0:48:33  lr: 0.000100  loss/low_gen_loss: 1.9781 (1.9938)  loss/high_gen_loss: 1.7627 (1.7964)  loss/pix_loss: 0.0076 (0.0107)  loss/enc_loss: 0.0024 (0.0081)  time: 4.2113  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [180/862]  eta: 0:47:51  lr: 0.000100  loss/low_gen_loss: 1.8292 (1.9756)  loss/high_gen_loss: 1.8560 (1.8018)  loss/pix_loss: 0.0088 (0.0106)  loss/enc_loss: 0.0021 (0.0078)  time: 4.2115  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [190/862]  eta: 0:47:09  lr: 0.000100  loss/low_gen_loss: 1.7532 (1.9751)  loss/high_gen_loss: 1.9340 (1.8096)  loss/pix_loss: 0.0100 (0.0107)  loss/enc_loss: 0.0017 (0.0075)  time: 4.2121  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [200/862]  eta: 0:46:26  lr: 0.000100  loss/low_gen_loss: 2.0061 (1.9769)  loss/high_gen_loss: 1.9461 (1.8167)  loss/pix_loss: 0.0116 (0.0107)  loss/enc_loss: 0.0018 (0.0074)  time: 4.2102  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [210/862]  eta: 0:45:44  lr: 0.000100  loss/low_gen_loss: 1.9971 (1.9779)  loss/high_gen_loss: 1.8929 (1.8134)  loss/pix_loss: 0.0163 (0.0114)  loss/enc_loss: 0.0100 (0.0077)  time: 4.2080  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [220/862]  eta: 0:45:02  lr: 0.000100  loss/low_gen_loss: 1.9971 (1.9788)  loss/high_gen_loss: 1.7121 (1.8071)  loss/pix_loss: 0.0191 (0.0117)  loss/enc_loss: 0.0110 (0.0078)  time: 4.2091  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [230/862]  eta: 0:44:20  lr: 0.000100  loss/low_gen_loss: 1.9970 (1.9793)  loss/high_gen_loss: 1.7359 (1.8050)  loss/pix_loss: 0.0175 (0.0119)  loss/enc_loss: 0.0088 (0.0078)  time: 4.2122  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [240/862]  eta: 0:43:38  lr: 0.000100  loss/low_gen_loss: 1.9919 (1.9798)  loss/high_gen_loss: 1.8308 (1.8094)  loss/pix_loss: 0.0168 (0.0121)  loss/enc_loss: 0.0058 (0.0076)  time: 4.2089  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [250/862]  eta: 0:42:56  lr: 0.000100  loss/low_gen_loss: 1.9931 (1.9804)  loss/high_gen_loss: 1.9600 (1.8158)  loss/pix_loss: 0.0125 (0.0120)  loss/enc_loss: 0.0033 (0.0075)  time: 4.2057  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [260/862]  eta: 0:42:14  lr: 0.000100  loss/low_gen_loss: 1.9949 (1.9810)  loss/high_gen_loss: 1.9747 (1.8219)  loss/pix_loss: 0.0094 (0.0119)  loss/enc_loss: 0.0022 (0.0072)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [270/862]  eta: 0:41:31  lr: 0.000100  loss/low_gen_loss: 1.9958 (1.9815)  loss/high_gen_loss: 1.9690 (1.8272)  loss/pix_loss: 0.0089 (0.0118)  loss/enc_loss: 0.0019 (0.0070)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [280/862]  eta: 0:40:49  lr: 0.000100  loss/low_gen_loss: 1.9962 (1.9820)  loss/high_gen_loss: 1.9645 (1.8320)  loss/pix_loss: 0.0094 (0.0117)  loss/enc_loss: 0.0018 (0.0069)  time: 4.2055  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [290/862]  eta: 0:40:07  lr: 0.000100  loss/low_gen_loss: 1.9961 (1.9825)  loss/high_gen_loss: 1.9662 (1.8368)  loss/pix_loss: 0.0097 (0.0116)  loss/enc_loss: 0.0018 (0.0067)  time: 4.2053  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [300/862]  eta: 0:39:25  lr: 0.000100  loss/low_gen_loss: 1.9948 (1.9829)  loss/high_gen_loss: 1.9724 (1.8413)  loss/pix_loss: 0.0089 (0.0115)  loss/enc_loss: 0.0017 (0.0065)  time: 4.2047  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [310/862]  eta: 0:38:43  lr: 0.000100  loss/low_gen_loss: 1.9944 (1.9833)  loss/high_gen_loss: 1.9736 (1.8455)  loss/pix_loss: 0.0083 (0.0114)  loss/enc_loss: 0.0017 (0.0064)  time: 4.2041  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [320/862]  eta: 0:38:01  lr: 0.000100  loss/low_gen_loss: 1.9948 (1.9836)  loss/high_gen_loss: 1.9745 (1.8496)  loss/pix_loss: 0.0078 (0.0113)  loss/enc_loss: 0.0018 (0.0063)  time: 4.2040  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [330/862]  eta: 0:37:18  lr: 0.000100  loss/low_gen_loss: 1.9939 (1.9839)  loss/high_gen_loss: 1.9755 (1.8533)  loss/pix_loss: 0.0079 (0.0112)  loss/enc_loss: 0.0035 (0.0062)  time: 4.2049  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [340/862]  eta: 0:36:36  lr: 0.000100  loss/low_gen_loss: 1.9933 (1.9842)  loss/high_gen_loss: 1.9640 (1.8564)  loss/pix_loss: 0.0082 (0.0112)  loss/enc_loss: 0.0026 (0.0061)  time: 4.2050  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [350/862]  eta: 0:35:54  lr: 0.000100  loss/low_gen_loss: 1.9925 (1.9844)  loss/high_gen_loss: 1.9526 (1.8589)  loss/pix_loss: 0.0103 (0.0112)  loss/enc_loss: 0.0021 (0.0060)  time: 4.2053  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [360/862]  eta: 0:35:12  lr: 0.000100  loss/low_gen_loss: 1.9921 (1.9846)  loss/high_gen_loss: 1.9236 (1.8557)  loss/pix_loss: 0.0138 (0.0113)  loss/enc_loss: 0.0023 (0.0060)  time: 4.2061  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [370/862]  eta: 0:34:30  lr: 0.000100  loss/low_gen_loss: 1.9920 (1.9848)  loss/high_gen_loss: 1.6373 (1.8518)  loss/pix_loss: 0.0126 (0.0114)  loss/enc_loss: 0.0096 (0.0065)  time: 4.2055  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [380/862]  eta: 0:33:48  lr: 0.000100  loss/low_gen_loss: 1.9925 (1.9850)  loss/high_gen_loss: 1.7344 (1.8494)  loss/pix_loss: 0.0181 (0.0119)  loss/enc_loss: 0.0143 (0.0066)  time: 4.2059  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [390/862]  eta: 0:33:06  lr: 0.000100  loss/low_gen_loss: 1.9930 (1.9852)  loss/high_gen_loss: 1.9107 (1.8512)  loss/pix_loss: 0.0281 (0.0122)  loss/enc_loss: 0.0073 (0.0066)  time: 4.2069  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [400/862]  eta: 0:32:24  lr: 0.000100  loss/low_gen_loss: 1.9922 (1.9854)  loss/high_gen_loss: 1.9398 (1.8540)  loss/pix_loss: 0.0206 (0.0124)  loss/enc_loss: 0.0038 (0.0065)  time: 4.2068  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [410/862]  eta: 0:31:42  lr: 0.000100  loss/low_gen_loss: 1.9930 (1.9856)  loss/high_gen_loss: 1.9437 (1.8556)  loss/pix_loss: 0.0158 (0.0124)  loss/enc_loss: 0.0030 (0.0064)  time: 4.2060  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [420/862]  eta: 0:30:59  lr: 0.000100  loss/low_gen_loss: 1.9934 (1.9857)  loss/high_gen_loss: 1.9344 (1.8579)  loss/pix_loss: 0.0117 (0.0124)  loss/enc_loss: 0.0027 (0.0063)  time: 4.2058  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [430/862]  eta: 0:30:17  lr: 0.000100  loss/low_gen_loss: 1.9916 (1.9858)  loss/high_gen_loss: 1.9718 (1.8606)  loss/pix_loss: 0.0109 (0.0123)  loss/enc_loss: 0.0022 (0.0062)  time: 4.2066  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [440/862]  eta: 0:29:35  lr: 0.000100  loss/low_gen_loss: 1.9904 (1.9859)  loss/high_gen_loss: 1.9774 (1.8634)  loss/pix_loss: 0.0099 (0.0123)  loss/enc_loss: 0.0018 (0.0061)  time: 4.2066  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [450/862]  eta: 0:28:53  lr: 0.000100  loss/low_gen_loss: 1.9791 (1.9854)  loss/high_gen_loss: 1.9851 (1.8657)  loss/pix_loss: 0.0093 (0.0122)  loss/enc_loss: 0.0016 (0.0060)  time: 4.2073  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [460/862]  eta: 0:28:11  lr: 0.000100  loss/low_gen_loss: 1.9650 (1.9851)  loss/high_gen_loss: 1.9565 (1.8785)  loss/pix_loss: 0.0105 (0.0122)  loss/enc_loss: 0.0016 (0.0061)  time: 4.2078  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [470/862]  eta: 0:27:29  lr: 0.000100  loss/low_gen_loss: 1.9897 (1.9853)  loss/high_gen_loss: 4.5480 (10.7126)  loss/pix_loss: 0.0177 (0.0151)  loss/enc_loss: 0.0281 (0.4543)  time: 4.2017  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [480/862]  eta: 0:26:47  lr: 0.000100  loss/low_gen_loss: 1.9944 (1.9855)  loss/high_gen_loss: 223.5744 (29.8272)  loss/pix_loss: 0.1570 (0.0181)  loss/enc_loss: 8.1969 (0.5857)  time: 4.1967  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [490/862]  eta: 0:26:05  lr: 0.000100  loss/low_gen_loss: 1.9935 (1.9852)  loss/high_gen_loss: 208.2809 (63.7685)  loss/pix_loss: 0.1640 (0.0211)  loss/enc_loss: 6.7505 (0.8720)  time: 4.1927  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [500/862]  eta: 0:25:22  lr: 0.000100  loss/low_gen_loss: 1.9769 (1.9851)  loss/high_gen_loss: 12774.3369 (23024.9939)  loss/pix_loss: 0.1567 (0.0238)  loss/enc_loss: 6.9354 (0.9759)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [510/862]  eta: 0:24:40  lr: 0.000100  loss/low_gen_loss: 1.9769 (1.9849)  loss/high_gen_loss: 3075680.5000 (97284.5533)  loss/pix_loss: 0.1738 (0.0269)  loss/enc_loss: 2.3973 (0.9952)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [520/862]  eta: 0:23:58  lr: 0.000100  loss/low_gen_loss: 1.9844 (1.9850)  loss/high_gen_loss: 3411807.5000 (149686.0738)  loss/pix_loss: 0.1813 (0.0298)  loss/enc_loss: 1.0433 (0.9897)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [530/862]  eta: 0:23:16  lr: 0.000100  loss/low_gen_loss: 1.9909 (1.9852)  loss/high_gen_loss: 2297090.7500 (186634.2918)  loss/pix_loss: 0.1595 (0.0321)  loss/enc_loss: 0.4551 (0.9760)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [540/862]  eta: 0:22:34  lr: 0.000100  loss/low_gen_loss: 1.9888 (1.9851)  loss/high_gen_loss: 2293027.5000 (228485.6478)  loss/pix_loss: 0.1569 (0.0348)  loss/enc_loss: 0.1668 (0.9598)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [550/862]  eta: 0:21:51  lr: 0.000100  loss/low_gen_loss: 1.9702 (1.9847)  loss/high_gen_loss: 2632899.0000 (275565.3815)  loss/pix_loss: 0.1808 (0.0375)  loss/enc_loss: 0.0538 (0.9431)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [560/862]  eta: 0:21:09  lr: 0.000100  loss/low_gen_loss: 1.9708 (1.9845)  loss/high_gen_loss: 2766429.0000 (317050.4068)  loss/pix_loss: 0.1780 (0.0398)  loss/enc_loss: 0.0249 (0.9267)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [570/862]  eta: 0:20:27  lr: 0.000100  loss/low_gen_loss: 1.9748 (1.9842)  loss/high_gen_loss: 2013114.3750 (344771.6074)  loss/pix_loss: 0.1600 (0.0420)  loss/enc_loss: 0.0138 (0.9106)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [580/862]  eta: 0:19:45  lr: 0.000100  loss/low_gen_loss: 1.9788 (1.9843)  loss/high_gen_loss: 1915932.7500 (372831.2164)  loss/pix_loss: 0.1545 (0.0440)  loss/enc_loss: 0.0087 (0.8951)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [590/862]  eta: 0:19:03  lr: 0.000100  loss/low_gen_loss: 1.9782 (1.9838)  loss/high_gen_loss: 1940797.0000 (399671.3037)  loss/pix_loss: 0.1534 (0.0459)  loss/enc_loss: 0.0073 (0.8801)  time: 4.1917  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [600/862]  eta: 0:18:21  lr: 0.000100  loss/low_gen_loss: 1.9517 (1.9830)  loss/high_gen_loss: 1888831.5000 (423087.3103)  loss/pix_loss: 0.1553 (0.0479)  loss/enc_loss: 0.0064 (0.8655)  time: 4.1917  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [610/862]  eta: 0:17:39  lr: 0.000100  loss/low_gen_loss: 1.9454 (1.9822)  loss/high_gen_loss: 1643921.1250 (438367.5354)  loss/pix_loss: 0.1653 (0.0499)  loss/enc_loss: 0.0055 (0.8514)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [620/862]  eta: 0:16:57  lr: 0.000100  loss/low_gen_loss: 1.9209 (1.9808)  loss/high_gen_loss: 607807.3750 (435324.8304)  loss/pix_loss: 0.1743 (0.0520)  loss/enc_loss: 0.0050 (0.8378)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [630/862]  eta: 0:16:15  lr: 0.000100  loss/low_gen_loss: 1.9144 (1.9800)  loss/high_gen_loss: 139353.8438 (431211.7742)  loss/pix_loss: 0.1684 (0.0537)  loss/enc_loss: 0.0045 (0.8246)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [640/862]  eta: 0:15:32  lr: 0.000100  loss/low_gen_loss: 1.9428 (1.9795)  loss/high_gen_loss: 179044.5938 (429527.5622)  loss/pix_loss: 0.1628 (0.0555)  loss/enc_loss: 0.0043 (0.8118)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [650/862]  eta: 0:14:50  lr: 0.000100  loss/low_gen_loss: 1.9443 (1.9789)  loss/high_gen_loss: 607056.8750 (435079.2892)  loss/pix_loss: 0.1710 (0.0573)  loss/enc_loss: 0.0041 (0.7994)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [660/862]  eta: 0:14:08  lr: 0.000100  loss/low_gen_loss: 1.9466 (1.9786)  loss/high_gen_loss: 419673.0312 (432160.8685)  loss/pix_loss: 0.1555 (0.0588)  loss/enc_loss: 0.0041 (0.7874)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [670/862]  eta: 0:13:26  lr: 0.000100  loss/low_gen_loss: 1.9649 (1.9784)  loss/high_gen_loss: 419673.0312 (433709.4804)  loss/pix_loss: 0.1585 (0.0603)  loss/enc_loss: 0.0038 (0.7757)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [680/862]  eta: 0:12:44  lr: 0.000100  loss/low_gen_loss: 1.9652 (1.9782)  loss/high_gen_loss: 598069.5000 (490421.1118)  loss/pix_loss: 0.1656 (0.0620)  loss/enc_loss: 0.0033 (0.7643)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [690/862]  eta: 0:12:02  lr: 0.000100  loss/low_gen_loss: 1.9714 (1.9783)  loss/high_gen_loss: 12184843.0000 (692957.8323)  loss/pix_loss: 0.1793 (0.0637)  loss/enc_loss: 0.0033 (0.7533)  time: 4.1870  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [700/862]  eta: 0:11:20  lr: 0.000100  loss/low_gen_loss: 1.9745 (1.9782)  loss/high_gen_loss: 12505574.0000 (788103.5636)  loss/pix_loss: 0.1664 (0.0650)  loss/enc_loss: 0.0033 (0.7426)  time: 4.1878  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [710/862]  eta: 0:10:38  lr: 0.000100  loss/low_gen_loss: 1.9685 (1.9780)  loss/high_gen_loss: 1799741.8750 (800289.4158)  loss/pix_loss: 0.1501 (0.0664)  loss/enc_loss: 0.0029 (0.7322)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [720/862]  eta: 0:09:56  lr: 0.000100  loss/low_gen_loss: 1.9694 (1.9779)  loss/high_gen_loss: 1773019.8750 (844212.7855)  loss/pix_loss: 0.1637 (0.0678)  loss/enc_loss: 0.0028 (0.7221)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [730/862]  eta: 0:09:14  lr: 0.000100  loss/low_gen_loss: 1.9479 (1.9771)  loss/high_gen_loss: 3549546.5000 (888327.2751)  loss/pix_loss: 0.1704 (0.0691)  loss/enc_loss: 0.0026 (0.7123)  time: 4.1901  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [740/862]  eta: 0:08:32  lr: 0.000100  loss/low_gen_loss: 1.9410 (1.9768)  loss/high_gen_loss: 2134674.7500 (894463.0610)  loss/pix_loss: 0.1730 (0.0707)  loss/enc_loss: 0.0025 (0.7027)  time: 4.1910  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [750/862]  eta: 0:07:50  lr: 0.000100  loss/low_gen_loss: 1.9446 (1.9763)  loss/high_gen_loss: 2134674.7500 (943688.7080)  loss/pix_loss: 0.1688 (0.0720)  loss/enc_loss: 0.0024 (0.6934)  time: 4.1909  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [760/862]  eta: 0:07:08  lr: 0.000100  loss/low_gen_loss: 1.9454 (1.9759)  loss/high_gen_loss: 5193927.5000 (1010598.1580)  loss/pix_loss: 0.1629 (0.0731)  loss/enc_loss: 0.0024 (0.6843)  time: 4.1901  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [770/862]  eta: 0:06:26  lr: 0.000100  loss/low_gen_loss: 1.9409 (1.9754)  loss/high_gen_loss: 4443690.0000 (1039888.6148)  loss/pix_loss: 0.1649 (0.0744)  loss/enc_loss: 0.0023 (0.6754)  time: 4.1896  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:11]  [780/862]  eta: 0:05:44  lr: 0.000100  loss/low_gen_loss: 1.9382 (1.9749)  loss/high_gen_loss: 3926189.7500 (1090436.8476)  loss/pix_loss: 0.1665 (0.0755)  loss/enc_loss: 0.0023 (0.6668)  time: 4.1894  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [790/862]  eta: 0:05:02  lr: 0.000100  loss/low_gen_loss: 1.9469 (1.9746)  loss/high_gen_loss: 4751439.5000 (1189244.1131)  loss/pix_loss: 0.1543 (0.0765)  loss/enc_loss: 0.0022 (0.6584)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [800/862]  eta: 0:04:20  lr: 0.000100  loss/low_gen_loss: 1.9552 (1.9745)  loss/high_gen_loss: 10404877.0000 (1349423.2278)  loss/pix_loss: 0.1629 (0.0776)  loss/enc_loss: 0.0020 (0.6502)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [810/862]  eta: 0:03:38  lr: 0.000100  loss/low_gen_loss: 1.9797 (1.9747)  loss/high_gen_loss: 6401305.0000 (1370162.1415)  loss/pix_loss: 0.1775 (0.0789)  loss/enc_loss: 0.0021 (0.6422)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [820/862]  eta: 0:02:56  lr: 0.000100  loss/low_gen_loss: 1.9855 (1.9748)  loss/high_gen_loss: 2313981.2500 (1392762.3001)  loss/pix_loss: 0.1782 (0.0801)  loss/enc_loss: 0.0021 (0.6344)  time: 4.1901  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [830/862]  eta: 0:02:14  lr: 0.000100  loss/low_gen_loss: 1.9862 (1.9749)  loss/high_gen_loss: 5099916.0000 (1454146.7203)  loss/pix_loss: 0.1710 (0.0811)  loss/enc_loss: 0.0020 (0.6268)  time: 4.1908  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.9841 (1.9750)  loss/high_gen_loss: 4015088.5000 (1478117.0111)  loss/pix_loss: 0.1650 (0.0820)  loss/enc_loss: 0.0019 (0.6194)  time: 4.1904  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.9753 (1.9750)  loss/high_gen_loss: 2546076.5000 (1478519.7866)  loss/pix_loss: 0.1644 (0.0830)  loss/enc_loss: 0.0020 (0.6121)  time: 4.1900  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.9754 (1.9750)  loss/high_gen_loss: 1307852.5000 (1475423.8862)  loss/pix_loss: 0.1643 (0.0840)  loss/enc_loss: 0.0019 (0.6050)  time: 4.1898  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.9754 (1.9750)  loss/high_gen_loss: 1296105.7500 (1474146.8473)  loss/pix_loss: 0.1643 (0.0841)  loss/enc_loss: 0.0019 (0.6043)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:11] Total time: 1:00:19 (4.1994 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.9754 (1.9750)  loss/high_gen_loss: 1296105.7500 (1474146.8473)  loss/pix_loss: 0.1643 (0.0841)  loss/enc_loss: 0.0019 (0.6043)\n",
      "Valid: [epoch:11]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1620 (0.1620)  time: 3.0249  data: 0.3997  max mem: 31350\n",
      "Valid: [epoch:11]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6300  data: 0.0286  max mem: 31350\n",
      "Valid: [epoch:11] Total time: 0:00:36 (2.6394 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_11_input_n_20.png\n",
      "Train: [epoch:12]  [  0/862]  eta: 1:16:12  lr: 0.000100  loss/low_gen_loss: 1.9780 (1.9780)  loss/high_gen_loss: 351323.8438 (351323.8438)  loss/pix_loss: 0.1721 (0.1721)  loss/enc_loss: 0.0020 (0.0020)  time: 5.3051  data: 1.1042  max mem: 31350\n",
      "Train: [epoch:12]  [ 10/862]  eta: 1:01:00  lr: 0.000100  loss/low_gen_loss: 1.9774 (1.9775)  loss/high_gen_loss: 807241.8125 (935241.2443)  loss/pix_loss: 0.1721 (0.1673)  loss/enc_loss: 0.0018 (0.0019)  time: 4.2968  data: 0.1005  max mem: 31350\n",
      "Train: [epoch:12]  [ 20/862]  eta: 0:59:35  lr: 0.000100  loss/low_gen_loss: 1.9787 (1.9798)  loss/high_gen_loss: 1127139.5000 (1080201.5446)  loss/pix_loss: 0.1711 (0.1691)  loss/enc_loss: 0.0017 (0.0018)  time: 4.1933  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [ 30/862]  eta: 0:58:41  lr: 0.000100  loss/low_gen_loss: 1.9797 (1.9792)  loss/high_gen_loss: 948080.3125 (1017774.9012)  loss/pix_loss: 0.1693 (0.1683)  loss/enc_loss: 0.0015 (0.0017)  time: 4.1965  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [ 40/862]  eta: 0:57:50  lr: 0.000100  loss/low_gen_loss: 1.9773 (1.9784)  loss/high_gen_loss: 621156.1250 (889173.4223)  loss/pix_loss: 0.1696 (0.1704)  loss/enc_loss: 0.0015 (0.0017)  time: 4.1958  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [ 50/862]  eta: 0:57:02  lr: 0.000100  loss/low_gen_loss: 1.9755 (1.9777)  loss/high_gen_loss: 549025.9375 (972881.9105)  loss/pix_loss: 0.1792 (0.1699)  loss/enc_loss: 0.0015 (0.0017)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [ 60/862]  eta: 0:56:17  lr: 0.000100  loss/low_gen_loss: 1.9756 (1.9772)  loss/high_gen_loss: 1959000.0000 (1231151.7654)  loss/pix_loss: 0.1557 (0.1674)  loss/enc_loss: 0.0015 (0.0017)  time: 4.1886  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [ 70/862]  eta: 0:55:32  lr: 0.000100  loss/low_gen_loss: 1.9748 (1.9761)  loss/high_gen_loss: 3852103.2500 (1986050.1118)  loss/pix_loss: 0.1563 (0.1685)  loss/enc_loss: 0.0015 (0.0017)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [ 80/862]  eta: 0:54:48  lr: 0.000100  loss/low_gen_loss: 1.9748 (1.9761)  loss/high_gen_loss: 9276724.0000 (3102853.4066)  loss/pix_loss: 0.1711 (0.1687)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1900  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [ 90/862]  eta: 0:54:05  lr: 0.000100  loss/low_gen_loss: 1.9767 (1.9762)  loss/high_gen_loss: 9745798.0000 (3766128.0543)  loss/pix_loss: 0.1749 (0.1680)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1901  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [100/862]  eta: 0:53:22  lr: 0.000100  loss/low_gen_loss: 1.9756 (1.9759)  loss/high_gen_loss: 6098252.0000 (3813777.6850)  loss/pix_loss: 0.1580 (0.1670)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1894  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [110/862]  eta: 0:52:39  lr: 0.000100  loss/low_gen_loss: 1.9739 (1.9757)  loss/high_gen_loss: 3405991.7500 (3643711.2630)  loss/pix_loss: 0.1680 (0.1677)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [120/862]  eta: 0:51:56  lr: 0.000100  loss/low_gen_loss: 1.9655 (1.9747)  loss/high_gen_loss: 2857798.5000 (3734706.9478)  loss/pix_loss: 0.1783 (0.1682)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [130/862]  eta: 0:51:13  lr: 0.000100  loss/low_gen_loss: 1.9660 (1.9748)  loss/high_gen_loss: 4074944.5000 (3731143.6980)  loss/pix_loss: 0.1738 (0.1692)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [140/862]  eta: 0:50:31  lr: 0.000100  loss/low_gen_loss: 1.9711 (1.9738)  loss/high_gen_loss: 3283284.7500 (3709626.8613)  loss/pix_loss: 0.1635 (0.1679)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [150/862]  eta: 0:49:48  lr: 0.000100  loss/low_gen_loss: 1.9465 (1.9717)  loss/high_gen_loss: 2707022.2500 (3586978.8423)  loss/pix_loss: 0.1586 (0.1675)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [160/862]  eta: 0:49:06  lr: 0.000100  loss/low_gen_loss: 1.9378 (1.9690)  loss/high_gen_loss: 1733800.3750 (3486904.4592)  loss/pix_loss: 0.1602 (0.1670)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1898  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [170/862]  eta: 0:48:24  lr: 0.000100  loss/low_gen_loss: 1.9481 (1.9679)  loss/high_gen_loss: 2952842.7500 (3569909.9061)  loss/pix_loss: 0.1658 (0.1672)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [180/862]  eta: 0:47:42  lr: 0.000100  loss/low_gen_loss: 1.9544 (1.9676)  loss/high_gen_loss: 4315924.0000 (3575680.3381)  loss/pix_loss: 0.1658 (0.1670)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1886  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [190/862]  eta: 0:46:59  lr: 0.000100  loss/low_gen_loss: 1.9648 (1.9675)  loss/high_gen_loss: 2605877.0000 (3467778.2228)  loss/pix_loss: 0.1693 (0.1673)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1884  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [200/862]  eta: 0:46:17  lr: 0.000100  loss/low_gen_loss: 1.9604 (1.9671)  loss/high_gen_loss: 1434544.0000 (3437871.6769)  loss/pix_loss: 0.1849 (0.1678)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1878  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [210/862]  eta: 0:45:35  lr: 0.000100  loss/low_gen_loss: 1.9631 (1.9675)  loss/high_gen_loss: 8269322.0000 (4446107.4648)  loss/pix_loss: 0.1780 (0.1680)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [220/862]  eta: 0:44:53  lr: 0.000100  loss/low_gen_loss: 1.9788 (1.9680)  loss/high_gen_loss: 32741956.0000 (5880427.6157)  loss/pix_loss: 0.1735 (0.1681)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1894  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [230/862]  eta: 0:44:11  lr: 0.000100  loss/low_gen_loss: 1.9791 (1.9685)  loss/high_gen_loss: 30858614.0000 (6693631.2730)  loss/pix_loss: 0.1675 (0.1679)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [240/862]  eta: 0:43:29  lr: 0.000100  loss/low_gen_loss: 1.9821 (1.9691)  loss/high_gen_loss: 19846580.0000 (7115298.7720)  loss/pix_loss: 0.1640 (0.1678)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [250/862]  eta: 0:42:47  lr: 0.000100  loss/low_gen_loss: 1.9821 (1.9693)  loss/high_gen_loss: 22197458.0000 (7972513.6337)  loss/pix_loss: 0.1566 (0.1676)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [260/862]  eta: 0:42:04  lr: 0.000100  loss/low_gen_loss: 1.9679 (1.9689)  loss/high_gen_loss: 34145800.0000 (9065767.9159)  loss/pix_loss: 0.1627 (0.1675)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1904  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [270/862]  eta: 0:41:22  lr: 0.000100  loss/low_gen_loss: 1.9708 (1.9692)  loss/high_gen_loss: 30608116.0000 (9525039.5648)  loss/pix_loss: 0.1678 (0.1678)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [280/862]  eta: 0:40:40  lr: 0.000100  loss/low_gen_loss: 1.9806 (1.9697)  loss/high_gen_loss: 16775964.0000 (9574057.1960)  loss/pix_loss: 0.1754 (0.1678)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1884  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [290/862]  eta: 0:39:58  lr: 0.000100  loss/low_gen_loss: 1.9834 (1.9702)  loss/high_gen_loss: 10187228.0000 (9610879.9452)  loss/pix_loss: 0.1629 (0.1675)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [300/862]  eta: 0:39:16  lr: 0.000100  loss/low_gen_loss: 1.9837 (1.9706)  loss/high_gen_loss: 9002582.0000 (9518001.8856)  loss/pix_loss: 0.1554 (0.1669)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1883  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [310/862]  eta: 0:38:34  lr: 0.000100  loss/low_gen_loss: 1.9861 (1.9713)  loss/high_gen_loss: 6336006.5000 (9441041.5758)  loss/pix_loss: 0.1445 (0.1666)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [320/862]  eta: 0:37:52  lr: 0.000100  loss/low_gen_loss: 1.9929 (1.9720)  loss/high_gen_loss: 14226015.0000 (9669990.8756)  loss/pix_loss: 0.1472 (0.1661)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [330/862]  eta: 0:37:10  lr: 0.000100  loss/low_gen_loss: 1.9934 (1.9726)  loss/high_gen_loss: 14505922.0000 (9664489.3612)  loss/pix_loss: 0.1472 (0.1658)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1878  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [340/862]  eta: 0:36:28  lr: 0.000100  loss/low_gen_loss: 1.9926 (1.9732)  loss/high_gen_loss: 6809840.0000 (9554427.4547)  loss/pix_loss: 0.1614 (0.1660)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [350/862]  eta: 0:35:46  lr: 0.000100  loss/low_gen_loss: 1.9902 (1.9736)  loss/high_gen_loss: 6915326.0000 (9651315.6013)  loss/pix_loss: 0.1667 (0.1660)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [360/862]  eta: 0:35:04  lr: 0.000100  loss/low_gen_loss: 1.9840 (1.9739)  loss/high_gen_loss: 19048740.0000 (9929238.6484)  loss/pix_loss: 0.1684 (0.1661)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [370/862]  eta: 0:34:22  lr: 0.000100  loss/low_gen_loss: 1.9852 (1.9742)  loss/high_gen_loss: 18427266.0000 (9962788.7212)  loss/pix_loss: 0.1651 (0.1660)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1867  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [380/862]  eta: 0:33:40  lr: 0.000100  loss/low_gen_loss: 1.9879 (1.9746)  loss/high_gen_loss: 6004589.5000 (9822011.3702)  loss/pix_loss: 0.1589 (0.1660)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [390/862]  eta: 0:32:58  lr: 0.000100  loss/low_gen_loss: 1.9895 (1.9750)  loss/high_gen_loss: 4667468.5000 (9706277.4298)  loss/pix_loss: 0.1594 (0.1659)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [400/862]  eta: 0:32:16  lr: 0.000100  loss/low_gen_loss: 1.9905 (1.9754)  loss/high_gen_loss: 6949561.0000 (9744528.9677)  loss/pix_loss: 0.1680 (0.1662)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [410/862]  eta: 0:31:34  lr: 0.000100  loss/low_gen_loss: 1.9897 (1.9758)  loss/high_gen_loss: 11945375.0000 (9811317.7666)  loss/pix_loss: 0.1738 (0.1665)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [420/862]  eta: 0:30:52  lr: 0.000100  loss/low_gen_loss: 1.9883 (1.9760)  loss/high_gen_loss: 8243018.5000 (9722611.0275)  loss/pix_loss: 0.1656 (0.1664)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1911  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [430/862]  eta: 0:30:10  lr: 0.000100  loss/low_gen_loss: 1.9862 (1.9762)  loss/high_gen_loss: 3124564.7500 (9555145.2542)  loss/pix_loss: 0.1623 (0.1663)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [440/862]  eta: 0:29:28  lr: 0.000100  loss/low_gen_loss: 1.9820 (1.9764)  loss/high_gen_loss: 2124620.2500 (9380844.3605)  loss/pix_loss: 0.1623 (0.1661)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1885  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [450/862]  eta: 0:28:46  lr: 0.000100  loss/low_gen_loss: 1.9820 (1.9766)  loss/high_gen_loss: 2844697.0000 (9285347.6225)  loss/pix_loss: 0.1589 (0.1659)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1883  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [460/862]  eta: 0:28:05  lr: 0.000100  loss/low_gen_loss: 1.9869 (1.9768)  loss/high_gen_loss: 3923191.2500 (9190700.3975)  loss/pix_loss: 0.1589 (0.1658)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [470/862]  eta: 0:27:23  lr: 0.000100  loss/low_gen_loss: 1.9850 (1.9769)  loss/high_gen_loss: 3296977.7500 (9035916.7294)  loss/pix_loss: 0.1567 (0.1658)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1886  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [480/862]  eta: 0:26:41  lr: 0.000100  loss/low_gen_loss: 1.9808 (1.9769)  loss/high_gen_loss: 1817759.3750 (8886587.1662)  loss/pix_loss: 0.1541 (0.1655)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [490/862]  eta: 0:25:59  lr: 0.000100  loss/low_gen_loss: 1.9789 (1.9770)  loss/high_gen_loss: 1110078.1250 (8726293.4819)  loss/pix_loss: 0.1457 (0.1652)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [500/862]  eta: 0:25:17  lr: 0.000100  loss/low_gen_loss: 1.9766 (1.9770)  loss/high_gen_loss: 819911.5000 (8565466.9930)  loss/pix_loss: 0.1660 (0.1654)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [510/862]  eta: 0:24:35  lr: 0.000100  loss/low_gen_loss: 1.9807 (1.9771)  loss/high_gen_loss: 662237.0000 (8415358.9754)  loss/pix_loss: 0.1753 (0.1657)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [520/862]  eta: 0:23:53  lr: 0.000100  loss/low_gen_loss: 1.9833 (1.9772)  loss/high_gen_loss: 1464112.6250 (8287787.7606)  loss/pix_loss: 0.1793 (0.1659)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1878  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [530/862]  eta: 0:23:11  lr: 0.000100  loss/low_gen_loss: 1.9829 (1.9773)  loss/high_gen_loss: 1464112.6250 (8150219.4879)  loss/pix_loss: 0.1735 (0.1658)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1869  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [540/862]  eta: 0:22:29  lr: 0.000100  loss/low_gen_loss: 1.9751 (1.9772)  loss/high_gen_loss: 418600.8750 (8004830.9054)  loss/pix_loss: 0.1737 (0.1662)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [550/862]  eta: 0:21:47  lr: 0.000100  loss/low_gen_loss: 1.9750 (1.9772)  loss/high_gen_loss: 431773.0000 (7872829.5700)  loss/pix_loss: 0.1745 (0.1662)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [560/862]  eta: 0:21:05  lr: 0.000100  loss/low_gen_loss: 1.9784 (1.9773)  loss/high_gen_loss: 694276.5625 (7747195.8944)  loss/pix_loss: 0.1559 (0.1661)  loss/enc_loss: 0.0008 (0.0011)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [570/862]  eta: 0:20:23  lr: 0.000100  loss/low_gen_loss: 1.9804 (1.9773)  loss/high_gen_loss: 583991.3125 (7618637.1550)  loss/pix_loss: 0.1680 (0.1663)  loss/enc_loss: 0.0008 (0.0011)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [580/862]  eta: 0:19:41  lr: 0.000100  loss/low_gen_loss: 1.9775 (1.9773)  loss/high_gen_loss: 639670.1250 (7530927.6520)  loss/pix_loss: 0.1627 (0.1661)  loss/enc_loss: 0.0008 (0.0011)  time: 4.1866  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [590/862]  eta: 0:18:59  lr: 0.000100  loss/low_gen_loss: 1.9791 (1.9773)  loss/high_gen_loss: 1642068.2500 (7424883.5052)  loss/pix_loss: 0.1548 (0.1659)  loss/enc_loss: 0.0008 (0.0011)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [600/862]  eta: 0:18:17  lr: 0.000100  loss/low_gen_loss: 1.9806 (1.9774)  loss/high_gen_loss: 726044.0625 (7310317.6461)  loss/pix_loss: 0.1589 (0.1658)  loss/enc_loss: 0.0008 (0.0011)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [610/862]  eta: 0:17:36  lr: 0.000100  loss/low_gen_loss: 1.9832 (1.9775)  loss/high_gen_loss: 507613.7812 (7198949.0964)  loss/pix_loss: 0.1606 (0.1659)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [620/862]  eta: 0:16:54  lr: 0.000100  loss/low_gen_loss: 1.9776 (1.9775)  loss/high_gen_loss: 392045.4375 (7087626.0538)  loss/pix_loss: 0.1738 (0.1660)  loss/enc_loss: 0.0006 (0.0011)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [630/862]  eta: 0:16:12  lr: 0.000100  loss/low_gen_loss: 1.9776 (1.9775)  loss/high_gen_loss: 231004.3125 (6978260.1773)  loss/pix_loss: 0.1655 (0.1659)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [640/862]  eta: 0:15:30  lr: 0.000100  loss/low_gen_loss: 1.9768 (1.9775)  loss/high_gen_loss: 178933.7031 (6872235.8641)  loss/pix_loss: 0.1582 (0.1659)  loss/enc_loss: 0.0008 (0.0011)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [650/862]  eta: 0:14:48  lr: 0.000100  loss/low_gen_loss: 1.9732 (1.9774)  loss/high_gen_loss: 185186.5781 (6772039.7634)  loss/pix_loss: 0.1622 (0.1659)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [660/862]  eta: 0:14:06  lr: 0.000100  loss/low_gen_loss: 1.9716 (1.9773)  loss/high_gen_loss: 288210.9375 (6678808.0054)  loss/pix_loss: 0.1656 (0.1660)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [670/862]  eta: 0:13:24  lr: 0.000100  loss/low_gen_loss: 1.9727 (1.9772)  loss/high_gen_loss: 123705.0859 (6580848.5526)  loss/pix_loss: 0.1720 (0.1661)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [680/862]  eta: 0:12:42  lr: 0.000100  loss/low_gen_loss: 1.9694 (1.9771)  loss/high_gen_loss: 70210.5703 (6485009.8730)  loss/pix_loss: 0.1691 (0.1660)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [690/862]  eta: 0:12:00  lr: 0.000100  loss/low_gen_loss: 1.9700 (1.9771)  loss/high_gen_loss: 46054.3906 (6391707.5801)  loss/pix_loss: 0.1673 (0.1662)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [700/862]  eta: 0:11:18  lr: 0.000100  loss/low_gen_loss: 1.9773 (1.9771)  loss/high_gen_loss: 33950.9883 (6301002.1694)  loss/pix_loss: 0.1669 (0.1661)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [710/862]  eta: 0:10:36  lr: 0.000100  loss/low_gen_loss: 1.9842 (1.9772)  loss/high_gen_loss: 28354.1836 (6212611.0160)  loss/pix_loss: 0.1646 (0.1664)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [720/862]  eta: 0:09:54  lr: 0.000100  loss/low_gen_loss: 1.9859 (1.9774)  loss/high_gen_loss: 6064.8369 (6126493.7153)  loss/pix_loss: 0.1806 (0.1665)  loss/enc_loss: 0.0006 (0.0011)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [730/862]  eta: 0:09:13  lr: 0.000100  loss/low_gen_loss: 1.9855 (1.9774)  loss/high_gen_loss: 4007.8491 (6042767.5813)  loss/pix_loss: 0.1707 (0.1666)  loss/enc_loss: 0.0007 (0.0010)  time: 4.1884  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [740/862]  eta: 0:08:31  lr: 0.000100  loss/low_gen_loss: 1.9848 (1.9775)  loss/high_gen_loss: 9798.9668 (5961847.8760)  loss/pix_loss: 0.1707 (0.1667)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [750/862]  eta: 0:07:49  lr: 0.000100  loss/low_gen_loss: 1.9879 (1.9777)  loss/high_gen_loss: 102241.5938 (5884526.6895)  loss/pix_loss: 0.1721 (0.1668)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [760/862]  eta: 0:07:07  lr: 0.000100  loss/low_gen_loss: 1.9834 (1.9777)  loss/high_gen_loss: 159646.4062 (5810381.8918)  loss/pix_loss: 0.1781 (0.1669)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1880  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [770/862]  eta: 0:06:25  lr: 0.000100  loss/low_gen_loss: 1.9824 (1.9777)  loss/high_gen_loss: 157177.5000 (5736620.9695)  loss/pix_loss: 0.1800 (0.1670)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [780/862]  eta: 0:05:43  lr: 0.000100  loss/low_gen_loss: 1.9765 (1.9777)  loss/high_gen_loss: 90372.1797 (5664008.4624)  loss/pix_loss: 0.1616 (0.1668)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [790/862]  eta: 0:05:01  lr: 0.000100  loss/low_gen_loss: 1.9766 (1.9777)  loss/high_gen_loss: 18974.6328 (5592566.3566)  loss/pix_loss: 0.1634 (0.1667)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [800/862]  eta: 0:04:19  lr: 0.000100  loss/low_gen_loss: 1.9791 (1.9778)  loss/high_gen_loss: 8728.0371 (5522837.9608)  loss/pix_loss: 0.1745 (0.1668)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.9835 (1.9779)  loss/high_gen_loss: 7586.1533 (5454866.8993)  loss/pix_loss: 0.1718 (0.1668)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1902  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.9810 (1.9778)  loss/high_gen_loss: 16394.8457 (5399438.0028)  loss/pix_loss: 0.1689 (0.1669)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1899  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [830/862]  eta: 0:02:14  lr: 0.000100  loss/low_gen_loss: 1.9795 (1.9779)  loss/high_gen_loss: 2007926.0000 (5371074.3999)  loss/pix_loss: 0.1707 (0.1670)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1884  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.9809 (1.9779)  loss/high_gen_loss: 4118383.5000 (5367932.4962)  loss/pix_loss: 0.1723 (0.1671)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.9752 (1.9778)  loss/high_gen_loss: 7354544.5000 (5442182.6749)  loss/pix_loss: 0.1760 (0.1671)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1902  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.9744 (1.9778)  loss/high_gen_loss: 12962696.0000 (5601275.6194)  loss/pix_loss: 0.1687 (0.1670)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1887  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.9744 (1.9778)  loss/high_gen_loss: 14325672.0000 (5620011.1698)  loss/pix_loss: 0.1760 (0.1670)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1885  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:12] Total time: 1:00:11 (4.1900 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.9744 (1.9778)  loss/high_gen_loss: 14325672.0000 (5620011.1698)  loss/pix_loss: 0.1760 (0.1670)  loss/enc_loss: 0.0006 (0.0010)\n",
      "Valid: [epoch:12]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1080 (0.1080)  time: 2.9798  data: 0.3774  max mem: 31350\n",
      "Valid: [epoch:12]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6038  data: 0.0270  max mem: 31350\n",
      "Valid: [epoch:12] Total time: 0:00:36 (2.6127 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_12_input_n_20.png\n",
      "Train: [epoch:13]  [  0/862]  eta: 1:14:27  lr: 0.000100  loss/low_gen_loss: 1.9729 (1.9729)  loss/high_gen_loss: 21583688.0000 (21583688.0000)  loss/pix_loss: 0.1976 (0.1976)  loss/enc_loss: 0.0005 (0.0005)  time: 5.1830  data: 1.0009  max mem: 31350\n",
      "Train: [epoch:13]  [ 10/862]  eta: 1:00:16  lr: 0.000100  loss/low_gen_loss: 1.9699 (1.9701)  loss/high_gen_loss: 15954128.0000 (16591721.5455)  loss/pix_loss: 0.1752 (0.1685)  loss/enc_loss: 0.0005 (0.0005)  time: 4.2452  data: 0.0911  max mem: 31350\n",
      "Train: [epoch:13]  [ 20/862]  eta: 0:59:02  lr: 0.000100  loss/low_gen_loss: 1.9719 (1.9720)  loss/high_gen_loss: 10103600.0000 (12427652.8333)  loss/pix_loss: 0.1697 (0.1663)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1581  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [ 30/862]  eta: 0:58:11  lr: 0.000100  loss/low_gen_loss: 1.9762 (1.9751)  loss/high_gen_loss: 5830655.0000 (9887024.6129)  loss/pix_loss: 0.1697 (0.1697)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [ 40/862]  eta: 0:57:26  lr: 0.000100  loss/low_gen_loss: 1.9799 (1.9758)  loss/high_gen_loss: 5508705.0000 (9304640.0732)  loss/pix_loss: 0.1686 (0.1693)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1790  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [ 50/862]  eta: 0:56:44  lr: 0.000100  loss/low_gen_loss: 1.9788 (1.9766)  loss/high_gen_loss: 7814339.0000 (9309838.1471)  loss/pix_loss: 0.1617 (0.1684)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [ 60/862]  eta: 0:56:01  lr: 0.000100  loss/low_gen_loss: 1.9721 (1.9748)  loss/high_gen_loss: 15159681.0000 (10579839.5820)  loss/pix_loss: 0.1618 (0.1669)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [ 70/862]  eta: 0:55:19  lr: 0.000100  loss/low_gen_loss: 1.9676 (1.9739)  loss/high_gen_loss: 16102482.0000 (11264436.5423)  loss/pix_loss: 0.1639 (0.1672)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [ 80/862]  eta: 0:54:37  lr: 0.000100  loss/low_gen_loss: 1.9691 (1.9740)  loss/high_gen_loss: 13479122.0000 (11219853.8827)  loss/pix_loss: 0.1699 (0.1670)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [ 90/862]  eta: 0:53:55  lr: 0.000100  loss/low_gen_loss: 1.9742 (1.9740)  loss/high_gen_loss: 8992324.0000 (10889191.1538)  loss/pix_loss: 0.1678 (0.1668)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1884  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [100/862]  eta: 0:53:13  lr: 0.000100  loss/low_gen_loss: 1.9757 (1.9743)  loss/high_gen_loss: 7802894.0000 (10455941.7376)  loss/pix_loss: 0.1678 (0.1670)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [110/862]  eta: 0:52:31  lr: 0.000100  loss/low_gen_loss: 1.9757 (1.9742)  loss/high_gen_loss: 5137814.0000 (9948507.1644)  loss/pix_loss: 0.1606 (0.1654)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [120/862]  eta: 0:51:49  lr: 0.000100  loss/low_gen_loss: 1.9753 (1.9744)  loss/high_gen_loss: 4166381.2500 (9436909.4298)  loss/pix_loss: 0.1543 (0.1660)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [130/862]  eta: 0:51:07  lr: 0.000100  loss/low_gen_loss: 1.9792 (1.9750)  loss/high_gen_loss: 4116393.5000 (9060891.8931)  loss/pix_loss: 0.1749 (0.1674)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [140/862]  eta: 0:50:25  lr: 0.000100  loss/low_gen_loss: 1.9825 (1.9756)  loss/high_gen_loss: 3618350.7500 (8636508.9025)  loss/pix_loss: 0.1714 (0.1673)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1883  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [150/862]  eta: 0:49:43  lr: 0.000100  loss/low_gen_loss: 1.9828 (1.9762)  loss/high_gen_loss: 4280857.0000 (8455442.7334)  loss/pix_loss: 0.1576 (0.1664)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1883  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [160/862]  eta: 0:49:01  lr: 0.000100  loss/low_gen_loss: 1.9830 (1.9765)  loss/high_gen_loss: 7081899.5000 (8421839.7220)  loss/pix_loss: 0.1648 (0.1668)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [170/862]  eta: 0:48:19  lr: 0.000100  loss/low_gen_loss: 1.9872 (1.9772)  loss/high_gen_loss: 7311340.0000 (8316186.1447)  loss/pix_loss: 0.1654 (0.1666)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1880  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [180/862]  eta: 0:47:37  lr: 0.000100  loss/low_gen_loss: 1.9886 (1.9776)  loss/high_gen_loss: 3845287.2500 (8008411.0428)  loss/pix_loss: 0.1673 (0.1671)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [190/862]  eta: 0:46:55  lr: 0.000100  loss/low_gen_loss: 1.9701 (1.9769)  loss/high_gen_loss: 2523951.0000 (7718333.0668)  loss/pix_loss: 0.1719 (0.1678)  loss/enc_loss: 0.0004 (0.0006)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [200/862]  eta: 0:46:13  lr: 0.000100  loss/low_gen_loss: 1.9674 (1.9765)  loss/high_gen_loss: 1884241.1250 (7422821.9490)  loss/pix_loss: 0.1785 (0.1681)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [210/862]  eta: 0:45:31  lr: 0.000100  loss/low_gen_loss: 1.9718 (1.9763)  loss/high_gen_loss: 1377594.3750 (7122835.2302)  loss/pix_loss: 0.1704 (0.1679)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [220/862]  eta: 0:44:49  lr: 0.000100  loss/low_gen_loss: 1.9737 (1.9762)  loss/high_gen_loss: 1018111.5625 (6846953.8637)  loss/pix_loss: 0.1628 (0.1679)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [230/862]  eta: 0:44:07  lr: 0.000100  loss/low_gen_loss: 1.9758 (1.9762)  loss/high_gen_loss: 1265133.1250 (6621623.3393)  loss/pix_loss: 0.1622 (0.1678)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [240/862]  eta: 0:43:25  lr: 0.000100  loss/low_gen_loss: 1.9713 (1.9759)  loss/high_gen_loss: 1422811.8750 (6396022.4183)  loss/pix_loss: 0.1604 (0.1674)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1884  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [250/862]  eta: 0:42:43  lr: 0.000100  loss/low_gen_loss: 1.9659 (1.9753)  loss/high_gen_loss: 1203940.1250 (6186503.5900)  loss/pix_loss: 0.1655 (0.1676)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [260/862]  eta: 0:42:01  lr: 0.000100  loss/low_gen_loss: 1.9688 (1.9754)  loss/high_gen_loss: 2389781.7500 (6084589.5684)  loss/pix_loss: 0.1624 (0.1673)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [270/862]  eta: 0:41:19  lr: 0.000100  loss/low_gen_loss: 1.9790 (1.9755)  loss/high_gen_loss: 2820618.2500 (5943044.9238)  loss/pix_loss: 0.1613 (0.1677)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1878  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [280/862]  eta: 0:40:38  lr: 0.000100  loss/low_gen_loss: 1.9687 (1.9751)  loss/high_gen_loss: 1471575.6250 (5778049.5186)  loss/pix_loss: 0.1771 (0.1679)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [290/862]  eta: 0:39:56  lr: 0.000100  loss/low_gen_loss: 1.9639 (1.9747)  loss/high_gen_loss: 1174832.3750 (5615619.9576)  loss/pix_loss: 0.1739 (0.1678)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1877  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [300/862]  eta: 0:39:14  lr: 0.000100  loss/low_gen_loss: 1.9611 (1.9741)  loss/high_gen_loss: 747480.7500 (5445280.7529)  loss/pix_loss: 0.1646 (0.1676)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1869  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [310/862]  eta: 0:38:32  lr: 0.000100  loss/low_gen_loss: 1.9583 (1.9736)  loss/high_gen_loss: 319168.8438 (5277724.5670)  loss/pix_loss: 0.1586 (0.1673)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [320/862]  eta: 0:37:50  lr: 0.000100  loss/low_gen_loss: 1.9540 (1.9730)  loss/high_gen_loss: 282650.5312 (5124323.4368)  loss/pix_loss: 0.1621 (0.1670)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1870  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [330/862]  eta: 0:37:08  lr: 0.000100  loss/low_gen_loss: 1.9533 (1.9727)  loss/high_gen_loss: 269813.5938 (4976555.3629)  loss/pix_loss: 0.1652 (0.1667)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1866  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [340/862]  eta: 0:36:26  lr: 0.000100  loss/low_gen_loss: 1.9599 (1.9723)  loss/high_gen_loss: 271205.9688 (4845607.7676)  loss/pix_loss: 0.1649 (0.1667)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [350/862]  eta: 0:35:44  lr: 0.000100  loss/low_gen_loss: 1.9585 (1.9719)  loss/high_gen_loss: 1004004.0000 (4753630.8964)  loss/pix_loss: 0.1589 (0.1666)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [360/862]  eta: 0:35:02  lr: 0.000100  loss/low_gen_loss: 1.9599 (1.9716)  loss/high_gen_loss: 1397145.0000 (4658029.8861)  loss/pix_loss: 0.1611 (0.1664)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [370/862]  eta: 0:34:20  lr: 0.000100  loss/low_gen_loss: 1.9632 (1.9715)  loss/high_gen_loss: 806163.5625 (4546899.2394)  loss/pix_loss: 0.1653 (0.1665)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [380/862]  eta: 0:33:38  lr: 0.000100  loss/low_gen_loss: 1.9741 (1.9716)  loss/high_gen_loss: 355232.3438 (4433859.2842)  loss/pix_loss: 0.1740 (0.1667)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [390/862]  eta: 0:32:56  lr: 0.000100  loss/low_gen_loss: 1.9731 (1.9717)  loss/high_gen_loss: 158484.5000 (4323122.6836)  loss/pix_loss: 0.1755 (0.1667)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [400/862]  eta: 0:32:15  lr: 0.000100  loss/low_gen_loss: 1.9746 (1.9718)  loss/high_gen_loss: 101798.2188 (4217905.3056)  loss/pix_loss: 0.1708 (0.1667)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [410/862]  eta: 0:31:33  lr: 0.000100  loss/low_gen_loss: 1.9804 (1.9721)  loss/high_gen_loss: 121976.5156 (4118708.6951)  loss/pix_loss: 0.1647 (0.1667)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [420/862]  eta: 0:30:51  lr: 0.000100  loss/low_gen_loss: 1.9758 (1.9721)  loss/high_gen_loss: 69978.4609 (4022007.1928)  loss/pix_loss: 0.1605 (0.1667)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [430/862]  eta: 0:30:09  lr: 0.000100  loss/low_gen_loss: 1.9708 (1.9720)  loss/high_gen_loss: 25497.6699 (3929126.0747)  loss/pix_loss: 0.1721 (0.1668)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1906  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [440/862]  eta: 0:29:27  lr: 0.000100  loss/low_gen_loss: 1.9707 (1.9720)  loss/high_gen_loss: 16232.8662 (3840401.8217)  loss/pix_loss: 0.1650 (0.1668)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1941  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [450/862]  eta: 0:28:45  lr: 0.000100  loss/low_gen_loss: 1.9736 (1.9721)  loss/high_gen_loss: 38872.8789 (3756169.8754)  loss/pix_loss: 0.1712 (0.1673)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1924  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [460/862]  eta: 0:28:03  lr: 0.000100  loss/low_gen_loss: 1.9755 (1.9721)  loss/high_gen_loss: 42052.7773 (3675621.9516)  loss/pix_loss: 0.1489 (0.1668)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [470/862]  eta: 0:27:21  lr: 0.000100  loss/low_gen_loss: 1.9760 (1.9722)  loss/high_gen_loss: 27424.2656 (3597978.6964)  loss/pix_loss: 0.1417 (0.1665)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1844  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [480/862]  eta: 0:26:40  lr: 0.000100  loss/low_gen_loss: 1.9736 (1.9722)  loss/high_gen_loss: 18300.6348 (3523576.1445)  loss/pix_loss: 0.1544 (0.1664)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1841  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [490/862]  eta: 0:25:58  lr: 0.000100  loss/low_gen_loss: 1.9692 (1.9721)  loss/high_gen_loss: 13124.2646 (3451985.4787)  loss/pix_loss: 0.1635 (0.1663)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [500/862]  eta: 0:25:16  lr: 0.000100  loss/low_gen_loss: 1.9685 (1.9720)  loss/high_gen_loss: 9663.8037 (3383410.6907)  loss/pix_loss: 0.1629 (0.1662)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [510/862]  eta: 0:24:34  lr: 0.000100  loss/low_gen_loss: 1.9584 (1.9717)  loss/high_gen_loss: 40491.2617 (3319535.8318)  loss/pix_loss: 0.1584 (0.1663)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [520/862]  eta: 0:23:52  lr: 0.000100  loss/low_gen_loss: 1.9543 (1.9714)  loss/high_gen_loss: 226514.7188 (3261094.8172)  loss/pix_loss: 0.1573 (0.1661)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [530/862]  eta: 0:23:10  lr: 0.000100  loss/low_gen_loss: 1.9565 (1.9711)  loss/high_gen_loss: 292758.1875 (3205750.6173)  loss/pix_loss: 0.1513 (0.1658)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1869  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [540/862]  eta: 0:22:28  lr: 0.000100  loss/low_gen_loss: 1.9590 (1.9710)  loss/high_gen_loss: 255698.0469 (3149692.6414)  loss/pix_loss: 0.1702 (0.1663)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [550/862]  eta: 0:21:46  lr: 0.000100  loss/low_gen_loss: 1.9674 (1.9709)  loss/high_gen_loss: 133055.0781 (3094826.8312)  loss/pix_loss: 0.1890 (0.1665)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [560/862]  eta: 0:21:04  lr: 0.000100  loss/low_gen_loss: 1.9609 (1.9706)  loss/high_gen_loss: 138025.5000 (3042238.3720)  loss/pix_loss: 0.1622 (0.1663)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [570/862]  eta: 0:20:22  lr: 0.000100  loss/low_gen_loss: 1.9525 (1.9703)  loss/high_gen_loss: 116250.8125 (2990172.1176)  loss/pix_loss: 0.1606 (0.1663)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1885  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [580/862]  eta: 0:19:41  lr: 0.000100  loss/low_gen_loss: 1.9537 (1.9701)  loss/high_gen_loss: 52686.6523 (2939559.4626)  loss/pix_loss: 0.1672 (0.1662)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1903  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [590/862]  eta: 0:18:59  lr: 0.000100  loss/low_gen_loss: 1.9667 (1.9703)  loss/high_gen_loss: 52140.1328 (2890804.3791)  loss/pix_loss: 0.1595 (0.1661)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1898  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [600/862]  eta: 0:18:17  lr: 0.000100  loss/low_gen_loss: 1.9780 (1.9704)  loss/high_gen_loss: 87938.0000 (2873207.9682)  loss/pix_loss: 0.1575 (0.1659)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [610/862]  eta: 0:17:35  lr: 0.000100  loss/low_gen_loss: 1.9755 (1.9705)  loss/high_gen_loss: 4853940.0000 (3039961.5636)  loss/pix_loss: 0.1657 (0.1661)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1901  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [620/862]  eta: 0:16:53  lr: 0.000100  loss/low_gen_loss: 1.9749 (1.9705)  loss/high_gen_loss: 16125576.0000 (3255468.4080)  loss/pix_loss: 0.1686 (0.1662)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1905  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:13]  [630/862]  eta: 0:16:11  lr: 0.000100  loss/low_gen_loss: 1.9749 (1.9706)  loss/high_gen_loss: 17380308.0000 (3560498.2050)  loss/pix_loss: 0.1627 (0.1660)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [640/862]  eta: 0:15:29  lr: 0.000100  loss/low_gen_loss: 1.9760 (1.9707)  loss/high_gen_loss: 18477832.0000 (3730214.8243)  loss/pix_loss: 0.1627 (0.1660)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [650/862]  eta: 0:14:47  lr: 0.000100  loss/low_gen_loss: 1.9715 (1.9707)  loss/high_gen_loss: 12544945.0000 (3855606.5843)  loss/pix_loss: 0.1728 (0.1662)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [660/862]  eta: 0:14:06  lr: 0.000100  loss/low_gen_loss: 1.9691 (1.9706)  loss/high_gen_loss: 14823136.0000 (4125432.5997)  loss/pix_loss: 0.1637 (0.1661)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [670/862]  eta: 0:13:24  lr: 0.000100  loss/low_gen_loss: 1.9668 (1.9706)  loss/high_gen_loss: 19655320.0000 (4338372.2167)  loss/pix_loss: 0.1649 (0.1663)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [680/862]  eta: 0:12:42  lr: 0.000100  loss/low_gen_loss: 1.9687 (1.9706)  loss/high_gen_loss: 15892843.0000 (4460303.0387)  loss/pix_loss: 0.1841 (0.1664)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [690/862]  eta: 0:12:00  lr: 0.000100  loss/low_gen_loss: 1.9697 (1.9706)  loss/high_gen_loss: 12258549.0000 (4583517.4506)  loss/pix_loss: 0.1700 (0.1665)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [700/862]  eta: 0:11:18  lr: 0.000100  loss/low_gen_loss: 1.9748 (1.9708)  loss/high_gen_loss: 13592560.0000 (4728124.2430)  loss/pix_loss: 0.1627 (0.1665)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [710/862]  eta: 0:10:36  lr: 0.000100  loss/low_gen_loss: 1.9845 (1.9710)  loss/high_gen_loss: 8078998.0000 (4764335.7649)  loss/pix_loss: 0.1689 (0.1666)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1902  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [720/862]  eta: 0:09:54  lr: 0.000100  loss/low_gen_loss: 1.9834 (1.9711)  loss/high_gen_loss: 7244139.0000 (4801923.1975)  loss/pix_loss: 0.1723 (0.1667)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1905  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [730/862]  eta: 0:09:12  lr: 0.000100  loss/low_gen_loss: 1.9762 (1.9711)  loss/high_gen_loss: 8435473.0000 (4874447.8186)  loss/pix_loss: 0.1684 (0.1666)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1896  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [740/862]  eta: 0:08:30  lr: 0.000100  loss/low_gen_loss: 1.9722 (1.9711)  loss/high_gen_loss: 9428090.0000 (4934127.6753)  loss/pix_loss: 0.1654 (0.1667)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1883  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [750/862]  eta: 0:07:49  lr: 0.000100  loss/low_gen_loss: 1.9626 (1.9709)  loss/high_gen_loss: 9571205.0000 (5000711.1203)  loss/pix_loss: 0.1732 (0.1669)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1894  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [760/862]  eta: 0:07:07  lr: 0.000100  loss/low_gen_loss: 1.9609 (1.9709)  loss/high_gen_loss: 11036845.0000 (5094014.3868)  loss/pix_loss: 0.1673 (0.1668)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [770/862]  eta: 0:06:25  lr: 0.000100  loss/low_gen_loss: 1.9722 (1.9709)  loss/high_gen_loss: 11273060.0000 (5133421.7644)  loss/pix_loss: 0.1620 (0.1667)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1908  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [780/862]  eta: 0:05:43  lr: 0.000100  loss/low_gen_loss: 1.9728 (1.9709)  loss/high_gen_loss: 5884503.5000 (5136392.9429)  loss/pix_loss: 0.1673 (0.1668)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1904  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [790/862]  eta: 0:05:01  lr: 0.000100  loss/low_gen_loss: 1.9762 (1.9710)  loss/high_gen_loss: 6936403.5000 (5171446.1048)  loss/pix_loss: 0.1650 (0.1667)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1910  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [800/862]  eta: 0:04:19  lr: 0.000100  loss/low_gen_loss: 1.9767 (1.9711)  loss/high_gen_loss: 8076733.5000 (5209773.1971)  loss/pix_loss: 0.1609 (0.1667)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1894  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.9774 (1.9712)  loss/high_gen_loss: 7848905.5000 (5241242.9986)  loss/pix_loss: 0.1676 (0.1668)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.9728 (1.9711)  loss/high_gen_loss: 7277662.0000 (5260405.7002)  loss/pix_loss: 0.1753 (0.1668)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1870  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [830/862]  eta: 0:02:14  lr: 0.000100  loss/low_gen_loss: 1.9705 (1.9712)  loss/high_gen_loss: 5303110.0000 (5244795.3566)  loss/pix_loss: 0.1643 (0.1668)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.9648 (1.9711)  loss/high_gen_loss: 3955887.2500 (5234443.0037)  loss/pix_loss: 0.1700 (0.1669)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1899  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.9645 (1.9710)  loss/high_gen_loss: 5668295.5000 (5248165.9261)  loss/pix_loss: 0.1728 (0.1670)  loss/enc_loss: 0.0003 (0.0005)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.9665 (1.9710)  loss/high_gen_loss: 6967874.5000 (5289874.9612)  loss/pix_loss: 0.1653 (0.1668)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.9667 (1.9710)  loss/high_gen_loss: 7453852.5000 (5292798.0814)  loss/pix_loss: 0.1653 (0.1669)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:13] Total time: 1:00:10 (4.1887 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.9667 (1.9710)  loss/high_gen_loss: 7453852.5000 (5292798.0814)  loss/pix_loss: 0.1653 (0.1669)  loss/enc_loss: 0.0003 (0.0004)\n",
      "Valid: [epoch:13]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1620 (0.1620)  time: 3.0527  data: 0.4483  max mem: 31350\n",
      "Valid: [epoch:13]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6131  data: 0.0321  max mem: 31350\n",
      "Valid: [epoch:13] Total time: 0:00:36 (2.6226 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_13_input_n_20.png\n",
      "Train: [epoch:14]  [  0/862]  eta: 1:15:31  lr: 0.000100  loss/low_gen_loss: 1.9779 (1.9779)  loss/high_gen_loss: 7265032.5000 (7265032.5000)  loss/pix_loss: 0.1754 (0.1754)  loss/enc_loss: 0.0004 (0.0004)  time: 5.2575  data: 1.0584  max mem: 31350\n",
      "Train: [epoch:14]  [ 10/862]  eta: 1:00:56  lr: 0.000100  loss/low_gen_loss: 1.9730 (1.9699)  loss/high_gen_loss: 5986107.0000 (5967680.5909)  loss/pix_loss: 0.1659 (0.1644)  loss/enc_loss: 0.0003 (0.0003)  time: 4.2912  data: 0.0963  max mem: 31350\n",
      "Train: [epoch:14]  [ 20/862]  eta: 0:59:32  lr: 0.000100  loss/low_gen_loss: 1.9613 (1.9632)  loss/high_gen_loss: 4125595.0000 (4976179.4405)  loss/pix_loss: 0.1640 (0.1654)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1917  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [ 30/862]  eta: 0:58:34  lr: 0.000100  loss/low_gen_loss: 1.9640 (1.9662)  loss/high_gen_loss: 4115941.2500 (5236579.1935)  loss/pix_loss: 0.1641 (0.1664)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [ 40/862]  eta: 0:57:45  lr: 0.000100  loss/low_gen_loss: 1.9705 (1.9665)  loss/high_gen_loss: 7833574.5000 (6369798.7561)  loss/pix_loss: 0.1764 (0.1698)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [ 50/862]  eta: 0:56:58  lr: 0.000100  loss/low_gen_loss: 1.9676 (1.9669)  loss/high_gen_loss: 9904540.0000 (7158124.9412)  loss/pix_loss: 0.1739 (0.1681)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1881  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [ 60/862]  eta: 0:56:13  lr: 0.000100  loss/low_gen_loss: 1.9723 (1.9683)  loss/high_gen_loss: 11804824.0000 (8962496.6721)  loss/pix_loss: 0.1632 (0.1679)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [ 70/862]  eta: 0:55:29  lr: 0.000100  loss/low_gen_loss: 1.9735 (1.9688)  loss/high_gen_loss: 21535450.0000 (11391259.9859)  loss/pix_loss: 0.1672 (0.1674)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1878  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [ 80/862]  eta: 0:54:45  lr: 0.000100  loss/low_gen_loss: 1.9720 (1.9695)  loss/high_gen_loss: 25234654.0000 (12522900.3457)  loss/pix_loss: 0.1640 (0.1649)  loss/enc_loss: 0.0004 (0.0003)  time: 4.1883  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [ 90/862]  eta: 0:54:02  lr: 0.000100  loss/low_gen_loss: 1.9782 (1.9710)  loss/high_gen_loss: 12765395.0000 (12177199.8187)  loss/pix_loss: 0.1545 (0.1652)  loss/enc_loss: 0.0004 (0.0003)  time: 4.1885  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [100/862]  eta: 0:53:19  lr: 0.000100  loss/low_gen_loss: 1.9764 (1.9714)  loss/high_gen_loss: 7264927.5000 (11626524.6733)  loss/pix_loss: 0.1658 (0.1652)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1885  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [110/862]  eta: 0:52:37  lr: 0.000100  loss/low_gen_loss: 1.9741 (1.9716)  loss/high_gen_loss: 5640076.5000 (11063422.9054)  loss/pix_loss: 0.1636 (0.1649)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1880  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [120/862]  eta: 0:51:54  lr: 0.000100  loss/low_gen_loss: 1.9752 (1.9721)  loss/high_gen_loss: 5019939.5000 (10487713.6921)  loss/pix_loss: 0.1670 (0.1660)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [130/862]  eta: 0:51:11  lr: 0.000100  loss/low_gen_loss: 1.9735 (1.9720)  loss/high_gen_loss: 3856266.5000 (9991823.7595)  loss/pix_loss: 0.1741 (0.1670)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [140/862]  eta: 0:50:29  lr: 0.000100  loss/low_gen_loss: 1.9669 (1.9714)  loss/high_gen_loss: 4878988.5000 (9736700.7021)  loss/pix_loss: 0.1696 (0.1668)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [150/862]  eta: 0:49:47  lr: 0.000100  loss/low_gen_loss: 1.9655 (1.9711)  loss/high_gen_loss: 7045836.0000 (9584742.7550)  loss/pix_loss: 0.1543 (0.1654)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [160/862]  eta: 0:49:04  lr: 0.000100  loss/low_gen_loss: 1.9674 (1.9710)  loss/high_gen_loss: 5307369.5000 (9237045.7904)  loss/pix_loss: 0.1535 (0.1648)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1880  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [170/862]  eta: 0:48:22  lr: 0.000100  loss/low_gen_loss: 1.9680 (1.9708)  loss/high_gen_loss: 2749629.7500 (8837963.2639)  loss/pix_loss: 0.1547 (0.1645)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [180/862]  eta: 0:47:40  lr: 0.000100  loss/low_gen_loss: 1.9709 (1.9709)  loss/high_gen_loss: 1969465.1250 (8430100.2065)  loss/pix_loss: 0.1738 (0.1659)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [190/862]  eta: 0:46:58  lr: 0.000100  loss/low_gen_loss: 1.9696 (1.9708)  loss/high_gen_loss: 1229399.2500 (8050160.6872)  loss/pix_loss: 0.1880 (0.1667)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1911  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [200/862]  eta: 0:46:16  lr: 0.000100  loss/low_gen_loss: 1.9661 (1.9703)  loss/high_gen_loss: 1117704.0000 (7695439.3312)  loss/pix_loss: 0.1810 (0.1672)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1910  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [210/862]  eta: 0:45:34  lr: 0.000100  loss/low_gen_loss: 1.9534 (1.9691)  loss/high_gen_loss: 441801.9688 (7340306.9274)  loss/pix_loss: 0.1730 (0.1673)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [220/862]  eta: 0:44:52  lr: 0.000100  loss/low_gen_loss: 1.9522 (1.9685)  loss/high_gen_loss: 132904.2812 (7015801.1657)  loss/pix_loss: 0.1723 (0.1669)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [230/862]  eta: 0:44:09  lr: 0.000100  loss/low_gen_loss: 1.9609 (1.9686)  loss/high_gen_loss: 361743.9375 (6758092.3186)  loss/pix_loss: 0.1666 (0.1666)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [240/862]  eta: 0:43:27  lr: 0.000100  loss/low_gen_loss: 1.9710 (1.9687)  loss/high_gen_loss: 1470883.5000 (6547511.2576)  loss/pix_loss: 0.1621 (0.1663)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [250/862]  eta: 0:42:45  lr: 0.000100  loss/low_gen_loss: 1.9723 (1.9688)  loss/high_gen_loss: 1660229.2500 (6347173.4874)  loss/pix_loss: 0.1552 (0.1659)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [260/862]  eta: 0:42:03  lr: 0.000100  loss/low_gen_loss: 1.9744 (1.9692)  loss/high_gen_loss: 1794790.5000 (6356746.9644)  loss/pix_loss: 0.1523 (0.1653)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [270/862]  eta: 0:41:21  lr: 0.000100  loss/low_gen_loss: 1.9756 (1.9693)  loss/high_gen_loss: 7607256.0000 (6608932.7425)  loss/pix_loss: 0.1637 (0.1659)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [280/862]  eta: 0:40:39  lr: 0.000100  loss/low_gen_loss: 1.9704 (1.9693)  loss/high_gen_loss: 6553974.5000 (7003588.6733)  loss/pix_loss: 0.1813 (0.1658)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [290/862]  eta: 0:39:57  lr: 0.000100  loss/low_gen_loss: 1.9710 (1.9696)  loss/high_gen_loss: 44516308.0000 (15671821.5712)  loss/pix_loss: 0.1701 (0.1660)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [300/862]  eta: 0:39:15  lr: 0.000100  loss/low_gen_loss: 1.9769 (1.9698)  loss/high_gen_loss: 182626768.0000 (28871644.6020)  loss/pix_loss: 0.1504 (0.1654)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1894  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [310/862]  eta: 0:38:34  lr: 0.000100  loss/low_gen_loss: 1.9759 (1.9699)  loss/high_gen_loss: 425060768.0000 (52150879.5409)  loss/pix_loss: 0.1410 (0.1648)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1935  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [320/862]  eta: 0:37:52  lr: 0.000100  loss/low_gen_loss: 1.9727 (1.9700)  loss/high_gen_loss: 1172035968.0000 (103854390.6829)  loss/pix_loss: 0.1535 (0.1648)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1928  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [330/862]  eta: 0:37:10  lr: 0.000100  loss/low_gen_loss: 1.9727 (1.9702)  loss/high_gen_loss: 1487577728.0000 (142298139.8949)  loss/pix_loss: 0.1570 (0.1647)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [340/862]  eta: 0:36:28  lr: 0.000100  loss/low_gen_loss: 1.9789 (1.9706)  loss/high_gen_loss: 2085368192.0000 (239396236.0622)  loss/pix_loss: 0.1603 (0.1644)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [350/862]  eta: 0:35:46  lr: 0.000100  loss/low_gen_loss: 1.9885 (1.9711)  loss/high_gen_loss: 1751168768.0000 (259611096.2086)  loss/pix_loss: 0.1646 (0.1643)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1901  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [360/862]  eta: 0:35:04  lr: 0.000100  loss/low_gen_loss: 1.9878 (1.9715)  loss/high_gen_loss: 1260430336.0000 (299069173.3219)  loss/pix_loss: 0.1727 (0.1648)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1906  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [370/862]  eta: 0:34:22  lr: 0.000100  loss/low_gen_loss: 1.9801 (1.9716)  loss/high_gen_loss: 923946048.0000 (313813987.6259)  loss/pix_loss: 0.1727 (0.1647)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1886  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [380/862]  eta: 0:33:40  lr: 0.000100  loss/low_gen_loss: 1.9767 (1.9717)  loss/high_gen_loss: 135402112.0000 (306538713.7079)  loss/pix_loss: 0.1647 (0.1647)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1877  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [390/862]  eta: 0:32:58  lr: 0.000100  loss/low_gen_loss: 1.9777 (1.9720)  loss/high_gen_loss: 30891848.0000 (301466224.8612)  loss/pix_loss: 0.1665 (0.1646)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [400/862]  eta: 0:32:16  lr: 0.000100  loss/low_gen_loss: 1.9793 (1.9721)  loss/high_gen_loss: 286437504.0000 (312005724.7300)  loss/pix_loss: 0.1665 (0.1645)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [410/862]  eta: 0:31:34  lr: 0.000100  loss/low_gen_loss: 1.9761 (1.9722)  loss/high_gen_loss: 1185441024.0000 (337873656.9944)  loss/pix_loss: 0.1652 (0.1646)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1913  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [420/862]  eta: 0:30:52  lr: 0.000100  loss/low_gen_loss: 1.9806 (1.9724)  loss/high_gen_loss: 1081710464.0000 (348636895.1656)  loss/pix_loss: 0.1652 (0.1647)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1909  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [430/862]  eta: 0:30:10  lr: 0.000100  loss/low_gen_loss: 1.9721 (1.9724)  loss/high_gen_loss: 876007744.0000 (362995850.0991)  loss/pix_loss: 0.1620 (0.1647)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [440/862]  eta: 0:29:28  lr: 0.000100  loss/low_gen_loss: 1.9711 (1.9724)  loss/high_gen_loss: 701276992.0000 (366606528.0016)  loss/pix_loss: 0.1647 (0.1648)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [450/862]  eta: 0:28:46  lr: 0.000100  loss/low_gen_loss: 1.9742 (1.9723)  loss/high_gen_loss: 457452384.0000 (366086728.0193)  loss/pix_loss: 0.1804 (0.1650)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [460/862]  eta: 0:28:04  lr: 0.000100  loss/low_gen_loss: 1.9563 (1.9719)  loss/high_gen_loss: 287063456.0000 (364244774.0406)  loss/pix_loss: 0.1720 (0.1651)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1883  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [470/862]  eta: 0:27:22  lr: 0.000100  loss/low_gen_loss: 1.9549 (1.9716)  loss/high_gen_loss: 293412352.0000 (363819001.9548)  loss/pix_loss: 0.1638 (0.1651)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [480/862]  eta: 0:26:41  lr: 0.000100  loss/low_gen_loss: 1.9785 (1.9718)  loss/high_gen_loss: 348572832.0000 (362886548.8580)  loss/pix_loss: 0.1675 (0.1651)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [490/862]  eta: 0:25:59  lr: 0.000100  loss/low_gen_loss: 1.9816 (1.9720)  loss/high_gen_loss: 187990016.0000 (358803989.6063)  loss/pix_loss: 0.1680 (0.1650)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [500/862]  eta: 0:25:17  lr: 0.000100  loss/low_gen_loss: 1.9826 (1.9723)  loss/high_gen_loss: 141998016.0000 (353715942.0214)  loss/pix_loss: 0.1659 (0.1649)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [510/862]  eta: 0:24:35  lr: 0.000100  loss/low_gen_loss: 1.9822 (1.9724)  loss/high_gen_loss: 91522800.0000 (348991978.1775)  loss/pix_loss: 0.1691 (0.1651)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [520/862]  eta: 0:23:53  lr: 0.000100  loss/low_gen_loss: 1.9777 (1.9725)  loss/high_gen_loss: 153277936.0000 (345636802.1204)  loss/pix_loss: 0.1765 (0.1653)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1866  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [530/862]  eta: 0:23:11  lr: 0.000100  loss/low_gen_loss: 1.9732 (1.9724)  loss/high_gen_loss: 165263296.0000 (342257239.6247)  loss/pix_loss: 0.1650 (0.1652)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [540/862]  eta: 0:22:29  lr: 0.000100  loss/low_gen_loss: 1.9637 (1.9720)  loss/high_gen_loss: 165263296.0000 (339046837.9754)  loss/pix_loss: 0.1573 (0.1654)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [550/862]  eta: 0:21:47  lr: 0.000100  loss/low_gen_loss: 1.9467 (1.9715)  loss/high_gen_loss: 107936048.0000 (334419117.0975)  loss/pix_loss: 0.1849 (0.1658)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [560/862]  eta: 0:21:05  lr: 0.000100  loss/low_gen_loss: 1.9571 (1.9713)  loss/high_gen_loss: 84886512.0000 (330540481.2419)  loss/pix_loss: 0.1779 (0.1659)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [570/862]  eta: 0:20:23  lr: 0.000100  loss/low_gen_loss: 1.9644 (1.9714)  loss/high_gen_loss: 90002128.0000 (326399472.8419)  loss/pix_loss: 0.1734 (0.1663)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [580/862]  eta: 0:19:41  lr: 0.000100  loss/low_gen_loss: 1.9498 (1.9709)  loss/high_gen_loss: 106115128.0000 (323104867.5813)  loss/pix_loss: 0.1747 (0.1662)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1849  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [590/862]  eta: 0:18:59  lr: 0.000100  loss/low_gen_loss: 1.9441 (1.9706)  loss/high_gen_loss: 114367488.0000 (319395025.6391)  loss/pix_loss: 0.1659 (0.1662)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [600/862]  eta: 0:18:17  lr: 0.000100  loss/low_gen_loss: 1.9607 (1.9704)  loss/high_gen_loss: 123477632.0000 (317468828.2874)  loss/pix_loss: 0.1693 (0.1662)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1878  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [610/862]  eta: 0:17:35  lr: 0.000100  loss/low_gen_loss: 1.9581 (1.9701)  loss/high_gen_loss: 179789440.0000 (315278052.0470)  loss/pix_loss: 0.1669 (0.1663)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [620/862]  eta: 0:16:54  lr: 0.000100  loss/low_gen_loss: 1.9471 (1.9697)  loss/high_gen_loss: 173147168.0000 (312865104.1557)  loss/pix_loss: 0.1735 (0.1665)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1869  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [630/862]  eta: 0:16:12  lr: 0.000100  loss/low_gen_loss: 1.9436 (1.9694)  loss/high_gen_loss: 131049456.0000 (309861745.2690)  loss/pix_loss: 0.1713 (0.1663)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [640/862]  eta: 0:15:30  lr: 0.000100  loss/low_gen_loss: 1.9737 (1.9695)  loss/high_gen_loss: 100866696.0000 (305893592.7936)  loss/pix_loss: 0.1586 (0.1663)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1859  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [650/862]  eta: 0:14:48  lr: 0.000100  loss/low_gen_loss: 1.9682 (1.9692)  loss/high_gen_loss: 68189432.0000 (302605933.4635)  loss/pix_loss: 0.1745 (0.1665)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [660/862]  eta: 0:14:06  lr: 0.000100  loss/low_gen_loss: 1.9461 (1.9688)  loss/high_gen_loss: 53265636.0000 (298625060.4126)  loss/pix_loss: 0.1571 (0.1662)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [670/862]  eta: 0:13:24  lr: 0.000100  loss/low_gen_loss: 1.9436 (1.9684)  loss/high_gen_loss: 62879844.0000 (295615278.6717)  loss/pix_loss: 0.1571 (0.1664)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [680/862]  eta: 0:12:42  lr: 0.000100  loss/low_gen_loss: 1.9449 (1.9682)  loss/high_gen_loss: 95841576.0000 (292716584.4768)  loss/pix_loss: 0.1797 (0.1664)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1848  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [690/862]  eta: 0:12:00  lr: 0.000100  loss/low_gen_loss: 1.9591 (1.9682)  loss/high_gen_loss: 90278520.0000 (289639215.1732)  loss/pix_loss: 0.1761 (0.1666)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [700/862]  eta: 0:11:18  lr: 0.000100  loss/low_gen_loss: 1.9703 (1.9682)  loss/high_gen_loss: 84841744.0000 (287031319.8527)  loss/pix_loss: 0.1704 (0.1665)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [710/862]  eta: 0:10:36  lr: 0.000100  loss/low_gen_loss: 1.9704 (1.9683)  loss/high_gen_loss: 126464104.0000 (284955485.0868)  loss/pix_loss: 0.1669 (0.1667)  loss/enc_loss: 0.0003 (0.0003)  time: 4.1874  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [720/862]  eta: 0:09:54  lr: 0.000100  loss/low_gen_loss: 1.9707 (1.9683)  loss/high_gen_loss: 99419480.0000 (282263361.0995)  loss/pix_loss: 0.1730 (0.1667)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1866  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [730/862]  eta: 0:09:13  lr: 0.000100  loss/low_gen_loss: 1.9728 (1.9683)  loss/high_gen_loss: 109453096.0000 (280288039.0051)  loss/pix_loss: 0.1647 (0.1668)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [740/862]  eta: 0:08:31  lr: 0.000100  loss/low_gen_loss: 1.9631 (1.9682)  loss/high_gen_loss: 95961080.0000 (277403772.1521)  loss/pix_loss: 0.1641 (0.1667)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [750/862]  eta: 0:07:49  lr: 0.000100  loss/low_gen_loss: 1.9618 (1.9682)  loss/high_gen_loss: 68443872.0000 (274717010.6001)  loss/pix_loss: 0.1646 (0.1667)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [760/862]  eta: 0:07:07  lr: 0.000100  loss/low_gen_loss: 1.9620 (1.9681)  loss/high_gen_loss: 75146872.0000 (272139129.6461)  loss/pix_loss: 0.1646 (0.1666)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [770/862]  eta: 0:06:25  lr: 0.000100  loss/low_gen_loss: 1.9562 (1.9677)  loss/high_gen_loss: 80796152.0000 (269717290.5690)  loss/pix_loss: 0.1580 (0.1664)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1916  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [780/862]  eta: 0:05:43  lr: 0.000100  loss/low_gen_loss: 1.9229 (1.9671)  loss/high_gen_loss: 61956092.0000 (266927500.2211)  loss/pix_loss: 0.1570 (0.1663)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1939  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [790/862]  eta: 0:05:01  lr: 0.000100  loss/low_gen_loss: 1.9246 (1.9667)  loss/high_gen_loss: 54060260.0000 (264343804.5369)  loss/pix_loss: 0.1594 (0.1662)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1903  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [800/862]  eta: 0:04:19  lr: 0.000100  loss/low_gen_loss: 1.9492 (1.9667)  loss/high_gen_loss: 50067584.0000 (261486070.9547)  loss/pix_loss: 0.1736 (0.1664)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1899  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.9653 (1.9667)  loss/high_gen_loss: 36460356.0000 (258731234.1562)  loss/pix_loss: 0.1753 (0.1666)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.9672 (1.9667)  loss/high_gen_loss: 50033796.0000 (256449616.6586)  loss/pix_loss: 0.1639 (0.1664)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1908  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [830/862]  eta: 0:02:14  lr: 0.000100  loss/low_gen_loss: 1.9702 (1.9668)  loss/high_gen_loss: 92565088.0000 (254637132.4533)  loss/pix_loss: 0.1582 (0.1664)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1910  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.9720 (1.9668)  loss/high_gen_loss: 114539664.0000 (253430157.3897)  loss/pix_loss: 0.1659 (0.1664)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1906  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.9730 (1.9669)  loss/high_gen_loss: 146172096.0000 (252185778.8634)  loss/pix_loss: 0.1674 (0.1665)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1905  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.9730 (1.9669)  loss/high_gen_loss: 186858464.0000 (252446148.8556)  loss/pix_loss: 0.1687 (0.1665)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1909  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.9714 (1.9669)  loss/high_gen_loss: 186858464.0000 (252343403.0310)  loss/pix_loss: 0.1707 (0.1665)  loss/enc_loss: 0.0002 (0.0003)  time: 4.1909  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:14] Total time: 1:00:11 (4.1899 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.9714 (1.9669)  loss/high_gen_loss: 186858464.0000 (252343403.0310)  loss/pix_loss: 0.1707 (0.1665)  loss/enc_loss: 0.0002 (0.0003)\n",
      "Valid: [epoch:14]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1242 (0.1242)  time: 2.9977  data: 0.3681  max mem: 31350\n",
      "Valid: [epoch:14]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6219  data: 0.0264  max mem: 31350\n",
      "Valid: [epoch:14] Total time: 0:00:36 (2.6294 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_14_input_n_20.png\n",
      "Train: [epoch:15]  [  0/862]  eta: 1:15:35  lr: 0.000100  loss/low_gen_loss: 1.9699 (1.9699)  loss/high_gen_loss: 146292848.0000 (146292848.0000)  loss/pix_loss: 0.1623 (0.1623)  loss/enc_loss: 0.0002 (0.0002)  time: 5.2616  data: 1.1020  max mem: 31350\n",
      "Train: [epoch:15]  [ 10/862]  eta: 1:00:31  lr: 0.000100  loss/low_gen_loss: 1.9717 (1.9717)  loss/high_gen_loss: 131728432.0000 (136996961.4545)  loss/pix_loss: 0.1654 (0.1706)  loss/enc_loss: 0.0002 (0.0002)  time: 4.2628  data: 0.1003  max mem: 31350\n",
      "Train: [epoch:15]  [ 20/862]  eta: 0:59:11  lr: 0.000100  loss/low_gen_loss: 1.9682 (1.9691)  loss/high_gen_loss: 132334240.0000 (140541209.9048)  loss/pix_loss: 0.1671 (0.1735)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1656  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [ 30/862]  eta: 0:58:23  lr: 0.000100  loss/low_gen_loss: 1.9644 (1.9653)  loss/high_gen_loss: 158901312.0000 (157884104.2581)  loss/pix_loss: 0.1671 (0.1689)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1817  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [ 40/862]  eta: 0:57:36  lr: 0.000100  loss/low_gen_loss: 1.9561 (1.9631)  loss/high_gen_loss: 150256080.0000 (149373299.5122)  loss/pix_loss: 0.1726 (0.1727)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1913  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [ 50/862]  eta: 0:56:51  lr: 0.000100  loss/low_gen_loss: 1.9550 (1.9613)  loss/high_gen_loss: 121330808.0000 (146336037.4902)  loss/pix_loss: 0.1714 (0.1700)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [ 60/862]  eta: 0:56:07  lr: 0.000100  loss/low_gen_loss: 1.9531 (1.9582)  loss/high_gen_loss: 135727168.0000 (145136985.5738)  loss/pix_loss: 0.1608 (0.1693)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [ 70/862]  eta: 0:55:24  lr: 0.000100  loss/low_gen_loss: 1.9297 (1.9538)  loss/high_gen_loss: 103688560.0000 (135762953.6338)  loss/pix_loss: 0.1623 (0.1694)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [ 80/862]  eta: 0:54:41  lr: 0.000100  loss/low_gen_loss: 1.9316 (1.9520)  loss/high_gen_loss: 75092704.0000 (128207770.1728)  loss/pix_loss: 0.1623 (0.1677)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [ 90/862]  eta: 0:53:59  lr: 0.000100  loss/low_gen_loss: 1.9438 (1.9525)  loss/high_gen_loss: 89635072.0000 (125923309.3626)  loss/pix_loss: 0.1649 (0.1675)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1885  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [100/862]  eta: 0:53:16  lr: 0.000100  loss/low_gen_loss: 1.9596 (1.9533)  loss/high_gen_loss: 106058640.0000 (124956172.1188)  loss/pix_loss: 0.1700 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [110/862]  eta: 0:52:34  lr: 0.000100  loss/low_gen_loss: 1.9553 (1.9531)  loss/high_gen_loss: 131417496.0000 (128026751.1351)  loss/pix_loss: 0.1639 (0.1670)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [120/862]  eta: 0:51:52  lr: 0.000100  loss/low_gen_loss: 1.9492 (1.9525)  loss/high_gen_loss: 118638560.0000 (123433402.3471)  loss/pix_loss: 0.1660 (0.1674)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [130/862]  eta: 0:51:09  lr: 0.000100  loss/low_gen_loss: 1.9374 (1.9508)  loss/high_gen_loss: 47490072.0000 (117498592.6107)  loss/pix_loss: 0.1692 (0.1678)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1885  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [140/862]  eta: 0:50:27  lr: 0.000100  loss/low_gen_loss: 1.9291 (1.9491)  loss/high_gen_loss: 50109440.0000 (115030832.3972)  loss/pix_loss: 0.1692 (0.1678)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1878  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [150/862]  eta: 0:49:45  lr: 0.000100  loss/low_gen_loss: 1.9379 (1.9500)  loss/high_gen_loss: 109803280.0000 (116217688.9007)  loss/pix_loss: 0.1676 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1880  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [160/862]  eta: 0:49:03  lr: 0.000100  loss/low_gen_loss: 1.9570 (1.9503)  loss/high_gen_loss: 96673968.0000 (114338554.5342)  loss/pix_loss: 0.1558 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [170/862]  eta: 0:48:21  lr: 0.000100  loss/low_gen_loss: 1.9596 (1.9511)  loss/high_gen_loss: 101735672.0000 (115835351.0643)  loss/pix_loss: 0.1619 (0.1666)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [180/862]  eta: 0:47:39  lr: 0.000100  loss/low_gen_loss: 1.9556 (1.9510)  loss/high_gen_loss: 136450416.0000 (117402759.6464)  loss/pix_loss: 0.1741 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [190/862]  eta: 0:46:56  lr: 0.000100  loss/low_gen_loss: 1.9548 (1.9516)  loss/high_gen_loss: 118042896.0000 (115916034.0733)  loss/pix_loss: 0.1828 (0.1679)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [200/862]  eta: 0:46:14  lr: 0.000100  loss/low_gen_loss: 1.9632 (1.9522)  loss/high_gen_loss: 41560264.0000 (111256848.2836)  loss/pix_loss: 0.1790 (0.1683)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [210/862]  eta: 0:45:32  lr: 0.000100  loss/low_gen_loss: 1.9701 (1.9535)  loss/high_gen_loss: 21511438.0000 (107875373.9763)  loss/pix_loss: 0.1721 (0.1681)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [220/862]  eta: 0:44:50  lr: 0.000100  loss/low_gen_loss: 1.9786 (1.9546)  loss/high_gen_loss: 45114096.0000 (106508440.3665)  loss/pix_loss: 0.1533 (0.1674)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [230/862]  eta: 0:44:08  lr: 0.000100  loss/low_gen_loss: 1.9783 (1.9556)  loss/high_gen_loss: 135222736.0000 (110258010.1515)  loss/pix_loss: 0.1626 (0.1674)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [240/862]  eta: 0:43:26  lr: 0.000100  loss/low_gen_loss: 1.9709 (1.9562)  loss/high_gen_loss: 171174912.0000 (112802092.5187)  loss/pix_loss: 0.1649 (0.1677)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1908  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [250/862]  eta: 0:42:45  lr: 0.000100  loss/low_gen_loss: 1.9673 (1.9562)  loss/high_gen_loss: 164225248.0000 (114569657.4064)  loss/pix_loss: 0.1649 (0.1677)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1897  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [260/862]  eta: 0:42:03  lr: 0.000100  loss/low_gen_loss: 1.9634 (1.9566)  loss/high_gen_loss: 155807168.0000 (116586870.9310)  loss/pix_loss: 0.1639 (0.1675)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [270/862]  eta: 0:41:21  lr: 0.000100  loss/low_gen_loss: 1.9691 (1.9571)  loss/high_gen_loss: 108017152.0000 (115612166.3506)  loss/pix_loss: 0.1641 (0.1678)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [280/862]  eta: 0:40:39  lr: 0.000100  loss/low_gen_loss: 1.9693 (1.9573)  loss/high_gen_loss: 90586000.0000 (115052386.8790)  loss/pix_loss: 0.1708 (0.1678)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1902  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [290/862]  eta: 0:39:57  lr: 0.000100  loss/low_gen_loss: 1.9556 (1.9572)  loss/high_gen_loss: 85035128.0000 (113572423.9072)  loss/pix_loss: 0.1686 (0.1679)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1904  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [300/862]  eta: 0:39:15  lr: 0.000100  loss/low_gen_loss: 1.9551 (1.9571)  loss/high_gen_loss: 81482096.0000 (113662208.1495)  loss/pix_loss: 0.1592 (0.1670)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1902  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [310/862]  eta: 0:38:33  lr: 0.000100  loss/low_gen_loss: 1.9563 (1.9573)  loss/high_gen_loss: 90373224.0000 (112690804.2219)  loss/pix_loss: 0.1625 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1899  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [320/862]  eta: 0:37:51  lr: 0.000100  loss/low_gen_loss: 1.9750 (1.9580)  loss/high_gen_loss: 112910504.0000 (113596996.0903)  loss/pix_loss: 0.1645 (0.1666)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1899  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [330/862]  eta: 0:37:09  lr: 0.000100  loss/low_gen_loss: 1.9755 (1.9584)  loss/high_gen_loss: 97784304.0000 (112848412.4260)  loss/pix_loss: 0.1650 (0.1662)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1903  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [340/862]  eta: 0:36:27  lr: 0.000100  loss/low_gen_loss: 1.9702 (1.9587)  loss/high_gen_loss: 83273288.0000 (111672653.5865)  loss/pix_loss: 0.1539 (0.1660)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [350/862]  eta: 0:35:45  lr: 0.000100  loss/low_gen_loss: 1.9649 (1.9587)  loss/high_gen_loss: 66999452.0000 (110181804.0826)  loss/pix_loss: 0.1513 (0.1656)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [360/862]  eta: 0:35:03  lr: 0.000100  loss/low_gen_loss: 1.9634 (1.9588)  loss/high_gen_loss: 55621896.0000 (108641493.8476)  loss/pix_loss: 0.1567 (0.1659)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1888  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [370/862]  eta: 0:34:21  lr: 0.000100  loss/low_gen_loss: 1.9645 (1.9591)  loss/high_gen_loss: 52527920.0000 (107078224.0135)  loss/pix_loss: 0.1750 (0.1659)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [380/862]  eta: 0:33:39  lr: 0.000100  loss/low_gen_loss: 1.9664 (1.9592)  loss/high_gen_loss: 80289688.0000 (106701753.6929)  loss/pix_loss: 0.1792 (0.1662)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1869  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [390/862]  eta: 0:32:57  lr: 0.000100  loss/low_gen_loss: 1.9650 (1.9594)  loss/high_gen_loss: 88204304.0000 (106044890.4373)  loss/pix_loss: 0.1697 (0.1661)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1860  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [400/862]  eta: 0:32:15  lr: 0.000100  loss/low_gen_loss: 1.9684 (1.9596)  loss/high_gen_loss: 79414080.0000 (105829757.7282)  loss/pix_loss: 0.1650 (0.1662)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [410/862]  eta: 0:31:33  lr: 0.000100  loss/low_gen_loss: 1.9641 (1.9597)  loss/high_gen_loss: 84571248.0000 (105484582.8540)  loss/pix_loss: 0.1655 (0.1660)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [420/862]  eta: 0:30:52  lr: 0.000100  loss/low_gen_loss: 1.9633 (1.9597)  loss/high_gen_loss: 92357920.0000 (106904123.9169)  loss/pix_loss: 0.1571 (0.1658)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [430/862]  eta: 0:30:10  lr: 0.000100  loss/low_gen_loss: 1.9572 (1.9596)  loss/high_gen_loss: 233787712.0000 (111283348.9582)  loss/pix_loss: 0.1571 (0.1657)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [440/862]  eta: 0:29:28  lr: 0.000100  loss/low_gen_loss: 1.9536 (1.9594)  loss/high_gen_loss: 250605968.0000 (114075355.1950)  loss/pix_loss: 0.1660 (0.1657)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [450/862]  eta: 0:28:46  lr: 0.000100  loss/low_gen_loss: 1.9483 (1.9592)  loss/high_gen_loss: 160361360.0000 (114105562.5920)  loss/pix_loss: 0.1673 (0.1655)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [460/862]  eta: 0:28:04  lr: 0.000100  loss/low_gen_loss: 1.9485 (1.9590)  loss/high_gen_loss: 63080132.0000 (112463078.2668)  loss/pix_loss: 0.1635 (0.1655)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1852  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [470/862]  eta: 0:27:22  lr: 0.000100  loss/low_gen_loss: 1.9500 (1.9588)  loss/high_gen_loss: 37080768.0000 (111346918.6603)  loss/pix_loss: 0.1665 (0.1655)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1837  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [480/862]  eta: 0:26:40  lr: 0.000100  loss/low_gen_loss: 1.9492 (1.9587)  loss/high_gen_loss: 99672888.0000 (111869840.8836)  loss/pix_loss: 0.1656 (0.1656)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [490/862]  eta: 0:25:58  lr: 0.000100  loss/low_gen_loss: 1.9553 (1.9587)  loss/high_gen_loss: 99137496.0000 (111490976.0835)  loss/pix_loss: 0.1595 (0.1655)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [500/862]  eta: 0:25:16  lr: 0.000100  loss/low_gen_loss: 1.9553 (1.9585)  loss/high_gen_loss: 83381688.0000 (110510912.7365)  loss/pix_loss: 0.1515 (0.1653)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [510/862]  eta: 0:24:34  lr: 0.000100  loss/low_gen_loss: 1.9539 (1.9586)  loss/high_gen_loss: 56756380.0000 (109586007.4775)  loss/pix_loss: 0.1640 (0.1655)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [520/862]  eta: 0:23:52  lr: 0.000100  loss/low_gen_loss: 1.9802 (1.9591)  loss/high_gen_loss: 68686752.0000 (108821525.2917)  loss/pix_loss: 0.1822 (0.1658)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1850  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [530/862]  eta: 0:23:10  lr: 0.000100  loss/low_gen_loss: 1.9875 (1.9596)  loss/high_gen_loss: 71377680.0000 (108432974.8493)  loss/pix_loss: 0.1657 (0.1656)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [540/862]  eta: 0:22:28  lr: 0.000100  loss/low_gen_loss: 1.9808 (1.9599)  loss/high_gen_loss: 167973264.0000 (110174119.8318)  loss/pix_loss: 0.1675 (0.1659)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [550/862]  eta: 0:21:46  lr: 0.000100  loss/low_gen_loss: 1.9645 (1.9599)  loss/high_gen_loss: 207581680.0000 (113443836.3067)  loss/pix_loss: 0.1811 (0.1662)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [560/862]  eta: 0:21:05  lr: 0.000100  loss/low_gen_loss: 1.9639 (1.9601)  loss/high_gen_loss: 273481344.0000 (116724082.8182)  loss/pix_loss: 0.1667 (0.1660)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1860  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [570/862]  eta: 0:20:23  lr: 0.000100  loss/low_gen_loss: 1.9624 (1.9601)  loss/high_gen_loss: 175426384.0000 (117086781.3047)  loss/pix_loss: 0.1677 (0.1663)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [580/862]  eta: 0:19:41  lr: 0.000100  loss/low_gen_loss: 1.9585 (1.9601)  loss/high_gen_loss: 57425100.0000 (115574287.7126)  loss/pix_loss: 0.1726 (0.1662)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [590/862]  eta: 0:18:59  lr: 0.000100  loss/low_gen_loss: 1.9523 (1.9599)  loss/high_gen_loss: 57425100.0000 (117663101.5110)  loss/pix_loss: 0.1557 (0.1658)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [600/862]  eta: 0:18:17  lr: 0.000100  loss/low_gen_loss: 1.9467 (1.9596)  loss/high_gen_loss: 377524288.0000 (127223773.6589)  loss/pix_loss: 0.1520 (0.1657)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [610/862]  eta: 0:17:35  lr: 0.000100  loss/low_gen_loss: 1.9443 (1.9593)  loss/high_gen_loss: 967943808.0000 (142424172.8854)  loss/pix_loss: 0.1739 (0.1660)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1850  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [620/862]  eta: 0:16:53  lr: 0.000100  loss/low_gen_loss: 1.9232 (1.9585)  loss/high_gen_loss: 1081811200.0000 (158465505.9597)  loss/pix_loss: 0.1773 (0.1661)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [630/862]  eta: 0:16:11  lr: 0.000100  loss/low_gen_loss: 1.9283 (1.9583)  loss/high_gen_loss: 1034349248.0000 (168857450.6006)  loss/pix_loss: 0.1616 (0.1660)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [640/862]  eta: 0:15:29  lr: 0.000100  loss/low_gen_loss: 1.9618 (1.9585)  loss/high_gen_loss: 540810304.0000 (173695275.5835)  loss/pix_loss: 0.1564 (0.1660)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [650/862]  eta: 0:14:47  lr: 0.000100  loss/low_gen_loss: 1.9576 (1.9582)  loss/high_gen_loss: 319583296.0000 (173789590.5637)  loss/pix_loss: 0.1739 (0.1662)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [660/862]  eta: 0:14:06  lr: 0.000100  loss/low_gen_loss: 1.9307 (1.9578)  loss/high_gen_loss: 180686896.0000 (174103778.4221)  loss/pix_loss: 0.1780 (0.1663)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [670/862]  eta: 0:13:24  lr: 0.000100  loss/low_gen_loss: 1.9229 (1.9572)  loss/high_gen_loss: 165731360.0000 (173678444.3651)  loss/pix_loss: 0.1780 (0.1664)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [680/862]  eta: 0:12:42  lr: 0.000100  loss/low_gen_loss: 1.9118 (1.9564)  loss/high_gen_loss: 99227048.0000 (172159412.9354)  loss/pix_loss: 0.1696 (0.1663)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [690/862]  eta: 0:12:00  lr: 0.000100  loss/low_gen_loss: 1.9231 (1.9562)  loss/high_gen_loss: 124268304.0000 (173656164.2156)  loss/pix_loss: 0.1708 (0.1666)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [700/862]  eta: 0:11:18  lr: 0.000100  loss/low_gen_loss: 1.9610 (1.9563)  loss/high_gen_loss: 407245568.0000 (178509124.4294)  loss/pix_loss: 0.1720 (0.1665)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [710/862]  eta: 0:10:36  lr: 0.000100  loss/low_gen_loss: 1.9554 (1.9562)  loss/high_gen_loss: 496055904.0000 (182420351.3713)  loss/pix_loss: 0.1742 (0.1667)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [720/862]  eta: 0:09:54  lr: 0.000100  loss/low_gen_loss: 1.9374 (1.9558)  loss/high_gen_loss: 344770112.0000 (182620506.3981)  loss/pix_loss: 0.1782 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [730/862]  eta: 0:09:12  lr: 0.000100  loss/low_gen_loss: 1.9275 (1.9554)  loss/high_gen_loss: 170100240.0000 (183068835.1970)  loss/pix_loss: 0.1773 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1845  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [740/862]  eta: 0:08:30  lr: 0.000100  loss/low_gen_loss: 1.9259 (1.9549)  loss/high_gen_loss: 342771520.0000 (185774369.4265)  loss/pix_loss: 0.1686 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1845  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [750/862]  eta: 0:07:49  lr: 0.000100  loss/low_gen_loss: 1.9323 (1.9547)  loss/high_gen_loss: 403182560.0000 (188997596.3369)  loss/pix_loss: 0.1686 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [760/862]  eta: 0:07:07  lr: 0.000100  loss/low_gen_loss: 1.9375 (1.9546)  loss/high_gen_loss: 376998112.0000 (189475053.0368)  loss/pix_loss: 0.1717 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [770/862]  eta: 0:06:25  lr: 0.000100  loss/low_gen_loss: 1.9487 (1.9545)  loss/high_gen_loss: 163208736.0000 (189011907.1764)  loss/pix_loss: 0.1761 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [780/862]  eta: 0:05:43  lr: 0.000100  loss/low_gen_loss: 1.9500 (1.9544)  loss/high_gen_loss: 155345408.0000 (188803009.3944)  loss/pix_loss: 0.1668 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [790/862]  eta: 0:05:01  lr: 0.000100  loss/low_gen_loss: 1.9492 (1.9543)  loss/high_gen_loss: 232851216.0000 (190131340.5626)  loss/pix_loss: 0.1549 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1858  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [800/862]  eta: 0:04:19  lr: 0.000100  loss/low_gen_loss: 1.9489 (1.9542)  loss/high_gen_loss: 217292144.0000 (190043487.3221)  loss/pix_loss: 0.1608 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.9424 (1.9541)  loss/high_gen_loss: 242939120.0000 (191848799.9026)  loss/pix_loss: 0.1639 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.9298 (1.9537)  loss/high_gen_loss: 277330880.0000 (192430875.0122)  loss/pix_loss: 0.1674 (0.1670)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [830/862]  eta: 0:02:14  lr: 0.000100  loss/low_gen_loss: 1.9270 (1.9535)  loss/high_gen_loss: 296399072.0000 (195582096.1360)  loss/pix_loss: 0.1674 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1860  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.9453 (1.9534)  loss/high_gen_loss: 564198720.0000 (201051265.4090)  loss/pix_loss: 0.1654 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.9479 (1.9534)  loss/high_gen_loss: 836211840.0000 (219603006.3843)  loss/pix_loss: 0.1690 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.9454 (1.9532)  loss/high_gen_loss: 2962095104.0000 (269121297.3577)  loss/pix_loss: 0.1743 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.9454 (1.9532)  loss/high_gen_loss: 3455725824.0000 (274423693.1798)  loss/pix_loss: 0.1747 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:15] Total time: 1:00:10 (4.1880 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.9454 (1.9532)  loss/high_gen_loss: 3455725824.0000 (274423693.1798)  loss/pix_loss: 0.1747 (0.1669)  loss/enc_loss: 0.0002 (0.0002)\n",
      "Valid: [epoch:15]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1614 (0.1614)  time: 2.9365  data: 0.3919  max mem: 31350\n",
      "Valid: [epoch:15]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5507  data: 0.0281  max mem: 31350\n",
      "Valid: [epoch:15] Total time: 0:00:35 (2.5593 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_15_input_n_20.png\n",
      "Train: [epoch:16]  [  0/862]  eta: 1:14:34  lr: 0.000100  loss/low_gen_loss: 1.9507 (1.9507)  loss/high_gen_loss: 4745719296.0000 (4745719296.0000)  loss/pix_loss: 0.1678 (0.1678)  loss/enc_loss: 0.0002 (0.0002)  time: 5.1910  data: 0.9842  max mem: 31350\n",
      "Train: [epoch:16]  [ 10/862]  eta: 1:00:54  lr: 0.000100  loss/low_gen_loss: 1.9473 (1.9476)  loss/high_gen_loss: 3702890752.0000 (3731208005.8182)  loss/pix_loss: 0.1678 (0.1594)  loss/enc_loss: 0.0002 (0.0002)  time: 4.2895  data: 0.0896  max mem: 31350\n",
      "Train: [epoch:16]  [ 20/862]  eta: 0:59:30  lr: 0.000100  loss/low_gen_loss: 1.9499 (1.9505)  loss/high_gen_loss: 3251218176.0000 (3494748574.4762)  loss/pix_loss: 0.1707 (0.1645)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1933  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [ 30/862]  eta: 0:58:33  lr: 0.000100  loss/low_gen_loss: 1.9533 (1.9513)  loss/high_gen_loss: 3444275968.0000 (3593123856.5161)  loss/pix_loss: 0.1655 (0.1634)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [ 40/862]  eta: 0:57:43  lr: 0.000100  loss/low_gen_loss: 1.9554 (1.9539)  loss/high_gen_loss: 3994352384.0000 (4283324890.5366)  loss/pix_loss: 0.1643 (0.1660)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1859  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [ 50/862]  eta: 0:56:57  lr: 0.000100  loss/low_gen_loss: 1.9596 (1.9542)  loss/high_gen_loss: 6210309120.0000 (4622586754.5098)  loss/pix_loss: 0.1702 (0.1663)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [ 60/862]  eta: 0:56:12  lr: 0.000100  loss/low_gen_loss: 1.9546 (1.9543)  loss/high_gen_loss: 5288814592.0000 (4708849458.3607)  loss/pix_loss: 0.1703 (0.1671)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [ 70/862]  eta: 0:55:27  lr: 0.000100  loss/low_gen_loss: 1.9568 (1.9550)  loss/high_gen_loss: 4894630400.0000 (4775253410.2535)  loss/pix_loss: 0.1703 (0.1680)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [ 80/862]  eta: 0:54:44  lr: 0.000100  loss/low_gen_loss: 1.9436 (1.9527)  loss/high_gen_loss: 3904398080.0000 (4654653604.3457)  loss/pix_loss: 0.1716 (0.1681)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [ 90/862]  eta: 0:54:01  lr: 0.000100  loss/low_gen_loss: 1.9272 (1.9488)  loss/high_gen_loss: 3577250560.0000 (4501553413.6264)  loss/pix_loss: 0.1700 (0.1677)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [100/862]  eta: 0:53:18  lr: 0.000100  loss/low_gen_loss: 1.9232 (1.9470)  loss/high_gen_loss: 2727183872.0000 (4239817229.9406)  loss/pix_loss: 0.1575 (0.1662)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [110/862]  eta: 0:52:35  lr: 0.000100  loss/low_gen_loss: 1.9332 (1.9462)  loss/high_gen_loss: 2322878976.0000 (4183098171.9640)  loss/pix_loss: 0.1543 (0.1653)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [120/862]  eta: 0:51:52  lr: 0.000100  loss/low_gen_loss: 1.9580 (1.9474)  loss/high_gen_loss: 4369714688.0000 (4239993775.6033)  loss/pix_loss: 0.1569 (0.1654)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [130/862]  eta: 0:51:10  lr: 0.000100  loss/low_gen_loss: 1.9607 (1.9485)  loss/high_gen_loss: 5127895040.0000 (4367730125.1908)  loss/pix_loss: 0.1750 (0.1665)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [140/862]  eta: 0:50:27  lr: 0.000100  loss/low_gen_loss: 1.9598 (1.9497)  loss/high_gen_loss: 6833545728.0000 (4648998476.2553)  loss/pix_loss: 0.1724 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [150/862]  eta: 0:49:45  lr: 0.000100  loss/low_gen_loss: 1.9473 (1.9489)  loss/high_gen_loss: 8155899904.0000 (4824324546.9669)  loss/pix_loss: 0.1697 (0.1665)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [160/862]  eta: 0:49:03  lr: 0.000100  loss/low_gen_loss: 1.9430 (1.9490)  loss/high_gen_loss: 3872129792.0000 (4667138584.6460)  loss/pix_loss: 0.1686 (0.1666)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1840  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [170/862]  eta: 0:48:20  lr: 0.000100  loss/low_gen_loss: 1.9429 (1.9475)  loss/high_gen_loss: 3282232832.0000 (4695484186.1988)  loss/pix_loss: 0.1649 (0.1663)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [180/862]  eta: 0:47:38  lr: 0.000100  loss/low_gen_loss: 1.9327 (1.9471)  loss/high_gen_loss: 4067661568.0000 (4619896228.7735)  loss/pix_loss: 0.1690 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1849  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [190/862]  eta: 0:46:56  lr: 0.000100  loss/low_gen_loss: 1.9465 (1.9472)  loss/high_gen_loss: 4017396224.0000 (4616894059.8953)  loss/pix_loss: 0.1733 (0.1673)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1849  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [200/862]  eta: 0:46:14  lr: 0.000100  loss/low_gen_loss: 1.9496 (1.9474)  loss/high_gen_loss: 3804396288.0000 (4561044616.9154)  loss/pix_loss: 0.1849 (0.1683)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [210/862]  eta: 0:45:32  lr: 0.000100  loss/low_gen_loss: 1.9325 (1.9466)  loss/high_gen_loss: 3060936704.0000 (4427542705.7441)  loss/pix_loss: 0.1603 (0.1676)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1840  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [220/862]  eta: 0:44:50  lr: 0.000100  loss/low_gen_loss: 1.9315 (1.9462)  loss/high_gen_loss: 428998848.0000 (4241658545.8575)  loss/pix_loss: 0.1516 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [230/862]  eta: 0:44:08  lr: 0.000100  loss/low_gen_loss: 1.9376 (1.9459)  loss/high_gen_loss: 2293176320.0000 (47424299942.8333)  loss/pix_loss: 0.1539 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1859  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [240/862]  eta: 0:43:26  lr: 0.000100  loss/low_gen_loss: 1.9424 (1.9457)  loss/high_gen_loss: 3859019202560.0000 (750028666662.8153)  loss/pix_loss: 0.1514 (0.1663)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [250/862]  eta: 0:42:44  lr: 0.000100  loss/low_gen_loss: 1.9457 (1.9458)  loss/high_gen_loss: 28979192922112.0000 (2312024528344.7749)  loss/pix_loss: 0.1561 (0.1664)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [260/862]  eta: 0:42:02  lr: 0.000100  loss/low_gen_loss: 1.9452 (1.9457)  loss/high_gen_loss: 41879303356416.0000 (3963294372055.3354)  loss/pix_loss: 0.1512 (0.1657)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [270/862]  eta: 0:41:20  lr: 0.000100  loss/low_gen_loss: 1.9452 (1.9459)  loss/high_gen_loss: 56002103738368.0000 (6039982113232.3340)  loss/pix_loss: 0.1628 (0.1661)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [280/862]  eta: 0:40:38  lr: 0.000100  loss/low_gen_loss: 1.9477 (1.9459)  loss/high_gen_loss: 54285123452928.0000 (7553415698391.4961)  loss/pix_loss: 0.1675 (0.1660)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [290/862]  eta: 0:39:56  lr: 0.000100  loss/low_gen_loss: 1.9405 (1.9455)  loss/high_gen_loss: 45861568512000.0000 (8824464019846.1934)  loss/pix_loss: 0.1703 (0.1660)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1860  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [300/862]  eta: 0:39:14  lr: 0.000100  loss/low_gen_loss: 1.9356 (1.9452)  loss/high_gen_loss: 43362279227392.0000 (9858253039700.6602)  loss/pix_loss: 0.1660 (0.1658)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [310/862]  eta: 0:38:32  lr: 0.000100  loss/low_gen_loss: 1.9362 (1.9450)  loss/high_gen_loss: 25822696046592.0000 (10245006894119.1328)  loss/pix_loss: 0.1468 (0.1651)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [320/862]  eta: 0:37:50  lr: 0.000100  loss/low_gen_loss: 1.9463 (1.9451)  loss/high_gen_loss: 21447604961280.0000 (10608928138909.5410)  loss/pix_loss: 0.1468 (0.1648)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1869  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [330/862]  eta: 0:37:08  lr: 0.000100  loss/low_gen_loss: 1.9475 (1.9451)  loss/high_gen_loss: 19741599072256.0000 (10847418805303.3301)  loss/pix_loss: 0.1672 (0.1650)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1870  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [340/862]  eta: 0:36:26  lr: 0.000100  loss/low_gen_loss: 1.9510 (1.9455)  loss/high_gen_loss: 12313391267840.0000 (10812376295931.1504)  loss/pix_loss: 0.1724 (0.1654)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [350/862]  eta: 0:35:44  lr: 0.000100  loss/low_gen_loss: 1.9441 (1.9452)  loss/high_gen_loss: 9446189170688.0000 (10781751244032.3945)  loss/pix_loss: 0.1641 (0.1651)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [360/862]  eta: 0:35:02  lr: 0.000100  loss/low_gen_loss: 1.9348 (1.9449)  loss/high_gen_loss: 9742974976000.0000 (10779014903708.3945)  loss/pix_loss: 0.1808 (0.1656)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [370/862]  eta: 0:34:20  lr: 0.000100  loss/low_gen_loss: 1.9300 (1.9445)  loss/high_gen_loss: 10942977933312.0000 (10817579506174.3027)  loss/pix_loss: 0.1773 (0.1655)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1866  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [380/862]  eta: 0:33:38  lr: 0.000100  loss/low_gen_loss: 1.9300 (1.9442)  loss/high_gen_loss: 9942487531520.0000 (10766044138592.4473)  loss/pix_loss: 0.1711 (0.1656)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1859  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [390/862]  eta: 0:32:57  lr: 0.000100  loss/low_gen_loss: 1.9399 (1.9442)  loss/high_gen_loss: 7322295336960.0000 (10649239356384.2715)  loss/pix_loss: 0.1711 (0.1657)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [400/862]  eta: 0:32:15  lr: 0.000100  loss/low_gen_loss: 1.9402 (1.9439)  loss/high_gen_loss: 6362423623680.0000 (10550894108556.7949)  loss/pix_loss: 0.1648 (0.1654)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1869  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [410/862]  eta: 0:31:33  lr: 0.000100  loss/low_gen_loss: 1.9363 (1.9437)  loss/high_gen_loss: 6362423623680.0000 (10442805157656.0059)  loss/pix_loss: 0.1656 (0.1659)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1870  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [420/862]  eta: 0:30:51  lr: 0.000100  loss/low_gen_loss: 1.9333 (1.9434)  loss/high_gen_loss: 5605155143680.0000 (10326304134382.0859)  loss/pix_loss: 0.1656 (0.1657)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1905  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [430/862]  eta: 0:30:09  lr: 0.000100  loss/low_gen_loss: 1.9248 (1.9429)  loss/high_gen_loss: 5587488210944.0000 (10229943520707.1426)  loss/pix_loss: 0.1606 (0.1657)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1912  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [440/862]  eta: 0:29:27  lr: 0.000100  loss/low_gen_loss: 1.9387 (1.9431)  loss/high_gen_loss: 5280988921856.0000 (10068402553451.7070)  loss/pix_loss: 0.1626 (0.1656)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [450/862]  eta: 0:28:45  lr: 0.000100  loss/low_gen_loss: 1.9364 (1.9429)  loss/high_gen_loss: 2227380682752.0000 (9894942163985.9043)  loss/pix_loss: 0.1702 (0.1660)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [460/862]  eta: 0:28:03  lr: 0.000100  loss/low_gen_loss: 1.9349 (1.9427)  loss/high_gen_loss: 2927176187904.0000 (9805942064443.1621)  loss/pix_loss: 0.1568 (0.1657)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1880  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [470/862]  eta: 0:27:21  lr: 0.000100  loss/low_gen_loss: 1.9358 (1.9426)  loss/high_gen_loss: 5680254156800.0000 (9709086290491.5371)  loss/pix_loss: 0.1557 (0.1657)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1843  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [480/862]  eta: 0:26:39  lr: 0.000100  loss/low_gen_loss: 1.9362 (1.9424)  loss/high_gen_loss: 3682115518464.0000 (9557103824842.5312)  loss/pix_loss: 0.1651 (0.1657)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [490/862]  eta: 0:25:58  lr: 0.000100  loss/low_gen_loss: 1.9202 (1.9415)  loss/high_gen_loss: 2848963428352.0000 (9462926425066.9043)  loss/pix_loss: 0.1677 (0.1657)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [500/862]  eta: 0:25:16  lr: 0.000100  loss/low_gen_loss: 1.9040 (1.9409)  loss/high_gen_loss: 7663215706112.0000 (9439394018978.2559)  loss/pix_loss: 0.1623 (0.1654)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [510/862]  eta: 0:24:34  lr: 0.000100  loss/low_gen_loss: 1.8940 (1.9399)  loss/high_gen_loss: 6886802325504.0000 (9351671548474.8848)  loss/pix_loss: 0.1594 (0.1654)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1885  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [520/862]  eta: 0:23:52  lr: 0.000100  loss/low_gen_loss: 1.8861 (1.9389)  loss/high_gen_loss: 4117484273664.0000 (9237890078729.6016)  loss/pix_loss: 0.1718 (0.1656)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [530/862]  eta: 0:23:10  lr: 0.000100  loss/low_gen_loss: 1.8856 (1.9382)  loss/high_gen_loss: 2041859014656.0000 (9091526211246.3008)  loss/pix_loss: 0.1666 (0.1655)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1853  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [540/862]  eta: 0:22:28  lr: 0.000100  loss/low_gen_loss: 1.9043 (1.9375)  loss/high_gen_loss: 1309496049664.0000 (8944457874477.2090)  loss/pix_loss: 0.1666 (0.1658)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [550/862]  eta: 0:21:46  lr: 0.000100  loss/low_gen_loss: 1.9130 (1.9373)  loss/high_gen_loss: 1489916002304.0000 (8845662820502.3203)  loss/pix_loss: 0.1869 (0.1661)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1836  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [560/862]  eta: 0:21:04  lr: 0.000100  loss/low_gen_loss: 1.9393 (1.9375)  loss/high_gen_loss: 3582261198848.0000 (8751249318886.2354)  loss/pix_loss: 0.1711 (0.1659)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1844  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [570/862]  eta: 0:20:22  lr: 0.000100  loss/low_gen_loss: 1.9545 (1.9379)  loss/high_gen_loss: 3350282633216.0000 (8655327699408.2695)  loss/pix_loss: 0.1690 (0.1660)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [580/862]  eta: 0:19:41  lr: 0.000100  loss/low_gen_loss: 1.9507 (1.9380)  loss/high_gen_loss: 3223621206016.0000 (8558396720307.5693)  loss/pix_loss: 0.1690 (0.1660)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1848  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [590/862]  eta: 0:18:59  lr: 0.000100  loss/low_gen_loss: 1.9268 (1.9374)  loss/high_gen_loss: 2305885732864.0000 (8446924498564.3486)  loss/pix_loss: 0.1620 (0.1659)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1831  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [600/862]  eta: 0:18:17  lr: 0.000100  loss/low_gen_loss: 1.8980 (1.9369)  loss/high_gen_loss: 1919337889792.0000 (8337995869251.9570)  loss/pix_loss: 0.1619 (0.1658)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1835  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [610/862]  eta: 0:17:35  lr: 0.000100  loss/low_gen_loss: 1.9172 (1.9367)  loss/high_gen_loss: 1697325645824.0000 (8227950730410.7529)  loss/pix_loss: 0.1599 (0.1658)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [620/862]  eta: 0:16:53  lr: 0.000100  loss/low_gen_loss: 1.9079 (1.9359)  loss/high_gen_loss: 1611503632384.0000 (8122566655965.1816)  loss/pix_loss: 0.1752 (0.1660)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1844  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [630/862]  eta: 0:16:11  lr: 0.000100  loss/low_gen_loss: 1.8796 (1.9352)  loss/high_gen_loss: 1590150430720.0000 (8018048783113.1445)  loss/pix_loss: 0.1716 (0.1661)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1836  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [640/862]  eta: 0:15:29  lr: 0.000100  loss/low_gen_loss: 1.9116 (1.9350)  loss/high_gen_loss: 1476141514752.0000 (7913286621140.6836)  loss/pix_loss: 0.1568 (0.1658)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1828  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [650/862]  eta: 0:14:47  lr: 0.000100  loss/low_gen_loss: 1.9327 (1.9350)  loss/high_gen_loss: 1608583741440.0000 (7817972731902.2461)  loss/pix_loss: 0.1540 (0.1660)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1835  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [660/862]  eta: 0:14:05  lr: 0.000100  loss/low_gen_loss: 1.9481 (1.9353)  loss/high_gen_loss: 1676052398080.0000 (7723181435513.4316)  loss/pix_loss: 0.1707 (0.1659)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1837  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [670/862]  eta: 0:13:23  lr: 0.000100  loss/low_gen_loss: 1.9469 (1.9355)  loss/high_gen_loss: 1107572555776.0000 (7620969838507.8896)  loss/pix_loss: 0.1673 (0.1660)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1833  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [680/862]  eta: 0:12:42  lr: 0.000100  loss/low_gen_loss: 1.9298 (1.9353)  loss/high_gen_loss: 761212305408.0000 (7520200077671.2041)  loss/pix_loss: 0.1687 (0.1660)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1827  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [690/862]  eta: 0:12:00  lr: 0.000100  loss/low_gen_loss: 1.9271 (1.9358)  loss/high_gen_loss: 973429866496.0000 (7429178695779.1172)  loss/pix_loss: 0.1695 (0.1662)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [700/862]  eta: 0:11:18  lr: 0.000100  loss/low_gen_loss: 1.9522 (1.9357)  loss/high_gen_loss: 1257405939712.0000 (7340377071246.2568)  loss/pix_loss: 0.1695 (0.1661)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [710/862]  eta: 0:10:36  lr: 0.000100  loss/low_gen_loss: 1.9114 (1.9353)  loss/high_gen_loss: 826262683648.0000 (7244814871456.7793)  loss/pix_loss: 0.1716 (0.1663)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [720/862]  eta: 0:09:54  lr: 0.000100  loss/low_gen_loss: 1.9161 (1.9351)  loss/high_gen_loss: 352752140288.0000 (7147731736980.6074)  loss/pix_loss: 0.1774 (0.1664)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [730/862]  eta: 0:09:12  lr: 0.000100  loss/low_gen_loss: 1.9161 (1.9346)  loss/high_gen_loss: 230853066752.0000 (7053440824908.1836)  loss/pix_loss: 0.1707 (0.1664)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1826  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [740/862]  eta: 0:08:30  lr: 0.000100  loss/low_gen_loss: 1.8678 (1.9337)  loss/high_gen_loss: 470945366016.0000 (6968225487186.4102)  loss/pix_loss: 0.1615 (0.1662)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1827  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [750/862]  eta: 0:07:48  lr: 0.000100  loss/low_gen_loss: 1.8678 (1.9332)  loss/high_gen_loss: 647627407360.0000 (6883122581775.1826)  loss/pix_loss: 0.1627 (0.1662)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1833  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [760/862]  eta: 0:07:07  lr: 0.000100  loss/low_gen_loss: 1.9242 (1.9333)  loss/high_gen_loss: 342968074240.0000 (6797042876893.5322)  loss/pix_loss: 0.1691 (0.1663)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1833  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [770/862]  eta: 0:06:25  lr: 0.000100  loss/low_gen_loss: 1.9350 (1.9333)  loss/high_gen_loss: 325281218560.0000 (6711327112279.5049)  loss/pix_loss: 0.1759 (0.1664)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1841  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [780/862]  eta: 0:05:43  lr: 0.000100  loss/low_gen_loss: 1.9170 (1.9330)  loss/high_gen_loss: 166045073408.0000 (6627702546351.8691)  loss/pix_loss: 0.1638 (0.1663)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1840  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [790/862]  eta: 0:05:01  lr: 0.000100  loss/low_gen_loss: 1.9057 (1.9327)  loss/high_gen_loss: 294488276992.0000 (6548590340889.4189)  loss/pix_loss: 0.1612 (0.1663)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [800/862]  eta: 0:04:19  lr: 0.000100  loss/low_gen_loss: 1.9153 (1.9325)  loss/high_gen_loss: 372648247296.0000 (6471183785394.5098)  loss/pix_loss: 0.1776 (0.1665)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1880  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.9179 (1.9322)  loss/high_gen_loss: 324553179136.0000 (6395308855072.3672)  loss/pix_loss: 0.1776 (0.1665)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.9405 (1.9327)  loss/high_gen_loss: 285203922944.0000 (6320178415736.8408)  loss/pix_loss: 0.1766 (0.1667)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.9339 (1.9326)  loss/high_gen_loss: 106829291520.0000 (6244897874943.8584)  loss/pix_loss: 0.1752 (0.1667)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.9096 (1.9321)  loss/high_gen_loss: 90079543296.0000 (6171922726754.7891)  loss/pix_loss: 0.1623 (0.1666)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1850  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.8941 (1.9317)  loss/high_gen_loss: 118701080576.0000 (6102706425512.9238)  loss/pix_loss: 0.1623 (0.1666)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1842  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:16]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.8992 (1.9314)  loss/high_gen_loss: 561777934336.0000 (6042381668707.4678)  loss/pix_loss: 0.1645 (0.1665)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.9026 (1.9314)  loss/high_gen_loss: 670769414144.0000 (6036433105398.3594)  loss/pix_loss: 0.1645 (0.1665)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:16] Total time: 1:00:09 (4.1872 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.9026 (1.9314)  loss/high_gen_loss: 670769414144.0000 (6036433105398.3594)  loss/pix_loss: 0.1645 (0.1665)  loss/enc_loss: 0.0001 (0.0002)\n",
      "Valid: [epoch:16]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1140 (0.1140)  time: 2.9847  data: 0.3799  max mem: 31350\n",
      "Valid: [epoch:16]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6134  data: 0.0272  max mem: 31350\n",
      "Valid: [epoch:16] Total time: 0:00:36 (2.6217 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_16_input_n_20.png\n",
      "Train: [epoch:17]  [  0/862]  eta: 1:21:10  lr: 0.000100  loss/low_gen_loss: 1.9427 (1.9427)  loss/high_gen_loss: 826963329024.0000 (826963329024.0000)  loss/pix_loss: 0.1731 (0.1731)  loss/enc_loss: 0.0001 (0.0001)  time: 5.6507  data: 1.4876  max mem: 31350\n",
      "Train: [epoch:17]  [ 10/862]  eta: 1:00:50  lr: 0.000100  loss/low_gen_loss: 1.9260 (1.9085)  loss/high_gen_loss: 432123183104.0000 (495003452881.4545)  loss/pix_loss: 0.1731 (0.1686)  loss/enc_loss: 0.0001 (0.0001)  time: 4.2845  data: 0.1354  max mem: 31350\n",
      "Train: [epoch:17]  [ 20/862]  eta: 0:59:19  lr: 0.000100  loss/low_gen_loss: 1.8906 (1.8960)  loss/high_gen_loss: 318832640000.0000 (401025864265.1429)  loss/pix_loss: 0.1808 (0.1749)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1561  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [ 30/862]  eta: 0:58:24  lr: 0.000100  loss/low_gen_loss: 1.9105 (1.9021)  loss/high_gen_loss: 244491616256.0000 (345393150414.4516)  loss/pix_loss: 0.1787 (0.1718)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [ 40/862]  eta: 0:57:37  lr: 0.000100  loss/low_gen_loss: 1.9173 (1.9075)  loss/high_gen_loss: 147315490816.0000 (282339415214.8293)  loss/pix_loss: 0.1620 (0.1722)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1845  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [ 50/862]  eta: 0:56:52  lr: 0.000100  loss/low_gen_loss: 1.9246 (1.9112)  loss/high_gen_loss: 109215547392.0000 (256182045434.9804)  loss/pix_loss: 0.1580 (0.1693)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [ 60/862]  eta: 0:56:08  lr: 0.000100  loss/low_gen_loss: 1.9255 (1.9137)  loss/high_gen_loss: 175238299648.0000 (245441436688.7869)  loss/pix_loss: 0.1575 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [ 70/862]  eta: 0:55:25  lr: 0.000100  loss/low_gen_loss: 1.9139 (1.9103)  loss/high_gen_loss: 185859358720.0000 (230234359663.7747)  loss/pix_loss: 0.1598 (0.1678)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1878  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [ 80/862]  eta: 0:54:42  lr: 0.000100  loss/low_gen_loss: 1.8875 (1.9072)  loss/high_gen_loss: 101053562880.0000 (212869000406.9136)  loss/pix_loss: 0.1635 (0.1671)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1894  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [ 90/862]  eta: 0:53:59  lr: 0.000100  loss/low_gen_loss: 1.8505 (1.8987)  loss/high_gen_loss: 153716047872.0000 (213212758691.1648)  loss/pix_loss: 0.1622 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1898  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [100/862]  eta: 0:53:17  lr: 0.000100  loss/low_gen_loss: 1.8159 (1.8882)  loss/high_gen_loss: 161019510784.0000 (201969922899.6436)  loss/pix_loss: 0.1622 (0.1669)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [110/862]  eta: 0:52:34  lr: 0.000100  loss/low_gen_loss: 1.8159 (1.8896)  loss/high_gen_loss: 178054807552.0000 (286892679537.0090)  loss/pix_loss: 0.1584 (0.1666)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [120/862]  eta: 0:51:52  lr: 0.000100  loss/low_gen_loss: 1.9213 (1.8926)  loss/high_gen_loss: 2439404322816.0000 (532310312536.8595)  loss/pix_loss: 0.1609 (0.1663)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1884  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [130/862]  eta: 0:51:10  lr: 0.000100  loss/low_gen_loss: 1.9332 (1.8957)  loss/high_gen_loss: 2945046806528.0000 (671087630320.3665)  loss/pix_loss: 0.1749 (0.1676)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [140/862]  eta: 0:50:27  lr: 0.000100  loss/low_gen_loss: 1.9293 (1.8973)  loss/high_gen_loss: 1289672065024.0000 (702286261139.0638)  loss/pix_loss: 0.1671 (0.1668)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [150/862]  eta: 0:49:45  lr: 0.000100  loss/low_gen_loss: 1.9256 (1.8996)  loss/high_gen_loss: 858664992768.0000 (692485404332.9271)  loss/pix_loss: 0.1599 (0.1667)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [160/862]  eta: 0:49:03  lr: 0.000100  loss/low_gen_loss: 1.9306 (1.9014)  loss/high_gen_loss: 331065491456.0000 (665594974487.8510)  loss/pix_loss: 0.1669 (0.1666)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1886  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [170/862]  eta: 0:48:21  lr: 0.000100  loss/low_gen_loss: 1.9254 (1.9017)  loss/high_gen_loss: 331065491456.0000 (659687678574.7836)  loss/pix_loss: 0.1562 (0.1657)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [180/862]  eta: 0:47:39  lr: 0.000100  loss/low_gen_loss: 1.9419 (1.9058)  loss/high_gen_loss: 506783858688.0000 (647043393705.7238)  loss/pix_loss: 0.1706 (0.1667)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1893  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [190/862]  eta: 0:46:57  lr: 0.000100  loss/low_gen_loss: 1.9800 (1.9097)  loss/high_gen_loss: 334471036928.0000 (629066817321.5497)  loss/pix_loss: 0.1774 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [200/862]  eta: 0:46:15  lr: 0.000100  loss/low_gen_loss: 1.9596 (1.9116)  loss/high_gen_loss: 403983237120.0000 (632179714323.1045)  loss/pix_loss: 0.1814 (0.1684)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [210/862]  eta: 0:45:33  lr: 0.000100  loss/low_gen_loss: 1.9634 (1.9149)  loss/high_gen_loss: 785535205376.0000 (641570195349.2322)  loss/pix_loss: 0.1905 (0.1688)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1908  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [220/862]  eta: 0:44:51  lr: 0.000100  loss/low_gen_loss: 1.9631 (1.9158)  loss/high_gen_loss: 609209876480.0000 (630459537936.2172)  loss/pix_loss: 0.1646 (0.1685)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1925  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [230/862]  eta: 0:44:09  lr: 0.000100  loss/low_gen_loss: 1.9205 (1.9153)  loss/high_gen_loss: 264350285824.0000 (612575378533.9567)  loss/pix_loss: 0.1597 (0.1681)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1930  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [240/862]  eta: 0:43:27  lr: 0.000100  loss/low_gen_loss: 1.9362 (1.9172)  loss/high_gen_loss: 209344102400.0000 (596050261548.6141)  loss/pix_loss: 0.1603 (0.1680)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1930  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [250/862]  eta: 0:42:45  lr: 0.000100  loss/low_gen_loss: 1.9391 (1.9170)  loss/high_gen_loss: 189689315328.0000 (579441662400.7649)  loss/pix_loss: 0.1636 (0.1679)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1913  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [260/862]  eta: 0:42:03  lr: 0.000100  loss/low_gen_loss: 1.9355 (1.9180)  loss/high_gen_loss: 170453860352.0000 (562203011942.9885)  loss/pix_loss: 0.1731 (0.1678)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1885  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [270/862]  eta: 0:41:21  lr: 0.000100  loss/low_gen_loss: 1.9142 (1.9176)  loss/high_gen_loss: 118041837568.0000 (546188610873.6236)  loss/pix_loss: 0.1834 (0.1688)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [280/862]  eta: 0:40:39  lr: 0.000100  loss/low_gen_loss: 1.8773 (1.9154)  loss/high_gen_loss: 160882311168.0000 (534379342720.4555)  loss/pix_loss: 0.1834 (0.1689)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [290/862]  eta: 0:39:57  lr: 0.000100  loss/low_gen_loss: 1.8661 (1.9143)  loss/high_gen_loss: 293801689088.0000 (526879473889.2096)  loss/pix_loss: 0.1832 (0.1693)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [300/862]  eta: 0:39:15  lr: 0.000100  loss/low_gen_loss: 1.8682 (1.9125)  loss/high_gen_loss: 296982577152.0000 (517119470078.2990)  loss/pix_loss: 0.1669 (0.1688)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [310/862]  eta: 0:38:33  lr: 0.000100  loss/low_gen_loss: 1.8682 (1.9116)  loss/high_gen_loss: 138849304576.0000 (503613268982.1222)  loss/pix_loss: 0.1481 (0.1682)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [320/862]  eta: 0:37:51  lr: 0.000100  loss/low_gen_loss: 1.8930 (1.9109)  loss/high_gen_loss: 127781888000.0000 (493281018940.6106)  loss/pix_loss: 0.1564 (0.1680)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [330/862]  eta: 0:37:09  lr: 0.000100  loss/low_gen_loss: 1.8762 (1.9095)  loss/high_gen_loss: 155307540480.0000 (483013081143.6858)  loss/pix_loss: 0.1611 (0.1678)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1866  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [340/862]  eta: 0:36:27  lr: 0.000100  loss/low_gen_loss: 1.8810 (1.9090)  loss/high_gen_loss: 142028587008.0000 (472816381039.1085)  loss/pix_loss: 0.1619 (0.1676)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [350/862]  eta: 0:35:45  lr: 0.000100  loss/low_gen_loss: 1.9109 (1.9092)  loss/high_gen_loss: 143073820672.0000 (463932545263.2251)  loss/pix_loss: 0.1656 (0.1674)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [360/862]  eta: 0:35:03  lr: 0.000100  loss/low_gen_loss: 1.9098 (1.9091)  loss/high_gen_loss: 164580360192.0000 (455330561265.1080)  loss/pix_loss: 0.1709 (0.1677)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [370/862]  eta: 0:34:21  lr: 0.000100  loss/low_gen_loss: 1.9062 (1.9091)  loss/high_gen_loss: 165736644608.0000 (447396567310.4905)  loss/pix_loss: 0.1729 (0.1677)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [380/862]  eta: 0:33:39  lr: 0.000100  loss/low_gen_loss: 1.9038 (1.9088)  loss/high_gen_loss: 156451995648.0000 (439652318726.7192)  loss/pix_loss: 0.1609 (0.1674)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [390/862]  eta: 0:32:57  lr: 0.000100  loss/low_gen_loss: 1.8722 (1.9075)  loss/high_gen_loss: 138997448704.0000 (430773009593.9437)  loss/pix_loss: 0.1599 (0.1675)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [400/862]  eta: 0:32:15  lr: 0.000100  loss/low_gen_loss: 1.8653 (1.9066)  loss/high_gen_loss: 44585377792.0000 (420821052576.8778)  loss/pix_loss: 0.1665 (0.1675)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [410/862]  eta: 0:31:33  lr: 0.000100  loss/low_gen_loss: 1.8738 (1.9057)  loss/high_gen_loss: 39691296768.0000 (411788547996.3406)  loss/pix_loss: 0.1735 (0.1674)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1867  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [420/862]  eta: 0:30:52  lr: 0.000100  loss/low_gen_loss: 1.8719 (1.9049)  loss/high_gen_loss: 54969237504.0000 (403611682864.6461)  loss/pix_loss: 0.1754 (0.1677)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [430/862]  eta: 0:30:10  lr: 0.000100  loss/low_gen_loss: 1.8574 (1.9034)  loss/high_gen_loss: 72118575104.0000 (396030733856.0742)  loss/pix_loss: 0.1760 (0.1678)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1866  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [440/862]  eta: 0:29:28  lr: 0.000100  loss/low_gen_loss: 1.8249 (1.9012)  loss/high_gen_loss: 61981290496.0000 (388328301765.3696)  loss/pix_loss: 0.1717 (0.1679)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1850  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [450/862]  eta: 0:28:46  lr: 0.000100  loss/low_gen_loss: 1.8125 (1.8994)  loss/high_gen_loss: 67741728768.0000 (382177241106.1641)  loss/pix_loss: 0.1735 (0.1682)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1850  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [460/862]  eta: 0:28:04  lr: 0.000100  loss/low_gen_loss: 1.8201 (1.8980)  loss/high_gen_loss: 155245412352.0000 (378106025184.3470)  loss/pix_loss: 0.1688 (0.1679)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [470/862]  eta: 0:27:22  lr: 0.000100  loss/low_gen_loss: 1.8708 (1.8981)  loss/high_gen_loss: 162444214272.0000 (372555560655.6263)  loss/pix_loss: 0.1471 (0.1675)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [480/862]  eta: 0:26:40  lr: 0.000100  loss/low_gen_loss: 1.8824 (1.8971)  loss/high_gen_loss: 102527893504.0000 (367133144985.8129)  loss/pix_loss: 0.1571 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1880  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [490/862]  eta: 0:25:58  lr: 0.000100  loss/low_gen_loss: 1.8552 (1.8963)  loss/high_gen_loss: 197797937152.0000 (365178283998.6313)  loss/pix_loss: 0.1569 (0.1671)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1867  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [500/862]  eta: 0:25:16  lr: 0.000100  loss/low_gen_loss: 1.8419 (1.8951)  loss/high_gen_loss: 286901993472.0000 (363783969291.2415)  loss/pix_loss: 0.1615 (0.1670)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [510/862]  eta: 0:24:34  lr: 0.000100  loss/low_gen_loss: 1.8481 (1.8945)  loss/high_gen_loss: 290965061632.0000 (362496045236.3522)  loss/pix_loss: 0.1702 (0.1672)  loss/enc_loss: 0.0001 (0.0002)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [520/862]  eta: 0:23:52  lr: 0.000100  loss/low_gen_loss: 1.8663 (1.8940)  loss/high_gen_loss: 276150353920.0000 (359816734539.1785)  loss/pix_loss: 0.1719 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [530/862]  eta: 0:23:10  lr: 0.000100  loss/low_gen_loss: 1.8725 (1.8939)  loss/high_gen_loss: 210547490816.0000 (357366237168.5725)  loss/pix_loss: 0.1701 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [540/862]  eta: 0:22:28  lr: 0.000100  loss/low_gen_loss: 1.8960 (1.8941)  loss/high_gen_loss: 337085136896.0000 (358348883127.6008)  loss/pix_loss: 0.1690 (0.1674)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1850  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [550/862]  eta: 0:21:47  lr: 0.000100  loss/low_gen_loss: 1.9024 (1.8943)  loss/high_gen_loss: 447205703680.0000 (362664932833.3358)  loss/pix_loss: 0.1735 (0.1677)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [560/862]  eta: 0:21:05  lr: 0.000100  loss/low_gen_loss: 1.9081 (1.8947)  loss/high_gen_loss: 596425310208.0000 (366652468988.8057)  loss/pix_loss: 0.1685 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [570/862]  eta: 0:20:23  lr: 0.000100  loss/low_gen_loss: 1.9015 (1.8948)  loss/high_gen_loss: 423505395712.0000 (364855835606.7531)  loss/pix_loss: 0.1774 (0.1677)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [580/862]  eta: 0:19:41  lr: 0.000100  loss/low_gen_loss: 1.8930 (1.8946)  loss/high_gen_loss: 185398198272.0000 (361249310120.7573)  loss/pix_loss: 0.1741 (0.1675)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1865  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [590/862]  eta: 0:18:59  lr: 0.000100  loss/low_gen_loss: 1.8879 (1.8947)  loss/high_gen_loss: 130866405376.0000 (357150015581.5635)  loss/pix_loss: 0.1513 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1878  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [600/862]  eta: 0:18:17  lr: 0.000100  loss/low_gen_loss: 1.9050 (1.8949)  loss/high_gen_loss: 129988075520.0000 (353748112971.8203)  loss/pix_loss: 0.1615 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [610/862]  eta: 0:17:35  lr: 0.000100  loss/low_gen_loss: 1.9139 (1.8953)  loss/high_gen_loss: 102089211904.0000 (349538553175.5679)  loss/pix_loss: 0.1689 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [620/862]  eta: 0:16:53  lr: 0.000100  loss/low_gen_loss: 1.9227 (1.8958)  loss/high_gen_loss: 109680836608.0000 (349340779627.1819)  loss/pix_loss: 0.1741 (0.1673)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1876  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [630/862]  eta: 0:16:11  lr: 0.000100  loss/low_gen_loss: 1.9128 (1.8959)  loss/high_gen_loss: 416539115520.0000 (351482012566.5167)  loss/pix_loss: 0.1752 (0.1673)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [640/862]  eta: 0:15:29  lr: 0.000100  loss/low_gen_loss: 1.9044 (1.8961)  loss/high_gen_loss: 540392062976.0000 (354933363624.1373)  loss/pix_loss: 0.1696 (0.1672)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [650/862]  eta: 0:14:48  lr: 0.000100  loss/low_gen_loss: 1.9089 (1.8965)  loss/high_gen_loss: 459732058112.0000 (355297135963.6252)  loss/pix_loss: 0.1651 (0.1671)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [660/862]  eta: 0:14:06  lr: 0.000100  loss/low_gen_loss: 1.9072 (1.8966)  loss/high_gen_loss: 377174196224.0000 (355944594114.4206)  loss/pix_loss: 0.1659 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1870  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [670/862]  eta: 0:13:24  lr: 0.000100  loss/low_gen_loss: 1.9042 (1.8967)  loss/high_gen_loss: 441546964992.0000 (357342229325.4486)  loss/pix_loss: 0.1705 (0.1673)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [680/862]  eta: 0:12:42  lr: 0.000100  loss/low_gen_loss: 1.9043 (1.8968)  loss/high_gen_loss: 480046579712.0000 (361616430562.6784)  loss/pix_loss: 0.1655 (0.1672)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [690/862]  eta: 0:12:00  lr: 0.000100  loss/low_gen_loss: 1.9080 (1.8972)  loss/high_gen_loss: 771213885440.0000 (368683944872.5673)  loss/pix_loss: 0.1653 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1866  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [700/862]  eta: 0:11:18  lr: 0.000100  loss/low_gen_loss: 1.9262 (1.8977)  loss/high_gen_loss: 670836391936.0000 (368803638737.9857)  loss/pix_loss: 0.1656 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1859  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [710/862]  eta: 0:10:36  lr: 0.000100  loss/low_gen_loss: 1.9207 (1.8979)  loss/high_gen_loss: 137148039168.0000 (364963529415.4712)  loss/pix_loss: 0.1663 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [720/862]  eta: 0:09:54  lr: 0.000100  loss/low_gen_loss: 1.9205 (1.8983)  loss/high_gen_loss: 55944245248.0000 (360552519322.0971)  loss/pix_loss: 0.1821 (0.1675)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [730/862]  eta: 0:09:12  lr: 0.000100  loss/low_gen_loss: 1.9138 (1.8981)  loss/high_gen_loss: 65737129984.0000 (358133192255.7374)  loss/pix_loss: 0.1670 (0.1673)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1883  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [740/862]  eta: 0:08:31  lr: 0.000100  loss/low_gen_loss: 1.8948 (1.8981)  loss/high_gen_loss: 227174088704.0000 (356440625657.7814)  loss/pix_loss: 0.1685 (0.1675)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1879  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [750/862]  eta: 0:07:49  lr: 0.000100  loss/low_gen_loss: 1.8896 (1.8979)  loss/high_gen_loss: 230062948352.0000 (354871376788.2823)  loss/pix_loss: 0.1764 (0.1674)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1894  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [760/862]  eta: 0:07:07  lr: 0.000100  loss/low_gen_loss: 1.8694 (1.8974)  loss/high_gen_loss: 285357178880.0000 (355180182349.0355)  loss/pix_loss: 0.1656 (0.1674)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1899  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [770/862]  eta: 0:06:25  lr: 0.000100  loss/low_gen_loss: 1.8779 (1.8973)  loss/high_gen_loss: 489383297024.0000 (361705685270.9105)  loss/pix_loss: 0.1656 (0.1673)  loss/enc_loss: 0.0004 (0.0002)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [780/862]  eta: 0:05:43  lr: 0.000100  loss/low_gen_loss: 1.8912 (1.8976)  loss/high_gen_loss: 622825046016.0000 (363086129907.2164)  loss/pix_loss: 0.1602 (0.1672)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1895  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [790/862]  eta: 0:05:01  lr: 0.000100  loss/low_gen_loss: 1.9341 (1.8981)  loss/high_gen_loss: 300310659072.0000 (361797887808.4045)  loss/pix_loss: 0.1660 (0.1673)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1892  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [800/862]  eta: 0:04:19  lr: 0.000100  loss/low_gen_loss: 1.9235 (1.8984)  loss/high_gen_loss: 330957783040.0000 (363410745538.3171)  loss/pix_loss: 0.1585 (0.1672)  loss/enc_loss: 0.0002 (0.0002)  time: 4.1880  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.9218 (1.8986)  loss/high_gen_loss: 616395440128.0000 (366908310375.2207)  loss/pix_loss: 0.1700 (0.1674)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1889  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.9181 (1.8988)  loss/high_gen_loss: 619791777792.0000 (367480859921.1498)  loss/pix_loss: 0.1825 (0.1676)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [830/862]  eta: 0:02:14  lr: 0.000100  loss/low_gen_loss: 1.9204 (1.8992)  loss/high_gen_loss: 213826699264.0000 (365097365107.2154)  loss/pix_loss: 0.1763 (0.1675)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1910  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.9154 (1.8991)  loss/high_gen_loss: 100028252160.0000 (361677712899.0440)  loss/pix_loss: 0.1628 (0.1674)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1911  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.8860 (1.8988)  loss/high_gen_loss: 116104282112.0000 (359850122072.7427)  loss/pix_loss: 0.1754 (0.1675)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.8745 (1.8986)  loss/high_gen_loss: 233142550528.0000 (358785793089.4123)  loss/pix_loss: 0.1699 (0.1675)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1886  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.8748 (1.8985)  loss/high_gen_loss: 234222632960.0000 (358673284295.5731)  loss/pix_loss: 0.1754 (0.1675)  loss/enc_loss: 0.0003 (0.0002)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:17] Total time: 1:00:10 (4.1890 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.8748 (1.8985)  loss/high_gen_loss: 234222632960.0000 (358673284295.5731)  loss/pix_loss: 0.1754 (0.1675)  loss/enc_loss: 0.0003 (0.0002)\n",
      "Valid: [epoch:17]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1080 (0.1080)  time: 2.9597  data: 0.3669  max mem: 31350\n",
      "Valid: [epoch:17]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5901  data: 0.0263  max mem: 31350\n",
      "Valid: [epoch:17] Total time: 0:00:36 (2.5999 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_17_input_n_20.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [  0/862]  eta: 1:16:03  lr: 0.000100  loss/low_gen_loss: 1.8870 (1.8870)  loss/high_gen_loss: 250142834688.0000 (250142834688.0000)  loss/pix_loss: 0.1738 (0.1738)  loss/enc_loss: 0.0004 (0.0004)  time: 5.2937  data: 1.1020  max mem: 31350\n",
      "Train: [epoch:18]  [ 10/862]  eta: 1:00:53  lr: 0.000100  loss/low_gen_loss: 1.8938 (1.8923)  loss/high_gen_loss: 129396170752.0000 (143417845946.1818)  loss/pix_loss: 0.1752 (0.1708)  loss/enc_loss: 0.0004 (0.0004)  time: 4.2876  data: 0.1003  max mem: 31350\n",
      "Train: [epoch:18]  [ 20/862]  eta: 0:59:31  lr: 0.000100  loss/low_gen_loss: 1.8934 (1.8896)  loss/high_gen_loss: 192966934528.0000 (420996388961.5238)  loss/pix_loss: 0.1659 (0.1656)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1886  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [ 30/862]  eta: 0:58:34  lr: 0.000100  loss/low_gen_loss: 1.8948 (1.8940)  loss/high_gen_loss: 1406593007616.0000 (774075722058.3226)  loss/pix_loss: 0.1596 (0.1701)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1887  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [ 40/862]  eta: 0:57:45  lr: 0.000100  loss/low_gen_loss: 1.8976 (1.8949)  loss/high_gen_loss: 1522548604928.0000 (954666065720.1951)  loss/pix_loss: 0.1850 (0.1731)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [ 50/862]  eta: 0:56:58  lr: 0.000100  loss/low_gen_loss: 1.9001 (1.8967)  loss/high_gen_loss: 1502819385344.0000 (1052645642962.8235)  loss/pix_loss: 0.1808 (0.1719)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1870  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [ 60/862]  eta: 0:56:13  lr: 0.000100  loss/low_gen_loss: 1.8906 (1.8940)  loss/high_gen_loss: 1456274800640.0000 (1109613913004.0657)  loss/pix_loss: 0.1729 (0.1713)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [ 70/862]  eta: 0:55:28  lr: 0.000100  loss/low_gen_loss: 1.8732 (1.8872)  loss/high_gen_loss: 1408198639616.0000 (1152367836030.1973)  loss/pix_loss: 0.1683 (0.1713)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1867  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [ 80/862]  eta: 0:54:45  lr: 0.000100  loss/low_gen_loss: 1.8686 (1.8861)  loss/high_gen_loss: 1165673627648.0000 (1082582451642.4691)  loss/pix_loss: 0.1618 (0.1700)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [ 90/862]  eta: 0:54:01  lr: 0.000100  loss/low_gen_loss: 1.8686 (1.8837)  loss/high_gen_loss: 1165673627648.0000 (1559218176945.2307)  loss/pix_loss: 0.1675 (0.1699)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [100/862]  eta: 0:53:18  lr: 0.000100  loss/low_gen_loss: 1.8593 (1.8815)  loss/high_gen_loss: 8297251864576.0000 (2292882875949.6235)  loss/pix_loss: 0.1673 (0.1694)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [110/862]  eta: 0:52:36  lr: 0.000100  loss/low_gen_loss: 1.8651 (1.8801)  loss/high_gen_loss: 9233713070080.0000 (3198074793245.9819)  loss/pix_loss: 0.1652 (0.1695)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [120/862]  eta: 0:51:53  lr: 0.000100  loss/low_gen_loss: 1.8646 (1.8779)  loss/high_gen_loss: 15671945592832.0000 (4498408873950.1484)  loss/pix_loss: 0.1652 (0.1690)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [130/862]  eta: 0:51:10  lr: 0.000100  loss/low_gen_loss: 1.8674 (1.8786)  loss/high_gen_loss: 20180988067840.0000 (5951045342372.1523)  loss/pix_loss: 0.1722 (0.1704)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [140/862]  eta: 0:50:28  lr: 0.000100  loss/low_gen_loss: 1.8754 (1.8784)  loss/high_gen_loss: 20162057076736.0000 (6861356460627.5176)  loss/pix_loss: 0.1722 (0.1697)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [150/862]  eta: 0:49:45  lr: 0.000100  loss/low_gen_loss: 1.8777 (1.8785)  loss/high_gen_loss: 20617797566464.0000 (7845404007986.8613)  loss/pix_loss: 0.1617 (0.1694)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1843  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [160/862]  eta: 0:49:03  lr: 0.000100  loss/low_gen_loss: 1.8791 (1.8786)  loss/high_gen_loss: 20480438304768.0000 (8388059301290.1367)  loss/pix_loss: 0.1674 (0.1695)  loss/enc_loss: 0.0005 (0.0004)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [170/862]  eta: 0:48:21  lr: 0.000100  loss/low_gen_loss: 1.8942 (1.8801)  loss/high_gen_loss: 12030602903552.0000 (8505776114897.5908)  loss/pix_loss: 0.1748 (0.1693)  loss/enc_loss: 0.0005 (0.0004)  time: 4.1841  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [180/862]  eta: 0:47:39  lr: 0.000100  loss/low_gen_loss: 1.8838 (1.8797)  loss/high_gen_loss: 9303143481344.0000 (8520808296402.7402)  loss/pix_loss: 0.1791 (0.1701)  loss/enc_loss: 0.0005 (0.0004)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [190/862]  eta: 0:46:56  lr: 0.000100  loss/low_gen_loss: 1.8788 (1.8798)  loss/high_gen_loss: 9703045201920.0000 (8670886530943.3301)  loss/pix_loss: 0.1845 (0.1702)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1848  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [200/862]  eta: 0:46:14  lr: 0.000100  loss/low_gen_loss: 1.8865 (1.8804)  loss/high_gen_loss: 10248243904512.0000 (8697386780845.2139)  loss/pix_loss: 0.1796 (0.1705)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [210/862]  eta: 0:45:32  lr: 0.000100  loss/low_gen_loss: 1.8905 (1.8807)  loss/high_gen_loss: 7942000607232.0000 (8597308598068.1709)  loss/pix_loss: 0.1729 (0.1702)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [220/862]  eta: 0:44:50  lr: 0.000100  loss/low_gen_loss: 1.8874 (1.8808)  loss/high_gen_loss: 4800020742144.0000 (8386177895187.6924)  loss/pix_loss: 0.1624 (0.1697)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [230/862]  eta: 0:44:08  lr: 0.000100  loss/low_gen_loss: 1.8844 (1.8810)  loss/high_gen_loss: 2862472232960.0000 (8107021104380.6758)  loss/pix_loss: 0.1620 (0.1696)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1839  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [240/862]  eta: 0:43:26  lr: 0.000100  loss/low_gen_loss: 1.8819 (1.8807)  loss/high_gen_loss: 1753616351232.0000 (7843140010000.9961)  loss/pix_loss: 0.1580 (0.1692)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [250/862]  eta: 0:42:44  lr: 0.000100  loss/low_gen_loss: 1.8601 (1.8785)  loss/high_gen_loss: 2145933328384.0000 (7634651639220.5264)  loss/pix_loss: 0.1546 (0.1690)  loss/enc_loss: 0.0005 (0.0004)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [260/862]  eta: 0:42:02  lr: 0.000100  loss/low_gen_loss: 1.8326 (1.8769)  loss/high_gen_loss: 2674189926400.0000 (7446875582620.9346)  loss/pix_loss: 0.1549 (0.1685)  loss/enc_loss: 0.0006 (0.0004)  time: 4.1838  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [270/862]  eta: 0:41:20  lr: 0.000100  loss/low_gen_loss: 1.8793 (1.8777)  loss/high_gen_loss: 2286056636416.0000 (7240449571367.6748)  loss/pix_loss: 0.1549 (0.1687)  loss/enc_loss: 0.0005 (0.0004)  time: 4.1839  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [280/862]  eta: 0:40:38  lr: 0.000100  loss/low_gen_loss: 1.8928 (1.8781)  loss/high_gen_loss: 1311085035520.0000 (7015805752112.2852)  loss/pix_loss: 0.1781 (0.1689)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1848  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [290/862]  eta: 0:39:56  lr: 0.000100  loss/low_gen_loss: 1.8856 (1.8782)  loss/high_gen_loss: 745629417472.0000 (6799946974436.7285)  loss/pix_loss: 0.1640 (0.1685)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1840  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [300/862]  eta: 0:39:14  lr: 0.000100  loss/low_gen_loss: 1.8795 (1.8783)  loss/high_gen_loss: 699866415104.0000 (6593473745277.0234)  loss/pix_loss: 0.1564 (0.1677)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1827  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [310/862]  eta: 0:38:32  lr: 0.000100  loss/low_gen_loss: 1.8788 (1.8782)  loss/high_gen_loss: 498625708032.0000 (6393521855234.4697)  loss/pix_loss: 0.1524 (0.1674)  loss/enc_loss: 0.0006 (0.0004)  time: 4.1836  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [320/862]  eta: 0:37:50  lr: 0.000100  loss/low_gen_loss: 1.8952 (1.8795)  loss/high_gen_loss: 286527291392.0000 (6202293836586.2676)  loss/pix_loss: 0.1588 (0.1671)  loss/enc_loss: 0.0005 (0.0004)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [330/862]  eta: 0:37:08  lr: 0.000100  loss/low_gen_loss: 1.8936 (1.8793)  loss/high_gen_loss: 284650799104.0000 (6040604675774.2598)  loss/pix_loss: 0.1588 (0.1668)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1838  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [340/862]  eta: 0:36:26  lr: 0.000100  loss/low_gen_loss: 1.8703 (1.8795)  loss/high_gen_loss: 1344861503488.0000 (5911088155711.0615)  loss/pix_loss: 0.1630 (0.1667)  loss/enc_loss: 0.0005 (0.0004)  time: 4.1825  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [350/862]  eta: 0:35:44  lr: 0.000100  loss/low_gen_loss: 1.9010 (1.8805)  loss/high_gen_loss: 1278324113408.0000 (5774369865599.6357)  loss/pix_loss: 0.1630 (0.1665)  loss/enc_loss: 0.0006 (0.0004)  time: 4.1821  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [360/862]  eta: 0:35:02  lr: 0.000100  loss/low_gen_loss: 1.8937 (1.8808)  loss/high_gen_loss: 1144477974528.0000 (5651893780219.0361)  loss/pix_loss: 0.1578 (0.1663)  loss/enc_loss: 0.0005 (0.0004)  time: 4.1839  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [370/862]  eta: 0:34:20  lr: 0.000100  loss/low_gen_loss: 1.8937 (1.8817)  loss/high_gen_loss: 626349506560.0000 (5513836994858.0918)  loss/pix_loss: 0.1727 (0.1667)  loss/enc_loss: 0.0004 (0.0004)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [380/862]  eta: 0:33:38  lr: 0.000100  loss/low_gen_loss: 1.9554 (1.8838)  loss/high_gen_loss: 626349506560.0000 (5397974748624.9658)  loss/pix_loss: 0.1758 (0.1669)  loss/enc_loss: 0.0003 (0.0004)  time: 4.1841  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [390/862]  eta: 0:32:56  lr: 0.000100  loss/low_gen_loss: 1.9516 (1.8846)  loss/high_gen_loss: 1501682991104.0000 (5300757843611.8262)  loss/pix_loss: 0.1673 (0.1667)  loss/enc_loss: 0.0006 (0.0004)  time: 4.1834  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [400/862]  eta: 0:32:14  lr: 0.000100  loss/low_gen_loss: 1.8953 (1.8840)  loss/high_gen_loss: 1899355176960.0000 (5245880499008.4785)  loss/pix_loss: 0.1582 (0.1665)  loss/enc_loss: 0.0006 (0.0004)  time: 4.1835  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [410/862]  eta: 0:31:32  lr: 0.000100  loss/low_gen_loss: 1.8753 (1.8842)  loss/high_gen_loss: 3433460137984.0000 (5203289808367.8057)  loss/pix_loss: 0.1615 (0.1667)  loss/enc_loss: 0.0007 (0.0005)  time: 4.1839  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [420/862]  eta: 0:30:50  lr: 0.000100  loss/low_gen_loss: 1.8862 (1.8843)  loss/high_gen_loss: 3611095990272.0000 (5175103155192.7031)  loss/pix_loss: 0.1757 (0.1666)  loss/enc_loss: 0.0014 (0.0005)  time: 4.1835  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [430/862]  eta: 0:30:08  lr: 0.000100  loss/low_gen_loss: 1.8623 (1.8830)  loss/high_gen_loss: 3659592630272.0000 (5123832992409.2432)  loss/pix_loss: 0.1652 (0.1663)  loss/enc_loss: 0.0010 (0.0005)  time: 4.1833  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [440/862]  eta: 0:29:27  lr: 0.000100  loss/low_gen_loss: 1.8416 (1.8822)  loss/high_gen_loss: 2155096309760.0000 (5051284081907.8096)  loss/pix_loss: 0.1662 (0.1664)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1841  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [450/862]  eta: 0:28:45  lr: 0.000100  loss/low_gen_loss: 1.8494 (1.8815)  loss/high_gen_loss: 1759948963840.0000 (4969962949584.3193)  loss/pix_loss: 0.1741 (0.1668)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1845  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [460/862]  eta: 0:28:03  lr: 0.000100  loss/low_gen_loss: 1.8538 (1.8811)  loss/high_gen_loss: 1025309605888.0000 (4880525305505.0410)  loss/pix_loss: 0.1599 (0.1666)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [470/862]  eta: 0:27:21  lr: 0.000100  loss/low_gen_loss: 1.8698 (1.8813)  loss/high_gen_loss: 1286387269632.0000 (4840838084821.0615)  loss/pix_loss: 0.1496 (0.1664)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1843  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [480/862]  eta: 0:26:39  lr: 0.000100  loss/low_gen_loss: 1.8951 (1.8816)  loss/high_gen_loss: 3061866037248.0000 (4802962424225.2637)  loss/pix_loss: 0.1609 (0.1664)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1839  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [490/862]  eta: 0:25:57  lr: 0.000100  loss/low_gen_loss: 1.8891 (1.8816)  loss/high_gen_loss: 2666305421312.0000 (4757891188231.2998)  loss/pix_loss: 0.1645 (0.1664)  loss/enc_loss: 0.0006 (0.0005)  time: 4.1841  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [500/862]  eta: 0:25:15  lr: 0.000100  loss/low_gen_loss: 1.8736 (1.8815)  loss/high_gen_loss: 2335985893376.0000 (4707484289960.1113)  loss/pix_loss: 0.1645 (0.1662)  loss/enc_loss: 0.0007 (0.0005)  time: 4.1890  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [510/862]  eta: 0:24:33  lr: 0.000100  loss/low_gen_loss: 1.8758 (1.8814)  loss/high_gen_loss: 2051752067072.0000 (4648899049924.8848)  loss/pix_loss: 0.1702 (0.1664)  loss/enc_loss: 0.0008 (0.0005)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [520/862]  eta: 0:23:51  lr: 0.000100  loss/low_gen_loss: 1.8822 (1.8814)  loss/high_gen_loss: 1626361561088.0000 (4590472798766.1885)  loss/pix_loss: 0.1709 (0.1665)  loss/enc_loss: 0.0006 (0.0005)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [530/862]  eta: 0:23:10  lr: 0.000100  loss/low_gen_loss: 1.8967 (1.8818)  loss/high_gen_loss: 1399012589568.0000 (4526892660169.0391)  loss/pix_loss: 0.1646 (0.1663)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [540/862]  eta: 0:22:28  lr: 0.000100  loss/low_gen_loss: 1.9014 (1.8823)  loss/high_gen_loss: 1107956989952.0000 (4462391650701.4863)  loss/pix_loss: 0.1656 (0.1667)  loss/enc_loss: 0.0006 (0.0005)  time: 4.1859  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [550/862]  eta: 0:21:46  lr: 0.000100  loss/low_gen_loss: 1.8935 (1.8824)  loss/high_gen_loss: 1284470079488.0000 (4407547701957.9238)  loss/pix_loss: 0.1936 (0.1671)  loss/enc_loss: 0.0007 (0.0005)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [560/862]  eta: 0:21:04  lr: 0.000100  loss/low_gen_loss: 1.8882 (1.8825)  loss/high_gen_loss: 1574729285632.0000 (4370112784022.5884)  loss/pix_loss: 0.1858 (0.1671)  loss/enc_loss: 0.0008 (0.0005)  time: 4.1848  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [570/862]  eta: 0:20:22  lr: 0.000100  loss/low_gen_loss: 1.8726 (1.8822)  loss/high_gen_loss: 2231585472512.0000 (4334917976128.5605)  loss/pix_loss: 0.1685 (0.1672)  loss/enc_loss: 0.0011 (0.0005)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [580/862]  eta: 0:19:40  lr: 0.000100  loss/low_gen_loss: 1.8659 (1.8818)  loss/high_gen_loss: 1987884613632.0000 (4288211902823.5454)  loss/pix_loss: 0.1629 (0.1670)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [590/862]  eta: 0:18:58  lr: 0.000100  loss/low_gen_loss: 1.8698 (1.8818)  loss/high_gen_loss: 1460319813632.0000 (4240128009792.9746)  loss/pix_loss: 0.1510 (0.1668)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [600/862]  eta: 0:18:16  lr: 0.000100  loss/low_gen_loss: 1.8863 (1.8819)  loss/high_gen_loss: 1859167584256.0000 (4216708027649.2778)  loss/pix_loss: 0.1629 (0.1669)  loss/enc_loss: 0.0007 (0.0005)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [610/862]  eta: 0:17:35  lr: 0.000100  loss/low_gen_loss: 1.8794 (1.8815)  loss/high_gen_loss: 3664264036352.0000 (4215863114441.9507)  loss/pix_loss: 0.1702 (0.1669)  loss/enc_loss: 0.0007 (0.0005)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [620/862]  eta: 0:16:53  lr: 0.000100  loss/low_gen_loss: 1.8552 (1.8812)  loss/high_gen_loss: 3314775228416.0000 (4194425850690.3706)  loss/pix_loss: 0.1630 (0.1669)  loss/enc_loss: 0.0006 (0.0005)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [630/862]  eta: 0:16:11  lr: 0.000100  loss/low_gen_loss: 1.8668 (1.8810)  loss/high_gen_loss: 2727174995968.0000 (4170465761452.0190)  loss/pix_loss: 0.1556 (0.1667)  loss/enc_loss: 0.0008 (0.0006)  time: 4.1861  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:18]  [640/862]  eta: 0:15:29  lr: 0.000100  loss/low_gen_loss: 1.8580 (1.8806)  loss/high_gen_loss: 2460658171904.0000 (4139692263273.8345)  loss/pix_loss: 0.1584 (0.1667)  loss/enc_loss: 0.0010 (0.0006)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [650/862]  eta: 0:14:47  lr: 0.000100  loss/low_gen_loss: 1.8411 (1.8795)  loss/high_gen_loss: 2388955758592.0000 (4117239217100.0923)  loss/pix_loss: 0.1646 (0.1667)  loss/enc_loss: 0.0010 (0.0006)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [660/862]  eta: 0:14:05  lr: 0.000100  loss/low_gen_loss: 1.8160 (1.8787)  loss/high_gen_loss: 2388955758592.0000 (4090507030614.7534)  loss/pix_loss: 0.1665 (0.1667)  loss/enc_loss: 0.0008 (0.0006)  time: 4.1850  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [670/862]  eta: 0:13:23  lr: 0.000100  loss/low_gen_loss: 1.8218 (1.8778)  loss/high_gen_loss: 2198206939136.0000 (4058605972331.9702)  loss/pix_loss: 0.1722 (0.1668)  loss/enc_loss: 0.0008 (0.0006)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [680/862]  eta: 0:12:41  lr: 0.000100  loss/low_gen_loss: 1.8443 (1.8776)  loss/high_gen_loss: 2025334898688.0000 (4033900675655.4243)  loss/pix_loss: 0.1680 (0.1668)  loss/enc_loss: 0.0008 (0.0006)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [690/862]  eta: 0:12:00  lr: 0.000100  loss/low_gen_loss: 1.8781 (1.8779)  loss/high_gen_loss: 3280320593920.0000 (4029638973419.2534)  loss/pix_loss: 0.1642 (0.1668)  loss/enc_loss: 0.0007 (0.0006)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [700/862]  eta: 0:11:18  lr: 0.000100  loss/low_gen_loss: 1.9124 (1.8785)  loss/high_gen_loss: 3918886600704.0000 (4033909534497.9629)  loss/pix_loss: 0.1643 (0.1667)  loss/enc_loss: 0.0012 (0.0006)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [710/862]  eta: 0:10:36  lr: 0.000100  loss/low_gen_loss: 1.9065 (1.8788)  loss/high_gen_loss: 3929324126208.0000 (4024631799416.2588)  loss/pix_loss: 0.1731 (0.1669)  loss/enc_loss: 0.0007 (0.0006)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [720/862]  eta: 0:09:54  lr: 0.000100  loss/low_gen_loss: 1.8949 (1.8788)  loss/high_gen_loss: 2806157672448.0000 (4004663440075.8057)  loss/pix_loss: 0.1733 (0.1671)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [730/862]  eta: 0:09:12  lr: 0.000100  loss/low_gen_loss: 1.8794 (1.8788)  loss/high_gen_loss: 2689582759936.0000 (3990630806579.8306)  loss/pix_loss: 0.1858 (0.1673)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1867  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [740/862]  eta: 0:08:30  lr: 0.000100  loss/low_gen_loss: 1.8493 (1.8783)  loss/high_gen_loss: 3244967329792.0000 (3989241256497.0581)  loss/pix_loss: 0.1706 (0.1673)  loss/enc_loss: 0.0007 (0.0006)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [750/862]  eta: 0:07:48  lr: 0.000100  loss/low_gen_loss: 1.8493 (1.8783)  loss/high_gen_loss: 3754632937472.0000 (3987073945850.8867)  loss/pix_loss: 0.1694 (0.1673)  loss/enc_loss: 0.0009 (0.0006)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [760/862]  eta: 0:07:07  lr: 0.000100  loss/low_gen_loss: 1.8681 (1.8781)  loss/high_gen_loss: 3024762175488.0000 (3967531665152.3364)  loss/pix_loss: 0.1659 (0.1673)  loss/enc_loss: 0.0011 (0.0006)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [770/862]  eta: 0:06:25  lr: 0.000100  loss/low_gen_loss: 1.8574 (1.8776)  loss/high_gen_loss: 1806160625664.0000 (3935539251006.0908)  loss/pix_loss: 0.1653 (0.1673)  loss/enc_loss: 0.0012 (0.0006)  time: 4.1849  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [780/862]  eta: 0:05:43  lr: 0.000100  loss/low_gen_loss: 1.8370 (1.8770)  loss/high_gen_loss: 1409873215488.0000 (3901988021225.7104)  loss/pix_loss: 0.1610 (0.1673)  loss/enc_loss: 0.0010 (0.0006)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [790/862]  eta: 0:05:01  lr: 0.000100  loss/low_gen_loss: 1.8094 (1.8761)  loss/high_gen_loss: 1546582622208.0000 (3877864390516.1870)  loss/pix_loss: 0.1724 (0.1673)  loss/enc_loss: 0.0007 (0.0006)  time: 4.1841  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [800/862]  eta: 0:04:19  lr: 0.000100  loss/low_gen_loss: 1.8215 (1.8756)  loss/high_gen_loss: 2272588464128.0000 (3859683075658.7866)  loss/pix_loss: 0.1748 (0.1674)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1840  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.8346 (1.8750)  loss/high_gen_loss: 2675337854976.0000 (3849597441222.2344)  loss/pix_loss: 0.1742 (0.1676)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1840  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.8385 (1.8747)  loss/high_gen_loss: 3270266847232.0000 (3848847576130.1050)  loss/pix_loss: 0.1697 (0.1676)  loss/enc_loss: 0.0012 (0.0006)  time: 4.1835  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.8214 (1.8739)  loss/high_gen_loss: 3827457851392.0000 (3848094449274.6089)  loss/pix_loss: 0.1740 (0.1677)  loss/enc_loss: 0.0018 (0.0006)  time: 4.1838  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.8119 (1.8731)  loss/high_gen_loss: 3522592505856.0000 (3836521515380.5850)  loss/pix_loss: 0.1666 (0.1676)  loss/enc_loss: 0.0009 (0.0006)  time: 4.1845  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.8137 (1.8724)  loss/high_gen_loss: 2309099880448.0000 (3817141944806.1294)  loss/pix_loss: 0.1666 (0.1676)  loss/enc_loss: 0.0009 (0.0007)  time: 4.1848  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.8576 (1.8726)  loss/high_gen_loss: 2063458369536.0000 (3795442725577.5889)  loss/pix_loss: 0.1652 (0.1674)  loss/enc_loss: 0.0008 (0.0007)  time: 4.1845  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.8655 (1.8726)  loss/high_gen_loss: 2061050052608.0000 (3792961844487.7217)  loss/pix_loss: 0.1652 (0.1675)  loss/enc_loss: 0.0008 (0.0007)  time: 4.1844  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:18] Total time: 1:00:08 (4.1866 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.8655 (1.8726)  loss/high_gen_loss: 2061050052608.0000 (3792961844487.7217)  loss/pix_loss: 0.1652 (0.1675)  loss/enc_loss: 0.0008 (0.0007)\n",
      "Valid: [epoch:18]  [ 0/14]  eta: 0:00:40  L1_loss: 0.1194 (0.1194)  time: 2.9121  data: 0.3588  max mem: 31350\n",
      "Valid: [epoch:18]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5459  data: 0.0257  max mem: 31350\n",
      "Valid: [epoch:18] Total time: 0:00:35 (2.5537 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_18_input_n_20.png\n",
      "Train: [epoch:19]  [  0/862]  eta: 1:16:36  lr: 0.000100  loss/low_gen_loss: 1.8767 (1.8767)  loss/high_gen_loss: 1647242379264.0000 (1647242379264.0000)  loss/pix_loss: 0.1672 (0.1672)  loss/enc_loss: 0.0009 (0.0009)  time: 5.3320  data: 1.1630  max mem: 31350\n",
      "Train: [epoch:19]  [ 10/862]  eta: 1:00:27  lr: 0.000100  loss/low_gen_loss: 1.8724 (1.8600)  loss/high_gen_loss: 2023155433472.0000 (2033297165218.9092)  loss/pix_loss: 0.1672 (0.1652)  loss/enc_loss: 0.0013 (0.0012)  time: 4.2577  data: 0.1058  max mem: 31350\n",
      "Train: [epoch:19]  [ 20/862]  eta: 0:59:08  lr: 0.000100  loss/low_gen_loss: 1.8248 (1.8369)  loss/high_gen_loss: 2331333361664.0000 (2194255112094.4761)  loss/pix_loss: 0.1647 (0.1656)  loss/enc_loss: 0.0011 (0.0011)  time: 4.1581  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [ 30/862]  eta: 0:58:17  lr: 0.000100  loss/low_gen_loss: 1.8073 (1.8264)  loss/high_gen_loss: 2394427490304.0000 (2420594049024.0000)  loss/pix_loss: 0.1637 (0.1642)  loss/enc_loss: 0.0008 (0.0009)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [ 40/862]  eta: 0:57:31  lr: 0.000100  loss/low_gen_loss: 1.8039 (1.8211)  loss/high_gen_loss: 3231430737920.0000 (2717292835315.5122)  loss/pix_loss: 0.1700 (0.1667)  loss/enc_loss: 0.0009 (0.0010)  time: 4.1837  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:19]  [ 50/862]  eta: 0:56:47  lr: 0.000100  loss/low_gen_loss: 1.8382 (1.8274)  loss/high_gen_loss: 2959125512192.0000 (2697499346823.5293)  loss/pix_loss: 0.1701 (0.1664)  loss/enc_loss: 0.0014 (0.0011)  time: 4.1848  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [ 60/862]  eta: 0:56:03  lr: 0.000100  loss/low_gen_loss: 1.8536 (1.8312)  loss/high_gen_loss: 2547189547008.0000 (2721521587720.3936)  loss/pix_loss: 0.1684 (0.1657)  loss/enc_loss: 0.0009 (0.0011)  time: 4.1840  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [ 70/862]  eta: 0:55:20  lr: 0.000100  loss/low_gen_loss: 1.8371 (1.8309)  loss/high_gen_loss: 1661886267392.0000 (2532195665256.5635)  loss/pix_loss: 0.1663 (0.1665)  loss/enc_loss: 0.0009 (0.0011)  time: 4.1837  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [ 80/862]  eta: 0:54:37  lr: 0.000100  loss/low_gen_loss: 1.8392 (1.8339)  loss/high_gen_loss: 1226257989632.0000 (2360332140341.7285)  loss/pix_loss: 0.1626 (0.1660)  loss/enc_loss: 0.0011 (0.0011)  time: 4.1840  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [ 90/862]  eta: 0:53:55  lr: 0.000100  loss/low_gen_loss: 1.8639 (1.8388)  loss/high_gen_loss: 1136279420928.0000 (2227446480175.8242)  loss/pix_loss: 0.1664 (0.1667)  loss/enc_loss: 0.0006 (0.0010)  time: 4.1843  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [100/862]  eta: 0:53:12  lr: 0.000100  loss/low_gen_loss: 1.8606 (1.8401)  loss/high_gen_loss: 1195842600960.0000 (2128975081836.9900)  loss/pix_loss: 0.1681 (0.1661)  loss/enc_loss: 0.0008 (0.0010)  time: 4.1845  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [110/862]  eta: 0:52:30  lr: 0.000100  loss/low_gen_loss: 1.8506 (1.8421)  loss/high_gen_loss: 1224615788544.0000 (2049480772930.8828)  loss/pix_loss: 0.1563 (0.1657)  loss/enc_loss: 0.0007 (0.0010)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [120/862]  eta: 0:51:48  lr: 0.000100  loss/low_gen_loss: 1.8795 (1.8460)  loss/high_gen_loss: 1224615788544.0000 (1981125014485.6860)  loss/pix_loss: 0.1563 (0.1659)  loss/enc_loss: 0.0007 (0.0010)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [130/862]  eta: 0:51:06  lr: 0.000100  loss/low_gen_loss: 1.9031 (1.8517)  loss/high_gen_loss: 1261547290624.0000 (1929533707021.6794)  loss/pix_loss: 0.1699 (0.1666)  loss/enc_loss: 0.0021 (0.0011)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [140/862]  eta: 0:50:24  lr: 0.000100  loss/low_gen_loss: 1.9141 (1.8549)  loss/high_gen_loss: 1344527532032.0000 (1911309661467.2341)  loss/pix_loss: 0.1666 (0.1663)  loss/enc_loss: 0.0021 (0.0012)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [150/862]  eta: 0:49:42  lr: 0.000100  loss/low_gen_loss: 1.8603 (1.8526)  loss/high_gen_loss: 2070182363136.0000 (1930880629590.4636)  loss/pix_loss: 0.1595 (0.1658)  loss/enc_loss: 0.0015 (0.0012)  time: 4.1840  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [160/862]  eta: 0:48:59  lr: 0.000100  loss/low_gen_loss: 1.8223 (1.8515)  loss/high_gen_loss: 2309855117312.0000 (1984986713883.0310)  loss/pix_loss: 0.1660 (0.1660)  loss/enc_loss: 0.0016 (0.0012)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [170/862]  eta: 0:48:17  lr: 0.000100  loss/low_gen_loss: 1.9275 (1.8583)  loss/high_gen_loss: 2086702546944.0000 (1976318406057.1697)  loss/pix_loss: 0.1648 (0.1660)  loss/enc_loss: 0.0017 (0.0012)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [180/862]  eta: 0:47:35  lr: 0.000100  loss/low_gen_loss: 1.9281 (1.8618)  loss/high_gen_loss: 1832711356416.0000 (1973312076104.1326)  loss/pix_loss: 0.1725 (0.1672)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1839  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [190/862]  eta: 0:46:53  lr: 0.000100  loss/low_gen_loss: 1.9122 (1.8638)  loss/high_gen_loss: 1832711356416.0000 (1961838486404.6912)  loss/pix_loss: 0.1857 (0.1676)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1835  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [200/862]  eta: 0:46:11  lr: 0.000100  loss/low_gen_loss: 1.8995 (1.8648)  loss/high_gen_loss: 1954939404288.0000 (1969812128803.6616)  loss/pix_loss: 0.1855 (0.1687)  loss/enc_loss: 0.0006 (0.0011)  time: 4.1834  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [210/862]  eta: 0:45:29  lr: 0.000100  loss/low_gen_loss: 1.8606 (1.8637)  loss/high_gen_loss: 2147534897152.0000 (1980685440858.9954)  loss/pix_loss: 0.1748 (0.1678)  loss/enc_loss: 0.0009 (0.0011)  time: 4.1831  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [220/862]  eta: 0:44:47  lr: 0.000100  loss/low_gen_loss: 1.8721 (1.8645)  loss/high_gen_loss: 2052996857856.0000 (1974816207682.0271)  loss/pix_loss: 0.1636 (0.1680)  loss/enc_loss: 0.0011 (0.0011)  time: 4.1836  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [230/862]  eta: 0:44:05  lr: 0.000100  loss/low_gen_loss: 1.8825 (1.8649)  loss/high_gen_loss: 1663953797120.0000 (1955691506488.5195)  loss/pix_loss: 0.1655 (0.1674)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1833  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [240/862]  eta: 0:43:23  lr: 0.000100  loss/low_gen_loss: 1.8544 (1.8639)  loss/high_gen_loss: 1583250669568.0000 (1942613164167.9668)  loss/pix_loss: 0.1544 (0.1673)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1825  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [250/862]  eta: 0:42:42  lr: 0.000100  loss/low_gen_loss: 1.8544 (1.8643)  loss/high_gen_loss: 1488444325888.0000 (1919341463984.4463)  loss/pix_loss: 0.1640 (0.1676)  loss/enc_loss: 0.0021 (0.0013)  time: 4.1828  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [260/862]  eta: 0:42:00  lr: 0.000100  loss/low_gen_loss: 1.8915 (1.8655)  loss/high_gen_loss: 1206060449792.0000 (1890336784572.3218)  loss/pix_loss: 0.1661 (0.1675)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1831  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [270/862]  eta: 0:41:18  lr: 0.000100  loss/low_gen_loss: 1.8958 (1.8664)  loss/high_gen_loss: 1164132483072.0000 (1865454885370.3320)  loss/pix_loss: 0.1756 (0.1681)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1828  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [280/862]  eta: 0:40:36  lr: 0.000100  loss/low_gen_loss: 1.8732 (1.8655)  loss/high_gen_loss: 1834590928896.0000 (1879952849777.8789)  loss/pix_loss: 0.1785 (0.1682)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1827  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [290/862]  eta: 0:39:54  lr: 0.000100  loss/low_gen_loss: 1.8358 (1.8641)  loss/high_gen_loss: 2309860884480.0000 (1894416910765.3059)  loss/pix_loss: 0.1714 (0.1682)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1833  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [300/862]  eta: 0:39:12  lr: 0.000100  loss/low_gen_loss: 1.8316 (1.8625)  loss/high_gen_loss: 2196920598528.0000 (1891121071712.9568)  loss/pix_loss: 0.1521 (0.1674)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1849  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [310/862]  eta: 0:38:30  lr: 0.000100  loss/low_gen_loss: 1.8346 (1.8622)  loss/high_gen_loss: 1607346552832.0000 (1879139373648.6687)  loss/pix_loss: 0.1343 (0.1663)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [320/862]  eta: 0:37:48  lr: 0.000100  loss/low_gen_loss: 1.8555 (1.8622)  loss/high_gen_loss: 1740268765184.0000 (1877706746640.7476)  loss/pix_loss: 0.1500 (0.1662)  loss/enc_loss: 0.0015 (0.0012)  time: 4.1827  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [330/862]  eta: 0:37:06  lr: 0.000100  loss/low_gen_loss: 1.8432 (1.8616)  loss/high_gen_loss: 2080714260480.0000 (1894653224174.2114)  loss/pix_loss: 0.1626 (0.1660)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1825  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [340/862]  eta: 0:36:24  lr: 0.000100  loss/low_gen_loss: 1.8655 (1.8624)  loss/high_gen_loss: 2442069016576.0000 (1910924098863.2961)  loss/pix_loss: 0.1643 (0.1660)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1834  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [350/862]  eta: 0:35:42  lr: 0.000100  loss/low_gen_loss: 1.8892 (1.8634)  loss/high_gen_loss: 2719462981632.0000 (1942047340678.1995)  loss/pix_loss: 0.1659 (0.1660)  loss/enc_loss: 0.0012 (0.0012)  time: 4.1828  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [360/862]  eta: 0:35:01  lr: 0.000100  loss/low_gen_loss: 1.8871 (1.8638)  loss/high_gen_loss: 2964610351104.0000 (1967189871766.3379)  loss/pix_loss: 0.1720 (0.1662)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1825  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:19]  [370/862]  eta: 0:34:19  lr: 0.000100  loss/low_gen_loss: 1.8934 (1.8647)  loss/high_gen_loss: 2652969369600.0000 (1977708393585.1643)  loss/pix_loss: 0.1721 (0.1664)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1839  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [380/862]  eta: 0:33:37  lr: 0.000100  loss/low_gen_loss: 1.8961 (1.8655)  loss/high_gen_loss: 2026217799680.0000 (1972983209102.4463)  loss/pix_loss: 0.1704 (0.1660)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1843  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [390/862]  eta: 0:32:55  lr: 0.000100  loss/low_gen_loss: 1.8905 (1.8659)  loss/high_gen_loss: 1432010620928.0000 (1953750766961.2686)  loss/pix_loss: 0.1524 (0.1660)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1827  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [400/862]  eta: 0:32:13  lr: 0.000100  loss/low_gen_loss: 1.8055 (1.8621)  loss/high_gen_loss: 1432010620928.0000 (1953309292875.9700)  loss/pix_loss: 0.1621 (0.1659)  loss/enc_loss: 0.0015 (0.0012)  time: 4.1818  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [410/862]  eta: 0:31:31  lr: 0.000100  loss/low_gen_loss: 1.7662 (1.8602)  loss/high_gen_loss: 2286148911104.0000 (1962818130089.4209)  loss/pix_loss: 0.1750 (0.1661)  loss/enc_loss: 0.0015 (0.0012)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [420/862]  eta: 0:30:49  lr: 0.000100  loss/low_gen_loss: 1.8112 (1.8603)  loss/high_gen_loss: 2396867526656.0000 (1979078725933.6057)  loss/pix_loss: 0.1801 (0.1662)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1860  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [430/862]  eta: 0:30:07  lr: 0.000100  loss/low_gen_loss: 1.8891 (1.8616)  loss/high_gen_loss: 2497396080640.0000 (1983854034982.0139)  loss/pix_loss: 0.1701 (0.1661)  loss/enc_loss: 0.0012 (0.0012)  time: 4.1830  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [440/862]  eta: 0:29:26  lr: 0.000100  loss/low_gen_loss: 1.9319 (1.8633)  loss/high_gen_loss: 2163938164736.0000 (1986791759964.8799)  loss/pix_loss: 0.1606 (0.1661)  loss/enc_loss: 0.0018 (0.0012)  time: 4.1832  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [450/862]  eta: 0:28:44  lr: 0.000100  loss/low_gen_loss: 1.9370 (1.8650)  loss/high_gen_loss: 2125424754688.0000 (1992404342961.0999)  loss/pix_loss: 0.1658 (0.1661)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1830  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [460/862]  eta: 0:28:02  lr: 0.000100  loss/low_gen_loss: 1.9413 (1.8666)  loss/high_gen_loss: 2599865810944.0000 (2010601474167.9480)  loss/pix_loss: 0.1510 (0.1657)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1830  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [470/862]  eta: 0:27:20  lr: 0.000100  loss/low_gen_loss: 1.9389 (1.8679)  loss/high_gen_loss: 2394210959360.0000 (2008507408088.3228)  loss/pix_loss: 0.1547 (0.1656)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1828  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [480/862]  eta: 0:26:38  lr: 0.000100  loss/low_gen_loss: 1.9194 (1.8690)  loss/high_gen_loss: 1967963635712.0000 (2013869329435.6758)  loss/pix_loss: 0.1547 (0.1651)  loss/enc_loss: 0.0018 (0.0013)  time: 4.1845  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [490/862]  eta: 0:25:56  lr: 0.000100  loss/low_gen_loss: 1.9194 (1.8700)  loss/high_gen_loss: 2632272576512.0000 (2029538096363.6660)  loss/pix_loss: 0.1526 (0.1651)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1849  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [500/862]  eta: 0:25:14  lr: 0.000100  loss/low_gen_loss: 1.9199 (1.8711)  loss/high_gen_loss: 2724097425408.0000 (2045518290862.2434)  loss/pix_loss: 0.1598 (0.1649)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1826  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [510/862]  eta: 0:24:33  lr: 0.000100  loss/low_gen_loss: 1.9357 (1.8724)  loss/high_gen_loss: 3182044119040.0000 (2090109870544.9080)  loss/pix_loss: 0.1688 (0.1653)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1818  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [520/862]  eta: 0:23:51  lr: 0.000100  loss/low_gen_loss: 1.9280 (1.8731)  loss/high_gen_loss: 4458258366464.0000 (2138405391212.5911)  loss/pix_loss: 0.1791 (0.1655)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1825  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [530/862]  eta: 0:23:09  lr: 0.000100  loss/low_gen_loss: 1.8952 (1.8731)  loss/high_gen_loss: 4459186356224.0000 (2181828309632.2410)  loss/pix_loss: 0.1680 (0.1654)  loss/enc_loss: 0.0019 (0.0013)  time: 4.1828  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [540/862]  eta: 0:22:27  lr: 0.000100  loss/low_gen_loss: 1.8736 (1.8732)  loss/high_gen_loss: 4220564799488.0000 (2216709236853.3530)  loss/pix_loss: 0.1751 (0.1659)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1829  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [550/862]  eta: 0:21:45  lr: 0.000100  loss/low_gen_loss: 1.8908 (1.8737)  loss/high_gen_loss: 3280158326784.0000 (2225839947567.8550)  loss/pix_loss: 0.1840 (0.1661)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1828  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [560/862]  eta: 0:21:03  lr: 0.000100  loss/low_gen_loss: 1.9010 (1.8744)  loss/high_gen_loss: 2667516526592.0000 (2239860923788.0928)  loss/pix_loss: 0.1752 (0.1661)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1829  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [570/862]  eta: 0:20:21  lr: 0.000100  loss/low_gen_loss: 1.9066 (1.8748)  loss/high_gen_loss: 3834922401792.0000 (2275038364394.0317)  loss/pix_loss: 0.1698 (0.1663)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1829  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [580/862]  eta: 0:19:40  lr: 0.000100  loss/low_gen_loss: 1.8966 (1.8751)  loss/high_gen_loss: 5398157852672.0000 (2370429390361.5562)  loss/pix_loss: 0.1684 (0.1663)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1821  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [590/862]  eta: 0:18:58  lr: 0.000100  loss/low_gen_loss: 1.9001 (1.8756)  loss/high_gen_loss: 7625611149312.0000 (2456736594581.8750)  loss/pix_loss: 0.1646 (0.1661)  loss/enc_loss: 0.0017 (0.0013)  time: 4.1822  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [600/862]  eta: 0:18:16  lr: 0.000100  loss/low_gen_loss: 1.8983 (1.8758)  loss/high_gen_loss: 7159594090496.0000 (2516016622804.9785)  loss/pix_loss: 0.1624 (0.1661)  loss/enc_loss: 0.0018 (0.0013)  time: 4.1828  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [610/862]  eta: 0:17:34  lr: 0.000100  loss/low_gen_loss: 1.8934 (1.8761)  loss/high_gen_loss: 4379538620416.0000 (2543939962574.9785)  loss/pix_loss: 0.1624 (0.1662)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1827  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [620/862]  eta: 0:16:52  lr: 0.000100  loss/low_gen_loss: 1.8936 (1.8764)  loss/high_gen_loss: 4242314362880.0000 (2571107049089.4429)  loss/pix_loss: 0.1778 (0.1663)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1827  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [630/862]  eta: 0:16:10  lr: 0.000100  loss/low_gen_loss: 1.8820 (1.8763)  loss/high_gen_loss: 3901391110144.0000 (2586378039964.6021)  loss/pix_loss: 0.1743 (0.1663)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1833  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [640/862]  eta: 0:15:28  lr: 0.000100  loss/low_gen_loss: 1.8658 (1.8761)  loss/high_gen_loss: 3427948298240.0000 (2596149325728.1499)  loss/pix_loss: 0.1723 (0.1663)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1835  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [650/862]  eta: 0:14:47  lr: 0.000100  loss/low_gen_loss: 1.8766 (1.8763)  loss/high_gen_loss: 3074599157760.0000 (2601589615325.0015)  loss/pix_loss: 0.1621 (0.1662)  loss/enc_loss: 0.0019 (0.0013)  time: 4.1838  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [660/862]  eta: 0:14:05  lr: 0.000100  loss/low_gen_loss: 1.8934 (1.8767)  loss/high_gen_loss: 2925240516608.0000 (2606653959033.2222)  loss/pix_loss: 0.1667 (0.1663)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1833  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [670/862]  eta: 0:13:23  lr: 0.000100  loss/low_gen_loss: 1.8916 (1.8766)  loss/high_gen_loss: 3182708916224.0000 (2620414617493.1743)  loss/pix_loss: 0.1704 (0.1662)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1836  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [680/862]  eta: 0:12:41  lr: 0.000100  loss/low_gen_loss: 1.8984 (1.8772)  loss/high_gen_loss: 3237928763392.0000 (2624069823026.3730)  loss/pix_loss: 0.1719 (0.1662)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1840  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:19]  [690/862]  eta: 0:11:59  lr: 0.000100  loss/low_gen_loss: 1.9076 (1.8775)  loss/high_gen_loss: 2768795074560.0000 (2626751632859.6934)  loss/pix_loss: 0.1754 (0.1664)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1841  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [700/862]  eta: 0:11:17  lr: 0.000100  loss/low_gen_loss: 1.8805 (1.8774)  loss/high_gen_loss: 3116042289152.0000 (2644641884344.0571)  loss/pix_loss: 0.1694 (0.1663)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1844  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [710/862]  eta: 0:10:36  lr: 0.000100  loss/low_gen_loss: 1.8655 (1.8771)  loss/high_gen_loss: 4815154315264.0000 (2678375415024.5176)  loss/pix_loss: 0.1685 (0.1664)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1830  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [720/862]  eta: 0:09:54  lr: 0.000100  loss/low_gen_loss: 1.8612 (1.8772)  loss/high_gen_loss: 4764706275328.0000 (2694674361578.3413)  loss/pix_loss: 0.1756 (0.1665)  loss/enc_loss: 0.0023 (0.0013)  time: 4.1826  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [730/862]  eta: 0:09:12  lr: 0.000100  loss/low_gen_loss: 1.9005 (1.8775)  loss/high_gen_loss: 2788931928064.0000 (2693439830024.4048)  loss/pix_loss: 0.1722 (0.1667)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1841  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [740/862]  eta: 0:08:30  lr: 0.000100  loss/low_gen_loss: 1.9006 (1.8776)  loss/high_gen_loss: 2394634059776.0000 (2684693804229.6143)  loss/pix_loss: 0.1674 (0.1668)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [750/862]  eta: 0:07:48  lr: 0.000100  loss/low_gen_loss: 1.8856 (1.8777)  loss/high_gen_loss: 2052909826048.0000 (2679232458222.9561)  loss/pix_loss: 0.1615 (0.1667)  loss/enc_loss: 0.0020 (0.0013)  time: 4.1833  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [760/862]  eta: 0:07:06  lr: 0.000100  loss/low_gen_loss: 1.8880 (1.8779)  loss/high_gen_loss: 2781519282176.0000 (2685711244762.9961)  loss/pix_loss: 0.1699 (0.1669)  loss/enc_loss: 0.0023 (0.0014)  time: 4.1835  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.8894 (1.8781)  loss/high_gen_loss: 2677890875392.0000 (2682738427279.7715)  loss/pix_loss: 0.1781 (0.1669)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [780/862]  eta: 0:05:43  lr: 0.000100  loss/low_gen_loss: 1.8891 (1.8781)  loss/high_gen_loss: 2424672354304.0000 (2679939161535.0986)  loss/pix_loss: 0.1598 (0.1668)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1836  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [790/862]  eta: 0:05:01  lr: 0.000100  loss/low_gen_loss: 1.8913 (1.8784)  loss/high_gen_loss: 2252416745472.0000 (2666182048756.3491)  loss/pix_loss: 0.1552 (0.1667)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1823  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [800/862]  eta: 0:04:19  lr: 0.000100  loss/low_gen_loss: 1.9024 (1.8787)  loss/high_gen_loss: 1808785604608.0000 (2657116988240.8589)  loss/pix_loss: 0.1659 (0.1668)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1836  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.9038 (1.8791)  loss/high_gen_loss: 2231498178560.0000 (2655466782033.1245)  loss/pix_loss: 0.1778 (0.1670)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.9409 (1.8802)  loss/high_gen_loss: 2779776811008.0000 (2659431335264.9746)  loss/pix_loss: 0.1789 (0.1671)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1842  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.9479 (1.8806)  loss/high_gen_loss: 2879345917952.0000 (2662380727053.2466)  loss/pix_loss: 0.1666 (0.1671)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1837  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.9017 (1.8809)  loss/high_gen_loss: 2811933753344.0000 (2664267466320.9702)  loss/pix_loss: 0.1613 (0.1670)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1828  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.9060 (1.8813)  loss/high_gen_loss: 2678729998336.0000 (2657987849869.3867)  loss/pix_loss: 0.1697 (0.1671)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1838  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.9389 (1.8821)  loss/high_gen_loss: 1578851762176.0000 (2644044203601.4683)  loss/pix_loss: 0.1833 (0.1672)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1849  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.9389 (1.8822)  loss/high_gen_loss: 1577123053568.0000 (2642114229468.9561)  loss/pix_loss: 0.1833 (0.1672)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:19] Total time: 1:00:07 (4.1846 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.9389 (1.8822)  loss/high_gen_loss: 1577123053568.0000 (2642114229468.9561)  loss/pix_loss: 0.1833 (0.1672)  loss/enc_loss: 0.0022 (0.0013)\n",
      "Valid: [epoch:19]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1605 (0.1605)  time: 2.9814  data: 0.3950  max mem: 31350\n",
      "Valid: [epoch:19]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5959  data: 0.0283  max mem: 31350\n",
      "Valid: [epoch:19] Total time: 0:00:36 (2.6048 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_19_input_n_20.png\n",
      "Train: [epoch:20]  [  0/862]  eta: 1:16:12  lr: 0.000100  loss/low_gen_loss: 1.8910 (1.8910)  loss/high_gen_loss: 899440443392.0000 (899440443392.0000)  loss/pix_loss: 0.1751 (0.1751)  loss/enc_loss: 0.0019 (0.0019)  time: 5.3043  data: 1.1085  max mem: 31350\n",
      "Train: [epoch:20]  [ 10/862]  eta: 1:00:56  lr: 0.000100  loss/low_gen_loss: 1.8834 (1.8849)  loss/high_gen_loss: 892401287168.0000 (914547486347.6364)  loss/pix_loss: 0.1641 (0.1652)  loss/enc_loss: 0.0016 (0.0017)  time: 4.2914  data: 0.1009  max mem: 31350\n",
      "Train: [epoch:20]  [ 20/862]  eta: 0:59:30  lr: 0.000100  loss/low_gen_loss: 1.8787 (1.8849)  loss/high_gen_loss: 1124873142272.0000 (1274388130474.6667)  loss/pix_loss: 0.1678 (0.1688)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1867  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [ 30/862]  eta: 0:58:33  lr: 0.000100  loss/low_gen_loss: 1.8896 (1.8876)  loss/high_gen_loss: 2163079774208.0000 (1673134441505.0322)  loss/pix_loss: 0.1715 (0.1686)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [ 40/862]  eta: 0:57:44  lr: 0.000100  loss/low_gen_loss: 1.8584 (1.8762)  loss/high_gen_loss: 2163079774208.0000 (1655170238813.6584)  loss/pix_loss: 0.1715 (0.1685)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [ 50/862]  eta: 0:56:57  lr: 0.000100  loss/low_gen_loss: 1.8584 (1.8758)  loss/high_gen_loss: 825332137984.0000 (1429372997391.0588)  loss/pix_loss: 0.1603 (0.1667)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [ 60/862]  eta: 0:56:12  lr: 0.000100  loss/low_gen_loss: 1.8787 (1.8773)  loss/high_gen_loss: 607000788992.0000 (1400969946296.6558)  loss/pix_loss: 0.1629 (0.1669)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [ 70/862]  eta: 0:55:27  lr: 0.000100  loss/low_gen_loss: 1.8963 (1.8825)  loss/high_gen_loss: 2915805954048.0000 (1886496192713.9155)  loss/pix_loss: 0.1721 (0.1688)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1835  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [ 80/862]  eta: 0:54:44  lr: 0.000100  loss/low_gen_loss: 1.8840 (1.8805)  loss/high_gen_loss: 4562772033536.0000 (2163494136895.2100)  loss/pix_loss: 0.1745 (0.1692)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1848  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [ 90/862]  eta: 0:54:00  lr: 0.000100  loss/low_gen_loss: 1.8589 (1.8771)  loss/high_gen_loss: 2578937806848.0000 (2191108588420.2197)  loss/pix_loss: 0.1648 (0.1673)  loss/enc_loss: 0.0022 (0.0015)  time: 4.1854  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [100/862]  eta: 0:53:18  lr: 0.000100  loss/low_gen_loss: 1.8395 (1.8729)  loss/high_gen_loss: 2227353419776.0000 (2168472982436.7524)  loss/pix_loss: 0.1520 (0.1661)  loss/enc_loss: 0.0022 (0.0014)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [110/862]  eta: 0:52:35  lr: 0.000100  loss/low_gen_loss: 1.8549 (1.8719)  loss/high_gen_loss: 1621418704896.0000 (2110044660228.6125)  loss/pix_loss: 0.1611 (0.1665)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [120/862]  eta: 0:51:52  lr: 0.000100  loss/low_gen_loss: 1.8541 (1.8696)  loss/high_gen_loss: 1217568440320.0000 (2018301669680.6611)  loss/pix_loss: 0.1645 (0.1665)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [130/862]  eta: 0:51:10  lr: 0.000100  loss/low_gen_loss: 1.8504 (1.8684)  loss/high_gen_loss: 1217568440320.0000 (2062471370611.2976)  loss/pix_loss: 0.1719 (0.1666)  loss/enc_loss: 0.0017 (0.0014)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [140/862]  eta: 0:50:28  lr: 0.000100  loss/low_gen_loss: 1.8601 (1.8682)  loss/high_gen_loss: 2026302341120.0000 (2051980971073.3618)  loss/pix_loss: 0.1637 (0.1663)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1872  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [150/862]  eta: 0:49:45  lr: 0.000100  loss/low_gen_loss: 1.8687 (1.8689)  loss/high_gen_loss: 2200785387520.0000 (2120036159298.1191)  loss/pix_loss: 0.1581 (0.1655)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [160/862]  eta: 0:49:03  lr: 0.000100  loss/low_gen_loss: 1.8627 (1.8676)  loss/high_gen_loss: 3657183526912.0000 (2256685783510.6582)  loss/pix_loss: 0.1629 (0.1660)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [170/862]  eta: 0:48:21  lr: 0.000100  loss/low_gen_loss: 1.8317 (1.8640)  loss/high_gen_loss: 4007599276032.0000 (2344626541526.0820)  loss/pix_loss: 0.1673 (0.1662)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1886  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [180/862]  eta: 0:47:39  lr: 0.000100  loss/low_gen_loss: 1.8180 (1.8617)  loss/high_gen_loss: 1942660972544.0000 (2280019257151.6465)  loss/pix_loss: 0.1673 (0.1667)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1869  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [190/862]  eta: 0:46:57  lr: 0.000100  loss/low_gen_loss: 1.8207 (1.8595)  loss/high_gen_loss: 1178809532416.0000 (2238554767531.5601)  loss/pix_loss: 0.1695 (0.1671)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [200/862]  eta: 0:46:15  lr: 0.000100  loss/low_gen_loss: 1.8228 (1.8591)  loss/high_gen_loss: 2389994897408.0000 (2282985799924.5371)  loss/pix_loss: 0.1703 (0.1676)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [210/862]  eta: 0:45:33  lr: 0.000100  loss/low_gen_loss: 1.8566 (1.8595)  loss/high_gen_loss: 3278731476992.0000 (2336577180133.3081)  loss/pix_loss: 0.1648 (0.1673)  loss/enc_loss: 0.0024 (0.0016)  time: 4.1899  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [220/862]  eta: 0:44:51  lr: 0.000100  loss/low_gen_loss: 1.8597 (1.8594)  loss/high_gen_loss: 3278731476992.0000 (2384014909254.6606)  loss/pix_loss: 0.1628 (0.1669)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1891  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [230/862]  eta: 0:44:08  lr: 0.000100  loss/low_gen_loss: 1.8519 (1.8589)  loss/high_gen_loss: 4283081162752.0000 (2506918121418.8052)  loss/pix_loss: 0.1621 (0.1664)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [240/862]  eta: 0:43:26  lr: 0.000100  loss/low_gen_loss: 1.8451 (1.8583)  loss/high_gen_loss: 6931747438592.0000 (2961180270150.1079)  loss/pix_loss: 0.1579 (0.1667)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [250/862]  eta: 0:42:44  lr: 0.000100  loss/low_gen_loss: 1.8326 (1.8563)  loss/high_gen_loss: 16462593916928.0000 (3562966225891.4424)  loss/pix_loss: 0.1579 (0.1663)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [260/862]  eta: 0:42:02  lr: 0.000100  loss/low_gen_loss: 1.8008 (1.8541)  loss/high_gen_loss: 15737158631424.0000 (3934097669390.7124)  loss/pix_loss: 0.1498 (0.1657)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [270/862]  eta: 0:41:20  lr: 0.000100  loss/low_gen_loss: 1.8072 (1.8532)  loss/high_gen_loss: 22541852737536.0000 (4943962940147.7197)  loss/pix_loss: 0.1749 (0.1665)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1844  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [280/862]  eta: 0:40:38  lr: 0.000100  loss/low_gen_loss: 1.8218 (1.8520)  loss/high_gen_loss: 31634472566784.0000 (5988149829486.2354)  loss/pix_loss: 0.1807 (0.1665)  loss/enc_loss: 0.0024 (0.0016)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [290/862]  eta: 0:39:56  lr: 0.000100  loss/low_gen_loss: 1.8143 (1.8504)  loss/high_gen_loss: 45378703458304.0000 (7607410143105.3193)  loss/pix_loss: 0.1662 (0.1665)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [300/862]  eta: 0:39:14  lr: 0.000100  loss/low_gen_loss: 1.7995 (1.8487)  loss/high_gen_loss: 50433577975808.0000 (8990207290208.1055)  loss/pix_loss: 0.1453 (0.1656)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1845  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [310/862]  eta: 0:38:32  lr: 0.000100  loss/low_gen_loss: 1.8031 (1.8479)  loss/high_gen_loss: 40658203049984.0000 (9729867743442.7266)  loss/pix_loss: 0.1379 (0.1651)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1839  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [320/862]  eta: 0:37:50  lr: 0.000100  loss/low_gen_loss: 1.8361 (1.8477)  loss/high_gen_loss: 31258723745792.0000 (10414222046830.0566)  loss/pix_loss: 0.1641 (0.1653)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1851  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [330/862]  eta: 0:37:08  lr: 0.000100  loss/low_gen_loss: 1.8347 (1.8471)  loss/high_gen_loss: 33274193772544.0000 (11199969719794.0781)  loss/pix_loss: 0.1641 (0.1650)  loss/enc_loss: 0.0022 (0.0016)  time: 4.1860  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [340/862]  eta: 0:36:26  lr: 0.000100  loss/low_gen_loss: 1.8563 (1.8480)  loss/high_gen_loss: 35771486568448.0000 (11893958913195.1680)  loss/pix_loss: 0.1617 (0.1652)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1857  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [350/862]  eta: 0:35:44  lr: 0.000100  loss/low_gen_loss: 1.8697 (1.8483)  loss/high_gen_loss: 33878462955520.0000 (12506402007909.3789)  loss/pix_loss: 0.1665 (0.1651)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1850  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [360/862]  eta: 0:35:03  lr: 0.000100  loss/low_gen_loss: 1.8540 (1.8483)  loss/high_gen_loss: 33098360160256.0000 (13183753667876.1660)  loss/pix_loss: 0.1675 (0.1654)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1877  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [370/862]  eta: 0:34:21  lr: 0.000100  loss/low_gen_loss: 1.8293 (1.8476)  loss/high_gen_loss: 40918270869504.0000 (14006478616725.0449)  loss/pix_loss: 0.1675 (0.1655)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1881  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [380/862]  eta: 0:33:39  lr: 0.000100  loss/low_gen_loss: 1.8360 (1.8477)  loss/high_gen_loss: 35330606497792.0000 (14360827941283.2754)  loss/pix_loss: 0.1602 (0.1652)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [390/862]  eta: 0:32:57  lr: 0.000100  loss/low_gen_loss: 1.8445 (1.8472)  loss/high_gen_loss: 21391495659520.0000 (14511305989075.4785)  loss/pix_loss: 0.1549 (0.1652)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [400/862]  eta: 0:32:15  lr: 0.000100  loss/low_gen_loss: 1.8356 (1.8471)  loss/high_gen_loss: 19081732292608.0000 (14517059389108.0293)  loss/pix_loss: 0.1730 (0.1655)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1847  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [410/862]  eta: 0:31:33  lr: 0.000100  loss/low_gen_loss: 1.8513 (1.8473)  loss/high_gen_loss: 13200108027904.0000 (14528782739500.8477)  loss/pix_loss: 0.1732 (0.1657)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1871  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [420/862]  eta: 0:30:51  lr: 0.000100  loss/low_gen_loss: 1.8389 (1.8470)  loss/high_gen_loss: 22152952676352.0000 (14784830110732.1621)  loss/pix_loss: 0.1703 (0.1658)  loss/enc_loss: 0.0020 (0.0015)  time: 4.1874  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [430/862]  eta: 0:30:09  lr: 0.000100  loss/low_gen_loss: 1.8316 (1.8467)  loss/high_gen_loss: 29356042747904.0000 (15309996205571.5645)  loss/pix_loss: 0.1703 (0.1660)  loss/enc_loss: 0.0022 (0.0015)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [440/862]  eta: 0:29:27  lr: 0.000100  loss/low_gen_loss: 1.8250 (1.8464)  loss/high_gen_loss: 34317789036544.0000 (15707047502697.0703)  loss/pix_loss: 0.1618 (0.1659)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1859  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [450/862]  eta: 0:28:45  lr: 0.000100  loss/low_gen_loss: 1.8214 (1.8458)  loss/high_gen_loss: 27316535164928.0000 (15862289970232.7637)  loss/pix_loss: 0.1572 (0.1661)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1844  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [460/862]  eta: 0:28:03  lr: 0.000100  loss/low_gen_loss: 1.7974 (1.8443)  loss/high_gen_loss: 24523365679104.0000 (16134133763518.4727)  loss/pix_loss: 0.1548 (0.1658)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1849  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [470/862]  eta: 0:27:21  lr: 0.000100  loss/low_gen_loss: 1.7636 (1.8423)  loss/high_gen_loss: 33539517054976.0000 (16589530102416.5781)  loss/pix_loss: 0.1530 (0.1658)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [480/862]  eta: 0:26:39  lr: 0.000100  loss/low_gen_loss: 1.7523 (1.8406)  loss/high_gen_loss: 39189152268288.0000 (17112690070517.3555)  loss/pix_loss: 0.1588 (0.1657)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [490/862]  eta: 0:25:58  lr: 0.000100  loss/low_gen_loss: 1.7451 (1.8388)  loss/high_gen_loss: 36321271742464.0000 (17423136350124.5781)  loss/pix_loss: 0.1588 (0.1656)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1859  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [500/862]  eta: 0:25:16  lr: 0.000100  loss/low_gen_loss: 1.7994 (1.8385)  loss/high_gen_loss: 30156058001408.0000 (17681056538476.8398)  loss/pix_loss: 0.1583 (0.1656)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [510/862]  eta: 0:24:34  lr: 0.000100  loss/low_gen_loss: 1.8181 (1.8377)  loss/high_gen_loss: 30738059624448.0000 (17968227381881.2383)  loss/pix_loss: 0.1691 (0.1659)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1863  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [520/862]  eta: 0:23:52  lr: 0.000100  loss/low_gen_loss: 1.7850 (1.8365)  loss/high_gen_loss: 29482740088832.0000 (18153716363177.5195)  loss/pix_loss: 0.1775 (0.1661)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [530/862]  eta: 0:23:10  lr: 0.000100  loss/low_gen_loss: 1.8062 (1.8360)  loss/high_gen_loss: 26215245152256.0000 (18245839956650.6680)  loss/pix_loss: 0.1691 (0.1659)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [540/862]  eta: 0:22:28  lr: 0.000100  loss/low_gen_loss: 1.8099 (1.8355)  loss/high_gen_loss: 20862673616896.0000 (18279873590830.3750)  loss/pix_loss: 0.1527 (0.1660)  loss/enc_loss: 0.0027 (0.0016)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [550/862]  eta: 0:21:46  lr: 0.000100  loss/low_gen_loss: 1.7992 (1.8347)  loss/high_gen_loss: 17061078106112.0000 (18231418575097.0312)  loss/pix_loss: 0.1836 (0.1663)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1860  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [560/862]  eta: 0:21:04  lr: 0.000100  loss/low_gen_loss: 1.8038 (1.8346)  loss/high_gen_loss: 11866633928704.0000 (18097602508774.4453)  loss/pix_loss: 0.1719 (0.1663)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [570/862]  eta: 0:20:22  lr: 0.000100  loss/low_gen_loss: 1.8266 (1.8345)  loss/high_gen_loss: 8898074378240.0000 (17883367350286.3477)  loss/pix_loss: 0.1719 (0.1666)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1844  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [580/862]  eta: 0:19:40  lr: 0.000100  loss/low_gen_loss: 1.8238 (1.8343)  loss/high_gen_loss: 4351722258432.0000 (17649258043790.3203)  loss/pix_loss: 0.1644 (0.1664)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1848  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [590/862]  eta: 0:18:59  lr: 0.000100  loss/low_gen_loss: 1.8187 (1.8339)  loss/high_gen_loss: 4198227509248.0000 (17417868752587.5879)  loss/pix_loss: 0.1569 (0.1662)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [600/862]  eta: 0:18:17  lr: 0.000100  loss/low_gen_loss: 1.8062 (1.8334)  loss/high_gen_loss: 2247863828480.0000 (17158912422958.0039)  loss/pix_loss: 0.1559 (0.1659)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [610/862]  eta: 0:17:35  lr: 0.000100  loss/low_gen_loss: 1.8115 (1.8331)  loss/high_gen_loss: 1134671036416.0000 (16894841322393.7676)  loss/pix_loss: 0.1634 (0.1660)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1846  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [620/862]  eta: 0:16:53  lr: 0.000100  loss/low_gen_loss: 1.8243 (1.8332)  loss/high_gen_loss: 1092384194560.0000 (16658414206976.0000)  loss/pix_loss: 0.1765 (0.1663)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1861  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [630/862]  eta: 0:16:11  lr: 0.000100  loss/low_gen_loss: 1.8372 (1.8335)  loss/high_gen_loss: 5879037952000.0000 (16525384090482.8145)  loss/pix_loss: 0.1667 (0.1661)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [640/862]  eta: 0:15:29  lr: 0.000100  loss/low_gen_loss: 1.8283 (1.8332)  loss/high_gen_loss: 8973317046272.0000 (16488831897874.7715)  loss/pix_loss: 0.1652 (0.1660)  loss/enc_loss: 0.0025 (0.0016)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [650/862]  eta: 0:14:47  lr: 0.000100  loss/low_gen_loss: 1.8219 (1.8331)  loss/high_gen_loss: 15738467254272.0000 (16521430130222.4023)  loss/pix_loss: 0.1675 (0.1662)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [660/862]  eta: 0:14:05  lr: 0.000100  loss/low_gen_loss: 1.8336 (1.8334)  loss/high_gen_loss: 17516712689664.0000 (16529445815015.6016)  loss/pix_loss: 0.1717 (0.1662)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1867  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [670/862]  eta: 0:13:24  lr: 0.000100  loss/low_gen_loss: 1.8290 (1.8333)  loss/high_gen_loss: 18218726981632.0000 (16592618778862.0684)  loss/pix_loss: 0.1717 (0.1664)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1871  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [680/862]  eta: 0:12:42  lr: 0.000100  loss/low_gen_loss: 1.7873 (1.8322)  loss/high_gen_loss: 14973321347072.0000 (16543256903968.7051)  loss/pix_loss: 0.1755 (0.1664)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1873  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [690/862]  eta: 0:12:00  lr: 0.000100  loss/low_gen_loss: 1.7242 (1.8304)  loss/high_gen_loss: 13123479142400.0000 (16502355618624.8340)  loss/pix_loss: 0.1775 (0.1667)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [700/862]  eta: 0:11:18  lr: 0.000100  loss/low_gen_loss: 1.7020 (1.8282)  loss/high_gen_loss: 14583503781888.0000 (16481712497165.8770)  loss/pix_loss: 0.1801 (0.1666)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [710/862]  eta: 0:10:36  lr: 0.000100  loss/low_gen_loss: 1.7531 (1.8278)  loss/high_gen_loss: 15745940455424.0000 (16615271850709.8730)  loss/pix_loss: 0.1541 (0.1664)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1868  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [720/862]  eta: 0:09:54  lr: 0.000100  loss/low_gen_loss: 1.7965 (1.8274)  loss/high_gen_loss: 50563337158656.0000 (17368063600921.2090)  loss/pix_loss: 0.1698 (0.1667)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [730/862]  eta: 0:09:12  lr: 0.000100  loss/low_gen_loss: 1.7860 (1.8268)  loss/high_gen_loss: 75050485022720.0000 (18223418627891.4805)  loss/pix_loss: 0.1749 (0.1667)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1872  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:20]  [740/862]  eta: 0:08:30  lr: 0.000100  loss/low_gen_loss: 1.7940 (1.8266)  loss/high_gen_loss: 66603848826880.0000 (18828212337980.4570)  loss/pix_loss: 0.1652 (0.1668)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1865  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [750/862]  eta: 0:07:49  lr: 0.000100  loss/low_gen_loss: 1.8358 (1.8275)  loss/high_gen_loss: 66603848826880.0000 (19623737615154.1094)  loss/pix_loss: 0.1668 (0.1669)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1862  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [760/862]  eta: 0:07:07  lr: 0.000100  loss/low_gen_loss: 1.8442 (1.8274)  loss/high_gen_loss: 76792127815680.0000 (20442301354732.1523)  loss/pix_loss: 0.1812 (0.1670)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1864  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [770/862]  eta: 0:06:25  lr: 0.000100  loss/low_gen_loss: 1.8147 (1.8272)  loss/high_gen_loss: 67887695921152.0000 (21025103652314.1484)  loss/pix_loss: 0.1623 (0.1669)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1882  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [780/862]  eta: 0:05:43  lr: 0.000100  loss/low_gen_loss: 1.8081 (1.8269)  loss/high_gen_loss: 62104358879232.0000 (21525040906806.4141)  loss/pix_loss: 0.1623 (0.1669)  loss/enc_loss: 0.0020 (0.0015)  time: 4.1875  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [790/862]  eta: 0:05:01  lr: 0.000100  loss/low_gen_loss: 1.7818 (1.8261)  loss/high_gen_loss: 64391844200448.0000 (22331073951596.4180)  loss/pix_loss: 0.1584 (0.1668)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1860  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [800/862]  eta: 0:04:19  lr: 0.000100  loss/low_gen_loss: 1.7791 (1.8256)  loss/high_gen_loss: 85883650834432.0000 (23141555005693.1250)  loss/pix_loss: 0.1649 (0.1668)  loss/enc_loss: 0.0018 (0.0016)  time: 4.1859  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.7896 (1.8253)  loss/high_gen_loss: 84500000276480.0000 (23677294957357.1406)  loss/pix_loss: 0.1677 (0.1668)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.8010 (1.8251)  loss/high_gen_loss: 72912555999232.0000 (24326028558814.9492)  loss/pix_loss: 0.1714 (0.1668)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1858  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.8010 (1.8246)  loss/high_gen_loss: 84879324741632.0000 (25117948517187.4648)  loss/pix_loss: 0.1736 (0.1668)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1855  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [840/862]  eta: 0:01:32  lr: 0.000100  loss/low_gen_loss: 1.7759 (1.8240)  loss/high_gen_loss: 90470113869824.0000 (25949656019221.6133)  loss/pix_loss: 0.1659 (0.1668)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1852  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.7635 (1.8232)  loss/high_gen_loss: 84738664562688.0000 (26486165564761.3438)  loss/pix_loss: 0.1590 (0.1668)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1856  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.7432 (1.8219)  loss/high_gen_loss: 54785420034048.0000 (26686992215707.2070)  loss/pix_loss: 0.1749 (0.1669)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1854  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.7429 (1.8217)  loss/high_gen_loss: 52801392607232.0000 (26680359380027.3984)  loss/pix_loss: 0.1749 (0.1670)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1853  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:20] Total time: 1:00:09 (4.1877 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.7429 (1.8217)  loss/high_gen_loss: 52801392607232.0000 (26680359380027.3984)  loss/pix_loss: 0.1749 (0.1670)  loss/enc_loss: 0.0010 (0.0016)\n",
      "Valid: [epoch:20]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1329 (0.1329)  time: 2.9677  data: 0.3656  max mem: 31350\n",
      "Valid: [epoch:20]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6059  data: 0.0262  max mem: 31350\n",
      "Valid: [epoch:20] Total time: 0:00:36 (2.6163 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_20_input_n_20.png\n",
      "Train: [epoch:21]  [  0/862]  eta: 1:15:51  lr: 0.000100  loss/low_gen_loss: 1.6742 (1.6742)  loss/high_gen_loss: 18571124015104.0000 (18571124015104.0000)  loss/pix_loss: 0.1379 (0.1379)  loss/enc_loss: 0.0022 (0.0022)  time: 5.2804  data: 1.1112  max mem: 31350\n",
      "Train: [epoch:21]  [ 10/862]  eta: 1:00:26  lr: 0.000100  loss/low_gen_loss: 1.7163 (1.7095)  loss/high_gen_loss: 14968227364864.0000 (15807501208482.9082)  loss/pix_loss: 0.1675 (0.1669)  loss/enc_loss: 0.0022 (0.0021)  time: 4.2559  data: 0.1011  max mem: 31350\n",
      "Train: [epoch:21]  [ 20/862]  eta: 0:59:06  lr: 0.000100  loss/low_gen_loss: 1.7001 (1.7005)  loss/high_gen_loss: 19168046874624.0000 (22422541416155.4297)  loss/pix_loss: 0.1675 (0.1686)  loss/enc_loss: 0.0019 (0.0019)  time: 4.1585  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [ 30/862]  eta: 0:58:14  lr: 0.000100  loss/low_gen_loss: 1.7243 (1.7201)  loss/high_gen_loss: 34250529177600.0000 (26670793279025.5469)  loss/pix_loss: 0.1716 (0.1701)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [ 40/862]  eta: 0:57:27  lr: 0.000100  loss/low_gen_loss: 1.7502 (1.7259)  loss/high_gen_loss: 32424044003328.0000 (27816097052322.3398)  loss/pix_loss: 0.1716 (0.1697)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [ 50/862]  eta: 0:56:42  lr: 0.000100  loss/low_gen_loss: 1.7548 (1.7356)  loss/high_gen_loss: 30457605390336.0000 (27461626276522.6680)  loss/pix_loss: 0.1613 (0.1677)  loss/enc_loss: 0.0017 (0.0019)  time: 4.1760  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [ 60/862]  eta: 0:55:58  lr: 0.000100  loss/low_gen_loss: 1.7784 (1.7478)  loss/high_gen_loss: 16379731247104.0000 (25143855593639.8672)  loss/pix_loss: 0.1627 (0.1668)  loss/enc_loss: 0.0024 (0.0019)  time: 4.1762  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [ 70/862]  eta: 0:55:15  lr: 0.000100  loss/low_gen_loss: 1.8421 (1.7631)  loss/high_gen_loss: 10713249611776.0000 (22919900731247.7734)  loss/pix_loss: 0.1665 (0.1685)  loss/enc_loss: 0.0013 (0.0018)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [ 80/862]  eta: 0:54:32  lr: 0.000100  loss/low_gen_loss: 1.8452 (1.7712)  loss/high_gen_loss: 10713249611776.0000 (21630455540596.9375)  loss/pix_loss: 0.1707 (0.1681)  loss/enc_loss: 0.0012 (0.0017)  time: 4.1760  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [ 90/862]  eta: 0:53:50  lr: 0.000100  loss/low_gen_loss: 1.8182 (1.7765)  loss/high_gen_loss: 12628360429568.0000 (20504179603703.5586)  loss/pix_loss: 0.1667 (0.1676)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1765  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [100/862]  eta: 0:53:07  lr: 0.000100  loss/low_gen_loss: 1.8122 (1.7798)  loss/high_gen_loss: 9780076740608.0000 (19381029401103.2070)  loss/pix_loss: 0.1599 (0.1647)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1767  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [110/862]  eta: 0:52:25  lr: 0.000100  loss/low_gen_loss: 1.7550 (1.7743)  loss/high_gen_loss: 8852935278592.0000 (18446080018745.6562)  loss/pix_loss: 0.1632 (0.1655)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1768  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [120/862]  eta: 0:51:43  lr: 0.000100  loss/low_gen_loss: 1.7352 (1.7712)  loss/high_gen_loss: 9327046819840.0000 (17732695891358.6758)  loss/pix_loss: 0.1655 (0.1649)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1765  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [130/862]  eta: 0:51:01  lr: 0.000100  loss/low_gen_loss: 1.7255 (1.7674)  loss/high_gen_loss: 8670238212096.0000 (16977216307450.1367)  loss/pix_loss: 0.1616 (0.1652)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1762  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [140/862]  eta: 0:50:18  lr: 0.000100  loss/low_gen_loss: 1.7293 (1.7656)  loss/high_gen_loss: 4772829593600.0000 (16059549119538.8359)  loss/pix_loss: 0.1653 (0.1652)  loss/enc_loss: 0.0020 (0.0017)  time: 4.1761  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:21]  [150/862]  eta: 0:49:36  lr: 0.000100  loss/low_gen_loss: 1.7464 (1.7649)  loss/high_gen_loss: 4772829593600.0000 (15784997033048.1582)  loss/pix_loss: 0.1591 (0.1646)  loss/enc_loss: 0.0027 (0.0018)  time: 4.1757  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [160/862]  eta: 0:48:54  lr: 0.000100  loss/low_gen_loss: 1.7558 (1.7647)  loss/high_gen_loss: 21971452559360.0000 (16831852453023.0059)  loss/pix_loss: 0.1513 (0.1643)  loss/enc_loss: 0.0013 (0.0017)  time: 4.1777  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [170/862]  eta: 0:48:12  lr: 0.000100  loss/low_gen_loss: 1.7506 (1.7640)  loss/high_gen_loss: 35157761327104.0000 (18049537824468.5859)  loss/pix_loss: 0.1601 (0.1644)  loss/enc_loss: 0.0007 (0.0016)  time: 4.1777  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [180/862]  eta: 0:47:31  lr: 0.000100  loss/low_gen_loss: 1.7787 (1.7654)  loss/high_gen_loss: 32661800222720.0000 (18398878001321.7227)  loss/pix_loss: 0.1806 (0.1658)  loss/enc_loss: 0.0007 (0.0016)  time: 4.1787  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [190/862]  eta: 0:46:49  lr: 0.000100  loss/low_gen_loss: 1.7542 (1.7628)  loss/high_gen_loss: 15858424348672.0000 (18092674561608.3789)  loss/pix_loss: 0.1858 (0.1663)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1786  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [200/862]  eta: 0:46:07  lr: 0.000100  loss/low_gen_loss: 1.7609 (1.7647)  loss/high_gen_loss: 13993367306240.0000 (18220476968898.8672)  loss/pix_loss: 0.1812 (0.1671)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [210/862]  eta: 0:45:25  lr: 0.000100  loss/low_gen_loss: 1.7966 (1.7663)  loss/high_gen_loss: 32241218486272.0000 (19908368080468.9297)  loss/pix_loss: 0.1715 (0.1664)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1757  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [220/862]  eta: 0:44:43  lr: 0.000100  loss/low_gen_loss: 1.8473 (1.7705)  loss/high_gen_loss: 58169682296832.0000 (21612014534952.5430)  loss/pix_loss: 0.1527 (0.1660)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1766  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [230/862]  eta: 0:44:01  lr: 0.000100  loss/low_gen_loss: 1.8717 (1.7762)  loss/high_gen_loss: 48534489399296.0000 (22372703949314.2148)  loss/pix_loss: 0.1655 (0.1662)  loss/enc_loss: 0.0025 (0.0016)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [240/862]  eta: 0:43:19  lr: 0.000100  loss/low_gen_loss: 1.8536 (1.7773)  loss/high_gen_loss: 30094057799680.0000 (22230809624915.9180)  loss/pix_loss: 0.1700 (0.1666)  loss/enc_loss: 0.0022 (0.0017)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [250/862]  eta: 0:42:37  lr: 0.000100  loss/low_gen_loss: 1.7166 (1.7726)  loss/high_gen_loss: 14282510041088.0000 (21883561389019.2812)  loss/pix_loss: 0.1698 (0.1665)  loss/enc_loss: 0.0019 (0.0017)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [260/862]  eta: 0:41:55  lr: 0.000100  loss/low_gen_loss: 1.7467 (1.7754)  loss/high_gen_loss: 17317351129088.0000 (22608035200710.1289)  loss/pix_loss: 0.1622 (0.1667)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1753  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [270/862]  eta: 0:41:13  lr: 0.000100  loss/low_gen_loss: 1.8701 (1.7791)  loss/high_gen_loss: 67225474039808.0000 (25158352058299.9844)  loss/pix_loss: 0.1790 (0.1673)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1765  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [280/862]  eta: 0:40:32  lr: 0.000100  loss/low_gen_loss: 1.8550 (1.7815)  loss/high_gen_loss: 113131602837504.0000 (28892975363228.6992)  loss/pix_loss: 0.1769 (0.1673)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1754  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [290/862]  eta: 0:39:50  lr: 0.000100  loss/low_gen_loss: 1.8244 (1.7817)  loss/high_gen_loss: 147296524173312.0000 (33436977061972.4531)  loss/pix_loss: 0.1617 (0.1672)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1759  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [300/862]  eta: 0:39:08  lr: 0.000100  loss/low_gen_loss: 1.8244 (1.7849)  loss/high_gen_loss: 152492897730560.0000 (37053190542332.6016)  loss/pix_loss: 0.1469 (0.1664)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1754  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [310/862]  eta: 0:38:26  lr: 0.000100  loss/low_gen_loss: 1.8693 (1.7864)  loss/high_gen_loss: 150655842910208.0000 (40798198076037.3516)  loss/pix_loss: 0.1467 (0.1659)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [320/862]  eta: 0:37:44  lr: 0.000100  loss/low_gen_loss: 1.9059 (1.7910)  loss/high_gen_loss: 148152648728576.0000 (43595117300318.1094)  loss/pix_loss: 0.1563 (0.1657)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1754  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [330/862]  eta: 0:37:02  lr: 0.000100  loss/low_gen_loss: 1.9145 (1.7939)  loss/high_gen_loss: 103515657601024.0000 (44517191530217.5703)  loss/pix_loss: 0.1659 (0.1658)  loss/enc_loss: 0.0032 (0.0016)  time: 4.1756  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [340/862]  eta: 0:36:21  lr: 0.000100  loss/low_gen_loss: 1.9038 (1.7973)  loss/high_gen_loss: 43546505641984.0000 (44340017431873.3125)  loss/pix_loss: 0.1623 (0.1656)  loss/enc_loss: 0.0023 (0.0016)  time: 4.1759  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [350/862]  eta: 0:35:39  lr: 0.000100  loss/low_gen_loss: 1.8902 (1.7994)  loss/high_gen_loss: 34785640579072.0000 (43774909141517.1250)  loss/pix_loss: 0.1643 (0.1658)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1761  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [360/862]  eta: 0:34:57  lr: 0.000100  loss/low_gen_loss: 1.8682 (1.8013)  loss/high_gen_loss: 27935998214144.0000 (43693524532476.4531)  loss/pix_loss: 0.1751 (0.1660)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1757  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [370/862]  eta: 0:34:15  lr: 0.000100  loss/low_gen_loss: 1.8835 (1.8040)  loss/high_gen_loss: 82976863944704.0000 (45171898592297.3984)  loss/pix_loss: 0.1767 (0.1661)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1794  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [380/862]  eta: 0:33:33  lr: 0.000100  loss/low_gen_loss: 1.8686 (1.8050)  loss/high_gen_loss: 100131424698368.0000 (46636469441447.3047)  loss/pix_loss: 0.1721 (0.1659)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1793  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [390/862]  eta: 0:32:52  lr: 0.000100  loss/low_gen_loss: 1.8419 (1.8060)  loss/high_gen_loss: 101650190565376.0000 (48135812894185.7422)  loss/pix_loss: 0.1721 (0.1659)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [400/862]  eta: 0:32:10  lr: 0.000100  loss/low_gen_loss: 1.8709 (1.8088)  loss/high_gen_loss: 93348169777152.0000 (48812179337348.7891)  loss/pix_loss: 0.1702 (0.1660)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [410/862]  eta: 0:31:28  lr: 0.000100  loss/low_gen_loss: 1.9206 (1.8114)  loss/high_gen_loss: 59858535579648.0000 (48851615495888.0391)  loss/pix_loss: 0.1686 (0.1661)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [420/862]  eta: 0:30:46  lr: 0.000100  loss/low_gen_loss: 1.9187 (1.8139)  loss/high_gen_loss: 56813458292736.0000 (49417988788214.2734)  loss/pix_loss: 0.1663 (0.1661)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [430/862]  eta: 0:30:04  lr: 0.000100  loss/low_gen_loss: 1.9143 (1.8162)  loss/high_gen_loss: 89397437399040.0000 (51327995335691.8828)  loss/pix_loss: 0.1629 (0.1660)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [440/862]  eta: 0:29:23  lr: 0.000100  loss/low_gen_loss: 1.9051 (1.8179)  loss/high_gen_loss: 118268954148864.0000 (52733202912225.8125)  loss/pix_loss: 0.1499 (0.1657)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1768  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [450/862]  eta: 0:28:41  lr: 0.000100  loss/low_gen_loss: 1.8850 (1.8193)  loss/high_gen_loss: 102036251082752.0000 (53484504313810.5859)  loss/pix_loss: 0.1651 (0.1659)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1770  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:21]  [460/862]  eta: 0:27:59  lr: 0.000100  loss/low_gen_loss: 1.8614 (1.8198)  loss/high_gen_loss: 63601830264832.0000 (53522762960496.1719)  loss/pix_loss: 0.1659 (0.1658)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [470/862]  eta: 0:27:17  lr: 0.000100  loss/low_gen_loss: 1.8298 (1.8197)  loss/high_gen_loss: 41434820378624.0000 (53181678383930.1562)  loss/pix_loss: 0.1621 (0.1655)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1754  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [480/862]  eta: 0:26:35  lr: 0.000100  loss/low_gen_loss: 1.8062 (1.8192)  loss/high_gen_loss: 41434820378624.0000 (53199401542398.4062)  loss/pix_loss: 0.1659 (0.1654)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1768  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [490/862]  eta: 0:25:54  lr: 0.000100  loss/low_gen_loss: 1.7815 (1.8182)  loss/high_gen_loss: 59616624902144.0000 (53431402102517.0547)  loss/pix_loss: 0.1659 (0.1654)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1793  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [500/862]  eta: 0:25:12  lr: 0.000100  loss/low_gen_loss: 1.7704 (1.8172)  loss/high_gen_loss: 69436249735168.0000 (54323678446549.0781)  loss/pix_loss: 0.1626 (0.1654)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1779  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [510/862]  eta: 0:24:30  lr: 0.000100  loss/low_gen_loss: 1.7787 (1.8167)  loss/high_gen_loss: 113244228288512.0000 (55675557830768.2188)  loss/pix_loss: 0.1709 (0.1656)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [520/862]  eta: 0:23:48  lr: 0.000100  loss/low_gen_loss: 1.7999 (1.8164)  loss/high_gen_loss: 99122174492672.0000 (56058343459032.2031)  loss/pix_loss: 0.1633 (0.1657)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1795  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [530/862]  eta: 0:23:07  lr: 0.000100  loss/low_gen_loss: 1.7855 (1.8157)  loss/high_gen_loss: 51176317911040.0000 (55875643052749.3750)  loss/pix_loss: 0.1584 (0.1655)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1811  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [540/862]  eta: 0:22:25  lr: 0.000100  loss/low_gen_loss: 1.8036 (1.8156)  loss/high_gen_loss: 54405822939136.0000 (56098026273998.3125)  loss/pix_loss: 0.1594 (0.1658)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1811  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [550/862]  eta: 0:21:43  lr: 0.000100  loss/low_gen_loss: 1.8110 (1.8154)  loss/high_gen_loss: 82303778816000.0000 (57234299544131.8359)  loss/pix_loss: 0.1811 (0.1659)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1792  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [560/862]  eta: 0:21:01  lr: 0.000100  loss/low_gen_loss: 1.8333 (1.8162)  loss/high_gen_loss: 136967404650496.0000 (58944559061273.1016)  loss/pix_loss: 0.1641 (0.1658)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1756  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [570/862]  eta: 0:20:19  lr: 0.000100  loss/low_gen_loss: 1.8245 (1.8158)  loss/high_gen_loss: 142792311439360.0000 (60090519071383.5391)  loss/pix_loss: 0.1641 (0.1660)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1760  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [580/862]  eta: 0:19:38  lr: 0.000100  loss/low_gen_loss: 1.8100 (1.8160)  loss/high_gen_loss: 89304902664192.0000 (60176538653454.5391)  loss/pix_loss: 0.1686 (0.1660)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1761  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [590/862]  eta: 0:18:56  lr: 0.000100  loss/low_gen_loss: 1.8649 (1.8180)  loss/high_gen_loss: 64340384284672.0000 (60357874983868.4297)  loss/pix_loss: 0.1606 (0.1658)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1785  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [600/862]  eta: 0:18:14  lr: 0.000100  loss/low_gen_loss: 1.9438 (1.8202)  loss/high_gen_loss: 92520054784000.0000 (61066909485788.6484)  loss/pix_loss: 0.1604 (0.1659)  loss/enc_loss: 0.0023 (0.0016)  time: 4.1771  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [610/862]  eta: 0:17:32  lr: 0.000100  loss/low_gen_loss: 1.9174 (1.8215)  loss/high_gen_loss: 96769287389184.0000 (61590063404355.4531)  loss/pix_loss: 0.1714 (0.1659)  loss/enc_loss: 0.0024 (0.0016)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.8509 (1.8215)  loss/high_gen_loss: 86520983715840.0000 (61793499386561.7500)  loss/pix_loss: 0.1716 (0.1660)  loss/enc_loss: 0.0023 (0.0016)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [630/862]  eta: 0:16:09  lr: 0.000100  loss/low_gen_loss: 1.8106 (1.8211)  loss/high_gen_loss: 57516738215936.0000 (61528602316442.9766)  loss/pix_loss: 0.1709 (0.1659)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [640/862]  eta: 0:15:27  lr: 0.000100  loss/low_gen_loss: 1.7847 (1.8202)  loss/high_gen_loss: 103492278550528.0000 (67245340168492.3281)  loss/pix_loss: 0.1606 (0.1658)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [650/862]  eta: 0:14:45  lr: 0.000100  loss/low_gen_loss: 1.7719 (1.8195)  loss/high_gen_loss: 776893347397632.0000 (86091626507249.8438)  loss/pix_loss: 0.1661 (0.1660)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.7782 (1.8190)  loss/high_gen_loss: 1571370827776000.0000 (109487328627168.2344)  loss/pix_loss: 0.1740 (0.1661)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [670/862]  eta: 0:13:22  lr: 0.000100  loss/low_gen_loss: 1.7892 (1.8185)  loss/high_gen_loss: 1536521060483072.0000 (128188093364416.2812)  loss/pix_loss: 0.1737 (0.1662)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [680/862]  eta: 0:12:40  lr: 0.000100  loss/low_gen_loss: 1.7774 (1.8177)  loss/high_gen_loss: 1147591236517888.0000 (140799384587127.1562)  loss/pix_loss: 0.1698 (0.1661)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1748  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [690/862]  eta: 0:11:58  lr: 0.000100  loss/low_gen_loss: 1.7494 (1.8166)  loss/high_gen_loss: 765541681725440.0000 (147803765266144.5000)  loss/pix_loss: 0.1730 (0.1663)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1768  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.7507 (1.8158)  loss/high_gen_loss: 488684398837760.0000 (150936674437970.1562)  loss/pix_loss: 0.1774 (0.1664)  loss/enc_loss: 0.0018 (0.0016)  time: 4.1767  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.7631 (1.8151)  loss/high_gen_loss: 288359876395008.0000 (152409760072048.6875)  loss/pix_loss: 0.1801 (0.1667)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [720/862]  eta: 0:09:53  lr: 0.000100  loss/low_gen_loss: 1.7380 (1.8135)  loss/high_gen_loss: 203911055015936.0000 (152527109354295.7500)  loss/pix_loss: 0.1729 (0.1667)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1753  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [730/862]  eta: 0:09:11  lr: 0.000100  loss/low_gen_loss: 1.7083 (1.8121)  loss/high_gen_loss: 121043368804352.0000 (151712582122421.7500)  loss/pix_loss: 0.1722 (0.1668)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.7136 (1.8109)  loss/high_gen_loss: 82106990460928.0000 (150800614119095.0938)  loss/pix_loss: 0.1781 (0.1669)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1791  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.6988 (1.8090)  loss/high_gen_loss: 105913037881344.0000 (150268984682705.9688)  loss/pix_loss: 0.1776 (0.1671)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1792  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [760/862]  eta: 0:07:06  lr: 0.000100  loss/low_gen_loss: 1.7024 (1.8078)  loss/high_gen_loss: 115098286817280.0000 (149996117108916.3125)  loss/pix_loss: 0.1672 (0.1670)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1750  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:21]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.7176 (1.8068)  loss/high_gen_loss: 137937974984704.0000 (150343149474604.8125)  loss/pix_loss: 0.1686 (0.1671)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.7182 (1.8056)  loss/high_gen_loss: 210563690921984.0000 (151353684583291.5625)  loss/pix_loss: 0.1686 (0.1670)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1767  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.7173 (1.8045)  loss/high_gen_loss: 232683426807808.0000 (152864920289590.6875)  loss/pix_loss: 0.1618 (0.1669)  loss/enc_loss: 0.0025 (0.0016)  time: 4.1767  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.7336 (1.8039)  loss/high_gen_loss: 410973408067584.0000 (157633174844522.0938)  loss/pix_loss: 0.1496 (0.1666)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1762  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.7584 (1.8035)  loss/high_gen_loss: 572214936076288.0000 (162900922983319.1875)  loss/pix_loss: 0.1586 (0.1668)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1764  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.7754 (1.8032)  loss/high_gen_loss: 542692840833024.0000 (166457992180575.0938)  loss/pix_loss: 0.1756 (0.1668)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.8249 (1.8041)  loss/high_gen_loss: 385356780273664.0000 (168591203930629.5312)  loss/pix_loss: 0.1651 (0.1668)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.8673 (1.8047)  loss/high_gen_loss: 270025818636288.0000 (169544871494508.6562)  loss/pix_loss: 0.1704 (0.1668)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.7982 (1.8044)  loss/high_gen_loss: 235736477466624.0000 (169761795547030.1250)  loss/pix_loss: 0.1771 (0.1670)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.7687 (1.8036)  loss/high_gen_loss: 165521697800192.0000 (169587893376170.0625)  loss/pix_loss: 0.1663 (0.1668)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.7614 (1.8036)  loss/high_gen_loss: 161614854619136.0000 (169545143197486.9375)  loss/pix_loss: 0.1663 (0.1667)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:21] Total time: 1:00:00 (4.1773 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.7614 (1.8036)  loss/high_gen_loss: 161614854619136.0000 (169545143197486.9375)  loss/pix_loss: 0.1663 (0.1667)  loss/enc_loss: 0.0012 (0.0016)\n",
      "Valid: [epoch:21]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1588 (0.1588)  time: 2.9572  data: 0.3750  max mem: 31350\n",
      "Valid: [epoch:21]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5791  data: 0.0269  max mem: 31350\n",
      "Valid: [epoch:21] Total time: 0:00:36 (2.5866 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_21_input_n_20.png\n",
      "Train: [epoch:22]  [  0/862]  eta: 1:16:12  lr: 0.000100  loss/low_gen_loss: 1.7353 (1.7353)  loss/high_gen_loss: 131738466516992.0000 (131738466516992.0000)  loss/pix_loss: 0.1596 (0.1596)  loss/enc_loss: 0.0023 (0.0023)  time: 5.3043  data: 1.1175  max mem: 31350\n",
      "Train: [epoch:22]  [ 10/862]  eta: 1:00:51  lr: 0.000100  loss/low_gen_loss: 1.7497 (1.7477)  loss/high_gen_loss: 132782068072448.0000 (134166989123211.6406)  loss/pix_loss: 0.1705 (0.1706)  loss/enc_loss: 0.0026 (0.0026)  time: 4.2863  data: 0.1017  max mem: 31350\n",
      "Train: [epoch:22]  [ 20/862]  eta: 0:59:24  lr: 0.000100  loss/low_gen_loss: 1.7339 (1.7389)  loss/high_gen_loss: 129024625999872.0000 (124706215740172.1875)  loss/pix_loss: 0.1716 (0.1720)  loss/enc_loss: 0.0021 (0.0020)  time: 4.1794  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [ 30/862]  eta: 0:58:26  lr: 0.000100  loss/low_gen_loss: 1.7214 (1.7270)  loss/high_gen_loss: 76993831895040.0000 (107766653166889.2969)  loss/pix_loss: 0.1749 (0.1737)  loss/enc_loss: 0.0015 (0.0019)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [ 40/862]  eta: 0:57:36  lr: 0.000100  loss/low_gen_loss: 1.6849 (1.7099)  loss/high_gen_loss: 69417425698816.0000 (96282140564904.5781)  loss/pix_loss: 0.1870 (0.1780)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1756  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [ 50/862]  eta: 0:56:49  lr: 0.000100  loss/low_gen_loss: 1.7031 (1.7139)  loss/high_gen_loss: 64023160684544.0000 (92463188657091.7656)  loss/pix_loss: 0.1748 (0.1741)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [ 60/862]  eta: 0:56:04  lr: 0.000100  loss/low_gen_loss: 1.7480 (1.7225)  loss/high_gen_loss: 110525354606592.0000 (103667465208613.7656)  loss/pix_loss: 0.1624 (0.1710)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [ 70/862]  eta: 0:55:19  lr: 0.000100  loss/low_gen_loss: 1.8093 (1.7374)  loss/high_gen_loss: 213690880098304.0000 (126812317729460.2812)  loss/pix_loss: 0.1651 (0.1718)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [ 80/862]  eta: 0:54:35  lr: 0.000100  loss/low_gen_loss: 1.7884 (1.7414)  loss/high_gen_loss: 315399346323456.0000 (154466613901135.0000)  loss/pix_loss: 0.1684 (0.1698)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [ 90/862]  eta: 0:53:52  lr: 0.000100  loss/low_gen_loss: 1.7654 (1.7436)  loss/high_gen_loss: 321786969325568.0000 (170380499713687.9062)  loss/pix_loss: 0.1649 (0.1687)  loss/enc_loss: 0.0018 (0.0017)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [100/862]  eta: 0:53:09  lr: 0.000100  loss/low_gen_loss: 1.7650 (1.7477)  loss/high_gen_loss: 380799685754880.0000 (195322453921913.6562)  loss/pix_loss: 0.1577 (0.1677)  loss/enc_loss: 0.0022 (0.0017)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [110/862]  eta: 0:52:27  lr: 0.000100  loss/low_gen_loss: 1.8125 (1.7540)  loss/high_gen_loss: 402157215940608.0000 (208378051917215.1250)  loss/pix_loss: 0.1636 (0.1673)  loss/enc_loss: 0.0018 (0.0017)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [120/862]  eta: 0:51:44  lr: 0.000100  loss/low_gen_loss: 1.8188 (1.7602)  loss/high_gen_loss: 201382812450816.0000 (206757141764857.6562)  loss/pix_loss: 0.1660 (0.1671)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [130/862]  eta: 0:51:02  lr: 0.000100  loss/low_gen_loss: 1.8110 (1.7632)  loss/high_gen_loss: 156003781836800.0000 (201335773459526.3438)  loss/pix_loss: 0.1661 (0.1672)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [140/862]  eta: 0:50:19  lr: 0.000100  loss/low_gen_loss: 1.8238 (1.7683)  loss/high_gen_loss: 128565643313152.0000 (194750394012199.9375)  loss/pix_loss: 0.1559 (0.1663)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [150/862]  eta: 0:49:37  lr: 0.000100  loss/low_gen_loss: 1.8356 (1.7728)  loss/high_gen_loss: 113615289974784.0000 (189918541688045.3438)  loss/pix_loss: 0.1502 (0.1652)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [160/862]  eta: 0:48:55  lr: 0.000100  loss/low_gen_loss: 1.8284 (1.7753)  loss/high_gen_loss: 149889057030144.0000 (187912204327280.9062)  loss/pix_loss: 0.1502 (0.1644)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [170/862]  eta: 0:48:13  lr: 0.000100  loss/low_gen_loss: 1.8165 (1.7786)  loss/high_gen_loss: 149889057030144.0000 (182343389046987.5938)  loss/pix_loss: 0.1598 (0.1640)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1739  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:22]  [180/862]  eta: 0:47:31  lr: 0.000100  loss/low_gen_loss: 1.8435 (1.7827)  loss/high_gen_loss: 60292675403776.0000 (175483752229124.2500)  loss/pix_loss: 0.1652 (0.1648)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1760  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [190/862]  eta: 0:46:49  lr: 0.000100  loss/low_gen_loss: 1.8007 (1.7815)  loss/high_gen_loss: 72693261008896.0000 (170329501460447.8438)  loss/pix_loss: 0.1852 (0.1653)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [200/862]  eta: 0:46:07  lr: 0.000100  loss/low_gen_loss: 1.7563 (1.7808)  loss/high_gen_loss: 81411138650112.0000 (169715098584996.3125)  loss/pix_loss: 0.1858 (0.1656)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [210/862]  eta: 0:45:25  lr: 0.000100  loss/low_gen_loss: 1.7496 (1.7793)  loss/high_gen_loss: 225728062816256.0000 (173170169692858.8438)  loss/pix_loss: 0.1661 (0.1655)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [220/862]  eta: 0:44:43  lr: 0.000100  loss/low_gen_loss: 1.7497 (1.7781)  loss/high_gen_loss: 254590461149184.0000 (177738524494296.6250)  loss/pix_loss: 0.1594 (0.1654)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [230/862]  eta: 0:44:01  lr: 0.000100  loss/low_gen_loss: 1.7490 (1.7764)  loss/high_gen_loss: 291615662931968.0000 (183836909080310.0312)  loss/pix_loss: 0.1627 (0.1652)  loss/enc_loss: 0.0025 (0.0017)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [240/862]  eta: 0:43:19  lr: 0.000100  loss/low_gen_loss: 1.7519 (1.7763)  loss/high_gen_loss: 269747232964608.0000 (184994055936042.5000)  loss/pix_loss: 0.1733 (0.1657)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [250/862]  eta: 0:42:37  lr: 0.000100  loss/low_gen_loss: 1.7667 (1.7760)  loss/high_gen_loss: 161950013063168.0000 (183583505725986.6875)  loss/pix_loss: 0.1706 (0.1658)  loss/enc_loss: 0.0016 (0.0017)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [260/862]  eta: 0:41:55  lr: 0.000100  loss/low_gen_loss: 1.7643 (1.7753)  loss/high_gen_loss: 128458571120640.0000 (180774940214629.0312)  loss/pix_loss: 0.1646 (0.1657)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [270/862]  eta: 0:41:13  lr: 0.000100  loss/low_gen_loss: 1.7755 (1.7758)  loss/high_gen_loss: 162923108368384.0000 (186430659152423.6875)  loss/pix_loss: 0.1709 (0.1662)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [280/862]  eta: 0:40:31  lr: 0.000100  loss/low_gen_loss: 1.7752 (1.7747)  loss/high_gen_loss: 429661381197824.0000 (196164865304364.6250)  loss/pix_loss: 0.1735 (0.1661)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [290/862]  eta: 0:39:49  lr: 0.000100  loss/low_gen_loss: 1.7657 (1.7754)  loss/high_gen_loss: 493041643159552.0000 (216991478867468.3125)  loss/pix_loss: 0.1698 (0.1662)  loss/enc_loss: 0.0007 (0.0016)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [300/862]  eta: 0:39:07  lr: 0.000100  loss/low_gen_loss: 1.8060 (1.7764)  loss/high_gen_loss: 1087199030280192.0000 (252216569751599.6250)  loss/pix_loss: 0.1532 (0.1655)  loss/enc_loss: 0.0007 (0.0016)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [310/862]  eta: 0:38:25  lr: 0.000100  loss/low_gen_loss: 1.7771 (1.7760)  loss/high_gen_loss: 1102041095077888.0000 (274571009747293.0312)  loss/pix_loss: 0.1464 (0.1652)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [320/862]  eta: 0:37:44  lr: 0.000100  loss/low_gen_loss: 1.7771 (1.7763)  loss/high_gen_loss: 921552811982848.0000 (295144420365653.3125)  loss/pix_loss: 0.1473 (0.1649)  loss/enc_loss: 0.0022 (0.0016)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [330/862]  eta: 0:37:02  lr: 0.000100  loss/low_gen_loss: 1.7929 (1.7775)  loss/high_gen_loss: 857737651027968.0000 (311731330968449.1875)  loss/pix_loss: 0.1629 (0.1650)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [340/862]  eta: 0:36:20  lr: 0.000100  loss/low_gen_loss: 1.8281 (1.7793)  loss/high_gen_loss: 557425316855808.0000 (316696533653750.2500)  loss/pix_loss: 0.1689 (0.1653)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [350/862]  eta: 0:35:38  lr: 0.000100  loss/low_gen_loss: 1.8252 (1.7786)  loss/high_gen_loss: 467153425793024.0000 (320109419942973.2500)  loss/pix_loss: 0.1630 (0.1650)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1761  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [360/862]  eta: 0:34:56  lr: 0.000100  loss/low_gen_loss: 1.7191 (1.7769)  loss/high_gen_loss: 411734657466368.0000 (323259063464038.1250)  loss/pix_loss: 0.1613 (0.1652)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [370/862]  eta: 0:34:15  lr: 0.000100  loss/low_gen_loss: 1.7286 (1.7776)  loss/high_gen_loss: 599942238306304.0000 (371465742546783.9375)  loss/pix_loss: 0.1725 (0.1655)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [380/862]  eta: 0:33:33  lr: 0.000100  loss/low_gen_loss: 1.7765 (1.7774)  loss/high_gen_loss: 3554571574050816.0000 (510370238576408.8750)  loss/pix_loss: 0.1740 (0.1654)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [390/862]  eta: 0:32:51  lr: 0.000100  loss/low_gen_loss: 1.7217 (1.7760)  loss/high_gen_loss: 6195544548442112.0000 (657984423383762.8750)  loss/pix_loss: 0.1652 (0.1652)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [400/862]  eta: 0:32:09  lr: 0.000100  loss/low_gen_loss: 1.7556 (1.7768)  loss/high_gen_loss: 5549067681660928.0000 (749313595427015.1250)  loss/pix_loss: 0.1601 (0.1652)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [410/862]  eta: 0:31:27  lr: 0.000100  loss/low_gen_loss: 1.8062 (1.7776)  loss/high_gen_loss: 3611360168509440.0000 (814119565577612.1250)  loss/pix_loss: 0.1709 (0.1654)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [420/862]  eta: 0:30:46  lr: 0.000100  loss/low_gen_loss: 1.7923 (1.7775)  loss/high_gen_loss: 2628237054181376.0000 (843175282864488.0000)  loss/pix_loss: 0.1771 (0.1656)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [430/862]  eta: 0:30:04  lr: 0.000100  loss/low_gen_loss: 1.7729 (1.7775)  loss/high_gen_loss: 1317033736142848.0000 (847859307486262.6250)  loss/pix_loss: 0.1749 (0.1657)  loss/enc_loss: 0.0018 (0.0016)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [440/862]  eta: 0:29:22  lr: 0.000100  loss/low_gen_loss: 1.8119 (1.7788)  loss/high_gen_loss: 961596805349376.0000 (850054136041314.1250)  loss/pix_loss: 0.1640 (0.1654)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [450/862]  eta: 0:28:40  lr: 0.000100  loss/low_gen_loss: 1.8317 (1.7799)  loss/high_gen_loss: 1057300689190912.0000 (855030565423490.0000)  loss/pix_loss: 0.1640 (0.1654)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [460/862]  eta: 0:27:58  lr: 0.000100  loss/low_gen_loss: 1.8195 (1.7803)  loss/high_gen_loss: 1104273605656576.0000 (873709119393712.0000)  loss/pix_loss: 0.1661 (0.1653)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [470/862]  eta: 0:27:17  lr: 0.000100  loss/low_gen_loss: 1.8151 (1.7816)  loss/high_gen_loss: 2670698979917824.0000 (917735113060760.7500)  loss/pix_loss: 0.1681 (0.1654)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [480/862]  eta: 0:26:35  lr: 0.000100  loss/low_gen_loss: 1.8400 (1.7827)  loss/high_gen_loss: 3159885554384896.0000 (977171585477744.8750)  loss/pix_loss: 0.1632 (0.1652)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:22]  [490/862]  eta: 0:25:53  lr: 0.000100  loss/low_gen_loss: 1.7908 (1.7826)  loss/high_gen_loss: 3865669477072896.0000 (1032999655400341.6250)  loss/pix_loss: 0.1615 (0.1650)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [500/862]  eta: 0:25:11  lr: 0.000100  loss/low_gen_loss: 1.7695 (1.7822)  loss/high_gen_loss: 2453876951220224.0000 (1054909148118484.0000)  loss/pix_loss: 0.1580 (0.1648)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 1.7703 (1.7821)  loss/high_gen_loss: 2007134317314048.0000 (1072881438951171.5000)  loss/pix_loss: 0.1648 (0.1649)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [520/862]  eta: 0:23:48  lr: 0.000100  loss/low_gen_loss: 1.7902 (1.7826)  loss/high_gen_loss: 1848746660855808.0000 (1082108001377439.2500)  loss/pix_loss: 0.1714 (0.1649)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [530/862]  eta: 0:23:06  lr: 0.000100  loss/low_gen_loss: 1.7922 (1.7827)  loss/high_gen_loss: 1394131351896064.0000 (1088582272592554.6250)  loss/pix_loss: 0.1686 (0.1649)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [540/862]  eta: 0:22:24  lr: 0.000100  loss/low_gen_loss: 1.7839 (1.7820)  loss/high_gen_loss: 1917993479045120.0000 (1119666730828502.8750)  loss/pix_loss: 0.1755 (0.1650)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.6763 (1.7798)  loss/high_gen_loss: 2688997419646976.0000 (1145133948848904.7500)  loss/pix_loss: 0.1754 (0.1652)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [560/862]  eta: 0:21:01  lr: 0.000100  loss/low_gen_loss: 1.6526 (1.7769)  loss/high_gen_loss: 2482322519621632.0000 (1170074229454705.7500)  loss/pix_loss: 0.1662 (0.1651)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [570/862]  eta: 0:20:19  lr: 0.000100  loss/low_gen_loss: 1.6007 (1.7737)  loss/high_gen_loss: 3659945643868160.0000 (1216848821948337.0000)  loss/pix_loss: 0.1710 (0.1653)  loss/enc_loss: 0.0022 (0.0016)  time: 4.1767  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [580/862]  eta: 0:19:37  lr: 0.000100  loss/low_gen_loss: 1.6031 (1.7709)  loss/high_gen_loss: 3810289900322816.0000 (1270100963570122.2500)  loss/pix_loss: 0.1805 (0.1655)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1765  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.6170 (1.7689)  loss/high_gen_loss: 3372181761294336.0000 (1302929534752612.0000)  loss/pix_loss: 0.1610 (0.1653)  loss/enc_loss: 0.0018 (0.0016)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [600/862]  eta: 0:18:14  lr: 0.000100  loss/low_gen_loss: 1.6331 (1.7659)  loss/high_gen_loss: 3147253250260992.0000 (1332824599431301.0000)  loss/pix_loss: 0.1647 (0.1655)  loss/enc_loss: 0.0018 (0.0016)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [610/862]  eta: 0:17:32  lr: 0.000100  loss/low_gen_loss: 1.5421 (1.7623)  loss/high_gen_loss: 2796193092468736.0000 (1340328818704705.7500)  loss/pix_loss: 0.1852 (0.1657)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.5372 (1.7587)  loss/high_gen_loss: 1492250282426368.0000 (1343955040464770.7500)  loss/pix_loss: 0.1903 (0.1661)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.5393 (1.7556)  loss/high_gen_loss: 2696752788406272.0000 (1402760908768478.2500)  loss/pix_loss: 0.1756 (0.1658)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [640/862]  eta: 0:15:27  lr: 0.000100  loss/low_gen_loss: 1.4983 (1.7511)  loss/high_gen_loss: 5154318311227392.0000 (1464006010857686.0000)  loss/pix_loss: 0.1601 (0.1659)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [650/862]  eta: 0:14:45  lr: 0.000100  loss/low_gen_loss: 1.5199 (1.7485)  loss/high_gen_loss: 5804437847146496.0000 (1541181554169550.7500)  loss/pix_loss: 0.1676 (0.1662)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1754  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.5763 (1.7458)  loss/high_gen_loss: 6562251003658240.0000 (1623106551566478.5000)  loss/pix_loss: 0.1695 (0.1661)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.5667 (1.7431)  loss/high_gen_loss: 8076540508110848.0000 (1722280455282065.2500)  loss/pix_loss: 0.1651 (0.1662)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.6273 (1.7422)  loss/high_gen_loss: 8101135101460480.0000 (1787076211859227.5000)  loss/pix_loss: 0.1758 (0.1662)  loss/enc_loss: 0.0022 (0.0016)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [690/862]  eta: 0:11:58  lr: 0.000100  loss/low_gen_loss: 1.6321 (1.7403)  loss/high_gen_loss: 5088344929206272.0000 (1820448645495480.5000)  loss/pix_loss: 0.1797 (0.1664)  loss/enc_loss: 0.0024 (0.0016)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.6197 (1.7386)  loss/high_gen_loss: 5088344929206272.0000 (1869896880153008.5000)  loss/pix_loss: 0.1718 (0.1663)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.6305 (1.7373)  loss/high_gen_loss: 5810805673033728.0000 (1969836193621177.7500)  loss/pix_loss: 0.1636 (0.1664)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.6245 (1.7347)  loss/high_gen_loss: 10202759236157440.0000 (2096626488799010.5000)  loss/pix_loss: 0.1714 (0.1665)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [730/862]  eta: 0:09:11  lr: 0.000100  loss/low_gen_loss: 1.5709 (1.7326)  loss/high_gen_loss: 9367639352672256.0000 (2168889493056297.7500)  loss/pix_loss: 0.1698 (0.1665)  loss/enc_loss: 0.0007 (0.0016)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.6236 (1.7319)  loss/high_gen_loss: 4303776273924096.0000 (2194597375594269.2500)  loss/pix_loss: 0.1690 (0.1667)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.6786 (1.7313)  loss/high_gen_loss: 4189713485266944.0000 (2226411186983397.5000)  loss/pix_loss: 0.1728 (0.1667)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.6501 (1.7300)  loss/high_gen_loss: 4596176573693952.0000 (2258577072228844.5000)  loss/pix_loss: 0.1653 (0.1667)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.7011 (1.7297)  loss/high_gen_loss: 3780869642780672.0000 (2280378403322799.0000)  loss/pix_loss: 0.1679 (0.1669)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.7200 (1.7299)  loss/high_gen_loss: 3436072084176896.0000 (2290148237737690.5000)  loss/pix_loss: 0.1704 (0.1669)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.7329 (1.7294)  loss/high_gen_loss: 3343643582660608.0000 (2312093916075025.0000)  loss/pix_loss: 0.1646 (0.1668)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1737  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:22]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.7003 (1.7292)  loss/high_gen_loss: 4268255283773440.0000 (2341483266224562.5000)  loss/pix_loss: 0.1678 (0.1669)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.7027 (1.7288)  loss/high_gen_loss: 5038714971488256.0000 (2382289157047423.5000)  loss/pix_loss: 0.1743 (0.1670)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.6593 (1.7279)  loss/high_gen_loss: 5074743841521664.0000 (2408101222618659.5000)  loss/pix_loss: 0.1757 (0.1672)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.6578 (1.7270)  loss/high_gen_loss: 3303814471876608.0000 (2416818162965197.0000)  loss/pix_loss: 0.1667 (0.1671)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.6342 (1.7257)  loss/high_gen_loss: 2814617696862208.0000 (2415403717160926.0000)  loss/pix_loss: 0.1583 (0.1671)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.6418 (1.7248)  loss/high_gen_loss: 2217986207252480.0000 (2413060283091957.0000)  loss/pix_loss: 0.1582 (0.1670)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.6491 (1.7241)  loss/high_gen_loss: 2230544288972800.0000 (2411856926655548.5000)  loss/pix_loss: 0.1686 (0.1670)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.6491 (1.7241)  loss/high_gen_loss: 2230544288972800.0000 (2412713488559700.5000)  loss/pix_loss: 0.1686 (0.1670)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:22] Total time: 0:59:59 (4.1756 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.6491 (1.7241)  loss/high_gen_loss: 2230544288972800.0000 (2412713488559700.5000)  loss/pix_loss: 0.1686 (0.1670)  loss/enc_loss: 0.0011 (0.0016)\n",
      "Valid: [epoch:22]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1080 (0.1080)  time: 2.9746  data: 0.4189  max mem: 31350\n",
      "Valid: [epoch:22]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5586  data: 0.0300  max mem: 31350\n",
      "Valid: [epoch:22] Total time: 0:00:35 (2.5684 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_22_input_n_20.png\n",
      "Train: [epoch:23]  [  0/862]  eta: 1:16:39  lr: 0.000100  loss/low_gen_loss: 1.6881 (1.6881)  loss/high_gen_loss: 3081698895986688.0000 (3081698895986688.0000)  loss/pix_loss: 0.1383 (0.1383)  loss/enc_loss: 0.0011 (0.0011)  time: 5.3355  data: 1.0978  max mem: 31350\n",
      "Train: [epoch:23]  [ 10/862]  eta: 1:00:23  lr: 0.000100  loss/low_gen_loss: 1.6485 (1.6525)  loss/high_gen_loss: 2943036413706240.0000 (2942339262423784.5000)  loss/pix_loss: 0.1669 (0.1677)  loss/enc_loss: 0.0014 (0.0014)  time: 4.2530  data: 0.0999  max mem: 31350\n",
      "Train: [epoch:23]  [ 20/862]  eta: 0:59:04  lr: 0.000100  loss/low_gen_loss: 1.6643 (1.6650)  loss/high_gen_loss: 2830179437117440.0000 (2936484658401085.0000)  loss/pix_loss: 0.1669 (0.1676)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1535  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [ 30/862]  eta: 0:58:11  lr: 0.000100  loss/low_gen_loss: 1.6742 (1.6623)  loss/high_gen_loss: 2177798332481536.0000 (2492890936094059.5000)  loss/pix_loss: 0.1643 (0.1683)  loss/enc_loss: 0.0018 (0.0018)  time: 4.1656  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [ 40/862]  eta: 0:57:24  lr: 0.000100  loss/low_gen_loss: 1.6653 (1.6661)  loss/high_gen_loss: 1232935592132608.0000 (2181069027007113.2500)  loss/pix_loss: 0.1746 (0.1687)  loss/enc_loss: 0.0024 (0.0020)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [ 50/862]  eta: 0:56:39  lr: 0.000100  loss/low_gen_loss: 1.6629 (1.6658)  loss/high_gen_loss: 1188126332551168.0000 (1993481266314942.7500)  loss/pix_loss: 0.1642 (0.1677)  loss/enc_loss: 0.0022 (0.0020)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [ 60/862]  eta: 0:55:56  lr: 0.000100  loss/low_gen_loss: 1.6567 (1.6620)  loss/high_gen_loss: 1131549533667328.0000 (1831402695097293.7500)  loss/pix_loss: 0.1567 (0.1666)  loss/enc_loss: 0.0010 (0.0018)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [ 70/862]  eta: 0:55:12  lr: 0.000100  loss/low_gen_loss: 1.5864 (1.6504)  loss/high_gen_loss: 1181337197215744.0000 (1784194068005094.7500)  loss/pix_loss: 0.1681 (0.1681)  loss/enc_loss: 0.0008 (0.0017)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [ 80/862]  eta: 0:54:30  lr: 0.000100  loss/low_gen_loss: 1.5760 (1.6393)  loss/high_gen_loss: 1994739310133248.0000 (1828587873938090.7500)  loss/pix_loss: 0.1637 (0.1668)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [ 90/862]  eta: 0:53:47  lr: 0.000100  loss/low_gen_loss: 1.5321 (1.6263)  loss/high_gen_loss: 2555229321035776.0000 (2001075068307928.5000)  loss/pix_loss: 0.1584 (0.1662)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [100/862]  eta: 0:53:04  lr: 0.000100  loss/low_gen_loss: 1.5321 (1.6203)  loss/high_gen_loss: 4633362400542720.0000 (2398321894757447.0000)  loss/pix_loss: 0.1593 (0.1662)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [110/862]  eta: 0:52:22  lr: 0.000100  loss/low_gen_loss: 1.5971 (1.6190)  loss/high_gen_loss: 6087540079591424.0000 (2791262501451314.5000)  loss/pix_loss: 0.1675 (0.1668)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [120/862]  eta: 0:51:40  lr: 0.000100  loss/low_gen_loss: 1.6128 (1.6192)  loss/high_gen_loss: 6272674644885504.0000 (3086143506066271.0000)  loss/pix_loss: 0.1807 (0.1674)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [130/862]  eta: 0:50:58  lr: 0.000100  loss/low_gen_loss: 1.6128 (1.6180)  loss/high_gen_loss: 5599485229006848.0000 (3226616965347750.0000)  loss/pix_loss: 0.1880 (0.1689)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [140/862]  eta: 0:50:16  lr: 0.000100  loss/low_gen_loss: 1.6296 (1.6203)  loss/high_gen_loss: 4242120944648192.0000 (3291863946216005.0000)  loss/pix_loss: 0.1706 (0.1679)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [150/862]  eta: 0:49:34  lr: 0.000100  loss/low_gen_loss: 1.6088 (1.6181)  loss/high_gen_loss: 4753182324424704.0000 (3505630807477756.5000)  loss/pix_loss: 0.1640 (0.1679)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [160/862]  eta: 0:48:52  lr: 0.000100  loss/low_gen_loss: 1.5898 (1.6179)  loss/high_gen_loss: 9395377325211648.0000 (3919992318468859.0000)  loss/pix_loss: 0.1673 (0.1675)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [170/862]  eta: 0:48:10  lr: 0.000100  loss/low_gen_loss: 1.5721 (1.6144)  loss/high_gen_loss: 10443337534275584.0000 (4356340133848716.5000)  loss/pix_loss: 0.1664 (0.1672)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [180/862]  eta: 0:47:28  lr: 0.000100  loss/low_gen_loss: 1.5463 (1.6096)  loss/high_gen_loss: 11824724644462592.0000 (4865101397911722.0000)  loss/pix_loss: 0.1675 (0.1678)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [190/862]  eta: 0:46:46  lr: 0.000100  loss/low_gen_loss: 1.5488 (1.6082)  loss/high_gen_loss: 15077409678163968.0000 (5660358511636201.0000)  loss/pix_loss: 0.1800 (0.1682)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1754  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [200/862]  eta: 0:46:05  lr: 0.000100  loss/low_gen_loss: 1.5897 (1.6073)  loss/high_gen_loss: 19427075530162176.0000 (6362367130703760.0000)  loss/pix_loss: 0.1776 (0.1690)  loss/enc_loss: 0.0023 (0.0016)  time: 4.1755  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:23]  [210/862]  eta: 0:45:23  lr: 0.000100  loss/low_gen_loss: 1.6291 (1.6086)  loss/high_gen_loss: 22439030868148224.0000 (7184518272055170.0000)  loss/pix_loss: 0.1753 (0.1687)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [220/862]  eta: 0:44:41  lr: 0.000100  loss/low_gen_loss: 1.6420 (1.6117)  loss/high_gen_loss: 24637259554750464.0000 (8007758564865205.0000)  loss/pix_loss: 0.1660 (0.1686)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [230/862]  eta: 0:43:59  lr: 0.000100  loss/low_gen_loss: 1.6453 (1.6120)  loss/high_gen_loss: 24216829501112320.0000 (8631455990784177.0000)  loss/pix_loss: 0.1642 (0.1682)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [240/862]  eta: 0:43:17  lr: 0.000100  loss/low_gen_loss: 1.6244 (1.6135)  loss/high_gen_loss: 18888834523594752.0000 (8850649449986056.0000)  loss/pix_loss: 0.1734 (0.1689)  loss/enc_loss: 0.0025 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [250/862]  eta: 0:42:35  lr: 0.000100  loss/low_gen_loss: 1.6368 (1.6143)  loss/high_gen_loss: 10524901110710272.0000 (8877616512994235.0000)  loss/pix_loss: 0.1771 (0.1690)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [260/862]  eta: 0:41:53  lr: 0.000100  loss/low_gen_loss: 1.6255 (1.6150)  loss/high_gen_loss: 9457997948387328.0000 (8898550226078473.0000)  loss/pix_loss: 0.1619 (0.1688)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [270/862]  eta: 0:41:12  lr: 0.000100  loss/low_gen_loss: 1.6869 (1.6198)  loss/high_gen_loss: 9215197004693504.0000 (8904582109176685.0000)  loss/pix_loss: 0.1800 (0.1695)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [280/862]  eta: 0:40:30  lr: 0.000100  loss/low_gen_loss: 1.7214 (1.6208)  loss/high_gen_loss: 10612987668725760.0000 (9217795895518146.0000)  loss/pix_loss: 0.1701 (0.1693)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [290/862]  eta: 0:39:48  lr: 0.000100  loss/low_gen_loss: 1.5664 (1.6179)  loss/high_gen_loss: 27962773275148288.0000 (10100367839402822.0000)  loss/pix_loss: 0.1641 (0.1690)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1766  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [300/862]  eta: 0:39:06  lr: 0.000100  loss/low_gen_loss: 1.5694 (1.6179)  loss/high_gen_loss: 39637084943679488.0000 (11276417461686858.0000)  loss/pix_loss: 0.1504 (0.1683)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1759  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [310/862]  eta: 0:38:25  lr: 0.000100  loss/low_gen_loss: 1.5544 (1.6153)  loss/high_gen_loss: 43805273395036160.0000 (12301858838103966.0000)  loss/pix_loss: 0.1444 (0.1679)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [320/862]  eta: 0:37:43  lr: 0.000100  loss/low_gen_loss: 1.5274 (1.6123)  loss/high_gen_loss: 38089827270262784.0000 (13022535503171214.0000)  loss/pix_loss: 0.1518 (0.1678)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [330/862]  eta: 0:37:01  lr: 0.000100  loss/low_gen_loss: 1.5092 (1.6071)  loss/high_gen_loss: 34872901060526080.0000 (13665062607641312.0000)  loss/pix_loss: 0.1552 (0.1678)  loss/enc_loss: 0.0024 (0.0016)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [340/862]  eta: 0:36:19  lr: 0.000100  loss/low_gen_loss: 1.5237 (1.6080)  loss/high_gen_loss: 28614841652477952.0000 (13965719768233054.0000)  loss/pix_loss: 0.1695 (0.1679)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [350/862]  eta: 0:35:37  lr: 0.000100  loss/low_gen_loss: 1.5631 (1.6045)  loss/high_gen_loss: 17334060657410048.0000 (13980539479747756.0000)  loss/pix_loss: 0.1682 (0.1678)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [360/862]  eta: 0:34:56  lr: 0.000100  loss/low_gen_loss: 1.4824 (1.6012)  loss/high_gen_loss: 14527664601694208.0000 (14010640400441366.0000)  loss/pix_loss: 0.1735 (0.1683)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [370/862]  eta: 0:34:14  lr: 0.000100  loss/low_gen_loss: 1.4887 (1.5983)  loss/high_gen_loss: 18049739647877120.0000 (14183602640894720.0000)  loss/pix_loss: 0.1769 (0.1685)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [380/862]  eta: 0:33:32  lr: 0.000100  loss/low_gen_loss: 1.4794 (1.5948)  loss/high_gen_loss: 24863606478733312.0000 (14558110190381566.0000)  loss/pix_loss: 0.1592 (0.1680)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [390/862]  eta: 0:32:50  lr: 0.000100  loss/low_gen_loss: 1.4779 (1.5937)  loss/high_gen_loss: 29510945776599040.0000 (14977923519009490.0000)  loss/pix_loss: 0.1505 (0.1677)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [400/862]  eta: 0:32:08  lr: 0.000100  loss/low_gen_loss: 1.6340 (1.5950)  loss/high_gen_loss: 28122629810421760.0000 (15115706477027062.0000)  loss/pix_loss: 0.1659 (0.1677)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [410/862]  eta: 0:31:27  lr: 0.000100  loss/low_gen_loss: 1.6511 (1.5971)  loss/high_gen_loss: 11375376576020480.0000 (14978369656432206.0000)  loss/pix_loss: 0.1782 (0.1679)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1768  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [420/862]  eta: 0:30:45  lr: 0.000100  loss/low_gen_loss: 1.6974 (1.6003)  loss/high_gen_loss: 11375376576020480.0000 (14913945315527060.0000)  loss/pix_loss: 0.1767 (0.1679)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1763  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [430/862]  eta: 0:30:03  lr: 0.000100  loss/low_gen_loss: 1.6942 (1.6016)  loss/high_gen_loss: 11905699810377728.0000 (14816067065436592.0000)  loss/pix_loss: 0.1764 (0.1679)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [440/862]  eta: 0:29:21  lr: 0.000100  loss/low_gen_loss: 1.7071 (1.6045)  loss/high_gen_loss: 12269595209498624.0000 (14871086258150774.0000)  loss/pix_loss: 0.1748 (0.1680)  loss/enc_loss: 0.0018 (0.0016)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [450/862]  eta: 0:28:40  lr: 0.000100  loss/low_gen_loss: 1.6957 (1.6055)  loss/high_gen_loss: 23289713565630464.0000 (15187127885391404.0000)  loss/pix_loss: 0.1711 (0.1683)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [460/862]  eta: 0:27:58  lr: 0.000100  loss/low_gen_loss: 1.6539 (1.6068)  loss/high_gen_loss: 39902376483618816.0000 (15763895301936482.0000)  loss/pix_loss: 0.1662 (0.1680)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [470/862]  eta: 0:27:16  lr: 0.000100  loss/low_gen_loss: 1.6602 (1.6080)  loss/high_gen_loss: 41586836887306240.0000 (16342228570758524.0000)  loss/pix_loss: 0.1551 (0.1679)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [480/862]  eta: 0:26:34  lr: 0.000100  loss/low_gen_loss: 1.6503 (1.6087)  loss/high_gen_loss: 39857867737530368.0000 (16791636273449262.0000)  loss/pix_loss: 0.1576 (0.1677)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [490/862]  eta: 0:25:53  lr: 0.000100  loss/low_gen_loss: 1.6538 (1.6101)  loss/high_gen_loss: 30115561207758848.0000 (17009818741759116.0000)  loss/pix_loss: 0.1609 (0.1675)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [500/862]  eta: 0:25:11  lr: 0.000100  loss/low_gen_loss: 1.7187 (1.6126)  loss/high_gen_loss: 23895082763550720.0000 (17017580697435474.0000)  loss/pix_loss: 0.1629 (0.1674)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 1.7352 (1.6149)  loss/high_gen_loss: 13255386840694784.0000 (16879756864907764.0000)  loss/pix_loss: 0.1717 (0.1676)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1736  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:23]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 1.6697 (1.6156)  loss/high_gen_loss: 6703682129231872.0000 (16671226219107428.0000)  loss/pix_loss: 0.1805 (0.1677)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [530/862]  eta: 0:23:06  lr: 0.000100  loss/low_gen_loss: 1.6492 (1.6160)  loss/high_gen_loss: 4631516638347264.0000 (16435692853992068.0000)  loss/pix_loss: 0.1696 (0.1676)  loss/enc_loss: 0.0022 (0.0016)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [540/862]  eta: 0:22:24  lr: 0.000100  loss/low_gen_loss: 1.5620 (1.6131)  loss/high_gen_loss: 4631516638347264.0000 (16308406828403062.0000)  loss/pix_loss: 0.1696 (0.1678)  loss/enc_loss: 0.0030 (0.0016)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.5610 (1.6138)  loss/high_gen_loss: 14187571911327744.0000 (16464707040426574.0000)  loss/pix_loss: 0.1805 (0.1679)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 1.6933 (1.6154)  loss/high_gen_loss: 20597469150707712.0000 (16412494797717534.0000)  loss/pix_loss: 0.1658 (0.1678)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [570/862]  eta: 0:20:18  lr: 0.000100  loss/low_gen_loss: 1.6933 (1.6163)  loss/high_gen_loss: 8736657117282304.0000 (16246949823455878.0000)  loss/pix_loss: 0.1669 (0.1678)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [580/862]  eta: 0:19:37  lr: 0.000100  loss/low_gen_loss: 1.6657 (1.6170)  loss/high_gen_loss: 10200546254258176.0000 (16172801036069114.0000)  loss/pix_loss: 0.1740 (0.1677)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.6635 (1.6174)  loss/high_gen_loss: 11610579722567680.0000 (16089032122928550.0000)  loss/pix_loss: 0.1569 (0.1675)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 1.6309 (1.6178)  loss/high_gen_loss: 13666181135204352.0000 (16062235223106776.0000)  loss/pix_loss: 0.1596 (0.1675)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [610/862]  eta: 0:17:31  lr: 0.000100  loss/low_gen_loss: 1.6910 (1.6196)  loss/high_gen_loss: 15346389521268736.0000 (16066077655460460.0000)  loss/pix_loss: 0.1609 (0.1673)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.6873 (1.6202)  loss/high_gen_loss: 16007861729492992.0000 (16072299617479470.0000)  loss/pix_loss: 0.1609 (0.1674)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.6494 (1.6207)  loss/high_gen_loss: 20906167777624064.0000 (16182398189869196.0000)  loss/pix_loss: 0.1580 (0.1673)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 1.6724 (1.6216)  loss/high_gen_loss: 19575307736449024.0000 (16199615979298650.0000)  loss/pix_loss: 0.1575 (0.1671)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 1.6587 (1.6219)  loss/high_gen_loss: 14907131404746752.0000 (16144888177251368.0000)  loss/pix_loss: 0.1617 (0.1671)  loss/enc_loss: 0.0031 (0.0016)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.6366 (1.6223)  loss/high_gen_loss: 9698798511063040.0000 (15995224800644470.0000)  loss/pix_loss: 0.1648 (0.1671)  loss/enc_loss: 0.0018 (0.0016)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.6306 (1.6218)  loss/high_gen_loss: 2577349476352000.0000 (15793272083657210.0000)  loss/pix_loss: 0.1673 (0.1671)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.6314 (1.6224)  loss/high_gen_loss: 2566294767403008.0000 (15664158690642374.0000)  loss/pix_loss: 0.1787 (0.1672)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.6160 (1.6221)  loss/high_gen_loss: 23256672382222336.0000 (16804501863910244.0000)  loss/pix_loss: 0.1787 (0.1673)  loss/enc_loss: 0.0010 (0.0016)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.6160 (1.6223)  loss/high_gen_loss: 157287938672033792.0000 (18890004184185080.0000)  loss/pix_loss: 0.1573 (0.1671)  loss/enc_loss: 0.0009 (0.0016)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.6331 (1.6228)  loss/high_gen_loss: 160766123447418880.0000 (20818702474017896.0000)  loss/pix_loss: 0.1592 (0.1673)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.6852 (1.6238)  loss/high_gen_loss: 113888445197189120.0000 (22059367356263680.0000)  loss/pix_loss: 0.1851 (0.1675)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 1.6971 (1.6248)  loss/high_gen_loss: 111023341233504256.0000 (23000196564143012.0000)  loss/pix_loss: 0.1851 (0.1676)  loss/enc_loss: 0.0006 (0.0015)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.6710 (1.6249)  loss/high_gen_loss: 63598338120876032.0000 (23417016882076004.0000)  loss/pix_loss: 0.1769 (0.1677)  loss/enc_loss: 0.0006 (0.0015)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.6285 (1.6249)  loss/high_gen_loss: 56739833694912512.0000 (23849310744121656.0000)  loss/pix_loss: 0.1728 (0.1677)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.6996 (1.6262)  loss/high_gen_loss: 42393831177453568.0000 (23985198456924748.0000)  loss/pix_loss: 0.1666 (0.1676)  loss/enc_loss: 0.0021 (0.0015)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.7247 (1.6274)  loss/high_gen_loss: 29133169043177472.0000 (24039546399596468.0000)  loss/pix_loss: 0.1652 (0.1676)  loss/enc_loss: 0.0028 (0.0016)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.7250 (1.6287)  loss/high_gen_loss: 30394403369517056.0000 (24135094958101336.0000)  loss/pix_loss: 0.1598 (0.1675)  loss/enc_loss: 0.0021 (0.0016)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.6774 (1.6288)  loss/high_gen_loss: 32316029719805952.0000 (24269941304587520.0000)  loss/pix_loss: 0.1677 (0.1676)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.6504 (1.6291)  loss/high_gen_loss: 29977381372428288.0000 (24277468861839588.0000)  loss/pix_loss: 0.1745 (0.1676)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.6238 (1.6290)  loss/high_gen_loss: 24770513062592512.0000 (24303516186098400.0000)  loss/pix_loss: 0.1714 (0.1676)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.6238 (1.6299)  loss/high_gen_loss: 28528321683783680.0000 (24400667584295736.0000)  loss/pix_loss: 0.1656 (0.1676)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1700  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:23]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.8781 (1.6334)  loss/high_gen_loss: 27451047249182720.0000 (24387540879147956.0000)  loss/pix_loss: 0.1692 (0.1677)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.8508 (1.6342)  loss/high_gen_loss: 21933897616982016.0000 (24342021646756628.0000)  loss/pix_loss: 0.1728 (0.1677)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.5102 (1.6322)  loss/high_gen_loss: 14842520064229376.0000 (24188551839246356.0000)  loss/pix_loss: 0.1667 (0.1676)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.4542 (1.6304)  loss/high_gen_loss: 9792821787623424.0000 (24007993503303020.0000)  loss/pix_loss: 0.1611 (0.1675)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.4542 (1.6304)  loss/high_gen_loss: 9518025485058048.0000 (23984613158342932.0000)  loss/pix_loss: 0.1611 (0.1675)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:23] Total time: 0:59:57 (4.1740 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.4542 (1.6304)  loss/high_gen_loss: 9518025485058048.0000 (23984613158342932.0000)  loss/pix_loss: 0.1611 (0.1675)  loss/enc_loss: 0.0015 (0.0016)\n",
      "Valid: [epoch:23]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1018 (0.1018)  time: 2.9705  data: 0.3907  max mem: 31350\n",
      "Valid: [epoch:23]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5721  data: 0.0280  max mem: 31350\n",
      "Valid: [epoch:23] Total time: 0:00:36 (2.5812 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_23_input_n_20.png\n",
      "Train: [epoch:24]  [  0/862]  eta: 1:15:32  lr: 0.000100  loss/low_gen_loss: 1.6414 (1.6414)  loss/high_gen_loss: 6667754190929920.0000 (6667754190929920.0000)  loss/pix_loss: 0.1801 (0.1801)  loss/enc_loss: 0.0015 (0.0015)  time: 5.2578  data: 1.0756  max mem: 31350\n",
      "Train: [epoch:24]  [ 10/862]  eta: 1:00:38  lr: 0.000100  loss/low_gen_loss: 1.6371 (1.6297)  loss/high_gen_loss: 7032387250683904.0000 (7357709084858182.0000)  loss/pix_loss: 0.1767 (0.1709)  loss/enc_loss: 0.0009 (0.0010)  time: 4.2704  data: 0.0979  max mem: 31350\n",
      "Train: [epoch:24]  [ 20/862]  eta: 0:59:16  lr: 0.000100  loss/low_gen_loss: 1.5859 (1.5902)  loss/high_gen_loss: 7808135653752832.0000 (7776351272367055.0000)  loss/pix_loss: 0.1725 (0.1719)  loss/enc_loss: 0.0010 (0.0010)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [ 30/862]  eta: 0:58:22  lr: 0.000100  loss/low_gen_loss: 1.5938 (1.5987)  loss/high_gen_loss: 9366830825078784.0000 (8962441132113920.0000)  loss/pix_loss: 0.1727 (0.1719)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1770  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [ 40/862]  eta: 0:57:33  lr: 0.000100  loss/low_gen_loss: 1.6026 (1.5965)  loss/high_gen_loss: 9202658921414656.0000 (8876542715897207.0000)  loss/pix_loss: 0.1757 (0.1734)  loss/enc_loss: 0.0022 (0.0015)  time: 4.1764  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [ 50/862]  eta: 0:56:46  lr: 0.000100  loss/low_gen_loss: 1.5786 (1.5811)  loss/high_gen_loss: 12081656030560256.0000 (10235399940182418.0000)  loss/pix_loss: 0.1754 (0.1723)  loss/enc_loss: 0.0022 (0.0016)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [ 60/862]  eta: 0:56:01  lr: 0.000100  loss/low_gen_loss: 1.5042 (1.5693)  loss/high_gen_loss: 14147762933202944.0000 (10714872834515078.0000)  loss/pix_loss: 0.1687 (0.1714)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [ 70/862]  eta: 0:55:17  lr: 0.000100  loss/low_gen_loss: 1.5196 (1.5636)  loss/high_gen_loss: 14147762933202944.0000 (11277261575612098.0000)  loss/pix_loss: 0.1687 (0.1715)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [ 80/862]  eta: 0:54:33  lr: 0.000100  loss/low_gen_loss: 1.5204 (1.5573)  loss/high_gen_loss: 13126421857697792.0000 (11079502161380946.0000)  loss/pix_loss: 0.1558 (0.1691)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [ 90/862]  eta: 0:53:50  lr: 0.000100  loss/low_gen_loss: 1.5159 (1.5547)  loss/high_gen_loss: 8790733976764416.0000 (10832565202128400.0000)  loss/pix_loss: 0.1537 (0.1680)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [100/862]  eta: 0:53:07  lr: 0.000100  loss/low_gen_loss: 1.4780 (1.5466)  loss/high_gen_loss: 8659993024790528.0000 (10618381384867596.0000)  loss/pix_loss: 0.1602 (0.1668)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [110/862]  eta: 0:52:25  lr: 0.000100  loss/low_gen_loss: 1.4760 (1.5447)  loss/high_gen_loss: 7570556853420032.0000 (10287935796637954.0000)  loss/pix_loss: 0.1694 (0.1683)  loss/enc_loss: 0.0022 (0.0016)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [120/862]  eta: 0:51:42  lr: 0.000100  loss/low_gen_loss: 1.5813 (1.5490)  loss/high_gen_loss: 6698437437292544.0000 (9926227214404244.0000)  loss/pix_loss: 0.1793 (0.1687)  loss/enc_loss: 0.0027 (0.0017)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [130/862]  eta: 0:51:00  lr: 0.000100  loss/low_gen_loss: 1.5957 (1.5536)  loss/high_gen_loss: 5937548547325952.0000 (9761106529880018.0000)  loss/pix_loss: 0.1730 (0.1691)  loss/enc_loss: 0.0024 (0.0017)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [140/862]  eta: 0:50:18  lr: 0.000100  loss/low_gen_loss: 1.5982 (1.5576)  loss/high_gen_loss: 13695278464892928.0000 (11263045348358332.0000)  loss/pix_loss: 0.1670 (0.1689)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [150/862]  eta: 0:49:35  lr: 0.000100  loss/low_gen_loss: 1.5147 (1.5546)  loss/high_gen_loss: 41617399874584576.0000 (14619331158946090.0000)  loss/pix_loss: 0.1624 (0.1675)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [160/862]  eta: 0:48:53  lr: 0.000100  loss/low_gen_loss: 1.5147 (1.5583)  loss/high_gen_loss: 53154145888108544.0000 (17085806727534146.0000)  loss/pix_loss: 0.1560 (0.1673)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [170/862]  eta: 0:48:11  lr: 0.000100  loss/low_gen_loss: 1.5983 (1.5606)  loss/high_gen_loss: 51181132401606656.0000 (18962285982118916.0000)  loss/pix_loss: 0.1571 (0.1671)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [180/862]  eta: 0:47:29  lr: 0.000100  loss/low_gen_loss: 1.6457 (1.5711)  loss/high_gen_loss: 37424996397613056.0000 (19763022481100144.0000)  loss/pix_loss: 0.1705 (0.1680)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [190/862]  eta: 0:46:47  lr: 0.000100  loss/low_gen_loss: 1.7318 (1.5777)  loss/high_gen_loss: 34979085536985088.0000 (20695467302850580.0000)  loss/pix_loss: 0.1757 (0.1686)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [200/862]  eta: 0:46:05  lr: 0.000100  loss/low_gen_loss: 1.6585 (1.5802)  loss/high_gen_loss: 42361760656654336.0000 (21967688695536728.0000)  loss/pix_loss: 0.1808 (0.1694)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [210/862]  eta: 0:45:23  lr: 0.000100  loss/low_gen_loss: 1.6224 (1.5819)  loss/high_gen_loss: 41054570180247552.0000 (22809030511166060.0000)  loss/pix_loss: 0.1723 (0.1684)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [220/862]  eta: 0:44:41  lr: 0.000100  loss/low_gen_loss: 1.5524 (1.5802)  loss/high_gen_loss: 39365698845147136.0000 (23473850645418928.0000)  loss/pix_loss: 0.1474 (0.1679)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1711  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:24]  [230/862]  eta: 0:44:00  lr: 0.000100  loss/low_gen_loss: 1.5238 (1.5768)  loss/high_gen_loss: 34507098695925760.0000 (23888662258076792.0000)  loss/pix_loss: 0.1484 (0.1672)  loss/enc_loss: 0.0022 (0.0015)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [240/862]  eta: 0:43:18  lr: 0.000100  loss/low_gen_loss: 1.5022 (1.5743)  loss/high_gen_loss: 35757900546703360.0000 (24718939599871696.0000)  loss/pix_loss: 0.1562 (0.1676)  loss/enc_loss: 0.0025 (0.0015)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [250/862]  eta: 0:42:36  lr: 0.000100  loss/low_gen_loss: 1.5285 (1.5729)  loss/high_gen_loss: 47344652864454656.0000 (25884086093525888.0000)  loss/pix_loss: 0.1636 (0.1676)  loss/enc_loss: 0.0023 (0.0016)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [260/862]  eta: 0:41:54  lr: 0.000100  loss/low_gen_loss: 1.5466 (1.5722)  loss/high_gen_loss: 47279416606195712.0000 (26464975216068756.0000)  loss/pix_loss: 0.1659 (0.1677)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [270/862]  eta: 0:41:12  lr: 0.000100  loss/low_gen_loss: 1.5633 (1.5746)  loss/high_gen_loss: 37248168299069440.0000 (26861651990504240.0000)  loss/pix_loss: 0.1733 (0.1681)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [280/862]  eta: 0:40:30  lr: 0.000100  loss/low_gen_loss: 1.6404 (1.5765)  loss/high_gen_loss: 34215096754372608.0000 (27015766930569108.0000)  loss/pix_loss: 0.1690 (0.1676)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [290/862]  eta: 0:39:48  lr: 0.000100  loss/low_gen_loss: 1.5706 (1.5761)  loss/high_gen_loss: 22189403073937408.0000 (26748522829386812.0000)  loss/pix_loss: 0.1543 (0.1671)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [300/862]  eta: 0:39:07  lr: 0.000100  loss/low_gen_loss: 1.5744 (1.5784)  loss/high_gen_loss: 14426054265405440.0000 (26208284964508288.0000)  loss/pix_loss: 0.1543 (0.1666)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [310/862]  eta: 0:38:25  lr: 0.000100  loss/low_gen_loss: 1.6281 (1.5801)  loss/high_gen_loss: 9163757255131136.0000 (25635164051063576.0000)  loss/pix_loss: 0.1564 (0.1664)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [320/862]  eta: 0:37:43  lr: 0.000100  loss/low_gen_loss: 1.6224 (1.5799)  loss/high_gen_loss: 9653200990765056.0000 (25176660674967660.0000)  loss/pix_loss: 0.1568 (0.1662)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [330/862]  eta: 0:37:01  lr: 0.000100  loss/low_gen_loss: 1.5299 (1.5767)  loss/high_gen_loss: 10793759620988928.0000 (24748254943616652.0000)  loss/pix_loss: 0.1586 (0.1662)  loss/enc_loss: 0.0024 (0.0016)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [340/862]  eta: 0:36:19  lr: 0.000100  loss/low_gen_loss: 1.5359 (1.5763)  loss/high_gen_loss: 12974409006448640.0000 (24504872488073920.0000)  loss/pix_loss: 0.1583 (0.1661)  loss/enc_loss: 0.0022 (0.0016)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [350/862]  eta: 0:35:37  lr: 0.000100  loss/low_gen_loss: 1.5791 (1.5769)  loss/high_gen_loss: 15110425091768320.0000 (24224226659198212.0000)  loss/pix_loss: 0.1521 (0.1656)  loss/enc_loss: 0.0011 (0.0016)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [360/862]  eta: 0:34:56  lr: 0.000100  loss/low_gen_loss: 1.5846 (1.5767)  loss/high_gen_loss: 13191875011805184.0000 (23827307215185528.0000)  loss/pix_loss: 0.1642 (0.1657)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [370/862]  eta: 0:34:14  lr: 0.000100  loss/low_gen_loss: 1.5717 (1.5766)  loss/high_gen_loss: 9346763664130048.0000 (23500715339146696.0000)  loss/pix_loss: 0.1724 (0.1657)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [380/862]  eta: 0:33:32  lr: 0.000100  loss/low_gen_loss: 1.5791 (1.5770)  loss/high_gen_loss: 16176344706580480.0000 (23454654176143872.0000)  loss/pix_loss: 0.1658 (0.1656)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [390/862]  eta: 0:32:50  lr: 0.000100  loss/low_gen_loss: 1.5909 (1.5771)  loss/high_gen_loss: 24806773323988992.0000 (23495696226910712.0000)  loss/pix_loss: 0.1593 (0.1656)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [400/862]  eta: 0:32:09  lr: 0.000100  loss/low_gen_loss: 1.5969 (1.5783)  loss/high_gen_loss: 22658757100044288.0000 (23425553967218360.0000)  loss/pix_loss: 0.1594 (0.1655)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [410/862]  eta: 0:31:27  lr: 0.000100  loss/low_gen_loss: 1.5819 (1.5778)  loss/high_gen_loss: 16282467979755520.0000 (23226631492762132.0000)  loss/pix_loss: 0.1743 (0.1658)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [420/862]  eta: 0:30:45  lr: 0.000100  loss/low_gen_loss: 1.5819 (1.5785)  loss/high_gen_loss: 14193402329432064.0000 (22978570531658240.0000)  loss/pix_loss: 0.1759 (0.1660)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [430/862]  eta: 0:30:03  lr: 0.000100  loss/low_gen_loss: 1.5849 (1.5771)  loss/high_gen_loss: 11811138589163520.0000 (22695900329113444.0000)  loss/pix_loss: 0.1681 (0.1659)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [440/862]  eta: 0:29:21  lr: 0.000100  loss/low_gen_loss: 1.4660 (1.5744)  loss/high_gen_loss: 12277077042528256.0000 (22521229260349308.0000)  loss/pix_loss: 0.1467 (0.1654)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [450/862]  eta: 0:28:40  lr: 0.000100  loss/low_gen_loss: 1.4982 (1.5740)  loss/high_gen_loss: 17787927031447552.0000 (22634168524767596.0000)  loss/pix_loss: 0.1593 (0.1657)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [460/862]  eta: 0:27:58  lr: 0.000100  loss/low_gen_loss: 1.5400 (1.5722)  loss/high_gen_loss: 31370411065212928.0000 (22848027609956280.0000)  loss/pix_loss: 0.1693 (0.1656)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [470/862]  eta: 0:27:16  lr: 0.000100  loss/low_gen_loss: 1.3983 (1.5682)  loss/high_gen_loss: 27152413878124544.0000 (22907713318327812.0000)  loss/pix_loss: 0.1562 (0.1655)  loss/enc_loss: 0.0020 (0.0015)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [480/862]  eta: 0:26:34  lr: 0.000100  loss/low_gen_loss: 1.3403 (1.5630)  loss/high_gen_loss: 21117316959830016.0000 (22816156427938624.0000)  loss/pix_loss: 0.1595 (0.1654)  loss/enc_loss: 0.0019 (0.0015)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [490/862]  eta: 0:25:52  lr: 0.000100  loss/low_gen_loss: 1.3585 (1.5607)  loss/high_gen_loss: 19019652784979968.0000 (22739753415502428.0000)  loss/pix_loss: 0.1595 (0.1654)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [500/862]  eta: 0:25:11  lr: 0.000100  loss/low_gen_loss: 1.4599 (1.5585)  loss/high_gen_loss: 15184715141087232.0000 (22532961756297204.0000)  loss/pix_loss: 0.1563 (0.1653)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 1.4345 (1.5556)  loss/high_gen_loss: 9668634955743232.0000 (22243496592702528.0000)  loss/pix_loss: 0.1633 (0.1653)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 1.5383 (1.5571)  loss/high_gen_loss: 9371231019073536.0000 (22032673036303376.0000)  loss/pix_loss: 0.1712 (0.1656)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [530/862]  eta: 0:23:05  lr: 0.000100  loss/low_gen_loss: 1.6292 (1.5588)  loss/high_gen_loss: 15079327381061632.0000 (22048068565412336.0000)  loss/pix_loss: 0.1711 (0.1654)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1727  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:24]  [540/862]  eta: 0:22:24  lr: 0.000100  loss/low_gen_loss: 1.5234 (1.5567)  loss/high_gen_loss: 28370369966505984.0000 (22281148208248456.0000)  loss/pix_loss: 0.1776 (0.1661)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.4810 (1.5564)  loss/high_gen_loss: 27041139865419776.0000 (22322607143373576.0000)  loss/pix_loss: 0.1948 (0.1666)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 1.5425 (1.5561)  loss/high_gen_loss: 18512932543397888.0000 (22205216843505184.0000)  loss/pix_loss: 0.1813 (0.1665)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [570/862]  eta: 0:20:18  lr: 0.000100  loss/low_gen_loss: 1.5855 (1.5575)  loss/high_gen_loss: 18512932543397888.0000 (22185399956156752.0000)  loss/pix_loss: 0.1611 (0.1664)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [580/862]  eta: 0:19:37  lr: 0.000100  loss/low_gen_loss: 1.6774 (1.5601)  loss/high_gen_loss: 20419988217135104.0000 (22114606017497492.0000)  loss/pix_loss: 0.1672 (0.1663)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.6836 (1.5608)  loss/high_gen_loss: 17167890520211456.0000 (22044223267205780.0000)  loss/pix_loss: 0.1630 (0.1661)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 1.5824 (1.5611)  loss/high_gen_loss: 16301073778081792.0000 (21943782320293940.0000)  loss/pix_loss: 0.1625 (0.1662)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [610/862]  eta: 0:17:31  lr: 0.000100  loss/low_gen_loss: 1.5752 (1.5613)  loss/high_gen_loss: 13804469418459136.0000 (21788413283410524.0000)  loss/pix_loss: 0.1732 (0.1664)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.5633 (1.5611)  loss/high_gen_loss: 14068216917655552.0000 (21711181102720072.0000)  loss/pix_loss: 0.1826 (0.1667)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.5521 (1.5612)  loss/high_gen_loss: 19823342097793024.0000 (21813439633932676.0000)  loss/pix_loss: 0.1739 (0.1667)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 1.5528 (1.5608)  loss/high_gen_loss: 31373877103820800.0000 (22367180856503072.0000)  loss/pix_loss: 0.1691 (0.1667)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 1.4764 (1.5587)  loss/high_gen_loss: 63757123061809152.0000 (23384762874663748.0000)  loss/pix_loss: 0.1582 (0.1667)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.4845 (1.5589)  loss/high_gen_loss: 75515154380357632.0000 (23990133603320676.0000)  loss/pix_loss: 0.1688 (0.1668)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.5180 (1.5574)  loss/high_gen_loss: 44967216667426816.0000 (24116494447267820.0000)  loss/pix_loss: 0.1688 (0.1666)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.4727 (1.5571)  loss/high_gen_loss: 18469012207828992.0000 (23911526179469916.0000)  loss/pix_loss: 0.1685 (0.1667)  loss/enc_loss: 0.0022 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.5937 (1.5581)  loss/high_gen_loss: 13802659089743872.0000 (23870127250378308.0000)  loss/pix_loss: 0.1685 (0.1667)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.4508 (1.5543)  loss/high_gen_loss: 20040626640781312.0000 (23842147142666904.0000)  loss/pix_loss: 0.1634 (0.1665)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.3443 (1.5529)  loss/high_gen_loss: 23622728149893120.0000 (24357982309709292.0000)  loss/pix_loss: 0.1737 (0.1668)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.4685 (1.5516)  loss/high_gen_loss: 119773031429046272.0000 (26298937522962184.0000)  loss/pix_loss: 0.1861 (0.1669)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 1.3583 (1.5481)  loss/high_gen_loss: 147252747584929792.0000 (27924694692563632.0000)  loss/pix_loss: 0.1679 (0.1669)  loss/enc_loss: 0.0006 (0.0015)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.4293 (1.5483)  loss/high_gen_loss: 83708964138647552.0000 (28161176299646364.0000)  loss/pix_loss: 0.1633 (0.1669)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.4854 (1.5467)  loss/high_gen_loss: 37782268957163520.0000 (28318484680927440.0000)  loss/pix_loss: 0.1673 (0.1669)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.4620 (1.5459)  loss/high_gen_loss: 37782268957163520.0000 (28548268630446160.0000)  loss/pix_loss: 0.1680 (0.1669)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.4640 (1.5441)  loss/high_gen_loss: 65482213856116736.0000 (29123029968961556.0000)  loss/pix_loss: 0.1579 (0.1667)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.4092 (1.5426)  loss/high_gen_loss: 41141508908253184.0000 (29181906136106092.0000)  loss/pix_loss: 0.1573 (0.1667)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.4209 (1.5408)  loss/high_gen_loss: 32977454683389952.0000 (29226549851204280.0000)  loss/pix_loss: 0.1625 (0.1667)  loss/enc_loss: 0.0026 (0.0015)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.3406 (1.5379)  loss/high_gen_loss: 28117785087311872.0000 (29188464855330516.0000)  loss/pix_loss: 0.1625 (0.1666)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.3891 (1.5370)  loss/high_gen_loss: 24634772768686080.0000 (29137174233571236.0000)  loss/pix_loss: 0.1671 (0.1666)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.4172 (1.5346)  loss/high_gen_loss: 28577642940727296.0000 (29142451669087928.0000)  loss/pix_loss: 0.1725 (0.1669)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.2553 (1.5309)  loss/high_gen_loss: 28892689529307136.0000 (29126274316607300.0000)  loss/pix_loss: 0.1740 (0.1668)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.2310 (1.5273)  loss/high_gen_loss: 26941707077550080.0000 (29104263947428296.0000)  loss/pix_loss: 0.1609 (0.1668)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1727  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:24]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.2502 (1.5247)  loss/high_gen_loss: 30170092260032512.0000 (29349172147533504.0000)  loss/pix_loss: 0.1693 (0.1668)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.3380 (1.5227)  loss/high_gen_loss: 51939099640070144.0000 (29649942075672356.0000)  loss/pix_loss: 0.1705 (0.1669)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.3394 (1.5225)  loss/high_gen_loss: 51939099640070144.0000 (29670713957058412.0000)  loss/pix_loss: 0.1719 (0.1670)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:24] Total time: 0:59:58 (4.1742 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.3394 (1.5225)  loss/high_gen_loss: 51939099640070144.0000 (29670713957058412.0000)  loss/pix_loss: 0.1719 (0.1670)  loss/enc_loss: 0.0013 (0.0015)\n",
      "Valid: [epoch:24]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1018 (0.1018)  time: 3.0059  data: 0.3983  max mem: 31350\n",
      "Valid: [epoch:24]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6300  data: 0.0285  max mem: 31350\n",
      "Valid: [epoch:24] Total time: 0:00:36 (2.6397 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_24_input_n_20.png\n",
      "Train: [epoch:25]  [  0/862]  eta: 1:16:57  lr: 0.000100  loss/low_gen_loss: 1.3588 (1.3588)  loss/high_gen_loss: 54499827861422080.0000 (54499827861422080.0000)  loss/pix_loss: 0.1828 (0.1828)  loss/enc_loss: 0.0014 (0.0014)  time: 5.3563  data: 1.1048  max mem: 31350\n",
      "Train: [epoch:25]  [ 10/862]  eta: 1:00:27  lr: 0.000100  loss/low_gen_loss: 1.3601 (1.3661)  loss/high_gen_loss: 40012190207442944.0000 (42400729285382520.0000)  loss/pix_loss: 0.1748 (0.1705)  loss/enc_loss: 0.0015 (0.0014)  time: 4.2571  data: 0.1005  max mem: 31350\n",
      "Train: [epoch:25]  [ 20/862]  eta: 0:59:06  lr: 0.000100  loss/low_gen_loss: 1.3521 (1.3431)  loss/high_gen_loss: 33163027335348224.0000 (37419681375584256.0000)  loss/pix_loss: 0.1687 (0.1665)  loss/enc_loss: 0.0015 (0.0018)  time: 4.1548  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [ 30/862]  eta: 0:58:12  lr: 0.000100  loss/low_gen_loss: 1.3707 (1.3719)  loss/high_gen_loss: 31407270474547200.0000 (34621454832581072.0000)  loss/pix_loss: 0.1705 (0.1688)  loss/enc_loss: 0.0020 (0.0020)  time: 4.1658  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [ 40/862]  eta: 0:57:25  lr: 0.000100  loss/low_gen_loss: 1.3569 (1.3570)  loss/high_gen_loss: 29808962819850240.0000 (33478837485309052.0000)  loss/pix_loss: 0.1785 (0.1702)  loss/enc_loss: 0.0017 (0.0019)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [ 50/862]  eta: 0:56:40  lr: 0.000100  loss/low_gen_loss: 1.3117 (1.3498)  loss/high_gen_loss: 30530873807863808.0000 (33226432126915604.0000)  loss/pix_loss: 0.1707 (0.1701)  loss/enc_loss: 0.0012 (0.0018)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [ 60/862]  eta: 0:55:55  lr: 0.000100  loss/low_gen_loss: 1.3117 (1.3371)  loss/high_gen_loss: 28645782596878336.0000 (31051550932925388.0000)  loss/pix_loss: 0.1678 (0.1683)  loss/enc_loss: 0.0013 (0.0017)  time: 4.1691  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [ 70/862]  eta: 0:55:12  lr: 0.000100  loss/low_gen_loss: 1.3700 (1.3464)  loss/high_gen_loss: 24034332045737984.0000 (30549668494012360.0000)  loss/pix_loss: 0.1697 (0.1691)  loss/enc_loss: 0.0014 (0.0017)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [ 80/862]  eta: 0:54:29  lr: 0.000100  loss/low_gen_loss: 1.3428 (1.3417)  loss/high_gen_loss: 27129148040282112.0000 (29986271875194576.0000)  loss/pix_loss: 0.1704 (0.1691)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [ 90/862]  eta: 0:53:47  lr: 0.000100  loss/low_gen_loss: 1.2583 (1.3292)  loss/high_gen_loss: 21990050019409920.0000 (28638245188859792.0000)  loss/pix_loss: 0.1680 (0.1685)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [100/862]  eta: 0:53:04  lr: 0.000100  loss/low_gen_loss: 1.2519 (1.3226)  loss/high_gen_loss: 16585918156636160.0000 (27358056370070560.0000)  loss/pix_loss: 0.1575 (0.1684)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [110/862]  eta: 0:52:22  lr: 0.000100  loss/low_gen_loss: 1.3683 (1.3343)  loss/high_gen_loss: 22117883278524416.0000 (27277673397433612.0000)  loss/pix_loss: 0.1577 (0.1679)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [120/862]  eta: 0:51:40  lr: 0.000100  loss/low_gen_loss: 1.4813 (1.3609)  loss/high_gen_loss: 28106068416528384.0000 (27436484585762172.0000)  loss/pix_loss: 0.1671 (0.1685)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [130/862]  eta: 0:50:58  lr: 0.000100  loss/low_gen_loss: 1.7028 (1.3885)  loss/high_gen_loss: 28460261484527616.0000 (27260836319422356.0000)  loss/pix_loss: 0.1663 (0.1690)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [140/862]  eta: 0:50:16  lr: 0.000100  loss/low_gen_loss: 1.4858 (1.3787)  loss/high_gen_loss: 24840256889028608.0000 (27270480511066172.0000)  loss/pix_loss: 0.1672 (0.1685)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [150/862]  eta: 0:49:34  lr: 0.000100  loss/low_gen_loss: 1.1956 (1.3635)  loss/high_gen_loss: 24840256889028608.0000 (27106020160486880.0000)  loss/pix_loss: 0.1648 (0.1679)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [160/862]  eta: 0:48:52  lr: 0.000100  loss/low_gen_loss: 1.3128 (1.3652)  loss/high_gen_loss: 34639594142040064.0000 (28255666482438196.0000)  loss/pix_loss: 0.1671 (0.1679)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [170/862]  eta: 0:48:10  lr: 0.000100  loss/low_gen_loss: 1.3825 (1.3665)  loss/high_gen_loss: 57253949870178304.0000 (30686606163583216.0000)  loss/pix_loss: 0.1699 (0.1677)  loss/enc_loss: 0.0031 (0.0017)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [180/862]  eta: 0:47:28  lr: 0.000100  loss/low_gen_loss: 1.4486 (1.3720)  loss/high_gen_loss: 53111320769200128.0000 (31461531578634668.0000)  loss/pix_loss: 0.1707 (0.1684)  loss/enc_loss: 0.0027 (0.0017)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [190/862]  eta: 0:46:46  lr: 0.000100  loss/low_gen_loss: 1.4605 (1.3761)  loss/high_gen_loss: 41662784794001408.0000 (31353677394784492.0000)  loss/pix_loss: 0.1746 (0.1691)  loss/enc_loss: 0.0012 (0.0017)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [200/862]  eta: 0:46:04  lr: 0.000100  loss/low_gen_loss: 1.4731 (1.3816)  loss/high_gen_loss: 32969362965004288.0000 (31485738239623332.0000)  loss/pix_loss: 0.1848 (0.1700)  loss/enc_loss: 0.0006 (0.0016)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [210/862]  eta: 0:45:22  lr: 0.000100  loss/low_gen_loss: 1.4376 (1.3820)  loss/high_gen_loss: 37382708149616640.0000 (31791545366267020.0000)  loss/pix_loss: 0.1848 (0.1702)  loss/enc_loss: 0.0005 (0.0016)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [220/862]  eta: 0:44:40  lr: 0.000100  loss/low_gen_loss: 1.3891 (1.3824)  loss/high_gen_loss: 28316324245536768.0000 (31154907806466492.0000)  loss/pix_loss: 0.1603 (0.1695)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [230/862]  eta: 0:43:59  lr: 0.000100  loss/low_gen_loss: 1.4014 (1.3839)  loss/high_gen_loss: 18917827700326400.0000 (31104790895200192.0000)  loss/pix_loss: 0.1566 (0.1691)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [240/862]  eta: 0:43:17  lr: 0.000100  loss/low_gen_loss: 1.4111 (1.3844)  loss/high_gen_loss: 50950827665260544.0000 (32752571550200912.0000)  loss/pix_loss: 0.1672 (0.1689)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:25]  [250/862]  eta: 0:42:35  lr: 0.000100  loss/low_gen_loss: 1.4260 (1.3906)  loss/high_gen_loss: 82454490090831872.0000 (35155169938840980.0000)  loss/pix_loss: 0.1751 (0.1689)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [260/862]  eta: 0:41:53  lr: 0.000100  loss/low_gen_loss: 1.5575 (1.3965)  loss/high_gen_loss: 71058472975728640.0000 (35621047008792876.0000)  loss/pix_loss: 0.1660 (0.1687)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [270/862]  eta: 0:41:11  lr: 0.000100  loss/low_gen_loss: 1.5107 (1.3993)  loss/high_gen_loss: 32831301241274368.0000 (35457198277219832.0000)  loss/pix_loss: 0.1652 (0.1690)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [280/862]  eta: 0:40:30  lr: 0.000100  loss/low_gen_loss: 1.5397 (1.4072)  loss/high_gen_loss: 26622558795202560.0000 (34947523064199000.0000)  loss/pix_loss: 0.1701 (0.1690)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [290/862]  eta: 0:39:48  lr: 0.000100  loss/low_gen_loss: 1.5397 (1.4070)  loss/high_gen_loss: 18015553855684608.0000 (34297200437704104.0000)  loss/pix_loss: 0.1676 (0.1690)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [300/862]  eta: 0:39:06  lr: 0.000100  loss/low_gen_loss: 1.3156 (1.4030)  loss/high_gen_loss: 18952900403265536.0000 (33974113955235696.0000)  loss/pix_loss: 0.1451 (0.1679)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [310/862]  eta: 0:38:24  lr: 0.000100  loss/low_gen_loss: 1.3236 (1.4029)  loss/high_gen_loss: 25093930542432256.0000 (33730343485543256.0000)  loss/pix_loss: 0.1362 (0.1674)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [320/862]  eta: 0:37:43  lr: 0.000100  loss/low_gen_loss: 1.4541 (1.4061)  loss/high_gen_loss: 27616126464688128.0000 (33691979822864976.0000)  loss/pix_loss: 0.1587 (0.1674)  loss/enc_loss: 0.0020 (0.0015)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [330/862]  eta: 0:37:01  lr: 0.000100  loss/low_gen_loss: 1.3833 (1.4037)  loss/high_gen_loss: 24869905048272896.0000 (33188516594066324.0000)  loss/pix_loss: 0.1598 (0.1672)  loss/enc_loss: 0.0024 (0.0016)  time: 4.1768  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [340/862]  eta: 0:36:19  lr: 0.000100  loss/low_gen_loss: 1.3563 (1.4031)  loss/high_gen_loss: 16049880468291584.0000 (32715227738014848.0000)  loss/pix_loss: 0.1680 (0.1673)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1761  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [350/862]  eta: 0:35:37  lr: 0.000100  loss/low_gen_loss: 1.3557 (1.3993)  loss/high_gen_loss: 23816983078240256.0000 (32559278750340672.0000)  loss/pix_loss: 0.1735 (0.1675)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [360/862]  eta: 0:34:56  lr: 0.000100  loss/low_gen_loss: 1.2061 (1.3932)  loss/high_gen_loss: 24683578629554176.0000 (32303024478526104.0000)  loss/pix_loss: 0.1748 (0.1676)  loss/enc_loss: 0.0015 (0.0016)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [370/862]  eta: 0:34:14  lr: 0.000100  loss/low_gen_loss: 1.2174 (1.3900)  loss/high_gen_loss: 21419532333613056.0000 (31897727093128908.0000)  loss/pix_loss: 0.1713 (0.1675)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1753  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [380/862]  eta: 0:33:32  lr: 0.000100  loss/low_gen_loss: 1.3373 (1.3919)  loss/high_gen_loss: 21419532333613056.0000 (31786153325504248.0000)  loss/pix_loss: 0.1484 (0.1671)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1762  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [390/862]  eta: 0:32:50  lr: 0.000100  loss/low_gen_loss: 1.5251 (1.3955)  loss/high_gen_loss: 34670092704808960.0000 (32116744533450940.0000)  loss/pix_loss: 0.1464 (0.1669)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1767  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [400/862]  eta: 0:32:09  lr: 0.000100  loss/low_gen_loss: 1.5120 (1.3971)  loss/high_gen_loss: 44340830047043584.0000 (32384426270696628.0000)  loss/pix_loss: 0.1564 (0.1668)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1762  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [410/862]  eta: 0:31:27  lr: 0.000100  loss/low_gen_loss: 1.4430 (1.3982)  loss/high_gen_loss: 37234441583591424.0000 (32473760826245240.0000)  loss/pix_loss: 0.1660 (0.1668)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [420/862]  eta: 0:30:45  lr: 0.000100  loss/low_gen_loss: 1.4312 (1.3992)  loss/high_gen_loss: 37078860688261120.0000 (32651306854073216.0000)  loss/pix_loss: 0.1693 (0.1669)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [430/862]  eta: 0:30:03  lr: 0.000100  loss/low_gen_loss: 1.4814 (1.4026)  loss/high_gen_loss: 37078860688261120.0000 (32699033288915052.0000)  loss/pix_loss: 0.1645 (0.1668)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1760  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [440/862]  eta: 0:29:22  lr: 0.000100  loss/low_gen_loss: 1.5259 (1.4046)  loss/high_gen_loss: 32493210005667840.0000 (32672314909227348.0000)  loss/pix_loss: 0.1594 (0.1666)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1764  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [450/862]  eta: 0:28:40  lr: 0.000100  loss/low_gen_loss: 1.5026 (1.4071)  loss/high_gen_loss: 31945575905624064.0000 (32918099582893316.0000)  loss/pix_loss: 0.1737 (0.1669)  loss/enc_loss: 0.0023 (0.0015)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [460/862]  eta: 0:27:58  lr: 0.000100  loss/low_gen_loss: 1.4824 (1.4070)  loss/high_gen_loss: 66446047467012096.0000 (33916441242338772.0000)  loss/pix_loss: 0.1660 (0.1667)  loss/enc_loss: 0.0021 (0.0015)  time: 4.1748  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [470/862]  eta: 0:27:16  lr: 0.000100  loss/low_gen_loss: 1.3786 (1.4063)  loss/high_gen_loss: 71161315967631360.0000 (34578819684567912.0000)  loss/pix_loss: 0.1613 (0.1666)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [480/862]  eta: 0:26:35  lr: 0.000100  loss/low_gen_loss: 1.3616 (1.4054)  loss/high_gen_loss: 48198183125254144.0000 (34736599929611552.0000)  loss/pix_loss: 0.1613 (0.1666)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1754  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [490/862]  eta: 0:25:53  lr: 0.000100  loss/low_gen_loss: 1.4913 (1.4081)  loss/high_gen_loss: 37871694471233536.0000 (34717316876178052.0000)  loss/pix_loss: 0.1564 (0.1664)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [500/862]  eta: 0:25:11  lr: 0.000100  loss/low_gen_loss: 1.5155 (1.4098)  loss/high_gen_loss: 33996594588155904.0000 (34620270642676724.0000)  loss/pix_loss: 0.1562 (0.1662)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 1.5267 (1.4128)  loss/high_gen_loss: 34496833724088320.0000 (34734622218214576.0000)  loss/pix_loss: 0.1622 (0.1663)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 1.5592 (1.4156)  loss/high_gen_loss: 56372747135090688.0000 (35248981949605364.0000)  loss/pix_loss: 0.1739 (0.1664)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1756  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [530/862]  eta: 0:23:06  lr: 0.000100  loss/low_gen_loss: 1.5360 (1.4174)  loss/high_gen_loss: 65064468157038592.0000 (36198645277990744.0000)  loss/pix_loss: 0.1529 (0.1661)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [540/862]  eta: 0:22:24  lr: 0.000100  loss/low_gen_loss: 1.4998 (1.4188)  loss/high_gen_loss: 96622427559165952.0000 (37515762521022144.0000)  loss/pix_loss: 0.1556 (0.1662)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.4789 (1.4194)  loss/high_gen_loss: 104815120625958912.0000 (38735430096583872.0000)  loss/pix_loss: 0.1804 (0.1664)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1752  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:25]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 1.4271 (1.4188)  loss/high_gen_loss: 114803161562087424.0000 (40134616542946784.0000)  loss/pix_loss: 0.1614 (0.1661)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1763  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [570/862]  eta: 0:20:19  lr: 0.000100  loss/low_gen_loss: 1.3801 (1.4183)  loss/high_gen_loss: 119642696351481856.0000 (41831157704089872.0000)  loss/pix_loss: 0.1517 (0.1661)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1769  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [580/862]  eta: 0:19:37  lr: 0.000100  loss/low_gen_loss: 1.4729 (1.4194)  loss/high_gen_loss: 138470097810358272.0000 (43591198105575752.0000)  loss/pix_loss: 0.1545 (0.1659)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.4436 (1.4188)  loss/high_gen_loss: 132606745896812544.0000 (45028335665386864.0000)  loss/pix_loss: 0.1522 (0.1656)  loss/enc_loss: 0.0019 (0.0015)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 1.3792 (1.4180)  loss/high_gen_loss: 120798781288480768.0000 (45891574969489016.0000)  loss/pix_loss: 0.1628 (0.1657)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [610/862]  eta: 0:17:32  lr: 0.000100  loss/low_gen_loss: 1.3510 (1.4167)  loss/high_gen_loss: 88317730335227904.0000 (46575852073589560.0000)  loss/pix_loss: 0.1695 (0.1659)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.2697 (1.4131)  loss/high_gen_loss: 81453419113480192.0000 (47129215810985624.0000)  loss/pix_loss: 0.1706 (0.1660)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.1985 (1.4098)  loss/high_gen_loss: 82603456736526336.0000 (47899972219703352.0000)  loss/pix_loss: 0.1706 (0.1660)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 1.2028 (1.4067)  loss/high_gen_loss: 84878827330732032.0000 (48176880978621448.0000)  loss/pix_loss: 0.1590 (0.1659)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1789  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [650/862]  eta: 0:14:45  lr: 0.000100  loss/low_gen_loss: 1.2425 (1.4052)  loss/high_gen_loss: 68600896983924736.0000 (48550593425560968.0000)  loss/pix_loss: 0.1590 (0.1661)  loss/enc_loss: 0.0023 (0.0015)  time: 4.1778  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.2322 (1.4017)  loss/high_gen_loss: 53369577152708608.0000 (48477724762397248.0000)  loss/pix_loss: 0.1647 (0.1661)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.1792 (1.3993)  loss/high_gen_loss: 43481342666604544.0000 (48403600721609928.0000)  loss/pix_loss: 0.1652 (0.1661)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.3601 (1.3993)  loss/high_gen_loss: 38335194456915968.0000 (48149791753957528.0000)  loss/pix_loss: 0.1678 (0.1662)  loss/enc_loss: 0.0022 (0.0016)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [690/862]  eta: 0:11:58  lr: 0.000100  loss/low_gen_loss: 1.2852 (1.3968)  loss/high_gen_loss: 30508204970475520.0000 (47901292491562664.0000)  loss/pix_loss: 0.1743 (0.1665)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.2686 (1.3969)  loss/high_gen_loss: 34285852045606912.0000 (47743146574816672.0000)  loss/pix_loss: 0.1721 (0.1664)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.3914 (1.3970)  loss/high_gen_loss: 40440797878812672.0000 (48056720696557408.0000)  loss/pix_loss: 0.1734 (0.1664)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.3939 (1.3971)  loss/high_gen_loss: 82154082898280448.0000 (48575709008162096.0000)  loss/pix_loss: 0.1784 (0.1665)  loss/enc_loss: 0.0003 (0.0015)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [730/862]  eta: 0:09:11  lr: 0.000100  loss/low_gen_loss: 1.4313 (1.3996)  loss/high_gen_loss: 67042068668612608.0000 (48495972949459168.0000)  loss/pix_loss: 0.1910 (0.1668)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.4929 (1.3982)  loss/high_gen_loss: 30279268181213184.0000 (48222339531231008.0000)  loss/pix_loss: 0.1712 (0.1667)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.4050 (1.3990)  loss/high_gen_loss: 25432713267773440.0000 (47829941124866232.0000)  loss/pix_loss: 0.1656 (0.1666)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.4505 (1.3989)  loss/high_gen_loss: 26067090674810880.0000 (48325005526283944.0000)  loss/pix_loss: 0.1649 (0.1665)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.3409 (1.3980)  loss/high_gen_loss: 171800066229534720.0000 (50284507015520864.0000)  loss/pix_loss: 0.1649 (0.1665)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.3513 (1.3977)  loss/high_gen_loss: 192493699697999872.0000 (51956302977593368.0000)  loss/pix_loss: 0.1666 (0.1664)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.3579 (1.3968)  loss/high_gen_loss: 169389163647336448.0000 (53473663282443184.0000)  loss/pix_loss: 0.1659 (0.1664)  loss/enc_loss: 0.0020 (0.0015)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.3672 (1.3964)  loss/high_gen_loss: 167141727520423936.0000 (54792240181470256.0000)  loss/pix_loss: 0.1716 (0.1665)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.3530 (1.3953)  loss/high_gen_loss: 146697786270679040.0000 (55963129825792832.0000)  loss/pix_loss: 0.1848 (0.1667)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.3779 (1.3952)  loss/high_gen_loss: 113352948674723840.0000 (56360151050135648.0000)  loss/pix_loss: 0.1848 (0.1668)  loss/enc_loss: 0.0020 (0.0015)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.3846 (1.3947)  loss/high_gen_loss: 85563814484901888.0000 (56722276481065696.0000)  loss/pix_loss: 0.1696 (0.1668)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.3836 (1.3950)  loss/high_gen_loss: 111960030651088896.0000 (57702775957098608.0000)  loss/pix_loss: 0.1639 (0.1667)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1754  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.4974 (1.3965)  loss/high_gen_loss: 140758928832069632.0000 (58718544097198024.0000)  loss/pix_loss: 0.1627 (0.1667)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1761  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.4681 (1.3966)  loss/high_gen_loss: 126745824934756352.0000 (59199915859993800.0000)  loss/pix_loss: 0.1757 (0.1668)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1765  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:25]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.4403 (1.3967)  loss/high_gen_loss: 123812362271588352.0000 (59217803848139248.0000)  loss/pix_loss: 0.1757 (0.1668)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1767  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:25] Total time: 0:59:59 (4.1752 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.4403 (1.3967)  loss/high_gen_loss: 123812362271588352.0000 (59217803848139248.0000)  loss/pix_loss: 0.1757 (0.1668)  loss/enc_loss: 0.0008 (0.0015)\n",
      "Valid: [epoch:25]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1329 (0.1329)  time: 3.0050  data: 0.3806  max mem: 31350\n",
      "Valid: [epoch:25]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6057  data: 0.0273  max mem: 31350\n",
      "Valid: [epoch:25] Total time: 0:00:36 (2.6143 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_25_input_n_20.png\n",
      "Train: [epoch:26]  [  0/862]  eta: 1:17:38  lr: 0.000100  loss/low_gen_loss: 1.4260 (1.4260)  loss/high_gen_loss: 74218074256965632.0000 (74218074256965632.0000)  loss/pix_loss: 0.1628 (0.1628)  loss/enc_loss: 0.0016 (0.0016)  time: 5.4047  data: 1.1225  max mem: 31350\n",
      "Train: [epoch:26]  [ 10/862]  eta: 1:00:50  lr: 0.000100  loss/low_gen_loss: 1.4207 (1.4209)  loss/high_gen_loss: 65829706775134208.0000 (65536638900788504.0000)  loss/pix_loss: 0.1628 (0.1604)  loss/enc_loss: 0.0009 (0.0010)  time: 4.2850  data: 0.1021  max mem: 31350\n",
      "Train: [epoch:26]  [ 20/862]  eta: 0:59:24  lr: 0.000100  loss/low_gen_loss: 1.3833 (1.3799)  loss/high_gen_loss: 60922899912982528.0000 (62138328004065768.0000)  loss/pix_loss: 0.1675 (0.1646)  loss/enc_loss: 0.0008 (0.0010)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [ 30/862]  eta: 0:58:28  lr: 0.000100  loss/low_gen_loss: 1.3308 (1.3650)  loss/high_gen_loss: 65340651734040576.0000 (66493997451735968.0000)  loss/pix_loss: 0.1675 (0.1657)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1795  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [ 40/862]  eta: 0:57:37  lr: 0.000100  loss/low_gen_loss: 1.3298 (1.3448)  loss/high_gen_loss: 80082766200307712.0000 (73711984118512464.0000)  loss/pix_loss: 0.1688 (0.1689)  loss/enc_loss: 0.0017 (0.0014)  time: 4.1779  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [ 50/862]  eta: 0:56:50  lr: 0.000100  loss/low_gen_loss: 1.2594 (1.3278)  loss/high_gen_loss: 83751415595401216.0000 (73589968554868416.0000)  loss/pix_loss: 0.1795 (0.1709)  loss/enc_loss: 0.0018 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [ 60/862]  eta: 0:56:04  lr: 0.000100  loss/low_gen_loss: 1.2942 (1.3253)  loss/high_gen_loss: 101729212393586688.0000 (86959950283953136.0000)  loss/pix_loss: 0.1660 (0.1709)  loss/enc_loss: 0.0022 (0.0017)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [ 70/862]  eta: 0:55:20  lr: 0.000100  loss/low_gen_loss: 1.2217 (1.3019)  loss/high_gen_loss: 205801484065964032.0000 (107808529236542128.0000)  loss/pix_loss: 0.1642 (0.1706)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [ 80/862]  eta: 0:54:36  lr: 0.000100  loss/low_gen_loss: 1.1730 (1.3025)  loss/high_gen_loss: 188642230724984832.0000 (111861830783954592.0000)  loss/pix_loss: 0.1656 (0.1696)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [ 90/862]  eta: 0:53:53  lr: 0.000100  loss/low_gen_loss: 1.3771 (1.3125)  loss/high_gen_loss: 115848702630821888.0000 (110380597159378048.0000)  loss/pix_loss: 0.1658 (0.1692)  loss/enc_loss: 0.0013 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [100/862]  eta: 0:53:10  lr: 0.000100  loss/low_gen_loss: 1.3740 (1.3146)  loss/high_gen_loss: 78360647523368960.0000 (104350871296056608.0000)  loss/pix_loss: 0.1734 (0.1689)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [110/862]  eta: 0:52:27  lr: 0.000100  loss/low_gen_loss: 1.3051 (1.3121)  loss/high_gen_loss: 37399819299323904.0000 (97861455879210144.0000)  loss/pix_loss: 0.1649 (0.1686)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [120/862]  eta: 0:51:44  lr: 0.000100  loss/low_gen_loss: 1.3051 (1.3129)  loss/high_gen_loss: 19504820880670720.0000 (91101867217119952.0000)  loss/pix_loss: 0.1661 (0.1694)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [130/862]  eta: 0:51:02  lr: 0.000100  loss/low_gen_loss: 1.3370 (1.3156)  loss/high_gen_loss: 19504820880670720.0000 (87119626897128976.0000)  loss/pix_loss: 0.1779 (0.1699)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1756  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [140/862]  eta: 0:50:20  lr: 0.000100  loss/low_gen_loss: 1.3704 (1.3247)  loss/high_gen_loss: 77085583402336256.0000 (98770121614872320.0000)  loss/pix_loss: 0.1671 (0.1691)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [150/862]  eta: 0:49:38  lr: 0.000100  loss/low_gen_loss: 1.4436 (1.3335)  loss/high_gen_loss: 298610350033469440.0000 (113388747468905680.0000)  loss/pix_loss: 0.1617 (0.1689)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [160/862]  eta: 0:48:55  lr: 0.000100  loss/low_gen_loss: 1.4268 (1.3394)  loss/high_gen_loss: 298610350033469440.0000 (124825825523414544.0000)  loss/pix_loss: 0.1638 (0.1688)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [170/862]  eta: 0:48:13  lr: 0.000100  loss/low_gen_loss: 1.3243 (1.3341)  loss/high_gen_loss: 278500351080923136.0000 (133392528385830800.0000)  loss/pix_loss: 0.1623 (0.1684)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [180/862]  eta: 0:47:31  lr: 0.000100  loss/low_gen_loss: 1.3243 (1.3371)  loss/high_gen_loss: 131380335165308928.0000 (129865702917720272.0000)  loss/pix_loss: 0.1790 (0.1698)  loss/enc_loss: 0.0019 (0.0015)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [190/862]  eta: 0:46:49  lr: 0.000100  loss/low_gen_loss: 1.3315 (1.3297)  loss/high_gen_loss: 72512791851827200.0000 (127961075137524464.0000)  loss/pix_loss: 0.1843 (0.1704)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [200/862]  eta: 0:46:07  lr: 0.000100  loss/low_gen_loss: 1.2428 (1.3323)  loss/high_gen_loss: 133923926467149824.0000 (128877914308831664.0000)  loss/pix_loss: 0.1826 (0.1713)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [210/862]  eta: 0:45:25  lr: 0.000100  loss/low_gen_loss: 1.4618 (1.3405)  loss/high_gen_loss: 141752861573775360.0000 (129513197833609024.0000)  loss/pix_loss: 0.1804 (0.1710)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1792  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [220/862]  eta: 0:44:43  lr: 0.000100  loss/low_gen_loss: 1.4373 (1.3429)  loss/high_gen_loss: 136169532937994240.0000 (129192971366134448.0000)  loss/pix_loss: 0.1622 (0.1700)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1783  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [230/862]  eta: 0:44:01  lr: 0.000100  loss/low_gen_loss: 1.3180 (1.3404)  loss/high_gen_loss: 97247723257856000.0000 (127781857801172352.0000)  loss/pix_loss: 0.1586 (0.1696)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [240/862]  eta: 0:43:20  lr: 0.000100  loss/low_gen_loss: 1.2629 (1.3368)  loss/high_gen_loss: 115282316703563776.0000 (128490692788139696.0000)  loss/pix_loss: 0.1755 (0.1700)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [250/862]  eta: 0:42:38  lr: 0.000100  loss/low_gen_loss: 1.3238 (1.3391)  loss/high_gen_loss: 100138700104531968.0000 (126245613570664256.0000)  loss/pix_loss: 0.1755 (0.1696)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [260/862]  eta: 0:41:56  lr: 0.000100  loss/low_gen_loss: 1.2973 (1.3349)  loss/high_gen_loss: 91033747394134016.0000 (128313680070050288.0000)  loss/pix_loss: 0.1679 (0.1697)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1741  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:26]  [270/862]  eta: 0:41:14  lr: 0.000100  loss/low_gen_loss: 1.2103 (1.3302)  loss/high_gen_loss: 298131409640357888.0000 (138172297425226704.0000)  loss/pix_loss: 0.1758 (0.1700)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [280/862]  eta: 0:40:32  lr: 0.000100  loss/low_gen_loss: 1.2251 (1.3279)  loss/high_gen_loss: 437800825528516608.0000 (152437106926453568.0000)  loss/pix_loss: 0.1718 (0.1697)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [290/862]  eta: 0:39:50  lr: 0.000100  loss/low_gen_loss: 1.3021 (1.3274)  loss/high_gen_loss: 509275712763461632.0000 (164705551874722208.0000)  loss/pix_loss: 0.1699 (0.1697)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [300/862]  eta: 0:39:08  lr: 0.000100  loss/low_gen_loss: 1.3195 (1.3281)  loss/high_gen_loss: 460462275573055488.0000 (173777473167931520.0000)  loss/pix_loss: 0.1520 (0.1688)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [310/862]  eta: 0:38:26  lr: 0.000100  loss/low_gen_loss: 1.3149 (1.3259)  loss/high_gen_loss: 382396812562006016.0000 (179021315445309696.0000)  loss/pix_loss: 0.1481 (0.1680)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [320/862]  eta: 0:37:44  lr: 0.000100  loss/low_gen_loss: 1.3047 (1.3265)  loss/high_gen_loss: 348808175442460672.0000 (186253418778565088.0000)  loss/pix_loss: 0.1503 (0.1679)  loss/enc_loss: 0.0030 (0.0015)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [330/862]  eta: 0:37:02  lr: 0.000100  loss/low_gen_loss: 1.3047 (1.3257)  loss/high_gen_loss: 501162519541317632.0000 (200299182258975040.0000)  loss/pix_loss: 0.1582 (0.1676)  loss/enc_loss: 0.0026 (0.0015)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [340/862]  eta: 0:36:21  lr: 0.000100  loss/low_gen_loss: 1.3203 (1.3260)  loss/high_gen_loss: 627150780964536320.0000 (212418232944533088.0000)  loss/pix_loss: 0.1611 (0.1674)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1766  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [350/862]  eta: 0:35:39  lr: 0.000100  loss/low_gen_loss: 1.3283 (1.3255)  loss/high_gen_loss: 571586376739323904.0000 (218629627239201312.0000)  loss/pix_loss: 0.1681 (0.1677)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [360/862]  eta: 0:34:57  lr: 0.000100  loss/low_gen_loss: 1.3153 (1.3261)  loss/high_gen_loss: 367290965905375232.0000 (222402001090079872.0000)  loss/pix_loss: 0.1711 (0.1677)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1748  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [370/862]  eta: 0:34:15  lr: 0.000100  loss/low_gen_loss: 1.4663 (1.3304)  loss/high_gen_loss: 361948198387843072.0000 (226045572175332992.0000)  loss/pix_loss: 0.1690 (0.1678)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [380/862]  eta: 0:33:33  lr: 0.000100  loss/low_gen_loss: 1.4594 (1.3312)  loss/high_gen_loss: 322116774763954176.0000 (228274006457805184.0000)  loss/pix_loss: 0.1652 (0.1675)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [390/862]  eta: 0:32:51  lr: 0.000100  loss/low_gen_loss: 1.2759 (1.3292)  loss/high_gen_loss: 324864145084121088.0000 (231858980657109056.0000)  loss/pix_loss: 0.1577 (0.1670)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [400/862]  eta: 0:32:10  lr: 0.000100  loss/low_gen_loss: 1.2909 (1.3300)  loss/high_gen_loss: 411696976376102912.0000 (240123101332466336.0000)  loss/pix_loss: 0.1603 (0.1669)  loss/enc_loss: 0.0019 (0.0015)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [410/862]  eta: 0:31:28  lr: 0.000100  loss/low_gen_loss: 1.3245 (1.3296)  loss/high_gen_loss: 592789530768048128.0000 (248927457554133088.0000)  loss/pix_loss: 0.1727 (0.1672)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [420/862]  eta: 0:30:46  lr: 0.000100  loss/low_gen_loss: 1.3142 (1.3291)  loss/high_gen_loss: 564828743915274240.0000 (255711864269263072.0000)  loss/pix_loss: 0.1689 (0.1670)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [430/862]  eta: 0:30:04  lr: 0.000100  loss/low_gen_loss: 1.3672 (1.3302)  loss/high_gen_loss: 525134896683810816.0000 (262266173585890432.0000)  loss/pix_loss: 0.1685 (0.1671)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1774  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [440/862]  eta: 0:29:22  lr: 0.000100  loss/low_gen_loss: 1.3761 (1.3314)  loss/high_gen_loss: 465180383047057408.0000 (264333747000281792.0000)  loss/pix_loss: 0.1667 (0.1670)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [450/862]  eta: 0:28:41  lr: 0.000100  loss/low_gen_loss: 1.4115 (1.3347)  loss/high_gen_loss: 218977601916502016.0000 (262725904065500576.0000)  loss/pix_loss: 0.1667 (0.1670)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [460/862]  eta: 0:27:59  lr: 0.000100  loss/low_gen_loss: 1.4718 (1.3374)  loss/high_gen_loss: 206304476275933184.0000 (261940550145265728.0000)  loss/pix_loss: 0.1669 (0.1668)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [470/862]  eta: 0:27:17  lr: 0.000100  loss/low_gen_loss: 1.5336 (1.3421)  loss/high_gen_loss: 215805699848929280.0000 (260764782140099936.0000)  loss/pix_loss: 0.1587 (0.1667)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [480/862]  eta: 0:26:35  lr: 0.000100  loss/low_gen_loss: 1.5387 (1.3461)  loss/high_gen_loss: 266600542891933696.0000 (263476290138042848.0000)  loss/pix_loss: 0.1621 (0.1668)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [490/862]  eta: 0:25:53  lr: 0.000100  loss/low_gen_loss: 1.5225 (1.3498)  loss/high_gen_loss: 410306059807227904.0000 (266077746281604128.0000)  loss/pix_loss: 0.1658 (0.1666)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [500/862]  eta: 0:25:12  lr: 0.000100  loss/low_gen_loss: 1.4308 (1.3508)  loss/high_gen_loss: 336293327936684032.0000 (266302546196197216.0000)  loss/pix_loss: 0.1607 (0.1665)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [510/862]  eta: 0:24:30  lr: 0.000100  loss/low_gen_loss: 1.3793 (1.3507)  loss/high_gen_loss: 491835843439230976.0000 (275938032998839616.0000)  loss/pix_loss: 0.1681 (0.1667)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [520/862]  eta: 0:23:48  lr: 0.000100  loss/low_gen_loss: 1.3264 (1.3502)  loss/high_gen_loss: 761382527737790464.0000 (285103245152980480.0000)  loss/pix_loss: 0.1702 (0.1666)  loss/enc_loss: 0.0016 (0.0014)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [530/862]  eta: 0:23:06  lr: 0.000100  loss/low_gen_loss: 1.3317 (1.3507)  loss/high_gen_loss: 760536797137600512.0000 (294745090316801024.0000)  loss/pix_loss: 0.1625 (0.1665)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [540/862]  eta: 0:22:24  lr: 0.000100  loss/low_gen_loss: 1.2357 (1.3474)  loss/high_gen_loss: 778243882147119104.0000 (305970551907449600.0000)  loss/pix_loss: 0.1719 (0.1669)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [550/862]  eta: 0:21:43  lr: 0.000100  loss/low_gen_loss: 1.3362 (1.3553)  loss/high_gen_loss: 873202241807319040.0000 (317178281464884480.0000)  loss/pix_loss: 0.1758 (0.1671)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [560/862]  eta: 0:21:01  lr: 0.000100  loss/low_gen_loss: 1.5616 (1.3561)  loss/high_gen_loss: 900908079401402368.0000 (327962141498119936.0000)  loss/pix_loss: 0.1545 (0.1668)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [570/862]  eta: 0:20:19  lr: 0.000100  loss/low_gen_loss: 1.3141 (1.3530)  loss/high_gen_loss: 798078384717430784.0000 (336104057498407936.0000)  loss/pix_loss: 0.1542 (0.1668)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1709  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:26]  [580/862]  eta: 0:19:37  lr: 0.000100  loss/low_gen_loss: 1.2486 (1.3531)  loss/high_gen_loss: 664395088088006656.0000 (339477946419234944.0000)  loss/pix_loss: 0.1591 (0.1667)  loss/enc_loss: 0.0021 (0.0015)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.2845 (1.3511)  loss/high_gen_loss: 349907034235207680.0000 (338552909329965888.0000)  loss/pix_loss: 0.1591 (0.1666)  loss/enc_loss: 0.0023 (0.0015)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [600/862]  eta: 0:18:14  lr: 0.000100  loss/low_gen_loss: 1.0684 (1.3457)  loss/high_gen_loss: 260937817490718720.0000 (336896570514778304.0000)  loss/pix_loss: 0.1629 (0.1665)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [610/862]  eta: 0:17:32  lr: 0.000100  loss/low_gen_loss: 1.0684 (1.3423)  loss/high_gen_loss: 262774225247404032.0000 (336208661351819072.0000)  loss/pix_loss: 0.1631 (0.1664)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.1768 (1.3406)  loss/high_gen_loss: 348064596344438784.0000 (340080417383298176.0000)  loss/pix_loss: 0.1653 (0.1666)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1748  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.1924 (1.3375)  loss/high_gen_loss: 678346103938088960.0000 (347376903850947968.0000)  loss/pix_loss: 0.1627 (0.1664)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1762  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [640/862]  eta: 0:15:27  lr: 0.000100  loss/low_gen_loss: 1.1473 (1.3347)  loss/high_gen_loss: 902424512094535680.0000 (357640994817122176.0000)  loss/pix_loss: 0.1547 (0.1663)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [650/862]  eta: 0:14:45  lr: 0.000100  loss/low_gen_loss: 1.1060 (1.3304)  loss/high_gen_loss: 824779199964250112.0000 (362691746266532800.0000)  loss/pix_loss: 0.1649 (0.1665)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.0905 (1.3274)  loss/high_gen_loss: 490214441745383424.0000 (364054370220396480.0000)  loss/pix_loss: 0.1639 (0.1665)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.1288 (1.3243)  loss/high_gen_loss: 469823758090108928.0000 (367533453153234880.0000)  loss/pix_loss: 0.1644 (0.1665)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.1317 (1.3220)  loss/high_gen_loss: 497840860554067968.0000 (369173734283262272.0000)  loss/pix_loss: 0.1666 (0.1667)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [690/862]  eta: 0:11:58  lr: 0.000100  loss/low_gen_loss: 1.1301 (1.3182)  loss/high_gen_loss: 471443922833375232.0000 (371678654347651712.0000)  loss/pix_loss: 0.1749 (0.1667)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.0385 (1.3142)  loss/high_gen_loss: 835494353093787648.0000 (392370493982639040.0000)  loss/pix_loss: 0.1625 (0.1667)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.0601 (1.3111)  loss/high_gen_loss: 1694063057208082432.0000 (409884783487973184.0000)  loss/pix_loss: 0.1775 (0.1670)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.0518 (1.3071)  loss/high_gen_loss: 1143339329490255872.0000 (418650600459872768.0000)  loss/pix_loss: 0.1806 (0.1670)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [730/862]  eta: 0:09:11  lr: 0.000100  loss/low_gen_loss: 1.0192 (1.3032)  loss/high_gen_loss: 1143339329490255872.0000 (437540154903350336.0000)  loss/pix_loss: 0.1674 (0.1669)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.0101 (1.2993)  loss/high_gen_loss: 2189439499887443968.0000 (461961444166957888.0000)  loss/pix_loss: 0.1573 (0.1669)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.0397 (1.2961)  loss/high_gen_loss: 2369167732148011008.0000 (492000029207175360.0000)  loss/pix_loss: 0.1733 (0.1669)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.0565 (1.2930)  loss/high_gen_loss: 2592368042830725120.0000 (519240939521863104.0000)  loss/pix_loss: 0.1726 (0.1669)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.0568 (1.2899)  loss/high_gen_loss: 2304114439495876608.0000 (532691739584796864.0000)  loss/pix_loss: 0.1667 (0.1670)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.0270 (1.2865)  loss/high_gen_loss: 1440682389293498368.0000 (543779499627153344.0000)  loss/pix_loss: 0.1681 (0.1669)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.0528 (1.2843)  loss/high_gen_loss: 1207109973109112832.0000 (551592858798468352.0000)  loss/pix_loss: 0.1728 (0.1670)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.1805 (1.2837)  loss/high_gen_loss: 1207109973109112832.0000 (563123355117200640.0000)  loss/pix_loss: 0.1765 (0.1670)  loss/enc_loss: 0.0023 (0.0014)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.1588 (1.2815)  loss/high_gen_loss: 1727037410925084672.0000 (581046982801305856.0000)  loss/pix_loss: 0.1709 (0.1671)  loss/enc_loss: 0.0024 (0.0015)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.1588 (1.2823)  loss/high_gen_loss: 1747329172893597696.0000 (595355658134719488.0000)  loss/pix_loss: 0.1727 (0.1671)  loss/enc_loss: 0.0026 (0.0015)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.3217 (1.2827)  loss/high_gen_loss: 1488779288499978240.0000 (602570594087775488.0000)  loss/pix_loss: 0.1733 (0.1672)  loss/enc_loss: 0.0026 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.2626 (1.2815)  loss/high_gen_loss: 1078232366926790656.0000 (607383081140941952.0000)  loss/pix_loss: 0.1655 (0.1671)  loss/enc_loss: 0.0022 (0.0015)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.1833 (1.2809)  loss/high_gen_loss: 603349240441208832.0000 (606682714030552704.0000)  loss/pix_loss: 0.1562 (0.1670)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.2501 (1.2807)  loss/high_gen_loss: 603349240441208832.0000 (612447925252922496.0000)  loss/pix_loss: 0.1675 (0.1670)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.2501 (1.2806)  loss/high_gen_loss: 625394311139164160.0000 (613530686206096128.0000)  loss/pix_loss: 0.1707 (0.1671)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:26] Total time: 0:59:59 (4.1753 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.2501 (1.2806)  loss/high_gen_loss: 625394311139164160.0000 (613530686206096128.0000)  loss/pix_loss: 0.1707 (0.1671)  loss/enc_loss: 0.0007 (0.0015)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:26]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1194 (0.1194)  time: 3.0082  data: 0.3981  max mem: 31350\n",
      "Valid: [epoch:26]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6100  data: 0.0285  max mem: 31350\n",
      "Valid: [epoch:26] Total time: 0:00:36 (2.6202 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_26_input_n_20.png\n",
      "Train: [epoch:27]  [  0/862]  eta: 1:18:16  lr: 0.000100  loss/low_gen_loss: 1.2220 (1.2220)  loss/high_gen_loss: 1506084502009544704.0000 (1506084502009544704.0000)  loss/pix_loss: 0.1925 (0.1925)  loss/enc_loss: 0.0006 (0.0006)  time: 5.4486  data: 1.2097  max mem: 31350\n",
      "Train: [epoch:27]  [ 10/862]  eta: 1:00:36  lr: 0.000100  loss/low_gen_loss: 1.3022 (1.2941)  loss/high_gen_loss: 1148292285776003072.0000 (1211076392586838016.0000)  loss/pix_loss: 0.1741 (0.1712)  loss/enc_loss: 0.0007 (0.0007)  time: 4.2683  data: 0.1101  max mem: 31350\n",
      "Train: [epoch:27]  [ 20/862]  eta: 0:59:10  lr: 0.000100  loss/low_gen_loss: 1.2488 (1.2418)  loss/high_gen_loss: 1008512746926374912.0000 (981876779959102080.0000)  loss/pix_loss: 0.1741 (0.1766)  loss/enc_loss: 0.0009 (0.0009)  time: 4.1548  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [ 30/862]  eta: 0:58:15  lr: 0.000100  loss/low_gen_loss: 1.2035 (1.2322)  loss/high_gen_loss: 719087613952131072.0000 (919550414321724800.0000)  loss/pix_loss: 0.1643 (0.1714)  loss/enc_loss: 0.0011 (0.0010)  time: 4.1639  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [ 40/862]  eta: 0:57:27  lr: 0.000100  loss/low_gen_loss: 1.2397 (1.2435)  loss/high_gen_loss: 793611275132207104.0000 (912738859714052864.0000)  loss/pix_loss: 0.1630 (0.1714)  loss/enc_loss: 0.0010 (0.0010)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [ 50/862]  eta: 0:56:41  lr: 0.000100  loss/low_gen_loss: 1.3097 (1.2592)  loss/high_gen_loss: 952673086837096448.0000 (924517278151667968.0000)  loss/pix_loss: 0.1618 (0.1686)  loss/enc_loss: 0.0010 (0.0010)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [ 60/862]  eta: 0:55:57  lr: 0.000100  loss/low_gen_loss: 1.3351 (1.2806)  loss/high_gen_loss: 1102662828101206016.0000 (1697308860595229184.0000)  loss/pix_loss: 0.1514 (0.1675)  loss/enc_loss: 0.0011 (0.0010)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [ 70/862]  eta: 0:55:13  lr: 0.000100  loss/low_gen_loss: 1.3861 (1.2968)  loss/high_gen_loss: 9789680998298943488.0000 (2985767161082789888.0000)  loss/pix_loss: 0.1698 (0.1689)  loss/enc_loss: 0.0014 (0.0011)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [ 80/862]  eta: 0:54:30  lr: 0.000100  loss/low_gen_loss: 1.3976 (1.3093)  loss/high_gen_loss: 11739661571624796160.0000 (4620909052832728064.0000)  loss/pix_loss: 0.1741 (0.1683)  loss/enc_loss: 0.0018 (0.0012)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [ 90/862]  eta: 0:53:48  lr: 0.000100  loss/low_gen_loss: 1.3976 (1.3147)  loss/high_gen_loss: 13221377734866894848.0000 (5400237988975065088.0000)  loss/pix_loss: 0.1694 (0.1684)  loss/enc_loss: 0.0031 (0.0015)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [100/862]  eta: 0:53:05  lr: 0.000100  loss/low_gen_loss: 1.2569 (1.3065)  loss/high_gen_loss: 10941641529743114240.0000 (5694152776091240448.0000)  loss/pix_loss: 0.1644 (0.1683)  loss/enc_loss: 0.0031 (0.0016)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [110/862]  eta: 0:52:23  lr: 0.000100  loss/low_gen_loss: 1.2417 (1.2997)  loss/high_gen_loss: 7463005542273777664.0000 (5844980058605663232.0000)  loss/pix_loss: 0.1642 (0.1685)  loss/enc_loss: 0.0020 (0.0016)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [120/862]  eta: 0:51:40  lr: 0.000100  loss/low_gen_loss: 1.1834 (1.2899)  loss/high_gen_loss: 7106690657351106560.0000 (5912559528494340096.0000)  loss/pix_loss: 0.1620 (0.1678)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [130/862]  eta: 0:50:58  lr: 0.000100  loss/low_gen_loss: 1.1751 (1.2819)  loss/high_gen_loss: 8694935203673538560.0000 (6187800331762116608.0000)  loss/pix_loss: 0.1620 (0.1686)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [140/862]  eta: 0:50:16  lr: 0.000100  loss/low_gen_loss: 1.2527 (1.2848)  loss/high_gen_loss: 8061838607423373312.0000 (6138835274170568704.0000)  loss/pix_loss: 0.1735 (0.1685)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [150/862]  eta: 0:49:34  lr: 0.000100  loss/low_gen_loss: 1.2694 (1.2802)  loss/high_gen_loss: 5348451168014041088.0000 (6076101840416330752.0000)  loss/pix_loss: 0.1642 (0.1677)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [160/862]  eta: 0:48:52  lr: 0.000100  loss/low_gen_loss: 1.2256 (1.2799)  loss/high_gen_loss: 5053498927525920768.0000 (6016477948557369344.0000)  loss/pix_loss: 0.1632 (0.1676)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [170/862]  eta: 0:48:10  lr: 0.000100  loss/low_gen_loss: 1.2676 (1.2787)  loss/high_gen_loss: 5698693450216505344.0000 (6130131718828224512.0000)  loss/pix_loss: 0.1709 (0.1676)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [180/862]  eta: 0:47:28  lr: 0.000100  loss/low_gen_loss: 1.1799 (1.2724)  loss/high_gen_loss: 7707575960953946112.0000 (6186980423400132608.0000)  loss/pix_loss: 0.1763 (0.1689)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [190/862]  eta: 0:46:46  lr: 0.000100  loss/low_gen_loss: 1.1503 (1.2657)  loss/high_gen_loss: 4291608287977144320.0000 (6052357570191680512.0000)  loss/pix_loss: 0.1861 (0.1696)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [200/862]  eta: 0:46:04  lr: 0.000100  loss/low_gen_loss: 1.1655 (1.2615)  loss/high_gen_loss: 4291608287977144320.0000 (6253269568893660160.0000)  loss/pix_loss: 0.1855 (0.1702)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [210/862]  eta: 0:45:22  lr: 0.000100  loss/low_gen_loss: 1.1717 (1.2565)  loss/high_gen_loss: 11342358542486077440.0000 (6507206951636188160.0000)  loss/pix_loss: 0.1790 (0.1701)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [220/862]  eta: 0:44:40  lr: 0.000100  loss/low_gen_loss: 1.1353 (1.2498)  loss/high_gen_loss: 11029590365337288704.0000 (6685709356126723072.0000)  loss/pix_loss: 0.1605 (0.1694)  loss/enc_loss: 0.0016 (0.0014)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [230/862]  eta: 0:43:59  lr: 0.000100  loss/low_gen_loss: 1.1312 (1.2464)  loss/high_gen_loss: 7385830271364366336.0000 (6600735314117873664.0000)  loss/pix_loss: 0.1548 (0.1692)  loss/enc_loss: 0.0016 (0.0014)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [240/862]  eta: 0:43:17  lr: 0.000100  loss/low_gen_loss: 1.1397 (1.2403)  loss/high_gen_loss: 3830302412107677696.0000 (6501126733882798080.0000)  loss/pix_loss: 0.1621 (0.1690)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [250/862]  eta: 0:42:35  lr: 0.000100  loss/low_gen_loss: 1.1218 (1.2367)  loss/high_gen_loss: 6226792183572201472.0000 (6589734349095711744.0000)  loss/pix_loss: 0.1614 (0.1687)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [260/862]  eta: 0:41:53  lr: 0.000100  loss/low_gen_loss: 1.1530 (1.2326)  loss/high_gen_loss: 9747231053373767680.0000 (6748494300031828992.0000)  loss/pix_loss: 0.1553 (0.1684)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [270/862]  eta: 0:41:11  lr: 0.000100  loss/low_gen_loss: 1.2171 (1.2355)  loss/high_gen_loss: 10544873962767122432.0000 (6877727285379228672.0000)  loss/pix_loss: 0.1615 (0.1686)  loss/enc_loss: 0.0021 (0.0014)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [280/862]  eta: 0:40:30  lr: 0.000100  loss/low_gen_loss: 1.3175 (1.2384)  loss/high_gen_loss: 8218036328776859648.0000 (6830474016254127104.0000)  loss/pix_loss: 0.1719 (0.1685)  loss/enc_loss: 0.0021 (0.0014)  time: 4.1745  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:27]  [290/862]  eta: 0:39:48  lr: 0.000100  loss/low_gen_loss: 1.2899 (1.2400)  loss/high_gen_loss: 4994768513928265728.0000 (6767408205510069248.0000)  loss/pix_loss: 0.1784 (0.1686)  loss/enc_loss: 0.0020 (0.0015)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [300/862]  eta: 0:39:06  lr: 0.000100  loss/low_gen_loss: 1.2375 (1.2379)  loss/high_gen_loss: 4646714809620889600.0000 (6684334822452691968.0000)  loss/pix_loss: 0.1644 (0.1680)  loss/enc_loss: 0.0019 (0.0015)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [310/862]  eta: 0:38:24  lr: 0.000100  loss/low_gen_loss: 1.1693 (1.2359)  loss/high_gen_loss: 4264443478823403520.0000 (6658697313404257280.0000)  loss/pix_loss: 0.1625 (0.1676)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [320/862]  eta: 0:37:42  lr: 0.000100  loss/low_gen_loss: 1.1061 (1.2315)  loss/high_gen_loss: 11443324496241491968.0000 (6983344794785427456.0000)  loss/pix_loss: 0.1571 (0.1671)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [330/862]  eta: 0:37:01  lr: 0.000100  loss/low_gen_loss: 1.0911 (1.2270)  loss/high_gen_loss: 17572636727674142720.0000 (7302661264856753152.0000)  loss/pix_loss: 0.1548 (0.1668)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [340/862]  eta: 0:36:19  lr: 0.000100  loss/low_gen_loss: 1.1152 (1.2240)  loss/high_gen_loss: 15692185971153960960.0000 (7465418945710892032.0000)  loss/pix_loss: 0.1600 (0.1667)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [350/862]  eta: 0:35:37  lr: 0.000100  loss/low_gen_loss: 1.1152 (1.2201)  loss/high_gen_loss: 15625269693487513600.0000 (7824622375246908416.0000)  loss/pix_loss: 0.1721 (0.1669)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [360/862]  eta: 0:34:55  lr: 0.000100  loss/low_gen_loss: 1.1242 (1.2193)  loss/high_gen_loss: 38579400112613621760.0000 (8965315915797687296.0000)  loss/pix_loss: 0.1700 (0.1671)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [370/862]  eta: 0:34:14  lr: 0.000100  loss/low_gen_loss: 1.2041 (1.2189)  loss/high_gen_loss: 62603812742402932736.0000 (11146255159080028160.0000)  loss/pix_loss: 0.1657 (0.1673)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [380/862]  eta: 0:33:32  lr: 0.000100  loss/low_gen_loss: 1.2054 (1.2185)  loss/high_gen_loss: 82726410448936108032.0000 (13019517602594940928.0000)  loss/pix_loss: 0.1634 (0.1671)  loss/enc_loss: 0.0033 (0.0014)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [390/862]  eta: 0:32:50  lr: 0.000100  loss/low_gen_loss: 1.1935 (1.2175)  loss/high_gen_loss: 75259151995686092800.0000 (14215328331509608448.0000)  loss/pix_loss: 0.1579 (0.1669)  loss/enc_loss: 0.0034 (0.0015)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [400/862]  eta: 0:32:08  lr: 0.000100  loss/low_gen_loss: 1.2011 (1.2173)  loss/high_gen_loss: 40153500541356343296.0000 (14767757976669034496.0000)  loss/pix_loss: 0.1568 (0.1668)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [410/862]  eta: 0:31:26  lr: 0.000100  loss/low_gen_loss: 1.0956 (1.2132)  loss/high_gen_loss: 33391589792440909824.0000 (15115809815368810496.0000)  loss/pix_loss: 0.1681 (0.1668)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [420/862]  eta: 0:30:45  lr: 0.000100  loss/low_gen_loss: 1.0763 (1.2113)  loss/high_gen_loss: 18392125833599778816.0000 (15055574286830835712.0000)  loss/pix_loss: 0.1687 (0.1670)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [430/862]  eta: 0:30:03  lr: 0.000100  loss/low_gen_loss: 1.1722 (1.2107)  loss/high_gen_loss: 10700839687167148032.0000 (14938782575063764992.0000)  loss/pix_loss: 0.1664 (0.1670)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [440/862]  eta: 0:29:21  lr: 0.000100  loss/low_gen_loss: 1.1647 (1.2084)  loss/high_gen_loss: 8732403811169075200.0000 (14774753609493149696.0000)  loss/pix_loss: 0.1644 (0.1669)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [450/862]  eta: 0:28:39  lr: 0.000100  loss/low_gen_loss: 1.1084 (1.2061)  loss/high_gen_loss: 10938150580324925440.0000 (14715461944508727296.0000)  loss/pix_loss: 0.1641 (0.1669)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [460/862]  eta: 0:27:57  lr: 0.000100  loss/low_gen_loss: 1.0563 (1.2023)  loss/high_gen_loss: 11828671435939774464.0000 (14686460000546611200.0000)  loss/pix_loss: 0.1641 (0.1669)  loss/enc_loss: 0.0019 (0.0014)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [470/862]  eta: 0:27:16  lr: 0.000100  loss/low_gen_loss: 1.0327 (1.1989)  loss/high_gen_loss: 16431552565251932160.0000 (14898783717909393408.0000)  loss/pix_loss: 0.1599 (0.1666)  loss/enc_loss: 0.0022 (0.0014)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [480/862]  eta: 0:26:34  lr: 0.000100  loss/low_gen_loss: 1.0683 (1.1966)  loss/high_gen_loss: 25707144807356301312.0000 (15379159158182287360.0000)  loss/pix_loss: 0.1549 (0.1663)  loss/enc_loss: 0.0020 (0.0014)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [490/862]  eta: 0:25:52  lr: 0.000100  loss/low_gen_loss: 1.0908 (1.1943)  loss/high_gen_loss: 48722174976521666560.0000 (16367076720543352832.0000)  loss/pix_loss: 0.1552 (0.1663)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [500/862]  eta: 0:25:10  lr: 0.000100  loss/low_gen_loss: 1.0250 (1.1907)  loss/high_gen_loss: 41598153267137740800.0000 (16849555486132260864.0000)  loss/pix_loss: 0.1568 (0.1662)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 1.0136 (1.1872)  loss/high_gen_loss: 39750608694613639168.0000 (17223670720000227328.0000)  loss/pix_loss: 0.1603 (0.1663)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 1.0196 (1.1846)  loss/high_gen_loss: 42839603049966600192.0000 (18352983408266790912.0000)  loss/pix_loss: 0.1690 (0.1663)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [530/862]  eta: 0:23:05  lr: 0.000100  loss/low_gen_loss: 1.0635 (1.1826)  loss/high_gen_loss: 50554823365512658944.0000 (18673305357196845056.0000)  loss/pix_loss: 0.1685 (0.1662)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [540/862]  eta: 0:22:23  lr: 0.000100  loss/low_gen_loss: 1.0638 (1.1804)  loss/high_gen_loss: 18848285720173346816.0000 (18651758935356780544.0000)  loss/pix_loss: 0.1664 (0.1664)  loss/enc_loss: 0.0029 (0.0014)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.1028 (1.1800)  loss/high_gen_loss: 19158968123764244480.0000 (18689655921752686592.0000)  loss/pix_loss: 0.1808 (0.1668)  loss/enc_loss: 0.0034 (0.0015)  time: 4.1696  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 1.2178 (1.1827)  loss/high_gen_loss: 21227787212355010560.0000 (18743340413101723648.0000)  loss/pix_loss: 0.1808 (0.1667)  loss/enc_loss: 0.0020 (0.0015)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [570/862]  eta: 0:20:18  lr: 0.000100  loss/low_gen_loss: 1.2861 (1.1838)  loss/high_gen_loss: 20891081567557910528.0000 (18779976745188921344.0000)  loss/pix_loss: 0.1709 (0.1670)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [580/862]  eta: 0:19:36  lr: 0.000100  loss/low_gen_loss: 1.1075 (1.1814)  loss/high_gen_loss: 22866688458392338432.0000 (18942411459513839616.0000)  loss/pix_loss: 0.1696 (0.1669)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1721  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:27]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.1205 (1.1812)  loss/high_gen_loss: 25845419389665411072.0000 (19027564968907177984.0000)  loss/pix_loss: 0.1625 (0.1666)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 1.1237 (1.1801)  loss/high_gen_loss: 28374254352108355584.0000 (20186875603369754624.0000)  loss/pix_loss: 0.1631 (0.1668)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [610/862]  eta: 0:17:31  lr: 0.000100  loss/low_gen_loss: 1.0705 (1.1772)  loss/high_gen_loss: 89980970576816111616.0000 (21487467594674536448.0000)  loss/pix_loss: 0.1774 (0.1667)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.0251 (1.1748)  loss/high_gen_loss: 49277274416920657920.0000 (21676395365133299712.0000)  loss/pix_loss: 0.1777 (0.1670)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.0293 (1.1728)  loss/high_gen_loss: 39794707906980478976.0000 (22129561526571315200.0000)  loss/pix_loss: 0.1680 (0.1669)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 1.0356 (1.1711)  loss/high_gen_loss: 27958256326762561536.0000 (22163924788848787456.0000)  loss/pix_loss: 0.1586 (0.1668)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 1.1436 (1.1716)  loss/high_gen_loss: 25753533202932170752.0000 (22491999321989562368.0000)  loss/pix_loss: 0.1683 (0.1669)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.2503 (1.1737)  loss/high_gen_loss: 71254194085651546112.0000 (23338899290794012672.0000)  loss/pix_loss: 0.1683 (0.1669)  loss/enc_loss: 0.0016 (0.0014)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.3605 (1.1777)  loss/high_gen_loss: 99580164484137746432.0000 (25074032402349252608.0000)  loss/pix_loss: 0.1671 (0.1670)  loss/enc_loss: 0.0021 (0.0015)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.4968 (1.1824)  loss/high_gen_loss: 165507866848005193728.0000 (27597692810845863936.0000)  loss/pix_loss: 0.1737 (0.1671)  loss/enc_loss: 0.0045 (0.0015)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.5087 (1.1876)  loss/high_gen_loss: 140150261185165393920.0000 (28829843077198553088.0000)  loss/pix_loss: 0.1692 (0.1671)  loss/enc_loss: 0.0039 (0.0015)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.5857 (1.1941)  loss/high_gen_loss: 97065669352344256512.0000 (29792437281838817280.0000)  loss/pix_loss: 0.1692 (0.1672)  loss/enc_loss: 0.0015 (0.0015)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.5535 (1.1985)  loss/high_gen_loss: 105506092353199276032.0000 (31464474222773690368.0000)  loss/pix_loss: 0.1798 (0.1674)  loss/enc_loss: 0.0007 (0.0015)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.5252 (1.2033)  loss/high_gen_loss: 174760248399647211520.0000 (34271228673773846528.0000)  loss/pix_loss: 0.1760 (0.1673)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 1.5311 (1.2078)  loss/high_gen_loss: 274698273132300468224.0000 (38206140453759336448.0000)  loss/pix_loss: 0.1686 (0.1674)  loss/enc_loss: 0.0003 (0.0015)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.5077 (1.2112)  loss/high_gen_loss: 181308165598495113216.0000 (39066011983273402368.0000)  loss/pix_loss: 0.1699 (0.1675)  loss/enc_loss: 0.0003 (0.0015)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.4716 (1.2147)  loss/high_gen_loss: 53073188778235920384.0000 (39125275734411526144.0000)  loss/pix_loss: 0.1697 (0.1674)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.4597 (1.2178)  loss/high_gen_loss: 41062092970085318656.0000 (39189482179908657152.0000)  loss/pix_loss: 0.1697 (0.1675)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [770/862]  eta: 0:06:23  lr: 0.000100  loss/low_gen_loss: 1.3729 (1.2187)  loss/high_gen_loss: 82437634715017019392.0000 (40139110926610120704.0000)  loss/pix_loss: 0.1713 (0.1675)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.4190 (1.2222)  loss/high_gen_loss: 195451878557926555648.0000 (47051951243582603264.0000)  loss/pix_loss: 0.1687 (0.1675)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.4572 (1.2246)  loss/high_gen_loss: 917005926889089400832.0000 (62511705422301175808.0000)  loss/pix_loss: 0.1591 (0.1674)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.4819 (1.2295)  loss/high_gen_loss: 1537350457649052778496.0000 (83432162666995908608.0000)  loss/pix_loss: 0.1668 (0.1675)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.5646 (1.2334)  loss/high_gen_loss: 1931594161654182445056.0000 (126573520380291301376.0000)  loss/pix_loss: 0.1763 (0.1676)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.4873 (1.2360)  loss/high_gen_loss: 1931594161654182445056.0000 (137746201655314432000.0000)  loss/pix_loss: 0.1754 (0.1676)  loss/enc_loss: 0.0022 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.4671 (1.2389)  loss/high_gen_loss: 203066550734135754752.0000 (137127190049184251904.0000)  loss/pix_loss: 0.1736 (0.1678)  loss/enc_loss: 0.0023 (0.0015)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.4414 (1.2407)  loss/high_gen_loss: 118112098718767382528.0000 (137252885967208448000.0000)  loss/pix_loss: 0.1569 (0.1675)  loss/enc_loss: 0.0019 (0.0015)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.3848 (1.2421)  loss/high_gen_loss: 259198994277216550912.0000 (141871673711985655808.0000)  loss/pix_loss: 0.1561 (0.1675)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.5153 (1.2460)  loss/high_gen_loss: 479386084547917512704.0000 (145397177672724627456.0000)  loss/pix_loss: 0.1708 (0.1675)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.5399 (1.2464)  loss/high_gen_loss: 479386084547917512704.0000 (145657050247608467456.0000)  loss/pix_loss: 0.1692 (0.1675)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:27] Total time: 0:59:57 (4.1734 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.5399 (1.2464)  loss/high_gen_loss: 479386084547917512704.0000 (145657050247608467456.0000)  loss/pix_loss: 0.1692 (0.1675)  loss/enc_loss: 0.0009 (0.0014)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:27]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1080 (0.1080)  time: 2.9871  data: 0.3813  max mem: 31350\n",
      "Valid: [epoch:27]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6036  data: 0.0273  max mem: 31350\n",
      "Valid: [epoch:27] Total time: 0:00:36 (2.6132 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_27_input_n_20.png\n",
      "Train: [epoch:28]  [  0/862]  eta: 1:15:26  lr: 0.000100  loss/low_gen_loss: 1.6213 (1.6213)  loss/high_gen_loss: 353866400070962774016.0000 (353866400070962774016.0000)  loss/pix_loss: 0.1714 (0.1714)  loss/enc_loss: 0.0006 (0.0006)  time: 5.2509  data: 1.0744  max mem: 31350\n",
      "Train: [epoch:28]  [ 10/862]  eta: 1:00:44  lr: 0.000100  loss/low_gen_loss: 1.5966 (1.5978)  loss/high_gen_loss: 264197444505830424576.0000 (264207019452907520000.0000)  loss/pix_loss: 0.1691 (0.1669)  loss/enc_loss: 0.0008 (0.0008)  time: 4.2781  data: 0.0978  max mem: 31350\n",
      "Train: [epoch:28]  [ 20/862]  eta: 0:59:19  lr: 0.000100  loss/low_gen_loss: 1.5814 (1.5603)  loss/high_gen_loss: 264197444505830424576.0000 (303042422123032543232.0000)  loss/pix_loss: 0.1670 (0.1686)  loss/enc_loss: 0.0010 (0.0009)  time: 4.1759  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [ 30/862]  eta: 0:58:21  lr: 0.000100  loss/low_gen_loss: 1.4315 (1.5094)  loss/high_gen_loss: 351627970318671282176.0000 (351639879661133496320.0000)  loss/pix_loss: 0.1643 (0.1671)  loss/enc_loss: 0.0010 (0.0010)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [ 40/862]  eta: 0:57:31  lr: 0.000100  loss/low_gen_loss: 1.4045 (1.4795)  loss/high_gen_loss: 274974716743802421248.0000 (313737549293068025856.0000)  loss/pix_loss: 0.1657 (0.1693)  loss/enc_loss: 0.0015 (0.0012)  time: 4.1694  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [ 50/862]  eta: 0:56:45  lr: 0.000100  loss/low_gen_loss: 1.3858 (1.4631)  loss/high_gen_loss: 206706268473609158656.0000 (303564133060334780416.0000)  loss/pix_loss: 0.1658 (0.1691)  loss/enc_loss: 0.0016 (0.0012)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [ 60/862]  eta: 0:56:00  lr: 0.000100  loss/low_gen_loss: 1.3778 (1.4476)  loss/high_gen_loss: 347127889128509669376.0000 (315247098717426745344.0000)  loss/pix_loss: 0.1648 (0.1687)  loss/enc_loss: 0.0008 (0.0011)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [ 70/862]  eta: 0:55:16  lr: 0.000100  loss/low_gen_loss: 1.4215 (1.4539)  loss/high_gen_loss: 264721128700000600064.0000 (295581367475728285696.0000)  loss/pix_loss: 0.1658 (0.1696)  loss/enc_loss: 0.0008 (0.0011)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [ 80/862]  eta: 0:54:33  lr: 0.000100  loss/low_gen_loss: 1.4715 (1.4536)  loss/high_gen_loss: 264721128700000600064.0000 (332287398329854853120.0000)  loss/pix_loss: 0.1653 (0.1677)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [ 90/862]  eta: 0:53:50  lr: 0.000100  loss/low_gen_loss: 1.4559 (1.4579)  loss/high_gen_loss: 728349434811097546752.0000 (385771458962908643328.0000)  loss/pix_loss: 0.1637 (0.1665)  loss/enc_loss: 0.0029 (0.0014)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [100/862]  eta: 0:53:07  lr: 0.000100  loss/low_gen_loss: 1.3623 (1.4470)  loss/high_gen_loss: 673727597099278663680.0000 (407450348795838267392.0000)  loss/pix_loss: 0.1565 (0.1657)  loss/enc_loss: 0.0033 (0.0017)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [110/862]  eta: 0:52:24  lr: 0.000100  loss/low_gen_loss: 1.3530 (1.4406)  loss/high_gen_loss: 491992891357950640128.0000 (396224543739249426432.0000)  loss/pix_loss: 0.1666 (0.1662)  loss/enc_loss: 0.0030 (0.0017)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [120/862]  eta: 0:51:42  lr: 0.000100  loss/low_gen_loss: 1.3291 (1.4275)  loss/high_gen_loss: 208848275454191206400.0000 (380421010785007304704.0000)  loss/pix_loss: 0.1686 (0.1657)  loss/enc_loss: 0.0018 (0.0017)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [130/862]  eta: 0:51:00  lr: 0.000100  loss/low_gen_loss: 1.2976 (1.4257)  loss/high_gen_loss: 216512997399696769024.0000 (371687863061723217920.0000)  loss/pix_loss: 0.1759 (0.1668)  loss/enc_loss: 0.0008 (0.0016)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [140/862]  eta: 0:50:17  lr: 0.000100  loss/low_gen_loss: 1.4522 (1.4296)  loss/high_gen_loss: 338092507191725522944.0000 (373891953508788404224.0000)  loss/pix_loss: 0.1753 (0.1665)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [150/862]  eta: 0:49:35  lr: 0.000100  loss/low_gen_loss: 1.4184 (1.4256)  loss/high_gen_loss: 597483484995244785664.0000 (414525093821721214976.0000)  loss/pix_loss: 0.1501 (0.1656)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [160/862]  eta: 0:48:53  lr: 0.000100  loss/low_gen_loss: 1.3164 (1.4166)  loss/high_gen_loss: 842712084529939480576.0000 (429662066373223120896.0000)  loss/pix_loss: 0.1632 (0.1655)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [170/862]  eta: 0:48:11  lr: 0.000100  loss/low_gen_loss: 1.3019 (1.4102)  loss/high_gen_loss: 351262791720761294848.0000 (421065264519703166976.0000)  loss/pix_loss: 0.1743 (0.1658)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [180/862]  eta: 0:47:29  lr: 0.000100  loss/low_gen_loss: 1.2866 (1.3996)  loss/high_gen_loss: 297159219809810907136.0000 (421936302637875593216.0000)  loss/pix_loss: 0.1742 (0.1659)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [190/862]  eta: 0:46:48  lr: 0.000100  loss/low_gen_loss: 1.1627 (1.3861)  loss/high_gen_loss: 928615362303520407552.0000 (529251313378471772160.0000)  loss/pix_loss: 0.1745 (0.1665)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [200/862]  eta: 0:46:06  lr: 0.000100  loss/low_gen_loss: 1.1774 (1.3807)  loss/high_gen_loss: 2344510774876808675328.0000 (622159120376124801024.0000)  loss/pix_loss: 0.1841 (0.1676)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [210/862]  eta: 0:45:24  lr: 0.000100  loss/low_gen_loss: 1.2608 (1.3750)  loss/high_gen_loss: 1095742959312821026816.0000 (635096274024743698432.0000)  loss/pix_loss: 0.1796 (0.1675)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1778  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [220/862]  eta: 0:44:42  lr: 0.000100  loss/low_gen_loss: 1.2138 (1.3668)  loss/high_gen_loss: 887065363247632744448.0000 (649995212986667630592.0000)  loss/pix_loss: 0.1599 (0.1672)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1786  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [230/862]  eta: 0:44:00  lr: 0.000100  loss/low_gen_loss: 1.1843 (1.3582)  loss/high_gen_loss: 990962632594884132864.0000 (671016323123509067776.0000)  loss/pix_loss: 0.1627 (0.1673)  loss/enc_loss: 0.0019 (0.0014)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [240/862]  eta: 0:43:18  lr: 0.000100  loss/low_gen_loss: 1.2412 (1.3545)  loss/high_gen_loss: 1049561711727624585216.0000 (684957450879199608832.0000)  loss/pix_loss: 0.1732 (0.1677)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [250/862]  eta: 0:42:36  lr: 0.000100  loss/low_gen_loss: 1.2743 (1.3514)  loss/high_gen_loss: 1060461337619535495168.0000 (705244639776712425472.0000)  loss/pix_loss: 0.1729 (0.1673)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [260/862]  eta: 0:41:54  lr: 0.000100  loss/low_gen_loss: 1.2118 (1.3447)  loss/high_gen_loss: 1287775462261480488960.0000 (789304895933406773248.0000)  loss/pix_loss: 0.1577 (0.1669)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [270/862]  eta: 0:41:13  lr: 0.000100  loss/low_gen_loss: 1.2453 (1.3431)  loss/high_gen_loss: 4610479335202229321728.0000 (1078882865209566953472.0000)  loss/pix_loss: 0.1662 (0.1672)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1759  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:28]  [280/862]  eta: 0:40:31  lr: 0.000100  loss/low_gen_loss: 1.2232 (1.3381)  loss/high_gen_loss: 9263790154660565745664.0000 (1387289645029358305280.0000)  loss/pix_loss: 0.1756 (0.1674)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [290/862]  eta: 0:39:49  lr: 0.000100  loss/low_gen_loss: 1.2197 (1.3409)  loss/high_gen_loss: 6711192670063428632576.0000 (1441909175581193011200.0000)  loss/pix_loss: 0.1644 (0.1673)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [300/862]  eta: 0:39:07  lr: 0.000100  loss/low_gen_loss: 1.3354 (1.3396)  loss/high_gen_loss: 2426494443230949539840.0000 (1476196401338929905664.0000)  loss/pix_loss: 0.1550 (0.1664)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [310/862]  eta: 0:38:25  lr: 0.000100  loss/low_gen_loss: 1.2515 (1.3347)  loss/high_gen_loss: 2821734568653634928640.0000 (1526561014446663663616.0000)  loss/pix_loss: 0.1447 (0.1655)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1757  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [320/862]  eta: 0:37:44  lr: 0.000100  loss/low_gen_loss: 1.2322 (1.3325)  loss/high_gen_loss: 4005513612007317700608.0000 (1772954876562985189376.0000)  loss/pix_loss: 0.1505 (0.1654)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [330/862]  eta: 0:37:02  lr: 0.000100  loss/low_gen_loss: 1.1972 (1.3268)  loss/high_gen_loss: 12768173317956602691584.0000 (2201736686604817006592.0000)  loss/pix_loss: 0.1637 (0.1653)  loss/enc_loss: 0.0031 (0.0015)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [340/862]  eta: 0:36:20  lr: 0.000100  loss/low_gen_loss: 1.1518 (1.3224)  loss/high_gen_loss: 10091269728244598833152.0000 (2408564319185888346112.0000)  loss/pix_loss: 0.1703 (0.1655)  loss/enc_loss: 0.0042 (0.0016)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [350/862]  eta: 0:35:38  lr: 0.000100  loss/low_gen_loss: 1.2020 (1.3203)  loss/high_gen_loss: 9562574153589066825728.0000 (2636639957913503793152.0000)  loss/pix_loss: 0.1667 (0.1654)  loss/enc_loss: 0.0034 (0.0016)  time: 4.1757  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [360/862]  eta: 0:34:56  lr: 0.000100  loss/low_gen_loss: 1.2803 (1.3196)  loss/high_gen_loss: 7790670034897070981120.0000 (2732426648458574168064.0000)  loss/pix_loss: 0.1700 (0.1656)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [370/862]  eta: 0:34:14  lr: 0.000100  loss/low_gen_loss: 1.2932 (1.3205)  loss/high_gen_loss: 5983282617690976419840.0000 (2890743840616815263744.0000)  loss/pix_loss: 0.1700 (0.1657)  loss/enc_loss: 0.0007 (0.0016)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [380/862]  eta: 0:33:33  lr: 0.000100  loss/low_gen_loss: 1.2808 (1.3181)  loss/high_gen_loss: 17825279976229721604096.0000 (3452098210767573614592.0000)  loss/pix_loss: 0.1607 (0.1656)  loss/enc_loss: 0.0004 (0.0016)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [390/862]  eta: 0:32:51  lr: 0.000100  loss/low_gen_loss: 1.1708 (1.3136)  loss/high_gen_loss: 23739890017952692436992.0000 (3940348393095519797248.0000)  loss/pix_loss: 0.1728 (0.1658)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [400/862]  eta: 0:32:09  lr: 0.000100  loss/low_gen_loss: 1.1827 (1.3114)  loss/high_gen_loss: 24696828377575257538560.0000 (4554210074420550565888.0000)  loss/pix_loss: 0.1735 (0.1659)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1771  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [410/862]  eta: 0:31:27  lr: 0.000100  loss/low_gen_loss: 1.2428 (1.3111)  loss/high_gen_loss: 27368503288119884251136.0000 (5088371986075435925504.0000)  loss/pix_loss: 0.1672 (0.1660)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1765  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [420/862]  eta: 0:30:46  lr: 0.000100  loss/low_gen_loss: 1.2862 (1.3099)  loss/high_gen_loss: 22184727260827435925504.0000 (5339349498344161411072.0000)  loss/pix_loss: 0.1688 (0.1660)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [430/862]  eta: 0:30:04  lr: 0.000100  loss/low_gen_loss: 1.2871 (1.3103)  loss/high_gen_loss: 17244142235713273856000.0000 (5675498532424477835264.0000)  loss/pix_loss: 0.1708 (0.1662)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [440/862]  eta: 0:29:22  lr: 0.000100  loss/low_gen_loss: 1.2953 (1.3096)  loss/high_gen_loss: 20108736717595663663104.0000 (6001291058273560035328.0000)  loss/pix_loss: 0.1705 (0.1662)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [450/862]  eta: 0:28:40  lr: 0.000100  loss/low_gen_loss: 1.2815 (1.3096)  loss/high_gen_loss: 16208075630637809139712.0000 (6193851849291061002240.0000)  loss/pix_loss: 0.1755 (0.1664)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [460/862]  eta: 0:27:58  lr: 0.000100  loss/low_gen_loss: 1.2657 (1.3082)  loss/high_gen_loss: 14375169129093173084160.0000 (6346565802451706839040.0000)  loss/pix_loss: 0.1680 (0.1664)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [470/862]  eta: 0:27:17  lr: 0.000100  loss/low_gen_loss: 1.2166 (1.3053)  loss/high_gen_loss: 10412479964467544719360.0000 (6417550876789545369600.0000)  loss/pix_loss: 0.1595 (0.1663)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [480/862]  eta: 0:26:35  lr: 0.000100  loss/low_gen_loss: 1.2374 (1.3047)  loss/high_gen_loss: 11719283838842107330560.0000 (6570307859365759025152.0000)  loss/pix_loss: 0.1566 (0.1661)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [490/862]  eta: 0:25:53  lr: 0.000100  loss/low_gen_loss: 1.3044 (1.3046)  loss/high_gen_loss: 13332697279447680679936.0000 (6685211685538909650944.0000)  loss/pix_loss: 0.1553 (0.1660)  loss/enc_loss: 0.0029 (0.0015)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [500/862]  eta: 0:25:11  lr: 0.000100  loss/low_gen_loss: 1.2412 (1.3021)  loss/high_gen_loss: 10461609732802529460224.0000 (6758760911545719324672.0000)  loss/pix_loss: 0.1557 (0.1657)  loss/enc_loss: 0.0030 (0.0015)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 1.2220 (1.3018)  loss/high_gen_loss: 10493525617461797322752.0000 (6872895368414753718272.0000)  loss/pix_loss: 0.1627 (0.1659)  loss/enc_loss: 0.0021 (0.0015)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [520/862]  eta: 0:23:48  lr: 0.000100  loss/low_gen_loss: 1.2930 (1.3011)  loss/high_gen_loss: 12440941769031862452224.0000 (6988908910670055997440.0000)  loss/pix_loss: 0.1691 (0.1659)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1773  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [530/862]  eta: 0:23:06  lr: 0.000100  loss/low_gen_loss: 1.2212 (1.2994)  loss/high_gen_loss: 11303279585862453559296.0000 (7050184123417824854016.0000)  loss/pix_loss: 0.1591 (0.1656)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1769  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [540/862]  eta: 0:22:24  lr: 0.000100  loss/low_gen_loss: 1.2463 (1.2988)  loss/high_gen_loss: 8812506391049951772672.0000 (7060253945478494814208.0000)  loss/pix_loss: 0.1730 (0.1660)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1763  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.2845 (1.2989)  loss/high_gen_loss: 6955179683475852623872.0000 (7048012156514497200128.0000)  loss/pix_loss: 0.1744 (0.1661)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [560/862]  eta: 0:21:01  lr: 0.000100  loss/low_gen_loss: 1.2679 (1.2967)  loss/high_gen_loss: 6305323205095218741248.0000 (7036294217780841938944.0000)  loss/pix_loss: 0.1636 (0.1660)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [570/862]  eta: 0:20:19  lr: 0.000100  loss/low_gen_loss: 1.1903 (1.2956)  loss/high_gen_loss: 6742710549105627627520.0000 (7130127230088141340672.0000)  loss/pix_loss: 0.1623 (0.1661)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1726  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:28]  [580/862]  eta: 0:19:37  lr: 0.000100  loss/low_gen_loss: 1.2189 (1.2945)  loss/high_gen_loss: 17496590386925620166656.0000 (7372147638677956198400.0000)  loss/pix_loss: 0.1627 (0.1661)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.1674 (1.2921)  loss/high_gen_loss: 16348800734094161870848.0000 (7454101400634597048320.0000)  loss/pix_loss: 0.1616 (0.1660)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1696  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [600/862]  eta: 0:18:14  lr: 0.000100  loss/low_gen_loss: 1.1674 (1.2911)  loss/high_gen_loss: 11687667443558059606016.0000 (7556702115055364210688.0000)  loss/pix_loss: 0.1647 (0.1661)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [610/862]  eta: 0:17:32  lr: 0.000100  loss/low_gen_loss: 1.2423 (1.2912)  loss/high_gen_loss: 19498449428491060379648.0000 (7772368497561953107968.0000)  loss/pix_loss: 0.1768 (0.1662)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.2575 (1.2900)  loss/high_gen_loss: 19763515539959391977472.0000 (7930389935205548818432.0000)  loss/pix_loss: 0.1769 (0.1665)  loss/enc_loss: 0.0016 (0.0014)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.3122 (1.2910)  loss/high_gen_loss: 13414766375457253228544.0000 (8007402702160124706816.0000)  loss/pix_loss: 0.1672 (0.1663)  loss/enc_loss: 0.0017 (0.0014)  time: 4.1703  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 1.3335 (1.2917)  loss/high_gen_loss: 13857196625150410227712.0000 (8120007893759422365696.0000)  loss/pix_loss: 0.1650 (0.1665)  loss/enc_loss: 0.0022 (0.0014)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [650/862]  eta: 0:14:45  lr: 0.000100  loss/low_gen_loss: 1.3110 (1.2916)  loss/high_gen_loss: 16345821602940656287744.0000 (8299031181624820629504.0000)  loss/pix_loss: 0.1811 (0.1667)  loss/enc_loss: 0.0019 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.2635 (1.2910)  loss/high_gen_loss: 19983869914327189291008.0000 (8453983381144414978048.0000)  loss/pix_loss: 0.1738 (0.1668)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1684  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.2377 (1.2901)  loss/high_gen_loss: 15857835191216833036288.0000 (8542433762378752458752.0000)  loss/pix_loss: 0.1733 (0.1669)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1690  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.2098 (1.2877)  loss/high_gen_loss: 16467446940377330745344.0000 (8687659132080183312384.0000)  loss/pix_loss: 0.1784 (0.1670)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [690/862]  eta: 0:11:58  lr: 0.000100  loss/low_gen_loss: 1.1275 (1.2856)  loss/high_gen_loss: 20425758606165154988032.0000 (8875632524776684126208.0000)  loss/pix_loss: 0.1826 (0.1671)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.0788 (1.2827)  loss/high_gen_loss: 22517709906476328288256.0000 (9181713491928038768640.0000)  loss/pix_loss: 0.1626 (0.1670)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.1113 (1.2808)  loss/high_gen_loss: 20230872087690137829376.0000 (9300251086409696280576.0000)  loss/pix_loss: 0.1652 (0.1671)  loss/enc_loss: 0.0020 (0.0014)  time: 4.1694  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.1603 (1.2797)  loss/high_gen_loss: 21583282789591174610944.0000 (9646083880472534843392.0000)  loss/pix_loss: 0.1810 (0.1672)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1690  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [730/862]  eta: 0:09:11  lr: 0.000100  loss/low_gen_loss: 1.1345 (1.2765)  loss/high_gen_loss: 31648447402595720364032.0000 (9911480064866045132800.0000)  loss/pix_loss: 0.1767 (0.1672)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.0847 (1.2747)  loss/high_gen_loss: 16135568802537050996736.0000 (9947536738909887135744.0000)  loss/pix_loss: 0.1709 (0.1673)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.1085 (1.2722)  loss/high_gen_loss: 10339822265779269664768.0000 (9953282221716090650624.0000)  loss/pix_loss: 0.1709 (0.1673)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.0899 (1.2699)  loss/high_gen_loss: 12803536708130622668800.0000 (10016572090312388771840.0000)  loss/pix_loss: 0.1597 (0.1672)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.1579 (1.2694)  loss/high_gen_loss: 14589939039923030982656.0000 (10125706712144582541312.0000)  loss/pix_loss: 0.1718 (0.1673)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.1942 (1.2681)  loss/high_gen_loss: 33804565990397668491264.0000 (10712913880847585640448.0000)  loss/pix_loss: 0.1742 (0.1672)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.1871 (1.2674)  loss/high_gen_loss: 68741012667943109001216.0000 (11740003346899475103744.0000)  loss/pix_loss: 0.1654 (0.1671)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.2237 (1.2671)  loss/high_gen_loss: 77703657811570524684288.0000 (12465165171495675101184.0000)  loss/pix_loss: 0.1562 (0.1671)  loss/enc_loss: 0.0016 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 1.2570 (1.2669)  loss/high_gen_loss: 75232316523250219745280.0000 (13245817999404933578752.0000)  loss/pix_loss: 0.1564 (0.1671)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.2432 (1.2666)  loss/high_gen_loss: 77653217495743975129088.0000 (14090932302575979986944.0000)  loss/pix_loss: 0.1673 (0.1672)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.2478 (1.2664)  loss/high_gen_loss: 72652663663891654377472.0000 (14711866643357703864320.0000)  loss/pix_loss: 0.1781 (0.1673)  loss/enc_loss: 0.0022 (0.0014)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.2195 (1.2650)  loss/high_gen_loss: 67053612966759186300928.0000 (15404719515976305999872.0000)  loss/pix_loss: 0.1698 (0.1674)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.1567 (1.2644)  loss/high_gen_loss: 80407745128633336856576.0000 (16267186688669876486144.0000)  loss/pix_loss: 0.1657 (0.1673)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1696  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.2746 (1.2647)  loss/high_gen_loss: 67057427515643569111040.0000 (16720818715744521945088.0000)  loss/pix_loss: 0.1639 (0.1672)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:28]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.2746 (1.2646)  loss/high_gen_loss: 62696101104101334450176.0000 (16774154310162568970240.0000)  loss/pix_loss: 0.1654 (0.1673)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1708  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:28] Total time: 0:59:58 (4.1743 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.2746 (1.2646)  loss/high_gen_loss: 62696101104101334450176.0000 (16774154310162568970240.0000)  loss/pix_loss: 0.1654 (0.1673)  loss/enc_loss: 0.0011 (0.0014)\n",
      "Valid: [epoch:28]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1242 (0.1242)  time: 3.0420  data: 0.3994  max mem: 31350\n",
      "Valid: [epoch:28]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5995  data: 0.0286  max mem: 31350\n",
      "Valid: [epoch:28] Total time: 0:00:36 (2.6079 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_28_input_n_20.png\n",
      "Train: [epoch:29]  [  0/862]  eta: 1:15:23  lr: 0.000100  loss/low_gen_loss: 1.1423 (1.1423)  loss/high_gen_loss: 64541572648606334189568.0000 (64541572648606334189568.0000)  loss/pix_loss: 0.1081 (0.1081)  loss/enc_loss: 0.0009 (0.0009)  time: 5.2478  data: 1.0968  max mem: 31350\n",
      "Train: [epoch:29]  [ 10/862]  eta: 1:00:12  lr: 0.000100  loss/low_gen_loss: 1.1423 (1.1525)  loss/high_gen_loss: 50970538121478765805568.0000 (50616027041356595593216.0000)  loss/pix_loss: 0.1630 (0.1626)  loss/enc_loss: 0.0011 (0.0010)  time: 4.2401  data: 0.0998  max mem: 31350\n",
      "Train: [epoch:29]  [ 20/862]  eta: 0:58:53  lr: 0.000100  loss/low_gen_loss: 1.1789 (1.1740)  loss/high_gen_loss: 52124540489996181700608.0000 (52581477852760441356288.0000)  loss/pix_loss: 0.1697 (0.1661)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1441  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [ 30/862]  eta: 0:58:02  lr: 0.000100  loss/low_gen_loss: 1.2156 (1.1935)  loss/high_gen_loss: 64719478344686350893056.0000 (60693955866043443314688.0000)  loss/pix_loss: 0.1709 (0.1678)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1551  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [ 40/862]  eta: 0:57:16  lr: 0.000100  loss/low_gen_loss: 1.2341 (1.2048)  loss/high_gen_loss: 69703702124289826226176.0000 (63066335328989966499840.0000)  loss/pix_loss: 0.1740 (0.1720)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1643  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [ 50/862]  eta: 0:56:32  lr: 0.000100  loss/low_gen_loss: 1.2347 (1.2096)  loss/high_gen_loss: 60601643550597529468928.0000 (61313283466257357602816.0000)  loss/pix_loss: 0.1710 (0.1689)  loss/enc_loss: 0.0006 (0.0011)  time: 4.1673  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [ 60/862]  eta: 0:55:49  lr: 0.000100  loss/low_gen_loss: 1.1018 (1.1841)  loss/high_gen_loss: 40826346594012936273920.0000 (56057994888330870784000.0000)  loss/pix_loss: 0.1495 (0.1671)  loss/enc_loss: 0.0008 (0.0011)  time: 4.1675  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [ 70/862]  eta: 0:55:07  lr: 0.000100  loss/low_gen_loss: 1.1018 (1.1856)  loss/high_gen_loss: 28674535921058259664896.0000 (52767025693757846585344.0000)  loss/pix_loss: 0.1634 (0.1681)  loss/enc_loss: 0.0023 (0.0015)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [ 80/862]  eta: 0:54:25  lr: 0.000100  loss/low_gen_loss: 1.1722 (1.1813)  loss/high_gen_loss: 56260434718590758813696.0000 (62066802536369727995904.0000)  loss/pix_loss: 0.1634 (0.1675)  loss/enc_loss: 0.0030 (0.0016)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [ 90/862]  eta: 0:53:43  lr: 0.000100  loss/low_gen_loss: 1.1123 (1.1718)  loss/high_gen_loss: 149039090642050346909696.0000 (72006093767760519626752.0000)  loss/pix_loss: 0.1555 (0.1664)  loss/enc_loss: 0.0016 (0.0016)  time: 4.1698  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [100/862]  eta: 0:53:00  lr: 0.000100  loss/low_gen_loss: 1.1212 (1.1697)  loss/high_gen_loss: 115580723110408089501696.0000 (74302641016102608437248.0000)  loss/pix_loss: 0.1508 (0.1646)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [110/862]  eta: 0:52:18  lr: 0.000100  loss/low_gen_loss: 1.1754 (1.1718)  loss/high_gen_loss: 68703168920274314723328.0000 (70677954085804178407424.0000)  loss/pix_loss: 0.1643 (0.1653)  loss/enc_loss: 0.0008 (0.0015)  time: 4.1691  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [120/862]  eta: 0:51:36  lr: 0.000100  loss/low_gen_loss: 1.1631 (1.1684)  loss/high_gen_loss: 16388263525828995842048.0000 (66027960489184038223872.0000)  loss/pix_loss: 0.1745 (0.1658)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [130/862]  eta: 0:50:54  lr: 0.000100  loss/low_gen_loss: 1.1231 (1.1638)  loss/high_gen_loss: 7462753938828970426368.0000 (61326988809428185120768.0000)  loss/pix_loss: 0.1689 (0.1661)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1698  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [140/862]  eta: 0:50:12  lr: 0.000100  loss/low_gen_loss: 1.2052 (1.1690)  loss/high_gen_loss: 4577076981190952484864.0000 (57419214414163432439808.0000)  loss/pix_loss: 0.1644 (0.1656)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1681  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [150/862]  eta: 0:49:30  lr: 0.000100  loss/low_gen_loss: 1.2171 (1.1716)  loss/high_gen_loss: 8045704378195434799104.0000 (54413787878116611325952.0000)  loss/pix_loss: 0.1674 (0.1656)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [160/862]  eta: 0:48:49  lr: 0.000100  loss/low_gen_loss: 1.2107 (1.1770)  loss/high_gen_loss: 14357315734270369595392.0000 (52474747398929097162752.0000)  loss/pix_loss: 0.1665 (0.1654)  loss/enc_loss: 0.0005 (0.0012)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [170/862]  eta: 0:48:07  lr: 0.000100  loss/low_gen_loss: 1.2147 (1.1790)  loss/high_gen_loss: 26548933724331374018560.0000 (51069529659339488362496.0000)  loss/pix_loss: 0.1589 (0.1656)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [180/862]  eta: 0:47:25  lr: 0.000100  loss/low_gen_loss: 1.2033 (1.1805)  loss/high_gen_loss: 33793885703881359360000.0000 (51996611955886978498560.0000)  loss/pix_loss: 0.1702 (0.1663)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1691  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [190/862]  eta: 0:46:43  lr: 0.000100  loss/low_gen_loss: 1.1768 (1.1771)  loss/high_gen_loss: 137238542725632059506688.0000 (61320199421700887019520.0000)  loss/pix_loss: 0.1742 (0.1667)  loss/enc_loss: 0.0028 (0.0014)  time: 4.1682  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [200/862]  eta: 0:46:01  lr: 0.000100  loss/low_gen_loss: 1.1338 (1.1754)  loss/high_gen_loss: 324270306068954571866112.0000 (78780823254375686209536.0000)  loss/pix_loss: 0.1766 (0.1673)  loss/enc_loss: 0.0030 (0.0014)  time: 4.1691  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [210/862]  eta: 0:45:19  lr: 0.000100  loss/low_gen_loss: 1.1115 (1.1718)  loss/high_gen_loss: 391622431129814756753408.0000 (90775609848557171900416.0000)  loss/pix_loss: 0.1735 (0.1674)  loss/enc_loss: 0.0023 (0.0015)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [220/862]  eta: 0:44:38  lr: 0.000100  loss/low_gen_loss: 1.0759 (1.1666)  loss/high_gen_loss: 193684561777667501719552.0000 (93481955399742429069312.0000)  loss/pix_loss: 0.1620 (0.1668)  loss/enc_loss: 0.0019 (0.0015)  time: 4.1683  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [230/862]  eta: 0:43:56  lr: 0.000100  loss/low_gen_loss: 1.0939 (1.1650)  loss/high_gen_loss: 111853354907611917451264.0000 (93221189347744526893056.0000)  loss/pix_loss: 0.1534 (0.1663)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1681  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [240/862]  eta: 0:43:14  lr: 0.000100  loss/low_gen_loss: 1.1103 (1.1615)  loss/high_gen_loss: 125955044075232924008448.0000 (96286747799880818753536.0000)  loss/pix_loss: 0.1526 (0.1659)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [250/862]  eta: 0:42:32  lr: 0.000100  loss/low_gen_loss: 1.1190 (1.1601)  loss/high_gen_loss: 160162450296899442311168.0000 (98515910570624640090112.0000)  loss/pix_loss: 0.1545 (0.1662)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [260/862]  eta: 0:41:51  lr: 0.000100  loss/low_gen_loss: 1.1193 (1.1580)  loss/high_gen_loss: 201432248331821041844224.0000 (103608118514493941612544.0000)  loss/pix_loss: 0.1729 (0.1662)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1700  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:29]  [270/862]  eta: 0:41:09  lr: 0.000100  loss/low_gen_loss: 1.0789 (1.1526)  loss/high_gen_loss: 257833960970722413117440.0000 (111497756311572937965568.0000)  loss/pix_loss: 0.1620 (0.1661)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [280/862]  eta: 0:40:27  lr: 0.000100  loss/low_gen_loss: 0.9914 (1.1477)  loss/high_gen_loss: 343916989227380718436352.0000 (120020513763926395060224.0000)  loss/pix_loss: 0.1675 (0.1662)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [290/862]  eta: 0:39:45  lr: 0.000100  loss/low_gen_loss: 1.0819 (1.1471)  loss/high_gen_loss: 358072631518537623535616.0000 (132718149698543069167616.0000)  loss/pix_loss: 0.1736 (0.1662)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1696  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [300/862]  eta: 0:39:04  lr: 0.000100  loss/low_gen_loss: 1.0793 (1.1425)  loss/high_gen_loss: 536334147997913615171584.0000 (146495458811562462019584.0000)  loss/pix_loss: 0.1609 (0.1658)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [310/862]  eta: 0:38:22  lr: 0.000100  loss/low_gen_loss: 1.0218 (1.1404)  loss/high_gen_loss: 502408928321698877407232.0000 (157299517180791735975936.0000)  loss/pix_loss: 0.1484 (0.1653)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [320/862]  eta: 0:37:40  lr: 0.000100  loss/low_gen_loss: 1.0330 (1.1369)  loss/high_gen_loss: 478801743622166097690624.0000 (168260317295967935135744.0000)  loss/pix_loss: 0.1544 (0.1651)  loss/enc_loss: 0.0020 (0.0014)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [330/862]  eta: 0:36:58  lr: 0.000100  loss/low_gen_loss: 1.0283 (1.1335)  loss/high_gen_loss: 651115806433636612308992.0000 (190601551449786461192192.0000)  loss/pix_loss: 0.1673 (0.1652)  loss/enc_loss: 0.0021 (0.0014)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [340/862]  eta: 0:36:17  lr: 0.000100  loss/low_gen_loss: 0.9986 (1.1288)  loss/high_gen_loss: 929682538648921840812032.0000 (211734575397671215824896.0000)  loss/pix_loss: 0.1704 (0.1651)  loss/enc_loss: 0.0052 (0.0016)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [350/862]  eta: 0:35:35  lr: 0.000100  loss/low_gen_loss: 0.9773 (1.1271)  loss/high_gen_loss: 922311767354782192238592.0000 (232386706785616506388480.0000)  loss/pix_loss: 0.1718 (0.1653)  loss/enc_loss: 0.0036 (0.0016)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [360/862]  eta: 0:34:53  lr: 0.000100  loss/low_gen_loss: 1.0609 (1.1265)  loss/high_gen_loss: 1442077964957134169833472.0000 (269382579380472894193664.0000)  loss/pix_loss: 0.1707 (0.1653)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [370/862]  eta: 0:34:11  lr: 0.000100  loss/low_gen_loss: 1.1116 (1.1269)  loss/high_gen_loss: 1685477997208525200162816.0000 (315549208102261063942144.0000)  loss/pix_loss: 0.1723 (0.1656)  loss/enc_loss: 0.0005 (0.0016)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [380/862]  eta: 0:33:30  lr: 0.000100  loss/low_gen_loss: 1.1455 (1.1276)  loss/high_gen_loss: 1843407923098144540196864.0000 (351247627004467218481152.0000)  loss/pix_loss: 0.1660 (0.1655)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [390/862]  eta: 0:32:48  lr: 0.000100  loss/low_gen_loss: 1.0084 (1.1237)  loss/high_gen_loss: 1291318634365417114566656.0000 (366850814701911305879552.0000)  loss/pix_loss: 0.1618 (0.1657)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [400/862]  eta: 0:32:06  lr: 0.000100  loss/low_gen_loss: 0.9864 (1.1222)  loss/high_gen_loss: 805027296476542825136128.0000 (376440553308690109693952.0000)  loss/pix_loss: 0.1793 (0.1659)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1703  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [410/862]  eta: 0:31:25  lr: 0.000100  loss/low_gen_loss: 1.1050 (1.1225)  loss/high_gen_loss: 709492257437147398668288.0000 (384073399788623894675456.0000)  loss/pix_loss: 0.1650 (0.1659)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [420/862]  eta: 0:30:43  lr: 0.000100  loss/low_gen_loss: 1.0658 (1.1209)  loss/high_gen_loss: 657157475405746680102912.0000 (386181325841589061287936.0000)  loss/pix_loss: 0.1710 (0.1661)  loss/enc_loss: 0.0003 (0.0014)  time: 4.1684  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [430/862]  eta: 0:30:01  lr: 0.000100  loss/low_gen_loss: 1.0249 (1.1178)  loss/high_gen_loss: 379872287500425999941632.0000 (385915925525837572472832.0000)  loss/pix_loss: 0.1721 (0.1662)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [440/862]  eta: 0:29:20  lr: 0.000100  loss/low_gen_loss: 1.0014 (1.1166)  loss/high_gen_loss: 341773347862346400268288.0000 (384300405335776059981824.0000)  loss/pix_loss: 0.1748 (0.1663)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [450/862]  eta: 0:28:38  lr: 0.000100  loss/low_gen_loss: 1.0613 (1.1153)  loss/high_gen_loss: 342225941610498625634304.0000 (386233212124676799594496.0000)  loss/pix_loss: 0.1818 (0.1668)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [460/862]  eta: 0:27:56  lr: 0.000100  loss/low_gen_loss: 0.9643 (1.1119)  loss/high_gen_loss: 506800694563122509250560.0000 (390123723136525511163904.0000)  loss/pix_loss: 0.1692 (0.1666)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [470/862]  eta: 0:27:14  lr: 0.000100  loss/low_gen_loss: 0.9635 (1.1094)  loss/high_gen_loss: 477208622275581548953600.0000 (391519050902957803438080.0000)  loss/pix_loss: 0.1592 (0.1666)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [480/862]  eta: 0:26:33  lr: 0.000100  loss/low_gen_loss: 0.9725 (1.1068)  loss/high_gen_loss: 474584392787111270416384.0000 (395253474872035291168768.0000)  loss/pix_loss: 0.1535 (0.1663)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [490/862]  eta: 0:25:51  lr: 0.000100  loss/low_gen_loss: 0.9898 (1.1046)  loss/high_gen_loss: 616913309135563927846912.0000 (400599039081581306183680.0000)  loss/pix_loss: 0.1563 (0.1663)  loss/enc_loss: 0.0017 (0.0015)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [500/862]  eta: 0:25:09  lr: 0.000100  loss/low_gen_loss: 0.9699 (1.1018)  loss/high_gen_loss: 592319259656884706082816.0000 (404171352397393371856896.0000)  loss/pix_loss: 0.1700 (0.1664)  loss/enc_loss: 0.0025 (0.0015)  time: 4.1691  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [510/862]  eta: 0:24:28  lr: 0.000100  loss/low_gen_loss: 0.9628 (1.0994)  loss/high_gen_loss: 598870231703654848528384.0000 (409346500575252845690880.0000)  loss/pix_loss: 0.1699 (0.1665)  loss/enc_loss: 0.0023 (0.0015)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [520/862]  eta: 0:23:46  lr: 0.000100  loss/low_gen_loss: 1.0118 (1.0980)  loss/high_gen_loss: 554149919749430050816000.0000 (411425935961803552980992.0000)  loss/pix_loss: 0.1717 (0.1666)  loss/enc_loss: 0.0020 (0.0015)  time: 4.1690  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [530/862]  eta: 0:23:04  lr: 0.000100  loss/low_gen_loss: 1.0041 (1.0960)  loss/high_gen_loss: 584536751270412337283072.0000 (417983748271899689353216.0000)  loss/pix_loss: 0.1717 (0.1665)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1691  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [540/862]  eta: 0:22:22  lr: 0.000100  loss/low_gen_loss: 0.9996 (1.0943)  loss/high_gen_loss: 960065839347796268810240.0000 (431464682057521197744128.0000)  loss/pix_loss: 0.1644 (0.1666)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1694  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [550/862]  eta: 0:21:41  lr: 0.000100  loss/low_gen_loss: 0.9988 (1.0923)  loss/high_gen_loss: 1005924084827068024487936.0000 (440521354403109792645120.0000)  loss/pix_loss: 0.1659 (0.1665)  loss/enc_loss: 0.0003 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:29]  [560/862]  eta: 0:20:59  lr: 0.000100  loss/low_gen_loss: 0.9974 (1.0915)  loss/high_gen_loss: 863551465547831363764224.0000 (444126012834233542770688.0000)  loss/pix_loss: 0.1680 (0.1666)  loss/enc_loss: 0.0003 (0.0014)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [570/862]  eta: 0:20:17  lr: 0.000100  loss/low_gen_loss: 1.0370 (1.0903)  loss/high_gen_loss: 487338622960621534052352.0000 (444256013799702382247936.0000)  loss/pix_loss: 0.1664 (0.1666)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [580/862]  eta: 0:19:36  lr: 0.000100  loss/low_gen_loss: 0.9727 (1.0881)  loss/high_gen_loss: 592746669275920675635200.0000 (450866092059261742874624.0000)  loss/pix_loss: 0.1586 (0.1664)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1698  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [590/862]  eta: 0:18:54  lr: 0.000100  loss/low_gen_loss: 0.9839 (1.0870)  loss/high_gen_loss: 757658435595859948208128.0000 (455923167340141521928192.0000)  loss/pix_loss: 0.1458 (0.1661)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [600/862]  eta: 0:18:12  lr: 0.000100  loss/low_gen_loss: 1.0776 (1.0877)  loss/high_gen_loss: 737585063394338211364864.0000 (459129449690215699447808.0000)  loss/pix_loss: 0.1588 (0.1663)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1689  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [610/862]  eta: 0:17:30  lr: 0.000100  loss/low_gen_loss: 1.1722 (1.0895)  loss/high_gen_loss: 619012490965076844478464.0000 (461436530440011155243008.0000)  loss/pix_loss: 0.1769 (0.1665)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1689  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [620/862]  eta: 0:16:49  lr: 0.000100  loss/low_gen_loss: 1.1126 (1.0886)  loss/high_gen_loss: 851023316075615099027456.0000 (470994796635886463221760.0000)  loss/pix_loss: 0.1809 (0.1667)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [630/862]  eta: 0:16:07  lr: 0.000100  loss/low_gen_loss: 1.0041 (1.0872)  loss/high_gen_loss: 984179192616648473313280.0000 (477626924094600226275328.0000)  loss/pix_loss: 0.1666 (0.1666)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [640/862]  eta: 0:15:25  lr: 0.000100  loss/low_gen_loss: 1.0458 (1.0890)  loss/high_gen_loss: 984179192616648473313280.0000 (486760713811420766011392.0000)  loss/pix_loss: 0.1596 (0.1666)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 1.1443 (1.0892)  loss/high_gen_loss: 1143100991288199891386368.0000 (499045297215574328213504.0000)  loss/pix_loss: 0.1663 (0.1667)  loss/enc_loss: 0.0024 (0.0014)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [660/862]  eta: 0:14:02  lr: 0.000100  loss/low_gen_loss: 1.0913 (1.0893)  loss/high_gen_loss: 1367319219949100467224576.0000 (514168731816718604697600.0000)  loss/pix_loss: 0.1639 (0.1666)  loss/enc_loss: 0.0022 (0.0014)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [670/862]  eta: 0:13:20  lr: 0.000100  loss/low_gen_loss: 1.0913 (1.0895)  loss/high_gen_loss: 1374207493593562150338560.0000 (525793338813200837115904.0000)  loss/pix_loss: 0.1635 (0.1666)  loss/enc_loss: 0.0024 (0.0015)  time: 4.1691  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.1344 (1.0912)  loss/high_gen_loss: 978866458265826084519936.0000 (529035804484525415727104.0000)  loss/pix_loss: 0.1702 (0.1666)  loss/enc_loss: 0.0016 (0.0014)  time: 4.1696  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.1348 (1.0913)  loss/high_gen_loss: 978866458265826084519936.0000 (541248618936842087038976.0000)  loss/pix_loss: 0.1747 (0.1667)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [700/862]  eta: 0:11:15  lr: 0.000100  loss/low_gen_loss: 1.1021 (1.0916)  loss/high_gen_loss: 1250553059344775915765760.0000 (546486463465392521084928.0000)  loss/pix_loss: 0.1664 (0.1666)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [710/862]  eta: 0:10:33  lr: 0.000100  loss/low_gen_loss: 1.1277 (1.0925)  loss/high_gen_loss: 581329539817378202779648.0000 (546497069431300282122240.0000)  loss/pix_loss: 0.1646 (0.1666)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.1541 (1.0932)  loss/high_gen_loss: 931742809377654276358144.0000 (556664604360242274238464.0000)  loss/pix_loss: 0.1657 (0.1666)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 1.0640 (1.0922)  loss/high_gen_loss: 1280841316077114316816384.0000 (564801872431248463364096.0000)  loss/pix_loss: 0.1691 (0.1668)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [740/862]  eta: 0:08:28  lr: 0.000100  loss/low_gen_loss: 1.1007 (1.0927)  loss/high_gen_loss: 779728523728172668157952.0000 (566353842824546286043136.0000)  loss/pix_loss: 0.1772 (0.1669)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.1458 (1.0936)  loss/high_gen_loss: 696994011866456874024960.0000 (568432072536658922176512.0000)  loss/pix_loss: 0.1701 (0.1668)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.0978 (1.0929)  loss/high_gen_loss: 707265101320623122022400.0000 (570103840168193053163520.0000)  loss/pix_loss: 0.1665 (0.1668)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [770/862]  eta: 0:06:23  lr: 0.000100  loss/low_gen_loss: 1.0150 (1.0917)  loss/high_gen_loss: 988427059842778363068416.0000 (581589401843144541077504.0000)  loss/pix_loss: 0.1679 (0.1668)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1769  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [780/862]  eta: 0:05:41  lr: 0.000100  loss/low_gen_loss: 0.9943 (1.0903)  loss/high_gen_loss: 1391123590254718036738048.0000 (591078818073498263486464.0000)  loss/pix_loss: 0.1599 (0.1667)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1696  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 0.9846 (1.0892)  loss/high_gen_loss: 1463834458440193827405824.0000 (605946693005901066928128.0000)  loss/pix_loss: 0.1602 (0.1667)  loss/enc_loss: 0.0029 (0.0014)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 0.9623 (1.0877)  loss/high_gen_loss: 1979231155597679892889600.0000 (626379584537743039922176.0000)  loss/pix_loss: 0.1789 (0.1668)  loss/enc_loss: 0.0024 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [810/862]  eta: 0:03:36  lr: 0.000100  loss/low_gen_loss: 0.9621 (1.0861)  loss/high_gen_loss: 1649357110584380760260608.0000 (637771663265801091153920.0000)  loss/pix_loss: 0.1788 (0.1668)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 0.9699 (1.0862)  loss/high_gen_loss: 1649357110584380760260608.0000 (657876885614938569048064.0000)  loss/pix_loss: 0.1755 (0.1670)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1683  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.1280 (1.0870)  loss/high_gen_loss: 2402907038340980171341824.0000 (680933026840323964272640.0000)  loss/pix_loss: 0.1713 (0.1670)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1677  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.0361 (1.0859)  loss/high_gen_loss: 3589111801518757985124352.0000 (722385479131152663969792.0000)  loss/pix_loss: 0.1625 (0.1670)  loss/enc_loss: 0.0030 (0.0015)  time: 4.1687  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:29]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.0135 (1.0857)  loss/high_gen_loss: 4048184680296497679433728.0000 (760310694180263531905024.0000)  loss/pix_loss: 0.1630 (0.1669)  loss/enc_loss: 0.0027 (0.0015)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.0925 (1.0862)  loss/high_gen_loss: 3434803922651049130721280.0000 (785224407397261796966400.0000)  loss/pix_loss: 0.1665 (0.1669)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1681  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.0925 (1.0862)  loss/high_gen_loss: 3366311738366117868994560.0000 (786354293735230105714688.0000)  loss/pix_loss: 0.1693 (0.1670)  loss/enc_loss: 0.0012 (0.0015)  time: 4.1681  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:29] Total time: 0:59:55 (4.1707 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.0925 (1.0862)  loss/high_gen_loss: 3366311738366117868994560.0000 (786354293735230105714688.0000)  loss/pix_loss: 0.1693 (0.1670)  loss/enc_loss: 0.0012 (0.0015)\n",
      "Valid: [epoch:29]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1605 (0.1605)  time: 3.0032  data: 0.3577  max mem: 31350\n",
      "Valid: [epoch:29]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6333  data: 0.0256  max mem: 31350\n",
      "Valid: [epoch:29] Total time: 0:00:36 (2.6426 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_29_input_n_20.png\n",
      "Train: [epoch:30]  [  0/862]  eta: 1:14:05  lr: 0.000100  loss/low_gen_loss: 1.0702 (1.0702)  loss/high_gen_loss: 1606345788587953499406336.0000 (1606345788587953499406336.0000)  loss/pix_loss: 0.1516 (0.1516)  loss/enc_loss: 0.0005 (0.0005)  time: 5.1568  data: 0.9273  max mem: 31350\n",
      "Train: [epoch:30]  [ 10/862]  eta: 1:00:28  lr: 0.000100  loss/low_gen_loss: 1.1938 (1.1641)  loss/high_gen_loss: 918879375920379532935168.0000 (1029267057256680019460096.0000)  loss/pix_loss: 0.1710 (0.1695)  loss/enc_loss: 0.0005 (0.0005)  time: 4.2582  data: 0.0844  max mem: 31350\n",
      "Train: [epoch:30]  [ 20/862]  eta: 0:59:10  lr: 0.000100  loss/low_gen_loss: 1.1149 (1.1029)  loss/high_gen_loss: 849296311719308080185344.0000 (1008243756031709003382784.0000)  loss/pix_loss: 0.1713 (0.1703)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1694  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [ 30/862]  eta: 0:58:15  lr: 0.000100  loss/low_gen_loss: 1.0806 (1.1299)  loss/high_gen_loss: 1530739646274033764270080.0000 (1764091584080420647469056.0000)  loss/pix_loss: 0.1775 (0.1713)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [ 40/862]  eta: 0:57:27  lr: 0.000100  loss/low_gen_loss: 1.2883 (1.1806)  loss/high_gen_loss: 5020525819019031123853312.0000 (2886646460052005699190784.0000)  loss/pix_loss: 0.1780 (0.1707)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [ 50/862]  eta: 0:56:41  lr: 0.000100  loss/low_gen_loss: 1.2434 (1.1852)  loss/high_gen_loss: 5514103620817020686172160.0000 (3348180331039964075655168.0000)  loss/pix_loss: 0.1681 (0.1697)  loss/enc_loss: 0.0006 (0.0005)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [ 60/862]  eta: 0:55:56  lr: 0.000100  loss/low_gen_loss: 1.1815 (1.1735)  loss/high_gen_loss: 5604717486471595824250880.0000 (3782054931702978290122752.0000)  loss/pix_loss: 0.1686 (0.1708)  loss/enc_loss: 0.0006 (0.0005)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [ 70/862]  eta: 0:55:13  lr: 0.000100  loss/low_gen_loss: 1.1080 (1.1625)  loss/high_gen_loss: 5577742582028309425553408.0000 (4012197706114050996305920.0000)  loss/pix_loss: 0.1692 (0.1702)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [ 80/862]  eta: 0:54:30  lr: 0.000100  loss/low_gen_loss: 1.0604 (1.1495)  loss/high_gen_loss: 5039888559228150815391744.0000 (4031462903395263558189056.0000)  loss/pix_loss: 0.1634 (0.1695)  loss/enc_loss: 0.0011 (0.0007)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [ 90/862]  eta: 0:53:47  lr: 0.000100  loss/low_gen_loss: 1.1180 (1.1555)  loss/high_gen_loss: 5180657392636885314043904.0000 (4248087457100678993805312.0000)  loss/pix_loss: 0.1634 (0.1689)  loss/enc_loss: 0.0014 (0.0008)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [100/862]  eta: 0:53:04  lr: 0.000100  loss/low_gen_loss: 1.1629 (1.1508)  loss/high_gen_loss: 5181303605140217451773952.0000 (4314183522919734069690368.0000)  loss/pix_loss: 0.1593 (0.1673)  loss/enc_loss: 0.0015 (0.0009)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [110/862]  eta: 0:52:22  lr: 0.000100  loss/low_gen_loss: 1.0364 (1.1401)  loss/high_gen_loss: 4893051323479918177681408.0000 (4385429562169855471255552.0000)  loss/pix_loss: 0.1667 (0.1684)  loss/enc_loss: 0.0017 (0.0010)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [120/862]  eta: 0:51:40  lr: 0.000100  loss/low_gen_loss: 1.0496 (1.1372)  loss/high_gen_loss: 5268520387581468515237888.0000 (4495782334222656845381632.0000)  loss/pix_loss: 0.1868 (0.1697)  loss/enc_loss: 0.0024 (0.0012)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [130/862]  eta: 0:50:57  lr: 0.000100  loss/low_gen_loss: 1.0883 (1.1326)  loss/high_gen_loss: 4808193130206716571418624.0000 (4485742169750770550833152.0000)  loss/pix_loss: 0.1815 (0.1697)  loss/enc_loss: 0.0033 (0.0013)  time: 4.1683  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [140/862]  eta: 0:50:15  lr: 0.000100  loss/low_gen_loss: 1.0929 (1.1314)  loss/high_gen_loss: 3854458703416656878632960.0000 (4407310939488198001164288.0000)  loss/pix_loss: 0.1730 (0.1695)  loss/enc_loss: 0.0015 (0.0012)  time: 4.1677  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [150/862]  eta: 0:49:33  lr: 0.000100  loss/low_gen_loss: 1.1013 (1.1281)  loss/high_gen_loss: 5084577526128969114451968.0000 (4600129786555581167828992.0000)  loss/pix_loss: 0.1682 (0.1686)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [160/862]  eta: 0:48:51  lr: 0.000100  loss/low_gen_loss: 1.0877 (1.1263)  loss/high_gen_loss: 7684863429021948805382144.0000 (4844810707141188760109056.0000)  loss/pix_loss: 0.1589 (0.1683)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [170/862]  eta: 0:48:09  lr: 0.000100  loss/low_gen_loss: 1.0909 (1.1241)  loss/high_gen_loss: 5222566665790096505044992.0000 (4800638710231519645925376.0000)  loss/pix_loss: 0.1607 (0.1682)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [180/862]  eta: 0:47:27  lr: 0.000100  loss/low_gen_loss: 1.0632 (1.1200)  loss/high_gen_loss: 4865354690174747892776960.0000 (4903148596083476207239168.0000)  loss/pix_loss: 0.1601 (0.1685)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [190/862]  eta: 0:46:45  lr: 0.000100  loss/low_gen_loss: 1.1412 (1.1251)  loss/high_gen_loss: 8679673278487012787093504.0000 (5157367326806577774592000.0000)  loss/pix_loss: 0.1729 (0.1687)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [200/862]  eta: 0:46:03  lr: 0.000100  loss/low_gen_loss: 1.2148 (1.1292)  loss/high_gen_loss: 9525762018465316543135744.0000 (5313210701349852563898368.0000)  loss/pix_loss: 0.1750 (0.1695)  loss/enc_loss: 0.0020 (0.0013)  time: 4.1694  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [210/862]  eta: 0:45:21  lr: 0.000100  loss/low_gen_loss: 1.1521 (1.1291)  loss/high_gen_loss: 8029430738035521823440896.0000 (5448020317461210321649664.0000)  loss/pix_loss: 0.1748 (0.1688)  loss/enc_loss: 0.0019 (0.0013)  time: 4.1685  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [220/862]  eta: 0:44:40  lr: 0.000100  loss/low_gen_loss: 1.1426 (1.1296)  loss/high_gen_loss: 8196904115794712415174656.0000 (5616772336234079407046656.0000)  loss/pix_loss: 0.1539 (0.1684)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [230/862]  eta: 0:43:58  lr: 0.000100  loss/low_gen_loss: 1.1140 (1.1278)  loss/high_gen_loss: 9406416195994434171568128.0000 (5860944901859545532334080.0000)  loss/pix_loss: 0.1529 (0.1674)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1746  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:30]  [240/862]  eta: 0:43:16  lr: 0.000100  loss/low_gen_loss: 1.0462 (1.1229)  loss/high_gen_loss: 10791948261066997076328448.0000 (6068485810596481215758336.0000)  loss/pix_loss: 0.1516 (0.1672)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [250/862]  eta: 0:42:34  lr: 0.000100  loss/low_gen_loss: 1.0756 (1.1254)  loss/high_gen_loss: 6006993128476759960846336.0000 (6011953006263286481551360.0000)  loss/pix_loss: 0.1749 (0.1675)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [260/862]  eta: 0:41:53  lr: 0.000100  loss/low_gen_loss: 1.2209 (1.1298)  loss/high_gen_loss: 5273648582433959770587136.0000 (6070930864492127604178944.0000)  loss/pix_loss: 0.1749 (0.1673)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [270/862]  eta: 0:41:11  lr: 0.000100  loss/low_gen_loss: 1.2540 (1.1341)  loss/high_gen_loss: 10781162680391400022867968.0000 (6317258153453381587304448.0000)  loss/pix_loss: 0.1818 (0.1682)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [280/862]  eta: 0:40:29  lr: 0.000100  loss/low_gen_loss: 1.0757 (1.1299)  loss/high_gen_loss: 12170534550535056031481856.0000 (6518363920928159580553216.0000)  loss/pix_loss: 0.1904 (0.1684)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [290/862]  eta: 0:39:47  lr: 0.000100  loss/low_gen_loss: 1.0757 (1.1317)  loss/high_gen_loss: 12502853797944438210691072.0000 (6741369725724494001078272.0000)  loss/pix_loss: 0.1757 (0.1682)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [300/862]  eta: 0:39:05  lr: 0.000100  loss/low_gen_loss: 1.1809 (1.1332)  loss/high_gen_loss: 12868041684528656990339072.0000 (6942995229201624186486784.0000)  loss/pix_loss: 0.1482 (0.1673)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [310/862]  eta: 0:38:24  lr: 0.000100  loss/low_gen_loss: 1.1561 (1.1314)  loss/high_gen_loss: 12994808862724693635891200.0000 (7162917170849035354898432.0000)  loss/pix_loss: 0.1418 (0.1666)  loss/enc_loss: 0.0015 (0.0012)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [320/862]  eta: 0:37:42  lr: 0.000100  loss/low_gen_loss: 1.0764 (1.1298)  loss/high_gen_loss: 11039754903424183551655936.0000 (7193835532446877836378112.0000)  loss/pix_loss: 0.1546 (0.1666)  loss/enc_loss: 0.0016 (0.0012)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [330/862]  eta: 0:37:00  lr: 0.000100  loss/low_gen_loss: 1.1030 (1.1310)  loss/high_gen_loss: 8981309825894292947730432.0000 (7320289116334109518462976.0000)  loss/pix_loss: 0.1614 (0.1661)  loss/enc_loss: 0.0018 (0.0013)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [340/862]  eta: 0:36:18  lr: 0.000100  loss/low_gen_loss: 1.2131 (1.1342)  loss/high_gen_loss: 14634203290357390479720448.0000 (7581207404466437554700288.0000)  loss/pix_loss: 0.1614 (0.1662)  loss/enc_loss: 0.0030 (0.0013)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [350/862]  eta: 0:35:37  lr: 0.000100  loss/low_gen_loss: 1.1719 (1.1339)  loss/high_gen_loss: 14686970201780236652118016.0000 (7731971447160398896168960.0000)  loss/pix_loss: 0.1615 (0.1659)  loss/enc_loss: 0.0032 (0.0014)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [360/862]  eta: 0:34:55  lr: 0.000100  loss/low_gen_loss: 1.1395 (1.1353)  loss/high_gen_loss: 14978729670657549954711552.0000 (7969282246879035697135616.0000)  loss/pix_loss: 0.1617 (0.1659)  loss/enc_loss: 0.0019 (0.0014)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [370/862]  eta: 0:34:13  lr: 0.000100  loss/low_gen_loss: 1.1746 (1.1367)  loss/high_gen_loss: 16061520113060667036008448.0000 (8200193542437614156513280.0000)  loss/pix_loss: 0.1644 (0.1658)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [380/862]  eta: 0:33:31  lr: 0.000100  loss/low_gen_loss: 1.2191 (1.1396)  loss/high_gen_loss: 18641155462423881187328000.0000 (8784996250032279952293888.0000)  loss/pix_loss: 0.1644 (0.1657)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [390/862]  eta: 0:32:49  lr: 0.000100  loss/low_gen_loss: 1.0835 (1.1378)  loss/high_gen_loss: 36992256626875762598739968.0000 (9707680851210237066084352.0000)  loss/pix_loss: 0.1655 (0.1656)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [400/862]  eta: 0:32:08  lr: 0.000100  loss/low_gen_loss: 1.0781 (1.1367)  loss/high_gen_loss: 38751273578140447457411072.0000 (10235255761259251917389824.0000)  loss/pix_loss: 0.1708 (0.1657)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [410/862]  eta: 0:31:26  lr: 0.000100  loss/low_gen_loss: 1.1048 (1.1367)  loss/high_gen_loss: 23307184435970912823541760.0000 (10499800483633478837993472.0000)  loss/pix_loss: 0.1692 (0.1657)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [420/862]  eta: 0:30:44  lr: 0.000100  loss/low_gen_loss: 1.1400 (1.1367)  loss/high_gen_loss: 18259108404677796484349952.0000 (10688270049122942676107264.0000)  loss/pix_loss: 0.1569 (0.1657)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [430/862]  eta: 0:30:02  lr: 0.000100  loss/low_gen_loss: 1.1071 (1.1354)  loss/high_gen_loss: 17528686514649174651174912.0000 (10836425593476630215393280.0000)  loss/pix_loss: 0.1569 (0.1656)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [440/862]  eta: 0:29:21  lr: 0.000100  loss/low_gen_loss: 1.0864 (1.1346)  loss/high_gen_loss: 11385964549121069023232000.0000 (10802767067482864385785856.0000)  loss/pix_loss: 0.1661 (0.1656)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [450/862]  eta: 0:28:39  lr: 0.000100  loss/low_gen_loss: 1.0478 (1.1324)  loss/high_gen_loss: 13499451828663147412062208.0000 (10876813151542347546230784.0000)  loss/pix_loss: 0.1661 (0.1656)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [460/862]  eta: 0:27:57  lr: 0.000100  loss/low_gen_loss: 1.0470 (1.1310)  loss/high_gen_loss: 14716252102154241351614464.0000 (11011514496473267492093952.0000)  loss/pix_loss: 0.1616 (0.1655)  loss/enc_loss: 0.0023 (0.0013)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [470/862]  eta: 0:27:15  lr: 0.000100  loss/low_gen_loss: 1.1083 (1.1310)  loss/high_gen_loss: 16695527789345036683968512.0000 (11122763303447044066115584.0000)  loss/pix_loss: 0.1566 (0.1654)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [480/862]  eta: 0:26:34  lr: 0.000100  loss/low_gen_loss: 1.1059 (1.1296)  loss/high_gen_loss: 16399223503896563190595584.0000 (11251662755792646886653952.0000)  loss/pix_loss: 0.1574 (0.1653)  loss/enc_loss: 0.0021 (0.0013)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [490/862]  eta: 0:25:52  lr: 0.000100  loss/low_gen_loss: 1.0862 (1.1290)  loss/high_gen_loss: 23226664398089170630737920.0000 (11632224755234226260934656.0000)  loss/pix_loss: 0.1562 (0.1651)  loss/enc_loss: 0.0019 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [500/862]  eta: 0:25:10  lr: 0.000100  loss/low_gen_loss: 1.1231 (1.1306)  loss/high_gen_loss: 26694246455576944724410368.0000 (11839066170846103776264192.0000)  loss/pix_loss: 0.1562 (0.1650)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [510/862]  eta: 0:24:28  lr: 0.000100  loss/low_gen_loss: 1.2199 (1.1319)  loss/high_gen_loss: 21112762066805433776996352.0000 (12028789229980338326863872.0000)  loss/pix_loss: 0.1699 (0.1653)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1753  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 1.0918 (1.1296)  loss/high_gen_loss: 25702982992660051403997184.0000 (12342095420211186066522112.0000)  loss/pix_loss: 0.1705 (0.1654)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1747  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:30]  [530/862]  eta: 0:23:05  lr: 0.000100  loss/low_gen_loss: 1.0019 (1.1271)  loss/high_gen_loss: 29841320946470033786142720.0000 (12788880682860543119196160.0000)  loss/pix_loss: 0.1592 (0.1652)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [540/862]  eta: 0:22:23  lr: 0.000100  loss/low_gen_loss: 1.0051 (1.1257)  loss/high_gen_loss: 38799046033605336768708608.0000 (13318430900917372071182336.0000)  loss/pix_loss: 0.1598 (0.1655)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.0982 (1.1261)  loss/high_gen_loss: 31143714112463140045193216.0000 (13572565191344843019780096.0000)  loss/pix_loss: 0.1798 (0.1657)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 1.1046 (1.1252)  loss/high_gen_loss: 29682033311393551807938560.0000 (14072509643876512171032576.0000)  loss/pix_loss: 0.1711 (0.1656)  loss/enc_loss: 0.0020 (0.0013)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [570/862]  eta: 0:20:18  lr: 0.000100  loss/low_gen_loss: 1.0988 (1.1273)  loss/high_gen_loss: 55862570226319814511558656.0000 (14985919519466949481332736.0000)  loss/pix_loss: 0.1736 (0.1658)  loss/enc_loss: 0.0018 (0.0013)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [580/862]  eta: 0:19:36  lr: 0.000100  loss/low_gen_loss: 1.2080 (1.1285)  loss/high_gen_loss: 65148375268492060297003008.0000 (15876751113028851367673856.0000)  loss/pix_loss: 0.1773 (0.1659)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.0915 (1.1263)  loss/high_gen_loss: 53218750583873632582238208.0000 (16436844748993017742884864.0000)  loss/pix_loss: 0.1678 (0.1658)  loss/enc_loss: 0.0017 (0.0013)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 1.0348 (1.1255)  loss/high_gen_loss: 53218750583873632582238208.0000 (17099583589272506643513344.0000)  loss/pix_loss: 0.1669 (0.1658)  loss/enc_loss: 0.0023 (0.0014)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [610/862]  eta: 0:17:31  lr: 0.000100  loss/low_gen_loss: 1.0655 (1.1244)  loss/high_gen_loss: 56182492108790159265234944.0000 (17743724899484977518870528.0000)  loss/pix_loss: 0.1759 (0.1660)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [620/862]  eta: 0:16:49  lr: 0.000100  loss/low_gen_loss: 1.0335 (1.1224)  loss/high_gen_loss: 70728206367825965025853440.0000 (18721860628796461461536768.0000)  loss/pix_loss: 0.1717 (0.1659)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 0.9755 (1.1199)  loss/high_gen_loss: 70142789721274755550543872.0000 (19192672533351859243450368.0000)  loss/pix_loss: 0.1665 (0.1660)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 0.9857 (1.1191)  loss/high_gen_loss: 26487234787738766922481664.0000 (19178596752028211590725632.0000)  loss/pix_loss: 0.1700 (0.1660)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1761  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 1.0012 (1.1167)  loss/high_gen_loss: 17820828753466017426964480.0000 (19215785483519722860314624.0000)  loss/pix_loss: 0.1700 (0.1662)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [660/862]  eta: 0:14:02  lr: 0.000100  loss/low_gen_loss: 0.9623 (1.1151)  loss/high_gen_loss: 30391963174599291542962176.0000 (19499702407170360403296256.0000)  loss/pix_loss: 0.1676 (0.1663)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.0818 (1.1151)  loss/high_gen_loss: 47305393128315022305394688.0000 (20324868311357809116577792.0000)  loss/pix_loss: 0.1656 (0.1663)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.0898 (1.1147)  loss/high_gen_loss: 96219489913810107188117504.0000 (21546244432058151163920384.0000)  loss/pix_loss: 0.1666 (0.1663)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.0260 (1.1130)  loss/high_gen_loss: 115423980117207462910623744.0000 (23156746726577032264679424.0000)  loss/pix_loss: 0.1731 (0.1664)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 0.9932 (1.1113)  loss/high_gen_loss: 135076431053690781384572928.0000 (25022574469195485224632320.0000)  loss/pix_loss: 0.1655 (0.1663)  loss/enc_loss: 0.0018 (0.0013)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.0420 (1.1110)  loss/high_gen_loss: 163765434626422382182531072.0000 (27357320988963594783686656.0000)  loss/pix_loss: 0.1590 (0.1663)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.0726 (1.1103)  loss/high_gen_loss: 163765434626422382182531072.0000 (29104771910372654820884480.0000)  loss/pix_loss: 0.1722 (0.1665)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 1.0544 (1.1096)  loss/high_gen_loss: 162156730969242319605202944.0000 (31363316812493945114198016.0000)  loss/pix_loss: 0.1662 (0.1664)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.0651 (1.1092)  loss/high_gen_loss: 173867406636763870224449536.0000 (33140626408755323964751872.0000)  loss/pix_loss: 0.1676 (0.1666)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.0586 (1.1080)  loss/high_gen_loss: 120376054680654976315817984.0000 (33819729743544031113117696.0000)  loss/pix_loss: 0.1732 (0.1667)  loss/enc_loss: 0.0017 (0.0013)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 0.9936 (1.1063)  loss/high_gen_loss: 75677527754720477280468992.0000 (34365555872086414908719104.0000)  loss/pix_loss: 0.1641 (0.1666)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [770/862]  eta: 0:06:23  lr: 0.000100  loss/low_gen_loss: 0.9611 (1.1044)  loss/high_gen_loss: 79549038167190269425876992.0000 (35089425892114373078417408.0000)  loss/pix_loss: 0.1592 (0.1665)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1765  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 0.9588 (1.1025)  loss/high_gen_loss: 82110940430891125663858688.0000 (35674761101563530867376128.0000)  loss/pix_loss: 0.1490 (0.1664)  loss/enc_loss: 0.0019 (0.0014)  time: 4.1765  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 0.9601 (1.1009)  loss/high_gen_loss: 91984689323552679133184000.0000 (36821965124257391363227648.0000)  loss/pix_loss: 0.1561 (0.1664)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 0.9769 (1.0994)  loss/high_gen_loss: 134694694131829435923431424.0000 (37903380824118870153363456.0000)  loss/pix_loss: 0.1778 (0.1665)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 0.9878 (1.0981)  loss/high_gen_loss: 97953677547551578990313472.0000 (38545913073107924728938496.0000)  loss/pix_loss: 0.1793 (0.1667)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:30]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 0.9890 (1.0967)  loss/high_gen_loss: 100343527029276946240372736.0000 (39456542383412776443838464.0000)  loss/pix_loss: 0.1682 (0.1668)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 0.9908 (1.0957)  loss/high_gen_loss: 111860650234605099389288448.0000 (40273438475558664884191232.0000)  loss/pix_loss: 0.1624 (0.1666)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 0.9961 (1.0944)  loss/high_gen_loss: 115940922449757062530334720.0000 (41461578044551847714226176.0000)  loss/pix_loss: 0.1532 (0.1664)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.0361 (1.0940)  loss/high_gen_loss: 144018425679817228546998272.0000 (42708903655877431114334208.0000)  loss/pix_loss: 0.1649 (0.1665)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.0288 (1.0926)  loss/high_gen_loss: 163178901951854713279348736.0000 (44728796335128553241706496.0000)  loss/pix_loss: 0.1717 (0.1666)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.0049 (1.0925)  loss/high_gen_loss: 163178901951854713279348736.0000 (45027475702370968291770368.0000)  loss/pix_loss: 0.1732 (0.1666)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:30] Total time: 0:59:57 (4.1733 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.0049 (1.0925)  loss/high_gen_loss: 163178901951854713279348736.0000 (45027475702370968291770368.0000)  loss/pix_loss: 0.1732 (0.1666)  loss/enc_loss: 0.0009 (0.0013)\n",
      "Valid: [epoch:30]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1605 (0.1605)  time: 3.0278  data: 0.4000  max mem: 31350\n",
      "Valid: [epoch:30]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6135  data: 0.0286  max mem: 31350\n",
      "Valid: [epoch:30] Total time: 0:00:36 (2.6219 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_30_input_n_20.png\n",
      "Train: [epoch:31]  [  0/862]  eta: 1:11:44  lr: 0.000100  loss/low_gen_loss: 0.9698 (0.9698)  loss/high_gen_loss: 292926861852645974712778752.0000 (292926861852645974712778752.0000)  loss/pix_loss: 0.1279 (0.1279)  loss/enc_loss: 0.0004 (0.0004)  time: 4.9932  data: 0.8404  max mem: 31350\n",
      "Train: [epoch:31]  [ 10/862]  eta: 0:59:54  lr: 0.000100  loss/low_gen_loss: 1.0091 (1.0064)  loss/high_gen_loss: 271612995687791968617758720.0000 (268691712279070353303535616.0000)  loss/pix_loss: 0.1688 (0.1689)  loss/enc_loss: 0.0005 (0.0005)  time: 4.2189  data: 0.0765  max mem: 31350\n",
      "Train: [epoch:31]  [ 20/862]  eta: 0:58:44  lr: 0.000100  loss/low_gen_loss: 0.9746 (0.9846)  loss/high_gen_loss: 214658175298123737845465088.0000 (234955152398085133887864832.0000)  loss/pix_loss: 0.1688 (0.1676)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1458  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [ 30/862]  eta: 0:57:58  lr: 0.000100  loss/low_gen_loss: 0.9593 (0.9780)  loss/high_gen_loss: 213707448555308821264728064.0000 (232882038669259612002189312.0000)  loss/pix_loss: 0.1572 (0.1670)  loss/enc_loss: 0.0007 (0.0007)  time: 4.1604  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [ 40/862]  eta: 0:57:15  lr: 0.000100  loss/low_gen_loss: 0.9739 (0.9842)  loss/high_gen_loss: 216171693755883459136454656.0000 (226936940945424518880428032.0000)  loss/pix_loss: 0.1770 (0.1708)  loss/enc_loss: 0.0011 (0.0009)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [ 50/862]  eta: 0:56:32  lr: 0.000100  loss/low_gen_loss: 0.9854 (0.9837)  loss/high_gen_loss: 229211143739266529887256576.0000 (230037796958039956401422336.0000)  loss/pix_loss: 0.1773 (0.1691)  loss/enc_loss: 0.0022 (0.0012)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [ 60/862]  eta: 0:55:50  lr: 0.000100  loss/low_gen_loss: 0.9741 (0.9823)  loss/high_gen_loss: 235437510159953862263308288.0000 (228744579918390700894322688.0000)  loss/pix_loss: 0.1656 (0.1692)  loss/enc_loss: 0.0028 (0.0016)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [ 70/862]  eta: 0:55:08  lr: 0.000100  loss/low_gen_loss: 0.9780 (0.9825)  loss/high_gen_loss: 237612897795078282266279936.0000 (237340021345515007310299136.0000)  loss/pix_loss: 0.1789 (0.1707)  loss/enc_loss: 0.0029 (0.0017)  time: 4.1756  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [ 80/862]  eta: 0:54:26  lr: 0.000100  loss/low_gen_loss: 0.9725 (0.9802)  loss/high_gen_loss: 368353181846570675319341056.0000 (263399599286078618787119104.0000)  loss/pix_loss: 0.1779 (0.1709)  loss/enc_loss: 0.0014 (0.0016)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [ 90/862]  eta: 0:53:44  lr: 0.000100  loss/low_gen_loss: 0.9660 (0.9787)  loss/high_gen_loss: 573366163411106121040003072.0000 (300842742656647868725592064.0000)  loss/pix_loss: 0.1709 (0.1709)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1767  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [100/862]  eta: 0:53:02  lr: 0.000100  loss/low_gen_loss: 0.9594 (0.9768)  loss/high_gen_loss: 628642680578204183096721408.0000 (347453207470190889646686208.0000)  loss/pix_loss: 0.1709 (0.1705)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1762  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [110/862]  eta: 0:52:20  lr: 0.000100  loss/low_gen_loss: 0.9699 (0.9804)  loss/high_gen_loss: 828676369408411356968779776.0000 (396915730495873717935013888.0000)  loss/pix_loss: 0.1639 (0.1702)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [120/862]  eta: 0:51:38  lr: 0.000100  loss/low_gen_loss: 0.9783 (0.9794)  loss/high_gen_loss: 877445354881650605663715328.0000 (435534121444006155304042496.0000)  loss/pix_loss: 0.1623 (0.1696)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [130/862]  eta: 0:50:56  lr: 0.000100  loss/low_gen_loss: 0.9580 (0.9782)  loss/high_gen_loss: 886865295423354830453735424.0000 (472033352775566327793319936.0000)  loss/pix_loss: 0.1619 (0.1699)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [140/862]  eta: 0:50:14  lr: 0.000100  loss/low_gen_loss: 0.9685 (0.9787)  loss/high_gen_loss: 945972869293169039609167872.0000 (510737877197688612526751744.0000)  loss/pix_loss: 0.1498 (0.1693)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [150/862]  eta: 0:49:32  lr: 0.000100  loss/low_gen_loss: 0.9753 (0.9785)  loss/high_gen_loss: 943169111767917777439948800.0000 (533656377617381705224552448.0000)  loss/pix_loss: 0.1584 (0.1691)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [160/862]  eta: 0:48:51  lr: 0.000100  loss/low_gen_loss: 0.9633 (0.9776)  loss/high_gen_loss: 764450340566976811107352576.0000 (545489003565731559080198144.0000)  loss/pix_loss: 0.1696 (0.1693)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [170/862]  eta: 0:48:09  lr: 0.000100  loss/low_gen_loss: 0.9596 (0.9765)  loss/high_gen_loss: 678427048632236700350808064.0000 (551150920613992068332650496.0000)  loss/pix_loss: 0.1713 (0.1692)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [180/862]  eta: 0:47:27  lr: 0.000100  loss/low_gen_loss: 0.9587 (0.9756)  loss/high_gen_loss: 618575001065095721111257088.0000 (554793699782664300779274240.0000)  loss/pix_loss: 0.1663 (0.1692)  loss/enc_loss: 0.0016 (0.0014)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [190/862]  eta: 0:46:45  lr: 0.000100  loss/low_gen_loss: 0.9661 (0.9781)  loss/high_gen_loss: 598572901318067274941202432.0000 (558777170893282679405412352.0000)  loss/pix_loss: 0.1664 (0.1694)  loss/enc_loss: 0.0026 (0.0015)  time: 4.1716  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:31]  [200/862]  eta: 0:46:03  lr: 0.000100  loss/low_gen_loss: 1.0533 (0.9850)  loss/high_gen_loss: 829601953239053807430664192.0000 (581362695912578954496573440.0000)  loss/pix_loss: 0.1839 (0.1702)  loss/enc_loss: 0.0027 (0.0015)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [210/862]  eta: 0:45:21  lr: 0.000100  loss/low_gen_loss: 1.0863 (0.9877)  loss/high_gen_loss: 886499090660003548435054592.0000 (588152082407080687124348928.0000)  loss/pix_loss: 0.1831 (0.1694)  loss/enc_loss: 0.0018 (0.0015)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [220/862]  eta: 0:44:39  lr: 0.000100  loss/low_gen_loss: 1.0015 (0.9883)  loss/high_gen_loss: 563627315557855605521645568.0000 (584913668612597236876967936.0000)  loss/pix_loss: 0.1516 (0.1687)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [230/862]  eta: 0:43:58  lr: 0.000100  loss/low_gen_loss: 0.9701 (0.9873)  loss/high_gen_loss: 522183273901869387839700992.0000 (584376300494754263311843328.0000)  loss/pix_loss: 0.1622 (0.1689)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [240/862]  eta: 0:43:16  lr: 0.000100  loss/low_gen_loss: 0.9604 (0.9862)  loss/high_gen_loss: 666663855084337298638110720.0000 (593261450539632291833970688.0000)  loss/pix_loss: 0.1652 (0.1684)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [250/862]  eta: 0:42:34  lr: 0.000100  loss/low_gen_loss: 0.9731 (0.9870)  loss/high_gen_loss: 755433719637700171953864704.0000 (598226429132392520950480896.0000)  loss/pix_loss: 0.1587 (0.1684)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [260/862]  eta: 0:41:52  lr: 0.000100  loss/low_gen_loss: 1.0007 (0.9875)  loss/high_gen_loss: 627482454162944147138281472.0000 (592014314832141247204818944.0000)  loss/pix_loss: 0.1695 (0.1686)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [270/862]  eta: 0:41:11  lr: 0.000100  loss/low_gen_loss: 0.9906 (0.9874)  loss/high_gen_loss: 314041060459646148621107200.0000 (580490971763056015396831232.0000)  loss/pix_loss: 0.1738 (0.1689)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [280/862]  eta: 0:40:29  lr: 0.000100  loss/low_gen_loss: 0.9579 (0.9863)  loss/high_gen_loss: 409352103568058281520791552.0000 (581700910883535485774331904.0000)  loss/pix_loss: 0.1681 (0.1688)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [290/862]  eta: 0:39:47  lr: 0.000100  loss/low_gen_loss: 0.9596 (0.9858)  loss/high_gen_loss: 611355535730456161314406400.0000 (582283424344841453731577856.0000)  loss/pix_loss: 0.1733 (0.1692)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [300/862]  eta: 0:39:05  lr: 0.000100  loss/low_gen_loss: 0.9694 (0.9852)  loss/high_gen_loss: 435760720638397907547979776.0000 (572698763826326313164079104.0000)  loss/pix_loss: 0.1621 (0.1687)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1766  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [310/862]  eta: 0:38:24  lr: 0.000100  loss/low_gen_loss: 0.9745 (0.9851)  loss/high_gen_loss: 170977004754598394291290112.0000 (558893121568377380643274752.0000)  loss/pix_loss: 0.1551 (0.1683)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [320/862]  eta: 0:37:42  lr: 0.000100  loss/low_gen_loss: 0.9768 (0.9849)  loss/high_gen_loss: 170977004754598394291290112.0000 (549234837697875586299461632.0000)  loss/pix_loss: 0.1606 (0.1681)  loss/enc_loss: 0.0025 (0.0014)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [330/862]  eta: 0:37:00  lr: 0.000100  loss/low_gen_loss: 0.9666 (0.9841)  loss/high_gen_loss: 235661398292776475091271680.0000 (539694299358843486745919488.0000)  loss/pix_loss: 0.1607 (0.1676)  loss/enc_loss: 0.0036 (0.0015)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [340/862]  eta: 0:36:18  lr: 0.000100  loss/low_gen_loss: 0.9570 (0.9836)  loss/high_gen_loss: 150829572334385227418828800.0000 (526804767610533369941590016.0000)  loss/pix_loss: 0.1623 (0.1675)  loss/enc_loss: 0.0025 (0.0015)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [350/862]  eta: 0:35:37  lr: 0.000100  loss/low_gen_loss: 0.9785 (0.9841)  loss/high_gen_loss: 60978608674466495266291712.0000 (513400124806480850170413056.0000)  loss/pix_loss: 0.1638 (0.1674)  loss/enc_loss: 0.0010 (0.0015)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [360/862]  eta: 0:34:55  lr: 0.000100  loss/low_gen_loss: 0.9850 (0.9836)  loss/high_gen_loss: 50882733313041368231182336.0000 (499761837388413452284854272.0000)  loss/pix_loss: 0.1610 (0.1674)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [370/862]  eta: 0:34:13  lr: 0.000100  loss/low_gen_loss: 0.9755 (0.9845)  loss/high_gen_loss: 3953167230955076689330176.0000 (486397867817909821556916224.0000)  loss/pix_loss: 0.1595 (0.1671)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [380/862]  eta: 0:33:31  lr: 0.000100  loss/low_gen_loss: 0.9885 (0.9845)  loss/high_gen_loss: 14156905316665201900126208.0000 (476242651526593989507547136.0000)  loss/pix_loss: 0.1665 (0.1672)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [390/862]  eta: 0:32:50  lr: 0.000100  loss/low_gen_loss: 1.0230 (0.9860)  loss/high_gen_loss: 203789759518263691643453440.0000 (472130748914907641309822976.0000)  loss/pix_loss: 0.1647 (0.1669)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [400/862]  eta: 0:32:08  lr: 0.000100  loss/low_gen_loss: 1.0174 (0.9863)  loss/high_gen_loss: 363277043705855428324753408.0000 (469829016915089630450155520.0000)  loss/pix_loss: 0.1628 (0.1669)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [410/862]  eta: 0:31:26  lr: 0.000100  loss/low_gen_loss: 0.9877 (0.9861)  loss/high_gen_loss: 357797622846200743112736768.0000 (465789434024521057676820480.0000)  loss/pix_loss: 0.1732 (0.1672)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [420/862]  eta: 0:30:44  lr: 0.000100  loss/low_gen_loss: 0.9826 (0.9862)  loss/high_gen_loss: 235223989097300674203353088.0000 (458959694579146692570906624.0000)  loss/pix_loss: 0.1764 (0.1673)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [430/862]  eta: 0:30:03  lr: 0.000100  loss/low_gen_loss: 0.9735 (0.9859)  loss/high_gen_loss: 121865942859256275671187456.0000 (450344324981123946578444288.0000)  loss/pix_loss: 0.1759 (0.1675)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1748  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [440/862]  eta: 0:29:21  lr: 0.000100  loss/low_gen_loss: 0.9709 (0.9856)  loss/high_gen_loss: 115341643075034460326985728.0000 (443723219705942774009298944.0000)  loss/pix_loss: 0.1741 (0.1674)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1761  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [450/862]  eta: 0:28:39  lr: 0.000100  loss/low_gen_loss: 0.9912 (0.9866)  loss/high_gen_loss: 152514544054938042137313280.0000 (437585678677464729882984448.0000)  loss/pix_loss: 0.1741 (0.1676)  loss/enc_loss: 0.0027 (0.0014)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [460/862]  eta: 0:27:57  lr: 0.000100  loss/low_gen_loss: 1.0575 (0.9886)  loss/high_gen_loss: 268849839446246941171646464.0000 (436245225982610269966172160.0000)  loss/pix_loss: 0.1613 (0.1673)  loss/enc_loss: 0.0042 (0.0015)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [470/862]  eta: 0:27:16  lr: 0.000100  loss/low_gen_loss: 1.0425 (0.9892)  loss/high_gen_loss: 362918992403384725927886848.0000 (433577766401985406966956032.0000)  loss/pix_loss: 0.1568 (0.1671)  loss/enc_loss: 0.0045 (0.0015)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [480/862]  eta: 0:26:34  lr: 0.000100  loss/low_gen_loss: 1.0114 (0.9899)  loss/high_gen_loss: 310571486153798413895860224.0000 (431610092973301167558754304.0000)  loss/pix_loss: 0.1483 (0.1666)  loss/enc_loss: 0.0044 (0.0016)  time: 4.1737  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:31]  [490/862]  eta: 0:25:52  lr: 0.000100  loss/low_gen_loss: 1.0161 (0.9920)  loss/high_gen_loss: 478889614111100460836323328.0000 (434854999678059810763309056.0000)  loss/pix_loss: 0.1572 (0.1665)  loss/enc_loss: 0.0019 (0.0016)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [500/862]  eta: 0:25:10  lr: 0.000100  loss/low_gen_loss: 1.0775 (0.9932)  loss/high_gen_loss: 476486372293177580451790848.0000 (434288204515824134346768384.0000)  loss/pix_loss: 0.1581 (0.1664)  loss/enc_loss: 0.0012 (0.0016)  time: 4.1688  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 0.9606 (0.9925)  loss/high_gen_loss: 303860302405365847084236800.0000 (430714033185338370415394816.0000)  loss/pix_loss: 0.1513 (0.1664)  loss/enc_loss: 0.0006 (0.0015)  time: 4.1684  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 0.9597 (0.9923)  loss/high_gen_loss: 303860302405365847084236800.0000 (429396762689277399482236928.0000)  loss/pix_loss: 0.1742 (0.1667)  loss/enc_loss: 0.0003 (0.0015)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [530/862]  eta: 0:23:05  lr: 0.000100  loss/low_gen_loss: 1.0223 (0.9932)  loss/high_gen_loss: 364142085322447964038234112.0000 (427405695737910152726052864.0000)  loss/pix_loss: 0.1735 (0.1666)  loss/enc_loss: 0.0004 (0.0015)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [540/862]  eta: 0:22:23  lr: 0.000100  loss/low_gen_loss: 1.0349 (0.9940)  loss/high_gen_loss: 263067191007508618350166016.0000 (424094413695631734761062400.0000)  loss/pix_loss: 0.1618 (0.1667)  loss/enc_loss: 0.0003 (0.0015)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.0628 (0.9961)  loss/high_gen_loss: 217220630964146805369995264.0000 (419821646413983471464611840.0000)  loss/pix_loss: 0.1708 (0.1667)  loss/enc_loss: 0.0003 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 1.0852 (0.9968)  loss/high_gen_loss: 165171574586929040173563904.0000 (414819658971044732825763840.0000)  loss/pix_loss: 0.1603 (0.1664)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [570/862]  eta: 0:20:18  lr: 0.000100  loss/low_gen_loss: 0.9640 (0.9962)  loss/high_gen_loss: 101370374261512025285853184.0000 (408817612890295111065272320.0000)  loss/pix_loss: 0.1529 (0.1662)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [580/862]  eta: 0:19:36  lr: 0.000100  loss/low_gen_loss: 0.9582 (0.9955)  loss/high_gen_loss: 52950613323704208967335936.0000 (402952808125626818305720320.0000)  loss/pix_loss: 0.1651 (0.1662)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 0.9582 (0.9949)  loss/high_gen_loss: 215724378658840076219318272.0000 (403630094099451042429140992.0000)  loss/pix_loss: 0.1670 (0.1661)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 0.9568 (0.9943)  loss/high_gen_loss: 421876778711320413524197376.0000 (403403934639853753948176384.0000)  loss/pix_loss: 0.1686 (0.1662)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [610/862]  eta: 0:17:31  lr: 0.000100  loss/low_gen_loss: 0.9596 (0.9942)  loss/high_gen_loss: 264363775754961515314151424.0000 (399451798666793771813830656.0000)  loss/pix_loss: 0.1688 (0.1662)  loss/enc_loss: 0.0022 (0.0014)  time: 4.1703  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [620/862]  eta: 0:16:49  lr: 0.000100  loss/low_gen_loss: 1.0070 (0.9952)  loss/high_gen_loss: 103910371016625351431290880.0000 (394618176470425533256040448.0000)  loss/pix_loss: 0.1727 (0.1664)  loss/enc_loss: 0.0026 (0.0014)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.0487 (0.9961)  loss/high_gen_loss: 93275232762321436219015168.0000 (389438655975599099021885440.0000)  loss/pix_loss: 0.1634 (0.1663)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 1.0470 (0.9965)  loss/high_gen_loss: 48913423479336394484088832.0000 (384056554427264916661469184.0000)  loss/pix_loss: 0.1620 (0.1663)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 0.9733 (0.9961)  loss/high_gen_loss: 36360990597929348032888832.0000 (378410295347416759944609792.0000)  loss/pix_loss: 0.1701 (0.1665)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [660/862]  eta: 0:14:02  lr: 0.000100  loss/low_gen_loss: 1.0529 (0.9988)  loss/high_gen_loss: 1731918768662898540544.0000 (372685499056116110255456256.0000)  loss/pix_loss: 0.1762 (0.1665)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.1416 (1.0001)  loss/high_gen_loss: 1553215091023907127296.0000 (367267162896478246153486336.0000)  loss/pix_loss: 0.1608 (0.1665)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1703  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.0591 (1.0007)  loss/high_gen_loss: 7342250898419436696371200.0000 (361996407158894972366749696.0000)  loss/pix_loss: 0.1650 (0.1664)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.0685 (1.0045)  loss/high_gen_loss: 1717425163870804778156032.0000 (356767139234926577351393280.0000)  loss/pix_loss: 0.1772 (0.1668)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [700/862]  eta: 0:11:15  lr: 0.000100  loss/low_gen_loss: 1.1937 (1.0069)  loss/high_gen_loss: 3645977742955448893440.0000 (351677752933001650453348352.0000)  loss/pix_loss: 0.1730 (0.1665)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.2300 (1.0103)  loss/high_gen_loss: 1126780993888472530944.0000 (346731531551659676231794688.0000)  loss/pix_loss: 0.1614 (0.1666)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.1306 (1.0103)  loss/high_gen_loss: 1221244629391266283520.0000 (341922510161760551276904448.0000)  loss/pix_loss: 0.1686 (0.1666)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 1.0234 (1.0114)  loss/high_gen_loss: 915758218686075240448.0000 (337245060076715218783174656.0000)  loss/pix_loss: 0.1578 (0.1665)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.0771 (1.0124)  loss/high_gen_loss: 876600756932228153344.0000 (332693856618901522482200576.0000)  loss/pix_loss: 0.1614 (0.1665)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.0667 (1.0131)  loss/high_gen_loss: 895904451572533297152.0000 (328263862244253778103500800.0000)  loss/pix_loss: 0.1659 (0.1665)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.0406 (1.0133)  loss/high_gen_loss: 2381311235544424906752.0000 (374414460231508117388525568.0000)  loss/pix_loss: 0.1701 (0.1666)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [770/862]  eta: 0:06:23  lr: 0.000100  loss/low_gen_loss: 1.0123 (1.0129)  loss/high_gen_loss: 10623888987045909358671036416.0000 (615599735329038925110968320.0000)  loss/pix_loss: 0.1694 (0.1665)  loss/enc_loss: 0.0017 (0.0014)  time: 4.1722  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:31]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 0.9609 (1.0122)  loss/high_gen_loss: 22146472649980809419379703808.0000 (932725893011285608421654528.0000)  loss/pix_loss: 0.1619 (0.1666)  loss/enc_loss: 0.0014 (0.0014)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 0.9545 (1.0115)  loss/high_gen_loss: 29468532577052332975909240832.0000 (1305542112540352926619533312.0000)  loss/pix_loss: 0.1705 (0.1667)  loss/enc_loss: 0.0021 (0.0014)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 0.9571 (1.0111)  loss/high_gen_loss: 31299224057267511118031486976.0000 (1689339611036776904983052288.0000)  loss/pix_loss: 0.1672 (0.1666)  loss/enc_loss: 0.0021 (0.0014)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [810/862]  eta: 0:03:36  lr: 0.000100  loss/low_gen_loss: 1.0135 (1.0147)  loss/high_gen_loss: 28479584032942737614547451904.0000 (1986182372532921506950283264.0000)  loss/pix_loss: 0.1660 (0.1666)  loss/enc_loss: 0.0017 (0.0014)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.1216 (1.0157)  loss/high_gen_loss: 28479584032942737614547451904.0000 (2473839812097802264326963200.0000)  loss/pix_loss: 0.1747 (0.1667)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.1403 (1.0176)  loss/high_gen_loss: 40110132799592244938954244096.0000 (2905835245905436983640981504.0000)  loss/pix_loss: 0.1717 (0.1668)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.1393 (1.0183)  loss/high_gen_loss: 32442102859252725434778910720.0000 (3237085696294775396149231616.0000)  loss/pix_loss: 0.1648 (0.1667)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 0.9938 (1.0179)  loss/high_gen_loss: 29588211510827698394559938560.0000 (3440660129565834742329245696.0000)  loss/pix_loss: 0.1638 (0.1667)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1761  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 0.9938 (1.0178)  loss/high_gen_loss: 13658030702938829321874178048.0000 (3539974933716155221688713216.0000)  loss/pix_loss: 0.1660 (0.1667)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1759  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 0.9931 (1.0177)  loss/high_gen_loss: 13486305387564136825912033280.0000 (3544478719684874017607516160.0000)  loss/pix_loss: 0.1667 (0.1667)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1757  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:31] Total time: 0:59:57 (4.1732 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 0.9931 (1.0177)  loss/high_gen_loss: 13486305387564136825912033280.0000 (3544478719684874017607516160.0000)  loss/pix_loss: 0.1667 (0.1667)  loss/enc_loss: 0.0009 (0.0014)\n",
      "Valid: [epoch:31]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1588 (0.1588)  time: 2.9630  data: 0.3598  max mem: 31350\n",
      "Valid: [epoch:31]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6004  data: 0.0258  max mem: 31350\n",
      "Valid: [epoch:31] Total time: 0:00:36 (2.6090 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_31_input_n_20.png\n",
      "Train: [epoch:32]  [  0/862]  eta: 1:15:54  lr: 0.000100  loss/low_gen_loss: 0.9872 (0.9872)  loss/high_gen_loss: 6823945891050054096800186368.0000 (6823945891050054096800186368.0000)  loss/pix_loss: 0.1998 (0.1998)  loss/enc_loss: 0.0013 (0.0013)  time: 5.2840  data: 1.1083  max mem: 31350\n",
      "Train: [epoch:32]  [ 10/862]  eta: 1:00:40  lr: 0.000100  loss/low_gen_loss: 0.9688 (0.9745)  loss/high_gen_loss: 6823945891050054096800186368.0000 (8672843381974826312987049984.0000)  loss/pix_loss: 0.1721 (0.1724)  loss/enc_loss: 0.0014 (0.0014)  time: 4.2728  data: 0.1009  max mem: 31350\n",
      "Train: [epoch:32]  [ 20/862]  eta: 0:59:17  lr: 0.000100  loss/low_gen_loss: 0.9672 (0.9667)  loss/high_gen_loss: 16742738338538696728614273024.0000 (15296867443334191785910992896.0000)  loss/pix_loss: 0.1738 (0.1742)  loss/enc_loss: 0.0009 (0.0011)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [ 30/862]  eta: 0:58:21  lr: 0.000100  loss/low_gen_loss: 0.9572 (0.9710)  loss/high_gen_loss: 21324138640119820880447537152.0000 (17161983256006944588902170624.0000)  loss/pix_loss: 0.1738 (0.1713)  loss/enc_loss: 0.0008 (0.0010)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [ 40/862]  eta: 0:57:31  lr: 0.000100  loss/low_gen_loss: 0.9737 (0.9740)  loss/high_gen_loss: 19319419690869551290321469440.0000 (16981982610139581346324938752.0000)  loss/pix_loss: 0.1675 (0.1694)  loss/enc_loss: 0.0008 (0.0010)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [ 50/862]  eta: 0:56:45  lr: 0.000100  loss/low_gen_loss: 0.9555 (0.9700)  loss/high_gen_loss: 11195283525556929255415218176.0000 (15201206409272051730072207360.0000)  loss/pix_loss: 0.1720 (0.1687)  loss/enc_loss: 0.0007 (0.0009)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [ 60/862]  eta: 0:56:01  lr: 0.000100  loss/low_gen_loss: 0.9520 (0.9675)  loss/high_gen_loss: 5730669055713471457260470272.0000 (13523022386941238633094447104.0000)  loss/pix_loss: 0.1720 (0.1677)  loss/enc_loss: 0.0007 (0.0009)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [ 70/862]  eta: 0:55:17  lr: 0.000100  loss/low_gen_loss: 0.9535 (0.9656)  loss/high_gen_loss: 3906527497810033513049620480.0000 (12017839952228040680117633024.0000)  loss/pix_loss: 0.1693 (0.1684)  loss/enc_loss: 0.0009 (0.0009)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [ 80/862]  eta: 0:54:33  lr: 0.000100  loss/low_gen_loss: 0.9557 (0.9655)  loss/high_gen_loss: 2308728965430537663931219968.0000 (10750433446427732864195887104.0000)  loss/pix_loss: 0.1763 (0.1690)  loss/enc_loss: 0.0011 (0.0009)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [ 90/862]  eta: 0:53:50  lr: 0.000100  loss/low_gen_loss: 0.9605 (0.9653)  loss/high_gen_loss: 1050413242937148177022713856.0000 (9675597859071207712307019776.0000)  loss/pix_loss: 0.1721 (0.1682)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [100/862]  eta: 0:53:08  lr: 0.000100  loss/low_gen_loss: 0.9537 (0.9642)  loss/high_gen_loss: 875237500976956456849899520.0000 (8764910946170650450984960000.0000)  loss/pix_loss: 0.1536 (0.1668)  loss/enc_loss: 0.0028 (0.0014)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [110/862]  eta: 0:52:25  lr: 0.000100  loss/low_gen_loss: 0.9542 (0.9648)  loss/high_gen_loss: 829399998284934835259572224.0000 (9048193721682846363703836672.0000)  loss/pix_loss: 0.1655 (0.1675)  loss/enc_loss: 0.0038 (0.0017)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [120/862]  eta: 0:51:42  lr: 0.000100  loss/low_gen_loss: 0.9763 (0.9665)  loss/high_gen_loss: 28636050201619657569412841472.0000 (11679727058870839034232438784.0000)  loss/pix_loss: 0.1745 (0.1673)  loss/enc_loss: 0.0038 (0.0019)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [130/862]  eta: 0:51:00  lr: 0.000100  loss/low_gen_loss: 0.9752 (0.9671)  loss/high_gen_loss: 57157115501747922147517399040.0000 (15736947462561503068725182464.0000)  loss/pix_loss: 0.1708 (0.1681)  loss/enc_loss: 0.0037 (0.0020)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [140/862]  eta: 0:50:18  lr: 0.000100  loss/low_gen_loss: 0.9633 (0.9673)  loss/high_gen_loss: 68858832692477516460117196800.0000 (19629383541032348651662344192.0000)  loss/pix_loss: 0.1698 (0.1680)  loss/enc_loss: 0.0017 (0.0019)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [150/862]  eta: 0:49:36  lr: 0.000100  loss/low_gen_loss: 0.9712 (0.9675)  loss/high_gen_loss: 66867547695279390293212790784.0000 (22608249207173104550012780544.0000)  loss/pix_loss: 0.1656 (0.1673)  loss/enc_loss: 0.0009 (0.0019)  time: 4.1733  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:32]  [160/862]  eta: 0:48:54  lr: 0.000100  loss/low_gen_loss: 0.9684 (0.9676)  loss/high_gen_loss: 68987399119973642551060070400.0000 (25843036783797159381499379712.0000)  loss/pix_loss: 0.1655 (0.1670)  loss/enc_loss: 0.0005 (0.0018)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [170/862]  eta: 0:48:11  lr: 0.000100  loss/low_gen_loss: 0.9584 (0.9670)  loss/high_gen_loss: 76010866175516559875550216192.0000 (28747360519906977763293134848.0000)  loss/pix_loss: 0.1655 (0.1666)  loss/enc_loss: 0.0005 (0.0017)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [180/862]  eta: 0:47:29  lr: 0.000100  loss/low_gen_loss: 0.9618 (0.9669)  loss/high_gen_loss: 61917837045191434619639037952.0000 (30110765389414009532846178304.0000)  loss/pix_loss: 0.1684 (0.1668)  loss/enc_loss: 0.0004 (0.0016)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [190/862]  eta: 0:46:47  lr: 0.000100  loss/low_gen_loss: 0.9671 (0.9672)  loss/high_gen_loss: 75208753338935219157423095808.0000 (34221039895862218919812005888.0000)  loss/pix_loss: 0.1784 (0.1676)  loss/enc_loss: 0.0002 (0.0015)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [200/862]  eta: 0:46:05  lr: 0.000100  loss/low_gen_loss: 0.9619 (0.9668)  loss/high_gen_loss: 103151623892817131549675749376.0000 (37157005910260186216944107520.0000)  loss/pix_loss: 0.1722 (0.1678)  loss/enc_loss: 0.0002 (0.0015)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [210/862]  eta: 0:45:23  lr: 0.000100  loss/low_gen_loss: 0.9605 (0.9667)  loss/high_gen_loss: 57007147309351430824466055168.0000 (37258692905968634274837954560.0000)  loss/pix_loss: 0.1722 (0.1675)  loss/enc_loss: 0.0003 (0.0014)  time: 4.1703  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [220/862]  eta: 0:44:41  lr: 0.000100  loss/low_gen_loss: 0.9601 (0.9664)  loss/high_gen_loss: 43182381651818681504209305600.0000 (37775246171785893164466831360.0000)  loss/pix_loss: 0.1608 (0.1670)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [230/862]  eta: 0:43:59  lr: 0.000100  loss/low_gen_loss: 0.9579 (0.9661)  loss/high_gen_loss: 43132551240691441007914385408.0000 (37862394015984515900967485440.0000)  loss/pix_loss: 0.1582 (0.1667)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [240/862]  eta: 0:43:17  lr: 0.000100  loss/low_gen_loss: 0.9579 (0.9662)  loss/high_gen_loss: 46810670267937087314796216320.0000 (38413555320886451622960431104.0000)  loss/pix_loss: 0.1642 (0.1672)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [250/862]  eta: 0:42:36  lr: 0.000100  loss/low_gen_loss: 0.9765 (0.9681)  loss/high_gen_loss: 44208684114807775759211429888.0000 (38306953119515046218437754880.0000)  loss/pix_loss: 0.1695 (0.1670)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [260/862]  eta: 0:41:54  lr: 0.000100  loss/low_gen_loss: 0.9920 (0.9688)  loss/high_gen_loss: 32293315258476951523030990848.0000 (38040248742297415067365277696.0000)  loss/pix_loss: 0.1695 (0.1670)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [270/862]  eta: 0:41:12  lr: 0.000100  loss/low_gen_loss: 1.0025 (0.9705)  loss/high_gen_loss: 29504347004458416365209911296.0000 (37699829034114042160828383232.0000)  loss/pix_loss: 0.1711 (0.1671)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [280/862]  eta: 0:40:30  lr: 0.000100  loss/low_gen_loss: 1.0182 (0.9727)  loss/high_gen_loss: 29615487899632753465314246656.0000 (37445447045921909771362893824.0000)  loss/pix_loss: 0.1690 (0.1673)  loss/enc_loss: 0.0029 (0.0015)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [290/862]  eta: 0:39:48  lr: 0.000100  loss/low_gen_loss: 1.0182 (0.9741)  loss/high_gen_loss: 30602325545924506095265513472.0000 (37145822192377383743481970688.0000)  loss/pix_loss: 0.1662 (0.1670)  loss/enc_loss: 0.0046 (0.0016)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [300/862]  eta: 0:39:06  lr: 0.000100  loss/low_gen_loss: 1.0540 (0.9798)  loss/high_gen_loss: 19286895572310407326323441664.0000 (36323172399760453757244014592.0000)  loss/pix_loss: 0.1579 (0.1666)  loss/enc_loss: 0.0030 (0.0017)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [310/862]  eta: 0:38:24  lr: 0.000100  loss/low_gen_loss: 1.1139 (0.9819)  loss/high_gen_loss: 9345790533486015979580293120.0000 (35453101447816049199077654528.0000)  loss/pix_loss: 0.1576 (0.1663)  loss/enc_loss: 0.0017 (0.0016)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [320/862]  eta: 0:37:43  lr: 0.000100  loss/low_gen_loss: 0.9678 (0.9815)  loss/high_gen_loss: 9901244133638299030199992320.0000 (34694627812014164181635825664.0000)  loss/pix_loss: 0.1609 (0.1663)  loss/enc_loss: 0.0006 (0.0016)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [330/862]  eta: 0:37:01  lr: 0.000100  loss/low_gen_loss: 0.9798 (0.9815)  loss/high_gen_loss: 11890105376239092351698468864.0000 (34065396694584762576838590464.0000)  loss/pix_loss: 0.1615 (0.1657)  loss/enc_loss: 0.0004 (0.0016)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [340/862]  eta: 0:36:19  lr: 0.000100  loss/low_gen_loss: 0.9827 (0.9816)  loss/high_gen_loss: 11853557801436543449978372096.0000 (33403627086392365221865848832.0000)  loss/pix_loss: 0.1615 (0.1659)  loss/enc_loss: 0.0003 (0.0015)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [350/862]  eta: 0:35:37  lr: 0.000100  loss/low_gen_loss: 0.9533 (0.9808)  loss/high_gen_loss: 11000882586923117440548208640.0000 (32706234120744085668088512512.0000)  loss/pix_loss: 0.1741 (0.1661)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [360/862]  eta: 0:34:55  lr: 0.000100  loss/low_gen_loss: 0.9533 (0.9807)  loss/high_gen_loss: 6014465572459626373434048512.0000 (31952228429494861215834308608.0000)  loss/pix_loss: 0.1784 (0.1664)  loss/enc_loss: 0.0006 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [370/862]  eta: 0:34:14  lr: 0.000100  loss/low_gen_loss: 1.0044 (0.9824)  loss/high_gen_loss: 5331431338814516270309834752.0000 (31213651141552944159775522816.0000)  loss/pix_loss: 0.1796 (0.1666)  loss/enc_loss: 0.0006 (0.0015)  time: 4.1758  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [380/862]  eta: 0:33:32  lr: 0.000100  loss/low_gen_loss: 0.9859 (0.9823)  loss/high_gen_loss: 2470008848866980273709907968.0000 (30440474010000946736853417984.0000)  loss/pix_loss: 0.1600 (0.1663)  loss/enc_loss: 0.0009 (0.0015)  time: 4.1765  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [390/862]  eta: 0:32:50  lr: 0.000100  loss/low_gen_loss: 0.9805 (0.9823)  loss/high_gen_loss: 1845191358926876798074486784.0000 (29711148956177144335963258880.0000)  loss/pix_loss: 0.1551 (0.1663)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [400/862]  eta: 0:32:08  lr: 0.000100  loss/low_gen_loss: 0.9641 (0.9816)  loss/high_gen_loss: 1435691349364835513368838144.0000 (29001836018903386650526613504.0000)  loss/pix_loss: 0.1631 (0.1661)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [410/862]  eta: 0:31:27  lr: 0.000100  loss/low_gen_loss: 0.9511 (0.9809)  loss/high_gen_loss: 1213679397988471536481206272.0000 (28332116205600796947140050944.0000)  loss/pix_loss: 0.1737 (0.1664)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [420/862]  eta: 0:30:45  lr: 0.000100  loss/low_gen_loss: 0.9524 (0.9803)  loss/high_gen_loss: 1338065129194708389484036096.0000 (27690377308816181282505490432.0000)  loss/pix_loss: 0.1741 (0.1665)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [430/862]  eta: 0:30:03  lr: 0.000100  loss/low_gen_loss: 0.9553 (0.9803)  loss/high_gen_loss: 485724538618779471320186880.0000 (27056010902740933251390504960.0000)  loss/pix_loss: 0.1612 (0.1662)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1703  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:32]  [440/862]  eta: 0:29:21  lr: 0.000100  loss/low_gen_loss: 0.9861 (0.9805)  loss/high_gen_loss: 369210955445998169469485056.0000 (26465500715398634484740915200.0000)  loss/pix_loss: 0.1612 (0.1663)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1688  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [450/862]  eta: 0:28:39  lr: 0.000100  loss/low_gen_loss: 0.9619 (0.9800)  loss/high_gen_loss: 3954234024611603386409680896.0000 (26074355030750010616401887232.0000)  loss/pix_loss: 0.1741 (0.1665)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1698  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [460/862]  eta: 0:27:58  lr: 0.000100  loss/low_gen_loss: 0.9562 (0.9795)  loss/high_gen_loss: 13667613565124192549424070656.0000 (25869269986629675518126981120.0000)  loss/pix_loss: 0.1630 (0.1663)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1688  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [470/862]  eta: 0:27:16  lr: 0.000100  loss/low_gen_loss: 0.9554 (0.9790)  loss/high_gen_loss: 15054022445447753035019190272.0000 (25634012905324478162513428480.0000)  loss/pix_loss: 0.1632 (0.1666)  loss/enc_loss: 0.0026 (0.0014)  time: 4.1689  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [480/862]  eta: 0:26:34  lr: 0.000100  loss/low_gen_loss: 0.9573 (0.9786)  loss/high_gen_loss: 19396498156602949639499415552.0000 (25744591532052528397620871168.0000)  loss/pix_loss: 0.1672 (0.1664)  loss/enc_loss: 0.0038 (0.0014)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [490/862]  eta: 0:25:52  lr: 0.000100  loss/low_gen_loss: 0.9604 (0.9784)  loss/high_gen_loss: 25225476847460991012112957440.0000 (25674695532278997657657016320.0000)  loss/pix_loss: 0.1661 (0.1665)  loss/enc_loss: 0.0021 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [500/862]  eta: 0:25:10  lr: 0.000100  loss/low_gen_loss: 0.9668 (0.9783)  loss/high_gen_loss: 19397589023260492527543779328.0000 (25537869487234876739680206848.0000)  loss/pix_loss: 0.1737 (0.1665)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 0.9702 (0.9782)  loss/high_gen_loss: 15195556491305839171718873088.0000 (25249053371966746256153247744.0000)  loss/pix_loss: 0.1754 (0.1668)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 0.9694 (0.9779)  loss/high_gen_loss: 8501208864828418183340752896.0000 (24929110369017354670311473152.0000)  loss/pix_loss: 0.1769 (0.1669)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [530/862]  eta: 0:23:05  lr: 0.000100  loss/low_gen_loss: 0.9662 (0.9782)  loss/high_gen_loss: 8051673222520418405219041280.0000 (24624380201324336469378072576.0000)  loss/pix_loss: 0.1560 (0.1665)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [540/862]  eta: 0:22:23  lr: 0.000100  loss/low_gen_loss: 0.9856 (0.9782)  loss/high_gen_loss: 4771630505166846531918102528.0000 (24238272302955567081167257600.0000)  loss/pix_loss: 0.1643 (0.1668)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 0.9982 (0.9790)  loss/high_gen_loss: 4771630505166846531918102528.0000 (23956746707219394763039965184.0000)  loss/pix_loss: 0.1766 (0.1670)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 1.0189 (0.9801)  loss/high_gen_loss: 10035753659353116569644302336.0000 (23715006304343121142648668160.0000)  loss/pix_loss: 0.1783 (0.1670)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [570/862]  eta: 0:20:18  lr: 0.000100  loss/low_gen_loss: 1.0452 (0.9817)  loss/high_gen_loss: 8070102257719817195665489920.0000 (23402259066922736404345651200.0000)  loss/pix_loss: 0.1680 (0.1670)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [580/862]  eta: 0:19:36  lr: 0.000100  loss/low_gen_loss: 1.0856 (0.9837)  loss/high_gen_loss: 4429879040907579074212265984.0000 (23069092949361659487394463744.0000)  loss/pix_loss: 0.1500 (0.1666)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 0.9811 (0.9833)  loss/high_gen_loss: 7619337029238840233671262208.0000 (22856940706206310371701030912.0000)  loss/pix_loss: 0.1500 (0.1663)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 0.9642 (0.9832)  loss/high_gen_loss: 10822149279687846391088939008.0000 (22657780041521299635851755520.0000)  loss/pix_loss: 0.1585 (0.1664)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [610/862]  eta: 0:17:31  lr: 0.000100  loss/low_gen_loss: 0.9756 (0.9830)  loss/high_gen_loss: 7054131742299431365685280768.0000 (22373665389981901867530059776.0000)  loss/pix_loss: 0.1729 (0.1666)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [620/862]  eta: 0:16:49  lr: 0.000100  loss/low_gen_loss: 0.9843 (0.9835)  loss/high_gen_loss: 4758413191677104753670619136.0000 (22093183837889688096431144960.0000)  loss/pix_loss: 0.1767 (0.1667)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 0.9976 (0.9842)  loss/high_gen_loss: 6232416362447698750276108288.0000 (21884262492882226867758694400.0000)  loss/pix_loss: 0.1675 (0.1667)  loss/enc_loss: 0.0022 (0.0014)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 0.9978 (0.9842)  loss/high_gen_loss: 10320762643693748267226497024.0000 (21728017974151993826572500992.0000)  loss/pix_loss: 0.1675 (0.1667)  loss/enc_loss: 0.0022 (0.0014)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 0.9761 (0.9840)  loss/high_gen_loss: 9083197442247945770416209920.0000 (21488981905725006616635375616.0000)  loss/pix_loss: 0.1698 (0.1669)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [660/862]  eta: 0:14:02  lr: 0.000100  loss/low_gen_loss: 0.9851 (0.9843)  loss/high_gen_loss: 5018817170902459702925328384.0000 (21239649967003199479962664960.0000)  loss/pix_loss: 0.1660 (0.1670)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.0072 (0.9852)  loss/high_gen_loss: 6223598523632560405250834432.0000 (21027120217791559207374290944.0000)  loss/pix_loss: 0.1652 (0.1670)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 0.9658 (0.9849)  loss/high_gen_loss: 6100234373113125587216498688.0000 (20787970808129423453829726208.0000)  loss/pix_loss: 0.1670 (0.1670)  loss/enc_loss: 0.0009 (0.0014)  time: 4.1753  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 0.9591 (0.9845)  loss/high_gen_loss: 3651582279090970694309117952.0000 (20526996462948813589849309184.0000)  loss/pix_loss: 0.1737 (0.1672)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 0.9708 (0.9845)  loss/high_gen_loss: 3237111978805709108016054272.0000 (20312950451750745275065434112.0000)  loss/pix_loss: 0.1819 (0.1672)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 0.9669 (0.9841)  loss/high_gen_loss: 6775964876696667425312079872.0000 (20143106249908563656516304896.0000)  loss/pix_loss: 0.1670 (0.1673)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1705  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:32]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 0.9508 (0.9837)  loss/high_gen_loss: 7886332546630565669585813504.0000 (19977278737926919649811759104.0000)  loss/pix_loss: 0.1699 (0.1673)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 0.9509 (0.9834)  loss/high_gen_loss: 7520107713221731454912823296.0000 (19793150741708093662026530816.0000)  loss/pix_loss: 0.1718 (0.1674)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 0.9665 (0.9832)  loss/high_gen_loss: 3990429487963273320208531456.0000 (19572432499048895763493945344.0000)  loss/pix_loss: 0.1734 (0.1674)  loss/enc_loss: 0.0027 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 0.9547 (0.9828)  loss/high_gen_loss: 4200330709133389207431020544.0000 (19407845245611473191619788800.0000)  loss/pix_loss: 0.1734 (0.1673)  loss/enc_loss: 0.0035 (0.0015)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 0.9526 (0.9824)  loss/high_gen_loss: 7212860514817456239313682432.0000 (19239421081859853699898146816.0000)  loss/pix_loss: 0.1599 (0.1673)  loss/enc_loss: 0.0059 (0.0015)  time: 4.1753  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [770/862]  eta: 0:06:23  lr: 0.000100  loss/low_gen_loss: 0.9690 (0.9833)  loss/high_gen_loss: 3437930023193930412022824960.0000 (19023295286996901254605570048.0000)  loss/pix_loss: 0.1674 (0.1672)  loss/enc_loss: 0.0028 (0.0015)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.0146 (0.9835)  loss/high_gen_loss: 2536755219457717608189526016.0000 (18812083185136164627529334784.0000)  loss/pix_loss: 0.1648 (0.1671)  loss/enc_loss: 0.0013 (0.0015)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 0.9631 (0.9832)  loss/high_gen_loss: 1717654112176111110435373056.0000 (18586783048570336343014506496.0000)  loss/pix_loss: 0.1744 (0.1672)  loss/enc_loss: 0.0006 (0.0015)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 0.9548 (0.9829)  loss/high_gen_loss: 932730025509629247342247936.0000 (18371004659540099662188904448.0000)  loss/pix_loss: 0.1746 (0.1672)  loss/enc_loss: 0.0003 (0.0015)  time: 4.1703  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [810/862]  eta: 0:03:36  lr: 0.000100  loss/low_gen_loss: 0.9632 (0.9828)  loss/high_gen_loss: 2393861869922327962050363392.0000 (18192890693860107551537889280.0000)  loss/pix_loss: 0.1662 (0.1672)  loss/enc_loss: 0.0002 (0.0015)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 0.9542 (0.9824)  loss/high_gen_loss: 4591102403520179837924802560.0000 (18034885759198484356143251456.0000)  loss/pix_loss: 0.1718 (0.1673)  loss/enc_loss: 0.0003 (0.0014)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 0.9581 (0.9829)  loss/high_gen_loss: 5413446448409944474853048320.0000 (17922306275656435507899924480.0000)  loss/pix_loss: 0.1742 (0.1674)  loss/enc_loss: 0.0002 (0.0014)  time: 4.1698  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.0164 (0.9832)  loss/high_gen_loss: 9712178288538509197013155840.0000 (17830576128062820029917298688.0000)  loss/pix_loss: 0.1634 (0.1672)  loss/enc_loss: 0.0002 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 0.9628 (0.9829)  loss/high_gen_loss: 10508170938158050854943326208.0000 (17779667961656731600552984576.0000)  loss/pix_loss: 0.1664 (0.1672)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 0.9556 (0.9826)  loss/high_gen_loss: 7651721247690929184429834240.0000 (17622999674189261620614529024.0000)  loss/pix_loss: 0.1674 (0.1672)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 0.9542 (0.9826)  loss/high_gen_loss: 6812248589271985985605861376.0000 (17605644508136398931001081856.0000)  loss/pix_loss: 0.1674 (0.1673)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:32] Total time: 0:59:57 (4.1731 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 0.9542 (0.9826)  loss/high_gen_loss: 6812248589271985985605861376.0000 (17605644508136398931001081856.0000)  loss/pix_loss: 0.1674 (0.1673)  loss/enc_loss: 0.0006 (0.0014)\n",
      "Valid: [epoch:32]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1194 (0.1194)  time: 3.0259  data: 0.3875  max mem: 31350\n",
      "Valid: [epoch:32]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6294  data: 0.0278  max mem: 31350\n",
      "Valid: [epoch:32] Total time: 0:00:36 (2.6392 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_32_input_n_20.png\n",
      "Train: [epoch:33]  [  0/862]  eta: 1:13:03  lr: 0.000100  loss/low_gen_loss: 0.9543 (0.9543)  loss/high_gen_loss: 3362266496517961880292032512.0000 (3362266496517961880292032512.0000)  loss/pix_loss: 0.1882 (0.1882)  loss/enc_loss: 0.0006 (0.0006)  time: 5.0856  data: 0.9177  max mem: 31350\n",
      "Train: [epoch:33]  [ 10/862]  eta: 1:00:03  lr: 0.000100  loss/low_gen_loss: 0.9495 (0.9503)  loss/high_gen_loss: 15793811850371421610438557696.0000 (17331592351380601241771966464.0000)  loss/pix_loss: 0.1573 (0.1605)  loss/enc_loss: 0.0008 (0.0007)  time: 4.2300  data: 0.0835  max mem: 31350\n",
      "Train: [epoch:33]  [ 20/862]  eta: 0:58:48  lr: 0.000100  loss/low_gen_loss: 0.9497 (0.9622)  loss/high_gen_loss: 21336331790378590304389300224.0000 (20836288625484880255519817728.0000)  loss/pix_loss: 0.1573 (0.1637)  loss/enc_loss: 0.0007 (0.0007)  time: 4.1455  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [ 30/862]  eta: 0:57:59  lr: 0.000100  loss/low_gen_loss: 0.9740 (0.9747)  loss/high_gen_loss: 9748299669765979113252716544.0000 (16093388487951592357793628160.0000)  loss/pix_loss: 0.1724 (0.1637)  loss/enc_loss: 0.0007 (0.0007)  time: 4.1552  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [ 40/862]  eta: 0:57:15  lr: 0.000100  loss/low_gen_loss: 0.9546 (0.9686)  loss/high_gen_loss: 6506408656079605924280401920.0000 (13887016993915535110959005696.0000)  loss/pix_loss: 0.1632 (0.1638)  loss/enc_loss: 0.0007 (0.0007)  time: 4.1675  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [ 50/862]  eta: 0:56:31  lr: 0.000100  loss/low_gen_loss: 0.9487 (0.9650)  loss/high_gen_loss: 5228092383365690182804176896.0000 (11553440650849467099735130112.0000)  loss/pix_loss: 0.1588 (0.1639)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1691  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [ 60/862]  eta: 0:55:49  lr: 0.000100  loss/low_gen_loss: 0.9556 (0.9649)  loss/high_gen_loss: 398427535899237863443660800.0000 (9712993803368914641628430336.0000)  loss/pix_loss: 0.1701 (0.1642)  loss/enc_loss: 0.0060 (0.0024)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [ 70/862]  eta: 0:55:07  lr: 0.000100  loss/low_gen_loss: 0.9583 (0.9637)  loss/high_gen_loss: 368536062867317431814062080.0000 (8401477739693952999486390272.0000)  loss/pix_loss: 0.1701 (0.1661)  loss/enc_loss: 0.0045 (0.0025)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [ 80/862]  eta: 0:54:25  lr: 0.000100  loss/low_gen_loss: 0.9503 (0.9619)  loss/high_gen_loss: 474876930766234569492398080.0000 (7507797171072003378214076416.0000)  loss/pix_loss: 0.1639 (0.1651)  loss/enc_loss: 0.0017 (0.0023)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [ 90/862]  eta: 0:53:43  lr: 0.000100  loss/low_gen_loss: 0.9503 (0.9616)  loss/high_gen_loss: 2041110095663073434848460800.0000 (6998050951955794637296238592.0000)  loss/pix_loss: 0.1543 (0.1638)  loss/enc_loss: 0.0008 (0.0021)  time: 4.1728  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:33]  [100/862]  eta: 0:53:00  lr: 0.000100  loss/low_gen_loss: 0.9518 (0.9607)  loss/high_gen_loss: 3088142271772439535574581248.0000 (6617516138538553081317031936.0000)  loss/pix_loss: 0.1545 (0.1629)  loss/enc_loss: 0.0004 (0.0019)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [110/862]  eta: 0:52:19  lr: 0.000100  loss/low_gen_loss: 0.9572 (0.9641)  loss/high_gen_loss: 2846204811530441154575204352.0000 (6232483106091495320293736448.0000)  loss/pix_loss: 0.1547 (0.1627)  loss/enc_loss: 0.0003 (0.0018)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [120/862]  eta: 0:51:37  lr: 0.000100  loss/low_gen_loss: 0.9896 (0.9680)  loss/high_gen_loss: 1869681108785181009123475456.0000 (5863258297018460689244618752.0000)  loss/pix_loss: 0.1690 (0.1635)  loss/enc_loss: 0.0003 (0.0017)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [130/862]  eta: 0:50:55  lr: 0.000100  loss/low_gen_loss: 0.9647 (0.9672)  loss/high_gen_loss: 1782792221831526151366901760.0000 (5561310969887824240932028416.0000)  loss/pix_loss: 0.1699 (0.1638)  loss/enc_loss: 0.0004 (0.0016)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [140/862]  eta: 0:50:13  lr: 0.000100  loss/low_gen_loss: 0.9606 (0.9672)  loss/high_gen_loss: 2304608995822139077835096064.0000 (5346441524329431330556215296.0000)  loss/pix_loss: 0.1680 (0.1640)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [150/862]  eta: 0:49:31  lr: 0.000100  loss/low_gen_loss: 0.9606 (0.9667)  loss/high_gen_loss: 1910225428945716117134901248.0000 (5074459905537951723417501696.0000)  loss/pix_loss: 0.1641 (0.1636)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [160/862]  eta: 0:48:49  lr: 0.000100  loss/low_gen_loss: 0.9638 (0.9683)  loss/high_gen_loss: 1224462626704199191973855232.0000 (4846645715408118323265667072.0000)  loss/pix_loss: 0.1590 (0.1636)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [170/862]  eta: 0:48:08  lr: 0.000100  loss/low_gen_loss: 0.9838 (0.9697)  loss/high_gen_loss: 1760880588924963587251765248.0000 (4777662201910691476281491456.0000)  loss/pix_loss: 0.1701 (0.1637)  loss/enc_loss: 0.0004 (0.0013)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [180/862]  eta: 0:47:26  lr: 0.000100  loss/low_gen_loss: 0.9918 (0.9718)  loss/high_gen_loss: 5046580553751060705842298880.0000 (4808797413400903023809527808.0000)  loss/pix_loss: 0.1768 (0.1650)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [190/862]  eta: 0:46:44  lr: 0.000100  loss/low_gen_loss: 0.9918 (0.9730)  loss/high_gen_loss: 4747341898605922049819934720.0000 (4744331708879631561670000640.0000)  loss/pix_loss: 0.1792 (0.1660)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [200/862]  eta: 0:46:02  lr: 0.000100  loss/low_gen_loss: 0.9888 (0.9738)  loss/high_gen_loss: 2826244253851066702315388928.0000 (4632667008690239034307379200.0000)  loss/pix_loss: 0.1947 (0.1677)  loss/enc_loss: 0.0019 (0.0014)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [210/862]  eta: 0:45:20  lr: 0.000100  loss/low_gen_loss: 0.9926 (0.9753)  loss/high_gen_loss: 1798458525064493609686925312.0000 (4488179843540293548215631872.0000)  loss/pix_loss: 0.1847 (0.1672)  loss/enc_loss: 0.0035 (0.0015)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [220/862]  eta: 0:44:39  lr: 0.000100  loss/low_gen_loss: 0.9792 (0.9750)  loss/high_gen_loss: 1248295598686503048147107840.0000 (4335158680573804068751802368.0000)  loss/pix_loss: 0.1511 (0.1666)  loss/enc_loss: 0.0037 (0.0015)  time: 4.1703  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [230/862]  eta: 0:43:57  lr: 0.000100  loss/low_gen_loss: 0.9682 (0.9747)  loss/high_gen_loss: 721763099040887011903799296.0000 (4164156188346309117130833920.0000)  loss/pix_loss: 0.1596 (0.1667)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [240/862]  eta: 0:43:15  lr: 0.000100  loss/low_gen_loss: 0.9643 (0.9740)  loss/high_gen_loss: 601298518435422303449776128.0000 (4046952190158229822093918208.0000)  loss/pix_loss: 0.1678 (0.1667)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [250/862]  eta: 0:42:33  lr: 0.000100  loss/low_gen_loss: 0.9503 (0.9731)  loss/high_gen_loss: 1329710525016749038718943232.0000 (3945246297309972706789163008.0000)  loss/pix_loss: 0.1739 (0.1670)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [260/862]  eta: 0:41:52  lr: 0.000100  loss/low_gen_loss: 0.9530 (0.9730)  loss/high_gen_loss: 1348226038552365379543367680.0000 (3845151746213962423386243072.0000)  loss/pix_loss: 0.1751 (0.1673)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [270/862]  eta: 0:41:10  lr: 0.000100  loss/low_gen_loss: 0.9783 (0.9737)  loss/high_gen_loss: 1346802982927543129893502976.0000 (3749335794592209494284959744.0000)  loss/pix_loss: 0.1751 (0.1676)  loss/enc_loss: 0.0003 (0.0014)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [280/862]  eta: 0:40:28  lr: 0.000100  loss/low_gen_loss: 0.9644 (0.9731)  loss/high_gen_loss: 930171314532653142856695808.0000 (3638085734938547820643221504.0000)  loss/pix_loss: 0.1781 (0.1678)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [290/862]  eta: 0:39:46  lr: 0.000100  loss/low_gen_loss: 0.9560 (0.9726)  loss/high_gen_loss: 397768212372555336649801728.0000 (3523600306379982772514062336.0000)  loss/pix_loss: 0.1661 (0.1678)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [300/862]  eta: 0:39:05  lr: 0.000100  loss/low_gen_loss: 0.9563 (0.9722)  loss/high_gen_loss: 164251487886020555158061056.0000 (3409098704882840592994795520.0000)  loss/pix_loss: 0.1616 (0.1675)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [310/862]  eta: 0:38:23  lr: 0.000100  loss/low_gen_loss: 0.9657 (0.9741)  loss/high_gen_loss: 21907141124380615839318016.0000 (3299947070760200311914102784.0000)  loss/pix_loss: 0.1559 (0.1670)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [320/862]  eta: 0:37:41  lr: 0.000100  loss/low_gen_loss: 1.1066 (0.9812)  loss/high_gen_loss: 27445231853561734280249344.0000 (3199443171754699455853494272.0000)  loss/pix_loss: 0.1512 (0.1665)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [330/862]  eta: 0:36:59  lr: 0.000100  loss/low_gen_loss: 1.0422 (0.9811)  loss/high_gen_loss: 79332501061881029854232576.0000 (3105336074449387649419444224.0000)  loss/pix_loss: 0.1558 (0.1664)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [340/862]  eta: 0:36:18  lr: 0.000100  loss/low_gen_loss: 0.9565 (0.9803)  loss/high_gen_loss: 71846812316769693808459776.0000 (3031150945439382874301136896.0000)  loss/pix_loss: 0.1606 (0.1664)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [350/862]  eta: 0:35:36  lr: 0.000100  loss/low_gen_loss: 0.9528 (0.9798)  loss/high_gen_loss: 2688200922267536771487105024.0000 (3146990287708683244088066048.0000)  loss/pix_loss: 0.1641 (0.1663)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [360/862]  eta: 0:34:54  lr: 0.000100  loss/low_gen_loss: 0.9532 (0.9791)  loss/high_gen_loss: 11716485211313148410594328576.0000 (3582233357278244530814976000.0000)  loss/pix_loss: 0.1673 (0.1666)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [370/862]  eta: 0:34:12  lr: 0.000100  loss/low_gen_loss: 0.9550 (0.9789)  loss/high_gen_loss: 22432064846582075518145789952.0000 (4146559478055637499768733696.0000)  loss/pix_loss: 0.1727 (0.1668)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1759  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [380/862]  eta: 0:33:31  lr: 0.000100  loss/low_gen_loss: 0.9594 (0.9785)  loss/high_gen_loss: 31012349738166145910589882368.0000 (4923344084961779597835239424.0000)  loss/pix_loss: 0.1740 (0.1667)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1728  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:33]  [390/862]  eta: 0:32:49  lr: 0.000100  loss/low_gen_loss: 0.9594 (0.9781)  loss/high_gen_loss: 33581650031684275216828071936.0000 (5624088956237453474924593152.0000)  loss/pix_loss: 0.1740 (0.1667)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [400/862]  eta: 0:32:07  lr: 0.000100  loss/low_gen_loss: 0.9596 (0.9777)  loss/high_gen_loss: 31533028421834387252561575936.0000 (6237168493649885868465324032.0000)  loss/pix_loss: 0.1751 (0.1668)  loss/enc_loss: 0.0030 (0.0014)  time: 4.1748  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [410/862]  eta: 0:31:26  lr: 0.000100  loss/low_gen_loss: 0.9550 (0.9773)  loss/high_gen_loss: 26370084035578935619008593920.0000 (6601071701918015112311996416.0000)  loss/pix_loss: 0.1630 (0.1667)  loss/enc_loss: 0.0024 (0.0014)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [420/862]  eta: 0:30:44  lr: 0.000100  loss/low_gen_loss: 0.9550 (0.9772)  loss/high_gen_loss: 21528326683289380035019931648.0000 (6970753086933495063404085248.0000)  loss/pix_loss: 0.1621 (0.1667)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [430/862]  eta: 0:30:02  lr: 0.000100  loss/low_gen_loss: 0.9628 (0.9769)  loss/high_gen_loss: 23175315746137687543506796544.0000 (7585917187848391207973552128.0000)  loss/pix_loss: 0.1725 (0.1669)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [440/862]  eta: 0:29:20  lr: 0.000100  loss/low_gen_loss: 0.9544 (0.9763)  loss/high_gen_loss: 40349056209426551768895979520.0000 (8381886498878220773732909056.0000)  loss/pix_loss: 0.1664 (0.1668)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [450/862]  eta: 0:28:39  lr: 0.000100  loss/low_gen_loss: 0.9539 (0.9762)  loss/high_gen_loss: 37681724310090531497666674688.0000 (8841449047840234054136889344.0000)  loss/pix_loss: 0.1653 (0.1669)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [460/862]  eta: 0:27:57  lr: 0.000100  loss/low_gen_loss: 0.9677 (0.9762)  loss/high_gen_loss: 26666653373069632208073916416.0000 (9192734129529365127814447104.0000)  loss/pix_loss: 0.1653 (0.1667)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [470/862]  eta: 0:27:15  lr: 0.000100  loss/low_gen_loss: 0.9563 (0.9758)  loss/high_gen_loss: 19675077638977154315123163136.0000 (9394194141715105028866310144.0000)  loss/pix_loss: 0.1642 (0.1666)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [480/862]  eta: 0:26:33  lr: 0.000100  loss/low_gen_loss: 0.9500 (0.9756)  loss/high_gen_loss: 18322003943656170655091523584.0000 (9528578610600987464877211648.0000)  loss/pix_loss: 0.1608 (0.1666)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [490/862]  eta: 0:25:52  lr: 0.000100  loss/low_gen_loss: 0.9739 (0.9756)  loss/high_gen_loss: 6007611647805551442112020480.0000 (9411211940685983763681771520.0000)  loss/pix_loss: 0.1613 (0.1665)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [500/862]  eta: 0:25:10  lr: 0.000100  loss/low_gen_loss: 0.9659 (0.9754)  loss/high_gen_loss: 3184022544509478197818032128.0000 (9279376530108019672380080128.0000)  loss/pix_loss: 0.1623 (0.1665)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [510/862]  eta: 0:24:28  lr: 0.000100  loss/low_gen_loss: 0.9659 (0.9758)  loss/high_gen_loss: 5971831457556468857739149312.0000 (9262873686718893113479266304.0000)  loss/pix_loss: 0.1779 (0.1668)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 0.9627 (0.9754)  loss/high_gen_loss: 9194470563683803220586528768.0000 (9364630491933002097991090176.0000)  loss/pix_loss: 0.1644 (0.1666)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [530/862]  eta: 0:23:05  lr: 0.000100  loss/low_gen_loss: 0.9620 (0.9752)  loss/high_gen_loss: 16592611946865029272448270336.0000 (9501248192644984939242061824.0000)  loss/pix_loss: 0.1558 (0.1663)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [540/862]  eta: 0:22:23  lr: 0.000100  loss/low_gen_loss: 0.9493 (0.9747)  loss/high_gen_loss: 14812798062544667970447081472.0000 (9573060854023853122642771968.0000)  loss/pix_loss: 0.1662 (0.1668)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [550/862]  eta: 0:21:41  lr: 0.000100  loss/low_gen_loss: 0.9488 (0.9743)  loss/high_gen_loss: 14812798062544667970447081472.0000 (9736448888165097420749799424.0000)  loss/pix_loss: 0.1861 (0.1670)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 0.9630 (0.9751)  loss/high_gen_loss: 20138435057684703186079711232.0000 (9931743473678900540911648768.0000)  loss/pix_loss: 0.1709 (0.1670)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [570/862]  eta: 0:20:18  lr: 0.000100  loss/low_gen_loss: 1.0582 (0.9774)  loss/high_gen_loss: 20641374171660044705806155776.0000 (10136289367486352974575304704.0000)  loss/pix_loss: 0.1709 (0.1671)  loss/enc_loss: 0.0031 (0.0014)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [580/862]  eta: 0:19:36  lr: 0.000100  loss/low_gen_loss: 1.0946 (0.9790)  loss/high_gen_loss: 20657607306444909111228235776.0000 (10276669907113439726418264064.0000)  loss/pix_loss: 0.1678 (0.1668)  loss/enc_loss: 0.0031 (0.0014)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [590/862]  eta: 0:18:54  lr: 0.000100  loss/low_gen_loss: 0.9591 (0.9785)  loss/high_gen_loss: 16056704811881154042073710592.0000 (10379037342543271129595772928.0000)  loss/pix_loss: 0.1514 (0.1666)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 0.9512 (0.9784)  loss/high_gen_loss: 19619423369384914828868452352.0000 (10566826435952498707856883712.0000)  loss/pix_loss: 0.1654 (0.1666)  loss/enc_loss: 0.0025 (0.0014)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [610/862]  eta: 0:17:31  lr: 0.000100  loss/low_gen_loss: 0.9579 (0.9782)  loss/high_gen_loss: 18025225641448607084225495040.0000 (10677441230919708419437887488.0000)  loss/pix_loss: 0.1682 (0.1665)  loss/enc_loss: 0.0024 (0.0014)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [620/862]  eta: 0:16:49  lr: 0.000100  loss/low_gen_loss: 0.9560 (0.9779)  loss/high_gen_loss: 16269996397038065155206807552.0000 (10725601306137272241092558848.0000)  loss/pix_loss: 0.1710 (0.1666)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1748  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 0.9607 (0.9779)  loss/high_gen_loss: 11136642359164274718562844672.0000 (10726698669128146683974123520.0000)  loss/pix_loss: 0.1675 (0.1666)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 0.9675 (0.9779)  loss/high_gen_loss: 10902345687891559423519227904.0000 (10727857710107485105098326016.0000)  loss/pix_loss: 0.1531 (0.1665)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 0.9678 (0.9779)  loss/high_gen_loss: 12914051378353234653738958848.0000 (10981765322376203135436718080.0000)  loss/pix_loss: 0.1604 (0.1666)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [660/862]  eta: 0:14:02  lr: 0.000100  loss/low_gen_loss: 1.0017 (0.9787)  loss/high_gen_loss: 39182199591624566828576014336.0000 (11594099105295147187814006784.0000)  loss/pix_loss: 0.1604 (0.1665)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1693  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:33]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.0147 (0.9794)  loss/high_gen_loss: 75535640269245938868760346624.0000 (12695824194696040319551537152.0000)  loss/pix_loss: 0.1594 (0.1666)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1683  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.0856 (0.9818)  loss/high_gen_loss: 86403751161319934799302885376.0000 (13806195020060859058081497088.0000)  loss/pix_loss: 0.1779 (0.1668)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.0215 (0.9815)  loss/high_gen_loss: 92325976520157099468894765056.0000 (15361835940235197935005990912.0000)  loss/pix_loss: 0.1769 (0.1670)  loss/enc_loss: 0.0032 (0.0014)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [700/862]  eta: 0:11:15  lr: 0.000100  loss/low_gen_loss: 0.9470 (0.9810)  loss/high_gen_loss: 181458499929938430058479747072.0000 (18430695636068587604080066560.0000)  loss/pix_loss: 0.1744 (0.1669)  loss/enc_loss: 0.0030 (0.0014)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 0.9464 (0.9805)  loss/high_gen_loss: 210650318359377291868624650240.0000 (20747132973202172696588189696.0000)  loss/pix_loss: 0.1675 (0.1669)  loss/enc_loss: 0.0017 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 0.9507 (0.9809)  loss/high_gen_loss: 165212765871297728422969606144.0000 (22447328759269058936714559488.0000)  loss/pix_loss: 0.1689 (0.1671)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 1.0143 (0.9814)  loss/high_gen_loss: 108171102785323003361636646912.0000 (23515307510954405001561112576.0000)  loss/pix_loss: 0.1643 (0.1670)  loss/enc_loss: 0.0016 (0.0015)  time: 4.1679  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.0053 (0.9816)  loss/high_gen_loss: 89349119470884629736956362752.0000 (23769138896022416029820911616.0000)  loss/pix_loss: 0.1696 (0.1673)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1678  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 0.9637 (0.9813)  loss/high_gen_loss: 37452828845482598359336222720.0000 (24119475534548747498031153152.0000)  loss/pix_loss: 0.1793 (0.1674)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 0.9538 (0.9811)  loss/high_gen_loss: 70335818923125758175733612544.0000 (24810508152341762409051979776.0000)  loss/pix_loss: 0.1754 (0.1674)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [770/862]  eta: 0:06:23  lr: 0.000100  loss/low_gen_loss: 1.0039 (0.9831)  loss/high_gen_loss: 85183038314964062990143324160.0000 (25958338318173523151215919104.0000)  loss/pix_loss: 0.1629 (0.1674)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 0.9683 (0.9827)  loss/high_gen_loss: 93034841508167696172632244224.0000 (26754448515847143184463298560.0000)  loss/pix_loss: 0.1612 (0.1672)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 0.9664 (0.9831)  loss/high_gen_loss: 97664205705523706593489715200.0000 (27853013248985004860229287936.0000)  loss/pix_loss: 0.1533 (0.1671)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1688  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 0.9558 (0.9827)  loss/high_gen_loss: 62764793473894105488715415552.0000 (28062692539164074255065284608.0000)  loss/pix_loss: 0.1589 (0.1672)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [810/862]  eta: 0:03:36  lr: 0.000100  loss/low_gen_loss: 0.9558 (0.9825)  loss/high_gen_loss: 59128684618880067545654624256.0000 (28710173634357819180478103552.0000)  loss/pix_loss: 0.1805 (0.1673)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 0.9621 (0.9821)  loss/high_gen_loss: 109381029746632000901128126464.0000 (30567391380631527222618882048.0000)  loss/pix_loss: 0.1805 (0.1674)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 0.9484 (0.9821)  loss/high_gen_loss: 179470704761571144559388262400.0000 (32297083949357694842939899904.0000)  loss/pix_loss: 0.1531 (0.1672)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1694  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.0191 (0.9834)  loss/high_gen_loss: 139260358622845922879354175488.0000 (33354744759074333416333770752.0000)  loss/pix_loss: 0.1457 (0.1670)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 0.9954 (0.9832)  loss/high_gen_loss: 94752347308521454658272624640.0000 (33924287420206856490278977536.0000)  loss/pix_loss: 0.1483 (0.1670)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 0.9751 (0.9840)  loss/high_gen_loss: 114254880301539138593989066752.0000 (35305361417377002629411897344.0000)  loss/pix_loss: 0.1591 (0.1669)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1698  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 0.9751 (0.9841)  loss/high_gen_loss: 129374084390958320624481599488.0000 (35423720295866526759808663552.0000)  loss/pix_loss: 0.1591 (0.1668)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1696  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:33] Total time: 0:59:56 (4.1722 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 0.9751 (0.9841)  loss/high_gen_loss: 129374084390958320624481599488.0000 (35423720295866526759808663552.0000)  loss/pix_loss: 0.1591 (0.1668)  loss/enc_loss: 0.0009 (0.0013)\n",
      "Valid: [epoch:33]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1629 (0.1629)  time: 2.9896  data: 0.3525  max mem: 31350\n",
      "Valid: [epoch:33]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6104  data: 0.0253  max mem: 31350\n",
      "Valid: [epoch:33] Total time: 0:00:36 (2.6196 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_33_input_n_20.png\n",
      "Train: [epoch:34]  [  0/862]  eta: 1:15:22  lr: 0.000100  loss/low_gen_loss: 1.0138 (1.0138)  loss/high_gen_loss: 135459590293307186146982232064.0000 (135459590293307186146982232064.0000)  loss/pix_loss: 0.1514 (0.1514)  loss/enc_loss: 0.0014 (0.0014)  time: 5.2463  data: 1.0656  max mem: 31350\n",
      "Train: [epoch:34]  [ 10/862]  eta: 1:00:37  lr: 0.000100  loss/low_gen_loss: 0.9689 (0.9681)  loss/high_gen_loss: 81611861999089482668770852864.0000 (95346949058500441635490365440.0000)  loss/pix_loss: 0.1514 (0.1584)  loss/enc_loss: 0.0008 (0.0009)  time: 4.2692  data: 0.0970  max mem: 31350\n",
      "Train: [epoch:34]  [ 20/862]  eta: 0:59:14  lr: 0.000100  loss/low_gen_loss: 0.9532 (0.9605)  loss/high_gen_loss: 99892076541147119115955077120.0000 (100070838351237240739566977024.0000)  loss/pix_loss: 0.1600 (0.1643)  loss/enc_loss: 0.0010 (0.0010)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [ 30/862]  eta: 0:58:18  lr: 0.000100  loss/low_gen_loss: 0.9573 (0.9658)  loss/high_gen_loss: 91142636482146658031956393984.0000 (91240573488300493470747852800.0000)  loss/pix_loss: 0.1746 (0.1667)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [ 40/862]  eta: 0:57:29  lr: 0.000100  loss/low_gen_loss: 0.9529 (0.9623)  loss/high_gen_loss: 61125763959752674767236235264.0000 (82131091376966164714314792960.0000)  loss/pix_loss: 0.1806 (0.1713)  loss/enc_loss: 0.0017 (0.0013)  time: 4.1699  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:34]  [ 50/862]  eta: 0:56:43  lr: 0.000100  loss/low_gen_loss: 0.9529 (0.9699)  loss/high_gen_loss: 61125763959752674767236235264.0000 (81326881071161483456011042816.0000)  loss/pix_loss: 0.1716 (0.1697)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [ 60/862]  eta: 0:55:58  lr: 0.000100  loss/low_gen_loss: 0.9693 (0.9689)  loss/high_gen_loss: 80477077333255906923919704064.0000 (81343269586376026584848007168.0000)  loss/pix_loss: 0.1697 (0.1706)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [ 70/862]  eta: 0:55:14  lr: 0.000100  loss/low_gen_loss: 0.9504 (0.9724)  loss/high_gen_loss: 66035632003824659244142034944.0000 (77969762256838192450521530368.0000)  loss/pix_loss: 0.1697 (0.1692)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1685  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [ 80/862]  eta: 0:54:31  lr: 0.000100  loss/low_gen_loss: 1.0646 (1.0019)  loss/high_gen_loss: 53695885322327512906010198016.0000 (74568038862167639080598241280.0000)  loss/pix_loss: 0.1644 (0.1698)  loss/enc_loss: 0.0009 (0.0011)  time: 4.1684  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [ 90/862]  eta: 0:53:48  lr: 0.000100  loss/low_gen_loss: 1.0702 (1.0052)  loss/high_gen_loss: 50486565060569302018782396416.0000 (72455917312018819013991727104.0000)  loss/pix_loss: 0.1630 (0.1691)  loss/enc_loss: 0.0009 (0.0011)  time: 4.1690  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [100/862]  eta: 0:53:05  lr: 0.000100  loss/low_gen_loss: 1.0595 (1.0120)  loss/high_gen_loss: 56809048757761532077396721664.0000 (71384437793917570368990609408.0000)  loss/pix_loss: 0.1596 (0.1686)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [110/862]  eta: 0:52:23  lr: 0.000100  loss/low_gen_loss: 1.0371 (1.0088)  loss/high_gen_loss: 69359800218446259902966923264.0000 (72299510537350689543210139648.0000)  loss/pix_loss: 0.1647 (0.1687)  loss/enc_loss: 0.0033 (0.0016)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [120/862]  eta: 0:51:40  lr: 0.000100  loss/low_gen_loss: 0.9570 (1.0046)  loss/high_gen_loss: 64472259523105283108631478272.0000 (70142539839240297321062203392.0000)  loss/pix_loss: 0.1703 (0.1695)  loss/enc_loss: 0.0033 (0.0017)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [130/862]  eta: 0:50:58  lr: 0.000100  loss/low_gen_loss: 0.9690 (1.0057)  loss/high_gen_loss: 42382459993285392301461340160.0000 (67967118971999779135393103872.0000)  loss/pix_loss: 0.1785 (0.1701)  loss/enc_loss: 0.0030 (0.0018)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [140/862]  eta: 0:50:16  lr: 0.000100  loss/low_gen_loss: 1.0079 (1.0094)  loss/high_gen_loss: 39002083811601435690480435200.0000 (65273481105115878258252972032.0000)  loss/pix_loss: 0.1679 (0.1700)  loss/enc_loss: 0.0023 (0.0018)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [150/862]  eta: 0:49:34  lr: 0.000100  loss/low_gen_loss: 0.9732 (1.0110)  loss/high_gen_loss: 26259356347471849612860456960.0000 (62917798257397909852600139776.0000)  loss/pix_loss: 0.1661 (0.1698)  loss/enc_loss: 0.0010 (0.0017)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [160/862]  eta: 0:48:52  lr: 0.000100  loss/low_gen_loss: 0.9503 (1.0073)  loss/high_gen_loss: 28653223087334613034232446976.0000 (61022473646878484639902597120.0000)  loss/pix_loss: 0.1831 (0.1703)  loss/enc_loss: 0.0006 (0.0017)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [170/862]  eta: 0:48:10  lr: 0.000100  loss/low_gen_loss: 0.9673 (1.0076)  loss/high_gen_loss: 39302331872582287733167226880.0000 (60298136605115155612377808896.0000)  loss/pix_loss: 0.1739 (0.1704)  loss/enc_loss: 0.0005 (0.0016)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [180/862]  eta: 0:47:28  lr: 0.000100  loss/low_gen_loss: 0.9541 (1.0042)  loss/high_gen_loss: 45391759700295176496017833984.0000 (59310421266404573148314861568.0000)  loss/pix_loss: 0.1768 (0.1712)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [190/862]  eta: 0:46:46  lr: 0.000100  loss/low_gen_loss: 0.9493 (1.0054)  loss/high_gen_loss: 52739813893671656014626160640.0000 (59627552002158822143356305408.0000)  loss/pix_loss: 0.1814 (0.1715)  loss/enc_loss: 0.0005 (0.0015)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [200/862]  eta: 0:46:04  lr: 0.000100  loss/low_gen_loss: 0.9800 (1.0048)  loss/high_gen_loss: 57330095786015437251695083520.0000 (59726534617994845074904580096.0000)  loss/pix_loss: 0.1814 (0.1725)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [210/862]  eta: 0:45:22  lr: 0.000100  loss/low_gen_loss: 1.0230 (1.0064)  loss/high_gen_loss: 79397213789618105152903839744.0000 (62713614704041148991282348032.0000)  loss/pix_loss: 0.1760 (0.1721)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [220/862]  eta: 0:44:40  lr: 0.000100  loss/low_gen_loss: 1.0317 (1.0066)  loss/high_gen_loss: 162717127411362641277597253632.0000 (67921052570454701878888366080.0000)  loss/pix_loss: 0.1593 (0.1714)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [230/862]  eta: 0:43:58  lr: 0.000100  loss/low_gen_loss: 0.9681 (1.0046)  loss/high_gen_loss: 127482493272580055537683529728.0000 (68743877004240257008011313152.0000)  loss/pix_loss: 0.1564 (0.1706)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [240/862]  eta: 0:43:16  lr: 0.000100  loss/low_gen_loss: 0.9747 (1.0046)  loss/high_gen_loss: 63025609774742995993867845632.0000 (68200689859064158486662217728.0000)  loss/pix_loss: 0.1616 (0.1704)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [250/862]  eta: 0:42:34  lr: 0.000100  loss/low_gen_loss: 0.9997 (1.0038)  loss/high_gen_loss: 75988231872964165666040971264.0000 (69147275759147441135951020032.0000)  loss/pix_loss: 0.1555 (0.1699)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [260/862]  eta: 0:41:53  lr: 0.000100  loss/low_gen_loss: 0.9513 (1.0017)  loss/high_gen_loss: 81801247784518486920420917248.0000 (68676333275355457771945328640.0000)  loss/pix_loss: 0.1596 (0.1700)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [270/862]  eta: 0:41:11  lr: 0.000100  loss/low_gen_loss: 0.9513 (1.0000)  loss/high_gen_loss: 39563417348320701808096837632.0000 (67460035084477399228374581248.0000)  loss/pix_loss: 0.1794 (0.1706)  loss/enc_loss: 0.0027 (0.0014)  time: 4.1779  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [280/862]  eta: 0:40:29  lr: 0.000100  loss/low_gen_loss: 0.9546 (0.9984)  loss/high_gen_loss: 47894264481096356105530900480.0000 (66967379379811565783025188864.0000)  loss/pix_loss: 0.1635 (0.1701)  loss/enc_loss: 0.0034 (0.0015)  time: 4.1761  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [290/862]  eta: 0:39:47  lr: 0.000100  loss/low_gen_loss: 0.9504 (0.9969)  loss/high_gen_loss: 48735393509559165832413577216.0000 (66158470549680427368297005056.0000)  loss/pix_loss: 0.1625 (0.1700)  loss/enc_loss: 0.0021 (0.0015)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [300/862]  eta: 0:39:06  lr: 0.000100  loss/low_gen_loss: 0.9538 (0.9962)  loss/high_gen_loss: 46244080737322387282056970240.0000 (66378568735984912386612002816.0000)  loss/pix_loss: 0.1506 (0.1691)  loss/enc_loss: 0.0011 (0.0015)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [310/862]  eta: 0:38:24  lr: 0.000100  loss/low_gen_loss: 0.9700 (0.9954)  loss/high_gen_loss: 45420490577976955417497960448.0000 (65554226007904861453201440768.0000)  loss/pix_loss: 0.1437 (0.1682)  loss/enc_loss: 0.0006 (0.0015)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [320/862]  eta: 0:37:42  lr: 0.000100  loss/low_gen_loss: 0.9482 (0.9939)  loss/high_gen_loss: 38125950241584354718451236864.0000 (64675644881664127216939696128.0000)  loss/pix_loss: 0.1487 (0.1677)  loss/enc_loss: 0.0004 (0.0014)  time: 4.1734  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:34]  [330/862]  eta: 0:37:00  lr: 0.000100  loss/low_gen_loss: 0.9489 (0.9928)  loss/high_gen_loss: 64590639806097859374848409600.0000 (65279741055497563338111451136.0000)  loss/pix_loss: 0.1672 (0.1679)  loss/enc_loss: 0.0003 (0.0014)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [340/862]  eta: 0:36:18  lr: 0.000100  loss/low_gen_loss: 0.9489 (0.9915)  loss/high_gen_loss: 76768385705400162533924405248.0000 (65532346107505925091351330816.0000)  loss/pix_loss: 0.1706 (0.1677)  loss/enc_loss: 0.0003 (0.0014)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [350/862]  eta: 0:35:37  lr: 0.000100  loss/low_gen_loss: 0.9497 (0.9904)  loss/high_gen_loss: 71405439653862215686280970240.0000 (65421075089476352769408368640.0000)  loss/pix_loss: 0.1500 (0.1672)  loss/enc_loss: 0.0004 (0.0013)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [360/862]  eta: 0:34:55  lr: 0.000100  loss/low_gen_loss: 0.9556 (0.9896)  loss/high_gen_loss: 40319437526845993354115678208.0000 (64619657237239448409877774336.0000)  loss/pix_loss: 0.1546 (0.1672)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [370/862]  eta: 0:34:13  lr: 0.000100  loss/low_gen_loss: 0.9611 (0.9892)  loss/high_gen_loss: 40319437526845993354115678208.0000 (64441779759637887898232029184.0000)  loss/pix_loss: 0.1767 (0.1674)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [380/862]  eta: 0:33:31  lr: 0.000100  loss/low_gen_loss: 0.9592 (0.9884)  loss/high_gen_loss: 51310410227704808844182945792.0000 (63944085910858234183194509312.0000)  loss/pix_loss: 0.1675 (0.1674)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1698  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [390/862]  eta: 0:32:50  lr: 0.000100  loss/low_gen_loss: 0.9686 (0.9922)  loss/high_gen_loss: 38229684104930310780037890048.0000 (63261824194817220488466530304.0000)  loss/pix_loss: 0.1625 (0.1672)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [400/862]  eta: 0:32:08  lr: 0.000100  loss/low_gen_loss: 1.0348 (0.9979)  loss/high_gen_loss: 38444039403137488280755372032.0000 (62790549490332939526076366848.0000)  loss/pix_loss: 0.1637 (0.1672)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [410/862]  eta: 0:31:26  lr: 0.000100  loss/low_gen_loss: 1.0515 (0.9989)  loss/high_gen_loss: 68120788201969268218604290048.0000 (64065631982003501481903259648.0000)  loss/pix_loss: 0.1684 (0.1674)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1703  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [420/862]  eta: 0:30:44  lr: 0.000100  loss/low_gen_loss: 0.9680 (0.9978)  loss/high_gen_loss: 83168788449559741738564714496.0000 (63929617836423164751469608960.0000)  loss/pix_loss: 0.1749 (0.1675)  loss/enc_loss: 0.0018 (0.0013)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [430/862]  eta: 0:30:03  lr: 0.000100  loss/low_gen_loss: 0.9566 (0.9970)  loss/high_gen_loss: 37062140382805068306339332096.0000 (63198508173613972973009502208.0000)  loss/pix_loss: 0.1749 (0.1675)  loss/enc_loss: 0.0023 (0.0013)  time: 4.1740  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [440/862]  eta: 0:29:21  lr: 0.000100  loss/low_gen_loss: 0.9615 (0.9981)  loss/high_gen_loss: 27913266038400802586407993344.0000 (62344908610999403331681517568.0000)  loss/pix_loss: 0.1519 (0.1671)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1764  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [450/862]  eta: 0:28:39  lr: 0.000100  loss/low_gen_loss: 1.0122 (0.9989)  loss/high_gen_loss: 30050637442746501227998085120.0000 (61798618557854470284037324800.0000)  loss/pix_loss: 0.1480 (0.1672)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [460/862]  eta: 0:27:57  lr: 0.000100  loss/low_gen_loss: 1.0086 (0.9995)  loss/high_gen_loss: 44284756716480322873958858752.0000 (62007374762949605230009909248.0000)  loss/pix_loss: 0.1705 (0.1671)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [470/862]  eta: 0:27:16  lr: 0.000100  loss/low_gen_loss: 1.0008 (1.0023)  loss/high_gen_loss: 73751383818656817948024373248.0000 (62096005881744733323367809024.0000)  loss/pix_loss: 0.1652 (0.1670)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [480/862]  eta: 0:26:34  lr: 0.000100  loss/low_gen_loss: 0.9719 (1.0016)  loss/high_gen_loss: 30272588667441374553041797120.0000 (61292342754719387328140279808.0000)  loss/pix_loss: 0.1630 (0.1667)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [490/862]  eta: 0:25:52  lr: 0.000100  loss/low_gen_loss: 0.9693 (1.0009)  loss/high_gen_loss: 32579951098070931813389303808.0000 (60995323298576087296822476800.0000)  loss/pix_loss: 0.1621 (0.1668)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [500/862]  eta: 0:25:10  lr: 0.000100  loss/low_gen_loss: 0.9717 (1.0007)  loss/high_gen_loss: 50390922972191743094269411328.0000 (61558265021122376707631742976.0000)  loss/pix_loss: 0.1749 (0.1669)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 0.9686 (0.9998)  loss/high_gen_loss: 156549934013593096632190107648.0000 (64112626592321386707993755648.0000)  loss/pix_loss: 0.1769 (0.1671)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 0.9485 (0.9990)  loss/high_gen_loss: 147848841542644254975889244160.0000 (65105160920424325474548711424.0000)  loss/pix_loss: 0.1759 (0.1671)  loss/enc_loss: 0.0023 (0.0014)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [530/862]  eta: 0:23:05  lr: 0.000100  loss/low_gen_loss: 0.9464 (0.9985)  loss/high_gen_loss: 68508645605940317919295569920.0000 (64771717630445020509437427712.0000)  loss/pix_loss: 0.1673 (0.1670)  loss/enc_loss: 0.0021 (0.0014)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [540/862]  eta: 0:22:23  lr: 0.000100  loss/low_gen_loss: 0.9513 (0.9992)  loss/high_gen_loss: 42357681736349775273025077248.0000 (64371148574271024323341844480.0000)  loss/pix_loss: 0.1594 (0.1674)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 0.9542 (0.9983)  loss/high_gen_loss: 48451711510200220505136431104.0000 (64288758995476089961168502784.0000)  loss/pix_loss: 0.1799 (0.1676)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 0.9542 (0.9979)  loss/high_gen_loss: 57787957550728546573034192896.0000 (64179327592606903394453422080.0000)  loss/pix_loss: 0.1609 (0.1673)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [570/862]  eta: 0:20:18  lr: 0.000100  loss/low_gen_loss: 0.9585 (0.9972)  loss/high_gen_loss: 33103982661942010603462721536.0000 (63488042817090140403920797696.0000)  loss/pix_loss: 0.1694 (0.1675)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [580/862]  eta: 0:19:36  lr: 0.000100  loss/low_gen_loss: 0.9578 (0.9967)  loss/high_gen_loss: 27770452231225858775855398912.0000 (63045965200187510724338122752.0000)  loss/pix_loss: 0.1678 (0.1675)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 0.9869 (0.9979)  loss/high_gen_loss: 40874268364918347970272821248.0000 (62687592963752805011000655872.0000)  loss/pix_loss: 0.1598 (0.1672)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 1.0259 (0.9980)  loss/high_gen_loss: 23120208090465840218685571072.0000 (61809480567005950152204615680.0000)  loss/pix_loss: 0.1646 (0.1673)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1756  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:34]  [610/862]  eta: 0:17:31  lr: 0.000100  loss/low_gen_loss: 1.0524 (1.0046)  loss/high_gen_loss: 10472069626988133134695923712.0000 (61062578875426072996184326144.0000)  loss/pix_loss: 0.1684 (0.1673)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [620/862]  eta: 0:16:49  lr: 0.000100  loss/low_gen_loss: 1.1535 (1.0060)  loss/high_gen_loss: 26066088776793926512844734464.0000 (60532034286974680681680994304.0000)  loss/pix_loss: 0.1705 (0.1674)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.0005 (1.0058)  loss/high_gen_loss: 27131006030513445856759250944.0000 (59986832915355511166007771136.0000)  loss/pix_loss: 0.1713 (0.1674)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 0.9970 (1.0062)  loss/high_gen_loss: 35565483134572433083585265664.0000 (59897617992059130941643161600.0000)  loss/pix_loss: 0.1660 (0.1674)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 0.9726 (1.0054)  loss/high_gen_loss: 61055292084728811051712249856.0000 (60091878262542561445366726656.0000)  loss/pix_loss: 0.1711 (0.1676)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [660/862]  eta: 0:14:02  lr: 0.000100  loss/low_gen_loss: 0.9484 (1.0046)  loss/high_gen_loss: 72638506210937274487319560192.0000 (60290818460742864652141068288.0000)  loss/pix_loss: 0.1711 (0.1676)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 0.9490 (1.0038)  loss/high_gen_loss: 72638506210937274487319560192.0000 (60423879425995201424790650880.0000)  loss/pix_loss: 0.1603 (0.1674)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 0.9679 (1.0039)  loss/high_gen_loss: 56252602870352036042576494592.0000 (60279974490824818489231933440.0000)  loss/pix_loss: 0.1657 (0.1675)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.0005 (1.0037)  loss/high_gen_loss: 61485971907966522695201325056.0000 (61171176212189654702696169472.0000)  loss/pix_loss: 0.1773 (0.1676)  loss/enc_loss: 0.0021 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.0174 (1.0044)  loss/high_gen_loss: 192786644875307655347159695360.0000 (63536988045192443389288644608.0000)  loss/pix_loss: 0.1756 (0.1676)  loss/enc_loss: 0.0021 (0.0014)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 0.9731 (1.0037)  loss/high_gen_loss: 219371490332611295256374149120.0000 (65671757966194483451318501376.0000)  loss/pix_loss: 0.1647 (0.1677)  loss/enc_loss: 0.0018 (0.0014)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 0.9490 (1.0029)  loss/high_gen_loss: 212711140203035673561300729856.0000 (67531950320331738398924472320.0000)  loss/pix_loss: 0.1647 (0.1677)  loss/enc_loss: 0.0013 (0.0014)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 0.9497 (1.0023)  loss/high_gen_loss: 150457363450985858120449785856.0000 (68365806624788989894138527744.0000)  loss/pix_loss: 0.1604 (0.1675)  loss/enc_loss: 0.0011 (0.0014)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 0.9524 (1.0017)  loss/high_gen_loss: 124266920597598525240192794624.0000 (69154299030381734468398350336.0000)  loss/pix_loss: 0.1666 (0.1678)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 0.9855 (1.0033)  loss/high_gen_loss: 137404062471560625520883269632.0000 (70170261986352783652833722368.0000)  loss/pix_loss: 0.1694 (0.1677)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.3082 (1.0084)  loss/high_gen_loss: 121131080358313766032490102784.0000 (70596806657590813855351570432.0000)  loss/pix_loss: 0.1675 (0.1678)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [770/862]  eta: 0:06:23  lr: 0.000100  loss/low_gen_loss: 1.3480 (1.0118)  loss/high_gen_loss: 79072839158276272092820275200.0000 (70545936572311782554406486016.0000)  loss/pix_loss: 0.1782 (0.1678)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.1136 (1.0125)  loss/high_gen_loss: 66435153653008396968511143936.0000 (70535343243547119287760060416.0000)  loss/pix_loss: 0.1618 (0.1677)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.0946 (1.0137)  loss/high_gen_loss: 79188815756729067709623435264.0000 (70638053310478700551530872832.0000)  loss/pix_loss: 0.1573 (0.1677)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.1056 (1.0156)  loss/high_gen_loss: 57707389256164307556043325440.0000 (70276915119682884035229515776.0000)  loss/pix_loss: 0.1653 (0.1676)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [810/862]  eta: 0:03:36  lr: 0.000100  loss/low_gen_loss: 1.1938 (1.0180)  loss/high_gen_loss: 29736448955908217992640462848.0000 (69716946376897599411178176512.0000)  loss/pix_loss: 0.1662 (0.1677)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.1693 (1.0191)  loss/high_gen_loss: 24540736068628133890949644288.0000 (69250810252995958089659187200.0000)  loss/pix_loss: 0.1689 (0.1676)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.0065 (1.0190)  loss/high_gen_loss: 33479599691989462183760101376.0000 (68836826985704617771354030080.0000)  loss/pix_loss: 0.1649 (0.1676)  loss/enc_loss: 0.0036 (0.0014)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.0065 (1.0189)  loss/high_gen_loss: 27536539252229876639485394944.0000 (68275469221710451594638655488.0000)  loss/pix_loss: 0.1649 (0.1676)  loss/enc_loss: 0.0040 (0.0014)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.0223 (1.0191)  loss/high_gen_loss: 16995022503744662502276857856.0000 (67610360241235590655674155008.0000)  loss/pix_loss: 0.1624 (0.1674)  loss/enc_loss: 0.0036 (0.0014)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.0515 (1.0197)  loss/high_gen_loss: 10401155030106500389933154304.0000 (66952176550052317627072643072.0000)  loss/pix_loss: 0.1599 (0.1674)  loss/enc_loss: 0.0025 (0.0014)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.0515 (1.0196)  loss/high_gen_loss: 10401155030106500389933154304.0000 (66893194253726513176197988352.0000)  loss/pix_loss: 0.1608 (0.1674)  loss/enc_loss: 0.0024 (0.0014)  time: 4.1703  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:34] Total time: 0:59:57 (4.1732 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.0515 (1.0196)  loss/high_gen_loss: 10401155030106500389933154304.0000 (66893194253726513176197988352.0000)  loss/pix_loss: 0.1608 (0.1674)  loss/enc_loss: 0.0024 (0.0014)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:34]  [ 0/14]  eta: 0:00:40  L1_loss: 0.1614 (0.1614)  time: 2.9090  data: 0.3493  max mem: 31350\n",
      "Valid: [epoch:34]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5570  data: 0.0250  max mem: 31350\n",
      "Valid: [epoch:34] Total time: 0:00:35 (2.5667 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_34_input_n_20.png\n",
      "Train: [epoch:35]  [  0/862]  eta: 1:15:48  lr: 0.000100  loss/low_gen_loss: 1.0063 (1.0063)  loss/high_gen_loss: 17725680032482081901264240640.0000 (17725680032482081901264240640.0000)  loss/pix_loss: 0.1247 (0.1247)  loss/enc_loss: 0.0011 (0.0011)  time: 5.2767  data: 1.0820  max mem: 31350\n",
      "Train: [epoch:35]  [ 10/862]  eta: 1:00:22  lr: 0.000100  loss/low_gen_loss: 1.1624 (1.1345)  loss/high_gen_loss: 24261195584674665242524909568.0000 (23743095849738623999100846080.0000)  loss/pix_loss: 0.1643 (0.1579)  loss/enc_loss: 0.0008 (0.0008)  time: 4.2521  data: 0.0985  max mem: 31350\n",
      "Train: [epoch:35]  [ 20/862]  eta: 0:59:03  lr: 0.000100  loss/low_gen_loss: 1.0592 (1.0779)  loss/high_gen_loss: 22030968288176300767097913344.0000 (21954746425991705179914764288.0000)  loss/pix_loss: 0.1695 (0.1661)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1553  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [ 30/862]  eta: 0:58:11  lr: 0.000100  loss/low_gen_loss: 0.9761 (1.0400)  loss/high_gen_loss: 9550874645695699649331986432.0000 (16514550757618636618043752448.0000)  loss/pix_loss: 0.1637 (0.1655)  loss/enc_loss: 0.0005 (0.0006)  time: 4.1651  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [ 40/862]  eta: 0:57:23  lr: 0.000100  loss/low_gen_loss: 0.9703 (1.0267)  loss/high_gen_loss: 5822596412556443047107231744.0000 (47117971011390437658013466624.0000)  loss/pix_loss: 0.1642 (0.1658)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [ 50/862]  eta: 0:56:38  lr: 0.000100  loss/low_gen_loss: 0.9546 (1.0113)  loss/high_gen_loss: 409132836123265204050993348608.0000 (173832471504882047803503673344.0000)  loss/pix_loss: 0.1713 (0.1667)  loss/enc_loss: 0.0004 (0.0005)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [ 60/862]  eta: 0:55:54  lr: 0.000100  loss/low_gen_loss: 0.9628 (1.0063)  loss/high_gen_loss: 735331849863692328430674640896.0000 (263847034913475780905313239040.0000)  loss/pix_loss: 0.1681 (0.1659)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [ 70/862]  eta: 0:55:12  lr: 0.000100  loss/low_gen_loss: 0.9534 (0.9977)  loss/high_gen_loss: 571255228699775242210377728000.0000 (296263800446286746164383449088.0000)  loss/pix_loss: 0.1662 (0.1668)  loss/enc_loss: 0.0005 (0.0005)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [ 80/862]  eta: 0:54:29  lr: 0.000100  loss/low_gen_loss: 0.9475 (0.9943)  loss/high_gen_loss: 429638824770227858898168053760.0000 (310628576515170106206119264256.0000)  loss/pix_loss: 0.1662 (0.1652)  loss/enc_loss: 0.0006 (0.0005)  time: 4.1752  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [ 90/862]  eta: 0:53:47  lr: 0.000100  loss/low_gen_loss: 0.9605 (0.9899)  loss/high_gen_loss: 380890062241155689100154503168.0000 (312385649899860786624809926656.0000)  loss/pix_loss: 0.1683 (0.1664)  loss/enc_loss: 0.0007 (0.0005)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [100/862]  eta: 0:53:04  lr: 0.000100  loss/low_gen_loss: 0.9607 (0.9897)  loss/high_gen_loss: 244717791287719747576102125568.0000 (302599110538497040343747264512.0000)  loss/pix_loss: 0.1712 (0.1667)  loss/enc_loss: 0.0007 (0.0006)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [110/862]  eta: 0:52:22  lr: 0.000100  loss/low_gen_loss: 0.9444 (0.9854)  loss/high_gen_loss: 157330560082677380464594911232.0000 (286088062312555888226366128128.0000)  loss/pix_loss: 0.1701 (0.1670)  loss/enc_loss: 0.0008 (0.0006)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [120/862]  eta: 0:51:40  lr: 0.000100  loss/low_gen_loss: 0.9434 (0.9868)  loss/high_gen_loss: 82527349410191557829188386816.0000 (266701249271532317977534791680.0000)  loss/pix_loss: 0.1740 (0.1675)  loss/enc_loss: 0.0009 (0.0006)  time: 4.1750  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [130/862]  eta: 0:50:58  lr: 0.000100  loss/low_gen_loss: 1.0978 (1.0255)  loss/high_gen_loss: 41541094846498439092317978624.0000 (249454873277657823713016414208.0000)  loss/pix_loss: 0.1728 (0.1678)  loss/enc_loss: 0.0013 (0.0007)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [140/862]  eta: 0:50:16  lr: 0.000100  loss/low_gen_loss: 1.0978 (1.0261)  loss/high_gen_loss: 43823697909658310802810077184.0000 (235968336224582464805575589888.0000)  loss/pix_loss: 0.1602 (0.1674)  loss/enc_loss: 0.0012 (0.0007)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [150/862]  eta: 0:49:34  lr: 0.000100  loss/low_gen_loss: 1.1548 (1.0479)  loss/high_gen_loss: 68942243851664443003526709248.0000 (225242308823282957354256039936.0000)  loss/pix_loss: 0.1633 (0.1667)  loss/enc_loss: 0.0011 (0.0007)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [160/862]  eta: 0:48:52  lr: 0.000100  loss/low_gen_loss: 1.2590 (1.0538)  loss/high_gen_loss: 76181286937150359632022077440.0000 (216234598032431422782446764032.0000)  loss/pix_loss: 0.1633 (0.1663)  loss/enc_loss: 0.0009 (0.0008)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [170/862]  eta: 0:48:10  lr: 0.000100  loss/low_gen_loss: 1.1591 (1.0653)  loss/high_gen_loss: 83311847819791794770668421120.0000 (208877707237134499594482221056.0000)  loss/pix_loss: 0.1614 (0.1659)  loss/enc_loss: 0.0010 (0.0008)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [180/862]  eta: 0:47:29  lr: 0.000100  loss/low_gen_loss: 1.4451 (1.0910)  loss/high_gen_loss: 89445285741941787192088068096.0000 (202262738737888023991306682368.0000)  loss/pix_loss: 0.1633 (0.1662)  loss/enc_loss: 0.0019 (0.0009)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [190/862]  eta: 0:46:47  lr: 0.000100  loss/low_gen_loss: 1.4145 (1.1048)  loss/high_gen_loss: 89444983510486883534794391552.0000 (196428130997748490269615980544.0000)  loss/pix_loss: 0.1747 (0.1665)  loss/enc_loss: 0.0039 (0.0012)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [200/862]  eta: 0:46:05  lr: 0.000100  loss/low_gen_loss: 1.3665 (1.1188)  loss/high_gen_loss: 83465438067280647111598669824.0000 (189161190325357445353505292288.0000)  loss/pix_loss: 0.1852 (0.1677)  loss/enc_loss: 0.0045 (0.0014)  time: 4.1729  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [210/862]  eta: 0:45:23  lr: 0.000100  loss/low_gen_loss: 1.3748 (1.1310)  loss/high_gen_loss: 29115934722425629481206022144.0000 (181313587064608026385958567936.0000)  loss/pix_loss: 0.1893 (0.1674)  loss/enc_loss: 0.0036 (0.0014)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [220/862]  eta: 0:44:41  lr: 0.000100  loss/low_gen_loss: 1.1434 (1.1295)  loss/high_gen_loss: 25265978223601322524288221184.0000 (174298596067750104758761816064.0000)  loss/pix_loss: 0.1633 (0.1672)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1757  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [230/862]  eta: 0:43:59  lr: 0.000100  loss/low_gen_loss: 1.1526 (1.1326)  loss/high_gen_loss: 20994956639698426521536430080.0000 (167414352710304144320614105088.0000)  loss/pix_loss: 0.1620 (0.1671)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [240/862]  eta: 0:43:17  lr: 0.000100  loss/low_gen_loss: 1.1973 (1.1349)  loss/high_gen_loss: 11691915919094398363958771712.0000 (160797152479999854635632295936.0000)  loss/pix_loss: 0.1634 (0.1670)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [250/862]  eta: 0:42:35  lr: 0.000100  loss/low_gen_loss: 1.2478 (1.1414)  loss/high_gen_loss: 4931829999696380120677744640.0000 (154531663180271509768798994432.0000)  loss/pix_loss: 0.1642 (0.1669)  loss/enc_loss: 0.0002 (0.0013)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [260/862]  eta: 0:41:54  lr: 0.000100  loss/low_gen_loss: 1.4588 (1.1586)  loss/high_gen_loss: 2946475704504927869456089088.0000 (148721989537948253188574412800.0000)  loss/pix_loss: 0.1642 (0.1667)  loss/enc_loss: 0.0002 (0.0013)  time: 4.1731  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:35]  [270/862]  eta: 0:41:12  lr: 0.000100  loss/low_gen_loss: 1.5295 (1.1769)  loss/high_gen_loss: 2803161916778610235216494592.0000 (143336097079875418707286032384.0000)  loss/pix_loss: 0.1727 (0.1674)  loss/enc_loss: 0.0003 (0.0012)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [280/862]  eta: 0:40:30  lr: 0.000100  loss/low_gen_loss: 1.5245 (1.1878)  loss/high_gen_loss: 2699130249196328206628552704.0000 (138333950488875399621275287552.0000)  loss/pix_loss: 0.1739 (0.1674)  loss/enc_loss: 0.0003 (0.0012)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [290/862]  eta: 0:39:48  lr: 0.000100  loss/low_gen_loss: 1.5194 (1.2043)  loss/high_gen_loss: 1959270008775416586530979840.0000 (133643228698401028653017202688.0000)  loss/pix_loss: 0.1677 (0.1673)  loss/enc_loss: 0.0003 (0.0012)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [300/862]  eta: 0:39:06  lr: 0.000100  loss/low_gen_loss: 1.7286 (1.2223)  loss/high_gen_loss: 1208780533058304638277648384.0000 (129219980691162465630423089152.0000)  loss/pix_loss: 0.1564 (0.1667)  loss/enc_loss: 0.0003 (0.0011)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [310/862]  eta: 0:38:25  lr: 0.000100  loss/low_gen_loss: 1.6423 (1.2297)  loss/high_gen_loss: 1208780533058304638277648384.0000 (125251092266940825152954302464.0000)  loss/pix_loss: 0.1547 (0.1661)  loss/enc_loss: 0.0005 (0.0011)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [320/862]  eta: 0:37:43  lr: 0.000100  loss/low_gen_loss: 1.7899 (1.2550)  loss/high_gen_loss: 7743655688083625078744416256.0000 (121647908906639059266759032832.0000)  loss/pix_loss: 0.1542 (0.1659)  loss/enc_loss: 0.0012 (0.0011)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [330/862]  eta: 0:37:01  lr: 0.000100  loss/low_gen_loss: 1.7162 (1.2613)  loss/high_gen_loss: 12132493822480204783815753728.0000 (118645233655846116483716349952.0000)  loss/pix_loss: 0.1542 (0.1657)  loss/enc_loss: 0.0011 (0.0011)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [340/862]  eta: 0:36:19  lr: 0.000100  loss/low_gen_loss: 1.4364 (1.2664)  loss/high_gen_loss: 32050864240879941068114624512.0000 (116548717384781435071300108288.0000)  loss/pix_loss: 0.1679 (0.1658)  loss/enc_loss: 0.0009 (0.0011)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [350/862]  eta: 0:35:37  lr: 0.000100  loss/low_gen_loss: 1.3601 (1.2647)  loss/high_gen_loss: 58625563693795135544587452416.0000 (115167127962488202246511132672.0000)  loss/pix_loss: 0.1679 (0.1656)  loss/enc_loss: 0.0010 (0.0011)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [360/862]  eta: 0:34:56  lr: 0.000100  loss/low_gen_loss: 0.9991 (1.2568)  loss/high_gen_loss: 60902740757866190032729014272.0000 (113642127920099341308644032512.0000)  loss/pix_loss: 0.1646 (0.1658)  loss/enc_loss: 0.0009 (0.0011)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [370/862]  eta: 0:34:14  lr: 0.000100  loss/low_gen_loss: 0.9894 (1.2544)  loss/high_gen_loss: 56959526965738173322131144704.0000 (111836428592514245240530403328.0000)  loss/pix_loss: 0.1741 (0.1661)  loss/enc_loss: 0.0007 (0.0011)  time: 4.1745  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [380/862]  eta: 0:33:32  lr: 0.000100  loss/low_gen_loss: 1.2919 (1.2563)  loss/high_gen_loss: 37978487264607025742185758720.0000 (109806522368002878726526205952.0000)  loss/pix_loss: 0.1646 (0.1656)  loss/enc_loss: 0.0012 (0.0011)  time: 4.1756  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [390/862]  eta: 0:32:50  lr: 0.000100  loss/low_gen_loss: 1.2375 (1.2506)  loss/high_gen_loss: 32876475573080041140825096192.0000 (107830420278183359378083545088.0000)  loss/pix_loss: 0.1566 (0.1657)  loss/enc_loss: 0.0016 (0.0011)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [400/862]  eta: 0:32:09  lr: 0.000100  loss/low_gen_loss: 1.0060 (1.2465)  loss/high_gen_loss: 31104110041294785986737209344.0000 (105922012085800752611648864256.0000)  loss/pix_loss: 0.1694 (0.1658)  loss/enc_loss: 0.0024 (0.0012)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [410/862]  eta: 0:31:27  lr: 0.000100  loss/low_gen_loss: 1.0665 (1.2435)  loss/high_gen_loss: 38252691474434851691519016960.0000 (104798070396352574363873050624.0000)  loss/pix_loss: 0.1697 (0.1659)  loss/enc_loss: 0.0051 (0.0013)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [420/862]  eta: 0:30:45  lr: 0.000100  loss/low_gen_loss: 1.1145 (1.2419)  loss/high_gen_loss: 83920343630575480035034005504.0000 (104549838292637438592585564160.0000)  loss/pix_loss: 0.1685 (0.1659)  loss/enc_loss: 0.0025 (0.0013)  time: 4.1751  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [430/862]  eta: 0:30:03  lr: 0.000100  loss/low_gen_loss: 1.2663 (1.2444)  loss/high_gen_loss: 87936357424403415196246212608.0000 (103951992347845441407164612608.0000)  loss/pix_loss: 0.1567 (0.1657)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1769  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [440/862]  eta: 0:29:22  lr: 0.000100  loss/low_gen_loss: 1.1616 (1.2403)  loss/high_gen_loss: 72348699302250047230200250368.0000 (103172579497239973394907136000.0000)  loss/pix_loss: 0.1634 (0.1659)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1748  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [450/862]  eta: 0:28:40  lr: 0.000100  loss/low_gen_loss: 1.2590 (1.2432)  loss/high_gen_loss: 65727091467299888104459993088.0000 (102071164337663467933227024384.0000)  loss/pix_loss: 0.1753 (0.1659)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [460/862]  eta: 0:27:58  lr: 0.000100  loss/low_gen_loss: 1.4439 (1.2504)  loss/high_gen_loss: 40728148901205395408070639616.0000 (100696330306449267428689969152.0000)  loss/pix_loss: 0.1679 (0.1660)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1742  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [470/862]  eta: 0:27:16  lr: 0.000100  loss/low_gen_loss: 1.6216 (1.2581)  loss/high_gen_loss: 33602839290092911314901925888.0000 (99179716351567849985163657216.0000)  loss/pix_loss: 0.1641 (0.1658)  loss/enc_loss: 0.0003 (0.0013)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [480/862]  eta: 0:26:34  lr: 0.000100  loss/low_gen_loss: 1.4762 (1.2600)  loss/high_gen_loss: 26857491286192118875627192320.0000 (97642978733306489603054632960.0000)  loss/pix_loss: 0.1641 (0.1659)  loss/enc_loss: 0.0005 (0.0012)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [490/862]  eta: 0:25:53  lr: 0.000100  loss/low_gen_loss: 1.2567 (1.2596)  loss/high_gen_loss: 26857491286192118875627192320.0000 (96260605743785657990129909760.0000)  loss/pix_loss: 0.1617 (0.1658)  loss/enc_loss: 0.0005 (0.0012)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [500/862]  eta: 0:25:11  lr: 0.000100  loss/low_gen_loss: 1.2567 (1.2602)  loss/high_gen_loss: 28143637242534632488867725312.0000 (94873767547855065540261314560.0000)  loss/pix_loss: 0.1609 (0.1656)  loss/enc_loss: 0.0004 (0.0012)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [510/862]  eta: 0:24:29  lr: 0.000100  loss/low_gen_loss: 1.3251 (1.2657)  loss/high_gen_loss: 28499911459468250002369806336.0000 (93741680870189135698780487680.0000)  loss/pix_loss: 0.1649 (0.1655)  loss/enc_loss: 0.0003 (0.0012)  time: 4.1739  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [520/862]  eta: 0:23:47  lr: 0.000100  loss/low_gen_loss: 1.2930 (1.2629)  loss/high_gen_loss: 39653437459400404419982917632.0000 (92770122072923383656978841600.0000)  loss/pix_loss: 0.1679 (0.1657)  loss/enc_loss: 0.0004 (0.0012)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [530/862]  eta: 0:23:06  lr: 0.000100  loss/low_gen_loss: 1.0636 (1.2591)  loss/high_gen_loss: 34629760383091261493427044352.0000 (91483480247721732260860264448.0000)  loss/pix_loss: 0.1674 (0.1656)  loss/enc_loss: 0.0004 (0.0012)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [540/862]  eta: 0:22:24  lr: 0.000100  loss/low_gen_loss: 1.1542 (1.2580)  loss/high_gen_loss: 13620433582185462641505337344.0000 (90020937385887643001084182528.0000)  loss/pix_loss: 0.1745 (0.1659)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1756  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:35]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.2869 (1.2672)  loss/high_gen_loss: 12820032603454162169768181760.0000 (88630408814850361936356311040.0000)  loss/pix_loss: 0.1693 (0.1660)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1738  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [560/862]  eta: 0:21:00  lr: 0.000100  loss/low_gen_loss: 1.3449 (1.2689)  loss/high_gen_loss: 12555058258917104942005092352.0000 (87237658059504985149146136576.0000)  loss/pix_loss: 0.1607 (0.1659)  loss/enc_loss: 0.0017 (0.0012)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [570/862]  eta: 0:20:19  lr: 0.000100  loss/low_gen_loss: 1.0949 (1.2646)  loss/high_gen_loss: 9460663869069251175520403456.0000 (85871956743437215241101901824.0000)  loss/pix_loss: 0.1677 (0.1663)  loss/enc_loss: 0.0021 (0.0012)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [580/862]  eta: 0:19:37  lr: 0.000100  loss/low_gen_loss: 1.0573 (1.2665)  loss/high_gen_loss: 7577725306679223996165128192.0000 (84498459313825709399079911424.0000)  loss/pix_loss: 0.1703 (0.1662)  loss/enc_loss: 0.0038 (0.0013)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.2912 (1.2685)  loss/high_gen_loss: 4234772108484578247385808896.0000 (83115025999199176653780549632.0000)  loss/pix_loss: 0.1563 (0.1660)  loss/enc_loss: 0.0031 (0.0013)  time: 4.1730  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [600/862]  eta: 0:18:13  lr: 0.000100  loss/low_gen_loss: 1.1041 (1.2649)  loss/high_gen_loss: 1465792451196409580343001088.0000 (81751417974923731367167524864.0000)  loss/pix_loss: 0.1565 (0.1660)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [610/862]  eta: 0:17:32  lr: 0.000100  loss/low_gen_loss: 1.1041 (1.2665)  loss/high_gen_loss: 930126599625018470903578624.0000 (80424136102670639085255655424.0000)  loss/pix_loss: 0.1657 (0.1661)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1689  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.5053 (1.2711)  loss/high_gen_loss: 119685629943464175217934336.0000 (79129610637841455090336006144.0000)  loss/pix_loss: 0.1809 (0.1664)  loss/enc_loss: 0.0005 (0.0012)  time: 4.1689  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.5204 (1.2733)  loss/high_gen_loss: 119685629943464175217934336.0000 (77904599930489049490625921024.0000)  loss/pix_loss: 0.1682 (0.1664)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 1.2459 (1.2724)  loss/high_gen_loss: 4536250345934217832650768384.0000 (76881585179712262929314217984.0000)  loss/pix_loss: 0.1656 (0.1664)  loss/enc_loss: 0.0018 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 1.2664 (1.2757)  loss/high_gen_loss: 19330919833846959593828122624.0000 (76133112291573339985283121152.0000)  loss/pix_loss: 0.1715 (0.1665)  loss/enc_loss: 0.0018 (0.0013)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.3076 (1.2730)  loss/high_gen_loss: 29539139039520958476321816576.0000 (75447285759813329975844536320.0000)  loss/pix_loss: 0.1613 (0.1664)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.1069 (1.2709)  loss/high_gen_loss: 27211571963894443438927511552.0000 (74703576417362669509139234816.0000)  loss/pix_loss: 0.1609 (0.1664)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.0989 (1.2682)  loss/high_gen_loss: 26200118982310732783299854336.0000 (74006877606243401849366380544.0000)  loss/pix_loss: 0.1653 (0.1664)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.1059 (1.2713)  loss/high_gen_loss: 29179764588991337040736944128.0000 (73414709779831279888711548928.0000)  loss/pix_loss: 0.1710 (0.1666)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.7961 (1.2793)  loss/high_gen_loss: 38237756990432776438530703360.0000 (72947348486590123050849533952.0000)  loss/pix_loss: 0.1710 (0.1665)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.8436 (1.2889)  loss/high_gen_loss: 44812282831548725201490411520.0000 (72698410159831492999470120960.0000)  loss/pix_loss: 0.1756 (0.1667)  loss/enc_loss: 0.0005 (0.0012)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 2.0151 (1.2994)  loss/high_gen_loss: 64890061452944209229622804480.0000 (72945795699690690849366081536.0000)  loss/pix_loss: 0.1746 (0.1668)  loss/enc_loss: 0.0005 (0.0012)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 1.1803 (1.2959)  loss/high_gen_loss: 104085405751673843715651141632.0000 (73566148960534267163079344128.0000)  loss/pix_loss: 0.1678 (0.1668)  loss/enc_loss: 0.0005 (0.0012)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.0920 (1.2963)  loss/high_gen_loss: 115854440276616744820772175872.0000 (74058658212365166716418785280.0000)  loss/pix_loss: 0.1673 (0.1669)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.6530 (1.3017)  loss/high_gen_loss: 98059071101355334847678119936.0000 (74252896516480880008369274880.0000)  loss/pix_loss: 0.1669 (0.1669)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.6530 (1.3038)  loss/high_gen_loss: 79406724635714604618364223488.0000 (74274012336528688056476106752.0000)  loss/pix_loss: 0.1669 (0.1669)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.4409 (1.3065)  loss/high_gen_loss: 83240247299178525209938362368.0000 (74736153147550229475295756288.0000)  loss/pix_loss: 0.1577 (0.1668)  loss/enc_loss: 0.0017 (0.0012)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.4409 (1.3081)  loss/high_gen_loss: 120921038941888689952675332096.0000 (75658317282444584731300331520.0000)  loss/pix_loss: 0.1598 (0.1668)  loss/enc_loss: 0.0022 (0.0012)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.9602 (1.3265)  loss/high_gen_loss: 169608873498598875588141776896.0000 (77245471113131380548428627968.0000)  loss/pix_loss: 0.1739 (0.1669)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 2.4714 (1.3398)  loss/high_gen_loss: 194160381285174435139823861760.0000 (78654384851594007156690518016.0000)  loss/pix_loss: 0.1725 (0.1668)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 2.3181 (1.3511)  loss/high_gen_loss: 182480873384013776768664076288.0000 (79840466560852559455215157248.0000)  loss/pix_loss: 0.1725 (0.1670)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 2.2805 (1.3613)  loss/high_gen_loss: 164685201977297463138276343808.0000 (80704739256020206428285304832.0000)  loss/pix_loss: 0.1805 (0.1672)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1736  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:35]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.9037 (1.3684)  loss/high_gen_loss: 143475080153540046971868282880.0000 (81458589968168115355363835904.0000)  loss/pix_loss: 0.1808 (0.1672)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1763  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 2.0413 (1.3774)  loss/high_gen_loss: 143475080153540046971868282880.0000 (82211598324951874755910172672.0000)  loss/pix_loss: 0.1663 (0.1672)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1764  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 2.0413 (1.3829)  loss/high_gen_loss: 150947922881226356865248526336.0000 (83204164195854277968910090240.0000)  loss/pix_loss: 0.1700 (0.1672)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 2.0712 (1.3929)  loss/high_gen_loss: 180845215639541114973867474944.0000 (84433964416226373003997347840.0000)  loss/pix_loss: 0.1709 (0.1672)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 2.0712 (1.3944)  loss/high_gen_loss: 184926001412048090188830736384.0000 (84582011265982277639322206208.0000)  loss/pix_loss: 0.1709 (0.1673)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:35] Total time: 0:59:58 (4.1741 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 2.0712 (1.3944)  loss/high_gen_loss: 184926001412048090188830736384.0000 (84582011265982277639322206208.0000)  loss/pix_loss: 0.1709 (0.1673)  loss/enc_loss: 0.0009 (0.0013)\n",
      "Valid: [epoch:35]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1329 (0.1329)  time: 2.9870  data: 0.3979  max mem: 31350\n",
      "Valid: [epoch:35]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.6002  data: 0.0285  max mem: 31350\n",
      "Valid: [epoch:35] Total time: 0:00:36 (2.6104 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_35_input_n_20.png\n",
      "Train: [epoch:36]  [  0/862]  eta: 1:20:17  lr: 0.000100  loss/low_gen_loss: 2.6238 (2.6238)  loss/high_gen_loss: 224667416559024356099144810496.0000 (224667416559024356099144810496.0000)  loss/pix_loss: 0.1935 (0.1935)  loss/enc_loss: 0.0009 (0.0009)  time: 5.5889  data: 1.4077  max mem: 31350\n",
      "Train: [epoch:36]  [ 10/862]  eta: 1:01:01  lr: 0.000100  loss/low_gen_loss: 2.6114 (2.3706)  loss/high_gen_loss: 230013550985883287009827487744.0000 (239438711030469217648109420544.0000)  loss/pix_loss: 0.1585 (0.1655)  loss/enc_loss: 0.0007 (0.0007)  time: 4.2976  data: 0.1281  max mem: 31350\n",
      "Train: [epoch:36]  [ 20/862]  eta: 0:59:27  lr: 0.000100  loss/low_gen_loss: 1.4078 (1.8199)  loss/high_gen_loss: 247308708213813212683306008576.0000 (248834628955204506144133349376.0000)  loss/pix_loss: 0.1614 (0.1636)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [ 30/862]  eta: 0:58:27  lr: 0.000100  loss/low_gen_loss: 1.2411 (1.6856)  loss/high_gen_loss: 277900179400376842899047841792.0000 (274461796944006980985228886016.0000)  loss/pix_loss: 0.1702 (0.1671)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [ 40/862]  eta: 0:57:35  lr: 0.000100  loss/low_gen_loss: 1.1309 (1.5381)  loss/high_gen_loss: 339965165385174495663545647104.0000 (292194986381680387655605420032.0000)  loss/pix_loss: 0.1779 (0.1703)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [ 50/862]  eta: 0:56:48  lr: 0.000100  loss/low_gen_loss: 1.2033 (1.6898)  loss/high_gen_loss: 346852378000587175114685022208.0000 (302668316767598195438094647296.0000)  loss/pix_loss: 0.1680 (0.1663)  loss/enc_loss: 0.0006 (0.0006)  time: 4.1684  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [ 60/862]  eta: 0:56:02  lr: 0.000100  loss/low_gen_loss: 2.5186 (1.8272)  loss/high_gen_loss: 334722469673756341461623767040.0000 (307070314580906624584020656128.0000)  loss/pix_loss: 0.1575 (0.1644)  loss/enc_loss: 0.0008 (0.0007)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [ 70/862]  eta: 0:55:18  lr: 0.000100  loss/low_gen_loss: 2.6271 (1.9573)  loss/high_gen_loss: 321247782488331684680348729344.0000 (303485823457326735148217008128.0000)  loss/pix_loss: 0.1597 (0.1663)  loss/enc_loss: 0.0015 (0.0008)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [ 80/862]  eta: 0:54:34  lr: 0.000100  loss/low_gen_loss: 2.0187 (1.9448)  loss/high_gen_loss: 234591885291025408044505759744.0000 (288226403869013778384767942656.0000)  loss/pix_loss: 0.1577 (0.1644)  loss/enc_loss: 0.0017 (0.0010)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [ 90/862]  eta: 0:53:51  lr: 0.000100  loss/low_gen_loss: 1.9160 (1.9713)  loss/high_gen_loss: 234591885291025408044505759744.0000 (289434054189678150200202362880.0000)  loss/pix_loss: 0.1524 (0.1640)  loss/enc_loss: 0.0018 (0.0011)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [100/862]  eta: 0:53:08  lr: 0.000100  loss/low_gen_loss: 2.5554 (2.0420)  loss/high_gen_loss: 392904140362894696095414222848.0000 (311167378503212256139214323712.0000)  loss/pix_loss: 0.1563 (0.1636)  loss/enc_loss: 0.0018 (0.0012)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [110/862]  eta: 0:52:26  lr: 0.000100  loss/low_gen_loss: 2.8614 (2.1834)  loss/high_gen_loss: 549693205570447345821935468544.0000 (335711976052724702903565025280.0000)  loss/pix_loss: 0.1530 (0.1631)  loss/enc_loss: 0.0021 (0.0013)  time: 4.1731  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [120/862]  eta: 0:51:43  lr: 0.000100  loss/low_gen_loss: 2.7170 (2.1694)  loss/high_gen_loss: 505844446061864445811976306688.0000 (335417487668515821611680530432.0000)  loss/pix_loss: 0.1654 (0.1643)  loss/enc_loss: 0.0026 (0.0014)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [130/862]  eta: 0:51:01  lr: 0.000100  loss/low_gen_loss: 1.5806 (2.1201)  loss/high_gen_loss: 218373106500268926343875395584.0000 (325702395045357333767339900928.0000)  loss/pix_loss: 0.1766 (0.1652)  loss/enc_loss: 0.0025 (0.0015)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [140/862]  eta: 0:50:18  lr: 0.000100  loss/low_gen_loss: 1.8376 (2.1911)  loss/high_gen_loss: 220134114740662880001224343552.0000 (319501171035253988643007627264.0000)  loss/pix_loss: 0.1687 (0.1648)  loss/enc_loss: 0.0023 (0.0015)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [150/862]  eta: 0:49:36  lr: 0.000100  loss/low_gen_loss: 2.6992 (2.1890)  loss/high_gen_loss: 222851836651554360821706391552.0000 (313362433792810267533109100544.0000)  loss/pix_loss: 0.1671 (0.1650)  loss/enc_loss: 0.0014 (0.0015)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [160/862]  eta: 0:48:54  lr: 0.000100  loss/low_gen_loss: 1.5007 (2.1435)  loss/high_gen_loss: 288154987112587592266397253632.0000 (329539210370846849831341654016.0000)  loss/pix_loss: 0.1712 (0.1653)  loss/enc_loss: 0.0006 (0.0014)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [170/862]  eta: 0:48:12  lr: 0.000100  loss/low_gen_loss: 1.4646 (2.1091)  loss/high_gen_loss: 662297240996904913842120687616.0000 (353552632237407759184422764544.0000)  loss/pix_loss: 0.1684 (0.1651)  loss/enc_loss: 0.0007 (0.0014)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [180/862]  eta: 0:47:30  lr: 0.000100  loss/low_gen_loss: 1.4104 (2.0729)  loss/high_gen_loss: 527792116527649408907149836288.0000 (353397023315641749389610844160.0000)  loss/pix_loss: 0.1823 (0.1662)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [190/862]  eta: 0:46:47  lr: 0.000100  loss/low_gen_loss: 1.7068 (2.1367)  loss/high_gen_loss: 219061155296823033651510902784.0000 (341687255639130281838576140288.0000)  loss/pix_loss: 0.1820 (0.1664)  loss/enc_loss: 0.0004 (0.0013)  time: 4.1704  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [200/862]  eta: 0:46:05  lr: 0.000100  loss/low_gen_loss: 2.8377 (2.1640)  loss/high_gen_loss: 76915194634619614064327786496.0000 (327367702871368036996775673856.0000)  loss/pix_loss: 0.1809 (0.1669)  loss/enc_loss: 0.0004 (0.0013)  time: 4.1708  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:36]  [210/862]  eta: 0:45:23  lr: 0.000100  loss/low_gen_loss: 2.2081 (2.1567)  loss/high_gen_loss: 28303328787519352411414069248.0000 (312744019903113691453844357120.0000)  loss/pix_loss: 0.1650 (0.1667)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [220/862]  eta: 0:44:42  lr: 0.000100  loss/low_gen_loss: 1.5535 (2.1238)  loss/high_gen_loss: 20202496320208071358226104320.0000 (299546884918965017770505273344.0000)  loss/pix_loss: 0.1533 (0.1661)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [230/862]  eta: 0:44:00  lr: 0.000100  loss/low_gen_loss: 1.5724 (2.1128)  loss/high_gen_loss: 20207969542961717277028777984.0000 (287451982474055722619480571904.0000)  loss/pix_loss: 0.1594 (0.1665)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [240/862]  eta: 0:43:18  lr: 0.000100  loss/low_gen_loss: 1.9226 (2.1099)  loss/high_gen_loss: 14014712223981594342275940352.0000 (275944055911828894867789971456.0000)  loss/pix_loss: 0.1575 (0.1660)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [250/862]  eta: 0:42:36  lr: 0.000100  loss/low_gen_loss: 1.6884 (2.0824)  loss/high_gen_loss: 16748033291957614318310129664.0000 (291271632778116755759057338368.0000)  loss/pix_loss: 0.1537 (0.1658)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [260/862]  eta: 0:41:54  lr: 0.000100  loss/low_gen_loss: 1.3632 (2.0622)  loss/high_gen_loss: 876065851281716621316833935360.0000 (321759073127645684407646289920.0000)  loss/pix_loss: 0.1562 (0.1655)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [270/862]  eta: 0:41:12  lr: 0.000100  loss/low_gen_loss: 1.3253 (2.0300)  loss/high_gen_loss: 703331281187038190518908485632.0000 (331813278335465164474175979520.0000)  loss/pix_loss: 0.1760 (0.1664)  loss/enc_loss: 0.0018 (0.0012)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [280/862]  eta: 0:40:30  lr: 0.000100  loss/low_gen_loss: 1.0561 (1.9993)  loss/high_gen_loss: 398690739356343844554468753408.0000 (330903025630359796322519744512.0000)  loss/pix_loss: 0.1674 (0.1663)  loss/enc_loss: 0.0018 (0.0012)  time: 4.1743  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [290/862]  eta: 0:39:49  lr: 0.000100  loss/low_gen_loss: 1.5417 (1.9899)  loss/high_gen_loss: 220355612618175397840327540736.0000 (325232608948177245788235104256.0000)  loss/pix_loss: 0.1652 (0.1667)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [300/862]  eta: 0:39:07  lr: 0.000100  loss/low_gen_loss: 1.6182 (1.9792)  loss/high_gen_loss: 122556743910026180443924070400.0000 (317005820466931896701268525056.0000)  loss/pix_loss: 0.1584 (0.1662)  loss/enc_loss: 0.0012 (0.0012)  time: 4.1755  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [310/862]  eta: 0:38:25  lr: 0.000100  loss/low_gen_loss: 2.0720 (1.9867)  loss/high_gen_loss: 46759234252205671139128639488.0000 (308018046534423683295451545600.0000)  loss/pix_loss: 0.1442 (0.1656)  loss/enc_loss: 0.0012 (0.0012)  time: 4.1760  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [320/862]  eta: 0:37:43  lr: 0.000100  loss/low_gen_loss: 2.3961 (2.0084)  loss/high_gen_loss: 27221850194544409221735120896.0000 (299031298226601746391336222720.0000)  loss/pix_loss: 0.1477 (0.1654)  loss/enc_loss: 0.0012 (0.0012)  time: 4.1771  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [330/862]  eta: 0:37:02  lr: 0.000100  loss/low_gen_loss: 2.4419 (2.0153)  loss/high_gen_loss: 11435623645336096978921062400.0000 (290274305722975017493290024960.0000)  loss/pix_loss: 0.1550 (0.1655)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1797  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [340/862]  eta: 0:36:20  lr: 0.000100  loss/low_gen_loss: 2.3195 (2.0269)  loss/high_gen_loss: 7300441523608756679446888448.0000 (281933493920400225987545006080.0000)  loss/pix_loss: 0.1569 (0.1653)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1803  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [350/862]  eta: 0:35:38  lr: 0.000100  loss/low_gen_loss: 2.4418 (2.0395)  loss/high_gen_loss: 3373719120682636307993722880.0000 (273954049671080165114720026624.0000)  loss/pix_loss: 0.1585 (0.1651)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1786  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [360/862]  eta: 0:34:56  lr: 0.000100  loss/low_gen_loss: 2.2848 (2.0446)  loss/high_gen_loss: 664757494764783858735906816.0000 (266375354779671757984387563520.0000)  loss/pix_loss: 0.1607 (0.1651)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1787  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [370/862]  eta: 0:34:15  lr: 0.000100  loss/low_gen_loss: 2.0612 (2.0315)  loss/high_gen_loss: 894593374385594710007742464.0000 (259937446529824168250506739712.0000)  loss/pix_loss: 0.1686 (0.1652)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1785  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [380/862]  eta: 0:33:33  lr: 0.000100  loss/low_gen_loss: 1.3018 (2.0097)  loss/high_gen_loss: 405114886454327197514596352.0000 (253119956561435427201943076864.0000)  loss/pix_loss: 0.1632 (0.1647)  loss/enc_loss: 0.0024 (0.0012)  time: 4.1770  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [390/862]  eta: 0:32:51  lr: 0.000100  loss/low_gen_loss: 1.2417 (1.9924)  loss/high_gen_loss: 365424060248594483037339648.0000 (246659104922630506526118248448.0000)  loss/pix_loss: 0.1541 (0.1647)  loss/enc_loss: 0.0029 (0.0013)  time: 4.1764  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [400/862]  eta: 0:32:09  lr: 0.000100  loss/low_gen_loss: 1.4624 (1.9846)  loss/high_gen_loss: 264970267806616937952182272.0000 (240509825764029009082655440896.0000)  loss/pix_loss: 0.1586 (0.1646)  loss/enc_loss: 0.0021 (0.0013)  time: 4.1807  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [410/862]  eta: 0:31:28  lr: 0.000100  loss/low_gen_loss: 1.5876 (1.9781)  loss/high_gen_loss: 154340245986029187025076224.0000 (234667357397646037467631976448.0000)  loss/pix_loss: 0.1611 (0.1649)  loss/enc_loss: 0.0029 (0.0013)  time: 4.1804  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [420/862]  eta: 0:30:46  lr: 0.000100  loss/low_gen_loss: 1.4291 (1.9643)  loss/high_gen_loss: 413397880371792407800315904.0000 (5884513877830370199619204284416.0000)  loss/pix_loss: 0.1778 (0.1650)  loss/enc_loss: 0.0033 (0.0014)  time: 4.1800  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [430/862]  eta: 0:30:04  lr: 0.000100  loss/low_gen_loss: 1.2710 (1.9470)  loss/high_gen_loss: 1128125627992977314836044524290048.0000 (inf)  loss/pix_loss: 0.1727 (0.1649)  loss/enc_loss: 0.0020 (0.0014)  time: 4.1796  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [440/862]  eta: 0:29:22  lr: 0.000100  loss/low_gen_loss: 1.2062 (1.9303)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1657 (0.1651)  loss/enc_loss: 0.0015 (0.0014)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [450/862]  eta: 0:28:41  lr: 0.000100  loss/low_gen_loss: 1.1915 (1.9129)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1640 (0.1651)  loss/enc_loss: 0.0010 (0.0014)  time: 4.1760  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [460/862]  eta: 0:27:59  lr: 0.000100  loss/low_gen_loss: 1.2179 (1.9005)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1608 (0.1649)  loss/enc_loss: 0.0005 (0.0014)  time: 4.1770  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [470/862]  eta: 0:27:17  lr: 0.000100  loss/low_gen_loss: 1.1982 (1.8829)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1604 (0.1647)  loss/enc_loss: 0.0004 (0.0013)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [480/862]  eta: 0:26:35  lr: 0.000100  loss/low_gen_loss: 1.0981 (1.8695)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1609 (0.1645)  loss/enc_loss: 0.0004 (0.0013)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [490/862]  eta: 0:25:53  lr: 0.000100  loss/low_gen_loss: 1.1301 (1.8546)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1574 (0.1643)  loss/enc_loss: 0.0003 (0.0013)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [500/862]  eta: 0:25:11  lr: 0.000100  loss/low_gen_loss: 1.0645 (1.8432)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1663 (0.1644)  loss/enc_loss: 0.0003 (0.0013)  time: 4.1711  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:36]  [510/862]  eta: 0:24:30  lr: 0.000100  loss/low_gen_loss: 0.9900 (1.8262)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1644 (0.1643)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [520/862]  eta: 0:23:48  lr: 0.000100  loss/low_gen_loss: 1.0744 (1.8177)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1644 (0.1646)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [530/862]  eta: 0:23:06  lr: 0.000100  loss/low_gen_loss: 1.3866 (1.8098)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1680 (0.1645)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [540/862]  eta: 0:22:24  lr: 0.000100  loss/low_gen_loss: 1.4791 (1.8068)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1776 (0.1650)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [550/862]  eta: 0:21:42  lr: 0.000100  loss/low_gen_loss: 1.6248 (1.8051)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1868 (0.1652)  loss/enc_loss: 0.0017 (0.0013)  time: 4.1716  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [560/862]  eta: 0:21:01  lr: 0.000100  loss/low_gen_loss: 1.5057 (1.7983)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1704 (0.1652)  loss/enc_loss: 0.0029 (0.0013)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [570/862]  eta: 0:20:19  lr: 0.000100  loss/low_gen_loss: 1.1224 (1.7859)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1725 (0.1655)  loss/enc_loss: 0.0018 (0.0013)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [580/862]  eta: 0:19:37  lr: 0.000100  loss/low_gen_loss: 1.1078 (1.7751)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1716 (0.1654)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1681  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [590/862]  eta: 0:18:55  lr: 0.000100  loss/low_gen_loss: 1.0951 (1.7633)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1631 (0.1654)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1698  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [600/862]  eta: 0:18:14  lr: 0.000100  loss/low_gen_loss: 1.1197 (1.7573)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1622 (0.1652)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [610/862]  eta: 0:17:32  lr: 0.000100  loss/low_gen_loss: 1.2637 (1.7475)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1740 (0.1655)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [620/862]  eta: 0:16:50  lr: 0.000100  loss/low_gen_loss: 1.2637 (1.7414)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1794 (0.1657)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1734  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [630/862]  eta: 0:16:08  lr: 0.000100  loss/low_gen_loss: 1.2516 (1.7318)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1725 (0.1656)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 1.1730 (1.7248)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1647 (0.1657)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [650/862]  eta: 0:14:45  lr: 0.000100  loss/low_gen_loss: 1.5046 (1.7242)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1816 (0.1660)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [660/862]  eta: 0:14:03  lr: 0.000100  loss/low_gen_loss: 1.5128 (1.7190)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1721 (0.1659)  loss/enc_loss: 0.0020 (0.0013)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [670/862]  eta: 0:13:21  lr: 0.000100  loss/low_gen_loss: 1.3152 (1.7194)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1599 (0.1659)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.0694 (1.7089)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1601 (0.1659)  loss/enc_loss: 0.0011 (0.0013)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [690/862]  eta: 0:11:58  lr: 0.000100  loss/low_gen_loss: 1.0694 (1.7048)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1748 (0.1661)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1702  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [700/862]  eta: 0:11:16  lr: 0.000100  loss/low_gen_loss: 1.6044 (1.7060)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1720 (0.1661)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.2850 (1.6988)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1717 (0.1664)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.2157 (1.6929)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1719 (0.1664)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1721  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [730/862]  eta: 0:09:11  lr: 0.000100  loss/low_gen_loss: 1.2056 (1.6850)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1686 (0.1664)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1732  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [740/862]  eta: 0:08:29  lr: 0.000100  loss/low_gen_loss: 1.3059 (1.6811)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1582 (0.1663)  loss/enc_loss: 0.0015 (0.0013)  time: 4.1736  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.4404 (1.6789)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1608 (0.1663)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.4143 (1.6737)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1692 (0.1664)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1748  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [770/862]  eta: 0:06:24  lr: 0.000100  loss/low_gen_loss: 1.1950 (1.6669)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1678 (0.1663)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1747  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.2357 (1.6619)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1665 (0.1663)  loss/enc_loss: 0.0012 (0.0013)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.1464 (1.6534)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1696 (0.1664)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 0.9408 (1.6446)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1721 (0.1664)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [810/862]  eta: 0:03:37  lr: 0.000100  loss/low_gen_loss: 0.9867 (1.6372)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1639 (0.1665)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.0661 (1.6305)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1682 (0.1665)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.1456 (1.6271)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1688 (0.1666)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.1157 (1.6206)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1723 (0.1666)  loss/enc_loss: 0.0022 (0.0013)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.1056 (1.6149)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1677 (0.1666)  loss/enc_loss: 0.0038 (0.0013)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.1419 (1.6102)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1664 (0.1666)  loss/enc_loss: 0.0032 (0.0013)  time: 4.1691  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:36]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.1635 (1.6099)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1676 (0.1666)  loss/enc_loss: 0.0032 (0.0013)  time: 4.1689  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:36] Total time: 0:59:58 (4.1748 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.1635 (1.6099)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1676 (0.1666)  loss/enc_loss: 0.0032 (0.0013)\n",
      "Valid: [epoch:36]  [ 0/14]  eta: 0:00:41  L1_loss: 0.1286 (0.1286)  time: 2.9491  data: 0.3530  max mem: 31350\n",
      "Valid: [epoch:36]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5986  data: 0.0253  max mem: 31350\n",
      "Valid: [epoch:36] Total time: 0:00:36 (2.6084 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_36_input_n_20.png\n",
      "Train: [epoch:37]  [  0/862]  eta: 1:19:09  lr: 0.000100  loss/low_gen_loss: 1.4621 (1.4621)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1435 (0.1435)  loss/enc_loss: 0.0015 (0.0015)  time: 5.5099  data: 1.3451  max mem: 31350\n",
      "Train: [epoch:37]  [ 10/862]  eta: 1:00:32  lr: 0.000100  loss/low_gen_loss: 1.4621 (1.4397)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1552 (0.1557)  loss/enc_loss: 0.0010 (0.0010)  time: 4.2641  data: 0.1224  max mem: 31350\n",
      "Train: [epoch:37]  [ 20/862]  eta: 0:59:04  lr: 0.000100  loss/low_gen_loss: 1.2986 (1.2788)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1591 (0.1608)  loss/enc_loss: 0.0007 (0.0009)  time: 4.1440  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [ 30/862]  eta: 0:58:10  lr: 0.000100  loss/low_gen_loss: 1.1170 (1.2901)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1647 (0.1636)  loss/enc_loss: 0.0008 (0.0009)  time: 4.1572  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [ 40/862]  eta: 0:57:22  lr: 0.000100  loss/low_gen_loss: 1.5110 (1.4256)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1677 (0.1677)  loss/enc_loss: 0.0008 (0.0008)  time: 4.1657  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [ 50/862]  eta: 0:56:37  lr: 0.000100  loss/low_gen_loss: 1.7725 (1.4802)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1795 (0.1694)  loss/enc_loss: 0.0005 (0.0007)  time: 4.1670  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [ 60/862]  eta: 0:55:53  lr: 0.000100  loss/low_gen_loss: 1.5430 (1.4755)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1784 (0.1693)  loss/enc_loss: 0.0004 (0.0007)  time: 4.1679  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [ 70/862]  eta: 0:55:10  lr: 0.000100  loss/low_gen_loss: 1.4913 (1.5041)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1740 (0.1712)  loss/enc_loss: 0.0006 (0.0007)  time: 4.1681  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [ 80/862]  eta: 0:54:27  lr: 0.000100  loss/low_gen_loss: 1.8155 (1.5529)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1727 (0.1705)  loss/enc_loss: 0.0007 (0.0007)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [ 90/862]  eta: 0:53:44  lr: 0.000100  loss/low_gen_loss: 1.7099 (1.5677)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1726 (0.1705)  loss/enc_loss: 0.0006 (0.0007)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [100/862]  eta: 0:53:02  lr: 0.000100  loss/low_gen_loss: 2.0699 (1.6477)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1662 (0.1690)  loss/enc_loss: 0.0006 (0.0007)  time: 4.1684  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [110/862]  eta: 0:52:19  lr: 0.000100  loss/low_gen_loss: 2.0810 (1.6679)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1620 (0.1685)  loss/enc_loss: 0.0009 (0.0007)  time: 4.1676  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [120/862]  eta: 0:51:37  lr: 0.000100  loss/low_gen_loss: 2.0578 (1.7093)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1601 (0.1674)  loss/enc_loss: 0.0019 (0.0009)  time: 4.1675  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [130/862]  eta: 0:50:55  lr: 0.000100  loss/low_gen_loss: 1.6924 (1.6749)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1615 (0.1680)  loss/enc_loss: 0.0020 (0.0009)  time: 4.1688  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [140/862]  eta: 0:50:13  lr: 0.000100  loss/low_gen_loss: 1.3904 (1.6646)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1622 (0.1672)  loss/enc_loss: 0.0012 (0.0009)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [150/862]  eta: 0:49:31  lr: 0.000100  loss/low_gen_loss: 1.3287 (1.6302)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1622 (0.1670)  loss/enc_loss: 0.0013 (0.0010)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [160/862]  eta: 0:48:49  lr: 0.000100  loss/low_gen_loss: 0.9714 (1.5926)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1669 (0.1669)  loss/enc_loss: 0.0020 (0.0011)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [170/862]  eta: 0:48:07  lr: 0.000100  loss/low_gen_loss: 1.1292 (1.5661)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1616 (0.1666)  loss/enc_loss: 0.0025 (0.0014)  time: 4.1677  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [180/862]  eta: 0:47:26  lr: 0.000100  loss/low_gen_loss: 1.1292 (1.5378)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1726 (0.1679)  loss/enc_loss: 0.0033 (0.0014)  time: 4.1713  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [190/862]  eta: 0:46:44  lr: 0.000100  loss/low_gen_loss: 1.1230 (1.5221)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1840 (0.1689)  loss/enc_loss: 0.0020 (0.0014)  time: 4.1753  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [200/862]  eta: 0:46:02  lr: 0.000100  loss/low_gen_loss: 1.2370 (1.5087)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1870 (0.1696)  loss/enc_loss: 0.0012 (0.0014)  time: 4.1749  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [210/862]  eta: 0:45:21  lr: 0.000100  loss/low_gen_loss: 1.3617 (1.5041)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1772 (0.1697)  loss/enc_loss: 0.0008 (0.0014)  time: 4.1727  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [220/862]  eta: 0:44:39  lr: 0.000100  loss/low_gen_loss: 1.2263 (1.4850)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1624 (0.1692)  loss/enc_loss: 0.0006 (0.0013)  time: 4.1737  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [230/862]  eta: 0:43:57  lr: 0.000100  loss/low_gen_loss: 1.1384 (1.4839)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1636 (0.1691)  loss/enc_loss: 0.0004 (0.0013)  time: 4.1746  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [240/862]  eta: 0:43:15  lr: 0.000100  loss/low_gen_loss: 1.3485 (1.4768)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1748 (0.1693)  loss/enc_loss: 0.0004 (0.0013)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [250/862]  eta: 0:42:34  lr: 0.000100  loss/low_gen_loss: 1.5475 (1.4914)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1717 (0.1690)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [260/862]  eta: 0:41:52  lr: 0.000100  loss/low_gen_loss: 1.5504 (1.4924)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1633 (0.1691)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [270/862]  eta: 0:41:10  lr: 0.000100  loss/low_gen_loss: 1.4120 (1.4867)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1669 (0.1693)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1707  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [280/862]  eta: 0:40:28  lr: 0.000100  loss/low_gen_loss: 1.4686 (1.4906)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1629 (0.1692)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1720  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [290/862]  eta: 0:39:46  lr: 0.000100  loss/low_gen_loss: 1.5566 (1.4959)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1649 (0.1690)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [300/862]  eta: 0:39:05  lr: 0.000100  loss/low_gen_loss: 1.4677 (1.4938)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1649 (0.1688)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1692  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [310/862]  eta: 0:38:23  lr: 0.000100  loss/low_gen_loss: 1.1095 (1.4839)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1487 (0.1681)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1681  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:37]  [320/862]  eta: 0:37:41  lr: 0.000100  loss/low_gen_loss: 1.7622 (1.4995)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1481 (0.1677)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1678  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [330/862]  eta: 0:36:59  lr: 0.000100  loss/low_gen_loss: 2.1243 (1.5319)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1589 (0.1676)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1685  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [340/862]  eta: 0:36:17  lr: 0.000100  loss/low_gen_loss: 2.3061 (1.5377)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1573 (0.1674)  loss/enc_loss: 0.0012 (0.0012)  time: 4.1682  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [350/862]  eta: 0:35:36  lr: 0.000100  loss/low_gen_loss: 1.3524 (1.5299)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1653 (0.1674)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1698  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [360/862]  eta: 0:34:54  lr: 0.000100  loss/low_gen_loss: 1.1966 (1.5202)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1729 (0.1677)  loss/enc_loss: 0.0012 (0.0012)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [370/862]  eta: 0:34:12  lr: 0.000100  loss/low_gen_loss: 1.4929 (1.5530)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1762 (0.1680)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1693  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [380/862]  eta: 0:33:30  lr: 0.000100  loss/low_gen_loss: 2.1465 (1.5614)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1707 (0.1678)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1695  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [390/862]  eta: 0:32:49  lr: 0.000100  loss/low_gen_loss: 1.2081 (1.5489)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1544 (0.1674)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1696  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [400/862]  eta: 0:32:07  lr: 0.000100  loss/low_gen_loss: 1.0895 (1.5446)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1544 (0.1673)  loss/enc_loss: 0.0016 (0.0012)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [410/862]  eta: 0:31:25  lr: 0.000100  loss/low_gen_loss: 1.5539 (1.5542)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1613 (0.1673)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1701  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [420/862]  eta: 0:30:43  lr: 0.000100  loss/low_gen_loss: 1.5290 (1.5517)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1628 (0.1671)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1681  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [430/862]  eta: 0:30:02  lr: 0.000100  loss/low_gen_loss: 1.3753 (1.5476)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1624 (0.1668)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1682  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [440/862]  eta: 0:29:20  lr: 0.000100  loss/low_gen_loss: 1.2183 (1.5387)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1498 (0.1663)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1700  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [450/862]  eta: 0:28:38  lr: 0.000100  loss/low_gen_loss: 1.0952 (1.5277)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1608 (0.1667)  loss/enc_loss: 0.0012 (0.0012)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [460/862]  eta: 0:27:57  lr: 0.000100  loss/low_gen_loss: 1.1175 (1.5308)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1722 (0.1664)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1699  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [470/862]  eta: 0:27:15  lr: 0.000100  loss/low_gen_loss: 1.8025 (1.5376)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1541 (0.1663)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1690  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [480/862]  eta: 0:26:33  lr: 0.000100  loss/low_gen_loss: 1.8851 (1.5460)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1657 (0.1663)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1697  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [490/862]  eta: 0:25:51  lr: 0.000100  loss/low_gen_loss: 1.9994 (1.5574)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1657 (0.1661)  loss/enc_loss: 0.0032 (0.0013)  time: 4.1696  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [500/862]  eta: 0:25:10  lr: 0.000100  loss/low_gen_loss: 2.4495 (1.5801)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1620 (0.1658)  loss/enc_loss: 0.0028 (0.0013)  time: 4.1690  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [510/862]  eta: 0:24:28  lr: 0.000100  loss/low_gen_loss: 1.9296 (1.5805)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1653 (0.1660)  loss/enc_loss: 0.0013 (0.0013)  time: 4.1684  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [520/862]  eta: 0:23:46  lr: 0.000100  loss/low_gen_loss: 1.6345 (1.5825)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1780 (0.1663)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [530/862]  eta: 0:23:04  lr: 0.000100  loss/low_gen_loss: 1.6158 (1.5808)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1718 (0.1663)  loss/enc_loss: 0.0007 (0.0013)  time: 4.1687  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [540/862]  eta: 0:22:23  lr: 0.000100  loss/low_gen_loss: 1.3895 (1.5758)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1624 (0.1664)  loss/enc_loss: 0.0005 (0.0013)  time: 4.1686  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [550/862]  eta: 0:21:41  lr: 0.000100  loss/low_gen_loss: 1.5471 (1.5784)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1794 (0.1666)  loss/enc_loss: 0.0004 (0.0013)  time: 4.1691  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [560/862]  eta: 0:20:59  lr: 0.000100  loss/low_gen_loss: 1.7219 (1.5825)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1669 (0.1663)  loss/enc_loss: 0.0004 (0.0012)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [570/862]  eta: 0:20:18  lr: 0.000100  loss/low_gen_loss: 1.8181 (1.5906)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1609 (0.1664)  loss/enc_loss: 0.0003 (0.0012)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [580/862]  eta: 0:19:36  lr: 0.000100  loss/low_gen_loss: 1.5753 (1.5901)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1699 (0.1663)  loss/enc_loss: 0.0003 (0.0012)  time: 4.1722  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [590/862]  eta: 0:18:54  lr: 0.000100  loss/low_gen_loss: 1.5692 (1.5900)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1559 (0.1662)  loss/enc_loss: 0.0005 (0.0012)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [600/862]  eta: 0:18:12  lr: 0.000100  loss/low_gen_loss: 1.5747 (1.5902)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1622 (0.1663)  loss/enc_loss: 0.0011 (0.0012)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [610/862]  eta: 0:17:31  lr: 0.000100  loss/low_gen_loss: 1.4872 (1.5864)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1749 (0.1666)  loss/enc_loss: 0.0016 (0.0012)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [620/862]  eta: 0:16:49  lr: 0.000100  loss/low_gen_loss: 1.3899 (1.5896)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1843 (0.1667)  loss/enc_loss: 0.0014 (0.0012)  time: 4.1741  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [630/862]  eta: 0:16:07  lr: 0.000100  loss/low_gen_loss: 1.5117 (1.6009)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1667 (0.1667)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1733  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [640/862]  eta: 0:15:26  lr: 0.000100  loss/low_gen_loss: 1.0291 (1.5914)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1680 (0.1668)  loss/enc_loss: 0.0017 (0.0012)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [650/862]  eta: 0:14:44  lr: 0.000100  loss/low_gen_loss: 0.9464 (1.5816)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1750 (0.1669)  loss/enc_loss: 0.0019 (0.0012)  time: 4.1725  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [660/862]  eta: 0:14:02  lr: 0.000100  loss/low_gen_loss: 0.9403 (1.5719)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1700 (0.1670)  loss/enc_loss: 0.0017 (0.0012)  time: 4.1744  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [670/862]  eta: 0:13:20  lr: 0.000100  loss/low_gen_loss: 0.9691 (1.5668)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1708 (0.1671)  loss/enc_loss: 0.0013 (0.0012)  time: 4.1737  data: 0.0001  max mem: 31350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:37]  [680/862]  eta: 0:12:39  lr: 0.000100  loss/low_gen_loss: 1.2674 (1.5642)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1708 (0.1670)  loss/enc_loss: 0.0009 (0.0012)  time: 4.1719  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [690/862]  eta: 0:11:57  lr: 0.000100  loss/low_gen_loss: 1.1506 (1.5560)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1718 (0.1672)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1724  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [700/862]  eta: 0:11:15  lr: 0.000100  loss/low_gen_loss: 1.1845 (1.5516)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1704 (0.1671)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1735  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [710/862]  eta: 0:10:34  lr: 0.000100  loss/low_gen_loss: 1.3192 (1.5591)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1705 (0.1673)  loss/enc_loss: 0.0007 (0.0012)  time: 4.1728  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [720/862]  eta: 0:09:52  lr: 0.000100  loss/low_gen_loss: 1.9451 (1.5628)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1772 (0.1675)  loss/enc_loss: 0.0008 (0.0012)  time: 4.1714  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [730/862]  eta: 0:09:10  lr: 0.000100  loss/low_gen_loss: 1.5499 (1.5628)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1772 (0.1673)  loss/enc_loss: 0.0010 (0.0012)  time: 4.1715  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [740/862]  eta: 0:08:28  lr: 0.000100  loss/low_gen_loss: 1.4202 (1.5582)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1787 (0.1675)  loss/enc_loss: 0.0016 (0.0012)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [750/862]  eta: 0:07:47  lr: 0.000100  loss/low_gen_loss: 1.1805 (1.5550)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1798 (0.1676)  loss/enc_loss: 0.0018 (0.0012)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [760/862]  eta: 0:07:05  lr: 0.000100  loss/low_gen_loss: 1.7409 (1.5597)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1658 (0.1674)  loss/enc_loss: 0.0023 (0.0012)  time: 4.1726  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [770/862]  eta: 0:06:23  lr: 0.000100  loss/low_gen_loss: 1.9382 (1.5677)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1626 (0.1673)  loss/enc_loss: 0.0025 (0.0013)  time: 4.1723  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [780/862]  eta: 0:05:42  lr: 0.000100  loss/low_gen_loss: 1.8513 (1.5715)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1665 (0.1673)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1718  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [790/862]  eta: 0:05:00  lr: 0.000100  loss/low_gen_loss: 1.8043 (1.5737)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1670 (0.1672)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1717  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [800/862]  eta: 0:04:18  lr: 0.000100  loss/low_gen_loss: 1.9424 (1.5830)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1681 (0.1673)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1705  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [810/862]  eta: 0:03:36  lr: 0.000100  loss/low_gen_loss: 2.0754 (1.5880)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1769 (0.1674)  loss/enc_loss: 0.0016 (0.0013)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [820/862]  eta: 0:02:55  lr: 0.000100  loss/low_gen_loss: 1.6806 (1.5880)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1808 (0.1675)  loss/enc_loss: 0.0014 (0.0013)  time: 4.1706  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [830/862]  eta: 0:02:13  lr: 0.000100  loss/low_gen_loss: 1.5385 (1.5886)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1681 (0.1674)  loss/enc_loss: 0.0010 (0.0013)  time: 4.1711  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [840/862]  eta: 0:01:31  lr: 0.000100  loss/low_gen_loss: 1.7042 (1.5910)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1581 (0.1674)  loss/enc_loss: 0.0009 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [850/862]  eta: 0:00:50  lr: 0.000100  loss/low_gen_loss: 1.1723 (1.5852)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1651 (0.1674)  loss/enc_loss: 0.0008 (0.0013)  time: 4.1708  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [860/862]  eta: 0:00:08  lr: 0.000100  loss/low_gen_loss: 1.0821 (1.5793)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1749 (0.1676)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1710  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37]  [861/862]  eta: 0:00:04  lr: 0.000100  loss/low_gen_loss: 1.0677 (1.5786)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1718 (0.1675)  loss/enc_loss: 0.0006 (0.0012)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:37] Total time: 0:59:56 (4.1718 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/low_gen_loss: 1.0677 (1.5786)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1718 (0.1675)  loss/enc_loss: 0.0006 (0.0012)\n",
      "Valid: [epoch:37]  [ 0/14]  eta: 0:00:42  L1_loss: 0.1611 (0.1611)  time: 3.0000  data: 0.3916  max mem: 31350\n",
      "Valid: [epoch:37]  [13/14]  eta: 0:00:02  L1_loss: 0.1329 (0.1397)  time: 2.5932  data: 0.0281  max mem: 31350\n",
      "Valid: [epoch:37] Total time: 0:00:36 (2.6025 s / it)\n",
      "Averaged stats: L1_loss: 0.1329 (0.1397)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/epoch_37_input_n_20.png\n",
      "Train: [epoch:38]  [  0/862]  eta: 1:17:44  lr: 0.000100  loss/low_gen_loss: 0.9952 (0.9952)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1661 (0.1661)  loss/enc_loss: 0.0007 (0.0007)  time: 5.4117  data: 1.2304  max mem: 31350\n",
      "Train: [epoch:38]  [ 10/862]  eta: 1:00:48  lr: 0.000100  loss/low_gen_loss: 1.0722 (1.0693)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1708 (0.1665)  loss/enc_loss: 0.0007 (0.0007)  time: 4.2827  data: 0.1120  max mem: 31350\n",
      "Train: [epoch:38]  [ 20/862]  eta: 0:59:21  lr: 0.000100  loss/low_gen_loss: 1.1419 (1.2144)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1714 (0.1711)  loss/enc_loss: 0.0007 (0.0009)  time: 4.1709  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:38]  [ 30/862]  eta: 0:58:23  lr: 0.000100  loss/low_gen_loss: 1.4390 (1.3358)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1791 (0.1740)  loss/enc_loss: 0.0019 (0.0013)  time: 4.1712  data: 0.0001  max mem: 31350\n",
      "Train: [epoch:38]  [ 40/862]  eta: 0:57:33  lr: 0.000100  loss/low_gen_loss: 1.2484 (1.3097)  loss/high_gen_loss: inf (inf)  loss/pix_loss: 0.1687 (0.1716)  loss/enc_loss: 0.0021 (0.0015)  time: 4.1707  data: 0.0001  max mem: 31350\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--batch-size 8 \\\n",
    "--epochs 1000 \\\n",
    "--lr_scheduler \"lambda\" \\\n",
    "--lr 1e-4 \\\n",
    "--data-set 'Sinogram_DCM' \\\n",
    "--model-name 'FSGAN' \\\n",
    "--criterion 'L1 Loss' \\\n",
    "--output_dir '/workspace/sunggu/4.Dose_img2img/model/[Ours]FSGAN' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Ours]FSGAN/low2high/' \\\n",
    "--validate-every 2 \\\n",
    "--num_workers 4 \\\n",
    "--criterion_mode 'not balance' \\\n",
    "--multiple_GT \"False\" \\\n",
    "--patch_training \"True\" \\\n",
    "--multi-gpu-mode 'Single' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import cv2\n",
    "import functools\n",
    "import pydicom\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(action='ignore') \n",
    "\n",
    "\n",
    "def list_sort_nicely(l):   \n",
    "    def tryint(s):        \n",
    "        try:            \n",
    "            return int(s)        \n",
    "        except:            \n",
    "            return s\n",
    "        \n",
    "    def alphanum_key(s):\n",
    "        return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "    l.sort(key=alphanum_key)    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_20_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/20/*/*/*.dcm')) + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/20/*/*/*.dcm'))\n",
    "n_100_imgs  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/X/*/*/*.dcm'))  + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/X/*/*/*.dcm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixels_hu(path):\n",
    "    # pydicom version...!\n",
    "    # referred from https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial\n",
    "    # ref: pydicom.pixel_data_handlers.util.apply_modality_lut\n",
    "    # '''\n",
    "    # Awesome pydicom lut fuction...!\n",
    "    # ds  = pydicom.dcmread(fname)\n",
    "    # arr = ds.pixel_array\n",
    "    # hu  = apply_modality_lut(arr, ds)\n",
    "    # '''\n",
    "    dcm_image = pydicom.read_file(path)\n",
    "    image = dcm_image.pixel_array\n",
    "    image = image.astype(np.int16)\n",
    "    image[image == -2000] = 0\n",
    "\n",
    "    intercept = dcm_image.RescaleIntercept\n",
    "    slope     = dcm_image.RescaleSlope\n",
    "\n",
    "    if slope != 1:\n",
    "        image = slope * image.astype(np.float64)\n",
    "        image = image.astype(np.int16)\n",
    "\n",
    "    image += np.int16(intercept)\n",
    "    # print(image.shape) # (512, 512)\n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "def dicom_normalize(image, MIN_HU=-1024.0, MAX_HU=3071.0):   # I already check the max value is 3071.0\n",
    "   image = (image - MIN_HU) / (MAX_HU - MIN_HU)   # Range  0.0 ~ 1.0\n",
    "#    image = (image - 0.5) / 0.5                  # Range -1.0 ~ 1.0   @ We do not use -1~1 range becuase there is no Tanh act.\n",
    "   return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from monai.transforms import *\n",
    "from monai.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_20_imgs   = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/20/*/*/*.dcm')) + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/20/*/*/*.dcm'))\n",
    "n_100_imgs  = list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Train/*/X/*/*/*.dcm'))  + list_sort_nicely(glob.glob('/workspace/sunggu/4.Dose_img2img/dataset/*Brain_3mm_DCM/Valid/*/X/*/*/*.dcm'))\n",
    "\n",
    "files = [{\"n_20\": n_20, \"n_100\": n_100} for n_20, n_100 in zip(n_20_imgs, n_100_imgs)]            \n",
    "print(\"Train [Total]  number = \", len(n_20_imgs))\n",
    "\n",
    "# CT에 맞는 Augmentation\n",
    "\n",
    "transforms = Compose(\n",
    "    [\n",
    "        Lambdad(keys=[\"n_20\", \"n_100\"], func=get_pixels_hu),\n",
    "        Lambdad(keys=[\"n_20\", \"n_100\"], func=dicom_normalize),\n",
    "        AddChanneld(keys=[\"n_20\", \"n_100\"]),                 \n",
    "\n",
    "        # Crop  \n",
    "        # RandWeightedCropd(keys=[\"image\"], w_key=[\"image\"], spatial_size=(512,512,1), num_samples=1),\n",
    "        # RandSpatialCropd(keys=[\"image\"], roi_size=(512, 512), random_size=False, random_center=True),\n",
    "        # RandSpatialCropd(keys=[\"image\"], roi_size=(512,512,3), random_size=False, random_center=True),\n",
    "#         RandSpatialCropSamplesd(keys=[\"n_20\", \"n_100\"], roi_size=(64, 64), num_samples=8, random_center=True, random_size=False, meta_keys=None, allow_missing_keys=False), \n",
    "            # patch training, next(iter(loader)) output : list로 sample 만큼,,, 그 List 안에 (B, C, H, W)\n",
    "\n",
    "        # (45 degree rotation, vertical & horizontal flip & scaling)\n",
    "#         RandFlipd(keys=[\"n_20\", \"n_100\"], prob=0.1, spatial_axis=[0, 1], allow_missing_keys=False),\n",
    "#         RandRotated(keys=[\"n_20\", \"n_100\"], prob=0.1, range_x=np.pi/4, range_y=np.pi/4, range_z=0.0, keep_size=True, align_corners=False, allow_missing_keys=False),\n",
    "#         RandZoomd(keys=[\"n_20\", \"n_100\"], prob=0.1, min_zoom=0.5, max_zoom=2.0, align_corners=None, keep_size=True, allow_missing_keys=False),\n",
    "        ToTensord(keys=[\"n_20\", \"n_100\"]),\n",
    "    ]\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Dataset(data=files, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_denormalize(image, MIN_HU=-1024.0, MAX_HU=3071.0):\n",
    "    # image = (image - 0.5) / 0.5           # Range -1.0 ~ 1.0   @ We do not use -1~1 range becuase there is no Tanh act.\n",
    "    image = (MAX_HU - MIN_HU)*image + MIN_HU\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(dicom_denormalize(t[470]['n_20'].squeeze()), 'gray', vmin=0, vmax=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dicom_denormalize(t[470]['n_100'].squeeze()), 'gray', vmin=0, vmax=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(t[470]['n_100'], t[470]['n_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCoshLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n",
    "#         return torch.mean(torch.log(torch.cosh(torch.pow(ey_t, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LogCoshLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a(t[470]['n_100'], t[470]['n_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.1081e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a(t[470]['n_100'], t[470]['n_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a(t[470]['n_100'], t[470]['n_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000*4.1081e-06 - 1000*2.1081e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_log(path):\n",
    "    log_list = []\n",
    "    lines = open(path, 'r').read().splitlines() \n",
    "    for i in range(len(lines)):\n",
    "        exec('log_list.append('+lines[i] + ')')\n",
    "    return  log_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = read_log(path = '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/log.txt')\n",
    "\n",
    "train_lr   = [ log_list[i]['train_lr'] for i in range(len(log_list)) ]\n",
    "train_loss = [ log_list[i]['train_loss'] for i in range(len(log_list)) ]\n",
    "valid_loss = [ log_list[i]['valid_loss'] for i in range(len(log_list)) ]\n",
    "epoch      = [ log_list[i]['epoch'] for i in range(len(log_list)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(train_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(valid_loss)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(np.argsort(valid_loss)[:10]) & set(np.argsort(train_loss)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py \\\n",
    "--training-mode 'sinogram' \\\n",
    "--data-set 'TEST_Sinogram_DCM' \\\n",
    "--model-name 'ED_CNN' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Test/png/[Privious]ED_CNN/epoch_999/' \\\n",
    "--num_workers 4 \\\n",
    "--pin-mem \\\n",
    "--range-minus1-plus1 'False' \\\n",
    "--teacher_forcing \"False\" \\\n",
    "--resume '/workspace/sunggu/4.Dose_img2img/model/[Privious]ED_CNN/epoch_999_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 978 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Original === \n",
    "PSNR avg: 54.4628 \n",
    "SSIM avg: 0.9956 \n",
    "RMSE avg: 7.9607\n",
    "\n",
    "\n",
    "Predictions === \n",
    "PSNR avg: 57.6190 \n",
    "SSIM avg: 0.9980 \n",
    "RMSE avg: 5.5423\n",
    "***********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
