{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pretrainedmodels==0.7.4\n",
    "# !pip install efficientnet-pytorch==0.6.3\n",
    "# !pip install timm==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CUDA 11.1\n",
    "# !pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE -> MAE Loss 꿀팁!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 20 12:47:08 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 43%   51C    P0    68W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 43%   52C    P0    59W / 280W |      0MiB / 24220MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 40%   49C    P0    59W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 31%   56C    P0    54W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/sunggu/4.Dose_img2img/scripts study\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/sunggu/4.Dose_img2img/scripts study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0+cu111\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 갯수 =  32\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(\"CPU 갯수 = \", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DU_GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "inintializing...!\n",
      "***********************************************\n",
      "***********************************************\n",
      "Dataset Name:  Sinogram_DCM\n",
      "---------- Model ----------\n",
      "Resume From:  /workspace/sunggu/4.Dose_img2img/model/[Privious]DU_GAN/epoch_1083_checkpoint.pth\n",
      "Output To:  /workspace/sunggu/4.Dose_img2img/model/[Privious]DU_GAN\n",
      "Save   To:  /workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/\n",
      "---------- Optimizer ----------\n",
      "Learning Rate:  0.0002\n",
      "Weight Decay:  0.05\n",
      "Batchsize:  40\n",
      "Loading dataset ....\n",
      "Train [Total]  number =  6899\n",
      "Valid [Total]  number =  14\n",
      "Creating model: DU_GAN\n",
      "Number of Learnable Params: 114613247\n",
      "Loading pre-trained Weight...!\n",
      "Start training for 20000 epochs\n",
      "Train: [epoch:0]  [  0/172]  eta: 0:29:46  lr: 0.000200  loss/img_gen_loss: 0.8864 (0.8864)  loss/grad_gen_loss: 0.5769 (0.5769)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0107 (0.0107)  time: 10.3855  data: 2.7976  max mem: 17155\n",
      "Train: [epoch:0]  [ 10/172]  eta: 0:17:32  lr: 0.000200  loss/img_gen_loss: 0.8864 (0.8864)  loss/grad_gen_loss: 0.5517 (0.5509)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.4988  data: 0.2546  max mem: 17400\n",
      "Train: [epoch:0]  [ 20/172]  eta: 0:16:15  lr: 0.000200  loss/img_gen_loss: 0.8864 (0.8864)  loss/grad_gen_loss: 0.5601 (0.5774)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0115)  time: 6.2160  data: 0.0004  max mem: 17402\n",
      "Train: [epoch:0]  [ 30/172]  eta: 0:15:33  lr: 0.000200  loss/img_gen_loss: 0.8865 (0.8865)  loss/grad_gen_loss: 0.6411 (0.6029)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0116)  time: 6.6203  data: 0.0004  max mem: 17402\n",
      "Train: [epoch:0]  [ 40/172]  eta: 0:14:42  lr: 0.000200  loss/img_gen_loss: 0.8865 (0.8865)  loss/grad_gen_loss: 0.6157 (0.6016)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0117)  time: 6.9760  data: 0.0004  max mem: 17402\n",
      "Train: [epoch:0]  [ 50/172]  eta: 0:13:44  lr: 0.000200  loss/img_gen_loss: 0.8865 (0.8865)  loss/grad_gen_loss: 0.6072 (0.6050)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0118)  time: 7.0300  data: 0.0005  max mem: 17402\n",
      "Train: [epoch:0]  [ 60/172]  eta: 0:12:40  lr: 0.000200  loss/img_gen_loss: 0.8865 (0.8865)  loss/grad_gen_loss: 0.6151 (0.6058)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 7.0082  data: 0.0005  max mem: 17402\n",
      "Train: [epoch:0]  [ 70/172]  eta: 0:11:35  lr: 0.000200  loss/img_gen_loss: 0.8865 (0.8865)  loss/grad_gen_loss: 0.5800 (0.5996)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.9655  data: 0.0005  max mem: 17402\n",
      "Train: [epoch:0]  [ 80/172]  eta: 0:10:28  lr: 0.000200  loss/img_gen_loss: 0.8866 (0.8865)  loss/grad_gen_loss: 0.5727 (0.6032)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.9347  data: 0.0005  max mem: 17402\n",
      "Train: [epoch:0]  [ 90/172]  eta: 0:09:20  lr: 0.000200  loss/img_gen_loss: 0.8866 (0.8865)  loss/grad_gen_loss: 0.6296 (0.6067)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.9184  data: 0.0005  max mem: 17402\n",
      "Train: [epoch:0]  [100/172]  eta: 0:08:12  lr: 0.000200  loss/img_gen_loss: 0.8866 (0.8865)  loss/grad_gen_loss: 0.5750 (0.6009)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.9081  data: 0.0005  max mem: 17402\n",
      "Train: [epoch:0]  [110/172]  eta: 0:07:04  lr: 0.000200  loss/img_gen_loss: 0.8866 (0.8865)  loss/grad_gen_loss: 0.5659 (0.6044)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 6.9169  data: 0.0004  max mem: 17402\n",
      "Train: [epoch:0]  [120/172]  eta: 0:05:56  lr: 0.000200  loss/img_gen_loss: 0.8866 (0.8865)  loss/grad_gen_loss: 0.6300 (0.6062)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.9416  data: 0.0005  max mem: 17402\n",
      "Train: [epoch:0]  [130/172]  eta: 0:04:48  lr: 0.000200  loss/img_gen_loss: 0.8866 (0.8865)  loss/grad_gen_loss: 0.5854 (0.6036)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.9542  data: 0.0006  max mem: 17402\n",
      "Train: [epoch:0]  [140/172]  eta: 0:03:39  lr: 0.000200  loss/img_gen_loss: 0.8867 (0.8865)  loss/grad_gen_loss: 0.5849 (0.6061)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0117)  time: 6.9462  data: 0.0006  max mem: 17402\n",
      "Train: [epoch:0]  [150/172]  eta: 0:02:31  lr: 0.000200  loss/img_gen_loss: 0.8867 (0.8866)  loss/grad_gen_loss: 0.6286 (0.6066)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0117)  time: 6.9480  data: 0.0005  max mem: 17404\n",
      "Train: [epoch:0]  [160/172]  eta: 0:01:22  lr: 0.000200  loss/img_gen_loss: 0.8867 (0.8866)  loss/grad_gen_loss: 0.5634 (0.6031)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.9480  data: 0.0005  max mem: 17404\n",
      "Train: [epoch:0]  [170/172]  eta: 0:00:13  lr: 0.000200  loss/img_gen_loss: 0.8867 (0.8866)  loss/grad_gen_loss: 0.5715 (0.6048)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.9341  data: 0.0005  max mem: 17404\n",
      "Train: [epoch:0]  [171/172]  eta: 0:00:06  lr: 0.000200  loss/img_gen_loss: 0.8867 (0.8866)  loss/grad_gen_loss: 0.5723 (0.6050)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0116)  time: 6.9332  data: 0.0005  max mem: 17404\n",
      "Train: [epoch:0] Total time: 0:19:44 (6.8859 s / it)\n",
      "Averaged stats: lr: 0.000200  loss/img_gen_loss: 0.8867 (0.8866)  loss/grad_gen_loss: 0.5723 (0.6050)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0116)\n",
      "Valid: [epoch:0]  [ 0/14]  eta: 0:00:05  L1_loss: 0.0014 (0.0014)  time: 0.3614  data: 0.3374  max mem: 17404\n",
      "Valid: [epoch:0]  [13/14]  eta: 0:00:00  L1_loss: 0.0013 (0.0013)  time: 0.0486  data: 0.0283  max mem: 17404\n",
      "Valid: [epoch:0] Total time: 0:00:00 (0.0566 s / it)\n",
      "Averaged stats: L1_loss: 0.0013 (0.0013)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_0_input_n_20.png\n",
      "/home/sunggu/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Train: [epoch:1]  [  0/172]  eta: 0:27:09  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6577 (0.6577)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0121 (0.0121)  time: 9.4736  data: 3.1311  max mem: 17404\n",
      "Train: [epoch:1]  [ 10/172]  eta: 0:19:00  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6418 (0.6459)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0114)  time: 7.0374  data: 0.2852  max mem: 17404\n",
      "Train: [epoch:1]  [ 20/172]  eta: 0:17:43  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6407 (0.6450)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0113)  time: 6.8751  data: 0.0005  max mem: 17404\n",
      "Train: [epoch:1]  [ 30/172]  eta: 0:16:31  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6408 (0.6452)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0116)  time: 6.9495  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [ 40/172]  eta: 0:15:19  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6423 (0.6444)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0120 (0.0116)  time: 6.9334  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [ 50/172]  eta: 0:14:08  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6413 (0.6431)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.9223  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [ 60/172]  eta: 0:12:58  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6324 (0.6424)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 6.9223  data: 0.0004  max mem: 17404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:1]  [ 70/172]  eta: 0:11:48  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6347 (0.6419)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.9135  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [ 80/172]  eta: 0:10:38  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6347 (0.6406)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0118)  time: 6.9213  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [ 90/172]  eta: 0:09:29  lr: 0.000001  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.6336 (0.6403)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0118)  time: 6.9305  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [100/172]  eta: 0:08:19  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6345 (0.6399)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0118)  time: 6.9103  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [110/172]  eta: 0:07:09  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6306 (0.6392)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0118)  time: 6.9039  data: 0.0003  max mem: 17404\n",
      "Train: [epoch:1]  [120/172]  eta: 0:06:00  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6318 (0.6388)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0118)  time: 6.9151  data: 0.0003  max mem: 17404\n",
      "Train: [epoch:1]  [130/172]  eta: 0:04:51  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6356 (0.6383)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0118)  time: 6.9099  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [140/172]  eta: 0:03:41  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6269 (0.6375)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0120 (0.0118)  time: 6.9103  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [150/172]  eta: 0:02:32  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6325 (0.6373)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 6.9102  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [160/172]  eta: 0:01:23  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6325 (0.6370)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0117)  time: 6.9113  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [170/172]  eta: 0:00:13  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6315 (0.6368)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.9146  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1]  [171/172]  eta: 0:00:06  lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6315 (0.6368)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.9161  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:1] Total time: 0:19:51 (6.9278 s / it)\n",
      "Averaged stats: lr: 0.000001  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6315 (0.6368)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)\n",
      "Valid: [epoch:1]  [ 0/14]  eta: 0:00:05  L1_loss: 0.0012 (0.0012)  time: 0.3965  data: 0.3752  max mem: 17404\n",
      "Valid: [epoch:1]  [13/14]  eta: 0:00:00  L1_loss: 0.0013 (0.0013)  time: 0.0477  data: 0.0273  max mem: 17404\n",
      "Valid: [epoch:1] Total time: 0:00:00 (0.0556 s / it)\n",
      "Averaged stats: L1_loss: 0.0013 (0.0013)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_1_input_n_20.png\n",
      "Train: [epoch:2]  [  0/172]  eta: 0:25:55  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6483 (0.6483)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0119)  time: 9.0450  data: 2.6780  max mem: 17404\n",
      "Train: [epoch:2]  [ 10/172]  eta: 0:18:49  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6245 (0.6270)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0115)  time: 6.9731  data: 0.2438  max mem: 17404\n",
      "Train: [epoch:2]  [ 20/172]  eta: 0:17:38  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6263 (0.6279)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0118)  time: 6.8574  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:2]  [ 30/172]  eta: 0:16:26  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6196 (0.6230)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0115)  time: 6.9377  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:2]  [ 40/172]  eta: 0:15:16  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6079 (0.6187)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0109 (0.0115)  time: 6.9186  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:2]  [ 50/172]  eta: 0:14:06  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6047 (0.6161)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0116)  time: 6.9109  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:2]  [ 60/172]  eta: 0:12:56  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6042 (0.6141)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0116)  time: 6.9104  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:2]  [ 70/172]  eta: 0:11:46  lr: 0.000020  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.6008 (0.6124)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.9018  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:2]  [ 80/172]  eta: 0:10:36  lr: 0.000020  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.6022 (0.6117)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.8983  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:2]  [ 90/172]  eta: 0:09:27  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6070 (0.6119)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0117)  time: 6.9033  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:2]  [100/172]  eta: 0:08:18  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6099 (0.6117)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.9155  data: 0.0004  max mem: 17404\n",
      "Train: [epoch:2]  [110/172]  eta: 0:07:09  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6062 (0.6109)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0110 (0.0116)  time: 6.9168  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:2]  [120/172]  eta: 0:05:59  lr: 0.000020  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.6039 (0.6105)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0109 (0.0116)  time: 6.8937  data: 0.0005  max mem: 17405\n",
      "Train: [epoch:2]  [130/172]  eta: 0:04:50  lr: 0.000020  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.6098 (0.6104)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0116)  time: 6.8889  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:2]  [140/172]  eta: 0:03:41  lr: 0.000020  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.6080 (0.6104)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.8931  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:2]  [150/172]  eta: 0:02:32  lr: 0.000020  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.6081 (0.6104)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.8879  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:2]  [160/172]  eta: 0:01:22  lr: 0.000020  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.6038 (0.6097)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)  time: 6.8921  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:2]  [170/172]  eta: 0:00:13  lr: 0.000020  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.6017 (0.6094)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.9086  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:2]  [171/172]  eta: 0:00:06  lr: 0.000020  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.5981 (0.6093)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.9094  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:2] Total time: 0:19:48 (6.9123 s / it)\n",
      "Averaged stats: lr: 0.000020  loss/img_gen_loss: 0.8868 (0.8867)  loss/grad_gen_loss: 0.5981 (0.6093)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:2]  [ 0/14]  eta: 0:00:07  L1_loss: 0.0013 (0.0013)  time: 0.5354  data: 0.5140  max mem: 17405\n",
      "Valid: [epoch:2]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0573  data: 0.0375  max mem: 17405\n",
      "Valid: [epoch:2] Total time: 0:00:00 (0.0653 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_2_input_n_20.png\n",
      "Train: [epoch:3]  [  0/172]  eta: 0:25:29  lr: 0.000040  loss/img_gen_loss: 0.8867 (0.8867)  loss/grad_gen_loss: 0.5808 (0.5808)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0098 (0.0098)  time: 8.8941  data: 2.5567  max mem: 17405\n",
      "Train: [epoch:3]  [ 10/172]  eta: 0:18:53  lr: 0.000040  loss/img_gen_loss: 0.8867 (0.8868)  loss/grad_gen_loss: 0.5871 (0.5920)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0113)  time: 6.9968  data: 0.2327  max mem: 17405\n",
      "Train: [epoch:3]  [ 20/172]  eta: 0:17:40  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5940 (0.5978)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0112)  time: 6.8834  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:3]  [ 30/172]  eta: 0:16:29  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.6061 (0.6004)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0113)  time: 6.9525  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:3]  [ 40/172]  eta: 0:15:19  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.6061 (0.6022)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0114)  time: 6.9500  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:3]  [ 50/172]  eta: 0:14:08  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5967 (0.5989)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0115)  time: 6.9441  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:3]  [ 60/172]  eta: 0:12:58  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5805 (0.5958)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0116)  time: 6.9313  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:3]  [ 70/172]  eta: 0:11:48  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5835 (0.5952)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0116)  time: 6.9172  data: 0.0006  max mem: 17405\n",
      "Train: [epoch:3]  [ 80/172]  eta: 0:10:38  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5903 (0.5953)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.9068  data: 0.0006  max mem: 17405\n",
      "Train: [epoch:3]  [ 90/172]  eta: 0:09:29  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5988 (0.5965)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.9106  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:3]  [100/172]  eta: 0:08:19  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.6067 (0.5984)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.9152  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:3]  [110/172]  eta: 0:07:10  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.6127 (0.5989)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0116)  time: 6.9319  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:3]  [120/172]  eta: 0:06:00  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.6026 (0.5988)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0116)  time: 6.9459  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:3]  [130/172]  eta: 0:04:51  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5953 (0.5986)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0115)  time: 6.9445  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:3]  [140/172]  eta: 0:03:42  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5953 (0.5984)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.9484  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:3]  [150/172]  eta: 0:02:32  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5967 (0.5984)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0115)  time: 6.9505  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:3]  [160/172]  eta: 0:01:23  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5973 (0.5984)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0115)  time: 6.9339  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:3]  [170/172]  eta: 0:00:13  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5942 (0.5981)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0115)  time: 6.9324  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:3]  [171/172]  eta: 0:00:06  lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5945 (0.5982)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)  time: 6.9297  data: 0.0003  max mem: 17405\n",
      "Train: [epoch:3] Total time: 0:19:53 (6.9400 s / it)\n",
      "Averaged stats: lr: 0.000040  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5945 (0.5982)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)\n",
      "Valid: [epoch:3]  [ 0/14]  eta: 0:00:05  L1_loss: 0.0012 (0.0012)  time: 0.4071  data: 0.3822  max mem: 17405\n",
      "Valid: [epoch:3]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0482  data: 0.0282  max mem: 17405\n",
      "Valid: [epoch:3] Total time: 0:00:00 (0.0553 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_3_input_n_20.png\n",
      "Train: [epoch:4]  [  0/172]  eta: 0:23:01  lr: 0.000060  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5910 (0.5910)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0115)  time: 8.0311  data: 1.6648  max mem: 17405\n",
      "Train: [epoch:4]  [ 10/172]  eta: 0:18:38  lr: 0.000060  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5891 (0.5908)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0114)  time: 6.9025  data: 0.1517  max mem: 17405\n",
      "Train: [epoch:4]  [ 20/172]  eta: 0:17:33  lr: 0.000060  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.5971 (0.5970)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0113)  time: 6.8764  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:4]  [ 30/172]  eta: 0:16:25  lr: 0.000060  loss/img_gen_loss: 0.8868 (0.8868)  loss/grad_gen_loss: 0.6004 (0.6013)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)  time: 6.9594  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:4]  [ 40/172]  eta: 0:15:15  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8868)  loss/grad_gen_loss: 0.6004 (0.6014)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0121 (0.0117)  time: 6.9453  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:4]  [ 50/172]  eta: 0:14:06  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8868)  loss/grad_gen_loss: 0.5987 (0.6023)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0117)  time: 6.9361  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:4]  [ 60/172]  eta: 0:12:56  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8868)  loss/grad_gen_loss: 0.5896 (0.6003)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.9248  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:4]  [ 70/172]  eta: 0:11:47  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8868)  loss/grad_gen_loss: 0.5869 (0.5986)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.9197  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:4]  [ 80/172]  eta: 0:10:37  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8868)  loss/grad_gen_loss: 0.5896 (0.5981)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0116)  time: 6.9267  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:4]  [ 90/172]  eta: 0:09:28  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.5976 (0.5988)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0116)  time: 6.9203  data: 0.0004  max mem: 17405\n",
      "Train: [epoch:4]  [100/172]  eta: 0:08:18  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.5996 (0.5991)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.9130  data: 0.0004  max mem: 17405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:4]  [110/172]  eta: 0:07:09  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.5837 (0.5974)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.9093  data: 0.0003  max mem: 17406\n",
      "Train: [epoch:4]  [120/172]  eta: 0:06:00  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.5754 (0.5955)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0115)  time: 6.9088  data: 0.0004  max mem: 17406\n",
      "Train: [epoch:4]  [130/172]  eta: 0:04:50  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.5785 (0.5950)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)  time: 6.9080  data: 0.0004  max mem: 17406\n",
      "Train: [epoch:4]  [140/172]  eta: 0:03:41  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.5926 (0.5953)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.9143  data: 0.0004  max mem: 17406\n",
      "Train: [epoch:4]  [150/172]  eta: 0:02:32  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.6023 (0.5966)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0115)  time: 6.9118  data: 0.0004  max mem: 17406\n",
      "Train: [epoch:4]  [160/172]  eta: 0:01:23  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.6046 (0.5969)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0110 (0.0115)  time: 6.9031  data: 0.0004  max mem: 17406\n",
      "Train: [epoch:4]  [170/172]  eta: 0:00:13  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.5886 (0.5962)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0115)  time: 6.9020  data: 0.0003  max mem: 17406\n",
      "Train: [epoch:4]  [171/172]  eta: 0:00:06  lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.5867 (0.5961)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)  time: 6.9006  data: 0.0003  max mem: 17406\n",
      "Train: [epoch:4] Total time: 0:19:50 (6.9207 s / it)\n",
      "Averaged stats: lr: 0.000060  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.5867 (0.5961)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)\n",
      "Valid: [epoch:4]  [ 0/14]  eta: 0:00:06  L1_loss: 0.0012 (0.0012)  time: 0.4384  data: 0.4183  max mem: 17406\n",
      "Valid: [epoch:4]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0527  data: 0.0329  max mem: 17406\n",
      "Valid: [epoch:4] Total time: 0:00:00 (0.0607 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_4_input_n_20.png\n",
      "Train: [epoch:5]  [  0/172]  eta: 0:29:56  lr: 0.000080  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5853 (0.5853)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0122 (0.0122)  time: 10.4457  data: 2.6088  max mem: 21171\n",
      "Train: [epoch:5]  [ 10/172]  eta: 0:23:19  lr: 0.000080  loss/img_gen_loss: 0.8927 (0.8926)  loss/grad_gen_loss: 0.6353 (0.6367)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0110)  time: 8.6404  data: 0.2374  max mem: 21186\n",
      "Train: [epoch:5]  [ 20/172]  eta: 0:21:48  lr: 0.000080  loss/img_gen_loss: 0.8977 (0.8982)  loss/grad_gen_loss: 0.7086 (0.6904)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0114)  time: 8.5138  data: 0.0003  max mem: 21186\n",
      "Train: [epoch:5]  [ 30/172]  eta: 0:20:21  lr: 0.000080  loss/img_gen_loss: 0.9103 (0.9046)  loss/grad_gen_loss: 0.7251 (0.6961)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 8.5795  data: 0.0003  max mem: 21186\n",
      "Train: [epoch:5]  [ 40/172]  eta: 0:18:54  lr: 0.000080  loss/img_gen_loss: 0.9245 (0.9117)  loss/grad_gen_loss: 0.7044 (0.6994)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0120 (0.0118)  time: 8.5821  data: 0.0003  max mem: 21186\n",
      "Train: [epoch:5]  [ 50/172]  eta: 0:17:27  lr: 0.000080  loss/img_gen_loss: 0.9417 (0.9195)  loss/grad_gen_loss: 0.7231 (0.7058)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0118)  time: 8.5702  data: 0.0004  max mem: 21186\n",
      "Train: [epoch:5]  [ 60/172]  eta: 0:16:01  lr: 0.000080  loss/img_gen_loss: 0.9586 (0.9266)  loss/grad_gen_loss: 0.7304 (0.7093)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0117)  time: 8.5622  data: 0.0004  max mem: 21187\n",
      "Train: [epoch:5]  [ 70/172]  eta: 0:14:34  lr: 0.000080  loss/img_gen_loss: 0.9624 (0.9315)  loss/grad_gen_loss: 0.7186 (0.7090)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0117)  time: 8.5481  data: 0.0003  max mem: 21187\n",
      "Train: [epoch:5]  [ 80/172]  eta: 0:13:08  lr: 0.000080  loss/img_gen_loss: 0.9582 (0.9345)  loss/grad_gen_loss: 0.6889 (0.7049)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 8.5473  data: 0.0003  max mem: 21187\n",
      "Train: [epoch:5]  [ 90/172]  eta: 0:11:42  lr: 0.000080  loss/img_gen_loss: 0.9531 (0.9364)  loss/grad_gen_loss: 0.6868 (0.7049)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 8.5545  data: 0.0004  max mem: 21187\n",
      "Train: [epoch:5]  [100/172]  eta: 0:10:17  lr: 0.000080  loss/img_gen_loss: 0.9509 (0.9378)  loss/grad_gen_loss: 0.7180 (0.7073)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0121 (0.0117)  time: 8.5495  data: 0.0004  max mem: 21187\n",
      "Train: [epoch:5]  [110/172]  eta: 0:08:51  lr: 0.000080  loss/img_gen_loss: 0.9501 (0.9389)  loss/grad_gen_loss: 0.7262 (0.7082)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 8.5439  data: 0.0004  max mem: 21187\n",
      "Train: [epoch:5]  [120/172]  eta: 0:07:25  lr: 0.000080  loss/img_gen_loss: 0.9496 (0.9398)  loss/grad_gen_loss: 0.6606 (0.7037)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0108 (0.0116)  time: 8.5369  data: 0.0005  max mem: 21187\n",
      "Train: [epoch:5]  [130/172]  eta: 0:05:59  lr: 0.000080  loss/img_gen_loss: 0.9488 (0.9404)  loss/grad_gen_loss: 0.6600 (0.7025)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 8.5410  data: 0.0004  max mem: 21187\n",
      "Train: [epoch:5]  [140/172]  eta: 0:04:33  lr: 0.000080  loss/img_gen_loss: 0.9474 (0.9408)  loss/grad_gen_loss: 0.7167 (0.7050)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 8.5428  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:5]  [150/172]  eta: 0:03:08  lr: 0.000080  loss/img_gen_loss: 0.9458 (0.9411)  loss/grad_gen_loss: 0.7301 (0.7058)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0105 (0.0115)  time: 8.5495  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:5]  [160/172]  eta: 0:01:42  lr: 0.000080  loss/img_gen_loss: 0.9448 (0.9413)  loss/grad_gen_loss: 0.7089 (0.7058)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0103 (0.0115)  time: 8.5607  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:5]  [170/172]  eta: 0:00:17  lr: 0.000080  loss/img_gen_loss: 0.9438 (0.9415)  loss/grad_gen_loss: 0.7023 (0.7051)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0103 (0.0114)  time: 8.5419  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:5]  [171/172]  eta: 0:00:08  lr: 0.000080  loss/img_gen_loss: 0.9436 (0.9415)  loss/grad_gen_loss: 0.6989 (0.7050)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0103 (0.0115)  time: 8.5421  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:5] Total time: 0:24:32 (8.5602 s / it)\n",
      "Averaged stats: lr: 0.000080  loss/img_gen_loss: 0.9436 (0.9415)  loss/grad_gen_loss: 0.6989 (0.7050)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0103 (0.0115)\n",
      "Valid: [epoch:5]  [ 0/14]  eta: 0:00:06  L1_loss: 0.0013 (0.0013)  time: 0.4916  data: 0.4711  max mem: 21190\n",
      "Valid: [epoch:5]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0548  data: 0.0348  max mem: 21190\n",
      "Valid: [epoch:5] Total time: 0:00:00 (0.0617 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_5_input_n_20.png\n",
      "Train: [epoch:6]  [  0/172]  eta: 0:24:55  lr: 0.000100  loss/img_gen_loss: 0.9416 (0.9416)  loss/grad_gen_loss: 0.6746 (0.6746)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0100 (0.0100)  time: 8.6939  data: 2.2872  max mem: 21190\n",
      "Train: [epoch:6]  [ 10/172]  eta: 0:18:46  lr: 0.000100  loss/img_gen_loss: 0.9275 (0.9274)  loss/grad_gen_loss: 0.6319 (0.6350)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0113)  time: 6.9547  data: 0.2083  max mem: 21190\n",
      "Train: [epoch:6]  [ 20/172]  eta: 0:17:39  lr: 0.000100  loss/img_gen_loss: 0.9099 (0.9148)  loss/grad_gen_loss: 0.5767 (0.6007)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8849  data: 0.0004  max mem: 21190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:6]  [ 30/172]  eta: 0:16:30  lr: 0.000100  loss/img_gen_loss: 0.8925 (0.9060)  loss/grad_gen_loss: 0.5741 (0.5972)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.9827  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [ 40/172]  eta: 0:15:21  lr: 0.000100  loss/img_gen_loss: 0.8823 (0.8993)  loss/grad_gen_loss: 0.6010 (0.5998)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.9904  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [ 50/172]  eta: 0:14:12  lr: 0.000100  loss/img_gen_loss: 0.8732 (0.8933)  loss/grad_gen_loss: 0.6010 (0.5995)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 7.0022  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [ 60/172]  eta: 0:13:02  lr: 0.000100  loss/img_gen_loss: 0.8634 (0.8877)  loss/grad_gen_loss: 0.5867 (0.5941)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.9921  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:6]  [ 70/172]  eta: 0:11:52  lr: 0.000100  loss/img_gen_loss: 0.8531 (0.8820)  loss/grad_gen_loss: 0.5630 (0.5898)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.9761  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [ 80/172]  eta: 0:10:41  lr: 0.000100  loss/img_gen_loss: 0.8411 (0.8764)  loss/grad_gen_loss: 0.5796 (0.5910)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.9355  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [ 90/172]  eta: 0:09:31  lr: 0.000100  loss/img_gen_loss: 0.8320 (0.8714)  loss/grad_gen_loss: 0.6102 (0.5938)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.9104  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:6]  [100/172]  eta: 0:08:20  lr: 0.000100  loss/img_gen_loss: 0.8318 (0.8677)  loss/grad_gen_loss: 0.6073 (0.5946)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.9009  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [110/172]  eta: 0:07:10  lr: 0.000100  loss/img_gen_loss: 0.8354 (0.8650)  loss/grad_gen_loss: 0.5899 (0.5931)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0105 (0.0115)  time: 6.8780  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [120/172]  eta: 0:06:01  lr: 0.000100  loss/img_gen_loss: 0.8386 (0.8629)  loss/grad_gen_loss: 0.5706 (0.5909)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0110 (0.0115)  time: 6.8688  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:6]  [130/172]  eta: 0:04:51  lr: 0.000100  loss/img_gen_loss: 0.8402 (0.8612)  loss/grad_gen_loss: 0.5724 (0.5906)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0110 (0.0115)  time: 6.8696  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [140/172]  eta: 0:03:41  lr: 0.000100  loss/img_gen_loss: 0.8412 (0.8598)  loss/grad_gen_loss: 0.6019 (0.5921)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0115)  time: 6.8737  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [150/172]  eta: 0:02:32  lr: 0.000100  loss/img_gen_loss: 0.8421 (0.8587)  loss/grad_gen_loss: 0.6097 (0.5934)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0115)  time: 6.8593  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [160/172]  eta: 0:01:23  lr: 0.000100  loss/img_gen_loss: 0.8434 (0.8578)  loss/grad_gen_loss: 0.6106 (0.5945)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0115)  time: 6.8513  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [170/172]  eta: 0:00:13  lr: 0.000100  loss/img_gen_loss: 0.8449 (0.8571)  loss/grad_gen_loss: 0.5991 (0.5947)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)  time: 6.8541  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6]  [171/172]  eta: 0:00:06  lr: 0.000100  loss/img_gen_loss: 0.8450 (0.8570)  loss/grad_gen_loss: 0.5963 (0.5946)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)  time: 6.8563  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:6] Total time: 0:19:50 (6.9200 s / it)\n",
      "Averaged stats: lr: 0.000100  loss/img_gen_loss: 0.8450 (0.8570)  loss/grad_gen_loss: 0.5963 (0.5946)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0115)\n",
      "Valid: [epoch:6]  [ 0/14]  eta: 0:00:05  L1_loss: 0.0013 (0.0013)  time: 0.4063  data: 0.3827  max mem: 21190\n",
      "Valid: [epoch:6]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0518  data: 0.0317  max mem: 21190\n",
      "Valid: [epoch:6] Total time: 0:00:00 (0.0603 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_6_input_n_20.png\n",
      "Train: [epoch:7]  [  0/172]  eta: 0:24:44  lr: 0.000120  loss/img_gen_loss: 0.8468 (0.8468)  loss/grad_gen_loss: 0.5830 (0.5830)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0130 (0.0130)  time: 8.6323  data: 2.3204  max mem: 21190\n",
      "Train: [epoch:7]  [ 10/172]  eta: 0:18:37  lr: 0.000120  loss/img_gen_loss: 0.8477 (0.8477)  loss/grad_gen_loss: 0.5866 (0.5880)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0114)  time: 6.8974  data: 0.2114  max mem: 21190\n",
      "Train: [epoch:7]  [ 20/172]  eta: 0:17:28  lr: 0.000120  loss/img_gen_loss: 0.8486 (0.8486)  loss/grad_gen_loss: 0.6012 (0.6005)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0114)  time: 6.8088  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [ 30/172]  eta: 0:16:19  lr: 0.000120  loss/img_gen_loss: 0.8506 (0.8496)  loss/grad_gen_loss: 0.6067 (0.5999)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.8983  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [ 40/172]  eta: 0:15:09  lr: 0.000120  loss/img_gen_loss: 0.8526 (0.8506)  loss/grad_gen_loss: 0.5929 (0.5977)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0116)  time: 6.8821  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [ 50/172]  eta: 0:13:59  lr: 0.000120  loss/img_gen_loss: 0.8548 (0.8517)  loss/grad_gen_loss: 0.6185 (0.6079)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8654  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [ 60/172]  eta: 0:12:50  lr: 0.000120  loss/img_gen_loss: 0.8572 (0.8528)  loss/grad_gen_loss: 0.6192 (0.6058)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0115)  time: 6.8634  data: 0.0005  max mem: 21190\n",
      "Train: [epoch:7]  [ 70/172]  eta: 0:11:41  lr: 0.000120  loss/img_gen_loss: 0.8598 (0.8540)  loss/grad_gen_loss: 0.5680 (0.5996)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0116)  time: 6.8564  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [ 80/172]  eta: 0:10:32  lr: 0.000120  loss/img_gen_loss: 0.8625 (0.8553)  loss/grad_gen_loss: 0.5626 (0.5965)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0116)  time: 6.8626  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [ 90/172]  eta: 0:09:23  lr: 0.000120  loss/img_gen_loss: 0.8655 (0.8566)  loss/grad_gen_loss: 0.5922 (0.5978)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8678  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [100/172]  eta: 0:08:14  lr: 0.000120  loss/img_gen_loss: 0.8687 (0.8580)  loss/grad_gen_loss: 0.6533 (0.6055)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0117)  time: 6.8635  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [110/172]  eta: 0:07:05  lr: 0.000120  loss/img_gen_loss: 0.8720 (0.8594)  loss/grad_gen_loss: 0.6533 (0.6053)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8521  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [120/172]  eta: 0:05:57  lr: 0.000120  loss/img_gen_loss: 0.8753 (0.8609)  loss/grad_gen_loss: 0.5627 (0.6011)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.8459  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [130/172]  eta: 0:04:48  lr: 0.000120  loss/img_gen_loss: 0.8785 (0.8623)  loss/grad_gen_loss: 0.5627 (0.5991)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0116)  time: 6.8493  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [140/172]  eta: 0:03:39  lr: 0.000120  loss/img_gen_loss: 0.8813 (0.8638)  loss/grad_gen_loss: 0.5842 (0.5984)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8521  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:7]  [150/172]  eta: 0:02:31  lr: 0.000120  loss/img_gen_loss: 0.8835 (0.8651)  loss/grad_gen_loss: 0.5942 (0.5994)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.8540  data: 0.0004  max mem: 21190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:7]  [160/172]  eta: 0:01:22  lr: 0.000120  loss/img_gen_loss: 0.8852 (0.8664)  loss/grad_gen_loss: 0.6189 (0.6012)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.8500  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [170/172]  eta: 0:00:13  lr: 0.000120  loss/img_gen_loss: 0.8863 (0.8676)  loss/grad_gen_loss: 0.6106 (0.6012)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0110 (0.0116)  time: 6.8454  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:7]  [171/172]  eta: 0:00:06  lr: 0.000120  loss/img_gen_loss: 0.8864 (0.8677)  loss/grad_gen_loss: 0.6080 (0.6013)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0108 (0.0116)  time: 6.8501  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:7] Total time: 0:19:40 (6.8649 s / it)\n",
      "Averaged stats: lr: 0.000120  loss/img_gen_loss: 0.8864 (0.8677)  loss/grad_gen_loss: 0.6080 (0.6013)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0108 (0.0116)\n",
      "Valid: [epoch:7]  [ 0/14]  eta: 0:00:06  L1_loss: 0.0011 (0.0011)  time: 0.4407  data: 0.4188  max mem: 21190\n",
      "Valid: [epoch:7]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0510  data: 0.0314  max mem: 21190\n",
      "Valid: [epoch:7] Total time: 0:00:00 (0.0606 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_7_input_n_20.png\n",
      "Train: [epoch:8]  [  0/172]  eta: 0:23:54  lr: 0.000140  loss/img_gen_loss: 0.8869 (0.8869)  loss/grad_gen_loss: 0.6025 (0.6025)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0121 (0.0121)  time: 8.3428  data: 1.9359  max mem: 21190\n",
      "Train: [epoch:8]  [ 10/172]  eta: 0:18:33  lr: 0.000140  loss/img_gen_loss: 0.8872 (0.8871)  loss/grad_gen_loss: 0.6025 (0.6067)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0120 (0.0122)  time: 6.8737  data: 0.1763  max mem: 21190\n",
      "Train: [epoch:8]  [ 20/172]  eta: 0:17:25  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8872)  loss/grad_gen_loss: 0.5936 (0.5891)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0118)  time: 6.8052  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:8]  [ 30/172]  eta: 0:16:17  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5635 (0.5807)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0117)  time: 6.8927  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:8]  [ 40/172]  eta: 0:15:08  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5955 (0.5937)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8898  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:8]  [ 50/172]  eta: 0:13:59  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.6355 (0.6024)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8734  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:8]  [ 60/172]  eta: 0:12:50  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.6114 (0.6004)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0116)  time: 6.8699  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:8]  [ 70/172]  eta: 0:11:41  lr: 0.000140  loss/img_gen_loss: 0.8872 (0.8873)  loss/grad_gen_loss: 0.5833 (0.5979)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.8758  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:8]  [ 80/172]  eta: 0:10:32  lr: 0.000140  loss/img_gen_loss: 0.8872 (0.8873)  loss/grad_gen_loss: 0.5833 (0.5966)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0116)  time: 6.8627  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:8]  [ 90/172]  eta: 0:09:23  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5848 (0.5951)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.8481  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:8]  [100/172]  eta: 0:08:14  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5928 (0.5978)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0116)  time: 6.8617  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:8]  [110/172]  eta: 0:07:06  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5994 (0.5973)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.8665  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:8]  [120/172]  eta: 0:05:57  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5643 (0.5941)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.8494  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:8]  [130/172]  eta: 0:04:48  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5737 (0.5965)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8465  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:8]  [140/172]  eta: 0:03:39  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.6203 (0.5992)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8501  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:8]  [150/172]  eta: 0:02:31  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5989 (0.5977)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.8514  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:8]  [160/172]  eta: 0:01:22  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5809 (0.5979)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.8538  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:8]  [170/172]  eta: 0:00:13  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.6334 (0.6009)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.8417  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:8]  [171/172]  eta: 0:00:06  lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.6334 (0.6010)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8414  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:8] Total time: 0:19:40 (6.8638 s / it)\n",
      "Averaged stats: lr: 0.000140  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.6334 (0.6010)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)\n",
      "Valid: [epoch:8]  [ 0/14]  eta: 0:00:05  L1_loss: 0.0014 (0.0014)  time: 0.4135  data: 0.3917  max mem: 21190\n",
      "Valid: [epoch:8]  [13/14]  eta: 0:00:00  L1_loss: 0.0013 (0.0013)  time: 0.0493  data: 0.0295  max mem: 21190\n",
      "Valid: [epoch:8] Total time: 0:00:00 (0.0573 s / it)\n",
      "Averaged stats: L1_loss: 0.0013 (0.0013)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_8_input_n_20.png\n",
      "Train: [epoch:9]  [  0/172]  eta: 0:24:30  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.6095 (0.6095)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0136 (0.0136)  time: 8.5514  data: 2.2158  max mem: 21190\n",
      "Train: [epoch:9]  [ 10/172]  eta: 0:18:34  lr: 0.000160  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5440 (0.5506)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0112)  time: 6.8767  data: 0.2018  max mem: 21190\n",
      "Train: [epoch:9]  [ 20/172]  eta: 0:17:27  lr: 0.000160  loss/img_gen_loss: 0.8873 (0.8873)  loss/grad_gen_loss: 0.5500 (0.5664)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0113)  time: 6.8107  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:9]  [ 30/172]  eta: 0:16:19  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.6304 (0.6007)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0114)  time: 6.9139  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:9]  [ 40/172]  eta: 0:15:12  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.6197 (0.5970)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0115)  time: 6.9382  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:9]  [ 50/172]  eta: 0:14:03  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.5588 (0.5867)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0115)  time: 6.9292  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:9]  [ 60/172]  eta: 0:12:53  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.5563 (0.5942)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0115)  time: 6.8812  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:9]  [ 70/172]  eta: 0:11:43  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.6438 (0.6043)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.8711  data: 0.0003  max mem: 21190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:9]  [ 80/172]  eta: 0:10:34  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.6048 (0.6015)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.8824  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:9]  [ 90/172]  eta: 0:09:25  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.5696 (0.5981)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0116)  time: 6.8876  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:9]  [100/172]  eta: 0:08:16  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.6088 (0.6021)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0117)  time: 6.8966  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:9]  [110/172]  eta: 0:07:07  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.6145 (0.6009)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0117)  time: 6.8959  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:9]  [120/172]  eta: 0:05:58  lr: 0.000160  loss/img_gen_loss: 0.8874 (0.8874)  loss/grad_gen_loss: 0.5691 (0.5975)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 6.8829  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:9]  [130/172]  eta: 0:04:49  lr: 0.000160  loss/img_gen_loss: 0.8875 (0.8874)  loss/grad_gen_loss: 0.6421 (0.6044)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8820  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:9]  [140/172]  eta: 0:03:40  lr: 0.000160  loss/img_gen_loss: 0.8875 (0.8874)  loss/grad_gen_loss: 0.6380 (0.6038)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0121 (0.0117)  time: 6.8787  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:9]  [150/172]  eta: 0:02:31  lr: 0.000160  loss/img_gen_loss: 0.8875 (0.8874)  loss/grad_gen_loss: 0.5811 (0.6024)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0120 (0.0117)  time: 6.8740  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:9]  [160/172]  eta: 0:01:22  lr: 0.000160  loss/img_gen_loss: 0.8875 (0.8874)  loss/grad_gen_loss: 0.6123 (0.6037)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.8799  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:9]  [170/172]  eta: 0:00:13  lr: 0.000160  loss/img_gen_loss: 0.8875 (0.8874)  loss/grad_gen_loss: 0.6180 (0.6043)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0117)  time: 6.8692  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:9]  [171/172]  eta: 0:00:06  lr: 0.000160  loss/img_gen_loss: 0.8875 (0.8874)  loss/grad_gen_loss: 0.6180 (0.6042)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 6.8657  data: 0.0004  max mem: 21190\n",
      "Train: [epoch:9] Total time: 0:19:45 (6.8902 s / it)\n",
      "Averaged stats: lr: 0.000160  loss/img_gen_loss: 0.8875 (0.8874)  loss/grad_gen_loss: 0.6180 (0.6042)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)\n",
      "Valid: [epoch:9]  [ 0/14]  eta: 0:00:05  L1_loss: 0.0014 (0.0014)  time: 0.3825  data: 0.3563  max mem: 21190\n",
      "Valid: [epoch:9]  [13/14]  eta: 0:00:00  L1_loss: 0.0013 (0.0013)  time: 0.0478  data: 0.0276  max mem: 21190\n",
      "Valid: [epoch:9] Total time: 0:00:00 (0.0562 s / it)\n",
      "Averaged stats: L1_loss: 0.0013 (0.0013)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_9_input_n_20.png\n",
      "Train: [epoch:10]  [  0/172]  eta: 0:22:56  lr: 0.000180  loss/img_gen_loss: 0.8875 (0.8875)  loss/grad_gen_loss: 0.6002 (0.6002)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0104 (0.0104)  time: 8.0005  data: 1.6865  max mem: 21190\n",
      "Train: [epoch:10]  [ 10/172]  eta: 0:18:28  lr: 0.000180  loss/img_gen_loss: 0.8875 (0.8875)  loss/grad_gen_loss: 0.6150 (0.6200)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8399  data: 0.1537  max mem: 21190\n",
      "Train: [epoch:10]  [ 20/172]  eta: 0:17:24  lr: 0.000180  loss/img_gen_loss: 0.8875 (0.8875)  loss/grad_gen_loss: 0.6049 (0.6087)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0114)  time: 6.8157  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [ 30/172]  eta: 0:16:16  lr: 0.000180  loss/img_gen_loss: 0.8875 (0.8875)  loss/grad_gen_loss: 0.6022 (0.6094)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.8982  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [ 40/172]  eta: 0:15:08  lr: 0.000180  loss/img_gen_loss: 0.8875 (0.8875)  loss/grad_gen_loss: 0.6172 (0.6130)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8916  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [ 50/172]  eta: 0:13:59  lr: 0.000180  loss/img_gen_loss: 0.8875 (0.8875)  loss/grad_gen_loss: 0.6268 (0.6155)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0118)  time: 6.8843  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [ 60/172]  eta: 0:12:50  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8875)  loss/grad_gen_loss: 0.5860 (0.6060)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0119)  time: 6.8729  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [ 70/172]  eta: 0:11:41  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8875)  loss/grad_gen_loss: 0.5753 (0.6099)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0118)  time: 6.8877  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:10]  [ 80/172]  eta: 0:10:33  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8875)  loss/grad_gen_loss: 0.6208 (0.6103)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0118)  time: 6.8949  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [ 90/172]  eta: 0:09:24  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8876)  loss/grad_gen_loss: 0.5708 (0.6029)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0118)  time: 6.8718  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [100/172]  eta: 0:08:15  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8876)  loss/grad_gen_loss: 0.5576 (0.6062)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0118)  time: 6.8583  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [110/172]  eta: 0:07:06  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8876)  loss/grad_gen_loss: 0.6366 (0.6097)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0118)  time: 6.8521  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:10]  [120/172]  eta: 0:05:57  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8876)  loss/grad_gen_loss: 0.5810 (0.6055)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0118)  time: 6.8592  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:10]  [130/172]  eta: 0:04:48  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8876)  loss/grad_gen_loss: 0.5494 (0.6007)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0118)  time: 6.8748  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:10]  [140/172]  eta: 0:03:40  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8876)  loss/grad_gen_loss: 0.5743 (0.6028)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0118)  time: 6.8800  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [150/172]  eta: 0:02:31  lr: 0.000180  loss/img_gen_loss: 0.8876 (0.8876)  loss/grad_gen_loss: 0.6439 (0.6067)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0117)  time: 6.8874  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [160/172]  eta: 0:01:22  lr: 0.000180  loss/img_gen_loss: 0.8877 (0.8876)  loss/grad_gen_loss: 0.6047 (0.6043)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0117)  time: 6.8778  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [170/172]  eta: 0:00:13  lr: 0.000180  loss/img_gen_loss: 0.8877 (0.8876)  loss/grad_gen_loss: 0.5687 (0.6040)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.8631  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10]  [171/172]  eta: 0:00:06  lr: 0.000180  loss/img_gen_loss: 0.8877 (0.8876)  loss/grad_gen_loss: 0.5687 (0.6042)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.8617  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:10] Total time: 0:19:42 (6.8756 s / it)\n",
      "Averaged stats: lr: 0.000180  loss/img_gen_loss: 0.8877 (0.8876)  loss/grad_gen_loss: 0.5687 (0.6042)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)\n",
      "Valid: [epoch:10]  [ 0/14]  eta: 0:00:06  L1_loss: 0.0013 (0.0013)  time: 0.4471  data: 0.4209  max mem: 21190\n",
      "Valid: [epoch:10]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0013)  time: 0.0515  data: 0.0306  max mem: 21190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: [epoch:10] Total time: 0:00:00 (0.0602 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0013)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_10_input_n_20.png\n",
      "Train: [epoch:11]  [  0/172]  eta: 0:26:03  lr: 0.000200  loss/img_gen_loss: 0.8877 (0.8877)  loss/grad_gen_loss: 0.6426 (0.6426)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0098 (0.0098)  time: 9.0896  data: 2.7306  max mem: 21190\n",
      "Train: [epoch:11]  [ 10/172]  eta: 0:18:43  lr: 0.000200  loss/img_gen_loss: 0.8877 (0.8877)  loss/grad_gen_loss: 0.6366 (0.6326)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0109 (0.0113)  time: 6.9325  data: 0.2485  max mem: 21190\n",
      "Train: [epoch:11]  [ 20/172]  eta: 0:17:31  lr: 0.000200  loss/img_gen_loss: 0.8877 (0.8877)  loss/grad_gen_loss: 0.6005 (0.6113)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0109 (0.0111)  time: 6.8058  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [ 30/172]  eta: 0:16:20  lr: 0.000200  loss/img_gen_loss: 0.8877 (0.8877)  loss/grad_gen_loss: 0.6005 (0.6174)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0110 (0.0112)  time: 6.8892  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [ 40/172]  eta: 0:15:10  lr: 0.000200  loss/img_gen_loss: 0.8877 (0.8877)  loss/grad_gen_loss: 0.6206 (0.6132)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0113)  time: 6.8767  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [ 50/172]  eta: 0:14:00  lr: 0.000200  loss/img_gen_loss: 0.8877 (0.8877)  loss/grad_gen_loss: 0.5604 (0.5979)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0113)  time: 6.8729  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [ 60/172]  eta: 0:12:52  lr: 0.000200  loss/img_gen_loss: 0.8877 (0.8877)  loss/grad_gen_loss: 0.5358 (0.5948)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0114)  time: 6.8868  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [ 70/172]  eta: 0:11:42  lr: 0.000200  loss/img_gen_loss: 0.8877 (0.8877)  loss/grad_gen_loss: 0.6326 (0.6111)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0115)  time: 6.8895  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [ 80/172]  eta: 0:10:33  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8877)  loss/grad_gen_loss: 0.6274 (0.6088)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0120 (0.0116)  time: 6.8789  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [ 90/172]  eta: 0:09:24  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8877)  loss/grad_gen_loss: 0.5612 (0.5980)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0116)  time: 6.8677  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [100/172]  eta: 0:08:15  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8877)  loss/grad_gen_loss: 0.5612 (0.6039)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0116)  time: 6.8618  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [110/172]  eta: 0:07:06  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8877)  loss/grad_gen_loss: 0.6489 (0.6082)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.8536  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:11]  [120/172]  eta: 0:05:57  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8877)  loss/grad_gen_loss: 0.6127 (0.6076)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0117)  time: 6.8364  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:11]  [130/172]  eta: 0:04:48  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8878)  loss/grad_gen_loss: 0.5991 (0.6077)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 6.8458  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [140/172]  eta: 0:03:39  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8878)  loss/grad_gen_loss: 0.6062 (0.6076)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.8509  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [150/172]  eta: 0:02:31  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8878)  loss/grad_gen_loss: 0.5990 (0.6071)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.8445  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [160/172]  eta: 0:01:22  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8878)  loss/grad_gen_loss: 0.5961 (0.6059)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.8413  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:11]  [170/172]  eta: 0:00:13  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8878)  loss/grad_gen_loss: 0.5861 (0.6051)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.8474  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11]  [171/172]  eta: 0:00:06  lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8878)  loss/grad_gen_loss: 0.5884 (0.6050)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)  time: 6.8473  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:11] Total time: 0:19:41 (6.8687 s / it)\n",
      "Averaged stats: lr: 0.000200  loss/img_gen_loss: 0.8878 (0.8878)  loss/grad_gen_loss: 0.5884 (0.6050)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0116)\n",
      "Valid: [epoch:11]  [ 0/14]  eta: 0:00:05  L1_loss: 0.0013 (0.0013)  time: 0.3819  data: 0.3618  max mem: 21190\n",
      "Valid: [epoch:11]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0472  data: 0.0275  max mem: 21190\n",
      "Valid: [epoch:11] Total time: 0:00:00 (0.0552 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_11_input_n_20.png\n",
      "Train: [epoch:12]  [  0/172]  eta: 0:28:10  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.6112 (0.6112)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0130 (0.0130)  time: 9.8279  data: 2.8127  max mem: 21190\n",
      "Train: [epoch:12]  [ 10/172]  eta: 0:18:55  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.6449 (0.6410)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 7.0078  data: 0.2560  max mem: 21190\n",
      "Train: [epoch:12]  [ 20/172]  eta: 0:17:37  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.6236 (0.6245)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.8162  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [ 30/172]  eta: 0:16:24  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.5982 (0.6153)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.8928  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [ 40/172]  eta: 0:15:13  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.5905 (0.6080)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 6.8850  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [ 50/172]  eta: 0:14:03  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.5880 (0.6064)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.8927  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [ 60/172]  eta: 0:12:53  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.6186 (0.6112)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.8767  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:12]  [ 70/172]  eta: 0:11:43  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.6199 (0.6105)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0118)  time: 6.8597  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:12]  [ 80/172]  eta: 0:10:34  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.5860 (0.6058)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0122 (0.0118)  time: 6.8549  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [ 90/172]  eta: 0:09:25  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.5604 (0.6009)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0118)  time: 6.8582  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [100/172]  eta: 0:08:15  lr: 0.000200  loss/img_gen_loss: 0.8879 (0.8879)  loss/grad_gen_loss: 0.5907 (0.6043)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0117)  time: 6.8599  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [110/172]  eta: 0:07:06  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8879)  loss/grad_gen_loss: 0.6263 (0.6055)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0117)  time: 6.8577  data: 0.0003  max mem: 21190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:12]  [120/172]  eta: 0:05:58  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8879)  loss/grad_gen_loss: 0.5862 (0.6038)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0118)  time: 6.8720  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [130/172]  eta: 0:04:49  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8879)  loss/grad_gen_loss: 0.6154 (0.6079)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0117)  time: 6.8879  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [140/172]  eta: 0:03:40  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8879)  loss/grad_gen_loss: 0.5936 (0.6061)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0118)  time: 6.8957  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [150/172]  eta: 0:02:31  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8879)  loss/grad_gen_loss: 0.5836 (0.6042)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0117)  time: 6.8903  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [160/172]  eta: 0:01:22  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8879)  loss/grad_gen_loss: 0.5883 (0.6039)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0105 (0.0117)  time: 6.8800  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [170/172]  eta: 0:00:13  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8880)  loss/grad_gen_loss: 0.6094 (0.6046)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8866  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12]  [171/172]  eta: 0:00:06  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8880)  loss/grad_gen_loss: 0.6094 (0.6045)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8849  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:12] Total time: 0:19:44 (6.8872 s / it)\n",
      "Averaged stats: lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8880)  loss/grad_gen_loss: 0.6094 (0.6045)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)\n",
      "Valid: [epoch:12]  [ 0/14]  eta: 0:00:08  L1_loss: 0.0012 (0.0012)  time: 0.6426  data: 0.6196  max mem: 21190\n",
      "Valid: [epoch:12]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0658  data: 0.0457  max mem: 21190\n",
      "Valid: [epoch:12] Total time: 0:00:01 (0.0725 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_12_input_n_20.png\n",
      "Train: [epoch:13]  [  0/172]  eta: 0:27:09  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8880)  loss/grad_gen_loss: 0.6137 (0.6137)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0114)  time: 9.4748  data: 2.8661  max mem: 21190\n",
      "Train: [epoch:13]  [ 10/172]  eta: 0:18:52  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8880)  loss/grad_gen_loss: 0.6038 (0.6025)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.9929  data: 0.2608  max mem: 21190\n",
      "Train: [epoch:13]  [ 20/172]  eta: 0:17:35  lr: 0.000200  loss/img_gen_loss: 0.8880 (0.8880)  loss/grad_gen_loss: 0.6093 (0.6168)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.8174  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [ 30/172]  eta: 0:16:24  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.6212 (0.6173)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0116)  time: 6.9009  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [ 40/172]  eta: 0:15:13  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.6010 (0.6058)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0116)  time: 6.8924  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [ 50/172]  eta: 0:14:03  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.5618 (0.5977)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0118)  time: 6.8776  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [ 60/172]  eta: 0:12:53  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.6176 (0.6100)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0118)  time: 6.8846  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [ 70/172]  eta: 0:11:44  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.6361 (0.6113)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.8841  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [ 80/172]  eta: 0:10:34  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.5887 (0.6075)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 6.8663  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [ 90/172]  eta: 0:09:25  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.5792 (0.6045)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0117)  time: 6.8521  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:13]  [100/172]  eta: 0:08:16  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.5869 (0.6078)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0117)  time: 6.8545  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [110/172]  eta: 0:07:06  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.6260 (0.6073)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0117)  time: 6.8604  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [120/172]  eta: 0:05:57  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.5606 (0.6026)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.8623  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [130/172]  eta: 0:04:49  lr: 0.000200  loss/img_gen_loss: 0.8881 (0.8881)  loss/grad_gen_loss: 0.5606 (0.6041)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0117)  time: 6.8557  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [140/172]  eta: 0:03:40  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8881)  loss/grad_gen_loss: 0.6298 (0.6067)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0117)  time: 6.8562  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [150/172]  eta: 0:02:31  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8881)  loss/grad_gen_loss: 0.5750 (0.6035)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0117)  time: 6.8629  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [160/172]  eta: 0:01:22  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8881)  loss/grad_gen_loss: 0.5623 (0.6022)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0116)  time: 6.8638  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [170/172]  eta: 0:00:13  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8881)  loss/grad_gen_loss: 0.6216 (0.6044)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0116)  time: 6.8821  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13]  [171/172]  eta: 0:00:06  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8881)  loss/grad_gen_loss: 0.6216 (0.6044)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0116)  time: 6.8838  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:13] Total time: 0:19:43 (6.8805 s / it)\n",
      "Averaged stats: lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8881)  loss/grad_gen_loss: 0.6216 (0.6044)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0116)\n",
      "Valid: [epoch:13]  [ 0/14]  eta: 0:00:07  L1_loss: 0.0013 (0.0013)  time: 0.5036  data: 0.4800  max mem: 21190\n",
      "Valid: [epoch:13]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0551  data: 0.0345  max mem: 21190\n",
      "Valid: [epoch:13] Total time: 0:00:00 (0.0635 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_13_input_n_20.png\n",
      "Train: [epoch:14]  [  0/172]  eta: 0:23:31  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8882)  loss/grad_gen_loss: 0.6039 (0.6039)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0108 (0.0108)  time: 8.2075  data: 1.8513  max mem: 21190\n",
      "Train: [epoch:14]  [ 10/172]  eta: 0:18:36  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8882)  loss/grad_gen_loss: 0.5689 (0.5695)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0108 (0.0108)  time: 6.8896  data: 0.1686  max mem: 21190\n",
      "Train: [epoch:14]  [ 20/172]  eta: 0:17:29  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8882)  loss/grad_gen_loss: 0.5775 (0.5823)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0108 (0.0109)  time: 6.8419  data: 0.0003  max mem: 21190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:14]  [ 30/172]  eta: 0:16:20  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8882)  loss/grad_gen_loss: 0.6102 (0.5966)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0109)  time: 6.9143  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [ 40/172]  eta: 0:15:11  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8882)  loss/grad_gen_loss: 0.6022 (0.5928)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0112)  time: 6.9081  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [ 50/172]  eta: 0:14:02  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8882)  loss/grad_gen_loss: 0.5839 (0.5937)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0113)  time: 6.9083  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [ 60/172]  eta: 0:12:52  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8882)  loss/grad_gen_loss: 0.6131 (0.5985)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0114)  time: 6.8788  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [ 70/172]  eta: 0:11:42  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8882)  loss/grad_gen_loss: 0.5937 (0.5957)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0114)  time: 6.8544  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:14]  [ 80/172]  eta: 0:10:34  lr: 0.000200  loss/img_gen_loss: 0.8882 (0.8882)  loss/grad_gen_loss: 0.5840 (0.5964)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0116)  time: 6.8771  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [ 90/172]  eta: 0:09:24  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8882)  loss/grad_gen_loss: 0.6188 (0.6013)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0116)  time: 6.8775  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [100/172]  eta: 0:08:15  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8882)  loss/grad_gen_loss: 0.5932 (0.5976)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0116)  time: 6.8696  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [110/172]  eta: 0:07:07  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8882)  loss/grad_gen_loss: 0.5899 (0.6009)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0115)  time: 6.8938  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:14]  [120/172]  eta: 0:05:58  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8882)  loss/grad_gen_loss: 0.6308 (0.6036)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0115)  time: 6.9092  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:14]  [130/172]  eta: 0:04:49  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8882)  loss/grad_gen_loss: 0.5721 (0.6001)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.9102  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [140/172]  eta: 0:03:40  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8882)  loss/grad_gen_loss: 0.5718 (0.5994)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0116)  time: 6.8918  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [150/172]  eta: 0:02:31  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8883)  loss/grad_gen_loss: 0.5902 (0.6005)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.8823  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [160/172]  eta: 0:01:22  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8883)  loss/grad_gen_loss: 0.6212 (0.6021)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0116)  time: 6.8838  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [170/172]  eta: 0:00:13  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8883)  loss/grad_gen_loss: 0.6018 (0.6008)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0116)  time: 6.8828  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14]  [171/172]  eta: 0:00:06  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8883)  loss/grad_gen_loss: 0.6018 (0.6009)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0116)  time: 6.8800  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:14] Total time: 0:19:45 (6.8911 s / it)\n",
      "Averaged stats: lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8883)  loss/grad_gen_loss: 0.6018 (0.6009)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0116)\n",
      "Valid: [epoch:14]  [ 0/14]  eta: 0:00:05  L1_loss: 0.0013 (0.0013)  time: 0.3953  data: 0.3745  max mem: 21190\n",
      "Valid: [epoch:14]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0465  data: 0.0269  max mem: 21190\n",
      "Valid: [epoch:14] Total time: 0:00:00 (0.0541 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_14_input_n_20.png\n",
      "Train: [epoch:15]  [  0/172]  eta: 0:28:37  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8883)  loss/grad_gen_loss: 0.5881 (0.5881)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0108 (0.0108)  time: 9.9883  data: 3.6860  max mem: 21190\n",
      "Train: [epoch:15]  [ 10/172]  eta: 0:19:02  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8883)  loss/grad_gen_loss: 0.5980 (0.6009)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0110 (0.0114)  time: 7.0522  data: 0.3353  max mem: 21190\n",
      "Train: [epoch:15]  [ 20/172]  eta: 0:17:43  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8883)  loss/grad_gen_loss: 0.6146 (0.6178)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0108 (0.0112)  time: 6.8493  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [ 30/172]  eta: 0:16:30  lr: 0.000200  loss/img_gen_loss: 0.8883 (0.8883)  loss/grad_gen_loss: 0.6054 (0.6106)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0115)  time: 6.9299  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [ 40/172]  eta: 0:15:18  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8883)  loss/grad_gen_loss: 0.5987 (0.6097)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0124 (0.0117)  time: 6.9159  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [ 50/172]  eta: 0:14:08  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6055 (0.6091)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0123 (0.0118)  time: 6.9189  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [ 60/172]  eta: 0:12:58  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6050 (0.6082)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0123 (0.0118)  time: 6.9222  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:15]  [ 70/172]  eta: 0:11:48  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6144 (0.6115)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0118)  time: 6.9176  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:15]  [ 80/172]  eta: 0:10:38  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6238 (0.6099)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0117)  time: 6.9185  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [ 90/172]  eta: 0:09:28  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.5549 (0.6032)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.9158  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [100/172]  eta: 0:08:19  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.5619 (0.6082)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.9153  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [110/172]  eta: 0:07:09  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6360 (0.6095)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.8930  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [120/172]  eta: 0:06:00  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.5647 (0.6032)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0117)  time: 6.8651  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [130/172]  eta: 0:04:50  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.5539 (0.6056)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.8682  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [140/172]  eta: 0:03:41  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6298 (0.6090)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0115 (0.0117)  time: 6.8683  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [150/172]  eta: 0:02:32  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6034 (0.6068)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0121 (0.0117)  time: 6.8597  data: 0.0003  max mem: 21190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:15]  [160/172]  eta: 0:01:22  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6016 (0.6083)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8603  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [170/172]  eta: 0:00:13  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6288 (0.6098)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8557  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15]  [171/172]  eta: 0:00:06  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6288 (0.6097)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8586  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:15] Total time: 0:19:47 (6.9056 s / it)\n",
      "Averaged stats: lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.6288 (0.6097)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)\n",
      "Valid: [epoch:15]  [ 0/14]  eta: 0:00:06  L1_loss: 0.0015 (0.0015)  time: 0.4448  data: 0.4246  max mem: 21190\n",
      "Valid: [epoch:15]  [13/14]  eta: 0:00:00  L1_loss: 0.0013 (0.0014)  time: 0.0526  data: 0.0319  max mem: 21190\n",
      "Valid: [epoch:15] Total time: 0:00:00 (0.0607 s / it)\n",
      "Averaged stats: L1_loss: 0.0013 (0.0014)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_15_input_n_20.png\n",
      "Train: [epoch:16]  [  0/172]  eta: 0:26:43  lr: 0.000200  loss/img_gen_loss: 0.8884 (0.8884)  loss/grad_gen_loss: 0.5939 (0.5939)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0104 (0.0104)  time: 9.3229  data: 2.9685  max mem: 21190\n",
      "Train: [epoch:16]  [ 10/172]  eta: 0:18:46  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.6323 (0.6273)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0118)  time: 6.9522  data: 0.2701  max mem: 21190\n",
      "Train: [epoch:16]  [ 20/172]  eta: 0:17:31  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.6279 (0.6240)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0120 (0.0118)  time: 6.7978  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [ 30/172]  eta: 0:16:20  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5594 (0.5966)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0117)  time: 6.8828  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [ 40/172]  eta: 0:15:10  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5594 (0.6100)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0118)  time: 6.8820  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:16]  [ 50/172]  eta: 0:14:01  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.6593 (0.6209)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0123 (0.0120)  time: 6.8795  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [ 60/172]  eta: 0:12:52  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.6314 (0.6191)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0122 (0.0119)  time: 6.8880  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [ 70/172]  eta: 0:11:43  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5973 (0.6155)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0119)  time: 6.9075  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [ 80/172]  eta: 0:10:34  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.6139 (0.6192)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0119)  time: 6.9070  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [ 90/172]  eta: 0:09:25  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.6307 (0.6160)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0119)  time: 6.8838  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [100/172]  eta: 0:08:16  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5726 (0.6113)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0119)  time: 6.8775  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [110/172]  eta: 0:07:07  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5974 (0.6152)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0119)  time: 6.8802  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [120/172]  eta: 0:05:58  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.6386 (0.6150)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0111 (0.0118)  time: 6.8723  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [130/172]  eta: 0:04:49  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5597 (0.6097)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0112 (0.0118)  time: 6.8539  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [140/172]  eta: 0:03:40  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5550 (0.6076)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0122 (0.0118)  time: 6.8537  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [150/172]  eta: 0:02:31  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.6077 (0.6123)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0118)  time: 6.8599  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [160/172]  eta: 0:01:22  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.6578 (0.6128)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0118)  time: 6.8672  data: 0.0002  max mem: 21190\n",
      "Train: [epoch:16]  [170/172]  eta: 0:00:13  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5683 (0.6083)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0118)  time: 6.8771  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16]  [171/172]  eta: 0:00:06  lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5559 (0.6080)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0118)  time: 6.8726  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:16] Total time: 0:19:43 (6.8836 s / it)\n",
      "Averaged stats: lr: 0.000200  loss/img_gen_loss: 0.8885 (0.8885)  loss/grad_gen_loss: 0.5559 (0.6080)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0118)\n",
      "Valid: [epoch:16]  [ 0/14]  eta: 0:00:06  L1_loss: 0.0011 (0.0011)  time: 0.4509  data: 0.4225  max mem: 21190\n",
      "Valid: [epoch:16]  [13/14]  eta: 0:00:00  L1_loss: 0.0012 (0.0012)  time: 0.0647  data: 0.0441  max mem: 21190\n",
      "Valid: [epoch:16] Total time: 0:00:01 (0.0729 s / it)\n",
      "Averaged stats: L1_loss: 0.0012 (0.0012)\n",
      "/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/epoch_16_input_n_20.png\n",
      "Train: [epoch:17]  [  0/172]  eta: 0:26:30  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.5753 (0.5753)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0130 (0.0130)  time: 9.2472  data: 2.8298  max mem: 21190\n",
      "Train: [epoch:17]  [ 10/172]  eta: 0:18:53  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.6639 (0.6546)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0121 (0.0121)  time: 6.9998  data: 0.2576  max mem: 21190\n",
      "Train: [epoch:17]  [ 20/172]  eta: 0:17:38  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.6271 (0.6313)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0114 (0.0119)  time: 6.8502  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:17]  [ 30/172]  eta: 0:16:26  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.5669 (0.6088)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0120)  time: 6.9227  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:17]  [ 40/172]  eta: 0:15:16  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.5711 (0.6140)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0113 (0.0118)  time: 6.9200  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:17]  [ 50/172]  eta: 0:14:06  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.6473 (0.6221)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0118)  time: 6.9203  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:17]  [ 60/172]  eta: 0:12:55  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.6167 (0.6188)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0118)  time: 6.8972  data: 0.0003  max mem: 21190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [epoch:17]  [ 70/172]  eta: 0:11:46  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.5970 (0.6162)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0118 (0.0118)  time: 6.8790  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:17]  [ 80/172]  eta: 0:10:36  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.5862 (0.6117)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0119 (0.0119)  time: 6.8802  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:17]  [ 90/172]  eta: 0:09:26  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.5863 (0.6113)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0117 (0.0118)  time: 6.8721  data: 0.0003  max mem: 21190\n",
      "Train: [epoch:17]  [100/172]  eta: 0:08:17  lr: 0.000200  loss/img_gen_loss: 0.8886 (0.8886)  loss/grad_gen_loss: 0.6192 (0.6140)  loss/pix_loss: 0.0000 (0.0000)  loss/grad_loss: 0.0116 (0.0118)  time: 6.8784  data: 0.0003  max mem: 21190\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--batch-size 40 \\\n",
    "--epochs 20000 \\\n",
    "--min-lr 5e-6 \\\n",
    "--lr 2e-4 \\\n",
    "--data-set 'Sinogram_DCM' \\\n",
    "--model-name 'DU_GAN' \\\n",
    "--criterion 'L1 Loss' \\\n",
    "--output_dir '/workspace/sunggu/4.Dose_img2img/model/[Privious]DU_GAN' \\\n",
    "--save_dir '/workspace/sunggu/4.Dose_img2img/Predictions/Train/png/[Privious]DU_GAN/low2high/' \\\n",
    "--validate-every 1 \\\n",
    "--num_workers 4 \\\n",
    "--criterion_mode 'not balance' \\\n",
    "--multiple_GT \"False\" \\\n",
    "--patch_training \"True\" \\\n",
    "--multi-gpu-mode 'Single' \\\n",
    "--resume '/workspace/sunggu/4.Dose_img2img/model/[Privious]DU_GAN/epoch_1083_checkpoint.pth'\n",
    "\n",
    "# --multi-gpu-mode 'DataParallel' \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "논문 읽고 구현 E-former / SACNN 까지만 해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
